[
  {
    "text": " OK.",
    "start": "0",
    "end": "5470"
  },
  {
    "text": "I'm live. How's everybody doing? [INAUDIBLE] People are still here. That's good. How's the assignment one going?",
    "start": "5470",
    "end": "12059"
  },
  {
    "text": "[INAUDIBLE] Pretty good. There's been a lot of conceptual\nquestions in office hours, which",
    "start": "12060",
    "end": "17900"
  },
  {
    "text": "I actually think is correct. I would think about it this way. I've given you four concepts,\nlike this idea of multicore",
    "start": "17900",
    "end": "26840"
  },
  {
    "text": "or SIMD, multithreading, and\na little bit of superscalar. I think that's all four.",
    "start": "26840",
    "end": "33140"
  },
  {
    "text": "And so step one is for\nyou to understand them all in isolation,\ncompletely in isolation.",
    "start": "33140",
    "end": "39710"
  },
  {
    "text": "And your written\nassignment that is out-- you can start taking a look at--",
    "start": "39710",
    "end": "45050"
  },
  {
    "text": "definitely should be able\nto answer those questions. That's like concept from\nthe slide, apply it.",
    "start": "45050",
    "end": "53120"
  },
  {
    "text": "I bet you can answer\nthose questions. When we go to the\nprogramming assignment, you're now running\non real hardware.",
    "start": "53120",
    "end": "59305"
  },
  {
    "text": "[LAUGHS] And real hardware\nis a little messy.",
    "start": "59305",
    "end": "64819"
  },
  {
    "text": "And that real hardware is\nbasically composing all four of those concepts\ntogether at once.",
    "start": "64819",
    "end": "71870"
  },
  {
    "text": "And so it's OK if\nyou're like, well, based on first principles,\nwhat we said in lecture, I should observe this, but\nI'm actually observing this.",
    "start": "71870",
    "end": "79980"
  },
  {
    "text": "And so I'm a little bit\ndoubting my understanding of the core principles. Just come to office hours,\nwe'll talk about it.",
    "start": "79980",
    "end": "85528"
  },
  {
    "text": "Often I can say, no,\nyour understanding is completely correct. It's just some\neffects are mixing. The two things you understand\nare now mixing and interacting.",
    "start": "85528",
    "end": "93560"
  },
  {
    "text": "And you can explain\nwhat you're seeing. You just have to think about\nit a little bit harder. So the mixing of it,\nI think, is where",
    "start": "93560",
    "end": "100130"
  },
  {
    "text": "it gets a little bit complex. And you're just going to\nsee it over and over again, and you're going to become\nmuch more acquainted with it",
    "start": "100130",
    "end": "106159"
  },
  {
    "text": "as time goes on. So I would not worry too much. I'll put it this way. One year in this\nclass, a long time",
    "start": "106160",
    "end": "112880"
  },
  {
    "text": "ago, we had final projects\nwhere people could do anything that you wanted. And probably the most creative\nproject that I've ever seen",
    "start": "112880",
    "end": "120320"
  },
  {
    "text": "is like, a student\ncame up to me and says, everybody works so\nhard in this class, but when you think\nabout it, everything",
    "start": "120320",
    "end": "126240"
  },
  {
    "text": "you teach us is stuff\nthat people do already. You get busy, you go\ndo something else. Or you have 10 tasks to do and\n3 people to do it, you just",
    "start": "126240",
    "end": "134940"
  },
  {
    "text": "go do that do that. So the final project\nwas to actually ask a bunch of exam questions\nor midterm questions",
    "start": "134940",
    "end": "141450"
  },
  {
    "text": "to people on the street,\nlike in a TV show, except they answered\nthe questions--",
    "start": "141450",
    "end": "146740"
  },
  {
    "text": "they ask the questions in\nterms of real-life metaphors and actually wanted\nto compute what the average person in the\nworld would get on a 149 exam,",
    "start": "146740",
    "end": "155340"
  },
  {
    "text": "if they just didn't have\ncomputer science concepts in it. And they actually\nscored pretty good. So that was a pretty\ngood final project.",
    "start": "155340",
    "end": "160810"
  },
  {
    "text": "So the stuff is actually\nconceptually challenging because of the composition,\nbut it's actually",
    "start": "160810",
    "end": "166769"
  },
  {
    "text": "quite easy in first principles. So you'll get it. I wanted to-- but one\nthing I wanted to do",
    "start": "166770",
    "end": "174300"
  },
  {
    "text": "is I want to go over\na lot from last time, again, given what\neverybody's asking me.",
    "start": "174300",
    "end": "180090"
  },
  {
    "text": "And let's talk about a\nlot of this as a class because last time was the first\ntime I was forcing you to think",
    "start": "180090",
    "end": "189469"
  },
  {
    "text": "about what is the program,\nthe parallel program, mean in terms of what\nshould it compute",
    "start": "189470",
    "end": "197660"
  },
  {
    "text": "And then there's a whole bunch\nof questions about how does it actually run on a computer.",
    "start": "197660",
    "end": "203330"
  },
  {
    "text": "And to keep those very\nseparate in your mind, there is a very, very helpful\nskill, both as a programmer",
    "start": "203330",
    "end": "209420"
  },
  {
    "text": "or if you're ever\ndesigning any system. So here is just this the\nsame example from last time.",
    "start": "209420",
    "end": "215970"
  },
  {
    "text": "I'll page it back in\nfor if you forgot. This is the same example\neven from last week, which is we're computing--\nwe have an array of numbers,",
    "start": "215970",
    "end": "224180"
  },
  {
    "text": "and we're computing the-- for\nevery element of that array, we're computing the sign. And this is just normal C code.",
    "start": "224180",
    "end": "230790"
  },
  {
    "text": "And at some point I\ncall this ISPC function. And an ISPC function\ndiffers from a normal C",
    "start": "230790",
    "end": "238040"
  },
  {
    "text": "function in what way? ",
    "start": "238040",
    "end": "245160"
  },
  {
    "text": "When I call a normalcy\nfunction, it's go look up-- if I go to the code,\nI go to this code,",
    "start": "245160",
    "end": "252430"
  },
  {
    "text": "if this is the\nnormal C function, my control just transfers\nto the top of this function",
    "start": "252430",
    "end": "258299"
  },
  {
    "text": "and I run those instructions. I do what the program\nsays sequentially,",
    "start": "258300",
    "end": "263430"
  },
  {
    "text": "and then I end up going\nback to the caller.",
    "start": "263430",
    "end": "269581"
  },
  {
    "text": "So, how does an ISPC\nfunction differ from that? Yes, sir. It's like eight instances\nof the same thing",
    "start": "269581",
    "end": "276060"
  },
  {
    "text": "with their local variables. Exactly. So this function\ncall here is not saying just move over to\nthat sequence of logic",
    "start": "276060",
    "end": "284370"
  },
  {
    "text": "and run it and then come back. It's saying, I want you to move\nover to this sequence of logic",
    "start": "284370",
    "end": "290729"
  },
  {
    "text": "and run it gang-size times. And let's just say\nour gang size is 8, because that's what's\ntrue in my illustrations,",
    "start": "290730",
    "end": "297580"
  },
  {
    "text": "we're going to run this\ncode eight different times. And each time, one little\ndetail will be different.",
    "start": "297580",
    "end": "305120"
  },
  {
    "text": "What is that detail? Program index. Program index. The value of program index,\nwhich just says basically which",
    "start": "305120",
    "end": "312500"
  },
  {
    "text": "time is this, which of these\neight copies of the program I'm going to run,\nwhich one is this.",
    "start": "312500",
    "end": "320380"
  },
  {
    "text": "Notice that so far,\nI've said nothing about parallelism\nor implementation,",
    "start": "320380",
    "end": "325639"
  },
  {
    "text": "but everything\nI've said is true. And if you want those eight\ndifferent copies of this program",
    "start": "325640",
    "end": "330980"
  },
  {
    "text": "to together do all the\nwork we need to do, notice that every\nprogram is sequential.",
    "start": "330980",
    "end": "338430"
  },
  {
    "text": "This is just a set\nof instructions that run back to back to back. And every program does\nsomething a little bit different",
    "start": "338430",
    "end": "345290"
  },
  {
    "text": "because its logic is dependent\non the value of program index.",
    "start": "345290",
    "end": "350770"
  },
  {
    "text": "Does that make sense? So this is the point where\neight copies of the function",
    "start": "350770",
    "end": "356020"
  },
  {
    "text": "get created, and the return\nvalue is the point when those copies have completed.",
    "start": "356020",
    "end": "363760"
  },
  {
    "text": "Again, no talk of\nimplementation at this time. So, are there any\nquestions about that?",
    "start": "363760",
    "end": "371187"
  },
  {
    "text": "This is a good time\nto ask a question. Yes, sir. How is the gang size determined?",
    "start": "371187",
    "end": "377320"
  },
  {
    "text": "Determined? It is determined-- you\njust said it, like, at compile time in your\nflags actually, it's like,",
    "start": "377320",
    "end": "383050"
  },
  {
    "text": "at compile time,\ngang size will be 8 or gang size will be 4, or 16. Yes.",
    "start": "383050",
    "end": "388960"
  },
  {
    "text": "[INAUDIBLE] gang size it's the\nsame as how wide the spectrum",
    "start": "388960",
    "end": "395050"
  },
  {
    "text": "structure is. I wouldn't call\nit a coincidence, but I would say that first of\nall, is everything fine, like,",
    "start": "395050",
    "end": "403669"
  },
  {
    "text": "could you imagine a\nvalid implementation if I set the gang size to 100?",
    "start": "403670",
    "end": "408950"
  },
  {
    "text": "Sure. I mean, I guess my program may\nnot handle multiples of that, but let's say, if I set\nthe gang size to 64,",
    "start": "408950",
    "end": "416640"
  },
  {
    "text": "this program is still valid. It's just 64 copies\nof the program",
    "start": "416640",
    "end": "421970"
  },
  {
    "text": "are going to get\ncreated, get executed, and they're all going\nto do their piece as defined by my code.",
    "start": "421970",
    "end": "428449"
  },
  {
    "text": "Yes. Is the entire gang\nrun at the same time? You're asking about\nimplementation details.",
    "start": "428450",
    "end": "434360"
  },
  {
    "text": "I'm just telling you\nwhat needs to happen. I'm telling if the gang size is\n64, 64 copies of this function",
    "start": "434360",
    "end": "440330"
  },
  {
    "text": "need to get run,\nand program index will have a different\nvalue in each of those.",
    "start": "440330",
    "end": "445610"
  },
  {
    "text": "And so if I ran them back\nto back to back serially, I'd get the right answer here.",
    "start": "445610",
    "end": "451670"
  },
  {
    "text": "Now I'm going to put an\nasterisk by in that there's a few tiny little\nthings if you read like page 42 of the manual\nthat actually prevent ISPC",
    "start": "451670",
    "end": "459410"
  },
  {
    "text": "from running them serially,\nbut that's not here today.",
    "start": "459410",
    "end": "465272"
  },
  {
    "text": "So, everybody's good on that?  So it would be perfectly fine\nfor all practical purposes,",
    "start": "465272",
    "end": "473580"
  },
  {
    "text": "if the implementation of this\ncall was to take this function and literally throw a\nfor loop around it, which",
    "start": "473580",
    "end": "481819"
  },
  {
    "text": "was for I equals 0\nto program count, set the value of\nprogram-- sorry, program count, set the\nvalue of program index,",
    "start": "481820",
    "end": "489530"
  },
  {
    "text": "and then just run this ISPC\nsinx function call over and over and over again. Perfectly valid\ncorrect implementation.",
    "start": "489530",
    "end": "497960"
  },
  {
    "text": "Now ISPC is not\ngoing to do that. Its implementation is not going\nto do that because you wouldn't",
    "start": "497960",
    "end": "503540"
  },
  {
    "text": "use ISPC if that's\nthe implementation you were going to get.",
    "start": "503540",
    "end": "508850"
  },
  {
    "text": "All right. And then we talked a little\nbit about what you should think about this program is doing is\nyou should ask the question,",
    "start": "508850",
    "end": "516020"
  },
  {
    "text": "what program instance\ndoes what work? And so the code\nthat I showed you,",
    "start": "516020",
    "end": "522450"
  },
  {
    "text": "program instance 0 just\nbecause of that for loop, if you go look at that\nfor loop for I equals 0",
    "start": "522450",
    "end": "527930"
  },
  {
    "text": "to program count,\ncompute and index, which is I0 plus my program\nindex and then",
    "start": "527930",
    "end": "534840"
  },
  {
    "text": "increment I by program\ncount every time, you're going to end up with a\nprogram that has divvied up work",
    "start": "534840",
    "end": "541410"
  },
  {
    "text": "like this.  Now we're going to\nget to implementation.",
    "start": "541410",
    "end": "548490"
  },
  {
    "text": "The implementation is not going\nto be run the sinx function program count times\nback to back to back.",
    "start": "548490",
    "end": "556269"
  },
  {
    "text": "The implementation,\nwhat the ISPC compiler is doing for you under the hood\nwithout you thinking about it,",
    "start": "556270",
    "end": "562620"
  },
  {
    "text": "is doing exactly the\nprogram transformation that you implemented in\npart 2 of your assignment.",
    "start": "562620",
    "end": "569884"
  },
  {
    "text": "You got a straight\nline set of C code, and it said, rewrite that\nC code in instructions,",
    "start": "569885",
    "end": "576660"
  },
  {
    "text": "in vector instructions so that\nvector size things were all",
    "start": "576660",
    "end": "582000"
  },
  {
    "text": "doing a piece of that\nloop at the same time. So the underlying implementation\nof this program, of that sinx",
    "start": "582000",
    "end": "588959"
  },
  {
    "text": "program is going to be as a\nset of vector instructions. Now the reason why you're\ngoing to set that gang",
    "start": "588960",
    "end": "595649"
  },
  {
    "text": "size to the SIMD\nwidth of the machine is that if I'm going to do\neight copies of this program,",
    "start": "595650",
    "end": "601269"
  },
  {
    "text": "I might as well run\nall 8 at the same time in different lanes of a vector.",
    "start": "601270",
    "end": "606580"
  },
  {
    "text": "So the result of compiling an\nISPC program where your gang size is your SIMD width\nis just a sequence",
    "start": "606580",
    "end": "613300"
  },
  {
    "text": "of 70 instructions\nthat carry out that logic for all eight\ninstances of the program all together.",
    "start": "613300",
    "end": "619540"
  },
  {
    "text": "So they are run simultaneously,\nand they're run simultaneously all within a thread, which is\nissuing vector instructions.",
    "start": "619540",
    "end": "626210"
  },
  {
    "text": "So if you actually trace\nyour program execution, you would see a thread running\nwith scalar instructions,",
    "start": "626210",
    "end": "631400"
  },
  {
    "text": "you'd see a normal\nfunction call, and then you just see\nthat same thread running with vector instructions.",
    "start": "631400",
    "end": "636550"
  },
  {
    "text": "And when it returned\nfrom sinx, ISPC sinx, it just goes back to running\nits scalar instructions again.",
    "start": "636550",
    "end": "644060"
  },
  {
    "text": "So once this ISPC\ncode is compiled, it's just like normal call\nreturn of a single thread, just your ISPC code\nis now vectorized.",
    "start": "644060",
    "end": "653180"
  },
  {
    "text": "Now I talked a little bit last\ntime I could change the program. This is me as the user.",
    "start": "653180",
    "end": "658560"
  },
  {
    "text": "This has nothing to\ndo with ISPC compiler. I said I want a different\nprogram now, and I want--",
    "start": "658560",
    "end": "663950"
  },
  {
    "text": "I just decided instead to have\na different mapping of program instances to who does what.",
    "start": "663950",
    "end": "670680"
  },
  {
    "text": "It's a different program. It does the same thing. It computes the same answer,\nbut the assignment is different.",
    "start": "670680",
    "end": "677270"
  },
  {
    "text": "But that was my choice\nas a programmer. And the way I want you to\nthink about how ISPC works",
    "start": "677270",
    "end": "682790"
  },
  {
    "text": "is a table like this. So this is iterations\nof the I-loop. Remember, this is I equals 0\nto program count by program.",
    "start": "682790",
    "end": "692250"
  },
  {
    "text": "So 0 to n by program count. And let's say we have\na gang size of 8.",
    "start": "692250",
    "end": "698180"
  },
  {
    "text": "Now, if you go back\nto that code here,",
    "start": "698180",
    "end": "703860"
  },
  {
    "text": "every program instance in every\niteration of this loop for I equals 0, we'll\ncompute some index.",
    "start": "703860",
    "end": "712470"
  },
  {
    "text": "And so drawing out this table\ncan be very, very helpful. Let's go right here.",
    "start": "712470",
    "end": "718500"
  },
  {
    "text": "During the I equals 0\niteration of the loop, every program\ninstance is a column.",
    "start": "718500",
    "end": "724480"
  },
  {
    "text": "And these are the\nindices that are-- those are the values of\nthe variable index in each",
    "start": "724480",
    "end": "729540"
  },
  {
    "text": "of those program instances. And then the next iteration of\nthe loop, these are the values,",
    "start": "729540",
    "end": "735250"
  },
  {
    "text": "and so on and so on\nbecause of that code",
    "start": "735250",
    "end": "740500"
  },
  {
    "text": "in the bottom, the code I\nhave in the bottom right. So that was my first program. This was my second program, and\nit's just a different program.",
    "start": "740500",
    "end": "748310"
  },
  {
    "text": "So in every iteration in\ntime, the program instances are accessing different\nindices of the array.",
    "start": "748310",
    "end": "755500"
  },
  {
    "text": "By the way, do you have a sense\nof which one is more efficient? Yeah.",
    "start": "755500",
    "end": "760910"
  },
  {
    "text": "[INAUDIBLE] goes one by one\nbecause earlier you said that when we're taking things\nto the cache, we do continuous",
    "start": "760910",
    "end": "766000"
  },
  {
    "text": "[INAUDIBLE]. And what do you mean\nby goes one by one? Because in my second program\nthat I'm showing you here,",
    "start": "766000",
    "end": "772160"
  },
  {
    "text": "every program instance\ngoes one by one in time.",
    "start": "772160",
    "end": "777699"
  },
  {
    "text": "In my first program at any\none time, at any one moment,",
    "start": "777700",
    "end": "783760"
  },
  {
    "text": "the different program instances\nwere accessing one-by-one data. Any idea which one is preferred?",
    "start": "783760",
    "end": "790589"
  },
  {
    "text": "[INAUDIBLE] You like this one because you're\nsaying at one moment in time, I'm going to ask memory for all\nthese consecutive indices, which",
    "start": "790590",
    "end": "797829"
  },
  {
    "text": "happens to fall right\non a cache line, and that will be\nmuch more efficient. Absolutely.",
    "start": "797830",
    "end": "803440"
  },
  {
    "text": "Absolutely. This second program\ncreates a situation where-- this program creates a situation\nwhere one instruction--",
    "start": "803440",
    "end": "812140"
  },
  {
    "text": "we're having a vector\nload instruction, and every address in every lane\nis separated by a whole bunch.",
    "start": "812140",
    "end": "818024"
  },
  {
    "text": "It could actually-- if this\nprogram count was large enough,",
    "start": "818025",
    "end": "823330"
  },
  {
    "text": "every single lane would\nneed a different cache line. So that vector\nload might actually need eight different\ncache lines.",
    "start": "823330",
    "end": "830079"
  },
  {
    "text": "And by the way, if they're\nspaced out by even more, some of them could\neven be paged out. So it actually could cause\neight different TLB misses,",
    "start": "830080",
    "end": "837760"
  },
  {
    "text": "eight different page faults. It could be quite expensive. Yeah. So if you have the program\ncount as a scalar multiple",
    "start": "837760",
    "end": "843760"
  },
  {
    "text": "of the vector width, would\nthe implementation [INAUDIBLE] would it compute\nthat all serially?",
    "start": "843760",
    "end": "849460"
  },
  {
    "text": "Or would it actually\nspawn both threads usin-- ISP will never spawn any\nthreads for any of the code",
    "start": "849460",
    "end": "855576"
  },
  {
    "text": "that I've had. So, what's your question? And I think it's important. So here's the blocked version.",
    "start": "855577",
    "end": "860600"
  },
  {
    "text": "If you had a vector width of 8-- Let me go back to the\ninterleave version for you. That's probably clear. If you set your\ngating count to 16,",
    "start": "860600",
    "end": "869200"
  },
  {
    "text": "is it going to serially execute,\nwrite the first portion and then the second portion? Good question. So if my width of\neverything was 16 here,",
    "start": "869200",
    "end": "879300"
  },
  {
    "text": "and I only have eight\nwide vector instructions, you now you're asking\nhow does the compiler implement that large gang size.",
    "start": "879300",
    "end": "885950"
  },
  {
    "text": "It's going to issue\ntwo instructions. It's going to back to back. And there's a reason why on\nyour computers, if you modify",
    "start": "885950",
    "end": "893180"
  },
  {
    "text": "the gang size and the\ncompiler to 16 from 8, you will get better performance. And the reason why you\nwill get better performance",
    "start": "893180",
    "end": "899839"
  },
  {
    "text": "is that think about\nthe vector operation here, followed by the next\nvector operation to do 16 wide,",
    "start": "899840",
    "end": "906720"
  },
  {
    "text": "those are two\nindependent instructions. So you just created\nan instruction string that has a lot more\nILP in it, and so it's",
    "start": "906720",
    "end": "912410"
  },
  {
    "text": "going to schedule much\nbetter on the pipeline. Absolutely. Now, there's been a lot\nof questions about what",
    "start": "912410",
    "end": "918800"
  },
  {
    "text": "is this for each mean. And this for each thing,\nI admit is weird and ugly, and you're not going to\nsee it in anything else you",
    "start": "918800",
    "end": "925310"
  },
  {
    "text": "we have in the class, but for\neach thing is the following. It's a construct that you\nshould think of as a per gang--",
    "start": "925310",
    "end": "935120"
  },
  {
    "text": "a per gang concept. For each says, I know\nthis program is being run",
    "start": "935120",
    "end": "942930"
  },
  {
    "text": "by a gang of program instances. So what for each\nsays is all together,",
    "start": "942930",
    "end": "949269"
  },
  {
    "text": "all of the program instances\nneed to run n iterations.",
    "start": "949270",
    "end": "954490"
  },
  {
    "text": "We have to run n\niterations of the loop, and in each iteration\nof the loop,",
    "start": "954490",
    "end": "959740"
  },
  {
    "text": "I is going to take\non a different value. So it's saying, look, there's\nn iterations we got to run.",
    "start": "959740",
    "end": "966350"
  },
  {
    "text": "ISPC compiler,\nyou figure out how to map those iterations onto\nthe eight program instances",
    "start": "966350",
    "end": "973810"
  },
  {
    "text": "that we have. I'm not going to tell\nyou as a programmer-- I'm not going to think about\ninterleaved or blocked. I'm just going to tell\nyou, here's the work.",
    "start": "973810",
    "end": "980023"
  },
  {
    "text": "Please do it. So you don't know which\nprogram instance is being",
    "start": "980023",
    "end": "985870"
  },
  {
    "text": "run running each iteration. So another way to say that\nis if I was the ISPC compiler",
    "start": "985870",
    "end": "993890"
  },
  {
    "text": "and I saw this, I could\neasily transform the program",
    "start": "993890",
    "end": "999550"
  },
  {
    "text": "into any of these\nfour implementations, and it would be valid.",
    "start": "999550",
    "end": "1006340"
  },
  {
    "text": "So I could transform it\ninto an implementation where out of the eight program\ninstances, the first program",
    "start": "1006340",
    "end": "1013480"
  },
  {
    "text": "instance, said, OK, I'll\ndo all the iterations and none of the other program\ninstances did anything.",
    "start": "1013480",
    "end": "1018580"
  },
  {
    "text": "I could easily transform\nit into my first program or I interleave those iterations\nover the program instances.",
    "start": "1018580",
    "end": "1026180"
  },
  {
    "text": "Or I could transform it\ninto the blocked version. I could even transform it into a\nversion of the program instances",
    "start": "1026180",
    "end": "1033668"
  },
  {
    "text": "where I'll just take the\nnext one, the next iteration that nobody else has gotten. All of those are potentially\nvalid implementations.",
    "start": "1033669",
    "end": "1041990"
  },
  {
    "text": "Now in practice, it's\ngoing to do something like this for the reasons\nthat were stated earlier, that it's going to get really\ngood memory utilization.",
    "start": "1041990",
    "end": "1049240"
  },
  {
    "text": "That is something I\nneed you to understand, is that when you see a program\nconstruct which says, here's",
    "start": "1049240",
    "end": "1055000"
  },
  {
    "text": "some independent work, system\nyou map it to workers however you want.",
    "start": "1055000",
    "end": "1061390"
  },
  {
    "text": "You don't know what worker\nis doing what piece of work, and you actually\ndon't even care. You say, system just\nassign all the work",
    "start": "1061390",
    "end": "1068175"
  },
  {
    "text": "so I get good parallelism,\nand I'll leave it to you to make a good decision. Because in my first program I\nchose to do it this way myself,",
    "start": "1068175",
    "end": "1076350"
  },
  {
    "text": "maybe that was a bad idea\non some future system. And if we would have written\nit with high level for each,",
    "start": "1076350",
    "end": "1081470"
  },
  {
    "text": "some future ISPC compiler\nmight do a better job. Yeah. Is there any cost to\nmaking the system decide",
    "start": "1081470",
    "end": "1089020"
  },
  {
    "text": "how to construct this way? Yes, there is. I mean, the system is going to\nhave some policy for doing it.",
    "start": "1089020",
    "end": "1094480"
  },
  {
    "text": "And maybe it's\nnot as good as me, like maybe I know my program\nreally well and I'm like,",
    "start": "1094480",
    "end": "1100700"
  },
  {
    "text": "I want it to run this way. And so notice what\nISPC has done. This is actually\nusually a clever design",
    "start": "1100700",
    "end": "1106029"
  },
  {
    "text": "of a programming system. They give you\nlow-level mechanisms to specify exactly\nwhat you want,",
    "start": "1106030",
    "end": "1111790"
  },
  {
    "text": "and they give you a\nhigher level mechanism that has an obvious translation\nto the lower-level thing.",
    "start": "1111790",
    "end": "1117680"
  },
  {
    "text": "So you're saying, look,\nuse the higher level 1 whenever you can because it's\nprobably going to do a good job",
    "start": "1117680",
    "end": "1123730"
  },
  {
    "text": "most of the time. And if you're ever\nunsatisfied, you have the ability to dig\ndeeper and do it yourself. And those layers of the onion\nare very, very important.",
    "start": "1123730",
    "end": "1130978"
  },
  {
    "text": "I think, in good\nprogramming system design, especially in good system\nprogramming design. So let's double down here.",
    "start": "1130978",
    "end": "1138160"
  },
  {
    "text": "Now this is-- so here's\na basic for-each loop. I took all the\ncomplexity out of it.",
    "start": "1138160",
    "end": "1144100"
  },
  {
    "text": "It's just for n\niterations, do something. So I just abstract\nit because I don't",
    "start": "1144100",
    "end": "1149140"
  },
  {
    "text": "want you to think about sinx. So in most cases, if you\nsee something like this,",
    "start": "1149140",
    "end": "1155300"
  },
  {
    "text": "you actually stop thinking\nabout program instances at all. You actually just go, I\nhave n things I need to do,",
    "start": "1155300",
    "end": "1161500"
  },
  {
    "text": "n loop iterations. ISPC, please make sure it's\nimplemented in good SIMD.",
    "start": "1161500",
    "end": "1166780"
  },
  {
    "text": "That's basically how you\nshould start thinking anymore. You're not thinking about\nprogram instances or gangs",
    "start": "1166780",
    "end": "1172150"
  },
  {
    "text": "or anything. You're just saying--\nyou're actually saying this for\neach, that's going to be like, that's\npotentially parallel work.",
    "start": "1172150",
    "end": "1178429"
  },
  {
    "text": "ISPC spread them out [INAUDIBLE]\ndo whatever you want. I trust you're going\nto do the right job.",
    "start": "1178430",
    "end": "1183970"
  },
  {
    "text": "You do way better than me\nimplementing intrinsics myself.  But it's important to\nunderstand how it runs.",
    "start": "1183970",
    "end": "1191780"
  },
  {
    "text": "What does this program do? Here's another ISPC program. For every input element of\nthe array x, what happens?",
    "start": "1191780",
    "end": "1201304"
  },
  {
    "text": "A big hint in the function name. ",
    "start": "1201305",
    "end": "1208480"
  },
  {
    "text": "It's valid, but what does it do? ",
    "start": "1208480",
    "end": "1213679"
  },
  {
    "text": "Takes every element,\ncomputes the absolute value,",
    "start": "1213680",
    "end": "1222750"
  },
  {
    "text": "and stores it twice\nin the output. It's a valid program. The input array is of size n.",
    "start": "1222750",
    "end": "1228480"
  },
  {
    "text": "The output array better\nbe of size to 2n.  So that's all it does--",
    "start": "1228480",
    "end": "1234360"
  },
  {
    "text": "makes sense. And again, if you\nsaw this code, you would just-- you wouldn't\nthink about it as what does every program instance do.",
    "start": "1234360",
    "end": "1240890"
  },
  {
    "text": "You would think about it as\nI need to process n elements. And for every element, I'm going\nto take the absolute value,",
    "start": "1240890",
    "end": "1246560"
  },
  {
    "text": "and I'm going to shove\nit into these two spots. And this can be done in\nany order that ISPC wants.",
    "start": "1246560",
    "end": "1251622"
  },
  {
    "text": "We already know how\nit's going to do it. It's going to interleave things\namongst the program instances. But I don't really think\nabout systems programming",
    "start": "1251623",
    "end": "1260420"
  },
  {
    "text": "when I'm using for each anymore. But here's an\ninteresting question. What does this program do?",
    "start": "1260420",
    "end": "1267690"
  },
  {
    "text": "This is a little bit\nmore interesting. So, as long as you're not the\nfirst element of the array,",
    "start": "1267690",
    "end": "1273460"
  },
  {
    "text": "if you're less than\n0, what happens? I slide it back. ",
    "start": "1273460",
    "end": "1280700"
  },
  {
    "text": "Is this a valid program? People are shaking\ntheir head, no. This is important.",
    "start": "1280700",
    "end": "1285770"
  },
  {
    "text": "Why is this not a valid program? Yeah. [INAUDIBLE]",
    "start": "1285770",
    "end": "1291610"
  },
  {
    "text": "So what we've told the system-- I know what this program would\ndo if it was run serially.",
    "start": "1291610",
    "end": "1298850"
  },
  {
    "text": "If it was run serially, I'd\nput something in I minus-- I might put something\nin I minus 1.",
    "start": "1298850",
    "end": "1304120"
  },
  {
    "text": "The next iteration, I might\noverwrite it or I might not. But it's very well defined\nwhat the answer is.",
    "start": "1304120",
    "end": "1309970"
  },
  {
    "text": "If these iterations\nare run in some order that you don't know because\nyou've left this up to the ISPC",
    "start": "1309970",
    "end": "1316840"
  },
  {
    "text": "compiler, you've said that these\nare independent iterations, execute them across the program\ninstances in whatever order",
    "start": "1316840",
    "end": "1323470"
  },
  {
    "text": "you wish, you have no idea\nwhat the output of this program is because the output of this\nprogram will depend on the order",
    "start": "1323470",
    "end": "1328990"
  },
  {
    "text": "that ISPC will run\nthese things in. So this is a program\nwith undefined output.",
    "start": "1328990",
    "end": "1336200"
  },
  {
    "text": "The next rev of the ISPC\ncompiler might come out, and your program might\nbe a different answer. And they're well\nwithin their rights",
    "start": "1336200",
    "end": "1343360"
  },
  {
    "text": "to do that because the\ncontract for for each was I'm saying that these iterations can\nbe scheduled onto the program",
    "start": "1343360",
    "end": "1350120"
  },
  {
    "text": "instances in whatever\norder the system wants. Will the compiler be able to\ncatch something like this?",
    "start": "1350120",
    "end": "1355430"
  },
  {
    "text": "Well, the current-- the\ncurrent ISPC compiler will make no effort to try\nand catch something like this. And it can't catch\nsomething like this",
    "start": "1355430",
    "end": "1361970"
  },
  {
    "text": "because what if\nI changed x sub i into x sub a sub i for some\narbitrary data dependent a",
    "start": "1361970",
    "end": "1368160"
  },
  {
    "text": "in the index? So, sure, maybe some compiler\nout there if they cared could",
    "start": "1368160",
    "end": "1373340"
  },
  {
    "text": "catch this one, but I could\ncontinue to write any program that doesn't. Is that similar to race\nconditions [INAUDIBLE]?",
    "start": "1373340",
    "end": "1379340"
  },
  {
    "text": "That's a race condition. Absolutely. It's unclear what the\noutput of this program is.",
    "start": "1379340",
    "end": "1385025"
  },
  {
    "text": "So here's one more\nthat should really get you to understand things.",
    "start": "1385025",
    "end": "1390789"
  },
  {
    "text": "This is a broken program\nfor how to compute the sum of all elements in the array.",
    "start": "1390790",
    "end": "1398470"
  },
  {
    "text": "Can you see why it is broken? For every element in\nthe array independently,",
    "start": "1398470",
    "end": "1406210"
  },
  {
    "text": "please add into\nthe variable sum, which is a per program instance\nvariable, and then return sum.",
    "start": "1406210",
    "end": "1415418"
  },
  {
    "text": "So first of all, this is\nactually not going to compile. Can you tell me why\nit will not compile? ",
    "start": "1415418",
    "end": "1422730"
  },
  {
    "text": "Yeah. [INAUDIBLE] If I'm running eight\nprogram instances and they all return sum,\nthat doesn't make any sense",
    "start": "1422730",
    "end": "1428760"
  },
  {
    "text": "because the caller is\nexpecting one return value. So the only way to return\nsomething actually in ISPC",
    "start": "1428760",
    "end": "1434090"
  },
  {
    "text": "is if it's a\nuniform value, which means there's one copy\nfor the entire program. So this actually\nwon't typecheck.",
    "start": "1434090",
    "end": "1440220"
  },
  {
    "text": "But here's another\nversion of it where, well,",
    "start": "1440220",
    "end": "1445669"
  },
  {
    "text": "also what's-- there's actually\nanother conceptual problem here. ",
    "start": "1445670",
    "end": "1451220"
  },
  {
    "text": "I have eight copies of sum. What will they be at\nthe end of every program instance is completion?",
    "start": "1451220",
    "end": "1457810"
  },
  {
    "text": "Yeah. It'll just be that index\nthat the program looks at. They'll be the sum of all of the\niterations-- the values from all",
    "start": "1457810",
    "end": "1466090"
  },
  {
    "text": "the iterations that\nwhatever got assigned to the different\nprogram instances. Now here's a version where\nI changed the program,",
    "start": "1466090",
    "end": "1472540"
  },
  {
    "text": "and I made some uniform. So I could return\nsome if I wanted to, but there's a problem\nwith this program.",
    "start": "1472540",
    "end": "1479060"
  },
  {
    "text": "Yeah. [INAUDIBLE] Now we've got another\nrace condition, which is I have a single\nsum and I'm trying",
    "start": "1479060",
    "end": "1484870"
  },
  {
    "text": "to have a bunch of program\ninstances plus equals into that sum. And so now I have\nsomething even--",
    "start": "1484870",
    "end": "1493120"
  },
  {
    "text": "I have another race condition. And I'll talk--\nso here's actually how to write this thing.",
    "start": "1493120",
    "end": "1498820"
  },
  {
    "text": "Oops! Sorry. Did I get this correctly? Yeah.",
    "start": "1498820",
    "end": "1504510"
  },
  {
    "text": "This is actually how\nyou write this thing. So notice that I have a\nvariable partial that's",
    "start": "1504510",
    "end": "1510000"
  },
  {
    "text": "per program instance. I say for all\niterations of the loop,",
    "start": "1510000",
    "end": "1515910"
  },
  {
    "text": "I don't care who you\nallocate the iterations to, but everybody is going to\naccumulate their local partial.",
    "start": "1515910",
    "end": "1522120"
  },
  {
    "text": "And then at the end, I'm using\na special cross-instance library",
    "start": "1522120",
    "end": "1527520"
  },
  {
    "text": "function that ISPC\nprovides to perform a safe summation of this value,\nwhich is unique per program",
    "start": "1527520",
    "end": "1536220"
  },
  {
    "text": "instance, to put the results in\na uniform value, which can then",
    "start": "1536220",
    "end": "1542580"
  },
  {
    "text": "be returned.  Yeah. Does ISPC have the\nability for you",
    "start": "1542580",
    "end": "1548430"
  },
  {
    "text": "to write a custom\nlambda for the reviews. No, not right now. It doesn't. It doesn't, but it would\nbe conceptually easy to do.",
    "start": "1548430",
    "end": "1557070"
  },
  {
    "text": "You could say, trust me, this\nis a cross-line operator. Yes. So another way to check\nyour understanding",
    "start": "1557070",
    "end": "1563940"
  },
  {
    "text": "is that ISPC will\ncompile this code-- now we're talking\nabout implementation",
    "start": "1563940",
    "end": "1569910"
  },
  {
    "text": "of the current ISPC compiler-- to a program to solution\nthat looks like this.",
    "start": "1569910",
    "end": "1577740"
  },
  {
    "text": "Notice what's going on here. For I equals 0 to n by 8, just\ndo a vector load and a vector",
    "start": "1577740",
    "end": "1584370"
  },
  {
    "text": "add. Add, add, add, add, add, add. At the end of this loop,\nI have a single vector,",
    "start": "1584370",
    "end": "1591310"
  },
  {
    "text": "and every lane is a\npartial sum of all of the elements in the array.",
    "start": "1591310",
    "end": "1596549"
  },
  {
    "text": "Can you see how that's going on? And then at the end,\nI need to do something to add up all the\nelements in the array.",
    "start": "1596550",
    "end": "1604250"
  },
  {
    "text": "So I iterate sequentially over\nall the elements of the array summing over that final vector.",
    "start": "1604250",
    "end": "1610570"
  },
  {
    "text": "So this is a naive\nimplementation to reduce add.",
    "start": "1610570",
    "end": "1617320"
  },
  {
    "text": "Yeah. So you need to declare load at\nthe beginning or you can also [INAUDIBLE] load sum at the\nbeginning or you can also do",
    "start": "1617320",
    "end": "1624670"
  },
  {
    "text": "[INAUDIBLE]? No. The variable can be declared--\ncan be declared anywhere. I was just adopting good\nprogramming conventions.",
    "start": "1624670",
    "end": "1633590"
  },
  {
    "text": "So ISPC has all of these\ninteresting cross-program",
    "start": "1633590",
    "end": "1639590"
  },
  {
    "text": "instance operators\nthat you can use if you want to think\nabout programming in terms",
    "start": "1639590",
    "end": "1644750"
  },
  {
    "text": "of a bunch of program\ninstances and what are they doing at the same time. ",
    "start": "1644750",
    "end": "1653360"
  },
  {
    "text": "So that's what I wanted\nto get across here. First, you always\nstart by saying, what does the programming\nlanguage mean and do?",
    "start": "1653360",
    "end": "1660620"
  },
  {
    "text": "And then you start talking\nabout how is it implemented. And nothing I have\nsaid here today",
    "start": "1660620",
    "end": "1668420"
  },
  {
    "text": "will ever run on more than one\ncore or one thread of one core. We have not talked about\nhow to create more threads",
    "start": "1668420",
    "end": "1674270"
  },
  {
    "text": "or anything like that. So that's the programming\nmodel of ISPC. Now, everything that we've said,\nyou can now just replicate out",
    "start": "1674270",
    "end": "1684560"
  },
  {
    "text": "and, that's the idea of tasks. So when you create a\ntask, that's like saying, here is some work\nto do, and I want",
    "start": "1684560",
    "end": "1691250"
  },
  {
    "text": "one gang of program\ninstances to do it. So I can create 100,000\ntasks if I want.",
    "start": "1691250",
    "end": "1697550"
  },
  {
    "text": "In the same way\nthat for each said, here's a gazillion\nloop iterations, ISPC you figure out how to\nassign it to program instances,",
    "start": "1697550",
    "end": "1705030"
  },
  {
    "text": "tasks are like saying, here's a\ngazillion gangs of work to do. You figure out how to assign it\nto the threads in the machine,",
    "start": "1705030",
    "end": "1712429"
  },
  {
    "text": "and do it however you want. So if I create a\nmillion tasks and I'm running on a myth machine\nwith eight hyper threads,",
    "start": "1712430",
    "end": "1720230"
  },
  {
    "text": "ISPC under the\nhood is just going to create eight hyper\nthreads and then go, OK, you do the next task,\nyou do the next task,",
    "start": "1720230",
    "end": "1725550"
  },
  {
    "text": "you do the next task,\nand so on and so on.  Now one thing that I'd like you\nto mull over a little bit is",
    "start": "1725550",
    "end": "1735169"
  },
  {
    "text": "if we're not using any of these\ncross-lane operators or anything like that, if we don't have to\nhave these program instances",
    "start": "1735170",
    "end": "1742445"
  },
  {
    "text": "communicate at all,\nwhich most of the time we don't, and if you're using\nfor each, I don't really--",
    "start": "1742445",
    "end": "1749809"
  },
  {
    "text": "I don't even ever think\nabout program instances. I don't think about\nprogram count at all.",
    "start": "1749810",
    "end": "1754830"
  },
  {
    "text": "I just say, here are\nmy loop iterations. ISPC, you go do it in\nparallel however you want. ",
    "start": "1754830",
    "end": "1762551"
  },
  {
    "text": "But ISPC has all\nthese concepts in it, so we can do really advanced\nshifting and other stuff.",
    "start": "1762551",
    "end": "1771110"
  },
  {
    "text": "Here's an example\nof an ISPC program that actually computes the\ndot product, I think, of--",
    "start": "1771110",
    "end": "1778640"
  },
  {
    "text": "no, computes the product of\nall the elements in an array.",
    "start": "1778640",
    "end": "1783800"
  },
  {
    "text": "So given all elements of\narray, compute their product. So one output.",
    "start": "1783800",
    "end": "1790130"
  },
  {
    "text": "So if ISPC wasn't trying\nto be so low level, it would just probably\ngive you a for each",
    "start": "1790130",
    "end": "1795440"
  },
  {
    "text": "and say, you're not allowed\nto have program count at all or program instance. You would just write code.",
    "start": "1795440",
    "end": "1801060"
  },
  {
    "text": "You'd almost never\nthink about parallelism, and you'd be like,\nwow, my program runs eight times faster\nthan it did before. This is awesome.",
    "start": "1801060",
    "end": "1807860"
  },
  {
    "text": "So if I take out all the\nlow-level stuff from ISPC, it turns out to be a\nvery, very simple thing.",
    "start": "1807860",
    "end": "1813445"
  },
  {
    "text": " Now there's going to be an\nalternative that some of you",
    "start": "1813445",
    "end": "1820620"
  },
  {
    "text": "might be if you're a functional\nprogramming person or a NumPy",
    "start": "1820620",
    "end": "1825690"
  },
  {
    "text": "programming person, you might be\nmore accustomed to not thinking about array indices, but\nthinking about operations",
    "start": "1825690",
    "end": "1835020"
  },
  {
    "text": "on vectors, like adding to\ntensors or giving a lambda",
    "start": "1835020",
    "end": "1840600"
  },
  {
    "text": "and mapping a lambda\nonto a collection. So you can think about\nthis ISPC program",
    "start": "1840600",
    "end": "1846269"
  },
  {
    "text": "as the collection\nis the set of values that are referenced by x sub i.",
    "start": "1846270",
    "end": "1851360"
  },
  {
    "text": " So a higher level\nprogramming language",
    "start": "1851360",
    "end": "1857460"
  },
  {
    "text": "just wouldn't allow you\nto do any indexing at all. It would just say, the data\naccess of add is well defined.",
    "start": "1857460",
    "end": "1865700"
  },
  {
    "text": "X plus y is just every element\nmatches up with everything else. So higher level\nprogramming languages",
    "start": "1865700",
    "end": "1871648"
  },
  {
    "text": "would exist and would be able\nto generate really fast code as well. Now we're going to talk\nabout them as well.",
    "start": "1871648",
    "end": "1877940"
  },
  {
    "text": "But now you can\nthink about if you had that in PyTorch or NumPy,\nhow would you actually implement",
    "start": "1877940",
    "end": "1883480"
  },
  {
    "text": "it well on a SIMD machine? And you have some of the\ntools to think about how you'd actually implement PyTorch.",
    "start": "1883480",
    "end": "1888505"
  },
  {
    "text": " All right. Any questions on that before\nwe actually get to the basics?",
    "start": "1888505",
    "end": "1899179"
  },
  {
    "text": "Yeah. Can you go over the\ntask thing again. Where did you exactly\ndefine [INAUDIBLE]",
    "start": "1899180",
    "end": "1904730"
  },
  {
    "text": "going to be a task [INAUDIBLE] That's in the program\nI would like everybody to as it says in the handout.",
    "start": "1904730",
    "end": "1910580"
  },
  {
    "text": "Go read the manual or my\noffice hours are at 1 o'clock today, so I'll take that.",
    "start": "1910580",
    "end": "1915940"
  },
  {
    "text": "[INAUDIBLE] [INAUDIBLE] tasks are\nnot same as [INAUDIBLE]? ",
    "start": "1915940",
    "end": "1921990"
  },
  {
    "text": "An ISPC task is just a task. A thread would be an\nimplementation detail.",
    "start": "1921990",
    "end": "1928470"
  },
  {
    "text": "But it's very true that\nif you create eight tasks, a smart thing for ISPC to\ndo would be under the hood,",
    "start": "1928470",
    "end": "1936039"
  },
  {
    "text": "spawn eight threads and run\nthem all on different threads. But if you create 100,000 tasks,\nit probably would be pretty dumb",
    "start": "1936040",
    "end": "1943620"
  },
  {
    "text": "for ISPC to create\n100,000 threads. And I'll show you\nwhy in a second. I don't quite follow up.",
    "start": "1943620",
    "end": "1950160"
  },
  {
    "text": "[INAUDIBLE] generally write\nthe code [INAUDIBLE] templates.",
    "start": "1950160",
    "end": "1955740"
  },
  {
    "text": "But how does it run on\neight threads [INAUDIBLE]? So, the question was let's say,\nI'm back in C land and I create",
    "start": "1955740",
    "end": "1964080"
  },
  {
    "text": "10 C++ threads, if I go to\nmy activity monitor right now",
    "start": "1964080",
    "end": "1973710"
  },
  {
    "text": "in my computer, there's a lot\nof threads and I have eight",
    "start": "1973710",
    "end": "1981820"
  },
  {
    "text": "execution contexts. So your question\nis in general, how does a computer that needs to\nrun apparently a 700 kernel",
    "start": "1981820",
    "end": "1991630"
  },
  {
    "text": "threads right now, how does\nit run 700 kernel threads on my computer? ",
    "start": "1991630",
    "end": "1998910"
  },
  {
    "text": "Yeah. [INAUDIBLE] It's got a context switch. the operating system from\ntime to time is saying,",
    "start": "1998910",
    "end": "2005160"
  },
  {
    "text": "here are those eight\nthreads that need to run. I'm going to put\nthem on the processor and let the processor run.",
    "start": "2005160",
    "end": "2010650"
  },
  {
    "text": "And periodically,\nsome timer expires, and the operating system says,\nwell, we have 700 threads. We need to have another 8 run.",
    "start": "2010650",
    "end": "2017230"
  },
  {
    "text": "So we're going to rip those\nthreads off the processor and put those on. And you can imagine that\ncould be pretty slow.",
    "start": "2017230",
    "end": "2024540"
  },
  {
    "text": "So, in fact, let\nme go ahead and-- since you asked, let me--",
    "start": "2024540",
    "end": "2029585"
  },
  {
    "start": "2029585",
    "end": "2034899"
  },
  {
    "text": "one second.  I have a demo of that. ",
    "start": "2034900",
    "end": "2054105"
  },
  {
    "text": "So here's a program\nthat I wrote. ",
    "start": "2054105",
    "end": "2063149"
  },
  {
    "text": "One second. So here's a C program, and\nit has three tests in it.",
    "start": "2063150",
    "end": "2071619"
  },
  {
    "text": "So there's this\nfunction called dowork, which literally does nothing. So the cost of doing work is\njust calling the function.",
    "start": "2071620",
    "end": "2077500"
  },
  {
    "text": "And I put some stuff\nup here, which says, hey, don't do anything fancy. I know there's nothing in it. Don't inline it. Don't try and optimize\nor anything like that.",
    "start": "2077500",
    "end": "2083574"
  },
  {
    "text": "So I've got a function. Imagine that this is my task-- does nothing. So it's like the cheapest\ntask in the world.",
    "start": "2083574",
    "end": "2090000"
  },
  {
    "text": "And then here's a test,\nwhich says run test 0. So test 0 sequentially\ncalls that function.",
    "start": "2090000",
    "end": "2098460"
  },
  {
    "text": "Test 1-- well, actually,\nlet me go to test 2 first. Test 2 says right\nhere, I'm going",
    "start": "2098460",
    "end": "2109710"
  },
  {
    "text": "to create num worker threads. So I'm going to-- I've hard coded that to\neight on my computer.",
    "start": "2109710",
    "end": "2114910"
  },
  {
    "text": "So I'm going to create\neight worker threads. They're all going to run worker\n2, where worker 2 is given",
    "start": "2114910",
    "end": "2122829"
  },
  {
    "text": "the total number of tasks,\ntake the next available task,",
    "start": "2122830",
    "end": "2131050"
  },
  {
    "text": "call dowork, run it, and then\nkeep a count of how many tasks",
    "start": "2131050",
    "end": "2136990"
  },
  {
    "text": "i, this thread has performed. And if we ever get to a total\ntask count that equals n,",
    "start": "2136990",
    "end": "2142009"
  },
  {
    "text": "we quit. So I create eight\nworkers, and they just go next, next, next,\nnext, next, next.",
    "start": "2142010",
    "end": "2147260"
  },
  {
    "text": "And then task 1-- sorry, strategy 1 test,\n1 is just for every task,",
    "start": "2147260",
    "end": "2155240"
  },
  {
    "text": "create a thread, run\nthe task, and then reap the thread-- join the thread.",
    "start": "2155240",
    "end": "2160432"
  },
  {
    "text": "So, which one do you think\nis going to be the fastest? ",
    "start": "2160433",
    "end": "2168640"
  },
  {
    "text": "Votes? Yeah. But is that one\nbecause you don't need to context\nswitch [INAUDIBLE] execute them [INAUDIBLE]?",
    "start": "2168640",
    "end": "2174970"
  },
  {
    "text": "So I'll say, 0 was do\neverything sequentially. 1 was spun up an actual thread,\na c++ thread for every task.",
    "start": "2174970",
    "end": "2183010"
  },
  {
    "text": "And 2 was spawn eight\nthreads and just have those eight\nthreads cooperate.",
    "start": "2183010",
    "end": "2190300"
  },
  {
    "text": "Yeah, 2. So you like 2? OK Any other votes? 0. 0.",
    "start": "2190300",
    "end": "2196240"
  },
  {
    "text": "Any other votes? The one with eight threads. One with eight threads--\nthe same vote here. So let's actually\nrun this thing.",
    "start": "2196240",
    "end": "2202990"
  },
  {
    "text": "What is my program called? Oh, thread launch. Here we go.",
    "start": "2202990",
    "end": "2208300"
  },
  {
    "text": "So 0 finished in\n1.6 milliseconds. I think I'm running like a\nbillion iterations or something",
    "start": "2208300",
    "end": "2215770"
  },
  {
    "text": "like that. This is the spawning threads. ",
    "start": "2215770",
    "end": "2221349"
  },
  {
    "text": "And then it just flashed test 2. So basically, the\nsequential one,",
    "start": "2221350",
    "end": "2227180"
  },
  {
    "text": "because there's just\nno work involved, it was just a lot easier\njust to call the function",
    "start": "2227180",
    "end": "2232300"
  },
  {
    "text": "and take the three-- the eight\noperations to push something onto the stack and pop it up. So the test 0 was\n23 times faster",
    "start": "2232300",
    "end": "2243280"
  },
  {
    "text": "than test 2, which\nwas my thread pool. And my thread pool\nwas 300 times faster",
    "start": "2243280",
    "end": "2249040"
  },
  {
    "text": "than spawning a thread per task. So this is an extreme\ncase where the task",
    "start": "2249040",
    "end": "2254050"
  },
  {
    "text": "is so tiny than any\noverhead that you see it. But that's a 300x difference\nbetween creating a thread per",
    "start": "2254050",
    "end": "2264670"
  },
  {
    "text": "task and letting the operating\nsystem sort it all out and me",
    "start": "2264670",
    "end": "2270130"
  },
  {
    "text": "just creating exactly the number\nof threads that my machine can use and me handling the work\ndispatch with an efficient get",
    "start": "2270130",
    "end": "2277120"
  },
  {
    "text": "next task kind of thing. So, what do you think ISPC\nis doing under the hood when you create tasks?",
    "start": "2277120",
    "end": "2283700"
  },
  {
    "text": "It's creating a pool of\nthe right size and saying, oh, I'm going to divvy up. ",
    "start": "2283700",
    "end": "2295260"
  },
  {
    "text": "Yeah. Now, If the function\nwas very long, would it be still better to--",
    "start": "2295260",
    "end": "2300720"
  },
  {
    "text": "If this function\nwas very, very long. I would expect to see my\nparallel thread pool definitely",
    "start": "2300720",
    "end": "2305819"
  },
  {
    "text": "outperform sequential\nbecause I'm doing all the work in parallel. Is it still better\nthan the eight thread",
    "start": "2305820",
    "end": "2311710"
  },
  {
    "text": "is still better than\none thread per task? Well, at some point, if\nthe function got so long,",
    "start": "2311710",
    "end": "2317760"
  },
  {
    "text": "it doesn't matter anymore\nbecause the overhead of creating that thread is insignificant. So what we could\ndo is we could put",
    "start": "2317760",
    "end": "2323640"
  },
  {
    "text": "a for loop inside my little task\nand make it do more and more work, and you could\ngo figure out what the cutoff point would be.",
    "start": "2323640",
    "end": "2329670"
  },
  {
    "text": "Yeah, exactly. There's also a cutoff point\nwhere if it's so small, you might as well not even do\nit in parallel, as we saw there.",
    "start": "2329670",
    "end": "2337270"
  },
  {
    "text": "Mm-hmm. When the OS is\nswitching context, the context is taking off\nthe [INAUDIBLE] just being",
    "start": "2337270",
    "end": "2345090"
  },
  {
    "text": "stored in ready? Yeah. So don't confuse\ncontext switching that you'd hear about in an OS\nclass, which is what we are now",
    "start": "2345090",
    "end": "2352799"
  },
  {
    "text": "talking about with\nhardware multithreading that we've talked\nabout in this course. In this class, we\nwill almost never",
    "start": "2352800",
    "end": "2359920"
  },
  {
    "text": "think about operating\nsystem context switching because we think about--\nwe're the only application",
    "start": "2359920",
    "end": "2366100"
  },
  {
    "text": "on the computer\nmost of the time. And it makes no sense\nfor an application",
    "start": "2366100",
    "end": "2371560"
  },
  {
    "text": "to create more threads\nthan execution context because all you're\nforcing to happen",
    "start": "2371560",
    "end": "2378220"
  },
  {
    "text": "is the operating system starts\nswapping them on and off. Your job is to create one thread\nper as much work as you can do.",
    "start": "2378220",
    "end": "2385600"
  },
  {
    "text": "And then it's your\nresponsibility to take work and assign them\nto your working threads.",
    "start": "2385600",
    "end": "2390759"
  },
  {
    "text": "Absolutely. An operating system context\nswitch is hundreds of thousands of cycles.",
    "start": "2390760",
    "end": "2396974"
  },
  {
    "text": "A hardware execution context\nswitch is one cycle-- very different.",
    "start": "2396975",
    "end": "2402310"
  },
  {
    "text": "If you use operating system\ncontext switching to hide the latency of a memory access,\nmemory would be done in a couple",
    "start": "2402310",
    "end": "2408280"
  },
  {
    "text": "hundred cycles, and you'd still\nbe spending 100,000 cycles swapping your thread out. It makes no sense.",
    "start": "2408280",
    "end": "2413480"
  },
  {
    "text": "So the same idea, but at very\ndifferent orders of magnitude. ",
    "start": "2413480",
    "end": "2421922"
  },
  {
    "text": "So the rest of the\ntime, I actually want to go through\na case study or two with you of the first time we're\nactually going to really start",
    "start": "2421922",
    "end": "2429410"
  },
  {
    "text": "kind of optimizing programs. I mean, you have to I\nguess, optimize programs a little bit in assignment\none, but it's not super crazy.",
    "start": "2429410",
    "end": "2437010"
  },
  {
    "text": "And our goal is going to just\nbe get the maximum speed up for now. Our goal is to reduce\nthe timer by some factor.",
    "start": "2437010",
    "end": "2445890"
  },
  {
    "text": "And hopefully, if\nI can do things-- if my time is p times less,\nthen I have this p speed up.",
    "start": "2445890",
    "end": "2452990"
  },
  {
    "text": "And I think, it's\nsomewhat helpful--",
    "start": "2452990",
    "end": "2460031"
  },
  {
    "text": "every year I decide whether or\nnot I should show this slide. I think it's useful just to\ntalk in general abstract terms",
    "start": "2460031",
    "end": "2466250"
  },
  {
    "text": "for a second about the process\nof parallelizing the program. And the process you can\nthink of as, what is step 1?",
    "start": "2466250",
    "end": "2476770"
  },
  {
    "text": "Step 1 is almost always figure\nout what is independent-- divide work, figure out\nwhat are the things I could",
    "start": "2476770",
    "end": "2484680"
  },
  {
    "text": "do in parallel if I want to. And terminology is weird, but\ndecomposition is something",
    "start": "2484680",
    "end": "2491760"
  },
  {
    "text": "that I think I used to say that\nit's like, I got a problem. I need to decompose\nit into things to do.",
    "start": "2491760",
    "end": "2497620"
  },
  {
    "text": "Sometimes people might say\ntasks or something like that. And then there's the problem of\nassigning those tasks assigning",
    "start": "2497620",
    "end": "2505260"
  },
  {
    "text": "that work really what\nI should say to things that can execute the work. And so you'll often hear me\nsay assignment to mean that.",
    "start": "2505260",
    "end": "2513460"
  },
  {
    "text": "So decomposition is\ngoing, oh, we can work and we can do-- we\ncan work in parallel. An assignment is like, OK,\nI'll do this, and you do that.",
    "start": "2513460",
    "end": "2521609"
  },
  {
    "text": "And then, of course,\nat some point, there's often some orchestration\nor some synchronization",
    "start": "2521610",
    "end": "2526890"
  },
  {
    "text": "because we have to sync up. We might have to\ncompute a total sum or it might need to be like,\nwhen you're done, I'll go.",
    "start": "2526890",
    "end": "2533640"
  },
  {
    "text": "You'll see me call\nthat orchestration. And last, there's often a\nnotion of mapping of what--",
    "start": "2533640",
    "end": "2540790"
  },
  {
    "text": "how does some worker\nactually get to the hardware?",
    "start": "2540790",
    "end": "2546450"
  },
  {
    "text": "So I'll give you some\nexamples of that in a second. So in this class,\nyou are almost always",
    "start": "2546450",
    "end": "2553080"
  },
  {
    "text": "going to be the entity\nresponsible for decomposing a problem into smaller pieces\nthat can be done in parallel.",
    "start": "2553080",
    "end": "2560550"
  },
  {
    "text": "The magic compiler\nthat does it for you largely does not\nexist unless you're",
    "start": "2560550",
    "end": "2566790"
  },
  {
    "text": "using very specialized\ncomputing languages. And it's a little\nbit shocking to see",
    "start": "2566790",
    "end": "2574710"
  },
  {
    "text": "how your speedup is limited if\nonly a pretty small fraction",
    "start": "2574710",
    "end": "2580500"
  },
  {
    "text": "of your program\nis not paralyzed. So let's say we had a program\nthat had some runtime,",
    "start": "2580500",
    "end": "2587310"
  },
  {
    "text": "and imagine that the fraction\nS of that program was serial.",
    "start": "2587310",
    "end": "2592990"
  },
  {
    "text": "So let's say, you have a program\nand have half the program just as inherently serial,\nor maybe you just don't get around\nto parallelizing,",
    "start": "2592990",
    "end": "2599227"
  },
  {
    "text": "S It's is one half here. if 10% of the program\nis serial, S is 0.1.",
    "start": "2599227",
    "end": "2605040"
  },
  {
    "text": "So then the maximum\nspeed up you could ever hope to achieve if you\nperfectly parallelized",
    "start": "2605040",
    "end": "2610800"
  },
  {
    "text": "the other part with an\ninfinite number of processors is 1 over S because your\nruntime is at least S.",
    "start": "2610800",
    "end": "2622400"
  },
  {
    "text": "And so if your total time over-- you're limited by 1\nover S of your speed up.",
    "start": "2622400",
    "end": "2627572"
  },
  {
    "text": "And this can actually\nbe pretty dramatic. Let's look at this. So here's a simple\nexample from programs",
    "start": "2627572",
    "end": "2633020"
  },
  {
    "text": "that I write all the time, which\nis imagine I had an image of me, and the goal was to\nmultiply all pixels by 2",
    "start": "2633020",
    "end": "2640160"
  },
  {
    "text": "to increase the brightness. And then maybe I want to compute\nthe average of all pixels.",
    "start": "2640160",
    "end": "2645855"
  },
  {
    "text": "It's actually a pretty\ncommon operation that your camera\ndoes all the time. Both steps, hopefully you\ncan see take n squared time.",
    "start": "2645855",
    "end": "2653250"
  },
  {
    "text": "There are n squared pixels. It's an n by n image. And if I plotted things out,\nlike this is execution time,",
    "start": "2653250",
    "end": "2661370"
  },
  {
    "text": "and this is the amount of\nparallelism when running. So if this is a sequential\nprogram right now,",
    "start": "2661370",
    "end": "2666990"
  },
  {
    "text": "the implementation\nhas parallelism one, and it has time 2n squared-- 2n squared.",
    "start": "2666990",
    "end": "2673430"
  },
  {
    "text": "So, what would be\nthe first step-- what do you identify\ncouldn't be done in parallel?",
    "start": "2673430",
    "end": "2679975"
  },
  {
    "text": "You can [INAUDIBLE]\nall at the same time. I can definitely compute the\nbrightness of every pixel",
    "start": "2679976",
    "end": "2686230"
  },
  {
    "text": "independently and\npotentially in parallel. And let's say that we run this\non a machine with P processors.",
    "start": "2686230",
    "end": "2692520"
  },
  {
    "text": "Now, I'm going to use the term\nP processors because I don't-- I mean you could think about\nit as a processor with P cores,",
    "start": "2692520",
    "end": "2700510"
  },
  {
    "text": "or we can think about it as\njust distributed computing with P processors. The details of\nthat don't matter.",
    "start": "2700510",
    "end": "2705964"
  },
  {
    "text": "But let's just say\nwe had P things that could run in parallel. Well, if I take\nyour strategy, then",
    "start": "2705965",
    "end": "2711250"
  },
  {
    "text": "what happens is the front\npart of this program now goes to time\nn squared over P,",
    "start": "2711250",
    "end": "2716470"
  },
  {
    "text": "and I haven't touched the\nback half of the program. What's my speed up? Perfectly parallelized\nfirst part of the program",
    "start": "2716470",
    "end": "2726819"
  },
  {
    "text": "didn't touch the back half,\nbut my speed up is what? In the limit, let's\nsay, n is huge.",
    "start": "2726820",
    "end": "2734054"
  },
  {
    "text": "[INAUDIBLE] Sorry. It's twice. So, what is my\noverall performance?",
    "start": "2734054",
    "end": "2739400"
  },
  {
    "text": "Well, it used to be 2n squared,\nand now it's n squared over P plus n squared.",
    "start": "2739400",
    "end": "2745520"
  },
  {
    "text": "And in the limit, that's\ngoing to go to bounded by 2. So half my program\nremains sequential.",
    "start": "2745520",
    "end": "2751609"
  },
  {
    "text": "There's nothing I can do. I can't be any fancier here. If I went to a\nmillion processors,",
    "start": "2751610",
    "end": "2757220"
  },
  {
    "text": "I would still be bounded by 2. Now what else could we do?",
    "start": "2757220",
    "end": "2763330"
  },
  {
    "text": "Yeah. [INAUDIBLE] the partial sum\nto get the sum of all pixels.",
    "start": "2763330",
    "end": "2769510"
  },
  {
    "text": "So I can take all\nmy processors-- every processor could take one\np from the image, compute a sum,",
    "start": "2769510",
    "end": "2775280"
  },
  {
    "text": "and then I've got to\ndo what at the end? [INAUDIBLE] Well, yeah, you're\nspeaking about in terms",
    "start": "2775280",
    "end": "2781960"
  },
  {
    "text": "of if we had to write an\nISP, but conceptually we just-- every processor\ndoes one piece of the sum.",
    "start": "2781960",
    "end": "2789340"
  },
  {
    "text": "And then if we just\nnaively add P things up to get the final answer, that\nwould be plus P here at the end.",
    "start": "2789340",
    "end": "2796152"
  },
  {
    "text": "So I have n squared-- n over P-- so I have 2n\nover P squared plus P,",
    "start": "2796152",
    "end": "2803549"
  },
  {
    "text": "if I added the partials\nup sequentially. Everybody see that?",
    "start": "2803550",
    "end": "2809100"
  },
  {
    "text": " So the real question\nhere is like, if p",
    "start": "2809100",
    "end": "2815860"
  },
  {
    "text": "is very, very small compared to\nn, I'm going to be doing great. If p is actually kind of\nsubstantial compared to n,",
    "start": "2815860",
    "end": "2823910"
  },
  {
    "text": "then I fundamentally\nstill have some problems. And so this factor S is\nactually pretty important.",
    "start": "2823910",
    "end": "2831890"
  },
  {
    "text": "So here is a plot where this\nis the total number of cores, number of processors-- 64 processors.",
    "start": "2831890",
    "end": "2838220"
  },
  {
    "text": "And this is a theoretical\noptimum speedup for programs that have different Ses.",
    "start": "2838220",
    "end": "2845090"
  },
  {
    "text": "So let's say that only 1% of\nyour program was sequential and you run that thing,\nthe other 99% is perfectly",
    "start": "2845090",
    "end": "2852820"
  },
  {
    "text": "parallelizable on a 64-core box. You are limited to\nabout 40x speedup.",
    "start": "2852820",
    "end": "2858850"
  },
  {
    "text": "That 1% of sequential\nreally starts to bite you.",
    "start": "2858850",
    "end": "2864790"
  },
  {
    "text": "And so I'm already\nnot perfect scaling on a machine with 64 cores. If 10% of my program\ncan't be parallelized,",
    "start": "2864790",
    "end": "2873440"
  },
  {
    "text": "my best case scenario on\na 64-core box is about 8x.",
    "start": "2873440",
    "end": "2878810"
  },
  {
    "text": "It's pretty dramatic. Now imagine you're not\nrunning on a 64-core machine, but you're running on a\nbig supercomputer that has",
    "start": "2878810",
    "end": "2885890"
  },
  {
    "text": "approximately 150\nmillion parallel units.",
    "start": "2885890",
    "end": "2893089"
  },
  {
    "text": "You better get that sequential\nportion of your code down to 0.00000001% of the problem,\notherwise you might as well not",
    "start": "2893090",
    "end": "2901010"
  },
  {
    "text": "be using this thing. Luckily, most of the\ncode we run is going to be pretty parallelizable.",
    "start": "2901010",
    "end": "2907580"
  },
  {
    "text": "So, like I said, in this\nclass, understanding how to decompose something\nis going to be almost just",
    "start": "2907580",
    "end": "2914090"
  },
  {
    "text": "like what we did here, is\nit's going to be up to you to give the-- write a program that\ndecomposes things well.",
    "start": "2914090",
    "end": "2920120"
  },
  {
    "text": "Don't hope for magic there. But what we often might rely\non systems for programming",
    "start": "2920120",
    "end": "2928220"
  },
  {
    "text": "languages or compilers\nis to assign that work to workers for us.",
    "start": "2928220",
    "end": "2933710"
  },
  {
    "text": "So assignment might\nbe something like-- well, the name of the\ngame on this assignment",
    "start": "2933710",
    "end": "2940910"
  },
  {
    "text": "is to keep all of\nmy workers busy. So you might be\nresponsible for assignment.",
    "start": "2940910",
    "end": "2947280"
  },
  {
    "text": "For example, earlier\nin this lecture, I wrote two different ISPC\nprograms where in this program,",
    "start": "2947280",
    "end": "2956720"
  },
  {
    "text": "I assigned loop iterations\nto program instances.",
    "start": "2956720",
    "end": "2961730"
  },
  {
    "text": "I wrote this code. So I decided that\nthis program instance was going to do this iteration. I assigned it.",
    "start": "2961730",
    "end": "2968180"
  },
  {
    "text": "I gave you a different version\nof the code where I said, ISPC, I'll let you do the assignment.",
    "start": "2968180",
    "end": "2974060"
  },
  {
    "text": "I trust you to do as\nwell or better than me. So that's an assignment\ntask right there.",
    "start": "2974060",
    "end": "2980432"
  },
  {
    "text": "On the first day\nof class, I think, I showed you this\npiece of code where I had a C program that\nspawned an additional thread.",
    "start": "2980432",
    "end": "2989040"
  },
  {
    "text": "And in this code, I assigned\none half of the array to one of those threads by the nature\nof the code that I wrote,",
    "start": "2989040",
    "end": "2996329"
  },
  {
    "text": "and I assign the other half of\nthe array to another thread. ",
    "start": "2996330",
    "end": "3001550"
  },
  {
    "text": "So I decide who does what.  In ISPC tasks, you are\ndecomposing this problem",
    "start": "3001550",
    "end": "3011550"
  },
  {
    "text": "into tasks, but\nyou're telling ISPC, I will let you assign these\ntasks to the running threads",
    "start": "3011550",
    "end": "3019080"
  },
  {
    "text": "that you have to do the work. So under the hood, there\nmight be a pool of threads, like one that you implemented\nin 111 and ISPC is going,",
    "start": "3019080",
    "end": "3027130"
  },
  {
    "text": "is there an idle thread? If so, hey, could you\nplease work on task 0? Or are you idle? Could you please work on task 1?",
    "start": "3027130",
    "end": "3033885"
  },
  {
    "text": "Or you just got\ndone with the task? Well, the next available\none is task 42. Could you go do that? That's what's going\non under the hood.",
    "start": "3033885",
    "end": "3041079"
  },
  {
    "text": "And most of the\ntime we would rather have the computer-- the system\ndo the assignment for us because we're going\nto assume that they're",
    "start": "3041080",
    "end": "3047220"
  },
  {
    "text": "going to do a better\njob than maybe we would. Or maybe there are different\nassignment strategies that are the right\nassignment strategy",
    "start": "3047220",
    "end": "3053730"
  },
  {
    "text": "for different computers. And I don't want\nto have to write my program with a\nspecific computer in mind",
    "start": "3053730",
    "end": "3058920"
  },
  {
    "text": "unless I really, really\ncare about performance. ",
    "start": "3058920",
    "end": "3066060"
  },
  {
    "text": "We won't talk too much\ntoday about orchestration, but you saw one example of\nit, like that reduce add",
    "start": "3066060",
    "end": "3071190"
  },
  {
    "text": "or those cross-link calls. But at some point, even\nif you are divvying stuff",
    "start": "3071190",
    "end": "3077040"
  },
  {
    "text": "up into two different\npieces, those workers are going to have to\ncommunicate and synchronize. One example of\nsynchronization would",
    "start": "3077040",
    "end": "3083550"
  },
  {
    "text": "be these workers\nhave to synchronize so that every task only\ngoes to one worker,",
    "start": "3083550",
    "end": "3089280"
  },
  {
    "text": "and every worker goes to-- gets the next task. So there's going to be a\nlittle bit of synchronization.",
    "start": "3089280",
    "end": "3094552"
  },
  {
    "text": "And you saw the effect of that\nsynchronization in my demo that I just showed you in\nthat my thread pool was",
    "start": "3094552",
    "end": "3100200"
  },
  {
    "text": "still slower than the sequential\nversion of the algorithm because my threads\nwere synchronizing to take the next task.",
    "start": "3100200",
    "end": "3106380"
  },
  {
    "text": "So that was an example\nof synchronization. And then last, at\nsome point, someone",
    "start": "3106380",
    "end": "3112230"
  },
  {
    "text": "has to actually take this\nidea of a thread or a program",
    "start": "3112230",
    "end": "3117300"
  },
  {
    "text": "instance and map it to an\nactual piece of hardware. That's the last step of this.",
    "start": "3117300",
    "end": "3122500"
  },
  {
    "text": "So, oh, sorry. We talked about orchestration\nand mapping it to hardware. So, for example, imagine\nyou create a thread,",
    "start": "3122500",
    "end": "3131320"
  },
  {
    "text": "who maps your C++ thread to\na hardware execution context? We just talked about it.",
    "start": "3131320",
    "end": "3138010"
  },
  {
    "text": "Operating system. In ISPC, who maps a program\ninstance to a vector lane?",
    "start": "3138010",
    "end": "3146000"
  },
  {
    "text": "Compiler. That's built in the\nimplementation of the compiler. Exactly.",
    "start": "3146000",
    "end": "3151220"
  },
  {
    "text": "And there's a bunch of\ninteresting mapping decisions. Imagine you're the operating\nsystem and imagine your program",
    "start": "3151220",
    "end": "3157430"
  },
  {
    "text": "creates two threads, and you're\nrunning on a myth machine. If your program\ncreates two threads",
    "start": "3157430",
    "end": "3164503"
  },
  {
    "text": "and I'm the operating\nsystem, do I put them both on execution\ncontext on the same core? Or do I put them\non different cores?",
    "start": "3164503",
    "end": "3172580"
  },
  {
    "text": "It's just a policy\ndecision that one can make. And there are different\npros and cons. ",
    "start": "3172580",
    "end": "3179741"
  },
  {
    "text": "So let's dig in with a little\nbit stronger case study here. How many people--\ndo we have any--",
    "start": "3179741",
    "end": "3185125"
  },
  {
    "text": " like any numerical\ncomputing folks?",
    "start": "3185125",
    "end": "3192200"
  },
  {
    "text": "Any scientific computing\nfolks in the room. There almost always are. OK, no. How many people have implemented\na solver, an iterative solver",
    "start": "3192200",
    "end": "3200540"
  },
  {
    "text": "in a numerical methods class? We got some folks. Cool. What solver did you implement? Just Newton's method.",
    "start": "3200540",
    "end": "3206910"
  },
  {
    "text": "You meant Newton's\nmethod solver. So here's actually, well,\nno, not similar idea.",
    "start": "3206910",
    "end": "3212140"
  },
  {
    "text": "But here's a grid of this-- Imagine we had a-- this is actually\nfrom a fluid solver",
    "start": "3212140",
    "end": "3219960"
  },
  {
    "text": "where we have a grid of values. And at every value, there's\na pressure or some quantity.",
    "start": "3219960",
    "end": "3226780"
  },
  {
    "text": "And the goal is to bring\nthis system to convergence.",
    "start": "3226780",
    "end": "3233650"
  },
  {
    "text": "And the details of that\nare not that important, but computationally\nwhat it basically is blurring out the grid.",
    "start": "3233650",
    "end": "3240660"
  },
  {
    "text": "The new value at\na location yellow is going to be the average\nof the surrounding values.",
    "start": "3240660",
    "end": "3248550"
  },
  {
    "text": "So we're trying to basically--\nwe're going to iterate on this and just bring this to\nconvergence so that if I",
    "start": "3248550",
    "end": "3254069"
  },
  {
    "text": "change-- if I change the blue\nvalue here, that should cause some update\nin the yellow value.",
    "start": "3254070",
    "end": "3259470"
  },
  {
    "text": "Now look carefully\nat my code here. This is the starting\ncode we have.",
    "start": "3259470",
    "end": "3264809"
  },
  {
    "text": "While not converged, for\nevery element in the array--",
    "start": "3264810",
    "end": "3269910"
  },
  {
    "text": "now, by the way, this is just\npseudocode, C-like pseudocode. For every element in\nthe grid, save off",
    "start": "3269910",
    "end": "3277710"
  },
  {
    "text": "the previous value\nand the new value is the combination\nof my neighbors.",
    "start": "3277710",
    "end": "3285270"
  },
  {
    "text": "And then I'm accumulating\nthe total amount of change of all values.",
    "start": "3285270",
    "end": "3292110"
  },
  {
    "text": "And if the total amount of\nchange over the whole grid has changed enough, we'll\nstop or we'll keep going.",
    "start": "3292110",
    "end": "3298900"
  },
  {
    "text": "If nothing is changing\nanymore, we've converged and we've stopped. So step 1 of anything, whenever\nI slam code up here is I'm",
    "start": "3298900",
    "end": "3305940"
  },
  {
    "text": "going to ask you, what\ncan be done in parallel? ",
    "start": "3305940",
    "end": "3311910"
  },
  {
    "text": "So take a look at this. And if we respect the code as\nis, what is the challenge that",
    "start": "3311910",
    "end": "3320970"
  },
  {
    "text": "makes us go, oh-oh? Yeah. [INAUDIBLE] are\nall the neighbors,",
    "start": "3320970",
    "end": "3330910"
  },
  {
    "text": "which we also have to compute. So the code is not [INAUDIBLE]. AIJ depends on my neighbors,\nbut my neighbors just",
    "start": "3330910",
    "end": "3337529"
  },
  {
    "text": "got updated in the previous\niteration of the J loop. So I cannot do the next\niteration of the innermost loop",
    "start": "3337530",
    "end": "3344730"
  },
  {
    "text": "until I complete the previous\niteration of the innermost loop.",
    "start": "3344730",
    "end": "3350980"
  },
  {
    "text": "So your dependencies might\nlook a little bit like this. The red arrows say\nthat the black dot",
    "start": "3350980",
    "end": "3356790"
  },
  {
    "text": "is dependent on\nanother dot if there's a red arrow from an\nexternal thing to me.",
    "start": "3356790",
    "end": "3362555"
  },
  {
    "text": " So if I asked you to\nparallelize this code,",
    "start": "3362555",
    "end": "3369220"
  },
  {
    "text": "and this was the code, is\nthere anything you could do? ",
    "start": "3369220",
    "end": "3375099"
  },
  {
    "text": "We could try different chunks\nthat aren't touching each other. Well, OK, but-- so let's\nsay I did the top left chunk",
    "start": "3375100",
    "end": "3384230"
  },
  {
    "text": "completely sequentially. What could I do in\nparallel with it? [INAUDIBLE]",
    "start": "3384230",
    "end": "3391820"
  },
  {
    "text": "But I can't do the\ntop right chunk because none of these values are\nknown until all that information propagates.",
    "start": "3391820",
    "end": "3397079"
  },
  {
    "text": " So I can't quite do that. I might get the wrong answer.",
    "start": "3397080",
    "end": "3402806"
  },
  {
    "text": "Yeah. [INAUDIBLE] Sorry. [INAUDIBLE]",
    "start": "3402806",
    "end": "3407900"
  },
  {
    "text": "But if I-- If I make a separate\nresult array every loop, I'm going to compute\na different answer",
    "start": "3407900",
    "end": "3414290"
  },
  {
    "text": "because my value\nat this iteration depends on previous\ncomputations in the same loop.",
    "start": "3414290",
    "end": "3420395"
  },
  {
    "text": "So if I write the new result\nto iA2 something else, I am not computing\nthe same thing.",
    "start": "3420395",
    "end": "3427930"
  },
  {
    "text": " Any other thoughts? Yeah.",
    "start": "3427930",
    "end": "3433010"
  },
  {
    "text": "You could split diagonally. There is a little bit\nof parallelism here.",
    "start": "3433010",
    "end": "3438860"
  },
  {
    "text": "There's a little bit\nof parallelism here. So you could be really clever,\nand you could say, well,",
    "start": "3438860",
    "end": "3444290"
  },
  {
    "text": "certain parts of the program,\nthere's at least a little bit more than O of n parallelism.",
    "start": "3444290",
    "end": "3449510"
  },
  {
    "text": "But I'm kind of\nlike, I don't even know if I want to\nwrite that code. I don't want to-- I don't know if I want to write\nthat code for two reasons.",
    "start": "3449510",
    "end": "3456007"
  },
  {
    "text": "One is I don't have\na lot of parallelism in large parts of the program. So Amdahl's law is\ngoing to get me.",
    "start": "3456007",
    "end": "3461790"
  },
  {
    "text": "And second of all,\nif I'm actually moving in this direction, I'm\nall over the memory address",
    "start": "3461790",
    "end": "3470140"
  },
  {
    "text": "space. And so it's not clear\nthat it's necessarily going to be a\nbenefit to me anyways even if I got some parallelism.",
    "start": "3470140",
    "end": "3476299"
  },
  {
    "text": "So here's what\nwe're going to do, which is a big part of often\nthinking about programs.",
    "start": "3476300",
    "end": "3481710"
  },
  {
    "text": "And when we do a mini\ntransformer in assignment 4 this year, this is going\nto be a big part of it,",
    "start": "3481710",
    "end": "3488670"
  },
  {
    "text": "is sometimes you look\nat a program and go, I don't really want\nto bother with this. This is not a program that I'm\ngoing to have a lot of success",
    "start": "3488670",
    "end": "3497460"
  },
  {
    "text": "with. So what we're going to do is\nwe're going to look at it, and we're going to use our\nknowledge of solvers and go,",
    "start": "3497460",
    "end": "3504760"
  },
  {
    "text": "there's another solver that\nwill compute approximately the same answer, but is more\nfriendly for parallelism.",
    "start": "3504760",
    "end": "3512598"
  },
  {
    "text": "So that's what I'm going to do. We needed some domain knowledge. You've got to go\ntalk to your expert, or you got to be an\nexpert in machine learning",
    "start": "3512598",
    "end": "3518010"
  },
  {
    "text": "or you've got to be an expert in\ngraphics or something like that. We're going to change the\nalgorithm a little bit to a different algorithm\nthat's way easier.",
    "start": "3518010",
    "end": "3525930"
  },
  {
    "text": "And that's we're going to do\nthis checkerboarding thing, and we're going to iterate back\nand forth, which is on one step,",
    "start": "3525930",
    "end": "3533400"
  },
  {
    "text": "I'm going to take\nall of the red cells and update them based\non the black cells.",
    "start": "3533400",
    "end": "3539910"
  },
  {
    "text": "And then on the\nnext step, I'm going to flip it around and update\nall the black cells based on the red cells.",
    "start": "3539910",
    "end": "3545440"
  },
  {
    "text": "So I hope you can\nconvince yourself that I can do all of the\nred cells in parallel,",
    "start": "3545440",
    "end": "3550769"
  },
  {
    "text": "and then I can do all the\nblack cells in parallel. Now I've changed the\nalgorithm, which by the way,",
    "start": "3550770",
    "end": "3556119"
  },
  {
    "text": "I told you just a second\nago, you can't do that. But now this is like, we just--",
    "start": "3556120",
    "end": "3561990"
  },
  {
    "text": "we had nothing to do. So it's like, OK, let's go\nto a different algorithm. It's more friendly\nto parallelism.",
    "start": "3561990",
    "end": "3567130"
  },
  {
    "text": "It turns out that this new\nalgorithm will actually take a little bit\nlonger to converge. We're actually probably going\nto need to do more iterations,",
    "start": "3567130",
    "end": "3574210"
  },
  {
    "text": "but the cost of doing some\nextra work, we're hoping, can be made up by the ability\nto massively paralyze, if we",
    "start": "3574210",
    "end": "3580152"
  },
  {
    "text": "have a big parallel computer.  Yeah. One question about\nboth the algorithms.",
    "start": "3580152",
    "end": "3586341"
  },
  {
    "text": "So they will converge to\nthe same value, right? I'm just asserting that, and I\nwant you to trust me for now.",
    "start": "3586342",
    "end": "3591900"
  },
  {
    "text": "Or they're going to converge\nnot to the same numerical value,",
    "start": "3591900",
    "end": "3597039"
  },
  {
    "text": "but this is already an\nalgorithm that's good enough. So as long as it converges\nto some threshold,",
    "start": "3597040",
    "end": "3603550"
  },
  {
    "text": "we are scientifically happy. Yes. The domain specific\naccelerators,",
    "start": "3603550",
    "end": "3608700"
  },
  {
    "text": "why wouldn't you right now,\nthink about using hardware to solve this? Probably something\nlike a systolic system",
    "start": "3608700",
    "end": "3615390"
  },
  {
    "text": "might be able to help\nwith the first approach. Yeah. So you are correct.",
    "start": "3615390",
    "end": "3621900"
  },
  {
    "text": "One possible solution would\nbe let's go build some custom hardware for this.",
    "start": "3621900",
    "end": "3627730"
  },
  {
    "text": "Now, the hardware does have some\nscalability issues in that there is only so much\nparallelism here,",
    "start": "3627730",
    "end": "3634770"
  },
  {
    "text": "but you're also proposing\na pretty expensive solution to the problem of go\ndesigning a $100 million",
    "start": "3634770",
    "end": "3640440"
  },
  {
    "text": "accelerator to handle\nthis thing that you have two weeks to do the assignment.",
    "start": "3640440",
    "end": "3646790"
  },
  {
    "text": "So that was decomposition. So we've decomposed the problem\ninto let's do all the red stuff",
    "start": "3646790",
    "end": "3652770"
  },
  {
    "text": "in parallel. So every red dot is\nsomething independent. And now we need to\nthink about assignment.",
    "start": "3652770",
    "end": "3659260"
  },
  {
    "text": "Let's say, if I'm going to\nchunk this grid up into two",
    "start": "3659260",
    "end": "3664290"
  },
  {
    "text": "possible assignments. Let's say I'm going\nto divide them in a blocked way\nacross the processors,",
    "start": "3664290",
    "end": "3670317"
  },
  {
    "text": "or I could divide them\nin an interleaved way across the processors. Two valid ways to\nparallelize this program, who",
    "start": "3670317",
    "end": "3677670"
  },
  {
    "text": "knows what might be better? It could be some\nissues that lead us to do one or over the\nother, but that would",
    "start": "3677670",
    "end": "3685170"
  },
  {
    "text": "be an assignment decision. So let's consider the\ndependencies in this program. We're going to compute all\nof the red cells, which",
    "start": "3685170",
    "end": "3692790"
  },
  {
    "text": "means every red cell needs\nto access its neighbors. And then I'm going to update--",
    "start": "3692790",
    "end": "3698799"
  },
  {
    "text": "I'm going to send all\nprocessors-- everybody needs to be able to get the updated\nvalue of the red cells",
    "start": "3698800",
    "end": "3706260"
  },
  {
    "text": "so that we can then do\nthe black cell update. So when I think about--",
    "start": "3706260",
    "end": "3711380"
  },
  {
    "text": "this program that I've\nwritten occurs in phases. So in this particular\ncase, if we",
    "start": "3711380",
    "end": "3717660"
  },
  {
    "text": "decide to put contiguous\nblocks of this array local to various processors,\nthere's much less data",
    "start": "3717660",
    "end": "3726240"
  },
  {
    "text": "that needs to be exchanged. Because if I'm, let's\nsay, processor 4, I just updated these black\ncells or these red cells,",
    "start": "3726240",
    "end": "3733500"
  },
  {
    "text": "well, I already\nhave the information I need to update my black cells. Whereas if I would have gone\nwith some interleave mapping,",
    "start": "3733500",
    "end": "3740590"
  },
  {
    "text": "every single thing\nthat I compute has to get transferred to my\nneighbors at some future time.",
    "start": "3740590",
    "end": "3745830"
  },
  {
    "text": "So there can be\nsome issues related to given the knowledge of\nthe program, in this case,",
    "start": "3745830",
    "end": "3751902"
  },
  {
    "text": "I'd probably do this kind of\nblocked assignment as opposed to interleaved. But when we were talking\nearlier about ISPC programming",
    "start": "3751903",
    "end": "3758070"
  },
  {
    "text": "on SIMD hardware, we actually\nmade a different conclusion. So you need to know what\nyou're running on in order to think about the thing.",
    "start": "3758070",
    "end": "3764920"
  },
  {
    "text": "So I want to write this solver\nnow in two different ways.",
    "start": "3764920",
    "end": "3771720"
  },
  {
    "text": "The first way, we are not\ngoing to think about threads or parallelism at all.",
    "start": "3771720",
    "end": "3776770"
  },
  {
    "text": "We're just going to think\nabout parallel work. It's very much like the for each\nway of thinking about things.",
    "start": "3776770",
    "end": "3782700"
  },
  {
    "text": "And then I'm going to\ncome back and rewrite it in a way that's more like,\nhere are all my workers,",
    "start": "3782700",
    "end": "3788099"
  },
  {
    "text": "and here's how they communicate\nto solve the problem. So I'd very much\nrather, as a programmer,",
    "start": "3788100",
    "end": "3793330"
  },
  {
    "text": "write it in this more-- I'm going to just think\nabout parallel work.",
    "start": "3793330",
    "end": "3799720"
  },
  {
    "text": "So here's a version of that. Now I'm stepping out of ISPC\njust to be in pseudocode.",
    "start": "3799720",
    "end": "3804790"
  },
  {
    "text": "This is just pseudocode. We're not thinking about SIMD. We're just thinking\nabstractly right now. Oh-oh, that might\nend up down here.",
    "start": "3804790",
    "end": "3812890"
  },
  {
    "text": "So I kept this simple,\nand this is only code for just the\nupdate of the red cells.",
    "start": "3812890",
    "end": "3818530"
  },
  {
    "text": "So there's another thing down\nhere, but just the update. So for basically,\nlook what this says is there's no\nparallelism at all.",
    "start": "3818530",
    "end": "3825670"
  },
  {
    "text": "I just have a program that\nruns sequentially logically,",
    "start": "3825670",
    "end": "3830829"
  },
  {
    "text": "but here, instead of a regular\nfor loop, I just wrote it as a for all red cells--",
    "start": "3830830",
    "end": "3837369"
  },
  {
    "text": "for all red cells independently,\nplease do your red cell update.",
    "start": "3837370",
    "end": "3842980"
  },
  {
    "text": "And then using some helper\nfunction, which we magically have available to us, please\ngo ahead and compute the--",
    "start": "3842980",
    "end": "3850269"
  },
  {
    "text": "the amount of update that\nthis iteration did, please accumulate it into this\nglobal variable diff.",
    "start": "3850270",
    "end": "3857130"
  },
  {
    "text": " Does that make sense? And we've left\neverything to the system",
    "start": "3857130",
    "end": "3864700"
  },
  {
    "text": "to figure out how\nto parallelize. We've said, trust me, these\niterations are almost completely",
    "start": "3864700",
    "end": "3871240"
  },
  {
    "text": "independent. The only thing you\nhave to worry about is that I want all\nthe information that I'm computing to\nget correctly added",
    "start": "3871240",
    "end": "3879069"
  },
  {
    "text": "into this global variable. So I am thinking about\nparallelism a little bit here because otherwise I\nwouldn't have written this.",
    "start": "3879070",
    "end": "3886120"
  },
  {
    "text": "But more or less,\nI'm leaving all the-- I've done the\ndecomposition, and I've",
    "start": "3886120",
    "end": "3891880"
  },
  {
    "text": "said assignment parallel system,\nyou go figure out for me. ",
    "start": "3891880",
    "end": "3899910"
  },
  {
    "text": "Make sense? And this is what I'd rather\nwrite it this way because it's basically the sequential code.",
    "start": "3899910",
    "end": "3905884"
  },
  {
    "text": "I just did one little\nthing which said, hey, compiler, trust\nme, all these iterations you can do in parallel provided\nthat you take a little bit",
    "start": "3905885",
    "end": "3912210"
  },
  {
    "text": "of care right here.  Now let's step down\nto a lower level",
    "start": "3912210",
    "end": "3919410"
  },
  {
    "text": "and see how we might\nwrite it ourselves with lower level abstractions.",
    "start": "3919410",
    "end": "3925432"
  },
  {
    "text": "Or we might--\nanother way to think about this is if you\nwere the compiler or runtime, how would\nyou implement this,",
    "start": "3925433",
    "end": "3933150"
  },
  {
    "text": "which at the end\nof the day, someone needs to decide who does what? So now I want you to think about\nISPC programming or threaded",
    "start": "3933150",
    "end": "3943380"
  },
  {
    "text": "programming, whatever\nprogramming model you want, we're just going to have a bunch\nof threads running in a shared",
    "start": "3943380",
    "end": "3949230"
  },
  {
    "text": "address space. So everybody can access\nshared variables. We have one address\nspace, but we're",
    "start": "3949230",
    "end": "3957660"
  },
  {
    "text": "going to have to synchronize\nwith some constructs, like locks and barriers. So here is my\nimplementation of this code.",
    "start": "3957660",
    "end": "3964990"
  },
  {
    "text": "Now it's a little bit long, so\nI've tried to explain it to you or I've tried to\nannotate it here,",
    "start": "3964990",
    "end": "3972910"
  },
  {
    "text": "but it's doing the same thing. It's saying while\nnot converged, this is code that's run by\nevery thread in the system.",
    "start": "3972910",
    "end": "3981010"
  },
  {
    "text": "So if this was ISPC,\nthis is like the code running by a program instance. If this was threaded\nC programming,",
    "start": "3981010",
    "end": "3989290"
  },
  {
    "text": "it's just the thread. And in the same way that I\ncould get my program index, in any threaded system,\nyou have the ability",
    "start": "3989290",
    "end": "3996040"
  },
  {
    "text": "to get your current thread ID. So you have some\nway of knowing out of all the running things on\nthe system, which one am I?",
    "start": "3996040",
    "end": "4003480"
  },
  {
    "text": "Because I need to take that\ninformation about which index I am and turn that into some\ndecision about what work",
    "start": "4003480",
    "end": "4010530"
  },
  {
    "text": "I'm responsible for viewing. So given this thread ID,\nnotice what happens here.",
    "start": "4010530",
    "end": "4016870"
  },
  {
    "text": "I want you to ignore all this\njumble of locks and barriers and just look at this.",
    "start": "4016870",
    "end": "4022119"
  },
  {
    "text": "It says, I'm going to compute\nthe rows that I'm responsible for, my min and my max, which\nis a blocked set of rows.",
    "start": "4022120",
    "end": "4030010"
  },
  {
    "text": "And for all elements between\nrow my min and my max, I'm going to do the update.",
    "start": "4030010",
    "end": "4036540"
  },
  {
    "text": "And I have this local\nvariable, my diff, which I'm accumulating\nmy local stuff into.",
    "start": "4036540",
    "end": "4044270"
  },
  {
    "text": "And then at some\npoint I take my diff, and I add it into a\nglobal variable diff",
    "start": "4044270",
    "end": "4050070"
  },
  {
    "text": "for all the threads. So this is like-- you could\nwrite this in C++ if you wanted",
    "start": "4050070",
    "end": "4055580"
  },
  {
    "text": "a C code. All right. So my question to you is,\nwhat is this lock doing here?",
    "start": "4055580",
    "end": "4062970"
  },
  {
    "text": "Why do I have lock unlock\naround this line of code? Yeah. This is for\norchestration purposes.",
    "start": "4062970",
    "end": "4069955"
  },
  {
    "text": "And what could go badly\nif I did not unlock that? [INAUDIBLE]",
    "start": "4069955",
    "end": "4076510"
  },
  {
    "text": "What's that? Race condition. It's a race condition,\nbut, I mean, true. But what could go in the\nspecific terms of this program,",
    "start": "4076510",
    "end": "4082970"
  },
  {
    "text": "what could go badly? Some players could read this\nwhile some other players write. So we need to make sure that\nthis change to this shared",
    "start": "4082970",
    "end": "4092800"
  },
  {
    "text": "variable is atomic. Let me elaborate on\nthat a little bit. So let's go think about\na simpler example.",
    "start": "4092800",
    "end": "4100040"
  },
  {
    "text": "Imagine I have thread\n1, which at some point writes 1 to some variable x.",
    "start": "4100040",
    "end": "4105278"
  },
  {
    "text": "And I have another\nthread 2, which also has access to variable x.",
    "start": "4105279",
    "end": "4111130"
  },
  {
    "text": "And whenever it's non-zero,\nwe're going to print x.",
    "start": "4111130",
    "end": "4117520"
  },
  {
    "text": "We'd really expect x to\nbe printed to be 1 here. So you can think about\nthe shared address space",
    "start": "4117520",
    "end": "4125109"
  },
  {
    "text": "as this is what you\nthought of any computer. There is some memory address\nspace-- there's an address x",
    "start": "4125109",
    "end": "4131109"
  },
  {
    "text": "and there's a value at\nx, and all my threads have the ability to read\nand write to that value.",
    "start": "4131109",
    "end": "4136790"
  },
  {
    "text": "That's just the\nnotion of computer that I haven't even taught\nyou, but you naturally would have assumed. People like to think\nabout a shared address",
    "start": "4136790",
    "end": "4143410"
  },
  {
    "text": "space as a bulletin board. You go to somebody's door,\nanybody can read and write. It could be some problems if we\nread and write to the same spot.",
    "start": "4143410",
    "end": "4152630"
  },
  {
    "text": "So the reason why\nwe protect updates to shared variables with\nlocks is let's think",
    "start": "4152630",
    "end": "4158981"
  },
  {
    "text": "about what can happen when we\nthink about what does it mean to write to a value in memory. When I have an X plus plus in\nmy code, what that really means",
    "start": "4158981",
    "end": "4168850"
  },
  {
    "text": "is load the value in\nmemory into register R1, then perform the math on R1, and\nthen store that value back out",
    "start": "4168850",
    "end": "4178659"
  },
  {
    "text": "to memory. There's actually\nthree operations-- three operations here, even\nthough it's one line of code.",
    "start": "4178660",
    "end": "4185170"
  },
  {
    "text": "So imagine that the value in\nmemory was 0 as we started, T1 would load 0, update it to\nbe 1, and then try and store 1.",
    "start": "4185170",
    "end": "4197230"
  },
  {
    "text": "What if at the same time\nthread 2 went in there, tried to do X plus\nplus, it also read 0",
    "start": "4197230",
    "end": "4203650"
  },
  {
    "text": "because it read the value\nbefore T1 had written it. It updates it by\nmaking the value 1",
    "start": "4203650",
    "end": "4210550"
  },
  {
    "text": "and then later writes\n1 back to memory. We would miss an update.",
    "start": "4210550",
    "end": "4216560"
  },
  {
    "text": "So this is a race\ncondition because we don't have mutual exclusion. We don't have a\npolicy set for it",
    "start": "4216560",
    "end": "4223550"
  },
  {
    "text": "so that only one\nthread is writing to a shared value at once.",
    "start": "4223550",
    "end": "4228590"
  },
  {
    "text": "And what the lock\ndoes is the lock provides that mutual exclusion. Only one thread\ncan have the lock",
    "start": "4228590",
    "end": "4234950"
  },
  {
    "text": "at once, which means only\none thread could be writing. Later in the course,\nI'll tell you about other really\nhelpful primitives",
    "start": "4234950",
    "end": "4242150"
  },
  {
    "text": "that allow you to ensure\nmutual exclusion without locks. But in this example here,\nthat's what that lock is doing.",
    "start": "4242150",
    "end": "4253458"
  },
  {
    "text": "And that's something you\nwould have seen probably in 111 with your thread pool. So review here.",
    "start": "4253458",
    "end": "4259110"
  },
  {
    "text": "Now, in the context of this\nprogram, what could happen if we didn't have the lock?",
    "start": "4259110",
    "end": "4264770"
  },
  {
    "text": "What would be the\neffect on the program? The total value would be what? Lower.",
    "start": "4264770",
    "end": "4269840"
  },
  {
    "text": "Potentially lower\nthan it should be. And some threads\nmight falsely conclude that they should terminate.",
    "start": "4269840",
    "end": "4276725"
  },
  {
    "text": "So that would be the effect\nhere, the incorrect assumption that things had falsely--",
    "start": "4276725",
    "end": "4283550"
  },
  {
    "text": "Now, this code is\ncorrect, but now there's a performance problem here--",
    "start": "4283550",
    "end": "4289074"
  },
  {
    "text": " something I really don't like.",
    "start": "4289075",
    "end": "4294190"
  },
  {
    "start": "4294190",
    "end": "4300234"
  },
  {
    "text": "Oh, sorry. Actually, I already fixed it. Shoot. I meant to do the--",
    "start": "4300234",
    "end": "4305607"
  },
  {
    "text": "I've already actually\nfixed it in this code. So the original code had\nthis lock unlock update here.",
    "start": "4305607",
    "end": "4312320"
  },
  {
    "text": "And in a copy paste thing\nlast night, I actually copied the better\nversion into here.",
    "start": "4312320",
    "end": "4317910"
  },
  {
    "text": "So my original version was\nI don't even have a my diff. Just do a lock-- just do a lock and\nupdate global diff.",
    "start": "4317910",
    "end": "4325310"
  },
  {
    "text": "And the problem with that is\nI'm doing this synchronization in my innermost loop.",
    "start": "4325310",
    "end": "4331170"
  },
  {
    "text": "So my solution here\nwas to actually create a private copy of my diff,\nhave everybody update",
    "start": "4331170",
    "end": "4337280"
  },
  {
    "text": "their partial diff\nwithout locks, and then come back together at\nthe very end of the iteration",
    "start": "4337280",
    "end": "4342860"
  },
  {
    "text": "and compute the overall\nsum before we actually did the check. Sorry about that.",
    "start": "4342860",
    "end": "4348540"
  },
  {
    "text": "I was looking about that. I was like, there is\nno performance problem with the code. But now the last question I\nwant to ask you as we finish up",
    "start": "4348540",
    "end": "4355670"
  },
  {
    "text": "is, what are these\nbarriers doing here? You might even be asking\nme, what is a barrier?",
    "start": "4355670",
    "end": "4362860"
  },
  {
    "text": "So what a barrier is, it's\nanother form of synchronization. If a lock is about\nmutual exclusion--",
    "start": "4362860",
    "end": "4368870"
  },
  {
    "text": "only one thread\ncan hold the lock-- a barrier is a very coarse\nframe of synchronization where",
    "start": "4368870",
    "end": "4374170"
  },
  {
    "text": "you can phase your computation. So a barrier says, no thread.",
    "start": "4374170",
    "end": "4379639"
  },
  {
    "text": "The caller will not\nproceed past a barrier until all threads have\ngotten to this point.",
    "start": "4379640",
    "end": "4388120"
  },
  {
    "text": "So say, once I know everybody is\nhere, then we can all continue.",
    "start": "4388120",
    "end": "4393940"
  },
  {
    "text": "So my question is, why do I have\nthree barriers in this code?",
    "start": "4393940",
    "end": "4401080"
  },
  {
    "text": "I intuitively would think\nI should probably have one. I should do all my work.",
    "start": "4401080",
    "end": "4406400"
  },
  {
    "text": "We should wait for\neverybody to get done and accumulate into my diff. And then we should do a check,\nand we should keep going.",
    "start": "4406400",
    "end": "4413409"
  },
  {
    "text": "But this code is correct, and\nI have three barriers in it. And if we have four\nminutes, the last thing",
    "start": "4413410",
    "end": "4419150"
  },
  {
    "text": "I'll ask you to do\ntoday is, why don't you see if you can talk this over? What is the purpose\nof all three of these?",
    "start": "4419150",
    "end": "4424830"
  },
  {
    "text": "I claim I need them. So wake up for one second.",
    "start": "4424830",
    "end": "4430650"
  },
  {
    "text": "[LAUGHTER] [SIDE CONVERSATION] ",
    "start": "4430650",
    "end": "4444850"
  },
  {
    "text": "So since we have\ntwo minutes, let's see if we can talk it over. So, I think, the first\none to really look at",
    "start": "4444850",
    "end": "4451890"
  },
  {
    "text": "is to be the one that's the\nmost obvious, the second barrier here. Why did I put a barrier\nin the code here?",
    "start": "4451890",
    "end": "4459520"
  },
  {
    "text": "Yes, sir. [INAUDIBLE] threads in order\nto get the correct diff value for that iteration [INAUDIBLE]?",
    "start": "4459520",
    "end": "4465300"
  },
  {
    "text": "Before any thread checks to\nsee if the system is converged, we need to make sure that\nall threads have performed",
    "start": "4465300",
    "end": "4472890"
  },
  {
    "text": "this update so that we're\nlooking at a correct diff value. That makes sense.",
    "start": "4472890",
    "end": "4478505"
  },
  {
    "text": "So let's say we decide to-- that done is we\nwant to continue.",
    "start": "4478505",
    "end": "4486989"
  },
  {
    "text": "What happens if this\nbarrier is not here and I immediately shoot up?",
    "start": "4486990",
    "end": "4493650"
  },
  {
    "text": "Yeah. One could just go and\nset the diff to 0. So I might [INAUDIBLE]\nthread zero might be like,",
    "start": "4493650",
    "end": "4499940"
  },
  {
    "text": "OK, sure, we got to keep going. All right, let me get started\nfor the next iteration setting",
    "start": "4499940",
    "end": "4504970"
  },
  {
    "text": "global diff to 0. And then what happens? All other threads\nmight be like, shoot.",
    "start": "4504970",
    "end": "4511130"
  },
  {
    "text": "By the time I got around\nto checking it, it's 0. We should stop. Good.",
    "start": "4511130",
    "end": "4517253"
  },
  {
    "text": "So that's why I need\nthis one, because I don't want people to\nclear that value before I take a look at it.",
    "start": "4517253",
    "end": "4522579"
  },
  {
    "text": "And then what about\nthis one, the last one?",
    "start": "4522580",
    "end": "4527710"
  },
  {
    "text": "A thread by update\nthe diff in the lock, and that might change the value. So what if in the\nnext iteration I",
    "start": "4527710",
    "end": "4533770"
  },
  {
    "text": "get all the way through my work\nand I update the diff value",
    "start": "4533770",
    "end": "4538780"
  },
  {
    "text": "before in the\nprevious iteration, the other threads have\nactually been able to check it?",
    "start": "4538780",
    "end": "4545860"
  },
  {
    "text": "And if that allowed to\nhappen, then the diff value would be incorrectly to--",
    "start": "4545860",
    "end": "4551715"
  },
  {
    "text": "well, who knows\nwhat it would be? I've set it to 0, and then\nI've updated something into it. So it could be too\nlarge or too small.",
    "start": "4551715",
    "end": "4557143"
  },
  {
    "text": "It's just wrong. So you see how I\nneed all of these here to have this\ncorrect program. So my challenge to\nyou in the lecture",
    "start": "4557143",
    "end": "4565180"
  },
  {
    "text": "is it is possible\nto do it with one. Can you do it\ncorrectly with one?",
    "start": "4565180",
    "end": "4572120"
  },
  {
    "text": "And the hint would be take some\ninspiration for what we did here with the diff variable is if\nwe didn't have a local diff",
    "start": "4572120",
    "end": "4582159"
  },
  {
    "text": "and we had one global\ndiff, every single time I wanted to access diff,\nI would have to lock it.",
    "start": "4582160",
    "end": "4589150"
  },
  {
    "text": "But what we did is\nwe had contention. So I made local\ncopies of something",
    "start": "4589150",
    "end": "4594190"
  },
  {
    "text": "in order to remove\nthe contention by replicating some stuff. Here, what are we contending\nfor with the barriers?",
    "start": "4594190",
    "end": "4603430"
  },
  {
    "text": "What's the variable that we're\nall making decisions off of? The diff. Diff.",
    "start": "4603430",
    "end": "4608450"
  },
  {
    "text": "And the problem is that we're\nreusing the same diff variable across different iterations.",
    "start": "4608450",
    "end": "4614390"
  },
  {
    "text": "Is there any way you can\nreplicate something in order to remove this dependency?",
    "start": "4614390",
    "end": "4619730"
  },
  {
    "text": "And you can get it down\nall the way to one, and this is the only\none you actually need. So I'll let-- I'll stop there.",
    "start": "4619730",
    "end": "4625710"
  },
  {
    "text": "And that's just a fun one to\ntalk about on the website. Mm-hmm. ",
    "start": "4625710",
    "end": "4634000"
  }
]
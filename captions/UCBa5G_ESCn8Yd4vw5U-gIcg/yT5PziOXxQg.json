[
  {
    "start": "0",
    "end": "35000"
  },
  {
    "text": "Welcome everyone, uh, to the class.",
    "start": "4010",
    "end": "7065"
  },
  {
    "text": "What we are going to talk today about is,",
    "start": "7065",
    "end": "9840"
  },
  {
    "text": "um, some advanced topics,",
    "start": "9840",
    "end": "11985"
  },
  {
    "text": "and in particular we are going first to talk about limitations of,",
    "start": "11985",
    "end": "15660"
  },
  {
    "text": "uh, graph neural networks,",
    "start": "15660",
    "end": "17324"
  },
  {
    "text": "um, and then we are also going about how do we improve",
    "start": "17324",
    "end": "20699"
  },
  {
    "text": "their expressive power and how do we, um,",
    "start": "20700",
    "end": "24840"
  },
  {
    "text": "then, uh, study, uh,",
    "start": "24840",
    "end": "26880"
  },
  {
    "text": "how robust are graph neural networks against, um, adversarial attacks.",
    "start": "26880",
    "end": "33075"
  },
  {
    "text": "So the idea for today's lecture is- lecture is the following.",
    "start": "33075",
    "end": "37470"
  },
  {
    "start": "35000",
    "end": "106000"
  },
  {
    "text": "Um, what would the perfect GNN model do, right,",
    "start": "37470",
    "end": "40950"
  },
  {
    "text": "if we wanna say about what are some limitations of graph neural networks and",
    "start": "40950",
    "end": "44960"
  },
  {
    "text": "especially when we looked at their expressive power in terms of the,",
    "start": "44960",
    "end": "49524"
  },
  {
    "text": "um, in terms of the, um,",
    "start": "49525",
    "end": "52665"
  },
  {
    "text": "uh, WL kernel, right?",
    "start": "52665",
    "end": "55485"
  },
  {
    "text": "If we go through a thought experiment then we could say,",
    "start": "55485",
    "end": "58070"
  },
  {
    "text": "what would a perfect graph neural network do?",
    "start": "58070",
    "end": "61430"
  },
  {
    "text": "And the k-layer graph neural network embeds a node",
    "start": "61430",
    "end": "65045"
  },
  {
    "text": "based on the K-hop neighborhood structure around that node, right?",
    "start": "65045",
    "end": "69400"
  },
  {
    "text": "And this picture tries to illustrate that.",
    "start": "69400",
    "end": "71660"
  },
  {
    "text": "That is that basically if I wanna embed this particular, um, node here,",
    "start": "71660",
    "end": "76295"
  },
  {
    "text": "I can take the graph structure around this node and then,",
    "start": "76295",
    "end": "80210"
  },
  {
    "text": "um, through message passing,",
    "start": "80210",
    "end": "81560"
  },
  {
    "text": "I wanna compute the embedding of that node;",
    "start": "81560",
    "end": "83770"
  },
  {
    "text": "and a perfect GNN would be such that it would build",
    "start": "83770",
    "end": "87109"
  },
  {
    "text": "an injective function between the neighborhood structure around the target node,",
    "start": "87110",
    "end": "92060"
  },
  {
    "text": "um, and the embedding that it produces.",
    "start": "92060",
    "end": "95509"
  },
  {
    "text": "So essentially, what we'd like to do is- with",
    "start": "95510",
    "end": "98120"
  },
  {
    "text": "a perfect GNN would take every different node neighborhood structure,",
    "start": "98120",
    "end": "102110"
  },
  {
    "text": "uh, and embed it into a different position,",
    "start": "102110",
    "end": "104990"
  },
  {
    "text": "uh, in the embedding space.",
    "start": "104990",
    "end": "107159"
  },
  {
    "text": "Um, there are two important, uh,",
    "start": "107160",
    "end": "109695"
  },
  {
    "text": "observations, uh, building on this intuition.",
    "start": "109695",
    "end": "113195"
  },
  {
    "text": "First is that a perfect GNN will do the following, right?",
    "start": "113195",
    "end": "116480"
  },
  {
    "text": "If two nodes have the same neighborhood structure around the- around them,",
    "start": "116480",
    "end": "121070"
  },
  {
    "text": "then they will have the same embedding.",
    "start": "121070",
    "end": "123215"
  },
  {
    "text": "Again, here we are assuming there is no discriminative,",
    "start": "123215",
    "end": "126149"
  },
  {
    "text": "uh, feature information given to us.",
    "start": "126150",
    "end": "128119"
  },
  {
    "text": "So v1 and v2 in this- in this,",
    "start": "128120",
    "end": "131180"
  },
  {
    "text": "uh, graph, with, let's say,",
    "start": "131180",
    "end": "132560"
  },
  {
    "text": "two connected components will be embedded into",
    "start": "132560",
    "end": "135620"
  },
  {
    "text": "the- exactly the same point because their neighborhood structure,",
    "start": "135620",
    "end": "139129"
  },
  {
    "text": "uh, around them is identical,",
    "start": "139130",
    "end": "141380"
  },
  {
    "text": "and of course, right?",
    "start": "141380",
    "end": "143015"
  },
  {
    "text": "If we have two nodes that have different neighborhood structures, then, um,",
    "start": "143015",
    "end": "147050"
  },
  {
    "text": "we'd like them to be embedded into different points in the space",
    "start": "147050",
    "end": "150560"
  },
  {
    "text": "because the net- the- the neighborhood structures of these two nodes are different.",
    "start": "150560",
    "end": "154890"
  },
  {
    "text": "One is in a triangle,",
    "start": "154890",
    "end": "156020"
  },
  {
    "text": "the other one is in a square,",
    "start": "156020",
    "end": "157370"
  },
  {
    "text": "so they should be embedded into different points.",
    "start": "157370",
    "end": "160019"
  },
  {
    "text": "So that's kind of what we'd like to do.",
    "start": "160020",
    "end": "162230"
  },
  {
    "text": "That's what we'd like our perfect,",
    "start": "162230",
    "end": "164375"
  },
  {
    "text": "uh, GNN to do.",
    "start": "164375",
    "end": "166070"
  },
  {
    "start": "166000",
    "end": "253000"
  },
  {
    "text": "However, these observations, 1 and 2 may not be always, uh, true.",
    "start": "166070",
    "end": "171925"
  },
  {
    "text": "For example, the- the observation 1,",
    "start": "171925",
    "end": "174795"
  },
  {
    "text": "um, can have kind of the following, uh, issues.",
    "start": "174795",
    "end": "177845"
  },
  {
    "text": "Even though two nodes may have the same neighborhood structure around them,",
    "start": "177845",
    "end": "182300"
  },
  {
    "text": "we may wanna assign,",
    "start": "182300",
    "end": "184115"
  },
  {
    "text": "um, different embeddings to them.",
    "start": "184115",
    "end": "186200"
  },
  {
    "text": "Um, and this is because, uh, you know,",
    "start": "186200",
    "end": "188450"
  },
  {
    "text": "nodes may appear in different positions or in different locations in the graph.",
    "start": "188450",
    "end": "194140"
  },
  {
    "text": "Um, and we, uh,",
    "start": "194140",
    "end": "196020"
  },
  {
    "text": "we are going to call, uh, uh,",
    "start": "196020",
    "end": "198285"
  },
  {
    "text": "this notion of a position in the graph and",
    "start": "198285",
    "end": "200360"
  },
  {
    "text": "these tasks that require us understanding the position,",
    "start": "200360",
    "end": "203555"
  },
  {
    "text": "we'll call those position-aware tasks.",
    "start": "203555",
    "end": "205969"
  },
  {
    "text": "And I'm going to define this more, uh,",
    "start": "205970",
    "end": "207695"
  },
  {
    "text": "precisely throughout, uh, the lecture, right?",
    "start": "207695",
    "end": "210350"
  },
  {
    "text": "So basically even a- a perfect GNN,",
    "start": "210350",
    "end": "213060"
  },
  {
    "text": "that has that, um, injective,",
    "start": "213060",
    "end": "215040"
  },
  {
    "text": "uh, function between the neighborhood structure and",
    "start": "215040",
    "end": "217430"
  },
  {
    "text": "the embedding will fail at these, uh, tasks.",
    "start": "217430",
    "end": "220594"
  },
  {
    "text": "Uh, for example, here if I have a simple grid graph and I have nodes v1 and v2,",
    "start": "220595",
    "end": "226115"
  },
  {
    "text": "and I'd like them to be embedded into different points in space because they",
    "start": "226115",
    "end": "229850"
  },
  {
    "text": "are kind of at the opposite ends of the- of the underlying uh,",
    "start": "229850",
    "end": "233840"
  },
  {
    "text": "graph, actually a graph neural network is going to embed them, uh,",
    "start": "233840",
    "end": "237319"
  },
  {
    "text": "into the same position because the neighborhood structure around them is identical.",
    "start": "237320",
    "end": "241970"
  },
  {
    "text": "They are both in the corner,",
    "start": "241970",
    "end": "243440"
  },
  {
    "text": "uh, of the grid.",
    "start": "243440",
    "end": "245080"
  },
  {
    "text": "Um, so this is kind of one issue that, uh,",
    "start": "245080",
    "end": "248830"
  },
  {
    "text": "graph neural networks, as we have defined them so far,",
    "start": "248830",
    "end": "251510"
  },
  {
    "text": "uh, are not able to do.",
    "start": "251510",
    "end": "253055"
  },
  {
    "start": "253000",
    "end": "330000"
  },
  {
    "text": "Um, the second important, uh,",
    "start": "253055",
    "end": "255409"
  },
  {
    "text": "implication of the observation 2 is that,",
    "start": "255410",
    "end": "258590"
  },
  {
    "text": "um, GNNs that we have introduced so far are kind of not perfect, right?",
    "start": "258590",
    "end": "262600"
  },
  {
    "text": "Their expressive power, um,",
    "start": "262600",
    "end": "264810"
  },
  {
    "text": "is not- is not enough, right?",
    "start": "264810",
    "end": "266580"
  },
  {
    "text": "Uh, and in- particularly in lecture 9,",
    "start": "266580",
    "end": "268819"
  },
  {
    "text": "we discussed that the expressive power of our graph neural network,",
    "start": "268820",
    "end": "272780"
  },
  {
    "text": "this message passing graph neural network with indiscriminative features, uh,",
    "start": "272780",
    "end": "277025"
  },
  {
    "text": "it's expressive power is upper binded- bounded by the Weisfeiler-Lehman,",
    "start": "277025",
    "end": "281150"
  },
  {
    "text": "um, graph isomorphism test.",
    "start": "281150",
    "end": "283419"
  },
  {
    "text": "So, uh, for example, um,",
    "start": "283420",
    "end": "286155"
  },
  {
    "text": "if I have nodes v1 on a cycle of length 3 and a node v2 on cycle of length 4,",
    "start": "286155",
    "end": "292230"
  },
  {
    "text": "if I look at the structure of their computation graphs,",
    "start": "292230",
    "end": "294860"
  },
  {
    "text": "um, the structure of the two computation graphs will be the same.",
    "start": "294860",
    "end": "298490"
  },
  {
    "text": "So without any discriminative node features",
    "start": "298490",
    "end": "301715"
  },
  {
    "text": "or if assuming all node features are the same,",
    "start": "301715",
    "end": "304040"
  },
  {
    "text": "graph neural network is not going to be able to distinguish, um,",
    "start": "304040",
    "end": "307775"
  },
  {
    "text": "or it won't be able to assign different embeddings to nodes 1 and, uh, 2.",
    "start": "307775",
    "end": "313040"
  },
  {
    "text": "So basically nodes v1 and v2 will always be embedded into the same space, uh,",
    "start": "313040",
    "end": "318380"
  },
  {
    "text": "under the assumption that there is no useful node features,",
    "start": "318380",
    "end": "321260"
  },
  {
    "text": "um, because their computation graphs,",
    "start": "321260",
    "end": "323525"
  },
  {
    "text": "uh, are identical even though one",
    "start": "323525",
    "end": "325880"
  },
  {
    "text": "resides in a triangle and the other one resides in a square.",
    "start": "325880",
    "end": "329485"
  },
  {
    "text": "So, uh, the plan for the lecture today is that we wanna resolve both of",
    "start": "329485",
    "end": "333830"
  },
  {
    "start": "330000",
    "end": "392000"
  },
  {
    "text": "these issues by building or designing more expressive graph neural networks.",
    "start": "333830",
    "end": "338060"
  },
  {
    "text": "Uh, and the way we are going to fix these issues is the following.",
    "start": "338060",
    "end": "341710"
  },
  {
    "text": "Uh, to fix the issue, um, uh, one,",
    "start": "341710",
    "end": "344979"
  },
  {
    "text": "we are going to create node embeddings based on their positions in the graph.",
    "start": "344980",
    "end": "348500"
  },
  {
    "text": "Um, and the idea will be that we wanna create reference points in",
    "start": "348500",
    "end": "352250"
  },
  {
    "text": "the graph and then quantify the position of a node against those,",
    "start": "352250",
    "end": "356930"
  },
  {
    "text": "uh, reference points, and the class of models that",
    "start": "356930",
    "end": "359930"
  },
  {
    "text": "allow us to do this are called position-aware graph neural networks.",
    "start": "359930",
    "end": "363490"
  },
  {
    "text": "And then to fix the issue number- number 2, um,",
    "start": "363490",
    "end": "367365"
  },
  {
    "text": "we- we- we are going to build, uh,",
    "start": "367365",
    "end": "369599"
  },
  {
    "text": "message-passing GNNs that are more expressive than the WL, uh, test.",
    "start": "369600",
    "end": "374530"
  },
  {
    "text": "Um, and the method, an example of such a mes- message- method,",
    "start": "374530",
    "end": "378210"
  },
  {
    "text": "is called Identity-aware graph neural network.",
    "start": "378210",
    "end": "381060"
  },
  {
    "text": "So this is what is going to be the,",
    "start": "381060",
    "end": "383175"
  },
  {
    "text": "uh, plan for the, uh,",
    "start": "383175",
    "end": "385425"
  },
  {
    "text": "for the first part of the lecture,",
    "start": "385425",
    "end": "387495"
  },
  {
    "text": "and then in the last part I'm going to talk about adversarial attacks.",
    "start": "387495",
    "end": "391585"
  },
  {
    "text": "So, uh, here is our approach,",
    "start": "391585",
    "end": "394395"
  },
  {
    "start": "392000",
    "end": "508000"
  },
  {
    "text": "and this is how we wanna think about it.",
    "start": "394395",
    "end": "396345"
  },
  {
    "text": "So, um, we will use the following thinking.",
    "start": "396345",
    "end": "399285"
  },
  {
    "text": "Um, given two different, uh, inputs,",
    "start": "399285",
    "end": "401610"
  },
  {
    "text": "for example, nodes, uh, graphs, uh,",
    "start": "401610",
    "end": "403710"
  },
  {
    "text": "uh, edges, um, er,",
    "start": "403710",
    "end": "405884"
  },
  {
    "text": "let's assume they are labeled differently,",
    "start": "405885",
    "end": "408165"
  },
  {
    "text": "and we are going to say that, you know, kind of,",
    "start": "408165",
    "end": "409910"
  },
  {
    "text": "the model fails, um,",
    "start": "409910",
    "end": "411650"
  },
  {
    "text": "if it- i- if it is always going to",
    "start": "411650",
    "end": "413720"
  },
  {
    "text": "assign the same embedding to these different inputs,",
    "start": "413720",
    "end": "416750"
  },
  {
    "text": "or these different objects,",
    "start": "416750",
    "end": "417880"
  },
  {
    "text": "and a successful model is going to assign different embeddings to these,",
    "start": "417880",
    "end": "422030"
  },
  {
    "text": "uh, different, uh, types of objects.",
    "start": "422030",
    "end": "424490"
  },
  {
    "text": "Um, so if we focus,",
    "start": "424490",
    "end": "426110"
  },
  {
    "text": "let's say on node-level embeddings, then, you know,",
    "start": "426110",
    "end": "428705"
  },
  {
    "text": "embeddings in a GNN are determined,",
    "start": "428705",
    "end": "431060"
  },
  {
    "text": "uh, by the underlying computation graph.",
    "start": "431060",
    "end": "433570"
  },
  {
    "text": "Right? And in my case,",
    "start": "433570",
    "end": "434690"
  },
  {
    "text": "imagine again I have a graph with two connected components.",
    "start": "434690",
    "end": "438050"
  },
  {
    "text": "I have two vertices, v1 and v2.",
    "start": "438050",
    "end": "440300"
  },
  {
    "text": "Imagine v1 and v2 are labeled with different labels.",
    "start": "440300",
    "end": "443449"
  },
  {
    "text": "V1 is labeled with A,",
    "start": "443450",
    "end": "444815"
  },
  {
    "text": "v2 is labeled with B.",
    "start": "444815",
    "end": "446330"
  },
  {
    "text": "The goal will be to build a graph neural network that is",
    "start": "446330",
    "end": "449479"
  },
  {
    "text": "going to assign different embeddings to node v1,",
    "start": "449480",
    "end": "453065"
  },
  {
    "text": "then to the node v2.",
    "start": "453065",
    "end": "454930"
  },
  {
    "text": "Again, under the assumption that node features are the same,",
    "start": "454930",
    "end": "458910"
  },
  {
    "text": "uh, or, non-discriminative between uh, v1 and v2;",
    "start": "458910",
    "end": "462675"
  },
  {
    "text": "and perhaps what is- you may seem- or you may say",
    "start": "462675",
    "end": "465680"
  },
  {
    "text": "striking or interesting is that the models we have,",
    "start": "465680",
    "end": "468425"
  },
  {
    "text": "uh, um, developed so far,",
    "start": "468425",
    "end": "470690"
  },
  {
    "text": "uh, actually fail to distinguish v1 and v2.",
    "start": "470690",
    "end": "473450"
  },
  {
    "text": "Like, even though we have built",
    "start": "473450",
    "end": "474740"
  },
  {
    "text": "so much super cool machinery that works amazingly well in practice, uh,",
    "start": "474740",
    "end": "478625"
  },
  {
    "text": "and empirically, um, we still cannot",
    "start": "478625",
    "end": "481680"
  },
  {
    "text": "distinguish v1 and v2 in this kind of corner case, uh, example.",
    "start": "481680",
    "end": "485565"
  },
  {
    "text": "So what we are going to do is to understand how can we resolve this?",
    "start": "485565",
    "end": "488915"
  },
  {
    "text": "How can we build a network that- a graph neural network that will be able to distinguish,",
    "start": "488915",
    "end": "493765"
  },
  {
    "text": "uh, basically, uh, v1 and v2.",
    "start": "493765",
    "end": "495900"
  },
  {
    "text": "So meaning assign them different embeddings,",
    "start": "495900",
    "end": "498240"
  },
  {
    "text": "so that then we can assign v1, one label,",
    "start": "498240",
    "end": "501139"
  },
  {
    "text": "and we can assign v2, the other label,",
    "start": "501140",
    "end": "503075"
  },
  {
    "text": "because we cannot assign them different label if they both map into the same point.",
    "start": "503075",
    "end": "507700"
  },
  {
    "text": "So a naive solution to this,",
    "start": "507700",
    "end": "510300"
  },
  {
    "start": "508000",
    "end": "576000"
  },
  {
    "text": "that kind of doesn't work, would be,",
    "start": "510300",
    "end": "512700"
  },
  {
    "text": "uh, to use one hold and- one-hot encoding.",
    "start": "512700",
    "end": "515340"
  },
  {
    "text": "So we would like to say,",
    "start": "515340",
    "end": "516664"
  },
  {
    "text": "Okay, we don't have any features,",
    "start": "516665",
    "end": "518375"
  },
  {
    "text": "but let us- let's assign each node a",
    "start": "518375",
    "end": "521060"
  },
  {
    "text": "different ID and then we can always differentiate different nodes,",
    "start": "521060",
    "end": "525335"
  },
  {
    "text": "um, in- in a graph or different edges or even different graphs.",
    "start": "525335",
    "end": "528620"
  },
  {
    "text": "So if I have, you know,",
    "start": "528620",
    "end": "530120"
  },
  {
    "text": "two- two graphs here,",
    "start": "530120",
    "end": "531529"
  },
  {
    "text": "uh, as we had before,",
    "start": "531530",
    "end": "532970"
  },
  {
    "text": "I could simply assign a one-hot encoding to every node,",
    "start": "532970",
    "end": "536694"
  },
  {
    "text": "um, and now of course,",
    "start": "536695",
    "end": "537950"
  },
  {
    "text": "because nodes now have, uh, features,",
    "start": "537950",
    "end": "540665"
  },
  {
    "text": "it will be- the computational graphs will be distinguishable because,",
    "start": "540665",
    "end": "545019"
  },
  {
    "text": "you know, v1 will have, uh,",
    "start": "545020",
    "end": "547330"
  },
  {
    "text": "two children, one with 0100,",
    "start": "547330",
    "end": "550720"
  },
  {
    "text": "and the other one with, you know, 001;",
    "start": "550720",
    "end": "552730"
  },
  {
    "text": "and v2 is going to have,",
    "start": "552730",
    "end": "554399"
  },
  {
    "text": "um, different, um, types of, um, uh,",
    "start": "554400",
    "end": "557910"
  },
  {
    "text": "neighbors because their- their,",
    "start": "557910",
    "end": "559649"
  },
  {
    "text": "um, one-hot encodings, uh, will be different.",
    "start": "559650",
    "end": "562440"
  },
  {
    "text": "Then, even though with the two,",
    "start": "562440",
    "end": "563820"
  },
  {
    "text": "if they will be the same at the first level,",
    "start": "563820",
    "end": "565755"
  },
  {
    "text": "they won't be the same on the second level.",
    "start": "565755",
    "end": "567440"
  },
  {
    "text": "So basically, computational graphs will be different,",
    "start": "567440",
    "end": "570785"
  },
  {
    "text": "so our GNN will be able to, uh, distinguish them.",
    "start": "570785",
    "end": "575300"
  },
  {
    "text": "Um, what are the issues with this?",
    "start": "575300",
    "end": "577920"
  },
  {
    "start": "576000",
    "end": "669000"
  },
  {
    "text": "The- there are two very important issues.",
    "start": "577920",
    "end": "580500"
  },
  {
    "text": "First is that this approach is not scalable;",
    "start": "580500",
    "end": "582810"
  },
  {
    "text": "meaning we need an order N feature dimensions",
    "start": "582810",
    "end": "586169"
  },
  {
    "text": "where N- N is the number of nodes to be able to encode, right?",
    "start": "586169",
    "end": "589150"
  },
  {
    "text": "Basically, we need a separate feature for every individual node,",
    "start": "589150",
    "end": "592705"
  },
  {
    "text": "and if, you know,",
    "start": "592705",
    "end": "593740"
  },
  {
    "text": "if we have a 10,000 or a 100,000 or a million node network,",
    "start": "593740",
    "end": "597475"
  },
  {
    "text": "then every node has now a million features,",
    "start": "597475",
    "end": "599800"
  },
  {
    "text": "basically a one-hot encoding of its ID.",
    "start": "599800",
    "end": "602695"
  },
  {
    "text": "Uh, and then the second problem is that this is in- this is not inductive;",
    "start": "602695",
    "end": "606550"
  },
  {
    "text": "meaning it won't generalize to new- new nodes or",
    "start": "606550",
    "end": "609490"
  },
  {
    "text": "new graphs because these one-hot encodings are kind of arbitrary,",
    "start": "609490",
    "end": "613620"
  },
  {
    "text": "node ordering is arbitrary,",
    "start": "613620",
    "end": "615415"
  },
  {
    "text": "so the map- the network,",
    "start": "615415",
    "end": "617290"
  },
  {
    "text": "it could basically learn according to that node ordering,",
    "start": "617290",
    "end": "620579"
  },
  {
    "text": "and then if we, um,",
    "start": "620580",
    "end": "621835"
  },
  {
    "text": "try to transfer this to a new graph,",
    "start": "621835",
    "end": "623930"
  },
  {
    "text": "or if a new node appears in the network,",
    "start": "623930",
    "end": "626630"
  },
  {
    "text": "this won't- this won't work, right.",
    "start": "626630",
    "end": "628700"
  },
  {
    "text": "If a new node appears we'll have to expand- extend the feature dimensionality because",
    "start": "628700",
    "end": "633020"
  },
  {
    "text": "we wanna encode- use one-hot encoding for that node as well and we'd have to retrain.",
    "start": "633020",
    "end": "637655"
  },
  {
    "text": "Uh, or if we wanna transfer to a new graph,",
    "start": "637655",
    "end": "640055"
  },
  {
    "text": "we have no guarantees because, uh,",
    "start": "640055",
    "end": "642820"
  },
  {
    "text": "the one-hot encoding and node IDs are kind of arbitrary,",
    "start": "642820",
    "end": "646310"
  },
  {
    "text": "so it won't, uh, it won't generalize.",
    "start": "646310",
    "end": "648980"
  },
  {
    "text": "So this is why, you know,",
    "start": "648980",
    "end": "650540"
  },
  {
    "text": "this is a bad- bad idea,",
    "start": "650540",
    "end": "652204"
  },
  {
    "text": "but, ah, this idea kind of to enrich,",
    "start": "652205",
    "end": "654830"
  },
  {
    "text": "uh, the nodes so that we can, um,",
    "start": "654830",
    "end": "657470"
  },
  {
    "text": "differentiate different computational graphs is a good idea.",
    "start": "657470",
    "end": "660725"
  },
  {
    "text": "Just one-hot encoding, uh,",
    "start": "660725",
    "end": "662464"
  },
  {
    "text": "doesn't work in this case.",
    "start": "662465",
    "end": "664560"
  }
]
[
  {
    "start": "0",
    "end": "5270"
  },
  {
    "text": "I'm super excited about\nthe lecture today. So before the course,\nI was figuring out",
    "start": "5270",
    "end": "10277"
  },
  {
    "text": "how the lecture materials\nwere going to look and preparing slides. And some of the\nslides in this lecture is actually what I started\nwith, because I was just",
    "start": "10277",
    "end": "17295"
  },
  {
    "text": "so excited to talk\nabout these topics. I think that they're extremely\nmathematically satisfying",
    "start": "17295",
    "end": "23150"
  },
  {
    "text": "and visually satisfying. So hopefully you\nenjoy it as well.",
    "start": "23150",
    "end": "28151"
  },
  {
    "text": "The other thing I want\nto say before we jump in is I think these topics, when\nI was first learning them,",
    "start": "28152",
    "end": "33960"
  },
  {
    "text": "it took me a few times\nthrough before it really clicked in my mind. Maybe that's just because they\nweren't presented as beautifully",
    "start": "33960",
    "end": "41480"
  },
  {
    "text": "as I'm about to present\nthem to you now. So maybe that won't\nbe an issue for you. But I think some\nof these, you just",
    "start": "41480",
    "end": "47120"
  },
  {
    "text": "have to sit with them\nfor a little bit. So maybe watch this lecture,\ngo back to the textbook,",
    "start": "47120",
    "end": "52740"
  },
  {
    "text": "maybe watch this lecture again. It just might take a few times\nbefore they really click.",
    "start": "52740",
    "end": "58600"
  },
  {
    "text": "OK. But with that, let's jump in. So over the last week or\ndo, week and a half or so,",
    "start": "58600",
    "end": "64125"
  },
  {
    "text": "we've been talking about the\ntask of falsification, where we're just trying to find\nfailures of a system, maybe",
    "start": "64125",
    "end": "69210"
  },
  {
    "text": "the most likely failure,\nmaybe any failure we can find. But sometimes maybe\nwe want more than just",
    "start": "69210",
    "end": "76604"
  },
  {
    "text": "one most likely failure. We want to know what is\nthe full distribution over possible failures\nthat we might observe?",
    "start": "76605",
    "end": "82885"
  },
  {
    "text": "So today, we're going\nto talk about how we can take that one step\nfurther and try to sample from the full distribution.",
    "start": "82885",
    "end": "89080"
  },
  {
    "text": "And as you'll probably see,\nthe process for doing that is maybe a little bit more\ncomplicated, a little bit more",
    "start": "89080",
    "end": "94290"
  },
  {
    "text": "difficult, but you\nget this extra reward of now having the full\ndistribution over failures",
    "start": "94290",
    "end": "99450"
  },
  {
    "text": "that you might see. OK. So let's talk about\nmathematically, what is actually the\nfailure distribution.",
    "start": "99450",
    "end": "107310"
  },
  {
    "text": "So in previous lectures,\nwe've talked about this thing that we're calling the\ntrajectory distribution, which",
    "start": "107310",
    "end": "112980"
  },
  {
    "text": "given a trajectory, tells us\nhow likely that trajectory is.",
    "start": "112980",
    "end": "118530"
  },
  {
    "text": "And so this is basically\nthe distribution over all possible\ntrajectories we might observe.",
    "start": "118530",
    "end": "124500"
  },
  {
    "text": "And then we're just\ngoing to extend this to the failure\ndistribution by creating a conditional probability.",
    "start": "124500",
    "end": "129879"
  },
  {
    "text": "So we're going to say that\nthe failure distribution is this probability conditioned on\nthe fact that tau is a failure.",
    "start": "129880",
    "end": "137740"
  },
  {
    "text": "That our trajectory\nis a failure. So if you remember this\ntau 0 in psi notation, it just means that\ntau is a failure.",
    "start": "137740",
    "end": "146610"
  },
  {
    "text": "And it turns out that we can\nactually write this distribution out like this. We can expand it out.",
    "start": "146610",
    "end": "152580"
  },
  {
    "text": "So let's just focus on the\nnumerator really quick. So what's going on here is this\none with the curly brackets.",
    "start": "152580",
    "end": "159340"
  },
  {
    "text": "That's the notation that we use\nin this course for the indicator function. So all this function is doing\nis saying if tau 0 and psi,",
    "start": "159340",
    "end": "167170"
  },
  {
    "text": "so if tau is a failure, this\nfunction returns the value of 1. If it is a success,\nit's not a failure,",
    "start": "167170",
    "end": "173349"
  },
  {
    "text": "then this function will\nreturn a value of 0. And then this p of tau here\nis just our nominal trajectory",
    "start": "173350",
    "end": "179710"
  },
  {
    "text": "distribution. So with this\nnumerator is basically it will return p of\ntau, if our trajectory",
    "start": "179710",
    "end": "186490"
  },
  {
    "text": "is a failure because\nthis will evaluate to 1. And if our trajectory\nis not a failure, this numerator will be 0.",
    "start": "186490",
    "end": "193120"
  },
  {
    "text": "And this is really\njust what's going on to get the failure distribution. But there's one extra\nthing we need to add in,",
    "start": "193120",
    "end": "199280"
  },
  {
    "text": "which is this denominator here. Because this will not\nintegrate to 1 because now",
    "start": "199280",
    "end": "204550"
  },
  {
    "text": "we're assigning\nsome trajectories in our full trajectory\ndistribution to a probability of 0. So it's not going to\nintegrate to 1 anymore.",
    "start": "204550",
    "end": "211100"
  },
  {
    "text": "And so we actually need\nto divide by this integral in order to create a valid\nprobability distribution.",
    "start": "211100",
    "end": "217180"
  },
  {
    "text": "So we're going to integrate this\nover all possible trajectories to get the failure distribution.",
    "start": "217180",
    "end": "223130"
  },
  {
    "text": " So let's visually see what\nall of this looks like.",
    "start": "223130",
    "end": "229820"
  },
  {
    "text": "And we're going to use\na very simple example. And so those of you who\nhave started project 1",
    "start": "229820",
    "end": "235340"
  },
  {
    "text": "will recognize this. This is actually\nthe example that we use for the small\nsystem in project 1.",
    "start": "235340",
    "end": "241250"
  },
  {
    "text": "It's a super simple system\nwhere trajectories basically just consist of one state. So just sample an initial\nstate, and that's it",
    "start": "241250",
    "end": "247280"
  },
  {
    "text": "for the trajectory. And this initial state, so\nour tau is just this state.",
    "start": "247280",
    "end": "252540"
  },
  {
    "text": "It's sampled from a\nGaussian distribution that looks like this. So our nominal\ntrajectory distribution",
    "start": "252540",
    "end": "257750"
  },
  {
    "text": "is just this white distribution\nhere that we call p of tau. And now let's look at what the\ncomponents of this equation",
    "start": "257750",
    "end": "264710"
  },
  {
    "text": "look like with respect\nto this distribution. So we're going to say\nthat our trajectory is a failure, if that state that we\nsample is less than some value.",
    "start": "264710",
    "end": "273810"
  },
  {
    "text": "So for example,\nminus 1 in this case. So anything to the left here is\na failure, anything to the right",
    "start": "273810",
    "end": "280070"
  },
  {
    "text": "here is not a failure. And now let's look at just what\nthis numerator, this numerator",
    "start": "280070",
    "end": "285620"
  },
  {
    "text": "part here looks\nlike with respect to this particular system. So this numerator,\nagain, we said",
    "start": "285620",
    "end": "291710"
  },
  {
    "text": "it just evaluates to the\nnominal trajectory distribution when the trajectory\nis a failure.",
    "start": "291710",
    "end": "297120"
  },
  {
    "text": "And then it evaluates\nto 0 otherwise. So that's exactly\nwhat's happening here. This red line shows\nthat numerator",
    "start": "297120",
    "end": "304280"
  },
  {
    "text": "where we're getting\nthe same exact value as the nominal\ntrajectory distribution for the trajectories\nthat were a failure.",
    "start": "304280",
    "end": "310350"
  },
  {
    "text": "The ones that were\nless than minus 1. And then we're getting a value\nof 0 for all other trajectories.",
    "start": "310350",
    "end": "317590"
  },
  {
    "text": "OK. And then for the\ndenominator, this is the integral over all\npossible trajectories",
    "start": "317590",
    "end": "323630"
  },
  {
    "text": "of this value. So we know from calculus\nthat integral is just going to be the area\nunder this curve.",
    "start": "323630",
    "end": "330500"
  },
  {
    "text": "And this is just\na constant value. So the way that we can\nthink of this as we",
    "start": "330500",
    "end": "335540"
  },
  {
    "text": "take this distribution\nhere, and we divide it by this constant value. That area is not going\nto change based on tau.",
    "start": "335540",
    "end": "342270"
  },
  {
    "text": "That area is always the same\nbecause we're computing it over all possible tau. And so all it's really going\nto do is scale this value,",
    "start": "342270",
    "end": "350410"
  },
  {
    "text": "so that the area under the\ncurve now is equal to 1. So this is now valid\nprobability distribution.",
    "start": "350410",
    "end": "357720"
  },
  {
    "text": "So what I'm trying to\nsay here is basically this numerator\nhere is really what gives us the actual shape\nof the failure distribution.",
    "start": "357720",
    "end": "364720"
  },
  {
    "text": "So we had this shape here. And then this\ndenominator is just what we compute to scale\nthat shape, such",
    "start": "364720",
    "end": "371190"
  },
  {
    "text": "that we get a distribution\nthat will integrate to 1. I'll pause for\nquestions on that.",
    "start": "371190",
    "end": "377740"
  },
  {
    "text": "Any questions? Oh. Yeah. Is each trajectory like a dot?",
    "start": "377740",
    "end": "384789"
  },
  {
    "text": "Yeah. So a the question is, is\neach trajectory like a dot? Yeah. So if you've done\nthe project already, you'll remember every single\ntrajectory is just one",
    "start": "384790",
    "end": "391860"
  },
  {
    "text": "sample from this distribution. So just one dot here. And then basically, this\ndistribution tells you, OK.",
    "start": "391860",
    "end": "397660"
  },
  {
    "text": "If I got this trajectory,\nwhat is the probability of that trajectory under\nthe failure distribution?",
    "start": "397660",
    "end": "404290"
  },
  {
    "text": " OK.",
    "start": "404290",
    "end": "410142"
  },
  {
    "text": "So yeah. The top one gives us the\nshape and the bottom one gives us this scaling\nfactor that we call the normalizing constant.",
    "start": "410142",
    "end": "416590"
  },
  {
    "text": "But it's just a constant. It just gives us that\narea under the curve.",
    "start": "416590",
    "end": "421915"
  },
  {
    "text": "OK. So this is our\nfailure distribution. And if we could\ncompute this, then we would know the\nfailure distribution for all of our systems.",
    "start": "421915",
    "end": "428590"
  },
  {
    "text": "But the main problem here is\nthat typically this denominator, this integral part here is\nvery difficult to compute.",
    "start": "428590",
    "end": "435490"
  },
  {
    "text": "Sometimes it's even\nimpossible to compute. So we're bummed. We can't actually often compute\nan analytical expression",
    "start": "435490",
    "end": "442590"
  },
  {
    "text": "for this failure distribution. But one thing that is nice is\nwe can compute this numerator.",
    "start": "442590",
    "end": "448569"
  },
  {
    "text": "So you might remember\na similar theme we had earlier in\nthe class when we were talking about\nBayesian estimation, where we had a similar idea.",
    "start": "448570",
    "end": "455070"
  },
  {
    "text": "Given a particular\ntrajectory, we know how to compute the\nnumerator of this equation. Because to compute\nthis first term here,",
    "start": "455070",
    "end": "462630"
  },
  {
    "text": "we just need to\ncheck whether or not that trajectory is a failure. And if it is a failure, we\nreturn one, and if it's not,",
    "start": "462630",
    "end": "468120"
  },
  {
    "text": "we return zero. And to compute\nthis term, we just need to evaluate the\nlikelihood of that trajectory",
    "start": "468120",
    "end": "473360"
  },
  {
    "text": "under the nominal\ntrajectory distribution. And we talked in the\nprevious chapter, when we were talking about likelihood\nobjectives and things like that,",
    "start": "473360",
    "end": "479900"
  },
  {
    "text": "we already talked\nabout how to compute the probability of a particular\ntrajectory occurring.",
    "start": "479900",
    "end": "485960"
  },
  {
    "text": "So we can compute\nthis numerator. Is the key idea here. And if you remember from the\nprevious slide I was just",
    "start": "485960",
    "end": "493670"
  },
  {
    "text": "showing, the numerator\nis really what gives us that shape of the distribution. So it turns out just\nknowing this numerator is",
    "start": "493670",
    "end": "499280"
  },
  {
    "text": "enough to do interesting\nthings as we'll see. And what we call this typically\nis an unnormalized probability",
    "start": "499280",
    "end": "506360"
  },
  {
    "text": "density. So it gives us the right shape\nfor our probability density. It just doesn't integrate to 1. So it's not a valid\nprobability distribution,",
    "start": "506360",
    "end": "513719"
  },
  {
    "text": "but it can still tell us things. So in this class when we talk\nabout unnormalized probability",
    "start": "513720",
    "end": "518840"
  },
  {
    "text": "densities, we're often going\nto talk about or denote them with this bar over the variable.",
    "start": "518840",
    "end": "525420"
  },
  {
    "text": "So this is just showing us the\nunnormalized failure probability density.",
    "start": "525420",
    "end": "531980"
  },
  {
    "text": "And it's equal to\nthat numerator there. And what's really\ncool about this",
    "start": "531980",
    "end": "537079"
  },
  {
    "text": "is that there are\nalgorithms that actually allow us to draw samples from\nan unnormalized probability",
    "start": "537080",
    "end": "543740"
  },
  {
    "text": "density. So we already talked\nabout this a little bit previously when we were talking\nabout the Bayesian estimation.",
    "start": "543740",
    "end": "548970"
  },
  {
    "text": "And I was like there's\nthis magic that happens. And you can take this\nunnormalized probability density. And you can get all\nof these samples.",
    "start": "548970",
    "end": "554730"
  },
  {
    "text": "So we're going to talk a\nlittle bit today about what that actual magic really is.",
    "start": "554730",
    "end": "559759"
  },
  {
    "text": "In this way-- so we can't\nactually maybe explicitly write down the\nfailure distribution. But what we can do\nthen is implicitly",
    "start": "559760",
    "end": "566630"
  },
  {
    "text": "represent it by just\ndrawing a bunch of samples from that distribution. So for example,\nin the grid world,",
    "start": "566630",
    "end": "573140"
  },
  {
    "text": "we can sample from its\nfailure distribution, get a bunch of\ndifferent trajectories that are part of\nthat distribution,",
    "start": "573140",
    "end": "579149"
  },
  {
    "text": "and just plot them all together. And this gives us\nan idea of what the distribution over failures\nfor the grid world system",
    "start": "579150",
    "end": "585770"
  },
  {
    "text": "looks like. Yeah. Do you still have your question. Yeah. So I guess, maybe I'm just\nnot understanding the--",
    "start": "585770",
    "end": "596509"
  },
  {
    "text": "The curly braces? Yeah. I guess this is\nsaying the likelihood",
    "start": "596510",
    "end": "602240"
  },
  {
    "text": "that a failure happens within\nthe probability of trajectories.",
    "start": "602240",
    "end": "607770"
  },
  {
    "text": "Is that kind of-- it's the\nsame or maybe I was just-- It's like you got a\ntrajectory and you",
    "start": "607770",
    "end": "614210"
  },
  {
    "text": "want to know what\nis its likelihood under the distribution\nover failure. So let's say maybe you\nfound a failure trajectory.",
    "start": "614210",
    "end": "621192"
  },
  {
    "text": "And you're like, compared to the\nwhole distribution over failures that could possibly happen,\nwhat is the likelihood that I",
    "start": "621192",
    "end": "626275"
  },
  {
    "text": "got this failure? That's kind of what it's\nsupposed to be describing. [INAUDIBLE] This side?",
    "start": "626275",
    "end": "632000"
  },
  {
    "text": "Yeah, well, so these\nare equivalent. So this is just another way of\nwriting it that's easier for us",
    "start": "632000",
    "end": "637040"
  },
  {
    "text": "to work with. So what this\ndistribution is saying is what I was just describing. It turns out, we can write\nthat in an unnormalized way",
    "start": "637040",
    "end": "645160"
  },
  {
    "text": "as the nominal probability\nof that trajectory occurring times this indicator\nthat just gives it--",
    "start": "645160",
    "end": "651990"
  },
  {
    "text": "will return 1 if it is a\nfailure, and 0 otherwise. Because if we\nobserve a trajectory, and that's not a\nfailure, and we're like,",
    "start": "651990",
    "end": "657580"
  },
  {
    "text": "what is the likelihood under\nthe failure distribution? Well, that's 0 because we're\ntrying to sample failure. So there is no likelihood.",
    "start": "657580",
    "end": "663120"
  },
  {
    "text": "Yep.  What other questions\ndo you have on this?",
    "start": "663120",
    "end": "668170"
  },
  {
    "text": "Yeah. So this doesn't take into\naccount robustness, right, and the idea that a\nfailure is a failure and there's a hard cut-off\nbetween not failure and failure.",
    "start": "668170",
    "end": "675577"
  },
  {
    "text": "Yeah, so the question\nwas this doesn't take into account robustness? You've alluded to\nsomething that's",
    "start": "675577",
    "end": "680760"
  },
  {
    "text": "going to happen at the\nvery end of lecture. We'll take care of that.",
    "start": "680760",
    "end": "686340"
  },
  {
    "text": "Anything else? Yeah. So why is it hard to\ncalculate that denominator,",
    "start": "686340",
    "end": "694050"
  },
  {
    "text": "like the normalizing constant? Is it just because\nit's really hard to know all the different\nways it can fail?",
    "start": "694050",
    "end": "699860"
  },
  {
    "text": "Yeah, that's pretty\nmuch exactly right. And it turns out-- so denominator, it's an integral\nover all possible trajectories.",
    "start": "699860",
    "end": "705562"
  },
  {
    "text": "So we need to now\ntake into account every single possible trajectory\nto compute that integral, which is generally not easy to do.",
    "start": "705562",
    "end": "712660"
  },
  {
    "text": "And in fact, we're\ngoing to find out next week that's\nactually equivalent-- computing that integral\nis equivalent to computing",
    "start": "712660",
    "end": "717923"
  },
  {
    "text": "the probability of failure,\nwhich is difficult to do. And we're going to talk about\na whole bunch of methods for actually doing that\nestimate next week.",
    "start": "717923",
    "end": "726709"
  },
  {
    "text": "So that's setting\nup the problem. And now, today, we're going\nto talk about different ways to actually go about\nsampling from drawing samples",
    "start": "726710",
    "end": "733990"
  },
  {
    "text": "from a density\nthat we don't have the normalization constant for. So one of these techniques\nis called rejection sampling.",
    "start": "733990",
    "end": "741610"
  },
  {
    "text": "Another technique is called\nMarkov Chain Monte Carlo. And then the final thing\nI'll talk about is just like,",
    "start": "741610",
    "end": "747252"
  },
  {
    "text": "throughout this lecture, I'm\ngoing to mostly just show this 1D Gaussian system. It's kind of silly. We already know a lot of things\nabout Gaussian distributions.",
    "start": "747252",
    "end": "754580"
  },
  {
    "text": "We could just like analytically\ncompute the failure distribution for this one if we want to. So This is all just kind of a\nway to get you some intuition.",
    "start": "754580",
    "end": "762170"
  },
  {
    "text": "But these things\nreally do scale up to things that are more than\njust this one dimensional Gaussian. And we can actually scale\nthem up to, for example,",
    "start": "762170",
    "end": "768200"
  },
  {
    "text": "the pendulum system, which has\n50 dimensions, 100 dimensions. And it's pretty cool to see the\nway that these things scale up.",
    "start": "768200",
    "end": "774590"
  },
  {
    "text": "So towards the end, we'll talk\nabout how to actually move from our 1D Gaussian to\nthese bigger systems.",
    "start": "774590",
    "end": "781389"
  },
  {
    "text": "But, OK, let's dive\ninto rejection sampling. And we're going to\nthink about rejection",
    "start": "781390",
    "end": "786550"
  },
  {
    "text": "sampling by first using\nthis analogy of a dartboard. So let's imagine that we\nhave this kind of rectangular",
    "start": "786550",
    "end": "793420"
  },
  {
    "text": "dartboard here. So it might not look like\nthe dartboard you're used to. But it's basically\na big rectangle that we can throw darts at,\nand they'll stick on the board.",
    "start": "793420",
    "end": "801540"
  },
  {
    "text": "And the first thing\nthat we're going to do is draw the shape of the\ntarget unnormalized density",
    "start": "801540",
    "end": "807490"
  },
  {
    "text": "that we want to sample\nfrom on this dartboard. So this is just the shape of\nthe density, which you remember, we can compute with just\nthat numerator there.",
    "start": "807490",
    "end": "814490"
  },
  {
    "text": "And we're just going to\ndraw it on the dartboard. And then what we're\ngoing to do is we're just going to throw\ndarts uniformly at this board.",
    "start": "814490",
    "end": "821520"
  },
  {
    "text": "So we're just going to assume\nthat somehow we can actually just kind of uniformly\nthrow a dart, and it'll end up in some\nrandom spot on that board.",
    "start": "821520",
    "end": "830569"
  },
  {
    "text": "Then, the next thing that we\ndo, is we look at all the darts that we just threw,\nand we separate the ones that landed\nabove this target density",
    "start": "830570",
    "end": "839420"
  },
  {
    "text": "that we drew on the\nboard from the ones that landed below this density. And then here comes\nthe rejection part.",
    "start": "839420",
    "end": "846360"
  },
  {
    "text": "We're going to reject all\nof the darts that landed above the target density.",
    "start": "846360",
    "end": "852470"
  },
  {
    "text": "And then, it turns\nout, if we just take the value on this axis\nfor all of those samples. So basically, we drop\nall of those samples",
    "start": "852470",
    "end": "859370"
  },
  {
    "text": "straight down to the\nbottom of the dartboard. Then, it turns out now these\nsamples are actually distributed",
    "start": "859370",
    "end": "866090"
  },
  {
    "text": "according to this density. Kind of insane. And--",
    "start": "866090",
    "end": "871190"
  },
  {
    "text": "Can you do that one more time? [LAUGHTER] And there will be more. OK. Yeah. It'll play a few more times.",
    "start": "871190",
    "end": "876900"
  },
  {
    "text": "The next part is even better. So this is hard to see that\nthese are really distributed",
    "start": "876900",
    "end": "883680"
  },
  {
    "text": "according to this distribution. But one thing that we could do\nto convince ourselves of this is could imagine just\nbinning up this axis here,",
    "start": "883680",
    "end": "891190"
  },
  {
    "text": "and then taking all of the\nsamples that landed in each bin and stacking them on\ntop of each other.",
    "start": "891190",
    "end": "896410"
  },
  {
    "text": "And so if we do that,\nthen, you can see why I started with these slides.",
    "start": "896410",
    "end": "901570"
  },
  {
    "text": "And so if we do that, you\nsee that they actually look like they're kind\nof distributed according to this target density.",
    "start": "901570",
    "end": "907868"
  },
  {
    "text": "And then, the other\nthing you could imagine is the more darts we throw. The more we do this, the better\napproximation that we'll get.",
    "start": "907868",
    "end": "913660"
  },
  {
    "text": "So if we continue to increase\nthe amount of darts that we use, we'll get closer and closer\nto approximating this target",
    "start": "913660",
    "end": "920280"
  },
  {
    "text": "density that we have. So that was kind of just\nlike a normal distribution.",
    "start": "920280",
    "end": "926640"
  },
  {
    "text": "But we can use this to sample\nfrom any arbitrarily shaped weird density that we want.",
    "start": "926640",
    "end": "931915"
  },
  {
    "text": "So let's say that maybe we had\na density that looked like this. We can do the same\nthing where we throw all of the darts at the board.",
    "start": "931915",
    "end": "937630"
  },
  {
    "text": "We separate out the ones\nthat lie above and below it. We reject the ones that are\nabove it, drop everything down.",
    "start": "937630",
    "end": "944110"
  },
  {
    "text": "And these are actually\nnow distributed according to this\nparticular distribution.",
    "start": "944110",
    "end": "949649"
  },
  {
    "text": "So we can do the same thing\nhere where we bin everything up. And then, there it is.",
    "start": "949650",
    "end": "956610"
  },
  {
    "text": "OK, pretty cool.  So, OK. That was kind of an\nintuitive explanation",
    "start": "956610",
    "end": "964387"
  },
  {
    "text": "for what's going on there. You can visually see\nwhat's happening. But ultimately, we want to\nspecify all of this in math",
    "start": "964387",
    "end": "970500"
  },
  {
    "text": "so that we can use this\nalgorithm a little bit more generally than what we just did. So I'm going to slowly introduce\nsome mathematical notation",
    "start": "970500",
    "end": "978480"
  },
  {
    "text": "to what we just did. So let's go back to this\nnormal looking distribution because it's a little bit easier\nto just see and understand.",
    "start": "978480",
    "end": "986670"
  },
  {
    "text": "And we're going to just\nfirst assign some dimensions to our dartboard. So we're going to say that\nthis axis of the dartboard",
    "start": "986670",
    "end": "993880"
  },
  {
    "text": "is the variable tau. So this is the trajectories. These are the samples that\nwe actually want to draw.",
    "start": "993880",
    "end": "999345"
  },
  {
    "text": "And we'll say,\nfor example, maybe it goes between\nnegative 3 and 3. And then this dimension of\nthe dartboard is the height.",
    "start": "999345",
    "end": "1007300"
  },
  {
    "text": "So it's like the on the board. So we're going to call it H. And\nmaybe it goes between 0 and 0.6.",
    "start": "1007300",
    "end": "1015630"
  },
  {
    "text": "So, now, let's\nwrite out the steps that we just took in order\nto actually draw samples",
    "start": "1015630",
    "end": "1021540"
  },
  {
    "text": "from this distribution. So the first thing\nthat we did was we threw darts uniformly\nat the board.",
    "start": "1021540",
    "end": "1028079"
  },
  {
    "text": "And so you can imagine\nif you're actually doing this with a dartboard,\nyou would throw a dart. And then, I don't know. Some really talented person\ncould actually uniformly",
    "start": "1028079",
    "end": "1035609"
  },
  {
    "text": "throw darts at a board. But we're going to\nactually break this up into a two-step process. So it's going to mimic\nthe same thing that",
    "start": "1035609",
    "end": "1042480"
  },
  {
    "text": "would happen if you were\nable to uniformly throw darts at a board. And this might seem kind\nof weird or silly at first.",
    "start": "1042480",
    "end": "1048207"
  },
  {
    "text": "But the reason is\nbecause we're trying to work towards this\ngeneral algorithm that we can write\ndown mathematically.",
    "start": "1048207",
    "end": "1055169"
  },
  {
    "text": "So that's why we're going to\nbreak it up into a process that might seem a little strange.",
    "start": "1055170",
    "end": "1060380"
  },
  {
    "text": "But basically, the\nfirst thing that we did, or the first thing\nthat we might do is sample from a value along\nthis axis of the dartboard.",
    "start": "1060380",
    "end": "1067890"
  },
  {
    "text": "So we'll sample\na value uniformly between negative 3 and 3.",
    "start": "1067890",
    "end": "1073429"
  },
  {
    "text": "And then once we\npick a value here, we need to pick a height\nuniformly on the dartboard.",
    "start": "1073430",
    "end": "1079980"
  },
  {
    "text": "So then, we just sample a value\nuniformly between 0 and 0.6 to get the height of the dart.",
    "start": "1079980",
    "end": "1086870"
  },
  {
    "text": "And if we repeat this process\nfor a bunch of darts-- so maybe for the second\ndart, we do the same thing,",
    "start": "1086870",
    "end": "1092150"
  },
  {
    "text": "where we sample a value\nbetween negative 3 and three. And then we, again, sample\na height between 0 and 0.6.",
    "start": "1092150",
    "end": "1100160"
  },
  {
    "text": "This is actually an equivalent\nprocess to just throwing darts uniformly at the board. So we just kind of\nbroken it up into two",
    "start": "1100160",
    "end": "1106600"
  },
  {
    "text": "steps to obtain the position\nfor every single dart. So then, we repeat that\na whole bunch of times.",
    "start": "1106600",
    "end": "1112630"
  },
  {
    "text": "And we get our darts\nuniformly distributed throughout the board. And then, we rejected any darts\nthat lie above the blue density.",
    "start": "1112630",
    "end": "1121634"
  },
  {
    "text": " And then, we moved all\nthe remaining darts",
    "start": "1121635",
    "end": "1127210"
  },
  {
    "text": "to the bottom of the board. Let's go one more time\nthrough that process",
    "start": "1127210",
    "end": "1133360"
  },
  {
    "text": "and add a little bit more math. So now, what we're\ngoing to do is we're actually going to give\na name to this blue density",
    "start": "1133360",
    "end": "1140410"
  },
  {
    "text": "that we were trying\nto sample from. And we're going to\ncall it p bar of tau. So you can imagine--",
    "start": "1140410",
    "end": "1146320"
  },
  {
    "text": "or as I mentioned, when we talk\nabout unnormalized densities, we typically use this bar.",
    "start": "1146320",
    "end": "1151370"
  },
  {
    "text": "So that's just the unnormalized\ndensity we want to sample from. And then the first\nthing that we want to do",
    "start": "1151370",
    "end": "1156640"
  },
  {
    "text": "is sample a value uniformly\nbetween negative 3 and 3. So along this axis of the board.",
    "start": "1156640",
    "end": "1162320"
  },
  {
    "text": "And to do that, we're\njust going to specify the actual distribution that\nwe're sampling from here. So we're going to say that tau\ncomes from some distribution",
    "start": "1162320",
    "end": "1170480"
  },
  {
    "text": "that we call q of tau. And in this case, if\nwe're sampling uniformly along the bottom of the\nboard, that q of tau",
    "start": "1170480",
    "end": "1177019"
  },
  {
    "text": "is a uniform distribution\nbetween negative 3 and 3.",
    "start": "1177020",
    "end": "1182210"
  },
  {
    "text": "But this is the\nexact same process that we were doing before. So now, we're just defining the\ndistribution that this actually",
    "start": "1182210",
    "end": "1187215"
  },
  {
    "text": "comes from and drawing a\nsample from this distribution. ",
    "start": "1187215",
    "end": "1193350"
  },
  {
    "text": "And then, the next\nthing that we did was sample a value uniformly\nbetween the bottom of the board",
    "start": "1193350",
    "end": "1199190"
  },
  {
    "text": "and the height of the board. And the way we're going\nto write down this process might look a little\nbit strange at first.",
    "start": "1199190",
    "end": "1205148"
  },
  {
    "text": "But all that's going\non here is we're saying that we're\ngoing to sample h, or h is going to be equal to\nsome value c times q of tau.",
    "start": "1205148",
    "end": "1214280"
  },
  {
    "text": "And c is just a\nconstant that we pick. So we're going to pick c\nsuch that it brings q of tau",
    "start": "1214280",
    "end": "1220429"
  },
  {
    "text": "up to the height of the board. So c times q of tau gives us\nthe height of the dartboard.",
    "start": "1220430",
    "end": "1227780"
  },
  {
    "text": "And then we're going to\nmultiply it by this value that we call r, which\nis just some sample from a uniform distribution\nbetween 0 and 1.",
    "start": "1227780",
    "end": "1234900"
  },
  {
    "text": "So we're taking the\nheight of the dartboard. We're multiplying it by\nsome number between 0 and 1. And that's going to give\nus the y position or the h",
    "start": "1234900",
    "end": "1242570"
  },
  {
    "text": "position of our dart. So it's still the\nsame exact process. We've just added in\nsome more variables",
    "start": "1242570",
    "end": "1247880"
  },
  {
    "text": "to describe what's going on. Yeah? We didn't specify q [INAUDIBLE]? Does that mean that this\nh then depends on tau,",
    "start": "1247880",
    "end": "1255094"
  },
  {
    "text": "which was how we first sampled? Yeah. So the question was,\ndoes h depend on tau? I mean, for this q of tau, no,\nbecause q of tau is uniform.",
    "start": "1255094",
    "end": "1265315"
  },
  {
    "text": "In a second, we're going\nto talk about how maybe we don't want to use a uniform\ndistribution for q of tau. And then h is actually\ngoing to be sampled from--",
    "start": "1265315",
    "end": "1272750"
  },
  {
    "text": "let's say, the distribution\nwas like this or something, h would be sampled from the\npoint on the distribution",
    "start": "1272750",
    "end": "1277770"
  },
  {
    "text": "and the bottom. So it's like, you get a\nsample from that distribution, and then you sample\nuniformly up to its height.",
    "start": "1277770",
    "end": "1285180"
  },
  {
    "text": "Yeah. Yeah. This procedure makes sense. But can you go\nover more carefully",
    "start": "1285180",
    "end": "1290880"
  },
  {
    "text": "why we can't just sample\nthe two axes as independent?",
    "start": "1290880",
    "end": "1296461"
  },
  {
    "text": "Why we independently sample two\nvalues, x and y, or tau and h.",
    "start": "1296461",
    "end": "1301480"
  },
  {
    "text": "Why we can't do that? Yeah. That kind of is\nwhat we're doing. So the first time we're\nsampling tau, and then",
    "start": "1301480",
    "end": "1307470"
  },
  {
    "text": "kind of regardless of tau. Or now, we're like\nlooking at that tau. You're saying like why\ndoes this depend on tau?",
    "start": "1307470",
    "end": "1313488"
  },
  {
    "text": "Yeah. I think it'll become\nmore clear in a second. OK. Yeah, so, I mean,\nfor now, it really",
    "start": "1313488",
    "end": "1319500"
  },
  {
    "text": "doesn't because\nthe q of tau is-- the height of the board\nis the same at every tau. But imagine that the\nheight of the board",
    "start": "1319500",
    "end": "1326160"
  },
  {
    "text": "was not the same at every tau. Maybe the board was like shaped\nlike this or something, which we're going to see in a second. Then we want to sample\nbetween the bottom",
    "start": "1326160",
    "end": "1333180"
  },
  {
    "text": "and the height of the board. And that height would change\ndepending on where tau is. ",
    "start": "1333180",
    "end": "1340090"
  },
  {
    "text": "I think it will be\nvisualized in a second. I think it'll make more sense.",
    "start": "1340090",
    "end": "1345130"
  },
  {
    "text": "So, then, the next\nthing that we do, so we now have sampled all of\nour darts using this process.",
    "start": "1345130",
    "end": "1350740"
  },
  {
    "text": "And then we're going to\nreject any darts that lie above the blue density. And mathematically,\nwhat that means",
    "start": "1350740",
    "end": "1356200"
  },
  {
    "text": "is we just look at this value\nthat we got for the height. And we check if it's higher than\nour unnormalized target density",
    "start": "1356200",
    "end": "1363730"
  },
  {
    "text": "that we're trying\nto sample from. And if it is, we'll reject it. And then, finally, we move\nall the remaining darts",
    "start": "1363730",
    "end": "1369850"
  },
  {
    "text": "to the bottom of the board. And in order to do that, we\njust want basically the value",
    "start": "1369850",
    "end": "1375370"
  },
  {
    "text": "on this axis. We don't care about\ntheir height anymore. So all we do is just\nkeep around the tau value of all of the samples.",
    "start": "1375370",
    "end": "1382360"
  },
  {
    "text": "And that's how we get\nour final samples. So now, we're just going to have\na bunch of samples of tau, which is what we were\ntrying to get which",
    "start": "1382360",
    "end": "1388258"
  },
  {
    "text": "are the samples from\nthe target distribution.  And then there's one more\nthing I want to note here.",
    "start": "1388258",
    "end": "1395390"
  },
  {
    "text": "So if you look at\nwhat's going on here, we rejected all of\nthese gray samples.",
    "start": "1395390",
    "end": "1402290"
  },
  {
    "text": "And then the samples\nthat we ended up with from our\ntarget distribution was just all of these blue ones.",
    "start": "1402290",
    "end": "1407450"
  },
  {
    "text": "So if we wanted, for\nexample, say, 100 samples from our target\ndistribution, we have",
    "start": "1407450",
    "end": "1412720"
  },
  {
    "text": "to throw more than 100\ndarts because we're going to reject some of them. And so we want as many samples\nas possible from our target",
    "start": "1412720",
    "end": "1418450"
  },
  {
    "text": "distribution in the end to\nhave a better representation of that distribution. And so you can think\nof all these gray darts",
    "start": "1418450",
    "end": "1424870"
  },
  {
    "text": "as wasted samples. So these are things\nthat didn't, in the end, contribute to a sample in\nour target distribution.",
    "start": "1424870",
    "end": "1431830"
  },
  {
    "text": "And so you could imagine that\nthis might be inefficient if we waste quite a few samples.",
    "start": "1431830",
    "end": "1436970"
  },
  {
    "text": "And what if instead we could\nsample from a dartboard that looked like\nthis, for example.",
    "start": "1436970",
    "end": "1442130"
  },
  {
    "text": "So now, we waste\nway fewer samples. There's way fewer samples\nthat got rejected.",
    "start": "1442130",
    "end": "1450010"
  },
  {
    "text": "But we need to then make sure\nwe're able to actually sample darts from this dartboard. And so what the point is\nhere is we can do this.",
    "start": "1450010",
    "end": "1460919"
  },
  {
    "text": "And in fact, we\nshould try to do this. We might not always want to\nuse a uniform distribution like that perfectly\nrectangular dartboard",
    "start": "1460920",
    "end": "1467000"
  },
  {
    "text": "like we were using before. But we just need to select q of\ntau then to be a distribution we",
    "start": "1467000",
    "end": "1472700"
  },
  {
    "text": "can sample from. So we need to be able to sample\nfrom this purple distribution. And then we need to\nselect a c, a value c,",
    "start": "1472700",
    "end": "1479720"
  },
  {
    "text": "such that that distribution is\nalways higher than our target. Because you can imagine, if\nit's lower than our target,",
    "start": "1479720",
    "end": "1486170"
  },
  {
    "text": "then we're going to miss out\non some of that region we need. Yeah? Why don't we [INAUDIBLE]\nmake it exactly [INAUDIBLE]?",
    "start": "1486170",
    "end": "1492905"
  },
  {
    "text": "Great question. So the question\nwas, why don't we just make it exactly p bar tau. Does anyone have\nan idea for why?",
    "start": "1492905",
    "end": "1498670"
  },
  {
    "text": "Yeah. I'm guessing we don't\nactually have p bar tau. Yeah, exactly. So, yeah. Here, it looks a little\nsilly because these both look",
    "start": "1498670",
    "end": "1504500"
  },
  {
    "text": "like normal distributions. And we can sample from\nnormal distributions. But you can imagine\nlike-- imagine,",
    "start": "1504500",
    "end": "1509980"
  },
  {
    "text": "p bar tau was some\ncrazy distribution that we want to sample from. We need to then be able to\ndraw the samples from it.",
    "start": "1509980",
    "end": "1516042"
  },
  {
    "text": "And the whole point\nof this process is that we don't know how\nto draw samples from it. And so we need to sample\nfrom a distribution",
    "start": "1516042",
    "end": "1521263"
  },
  {
    "text": "that we do know how to draw\nsamples from in order to produce samples from this distribution. How would you know\nit's [INAUDIBLE]?",
    "start": "1521263",
    "end": "1529050"
  },
  {
    "text": "I think it's like, how\nmuch [INAUDIBLE] p bar tau [INAUDIBLE] estimate how close?",
    "start": "1529050",
    "end": "1535630"
  },
  {
    "text": "Yeah, that's a great question. So the question is\nof how do you pick c? How do you know that it's\ngoing to be always above?",
    "start": "1535630",
    "end": "1541735"
  },
  {
    "text": "So in this case where\nit was one dimensional, we could actually just plot\nit and see and understand.",
    "start": "1541735",
    "end": "1546750"
  },
  {
    "text": "In general, you do need\nsome domain knowledge to be able to pick\na distribution that",
    "start": "1546750",
    "end": "1552030"
  },
  {
    "text": "fits those requirements. And furthermore,\nthis is actually one of the biggest\nchallenges and drawbacks",
    "start": "1552030",
    "end": "1557639"
  },
  {
    "text": "of rejection sampling\nis that, sometimes, it's not easy to pick that. And there's actually\nan example in the book",
    "start": "1557640",
    "end": "1563160"
  },
  {
    "text": "that I'll point\nyou guys to later where we show that\nif you're trying to do this for the\npendulum, for example, you might get something that's\nso large that you have to scale",
    "start": "1563160",
    "end": "1570660"
  },
  {
    "text": "your distribution by that. That is just not\neven useful anymore. So yeah, it's a great question. ",
    "start": "1570660",
    "end": "1579600"
  },
  {
    "text": "Yeah? [INAUDIBLE] conceptually why we\ndon't know the blue distribution",
    "start": "1579600",
    "end": "1586420"
  },
  {
    "text": "so we can't directly\nsample from it, but we can do step\ntwo where we reject",
    "start": "1586420",
    "end": "1592080"
  },
  {
    "text": "all samples that are greater\nthan the blue distribution. How do we know the blue\ndistribution in that step",
    "start": "1592080",
    "end": "1597100"
  },
  {
    "text": "but not in the first step? Yeah, OK. Good one. So the question is we don't\nknow the blue distribution, so we can't sample from it.",
    "start": "1597100",
    "end": "1602890"
  },
  {
    "text": "But then how do we go\nabout computing this? So the answer is we only need to\nknow the unnormalized density.",
    "start": "1602890",
    "end": "1609723"
  },
  {
    "text": "So we do have to know\nthe unnormalized density for the sample that we're-- for the distribution\nthat we're sampling from.",
    "start": "1609723",
    "end": "1614980"
  },
  {
    "text": "If you remember, that\ngives us the entire shape of the distribution, just\nthe unnormalized density. So what we don't know what the\ntrue density is because we don't",
    "start": "1614980",
    "end": "1623190"
  },
  {
    "text": "know the normalizing constant. As long as our\npurple distribution, so the height of\nthe dartboard is above our unnormalized density.",
    "start": "1623190",
    "end": "1630020"
  },
  {
    "text": "All of this will still work. OK. Yeah? Notation question,\nin general, why",
    "start": "1630020",
    "end": "1635920"
  },
  {
    "text": "is it that we're not saying\nit's h larger than p bar tau? ",
    "start": "1635920",
    "end": "1643960"
  },
  {
    "text": "Well, if you remember,\nh can depend on tau. In this case, the height of the\nboard actually depends on tau.",
    "start": "1643960",
    "end": "1649730"
  },
  {
    "text": "The height of this tau is\ndifferent from the height at this tau. So then, it's like\nh of tau, I guess.",
    "start": "1649730",
    "end": "1658000"
  },
  {
    "text": "You could say h of\ntau if you wanted to. And then h of tau would just\nbe equal to some constant times",
    "start": "1658000",
    "end": "1663010"
  },
  {
    "text": "the q of tau. And also, sorry, for\nthe new question. We have tau is\ndrawn from q of tau.",
    "start": "1663010",
    "end": "1670309"
  },
  {
    "text": "But one tau is the actual\ntau, and the other one is a t, or am I just blind?",
    "start": "1670310",
    "end": "1675940"
  },
  {
    "text": "Here and-- Yeah, here. And here? Yeah. These are the same tau. But when you get out\nof the distribution",
    "start": "1675940",
    "end": "1682540"
  },
  {
    "text": "is not what you put into\n[INAUDIBLE] better distribution. So we're saying the density\nof that distribution is--",
    "start": "1682540",
    "end": "1690110"
  },
  {
    "text": "this might actually be a-- I might need to have a tau\nin here or something to show. [INAUDIBLE] that you have tau\n[INAUDIBLE] q of tau, right?",
    "start": "1690110",
    "end": "1698780"
  },
  {
    "text": "Instead of tau in\nthe parentheses? Yes. Actually, that's\na notation error.",
    "start": "1698780",
    "end": "1705149"
  },
  {
    "text": "We should have just\nlike a dot in there. OK, got it. Yeah, good point.",
    "start": "1705150",
    "end": "1710179"
  },
  {
    "text": "I'll fix that. Yeah? I think going back\nto Ali's question, how do we know if it's\nin that distribution?",
    "start": "1710180",
    "end": "1719574"
  },
  {
    "text": "[INAUDIBLE] So given a tau-- so the\nquestion is how do we know if it's in this distribution? So given a value\nfor tau, we know",
    "start": "1719574",
    "end": "1728060"
  },
  {
    "text": "how to compute p bar of tau. So that was like computing\nthe numerator of that equation that we were talking about.",
    "start": "1728060",
    "end": "1733080"
  },
  {
    "text": "So we can compute p bar of tau. We also know how to compute-- we know what q of tau is. We know c and r.",
    "start": "1733080",
    "end": "1738240"
  },
  {
    "text": "So we can also\ncompute this side. And we just do that check. ",
    "start": "1738240",
    "end": "1746810"
  },
  {
    "text": "Other questions?  Yeah? Sorry.",
    "start": "1746810",
    "end": "1752373"
  },
  {
    "text": "Can you repeat how\nyou found p-bar because I just [INAUDIBLE]? So p-bar is like\nthe target density",
    "start": "1752373",
    "end": "1759080"
  },
  {
    "text": "that we're trying\nto sample from. So in a second, I'm going to\ntie this all back to the failure distribution.",
    "start": "1759080",
    "end": "1764790"
  },
  {
    "text": "So in this case,\nthe target density we're interested in this class\nis the failure distribution.",
    "start": "1764790",
    "end": "1770040"
  },
  {
    "text": "So it's that indicator\nfunction times p of tau that I was talking about earlier.",
    "start": "1770040",
    "end": "1775490"
  },
  {
    "text": "So to develop that, we\nneed to have samples like failure samples to get\nan understanding of p-bar?",
    "start": "1775490",
    "end": "1783559"
  },
  {
    "text": "No, you just have to know-- so if you remember\nthat numerator was just that indicator function\ntimes the nominal trajectory",
    "start": "1783560",
    "end": "1789470"
  },
  {
    "text": "distribution. So given a value\nfor tau, you need to be able to check whether\nor not it's a failure.",
    "start": "1789470",
    "end": "1794580"
  },
  {
    "text": "And you need to be able to\ncompute the nominal likelihood. But you don't need to have\nany samples of failures ahead of time.",
    "start": "1794580",
    "end": "1801779"
  },
  {
    "text": "Yeah? In 1b, you say, some of the\nvalue uniformly between 0",
    "start": "1801780",
    "end": "1807760"
  },
  {
    "text": "and 0.6. And this value is something. It's r, right, which is then\nactually sampled from 0 to 1.",
    "start": "1807760",
    "end": "1815040"
  },
  {
    "text": "Is the 0.6 just a\nremnant from the example? Yeah, I mean, it's\nrandom from the example. But I'm saying, in the\nexample, c times q of tau.",
    "start": "1815040",
    "end": "1823090"
  },
  {
    "text": "Not for this anymore. This is different. But c times q of tau is 0.6. Because the height\nof the board was 0.6.",
    "start": "1823090",
    "end": "1829179"
  },
  {
    "text": "That was just arbitrary. But in general, you're\nsampling a value uniformly between 0 and c times q of tau.",
    "start": "1829180",
    "end": "1835000"
  },
  {
    "text": "That's like what this\nstep ends up doing. But then, you say\nr is from 0 to 1.",
    "start": "1835000",
    "end": "1842460"
  },
  {
    "text": "In the same line, r is-- No, this one must [INAUDIBLE]. [LAUGHTER]",
    "start": "1842460",
    "end": "1848490"
  },
  {
    "text": " Can I just reply with that? Math isn't my strongest subject.",
    "start": "1848490",
    "end": "1853870"
  },
  {
    "text": "So I'm not going to answer that. I dropped it in [INAUDIBLE]. [LAUGHTER] r is between 0 and--",
    "start": "1853870",
    "end": "1862090"
  },
  {
    "text": "r is between 0 and 1. But then we're multiplying\nthis value by r. So we're scaling it by some\nvalues between 0 and-- yeah.",
    "start": "1862090",
    "end": "1871207"
  },
  {
    "text": "I'm going to try that one. Next time you guys stump me,\nI'm just going to go, math-- [LAUGHTER]",
    "start": "1871207",
    "end": "1877763"
  },
  {
    "text": " Awesome. So we're going to\nactually depart from this dartboard analogy now\nand talk about more generally",
    "start": "1877763",
    "end": "1885280"
  },
  {
    "text": "what rejection\nsampling looks like. But before we do that,\nI just want to give you a random fact about darts.",
    "start": "1885280",
    "end": "1891140"
  },
  {
    "text": "So maybe you already know this. But I didn't know this\nuntil I looked this up. So it turns out\ndartboards are actually designed to specifically\nreward accuracy and penalize",
    "start": "1891140",
    "end": "1899950"
  },
  {
    "text": "inaccuracy. So for example, the 20, which is\nthe highest value you can get, is up here. And it's next to 1 and 5.",
    "start": "1899950",
    "end": "1906649"
  },
  {
    "text": "So if you're aiming for the 20,\nthen you'll be in good shape if you're super accurate.",
    "start": "1906650",
    "end": "1911809"
  },
  {
    "text": "But if you're a\nlittle bit inaccurate, you might really lose\nout and get one instead. And so this is completely\noutside the scope of the class.",
    "start": "1911810",
    "end": "1919100"
  },
  {
    "text": "But one interesting\nthing here is, you might imagine that if you're\nactually not that accurate. So if you're like me and\nyou're lucky if the dart even",
    "start": "1919100",
    "end": "1926080"
  },
  {
    "text": "lands on the board,\nthen you probably don't actually want\nto aim for the 20 because you'll probably miss and\nget something like much, much",
    "start": "1926080",
    "end": "1932983"
  },
  {
    "text": "worse. And so then, you can think\nabout, OK, well then, I don't know what to do. What should my\noptimal dart strategy",
    "start": "1932983",
    "end": "1938320"
  },
  {
    "text": "be if I'm really\nnot that accurate? Well no worries, the Stanford\nStats Department has covered. So there's actually\nthis interesting paper",
    "start": "1938320",
    "end": "1945340"
  },
  {
    "text": "that came out where they assume\na Gaussian distribution over-- it's centered at\nwhere you're aiming.",
    "start": "1945340",
    "end": "1950990"
  },
  {
    "text": "And then there's\nsome variance that says like how bad your aim is. And they can actually get\nyou a personalized heat",
    "start": "1950990",
    "end": "1956800"
  },
  {
    "text": "map of where you should aim to\nmaximize your score in darts. So if you're interested, you\ncan check out this paper.",
    "start": "1956800",
    "end": "1964159"
  },
  {
    "text": "It was also written by\nRyan Tibshirani, who's the son of Rob\nTibshirani, who actually",
    "start": "1964160",
    "end": "1969730"
  },
  {
    "text": "has five times the amount\nof citations as Einstein, which is pretty cool. So, yeah, you can check\nthat out on your own time",
    "start": "1969730",
    "end": "1976970"
  },
  {
    "text": "if you're interested. But let's get back to\nrejection sampling. So now, I'm just going to\nrewrite the algorithm one more",
    "start": "1976970",
    "end": "1983540"
  },
  {
    "text": "time. And we're not going to talk\nabout darts or dartboards anymore. So the first thing that\nwe do in the algorithm",
    "start": "1983540",
    "end": "1988820"
  },
  {
    "text": "is we sample some tau\nfrom our q of tau. So you remember\nthat was sampling along the width\nof the dartboard.",
    "start": "1988820",
    "end": "1996530"
  },
  {
    "text": "And then just a\nnote here, q of tau is often referred\nto as something that we call a\nproposal distribution.",
    "start": "1996530",
    "end": "2003290"
  },
  {
    "text": "So this idea of\nproposal distribution is going to come\nup a whole bunch in the next couple of weeks\nas we talk about failure",
    "start": "2003290",
    "end": "2009669"
  },
  {
    "text": "probability estimation. Basically, what a\nproposal distribution is, it's just a\ndistribution that we're",
    "start": "2009670",
    "end": "2014860"
  },
  {
    "text": "sampling from that we know\nhow to sample from in order to end up getting samples\nfrom this distribution that we don't know\nhow to sample from.",
    "start": "2014860",
    "end": "2021315"
  },
  {
    "text": " And then we basically\nsaid we reject this dart",
    "start": "2021315",
    "end": "2026420"
  },
  {
    "text": "if c times q of tau times r\nis greater than this p-bar, is greater than\nour target density.",
    "start": "2026420",
    "end": "2033492"
  },
  {
    "text": "So I'm just going to\nrewrite that a little bit. I just divide both sides\nby c times q of tau.",
    "start": "2033492",
    "end": "2039610"
  },
  {
    "text": "And then just to switch\nit to a positive, I'm going to say we'll accept\nthe dart if r, which we sampled",
    "start": "2039610",
    "end": "2046179"
  },
  {
    "text": "between 0 and 1, is less than\nthis particular value here.",
    "start": "2046180",
    "end": "2051760"
  },
  {
    "text": "So this is the criteria we use. And r, if you remember,\nwas just a value",
    "start": "2051760",
    "end": "2057460"
  },
  {
    "text": "that we sampled uniformly\nbetween 0 and 1. And so in most\nprogramming languages, you can just do that using\na call to the rand function.",
    "start": "2057460",
    "end": "2065179"
  },
  {
    "text": "So that's what we do. And then one note here,\nas we were saying, we needed to make sure that that\nthe dart board was basically",
    "start": "2065179",
    "end": "2071921"
  },
  {
    "text": "tall enough to cover\nour full density. And so what that's saying is\nwe need to select a proposal distribution, q of tau.",
    "start": "2071922",
    "end": "2078820"
  },
  {
    "text": "And a value for c, this should\nprobably also note that. Such that our target density\nwe're trying to sample from",
    "start": "2078820",
    "end": "2085300"
  },
  {
    "text": "is always less than or\nequal to c times q of tau.",
    "start": "2085300",
    "end": "2090388"
  },
  {
    "text": "Yeah? So I think, previously,\nin the board analogy, that sampling the--",
    "start": "2090389",
    "end": "2096679"
  },
  {
    "text": "sorry, the distribution\nthat we sampled tau from was not necessarily\nthe height of the board that we used as this q of tau.",
    "start": "2096679",
    "end": "2103272"
  },
  {
    "text": "But in this case,\nthey're the same. So is that-- So the height of the\nboard in the board analogy",
    "start": "2103272",
    "end": "2109280"
  },
  {
    "text": "is c times q of tau. [INAUDIBLE] They're the same thing, yeah.",
    "start": "2109280",
    "end": "2115260"
  },
  {
    "text": "I mean, another place\nwhere this breaks down is, now, we can do this over the\nfull infinite line as well.",
    "start": "2115260",
    "end": "2120300"
  },
  {
    "text": "We don't really think about\ninfinitely long dartboards. But now, we don't have\nto worry about that. We just need to make sure\nthat for all values of tau,",
    "start": "2120300",
    "end": "2126720"
  },
  {
    "text": "this inequality is satisfied. Yeah? I'm sorry.",
    "start": "2126720",
    "end": "2131900"
  },
  {
    "text": "Can you talk about what\nthe [INAUDIBLE] is? Yeah, so this is just an\nimplementation detail.",
    "start": "2131900",
    "end": "2137123"
  },
  {
    "text": "So maybe I'll just pull up\nthe algorithm real quick. If we want to accept or\nreject, you remember,",
    "start": "2137123",
    "end": "2143390"
  },
  {
    "text": "r was sampled from a uniform\ndistribution between 0 and 1. So we're sampling where\nthat height should land.",
    "start": "2143390",
    "end": "2149970"
  },
  {
    "text": "This makes sense. So this is only\ntrue if [INAUDIBLE].",
    "start": "2149970",
    "end": "2156510"
  },
  {
    "text": "This is only true if [INAUDIBLE]\ndistribution is uniform. But you can only do\nthis [INAUDIBLE].",
    "start": "2156510",
    "end": "2163680"
  },
  {
    "text": "Is what? Uniform. Uniform? No. So you remember that when\nI switched the dartboard",
    "start": "2163680",
    "end": "2169319"
  },
  {
    "text": "to be that funky shape? So your proposal\ndistribution can be shaped like anything as long\nas this condition is satisfied.",
    "start": "2169320",
    "end": "2176290"
  },
  {
    "text": "But random [INAUDIBLE] uniform. Yeah, your proposal\ndistribution is q of tau. So the first sample we draw is\nfrom the proposal distribution.",
    "start": "2176290",
    "end": "2183570"
  },
  {
    "text": "That gives us our\nlocation along the width of the dartboard\nif we're thinking of the dartboard analogy. And then the second thing\nwe do is sample that height.",
    "start": "2183570",
    "end": "2190390"
  },
  {
    "text": "And we're sampling\nuniformly between the bottom of the dartboard and\nthe top of the dartboard",
    "start": "2190390",
    "end": "2195960"
  },
  {
    "text": "at that value for tau. OK, got it. Yeah. Yeah?",
    "start": "2195960",
    "end": "2201660"
  },
  {
    "text": "I'm a bit surprised that\nq can over bounce p.",
    "start": "2201660",
    "end": "2206670"
  },
  {
    "text": "I feel one distribution cannot\nstrictly overbound another distribution. Yeah, that's what c is for.",
    "start": "2206670",
    "end": "2212370"
  },
  {
    "text": "So you typically need\na c that's great-- or oftentimes, you'll need\na c that's greater than 1 so you can lift q\nup to overbound it.",
    "start": "2212370",
    "end": "2219695"
  },
  {
    "text": " Yeah? In line with the\nquestions before,",
    "start": "2219695",
    "end": "2225300"
  },
  {
    "text": "I still don't really understand. So if we have the\nunnormalized distribution, [INAUDIBLE]\ndistribution already,",
    "start": "2225300",
    "end": "2230470"
  },
  {
    "text": "and now we're drawing all\nthese samples and reject them. And then we're approximating\nthis unnormalized distribution",
    "start": "2230470",
    "end": "2236630"
  },
  {
    "text": "again. So I don't really understand\nwhat we're gaining by it. So the question is, what\ndo we gain from this?",
    "start": "2236630",
    "end": "2243789"
  },
  {
    "text": "So the unnormalized\ndistribution, we just",
    "start": "2243790",
    "end": "2248880"
  },
  {
    "text": "had an expression for it. So we had this indicator\nfunction times p of tau. But for the simple\nGaussian, we could visualize",
    "start": "2248880",
    "end": "2256193"
  },
  {
    "text": "what that looked like. But in general, we can't\nreally visualize that. You could imagine\nfor the grid world, we're just like, it's\nall the samples that",
    "start": "2256193",
    "end": "2262560"
  },
  {
    "text": "are failure samples\nweighted by their likelihood in the nominal\ntrajectory distribution. But we don't know\nwhat that looks like.",
    "start": "2262560",
    "end": "2268225"
  },
  {
    "text": "So we have the\nexpression for it, but we want to actually draw\nsamples from that expression",
    "start": "2268225",
    "end": "2273628"
  },
  {
    "text": "or from the distribution that\ncorresponds to that expression. And so this is allowing us\nto actually draw the samples.",
    "start": "2273628",
    "end": "2278984"
  },
  {
    "text": " Yeah? I'm just curious. My intuition is telling\nme that, basically,",
    "start": "2278985",
    "end": "2285670"
  },
  {
    "text": "what we're trying to do here\nis you can imagine if q of tau was just uniform, then\nwe're essentially just doing",
    "start": "2285670",
    "end": "2291550"
  },
  {
    "text": "a frequentist, empirical\nestimation of what the failure probability is or\ndistribution is.",
    "start": "2291550",
    "end": "2297500"
  },
  {
    "text": "And then in a more\nideal setting, we move our q of tau,\nour uniform distribution,",
    "start": "2297500",
    "end": "2303220"
  },
  {
    "text": "closer to, so that we\nsample more directly what we think will be failures.",
    "start": "2303220",
    "end": "2309008"
  },
  {
    "text": "And then that will just\ngive a more efficient way to approximate our\nfailure distribution. Yeah, I think that's exactly\nalong the lines of thinking.",
    "start": "2309008",
    "end": "2317740"
  },
  {
    "text": "I'm not sure uniform\ndistribution is what you mean. But I'll show you in a second. We're basically going\nto go through almost",
    "start": "2317740",
    "end": "2322770"
  },
  {
    "text": "that exact thought process. Yeah. And then just to show you\nwhat the algorithm looks",
    "start": "2322770",
    "end": "2328040"
  },
  {
    "text": "like in the book and\npoint these things out. So basically, at\neach step, we sample a trajectory from our proposal\ndistribution q of tau.",
    "start": "2328040",
    "end": "2335328"
  },
  {
    "text": "And you remember, now,\nwe're talking specifically about these trajectory\ndistributions. So to sample, we do a rollout.",
    "start": "2335328",
    "end": "2341510"
  },
  {
    "text": "And then this part here is\njust we say we call rand. So that gives us this r. And we check if it's less than\nthis value that we compute here.",
    "start": "2341510",
    "end": "2351260"
  },
  {
    "text": "And if it is, then\nwe accept the sample and we add it to our samples. And if it's not, then we just\ngo to the next iteration.",
    "start": "2351260",
    "end": "2357150"
  },
  {
    "text": " So that's rejection sampling.",
    "start": "2357150",
    "end": "2363630"
  },
  {
    "text": "So here's it all summed up. We just sample\nfrom our proposal, accept it with\nprobability proportional",
    "start": "2363630",
    "end": "2370339"
  },
  {
    "text": "to this or probability of this. And then we need to make sure\nthat we pick our distribution",
    "start": "2370340",
    "end": "2375770"
  },
  {
    "text": "such that they satisfy this. And so then, what this tells\nus is that we can actually",
    "start": "2375770",
    "end": "2381560"
  },
  {
    "text": "produce samples. Or sorry, wait. Yeah, so let's talk\nnow back to-- we're",
    "start": "2381560",
    "end": "2386722"
  },
  {
    "text": "trying to sample from\nthe failure distribution. This was like our\nultimate goal here.",
    "start": "2386722",
    "end": "2391730"
  },
  {
    "text": "And so, I didn't want\nto show that part yet. So I'm going to write\nsome stuff out here.",
    "start": "2391730",
    "end": "2398840"
  },
  {
    "text": "So this is our goal here. And so what we\nneed to do to apply rejection sampling\nin this scenario",
    "start": "2398840",
    "end": "2405320"
  },
  {
    "text": "is we're going to say our target\ndensity, so that p bar of tau here, this part.",
    "start": "2405320",
    "end": "2412280"
  },
  {
    "text": "For our failure\ndistribution is that p bar of tau, given that tau is\nnot in the specification.",
    "start": "2412280",
    "end": "2420230"
  },
  {
    "text": "And then we said that this\nwas equal to our indicator function times the nominal\ntrajectory distribution.",
    "start": "2420230",
    "end": "2431480"
  },
  {
    "text": "So that's our unnormalized\ntarget density we want to sample from. Now, we need to\nselect a q of tau.",
    "start": "2431480",
    "end": "2438900"
  },
  {
    "text": "We need to select a proposal. So let's imagine here that--",
    "start": "2438900",
    "end": "2444000"
  },
  {
    "text": "let's try out the nominal\ntrajectory distribution. So let's just say that q of\ntau is the nominal trajectory",
    "start": "2444000",
    "end": "2450120"
  },
  {
    "text": "distribution. So we know how to draw samples\nfrom the nominal trajectory distribution. We just perform a\nbunch of rollouts.",
    "start": "2450120",
    "end": "2456000"
  },
  {
    "text": "So we're going to say q of\ntau is equal to that p of tau. That's our nominal distribution. And then we need to\nselect a value for c.",
    "start": "2456000",
    "end": "2465210"
  },
  {
    "text": "And this needs to hold. So I'm going to just\nplug that in there. We know that p bar of\ntau is equal to this.",
    "start": "2465210",
    "end": "2474430"
  },
  {
    "text": "So it must be the case then that\nthis indicator function times p",
    "start": "2474430",
    "end": "2479730"
  },
  {
    "text": "of tau is less than or equal to\nthis kind of c times q of tau.",
    "start": "2479730",
    "end": "2486130"
  },
  {
    "text": "And we're saying q of\ntau is equal to p of tau. So c times p of tau.",
    "start": "2486130",
    "end": "2492690"
  },
  {
    "text": "And so we need to\nselect a value for c such that this\ninequality holds true.",
    "start": "2492690",
    "end": "2498400"
  },
  {
    "text": "Can anyone tell me a value\nfor c that would work here? 1.",
    "start": "2498400",
    "end": "2503770"
  },
  {
    "text": "1, yeah, exactly. So if we plug in a 1\nhere, we just get that-- so this becomes 1.",
    "start": "2503770",
    "end": "2511010"
  },
  {
    "text": "So this indicator\nfunction times p of tau is always going to be less\nthan or equal to p of tau. Because this is\neither 1 or 0, so it's",
    "start": "2511010",
    "end": "2517000"
  },
  {
    "text": "either going to be\nequal to p of tau or 0. p of tau and 0 is always less\nthan or equal to p of tau.",
    "start": "2517000",
    "end": "2523240"
  },
  {
    "text": " And so if we let c equal 1, then\nour algorithm reduces to this.",
    "start": "2523240",
    "end": "2531500"
  },
  {
    "text": "So the first thing that we do\nis sample tau from q of tau. And our q of tau is a nominal\ntrajectory distribution.",
    "start": "2531500",
    "end": "2537010"
  },
  {
    "text": "So we'll say sample\ntau from nominal. ",
    "start": "2537010",
    "end": "2546910"
  },
  {
    "text": "And then we're going\nto accept the sample.",
    "start": "2546910",
    "end": "2553869"
  },
  {
    "text": "If r is less than this\np bar over c times q,",
    "start": "2553870",
    "end": "2559850"
  },
  {
    "text": "which is going to\nbe equal to this. ",
    "start": "2559850",
    "end": "2568480"
  },
  {
    "text": "Whoops. So these two things cancel out. And we just get the\nindicator function left.",
    "start": "2568480",
    "end": "2576820"
  },
  {
    "text": "And so this might\nhave all seemed a bit convoluted and weird.",
    "start": "2576820",
    "end": "2582530"
  },
  {
    "text": "But we actually just derived\na very obvious result because this indicator\nfunction is equal to 1",
    "start": "2582530",
    "end": "2589390"
  },
  {
    "text": "if tau is a failure. Oops. And 0, otherwise.",
    "start": "2589390",
    "end": "2595869"
  },
  {
    "text": "And so basically,\nthe probability that we accept the trajectory\nis 1 if it's a failure, and 0 if it's not a failure.",
    "start": "2595870",
    "end": "2602720"
  },
  {
    "text": "So all we did was, say, sample\nfrom the nominal distribution. And if we get a\nfailure, keep it.",
    "start": "2602720",
    "end": "2608960"
  },
  {
    "text": "And if we get a\nsuccess, throw it out. And we actually talked about\nthis in previous lectures. I showed this as a\nbaseline method to sample",
    "start": "2608960",
    "end": "2615589"
  },
  {
    "text": "from the failure distribution. So all of this seems\ncrazy, but we just derived a very intuitive\nresult, which is just",
    "start": "2615590",
    "end": "2620750"
  },
  {
    "text": "sample from the\nnormal distribution and keep the failures. And those failures\nwill actually come from the failure distribution.",
    "start": "2620750",
    "end": "2627240"
  },
  {
    "text": " So basically, what\nwe just showed--",
    "start": "2627240",
    "end": "2633460"
  },
  {
    "text": "yeah? I'm sorry. Still, I'm not quite\nfollowing the notion of r. It doesn't make sense.",
    "start": "2633460",
    "end": "2638850"
  },
  {
    "text": "Why do we have this other\nuniform distribution that we're sampling from\nand checking against? Another way to look\nat it is you'll",
    "start": "2638850",
    "end": "2645680"
  },
  {
    "text": "say we accept the\nsample with probability proportional to this value.",
    "start": "2645680",
    "end": "2653460"
  },
  {
    "text": "That's another\nway to look at it. Or sorry, not even\nproportional to. We accept the sample with\nprobability of this value.",
    "start": "2653460",
    "end": "2659400"
  },
  {
    "text": "And so to decide whether\nor not to accept it, we could just sample\nbetween 0 and 1",
    "start": "2659400",
    "end": "2665210"
  },
  {
    "text": "and see if it's less\nthan that value. And that would allow us to\naccept with that probability. I guess the thing that's\nnot super intuitive to me",
    "start": "2665210",
    "end": "2672470"
  },
  {
    "text": "is, why is this\nnow probabilistic if we can check\nbriefly and check against our unnormalized\ndistribution already?",
    "start": "2672470",
    "end": "2679890"
  },
  {
    "text": "And we know if something is out\nof that or something is in that. Like a particular\ntau, we know it's",
    "start": "2679890",
    "end": "2685100"
  },
  {
    "text": "either in that or out of it. Why do we need to then make it\nin another probabilistic thing of-- we want to accept it\nwith this much probability.",
    "start": "2685100",
    "end": "2692730"
  },
  {
    "text": "So the intuition\nis you want to-- if you want to draw samples\nfrom a distribution.",
    "start": "2692730",
    "end": "2698760"
  },
  {
    "text": "Let's say I just drew a\ndensity function from you. And I was like, you give\nme some samples from it. And then you're going to\npretend to draw samples.",
    "start": "2698760",
    "end": "2705210"
  },
  {
    "text": "You're going to give me more\nsamples from areas where this value was higher then you\nare for areas with those values",
    "start": "2705210",
    "end": "2711410"
  },
  {
    "text": "lower. So what you want to\ndo is, let's say, now, imagine that I gave\nyou this dartboard where",
    "start": "2711410",
    "end": "2717289"
  },
  {
    "text": "you're doing this. You want to accept\nmore frequently where this is higher and less\nfrequently where this is lower.",
    "start": "2717290",
    "end": "2723960"
  },
  {
    "text": "So it's just kind of\na probabilistic way to meet that criteria. ",
    "start": "2723960",
    "end": "2731363"
  },
  {
    "text": "Let's talk about\nthis [INAUDIBLE]. Sounds good. Yeah, totally happy\nto talk [INAUDIBLE].",
    "start": "2731363",
    "end": "2736410"
  },
  {
    "text": "Any other questions? Question? This has just become\ndirect sampling?",
    "start": "2736410",
    "end": "2742080"
  },
  {
    "text": "Yeah. Yeah, I think, in\nthis case, it's what I was showing you where\nwe just reject all the ones.",
    "start": "2742080",
    "end": "2749070"
  },
  {
    "text": "But what might be a\nproblem with this method-- hint, what keeps coming\nup in this class.",
    "start": "2749070",
    "end": "2755530"
  },
  {
    "text": "Yeah? We probably don't want to\nbe sampling from q of tau but something closer to-- Yeah, so, exactly what you\nwere talking about earlier.",
    "start": "2755530",
    "end": "2762940"
  },
  {
    "text": "So if we just do this and\nfailures are really rare, then, we're not going to get\nvery many failures. And we're going to reject\na whole bunch of samples.",
    "start": "2762940",
    "end": "2769060"
  },
  {
    "text": "And we're not going to\nbe left with very much. So this is an issue. And so again, it will be\ninefficient for systems",
    "start": "2769060",
    "end": "2775500"
  },
  {
    "text": "with rare failure events. And so one solution is to try to\ncome up with a better proposal",
    "start": "2775500",
    "end": "2780600"
  },
  {
    "text": "distribution that's actually\ncloser to the distribution that we're trying\nto sample from.",
    "start": "2780600",
    "end": "2785880"
  },
  {
    "text": "So let's see a new-- let's\nsee a Pluto Notebook for this. So let's look here.",
    "start": "2785880",
    "end": "2793010"
  },
  {
    "text": "So this is what we\nwere doing where we make our proposal\ndistribution the nominal distribution. So this is exactly\nwhat we're saying.",
    "start": "2793010",
    "end": "2798992"
  },
  {
    "text": "It's just like this\ndirect sampling idea. And we'll just reject the\nones that aren't failures. So as we increase the\nnumber of samples,",
    "start": "2798992",
    "end": "2805930"
  },
  {
    "text": "you'll see that we get-- So this is showing\nthat dartboard I was showing before,\nwhere the dartboard is",
    "start": "2805930",
    "end": "2812110"
  },
  {
    "text": "shaped like this basically. And then this plot down here\nis showing the true failure",
    "start": "2812110",
    "end": "2817563"
  },
  {
    "text": "distribution, which\nwe can compute for this kind of\nsmall toy problem plotted against a histogram\nof the samples we're getting.",
    "start": "2817563",
    "end": "2825940"
  },
  {
    "text": "So you can see, as we\nincrease the number of samples and produce more\nand more samples, we get something that's roughly\nshaped like that distribution.",
    "start": "2825940",
    "end": "2834700"
  },
  {
    "text": "But as we were\nsaying, this might be really inefficient\nfor rare failure events. So let's make failures\nmore rare by moving",
    "start": "2834700",
    "end": "2841869"
  },
  {
    "text": "this threshold to the left. And so you can see, as I move\nthis threshold to the left,",
    "start": "2841870",
    "end": "2850400"
  },
  {
    "text": "now, we're at a point where--\nmaybe right around here. We're at a point here where\nthis is starting to break down.",
    "start": "2850400",
    "end": "2856820"
  },
  {
    "text": "These don't really look like\nthey're distributed according to this density anymore.",
    "start": "2856820",
    "end": "2862390"
  },
  {
    "text": "And so we might be\nable to do better if we select a new hand-designed\nproposal distribution.",
    "start": "2862390",
    "end": "2869150"
  },
  {
    "text": "So here, what I'm going\nto do is control the mean of this proposal distribution.",
    "start": "2869150",
    "end": "2874370"
  },
  {
    "text": "And then we'll\ncontrol this value c that tells us how tall that\ndistribution should be.",
    "start": "2874370",
    "end": "2880540"
  },
  {
    "text": "So which way-- well,\nthere's already an option because I'm already at 0 here. But which way should\nI move the mean?",
    "start": "2880540",
    "end": "2886210"
  },
  {
    "text": "Yeah, to the left. Didn't really have an\noption to move to the right. But yeah, so I'm going\nto center this mean now",
    "start": "2886210",
    "end": "2892570"
  },
  {
    "text": "around where our failure\nthreshold is because that looks like it'll get us the most. And that's already starting to\nimprove the results that we get.",
    "start": "2892570",
    "end": "2900549"
  },
  {
    "text": "And then what we can do,\nthis is super inefficient because this is way above\nthe failure density. We might as well just try to\nmove this down a little bit.",
    "start": "2900550",
    "end": "2908480"
  },
  {
    "text": "And so if we decrease\nc, you'll see that we can get kind\nof even better results.",
    "start": "2908480",
    "end": "2915567"
  },
  {
    "text": "Because we're rejecting\na lot fewer samples, we're getting a lot more samples\nto represent our distribution.",
    "start": "2915567",
    "end": "2921493"
  },
  {
    "text": "Can anyone tell\nme what they think would happen if I\ndecrease c past this? ",
    "start": "2921493",
    "end": "2929594"
  },
  {
    "text": "Can I? Yeah. [INAUDIBLE] Yeah, I think [INAUDIBLE]\nthat go above the white part",
    "start": "2929594",
    "end": "2935000"
  },
  {
    "text": "would get not counted. So you would get kind of\nan underrepresentation of the peaky part.",
    "start": "2935000",
    "end": "2940545"
  },
  {
    "text": "Yeah, that's exactly right. So the whole\nprocess breaks down. So it's that requirement we\nhad that it be greater than--",
    "start": "2940545",
    "end": "2946760"
  },
  {
    "text": "it be high enough,\nis that broken, and so we don't get the\nright distribution here.",
    "start": "2946760",
    "end": "2952730"
  },
  {
    "text": "So what we want to do is make\nc as small as we possibly can, but without violating that\nproperty that we need.",
    "start": "2952730",
    "end": "2959260"
  },
  {
    "text": " But just to be\nclear one more time,",
    "start": "2959260",
    "end": "2965170"
  },
  {
    "text": "it's generally not easy to tell\nif the c is appropriate or not.",
    "start": "2965170",
    "end": "2970335"
  },
  {
    "text": "So we don't have-- I mean, maybe now\nit's going to be easy. But in general, it's not easy. So the question was is\nit generally not easy?",
    "start": "2970335",
    "end": "2976845"
  },
  {
    "text": "And yeah, that's\nabsolutely true. I'm going to talk about\nthat actually in a second. And in fact, a lot of times,\nyou can pick a value for c",
    "start": "2976845",
    "end": "2985890"
  },
  {
    "text": "by being super,\nsuper conservative. But then, it will just be like\ntoo conservative to be useful. ",
    "start": "2985890",
    "end": "2993330"
  },
  {
    "text": "So what we just saw is that if\nwe use the nominal trajectory distribution, this can be\ninefficient for systems",
    "start": "2993330",
    "end": "3000680"
  },
  {
    "text": "with rare failure events. And then if we try to come\nup with a better proposal distribution, we can\nimprove this process.",
    "start": "3000680",
    "end": "3009750"
  },
  {
    "text": "But that might be\ndifficult to hand design. So that brings me to what are\nthe challenges or drawbacks",
    "start": "3009750",
    "end": "3015619"
  },
  {
    "text": "of rejection sampling? So one challenge is selecting\nan appropriate proposal distribution.",
    "start": "3015620",
    "end": "3020970"
  },
  {
    "text": "It's not always\nobvious how to do this. And then as we were\ntalking about, selecting an appropriate value for c\nis also not super easy to do.",
    "start": "3020970",
    "end": "3028988"
  },
  {
    "text": "And if you want to\nsee how this works and how this breaks\ndown for a bigger example like the pendulum,\nexample 6.1 in the textbook",
    "start": "3028988",
    "end": "3036140"
  },
  {
    "text": "goes through this process. So you can check it out. ",
    "start": "3036140",
    "end": "3041360"
  },
  {
    "text": "Awesome. So let's move on to the next\ntopic, which is also super cool. And that's Markov\nChain Monte Carlo.",
    "start": "3041360",
    "end": "3047300"
  },
  {
    "text": "So you'll see some parallels\nbetween these methods. We're going to accept\nthings and reject things. But I think my caution\nto you is if you",
    "start": "3047300",
    "end": "3054859"
  },
  {
    "text": "try to draw these\nparallels too much, I think you'll just confuse\nyourself because they're not--",
    "start": "3054860",
    "end": "3059940"
  },
  {
    "text": "So they have the\nsame goal to try to [INAUDIBLE] from this\nunnormalized target density. But we're going to talk about\naccepting and rejecting.",
    "start": "3059940",
    "end": "3066150"
  },
  {
    "text": "And they're not really trying\nto do-- they're not really doing it in the same way. So just be careful trying to\nmap these things together.",
    "start": "3066150",
    "end": "3072980"
  },
  {
    "text": "But with that, let's jump\ninto Markov Chain Monte Carlo. And again, before\nI talk about this, I just want to say\nsomething about it.",
    "start": "3072980",
    "end": "3080589"
  },
  {
    "text": "So when I first\nheard of this topic, I was honestly pretty\nterrified of it. I feel like it just seems\nlike this kind of scary topic.",
    "start": "3080590",
    "end": "3087760"
  },
  {
    "text": "I don't what it is. But I want to say that I\nthink this is very attainable.",
    "start": "3087760",
    "end": "3093295"
  },
  {
    "text": "This is a very attainable\ntopic to understand, especially from a practical standpoint. So my goal today is to give you\na very practical understanding",
    "start": "3093295",
    "end": "3100500"
  },
  {
    "text": "of this algorithm, how you\ncould use it, what it does. Because it's really\nextremely powerful.",
    "start": "3100500",
    "end": "3106050"
  },
  {
    "text": "With that said, there are these\ndeep statistical theoretical meanings behind it\nand proofs behind it.",
    "start": "3106050",
    "end": "3111690"
  },
  {
    "text": "That's beyond the\nscope of this class. But hopefully, this\npractical standpoint that I'm going to give\nyou is enough for you",
    "start": "3111690",
    "end": "3117243"
  },
  {
    "text": "to dive into that if that's\nsomething that interests you. And if it's not, you could\njust use this in your work",
    "start": "3117243",
    "end": "3122730"
  },
  {
    "text": "knowing that it works\nand why and how it works. And then also, with\nrespect to that,",
    "start": "3122730",
    "end": "3129329"
  },
  {
    "text": "I just want to maybe cure some\npeople's imposter syndrome, if you happen to have\nany, by telling you my first exposure\nto the word Markov.",
    "start": "3129330",
    "end": "3136790"
  },
  {
    "text": "So I was interviewing\nfor my internship at MIT Lincoln Laboratory.",
    "start": "3136790",
    "end": "3142369"
  },
  {
    "text": "And the group\nleader had called me and was telling me about\nthe things I'd be working on",
    "start": "3142370",
    "end": "3147670"
  },
  {
    "text": "and the things that the\ngroup there works on. And I was interviewing\nfor the group that both Michael\nand Robert worked in,",
    "start": "3147670",
    "end": "3153020"
  },
  {
    "text": "which is the group that\nworked on collision avoidance for aircraft. And they specifically use Markov\ndecision processes for this.",
    "start": "3153020",
    "end": "3161480"
  },
  {
    "text": "And so as the\ninterview was going on, I was writing down notes\nof everything that he was saying so I could remember.",
    "start": "3161480",
    "end": "3168010"
  },
  {
    "text": "And I recently found those notes\nwhen I was moving apartments. And unfortunately, I couldn't\nfind them again last night.",
    "start": "3168010",
    "end": "3173810"
  },
  {
    "text": "I really wanted to so that I\ncould show them to you guys. But I basically reproduced what\nthose notes looked like so you",
    "start": "3173810",
    "end": "3180160"
  },
  {
    "text": "could have an idea here. So it was kind of something,\nsomething surveillance systems, collision avoidance\nblah, blah, blah.",
    "start": "3180160",
    "end": "3185750"
  },
  {
    "text": "But there was a very\nfunny thing I saw in the notes, which was this. So to be honest, I had never\nheard of Markov decision",
    "start": "3185750",
    "end": "3193150"
  },
  {
    "text": "processes before that email. So that was my attempt\nto write Markov. I clearly had no idea\nwhat was going on.",
    "start": "3193150",
    "end": "3200000"
  },
  {
    "text": "I later found out that\nMarkov is actually this kind of famous\nmathematician that lots of things\nare named after.",
    "start": "3200000",
    "end": "3205790"
  },
  {
    "text": "And it was not, in fact,\nthe words \"mark off.\" But just in case, you're\nfeeling a little intimidated",
    "start": "3205790",
    "end": "3212890"
  },
  {
    "text": "or something, I came this far. So you can do it, too. You're already starting off\non a better foot because what",
    "start": "3212890",
    "end": "3218500"
  },
  {
    "text": "the word Markov is. I'm very glad they didn't see\nthese notes because I'm not sure if they still would\nhave hired me.",
    "start": "3218500",
    "end": "3224387"
  },
  {
    "text": "But it worked out for the best. So with that, let's dive into\nMarkov Chain Monte Carlo.",
    "start": "3224387",
    "end": "3230619"
  },
  {
    "text": "So what we do for Markov\nChain Monte Carlo is, instead of just drawing\nthese samples one",
    "start": "3230620",
    "end": "3235930"
  },
  {
    "text": "by one independent\nof each other, we actually maintain\na chain of samples. So the idea of a Markov\nchain is basically",
    "start": "3235930",
    "end": "3242410"
  },
  {
    "text": "just a chain where the\nnext sample in the chain depends on the previous\nsample in the chain.",
    "start": "3242410",
    "end": "3248710"
  },
  {
    "text": "And so what we do is we start\nwith some initial sample. We just need to pick something. So we start with some\ninitial sample for tau.",
    "start": "3248710",
    "end": "3254365"
  },
  {
    "text": "And then we build out a\nchain where the next sample-- I haven't told you how. But depends on the previous\nsample, then we do that again.",
    "start": "3254365",
    "end": "3261990"
  },
  {
    "text": "And we repeat this process\nto get this very long chain. And then once we\nhave this chain,",
    "start": "3261990",
    "end": "3268680"
  },
  {
    "text": "we can do a similar\nthing as before. We just take all\nof those samples. And it turns out that the\nsamples in this chain,",
    "start": "3268680",
    "end": "3274270"
  },
  {
    "text": "if we drop them all\ndown again, will be distributed according\nto the distribution that we were trying to sample from.",
    "start": "3274270",
    "end": "3281050"
  },
  {
    "text": "So I haven't told you how\nany of that works yet. But that's kind of what\nwe're heading towards.",
    "start": "3281050",
    "end": "3286540"
  },
  {
    "text": "So we basically\nwant to figure out how we can make this\nchain of samples such that when we're\ndone producing them, it will be distributed\naccording to this distribution.",
    "start": "3286540",
    "end": "3296730"
  },
  {
    "text": "So how do we actually go\nabout creating the chain? So we need to start with\nsome initial sample tau.",
    "start": "3296730",
    "end": "3301862"
  },
  {
    "text": "It does matter a little\nbit what we start with. But let's not worry\nabout that for now. So we're just going\nto say we start",
    "start": "3301862",
    "end": "3307368"
  },
  {
    "text": "with some initial\ntrajectory, initial sample. And then at each iteration\nof the algorithm,",
    "start": "3307368",
    "end": "3312710"
  },
  {
    "text": "we sample a new kind\nof proposed sample that we'll call tau prime from\nthis conditional distribution",
    "start": "3312710",
    "end": "3318740"
  },
  {
    "text": "that depends on tau. And this distribution is\noften called a kernel.",
    "start": "3318740",
    "end": "3324250"
  },
  {
    "text": "And to make it concrete,\na very common kernel is just like a Gaussian\ndistribution that's centered at the sample that we\ncurrently are at in the chain.",
    "start": "3324250",
    "end": "3331748"
  },
  {
    "text": "So it would look\nsomething like this. So we have our current sample. And we're going to\ndraw a new sample from a distribution that's\ncentered at our current sample.",
    "start": "3331748",
    "end": "3339970"
  },
  {
    "text": "So for example, maybe\nwe draw this sample, and this is our tau prime.",
    "start": "3339970",
    "end": "3345220"
  },
  {
    "text": "And then the next\nthing that we do is a similar idea with\nrejection sampling",
    "start": "3345220",
    "end": "3350900"
  },
  {
    "text": "but doesn't quite\nmap exactly the same. But we're going to accept this\nsample with some probability.",
    "start": "3350900",
    "end": "3356089"
  },
  {
    "text": "And that probability is\nspecifically this probability here, which depends on\nthe nominal target density",
    "start": "3356090",
    "end": "3362349"
  },
  {
    "text": "that we're trying to sample\nfrom in this kernel function. And I'm going to give you\nsome intuition for what's",
    "start": "3362350",
    "end": "3367710"
  },
  {
    "text": "going on here with this\nprobability in a second. But just to get an\nidea of the algorithm, we're going to accept with\nsome probability equal to this.",
    "start": "3367710",
    "end": "3378190"
  },
  {
    "text": "So then, we'll call\nrand or something to decide if we're going to\naccept it and accept according",
    "start": "3378190",
    "end": "3383280"
  },
  {
    "text": "to that probability. So let's say maybe we are\ngoing to accept this sample. So then this becomes our\nnext sample in the chain.",
    "start": "3383280",
    "end": "3390400"
  },
  {
    "text": "And then we just go back to\nour kernel, which is, again, this kind of Gaussian\ndistribution that's centered at our current sample.",
    "start": "3390400",
    "end": "3396640"
  },
  {
    "text": "We sample a new proposed sample. And then we decide whether\nor not to accept it according",
    "start": "3396640",
    "end": "3402810"
  },
  {
    "text": "to this probability here. Maybe this time,\nwe don't accept it so we just keep the current\nsample that we have.",
    "start": "3402810",
    "end": "3409588"
  },
  {
    "text": "And then we just\nrepeat this process. So maybe we accept that\nsample and so on and so on. And we build out this big chain.",
    "start": "3409588",
    "end": "3415510"
  },
  {
    "text": "And the crazy\nthing is once we're done with that, the samples\nin that chain are actually distributed according\nto the target density",
    "start": "3415510",
    "end": "3421530"
  },
  {
    "text": "that we were trying\nto sample from. ",
    "start": "3421530",
    "end": "3426610"
  },
  {
    "text": "And the cool thing\nis this process is actually guaranteed\nto converge to the target",
    "start": "3426610",
    "end": "3431740"
  },
  {
    "text": "distribution in the limit\nof infinite samples. So if we sampled forever, we\nwould get exactly the target",
    "start": "3431740",
    "end": "3438190"
  },
  {
    "text": "distribution that we're\ntrying to sample from. But like, what the heck\nis all of this magic?",
    "start": "3438190",
    "end": "3444549"
  },
  {
    "text": "How is any of this working? Why is this even like this? So I'm going to try to\ngive you some intuition",
    "start": "3444550",
    "end": "3449920"
  },
  {
    "text": "here because it's really not\ntoo crazy what's going on. So one thing I'm\nfirst going to say",
    "start": "3449920",
    "end": "3454960"
  },
  {
    "text": "is the kernel is often\nchosen to be symmetric, meaning that g of\ntau given tau prime is equal to g of\ntau prime given tau.",
    "start": "3454960",
    "end": "3463690"
  },
  {
    "text": "And so that means that\nthese two things are equal. So we can just cancel them out. So this might seem like\na weird crazy assumption.",
    "start": "3463690",
    "end": "3470030"
  },
  {
    "text": "There's an exercise that allows\nyou to show that it turns out like the Gaussian kernel I was\njust showing you is symmetric.",
    "start": "3470030",
    "end": "3475670"
  },
  {
    "text": "So it's not a weird thing. Most of the kernels are\nsymmetric so we can do this. But this allows us to simplify\nour acceptance probability.",
    "start": "3475670",
    "end": "3482750"
  },
  {
    "text": "So now, our\nacceptance probability is just the probability\ndensity of our new sample under the target\ndensity that we're",
    "start": "3482750",
    "end": "3489100"
  },
  {
    "text": "trying to sample from\ndivided by the probability density of our current sample.",
    "start": "3489100",
    "end": "3494650"
  },
  {
    "text": "And so just think,\nputting all of that aside, again, if I just handed\nyou a density function,",
    "start": "3494650",
    "end": "3501250"
  },
  {
    "text": "and I was like, here's\nwhat it looks like. And I told you to\njust draw some samples from it, more often,\nwould draw samples",
    "start": "3501250",
    "end": "3507280"
  },
  {
    "text": "from the areas of that\ndensity that are higher. And then less frequently, but\nevery once in a while, still,",
    "start": "3507280",
    "end": "3512415"
  },
  {
    "text": "you would draw\nsamples from parts of that density that are lower. And it turns out this\nacceptance criteria,",
    "start": "3512415",
    "end": "3518230"
  },
  {
    "text": "it forces that behavior. So there's two cases here. So the first case is that\nthe target density evaluated",
    "start": "3518230",
    "end": "3524890"
  },
  {
    "text": "at our proposed new\nsample is greater than the target density\nevaluated at our current sample.",
    "start": "3524890",
    "end": "3531339"
  },
  {
    "text": "And so in this\ncase, we're saying like tau prime is more\nlikely under the target density than the tau\nthat we're currently at.",
    "start": "3531340",
    "end": "3537640"
  },
  {
    "text": "And that's going to\nmake this fraction here. So this fraction here,\ngreater than or equal to 1.",
    "start": "3537640",
    "end": "3543130"
  },
  {
    "text": "So that means we're going to\naccept with probability greater than or equal to 1. Or in other words, we're always\ngoing to accept that sample.",
    "start": "3543130",
    "end": "3548609"
  },
  {
    "text": "So every time we get\na new proposed sample that has higher likelihood than\nthe one we're currently at, we're always going to accept it.",
    "start": "3548610",
    "end": "3555950"
  },
  {
    "text": "Now, the other case is that the\nnew sample has a lower target density than our current one.",
    "start": "3555950",
    "end": "3560970"
  },
  {
    "text": "So this is achieving the idea\nof we sample from a high density more often. And here, if it's lower,\nwe don't necessarily",
    "start": "3560970",
    "end": "3567772"
  },
  {
    "text": "want to keep it because we want\nto sample from high density more often. But every once in a\nwhile, we do probably want to put in a lower\ndensity sample in there.",
    "start": "3567772",
    "end": "3575450"
  },
  {
    "text": "And so basically,\nwhat we're saying, tau prime is less likely\nunder the target density. So we're going to sample it or\naccept it with some probability",
    "start": "3575450",
    "end": "3582349"
  },
  {
    "text": "less than 1. And that probability is\nproportional to how much less likely it is. So if it's a lot less likely,\nthen there's still some chance",
    "start": "3582350",
    "end": "3590210"
  },
  {
    "text": "that we might accept\nit, but a small chance that we're going\nto accept that sample. And so that gives you\nsome intuition like what",
    "start": "3590210",
    "end": "3596870"
  },
  {
    "text": "this is hopefully\nachieving is that we sample from these high\ndensity areas more often, but we still\nsometimes get samples",
    "start": "3596870",
    "end": "3603059"
  },
  {
    "text": "from the lower density areas. This is in no way a\nproof that this works.",
    "start": "3603060",
    "end": "3609540"
  },
  {
    "text": "That's beyond the\nscope of this class. But hopefully, this\ndemystifies what some of the magic\nthat's going on here",
    "start": "3609540",
    "end": "3615720"
  },
  {
    "text": "is because that's really\nall that's happening. I'll pause there for questions.",
    "start": "3615720",
    "end": "3622839"
  },
  {
    "text": " Yep. So basically, the value\nof [INAUDIBLE] sample",
    "start": "3622840",
    "end": "3629460"
  },
  {
    "text": "create a probability\ndistribution about that. And then you sample based on\nthat to get your mean sample.",
    "start": "3629460",
    "end": "3636000"
  },
  {
    "text": "So the question was,\nbased on the value of your current sample,\nyou create a probability distribution around that. So there's this thing called\na kernel that tells you",
    "start": "3636000",
    "end": "3643260"
  },
  {
    "text": "how you want to do that. So a common one\nis a Gaussian one where you just create a\nGaussian distribution around it,",
    "start": "3643260",
    "end": "3648750"
  },
  {
    "text": "and then draw a new\nsample from that. And then the next step is\nto decide whether or not you want to accept that new\nsample and add it to your chain,",
    "start": "3648750",
    "end": "3655810"
  },
  {
    "text": "or whether you want to stay\nat your current sample. And basically, we want to\naccept samples that are likely,",
    "start": "3655810",
    "end": "3661380"
  },
  {
    "text": "according to our target\ndensity, more often than we accept samples that are\nunlikely according to our target density.",
    "start": "3661380",
    "end": "3667770"
  },
  {
    "text": "But the target is not the\nprobability distribution about [INAUDIBLE].",
    "start": "3667770",
    "end": "3673542"
  },
  {
    "text": "No, the probability distribution\nabout the old sample is just a way to get us a new\nproposed sample for our chain.",
    "start": "3673542",
    "end": "3679013"
  },
  {
    "start": "3679013",
    "end": "3684106"
  },
  {
    "text": "Another question? Yeah. I think you're going to\ntalk about this later. But could you talk\na little bit more",
    "start": "3684106",
    "end": "3691080"
  },
  {
    "text": "about how [INAUDIBLE] point\nwith that [INAUDIBLE]? ",
    "start": "3691080",
    "end": "3697510"
  },
  {
    "text": "I'll save it for later,\nactually, just to save time. But yeah, good question. ",
    "start": "3697510",
    "end": "3704700"
  },
  {
    "text": "So maybe some of you are\nstill scratching your head. So let's see what this looks\nlike in a Pluto Notebook.",
    "start": "3704700",
    "end": "3712500"
  },
  {
    "text": "So let me explain\nthese plots here. ",
    "start": "3712500",
    "end": "3719109"
  },
  {
    "text": "So this first plot\nhere, so we just have one sample in\nour chain right now. So this is the initial sample\nthat we decided to start with.",
    "start": "3719110",
    "end": "3727762"
  },
  {
    "text": "And so this plot\nhere is just going to show the chain over time the\nsame way we were building it up before.",
    "start": "3727762",
    "end": "3733059"
  },
  {
    "text": "And this is showing\nalso our failure region. So we're trying to sample\nfrom this region here.",
    "start": "3733060",
    "end": "3738220"
  },
  {
    "text": "The second plot here is going\nto show the current sample, the proposed sample. So we're using this\nkind of Gaussian kernel.",
    "start": "3738220",
    "end": "3744020"
  },
  {
    "text": "And our proposed next\nsample is actually unlikely. We got a sample like\nall the way out here, according to that distribution.",
    "start": "3744020",
    "end": "3749480"
  },
  {
    "text": "And then this is\nthe target density that we're trying to sample\nfrom on the same plot. And then this plot\ndown here is going",
    "start": "3749480",
    "end": "3758230"
  },
  {
    "text": "to show a histogram as\nwe add more samples to it of all the samples that we've\nseen compared to our target density, so above\nwhat we were doing.",
    "start": "3758230",
    "end": "3765580"
  },
  {
    "text": "So let's go to the next sample. But before we do\nthat, can anyone tell me whether we're\ngoing to accept or reject",
    "start": "3765580",
    "end": "3772880"
  },
  {
    "text": "this new proposed sample? [INAUDIBLE]",
    "start": "3772880",
    "end": "3778130"
  },
  {
    "text": "Yeah, as we're\nsaying, like down. Yeah, we're going to reject it. And the reason for\nthat is the probability",
    "start": "3778130",
    "end": "3784160"
  },
  {
    "text": "density or the target density\nof our new sample is actually 0. So we're trying to sample\nfrom this density here.",
    "start": "3784160",
    "end": "3790350"
  },
  {
    "text": "And we're only going to-- so [INAUDIBLE] sample\nwith probability 1 if it's more likely. So it's definitely\nnot more likely.",
    "start": "3790350",
    "end": "3796490"
  },
  {
    "text": "It's 0. And if it's less likely,\nwe're going to sample with the ratio of\nthe new likelihood to the old likelihood.",
    "start": "3796490",
    "end": "3802410"
  },
  {
    "text": "The new likelihood is 0. So we're going to\nhave 0 probability that we accept this sample.",
    "start": "3802410",
    "end": "3807980"
  },
  {
    "text": "So then, if we go to\niteration two here, you'll see we stayed at\nthe same exact sample.",
    "start": "3807980",
    "end": "3814010"
  },
  {
    "text": "So now, there's a chance that\nwe'll accept this sample. And this bar over here\nis actually showing us",
    "start": "3814010",
    "end": "3819050"
  },
  {
    "text": "how big that chance is. So this is 0 and 1. So we have a small chance that\nwe'll accept this new sample",
    "start": "3819050",
    "end": "3824119"
  },
  {
    "text": "because it is much less\nlikely than this one according to our target density. But there's still\na non-zero chance.",
    "start": "3824120",
    "end": "3831950"
  },
  {
    "text": "So we can go to the next one. Turns out we didn't accept it. Now, they're almost\non top of each other so we probably do accept it.",
    "start": "3831950",
    "end": "3838559"
  },
  {
    "text": "And we can just do\nthis for a while and build out this\nreally big chain. And we're not quite looking\nlike the target density",
    "start": "3838560",
    "end": "3845150"
  },
  {
    "text": "just yet after a few samples. But after a while,\nthis chain is actually going to cause the\nsamples to start",
    "start": "3845150",
    "end": "3851840"
  },
  {
    "text": "being distributed according\nto this target density. So let's just move\nalong a little bit here.",
    "start": "3851840",
    "end": "3860030"
  },
  {
    "text": "So we build out this big chain. Just bring that out here. So here's our big\nchain that we created.",
    "start": "3860030",
    "end": "3865543"
  },
  {
    "text": "And it turns out if you\nplot all of the samples that were in this chain, you\nget this nice histogram that looks like the target we\nwere trying to sample from.",
    "start": "3865543",
    "end": "3873230"
  },
  {
    "text": "Kind of insane. I don't know. Blows my mind.",
    "start": "3873230",
    "end": "3878690"
  },
  {
    "text": "So I think that's all I\nwanted to show for that part.",
    "start": "3878690",
    "end": "3884030"
  },
  {
    "text": "Yes? So [INAUDIBLE] just the\nbig picture goal again, are we trying to find\nessentially that--",
    "start": "3884030",
    "end": "3889805"
  },
  {
    "text": "in the very\nbeginning of lecture, that it's scaled up\ndistribution of the red curve?",
    "start": "3889805",
    "end": "3896925"
  },
  {
    "text": "So the question is, are we\ntrying to find that one? So we can't compute that\none without computing the normalizing constant.",
    "start": "3896925",
    "end": "3903609"
  },
  {
    "text": "But we can draw\nsamples from it though. So the samples will be\ndistributed as if they",
    "start": "3903610",
    "end": "3909059"
  },
  {
    "text": "came from that distribution. But we can't calculate what\nthe actual density of that is. ",
    "start": "3909060",
    "end": "3916050"
  },
  {
    "text": "Yeah. Let's say I want to use\nthis in the project, and I want to get really high\nefficiency in the rejection",
    "start": "3916050",
    "end": "3924390"
  },
  {
    "text": "sampling. Our space of choices was how to\ndesign the proposal distribution",
    "start": "3924390",
    "end": "3930750"
  },
  {
    "text": "and getting a nice proposal\ndistribution gives you efficient sampling. And here was our design space.",
    "start": "3930750",
    "end": "3936759"
  },
  {
    "text": "Is it just what's\nkind of a Gaussian, why do we want to make it?",
    "start": "3936760",
    "end": "3942430"
  },
  {
    "text": "And if we want to take maybe\na non-Gaussian distribution, is this kind of our option? Yeah, kind of. I'm going to talk\nabout that shortly.",
    "start": "3942430",
    "end": "3948512"
  },
  {
    "text": "So you can greatly improve\nthis kernel that we're using",
    "start": "3948512",
    "end": "3953830"
  },
  {
    "text": "and do some other things. You mentioned that the\nGaussian kernel is symmetric. And I guess it's useful.",
    "start": "3953830",
    "end": "3959339"
  },
  {
    "text": "But could we also take\nthe non-symmetric kernel? Yeah, you can take a\nnon-symmetric kernel. It just won't reduce to that. So if you remember the\noriginal acceptance criteria",
    "start": "3959340",
    "end": "3966255"
  },
  {
    "text": "I had was p tau times g\nover p times g or whatever. That g won't go away. But you can still have a\nnon-symmetric kernel, yeah.",
    "start": "3966255",
    "end": "3973059"
  },
  {
    "start": "3973060",
    "end": "3979180"
  },
  {
    "text": "So we saw that as we increase\nthe number of samples, we get this distribution\nthat we want. But here's the catch here,\nwhich is this all works.",
    "start": "3979180",
    "end": "3988670"
  },
  {
    "text": "So it seems amazing. It all converges to the\ntarget distribution. But there was this\nextra thing I said,",
    "start": "3988670",
    "end": "3994003"
  },
  {
    "text": "which is in the limit\nof infinite samples. And we don't have time for that. So we don't have time to draw\ninfinite samples, unfortunately.",
    "start": "3994003",
    "end": "4002349"
  },
  {
    "text": "And so there's a lot of\nheuristics and things people use in practice. Because no matter what\nkernel or whatever you use,",
    "start": "4002350",
    "end": "4007890"
  },
  {
    "text": "it's going to converge\nto the thing you want in the limit\nof infinite samples. But we don't really want to\ntry to draw infinite samples.",
    "start": "4007890",
    "end": "4013930"
  },
  {
    "text": "And so we need to do some\nthings to make this work more efficiently or perform better\nwhen we don't have that.",
    "start": "4013930",
    "end": "4020970"
  },
  {
    "text": "So again, we deploy these\nextra tricks in practice to make it perform better.",
    "start": "4020970",
    "end": "4026260"
  },
  {
    "text": "So let me go back to\nthis Pluto Notebook to explain what I'm saying.",
    "start": "4026260",
    "end": "4032165"
  },
  {
    "text": "And so here, we're\nactually going to get back to talking\nabout the initial sample that we start with. So here, we started\nwith an initial sample",
    "start": "4032165",
    "end": "4039090"
  },
  {
    "text": "that's in the failure region. Let me zoom this back in again. ",
    "start": "4039090",
    "end": "4045119"
  },
  {
    "text": "Let's go back. Let's say now that we start\nwith an initial sample that's outside of the failure region.",
    "start": "4045120",
    "end": "4051100"
  },
  {
    "text": "So maybe it's got a\nvalue of 1 or something. So now, we start with\nthis initial sample.",
    "start": "4051100",
    "end": "4058599"
  },
  {
    "text": "Here's our new proposed sample. They both have zero likelihood. So we're not going to\naccept the new one.",
    "start": "4058600",
    "end": "4065030"
  },
  {
    "text": "And we're stuck at this bad\ninitial sample that we picked. And it's going to\ntake us a while. We're not going to accept a new\nsample until we get something",
    "start": "4065030",
    "end": "4072099"
  },
  {
    "text": "from our proposal that's\nin this failure region. And so what's going\nto happen here",
    "start": "4072100",
    "end": "4079089"
  },
  {
    "text": "is we're going to get this\nkind of period of time where things aren't\nreally looking so good. And we have this random extra\npeak of our distribution",
    "start": "4079090",
    "end": "4085510"
  },
  {
    "text": "out here. And the limit of\ninfinite samples, this will look like\nzero samples at all. But right now, it\ndoesn't look like that.",
    "start": "4085510",
    "end": "4092240"
  },
  {
    "text": "And so that's not super great. And in general, at\nthe beginning of MCMC, depending on where we\nstart, this doesn't always--",
    "start": "4092240",
    "end": "4099572"
  },
  {
    "text": "the first few\nsamples don't always really look like\nthe distribution that we're trying\nto sample from. And so a common\nthing people do is",
    "start": "4099573",
    "end": "4105609"
  },
  {
    "text": "they say there's\nthis burn in period. We're just going to throw out\nthe first however many samples. So for example, let's just\nsay we want to throw out",
    "start": "4105609",
    "end": "4112509"
  },
  {
    "text": "like the first 20 samples. So we threw out all the\nsamples in this region. That got rid of that.",
    "start": "4112510",
    "end": "4117769"
  },
  {
    "text": "And now, we can just draw\nthe rest of our samples, and everything looks\nreasonable from there.",
    "start": "4117770",
    "end": "4124134"
  },
  {
    "text": " I think that's all I\nwanted to say on that.",
    "start": "4124135",
    "end": "4130020"
  },
  {
    "text": "Yeah? But [INAUDIBLE] that's outside\nof the failure distribution. So if we just kept sampling,\nwouldn't it even out?",
    "start": "4130020",
    "end": "4137270"
  },
  {
    "text": "Yep. So the question was,\nwe're never going to get something from outside\nthe failure distribution. Yeah, that's only if we start\nin the failure distribution.",
    "start": "4137270",
    "end": "4143790"
  },
  {
    "text": "But in general, thinking of\njust non-failure in general,",
    "start": "4143790",
    "end": "4149540"
  },
  {
    "text": "depending on where we start, we\nmight not get great performance at the beginning. But, yeah.",
    "start": "4149540",
    "end": "4156140"
  },
  {
    "text": "So one of the things, tricks\nthat we do to make this better when we don't have infinite\nsamples is this burn in period",
    "start": "4156140",
    "end": "4161810"
  },
  {
    "text": "that I was talking about. Another common thing people do--\nso one kind of interesting thing is that because it's\nthis Markov chain",
    "start": "4161810",
    "end": "4168140"
  },
  {
    "text": "and the next sample depends\non the previous sample, the samples are actually\ncorrelated with one another.",
    "start": "4168140",
    "end": "4173778"
  },
  {
    "text": "And so a common thing people do\nis this thing called thinning where they'll just keep every,\nfor example, fifth sample,",
    "start": "4173779",
    "end": "4179189"
  },
  {
    "text": "every 10th sample, whatever\nto get rid of that correlation as best as they can.",
    "start": "4179189",
    "end": "4184318"
  },
  {
    "text": "And then finally, there's\nthis thing called smoothing. So let me go back to\nthe Pluto Notebook and explain this again and show\nyou what the problem is here.",
    "start": "4184319",
    "end": "4193229"
  },
  {
    "text": "So let's now imagine that we\nhave multiple failure modes. So now, we're saying that our\ndistribution or our sample",
    "start": "4193229",
    "end": "4201800"
  },
  {
    "text": "is going to be a failure if we\nsample something that's too low and also if we sample\nsomething that's too high.",
    "start": "4201800",
    "end": "4207240"
  },
  {
    "text": "So we have these two distinct\nfailure modes, and then 0 likelihood for our failure\ndistribution in the middle.",
    "start": "4207240",
    "end": "4213620"
  },
  {
    "text": "And then let's see\nnow what happens if we try to apply MCMC to this. ",
    "start": "4213620",
    "end": "4220880"
  },
  {
    "text": "So can anyone guess-- so what went wrong is\nwe only ever got samples from this failure mode.",
    "start": "4220880",
    "end": "4227719"
  },
  {
    "text": "Can anyone guess\nwhy this happened or what might be going on here? ",
    "start": "4227720",
    "end": "4234200"
  },
  {
    "text": "Yeah. Well, assuming that the g\ndistribution perturb only in a small amount. It's really hard to perturb your\nway all the way to the right.",
    "start": "4234200",
    "end": "4241180"
  },
  {
    "text": "Yep, that's exactly right. So you're saying, this only\nperturbs it a small amount. So how are we going to perturb\nourself all the way over",
    "start": "4241180",
    "end": "4248040"
  },
  {
    "text": "to this failure mode? And even if you just look at\nthis example at the end right here, here's our current sample.",
    "start": "4248040",
    "end": "4253929"
  },
  {
    "text": "Here's the distribution\nover possible next samples that we're going to get. There's a very low likelihood\nthat our next sample is going",
    "start": "4253930",
    "end": "4261150"
  },
  {
    "text": "to be all the way over here. So that's the issue.",
    "start": "4261150",
    "end": "4266760"
  },
  {
    "text": "Eventually, in the limit\nof infinite samples, this would eventually\nactually happen. And we would jump over\nto this failure mode,",
    "start": "4266760",
    "end": "4272623"
  },
  {
    "text": "and then maybe we'd jump back\nas we sample for infinity. But since we, again, don't\nhave time to do that,",
    "start": "4272623",
    "end": "4278340"
  },
  {
    "text": "we need to come up\nwith a better way. So that motivates this\nthing called smoothing.",
    "start": "4278340",
    "end": "4285656"
  },
  {
    "text": " And the idea here is that we\nneed to help the algorithm move",
    "start": "4285656",
    "end": "4293670"
  },
  {
    "text": "in between these failure modes. Because it's very unlikely that\nit'll just do it on its own.",
    "start": "4293670",
    "end": "4299260"
  },
  {
    "text": "And we can do this by\nkind of smoothing out the failure distribution. So these zero positions\nhere, we maybe",
    "start": "4299260",
    "end": "4304510"
  },
  {
    "text": "want to make them\nslightly non-zero. And so the way we do this is we\ndefine this distance function",
    "start": "4304510",
    "end": "4312250"
  },
  {
    "text": "that we'll call delta of tau. And this distance function\nis just a function that's 0 if tau is a failure.",
    "start": "4312250",
    "end": "4318290"
  },
  {
    "text": "So it's like\ndistance to failure. If you are a failure, it's 0. And then it's greater\nthan 0 otherwise.",
    "start": "4318290",
    "end": "4323870"
  },
  {
    "text": "And it should get closer to 0\nas you get closer to a failure. One really easy\nway to do that is",
    "start": "4323870",
    "end": "4329830"
  },
  {
    "text": "to just take the max of our\nrobustness function with 0. So if it's a success,\nour robustness",
    "start": "4329830",
    "end": "4335289"
  },
  {
    "text": "will get lower and lower as\nit gets closer to failure. And if it's a\nfailure, robustness will be negative so we'll\njust return 0 in that case.",
    "start": "4335290",
    "end": "4342350"
  },
  {
    "text": "So that's one really easy way\nto get this distance function. And so then we can rewrite\nthis unnormalized density here.",
    "start": "4342350",
    "end": "4350000"
  },
  {
    "text": "So before we had this\nindicator function that says it evaluates\nto 1 if tau is not--",
    "start": "4350000",
    "end": "4355880"
  },
  {
    "text": "or if tau is not in\nthe specification, if tau is a failure. And we can say, now, we\nknow if it's a failure,",
    "start": "4355880",
    "end": "4361130"
  },
  {
    "text": "then that means that this\ndistance evaluates to 0. So we can just\nreplace that condition with this distance\nbeing equal to 0.",
    "start": "4361130",
    "end": "4367949"
  },
  {
    "text": " And so, now, we can\nthink about this.",
    "start": "4367950",
    "end": "4374170"
  },
  {
    "text": "That's not supposed to\nhave a p of tau there. That's not supposed to be there.",
    "start": "4374170",
    "end": "4379719"
  },
  {
    "text": "This indicator\nfunction is actually kind of similar to a\nnormal distribution",
    "start": "4379720",
    "end": "4384970"
  },
  {
    "text": "with a tiny variance. So you can think\nabout it like this. So when delta tau is 0, the\nindicator function returns 1.",
    "start": "4384970",
    "end": "4391940"
  },
  {
    "text": "Otherwise, it always returns 0. We can say that's similar\nto this distribution that's",
    "start": "4391940",
    "end": "4397030"
  },
  {
    "text": "centered at 0 with\nsome tiny variance. But not quite the\nsame because now we're assigning non-zero values\nto values that are not 0.",
    "start": "4397030",
    "end": "4407080"
  },
  {
    "text": "So then, what we could\ndo to smooth things out is we could just take\nthis indicator function and replace it with\nthis normal distribution",
    "start": "4407080",
    "end": "4414740"
  },
  {
    "text": "with this tiny variance. And so now, this\nsmooth distribution",
    "start": "4414740",
    "end": "4419750"
  },
  {
    "text": "will assign non-zero\nprobability to successes with higher probabilities\nfor successes that are closer to failure.",
    "start": "4419750",
    "end": "4426140"
  },
  {
    "text": "So I'll show visually what\nthis looks like in a second to get more intuition here. But one more thing to note\nis this parameter epsilon",
    "start": "4426140",
    "end": "4433820"
  },
  {
    "text": "allows us to control how much\nsmoothing we're applying. So if it's 0, we're back\nto our indicator function.",
    "start": "4433820",
    "end": "4440670"
  },
  {
    "text": "We have no smoothing. As it approaches\ninfinity, you can imagine a normal distribution\nwith infinite variance,",
    "start": "4440670",
    "end": "4447800"
  },
  {
    "text": "almost looks like a uniform\ndistribution at that point. It's super wide. And so this almost just turns\ninto a uniform distribution.",
    "start": "4447800",
    "end": "4453660"
  },
  {
    "text": "And this just turns\ninto p of tau. So it actually approaches the\nnominal trajectory distribution when it's equal to infinity.",
    "start": "4453660",
    "end": "4460156"
  },
  {
    "text": " I'm just going to go\nthrough this really fast.",
    "start": "4460156",
    "end": "4466110"
  },
  {
    "text": "And I'll go through it again\nat the beginning of lecture because I just want you guys to\nsee it before this lecture ends in two minutes. So what we now have a bunch of\nsamples that are not failures.",
    "start": "4466110",
    "end": "4473610"
  },
  {
    "text": "Yes, but we can\njust reject them, and we'll be left with samples\nfrom the failure distribution. And you can actually\nthink of this",
    "start": "4473610",
    "end": "4479107"
  },
  {
    "text": "as just doing rejection sampling\nwith our smooth distribution as the proposal distribution,\nwhich is pretty cool.",
    "start": "4479107",
    "end": "4485400"
  },
  {
    "text": "And let me just show\nyou this cool animation to incentivize you to come\nback after the weekend. And I'll explain how\nit actually works.",
    "start": "4485400",
    "end": "4492270"
  },
  {
    "text": "So here's with a small\namount of smoothing. We still don't get this\nextra failure mode. You can see this\nsmooth distribution.",
    "start": "4492270",
    "end": "4498679"
  },
  {
    "text": "If we increase the amount of\nsmoothing-- let's go here. ",
    "start": "4498680",
    "end": "4504168"
  },
  {
    "text": "If we increase the amount\nof smoothing you'll see it actually starts to jump back\nand forth between failure modes.",
    "start": "4504168",
    "end": "4509430"
  },
  {
    "text": "And this is that smooth failure\ndistribution we end up with. And then we get a nice set of\nsamples from both failure modes.",
    "start": "4509430",
    "end": "4518639"
  },
  {
    "text": "Yeah, we'll talk more\nabout that on Tuesday. ",
    "start": "4518640",
    "end": "4528000"
  }
]
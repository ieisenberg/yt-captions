[
  {
    "start": "0",
    "end": "5440"
  },
  {
    "text": "Cool. So the plan for\ntoday is to continue talking about\nenergy-based models, which",
    "start": "5440",
    "end": "12507"
  },
  {
    "text": "is going to provide a\nlot of the foundation also to discuss score-based\nmodels and diffusion models.",
    "start": "12508",
    "end": "18710"
  },
  {
    "text": "Just as a recap, this\nis our usual slide providing an overview of all\nthe different things we've",
    "start": "18710",
    "end": "26090"
  },
  {
    "text": "been discussing in\nthis course so far. Energy-based models\nprovide you yet another way",
    "start": "26090",
    "end": "33920"
  },
  {
    "text": "of defining a very broad set\nof probability distributions and expanding that green\nset which potentially",
    "start": "33920",
    "end": "44930"
  },
  {
    "text": "would allow you to get closer\nto the true data distribution. The nice thing about\nenergy-based models",
    "start": "44930",
    "end": "51680"
  },
  {
    "text": "is that they are\ndefined in terms of this energy function f theta\nwhich can basically be anything.",
    "start": "51680",
    "end": "59880"
  },
  {
    "text": "So you can pick whatever neural\nnetwork architecture you want. And by using the expression\nthat you see there,",
    "start": "59880",
    "end": "68240"
  },
  {
    "text": "you get a valid\nprobabilistic model where essentially, you can get\nthe likelihood of a data point",
    "start": "68240",
    "end": "75080"
  },
  {
    "text": "by looking at the unnormalized\nprobability, which is what you get in the\nnumerator of that expression",
    "start": "75080",
    "end": "80659"
  },
  {
    "text": "and then dividing by the total\nlike unnormalized probability that exists And so\nwhich is just the sum",
    "start": "80660",
    "end": "87980"
  },
  {
    "text": "of the numerator over all\npossible things that can happen. So probabilities are defined\nrelatively to this partition",
    "start": "87980",
    "end": "97220"
  },
  {
    "text": "function, normalization\nconstant which depends on the parameters of the model. That's the crucial thing.",
    "start": "97220",
    "end": "104190"
  },
  {
    "text": "And the problem is that\ntypically evaluating Z theta is intractable because\nwe are interested",
    "start": "104190",
    "end": "112439"
  },
  {
    "text": "in modeling random variables. So multiple random\nvariables or random vectors",
    "start": "112440",
    "end": "117570"
  },
  {
    "text": "x with many\ndifferent components, which means that there is a\nhuge number of possible x's",
    "start": "117570",
    "end": "124020"
  },
  {
    "text": "that you would have to\nconsider in order to compute the normalization constant. Which means that evaluating the\nprobabilities of data points",
    "start": "124020",
    "end": "133650"
  },
  {
    "text": "is generally going\nto be intractable. You can always evaluate\nthe numerator very easily but it's very hard to\nevaluate the denominator",
    "start": "133650",
    "end": "140400"
  },
  {
    "text": "in that expression. And the good thing\nis that comparing",
    "start": "140400",
    "end": "145920"
  },
  {
    "text": "the probabilities of two\ndata points is actually easy. And this is important\nfor sampling. So if you want to know you\nhave an x and an x prime,",
    "start": "145920",
    "end": "153880"
  },
  {
    "text": "which could be two\nimages, for example, you cannot easily evaluate\nhow likely is any of the two",
    "start": "153880",
    "end": "160590"
  },
  {
    "text": "according to the model. But it's easy to\nfigure out which one is more likely because the\nratios of two probabilities",
    "start": "160590",
    "end": "167620"
  },
  {
    "text": "when you take the ratio,\nbasically the two normalization constants, they cancel. And so it's easy to evaluate\nthat expression in terms",
    "start": "167620",
    "end": "175300"
  },
  {
    "text": "of whatever energy\nfunction, whatever neural network you use\nto represent f theta.",
    "start": "175300",
    "end": "181220"
  },
  {
    "text": "And the price you pay is\nthat once again, evaluating",
    "start": "181220",
    "end": "188420"
  },
  {
    "text": "likelihoods is expensive. And so if you wanted to train\nthe model by maximum likelihood,",
    "start": "188420",
    "end": "193790"
  },
  {
    "text": "you would need to somehow be\nable to evaluate for every data point this expression or the\nlog of this expression, which",
    "start": "193790",
    "end": "202069"
  },
  {
    "text": "would be something like this. And the problem is that you have\ntwo terms that depend on theta.",
    "start": "202070",
    "end": "207900"
  },
  {
    "text": "And so whenever you want to\nfigure out how to adjust theta or how to pick theta to maximize\nthe probability of a training",
    "start": "207900",
    "end": "214280"
  },
  {
    "text": "data point, you\nneed to figure out how to adjust the parameters\nof your neural network to increase the numerator,\nthe unnormalized probability",
    "start": "214280",
    "end": "222800"
  },
  {
    "text": "of this training data\npoint, which is always easy. But then you have to worry about\nhow does changing theta affect",
    "start": "222800",
    "end": "228770"
  },
  {
    "text": "the normalization constant. So by how much are you changing\nthe probabilities of everything else that could have happened.",
    "start": "228770",
    "end": "236210"
  },
  {
    "text": "And so you need to figure out\nhow to change theta so that this increases while the partition\nfunction the log normalization",
    "start": "236210",
    "end": "243959"
  },
  {
    "text": "constant ideally also goes down. So that the relative\nimportance, the relative weight",
    "start": "243960",
    "end": "249360"
  },
  {
    "text": "of this training data point\ngoes up as much as possible. Again, doing this\nis hard because we",
    "start": "249360",
    "end": "255269"
  },
  {
    "text": "don't know how to evaluate the\nnormalization constant exactly. So it's different from a\nlikelihood-based model,",
    "start": "255270",
    "end": "263430"
  },
  {
    "text": "like an autoregressive model\nwhere this partition function Z theta is guaranteed\nto be 1 regardless",
    "start": "263430",
    "end": "268920"
  },
  {
    "text": "of how you choose the\nparameters of your conditionals, for example. In which case, you don't\nhave to worry about",
    "start": "268920",
    "end": "275260"
  },
  {
    "text": "if you were to change\nsome parameters in your neural network, how does\nthe partition function change",
    "start": "275260",
    "end": "281940"
  },
  {
    "text": "because it's\nconstructed by design to be 1 regardless of how\nyou choose your parameters.",
    "start": "281940",
    "end": "286990"
  },
  {
    "text": "So you basically only\nhave the first term when you train an autoregressive\nmodel and it's easy to optimize",
    "start": "286990",
    "end": "293910"
  },
  {
    "text": "and you don't have the\nissues that we have here. What we've seen is that it's\nrelatively straightforward",
    "start": "293910",
    "end": "300930"
  },
  {
    "text": "to come up with a\nsample based way",
    "start": "300930",
    "end": "308570"
  },
  {
    "text": "of describing an approximation\nof the log partition function.",
    "start": "308570",
    "end": "314480"
  },
  {
    "text": "And in particular,\nwe've seen that there is this contrastive divergence\nalgorithm that will give us",
    "start": "314480",
    "end": "321350"
  },
  {
    "text": "a way of evaluating gradients\nof the log likelihoods, which is what you will need\nif you wanted to update",
    "start": "321350",
    "end": "328490"
  },
  {
    "text": "your parameters to maximize the\nprobability of a data point, you will need to evaluate the\ngradient of this expression",
    "start": "328490",
    "end": "334520"
  },
  {
    "text": "here that we're maximizing. And it turns out that\nit's not too hard actually to figure out how the\ngradient of the log partition",
    "start": "334520",
    "end": "342500"
  },
  {
    "text": "function, how the log\npartition function changes as a function of theta or\nwhat's the gradient of the log",
    "start": "342500",
    "end": "348440"
  },
  {
    "text": "partition function\nif you have access to samples from the model. And so if you can somehow\nsample from the model, which",
    "start": "348440",
    "end": "357942"
  },
  {
    "text": "we know unfortunately,\nis also relatively hard. But if you have access\nto samples from the model then you can figure out--",
    "start": "357942",
    "end": "364069"
  },
  {
    "text": "you can get an estimate for the\ngradient of what you care about by basically looking at\nthe gradient of the energy",
    "start": "364070",
    "end": "370850"
  },
  {
    "text": "on the training data\nversus the gradient of the energy on\nthe samples that you",
    "start": "370850",
    "end": "376370"
  },
  {
    "text": "generate from your model. So this is a fairly\nintuitive explanation",
    "start": "376370",
    "end": "382760"
  },
  {
    "text": "where we're saying\nis, we're trying to figure out in which direction\nwe should now update theta to increase the probability\nof the training data,",
    "start": "382760",
    "end": "391400"
  },
  {
    "text": "we're decreasing\nthe probability of some alternative fake\nsynthetic data that",
    "start": "391400",
    "end": "398960"
  },
  {
    "text": "is produced by our model. And by doing that, you're\nactually figuring out",
    "start": "398960",
    "end": "406160"
  },
  {
    "text": "how the log partition\nfunction changes as a function of theta, that's\nthe right expression, so to the extent that you\ncan generate samples",
    "start": "406160",
    "end": "412639"
  },
  {
    "text": "from your model. Then you have this\ncontrastive divergence. And it's contrastive because\nyou're comparing or contrasting",
    "start": "412640",
    "end": "418800"
  },
  {
    "text": "the real data from and you're\ncontrasting two samples from the model. And so you just\nneed to figure out",
    "start": "418800",
    "end": "425280"
  },
  {
    "text": "how to adjust your parameters\nto basically by following",
    "start": "425280",
    "end": "432990"
  },
  {
    "text": "that expression that\ncontrasts real data to fake samples from the model.",
    "start": "432990",
    "end": "438590"
  },
  {
    "text": "So the gradient of log Z theta\nwould be the figuring out if you were to change the\nparameters by a little bit,",
    "start": "438590",
    "end": "444729"
  },
  {
    "text": "how does the partition\nfunction change. So how does the total\nunnormalized probability",
    "start": "444730",
    "end": "450370"
  },
  {
    "text": "that you have change. So if you remember the\nanalogy of the cake that we're dividing\nup into slices,",
    "start": "450370",
    "end": "457060"
  },
  {
    "text": "this term is basically saying,\nwhat is the size of the slice",
    "start": "457060",
    "end": "462280"
  },
  {
    "text": "that we assign to a\nparticular data point. The other term is\ntelling you how much does the size of the\nwhole cake changes.",
    "start": "462280",
    "end": "469510"
  },
  {
    "text": "And because everything\nis relative to the size, you have to figure\nout that to figure out",
    "start": "469510",
    "end": "475450"
  },
  {
    "text": "how to push up the\nprobability of a data point. Because it's not the size\nof the slice that matters, it's the relative\nsize of the slice",
    "start": "475450",
    "end": "481780"
  },
  {
    "text": "versus the total\ncake, the total amount of unnormalized probability. And this is the gradient of\nthe log partition function",
    "start": "481780",
    "end": "489139"
  },
  {
    "text": "which we can approximate\nwith samples basically. [INAUDIBLE]",
    "start": "489140",
    "end": "494410"
  },
  {
    "text": "The log partition\nfunction would be the log of this size of\nthe whole cake basically.",
    "start": "494410",
    "end": "501919"
  },
  {
    "text": "Cool. So that was the recap. And so training energy-based\nmodels by maximum likelihood",
    "start": "501920",
    "end": "510800"
  },
  {
    "text": "is feasible to the extent\nthat you can generate samples. And we've seen one recipe\nfor generating samples",
    "start": "510800",
    "end": "518419"
  },
  {
    "text": "from an energy-based model,\nwhich is this idea of setting up a Markov chain.",
    "start": "518419",
    "end": "523440"
  },
  {
    "text": "So using this technique called\nMarkov chain Monte Carlo, where essentially the way\nto generate a sample",
    "start": "523440",
    "end": "530270"
  },
  {
    "text": "is to initialize some\nprocedure by sampling x0",
    "start": "530270",
    "end": "539280"
  },
  {
    "text": "from some distribution. Turns out it doesn't\nmatter what that is. But if you think\nabout you're trying to sample a distribution\nover images,",
    "start": "539280",
    "end": "546150"
  },
  {
    "text": "you start with some\nimage, doesn't matter what that image is, at time 0.",
    "start": "546150",
    "end": "552300"
  },
  {
    "text": "And then you basically try to\nmake changes to this image, to this candidate sample that\nyou have to essentially try",
    "start": "552300",
    "end": "561270"
  },
  {
    "text": "to make it more likely. If you sample from this\ndistribution pi which you initialize your algorithm\nwith, this could be really bad.",
    "start": "561270",
    "end": "569399"
  },
  {
    "text": "It could be just set\nvalues of the variables uniformly at random. So you start with\npure noise and then",
    "start": "569400",
    "end": "576690"
  },
  {
    "text": "you need to figure\nout how to change the pixel values to go towards\nhigh probability regions.",
    "start": "576690",
    "end": "582390"
  },
  {
    "text": "And there is a\nprinciple way to do it, which basically\ninvolves trying to perturb, try to change your data\npoint a little bit.",
    "start": "582390",
    "end": "590070"
  },
  {
    "text": "If it's continuous, you\nmight want to add noise. If it's discrete,\nmaybe you change the value of a single\npixel, something like that.",
    "start": "590070",
    "end": "597920"
  },
  {
    "text": "Turns out can basically\ndo many different things and they all work.",
    "start": "597920",
    "end": "603519"
  },
  {
    "text": "And that way you propose\na new sample x prime. And then sometimes making this\nlittle change by adding noise",
    "start": "603520",
    "end": "612910"
  },
  {
    "text": "is good in the sense that you\ngo towards higher probability regions and sometimes it's not.",
    "start": "612910",
    "end": "618650"
  },
  {
    "text": "And so what the\nalgorithm does is it checks basically how good\nthis proposed sample is compared",
    "start": "618650",
    "end": "625780"
  },
  {
    "text": "to where you are right now. And remember, this is good\nbecause in an energy-based",
    "start": "625780",
    "end": "631300"
  },
  {
    "text": "model, although we cannot\nevaluate likelihoods, we can always compare\ntwo data points.",
    "start": "631300",
    "end": "636900"
  },
  {
    "text": "So we can always check\nwhether this sample x prime that we generate by making\nsome local small change",
    "start": "636900",
    "end": "643960"
  },
  {
    "text": "to the current best guess\nis better or worse than what we have. And if it's better, meaning that\nthe unnormalized probability",
    "start": "643960",
    "end": "652870"
  },
  {
    "text": "of x prime is larger than\na normalized probability that we have before we\ndid the perturbation,",
    "start": "652870",
    "end": "659110"
  },
  {
    "text": "then we accept the\ntransition and we say, OK, we're making progress. The state at time t plus\n1 is this new sample",
    "start": "659110",
    "end": "667899"
  },
  {
    "text": "x prime that we generated. And if not, then with some\nprobability, which depends on",
    "start": "667900",
    "end": "674080"
  },
  {
    "text": "basically how bad this\nproposed sample x prime is, we accept the\ntransition anyways.",
    "start": "674080",
    "end": "682200"
  },
  {
    "text": "So I mean the reason we're-- Adding noise is because we want\na new sample, which is much more",
    "start": "682200",
    "end": "688050"
  },
  {
    "text": "likely in our model. It can't be a\nguarantee that if we take the derivative of\nthe model with respect",
    "start": "688050",
    "end": "694440"
  },
  {
    "text": "to x and then learn that\ninstead of being noisy, would that be proper?",
    "start": "694440",
    "end": "700570"
  },
  {
    "text": "Yeah. So that's going to come up in\nthe next slide, where we're going to use the gradient\nof the energy of the theta",
    "start": "700570",
    "end": "708240"
  },
  {
    "text": "as a way to perturb\nthe sample basically. In general, this machinery works\nregardless of how you do it.",
    "start": "708240",
    "end": "716329"
  },
  {
    "text": "The reason and meaning\nthat in theory at least,",
    "start": "716330",
    "end": "721790"
  },
  {
    "text": "under some mild\nconditions on how you add noise, if\nyou were to repeat this procedure\nfor a sufficiently",
    "start": "721790",
    "end": "728840"
  },
  {
    "text": "large number of steps,\nwhat you get converges to a sample from the\ntrue energy-based model.",
    "start": "728840",
    "end": "737020"
  },
  {
    "text": "So you can picture\nthis in your head as some local search or some\nkind of stochastic hill climbing",
    "start": "737020",
    "end": "743760"
  },
  {
    "text": "procedure where\nyou're trying to go-- trying to move around this space\nof possible samples looking",
    "start": "743760",
    "end": "750600"
  },
  {
    "text": "for high probability regions. And the way you do it is you\nalways accept uphill moves",
    "start": "750600",
    "end": "757380"
  },
  {
    "text": "and with some small probability\nand occasionally, you accept downhill moves when\nthe height of the hill",
    "start": "757380",
    "end": "764399"
  },
  {
    "text": "would be the likelihood,\nor the log likelihood, or unnormalized log probability\nassigned by the model.",
    "start": "764400",
    "end": "772370"
  },
  {
    "text": "And the reason this works is\nbecause this operator satisfies",
    "start": "772370",
    "end": "778660"
  },
  {
    "text": "something called detailed\nbalance, meaning that if we",
    "start": "778660",
    "end": "784509"
  },
  {
    "text": "denote T x, x prime to be the\nprobability of transitioning from one state to\nanother state x prime,",
    "start": "784510",
    "end": "791980"
  },
  {
    "text": "we have the following\ncondition that the probability of being an x under\nthe true distribution",
    "start": "791980",
    "end": "797649"
  },
  {
    "text": "we're trying to sample from\nand transitioning to x prime is the same as the\nprobability of being",
    "start": "797650",
    "end": "802690"
  },
  {
    "text": "in x prime and doing the\nreverse move going back to x. You can see that this\nis true because one,",
    "start": "802690",
    "end": "813250"
  },
  {
    "text": "either x or x prime is\ngoing to have higher-- let's say x prime has\nhigher probability than x.",
    "start": "813250",
    "end": "818920"
  },
  {
    "text": "Then the transition from\nx to x prime is this T is 1 and the probability\nof going from x prime to x",
    "start": "818920",
    "end": "824950"
  },
  {
    "text": "is exactly the ratio of p theta\nx over p theta x prime, which is the probability with which\nwe accept a downhill move.",
    "start": "824950",
    "end": "833680"
  },
  {
    "text": "And it turns out that if\nthat condition is true, then basically p\ntheta is basically",
    "start": "833680",
    "end": "841240"
  },
  {
    "text": "a fixed point of\nthis kind of operator that we're using to\npropose new states.",
    "start": "841240",
    "end": "847670"
  },
  {
    "text": "Meaning that if at some point\nxt is distributed according",
    "start": "847670",
    "end": "853149"
  },
  {
    "text": "to p theta, then xt plus\n1 is also distributed according to p theta.",
    "start": "853150",
    "end": "859450"
  },
  {
    "text": "And what you can show is\nthat under some condition, you actually converge\nto this fixed point.",
    "start": "859450",
    "end": "866100"
  },
  {
    "text": "So p theta is a fixed point\nof this sort of operator and you get there regardless\nof where you start from.",
    "start": "866100",
    "end": "873550"
  },
  {
    "text": "So regardless of how you choose\nthis pi, how you initialize your sample,\neventually, xt is going",
    "start": "873550",
    "end": "879570"
  },
  {
    "text": "to be distributed\nas p theta, which is what you want because it's\na fixed point of this operator.",
    "start": "879570",
    "end": "887280"
  },
  {
    "text": "And I'm not doing\njustice to this topic. You could probably do a\nwhole course on MCMC methods.",
    "start": "887280",
    "end": "894899"
  },
  {
    "text": "But for our purposes, the\nimportant thing to note is that there are\nways of sampling",
    "start": "894900",
    "end": "901410"
  },
  {
    "text": "from energy-based\nmodels, namely MCMC. In principle, they work.",
    "start": "901410",
    "end": "906990"
  },
  {
    "text": "In practice, what happens\nis that you typically need a very large\nnumber of steps",
    "start": "906990",
    "end": "912210"
  },
  {
    "text": "before you get something good. So you can imagine\nif you were to start,",
    "start": "912210",
    "end": "917325"
  },
  {
    "text": "let's say x is an image, and you\nstart with random pixel values, and then you change\nthem one at a time,",
    "start": "917325",
    "end": "924402"
  },
  {
    "text": "it's going to take\na lot of changes before you get to something\nthat has the right structure.",
    "start": "924402",
    "end": "930269"
  },
  {
    "text": "Even though you have\nguidance provided by this f theta so know\nwhen you're making mistakes",
    "start": "930270",
    "end": "935529"
  },
  {
    "text": "and when you don't, it's still\ngoing to take a lot of steps before you get\nsomething that is good.",
    "start": "935530",
    "end": "942650"
  },
  {
    "text": "And so that's the problem\nof energy-based models is that even if you have an\nenergy-based model trained",
    "start": "942650",
    "end": "949210"
  },
  {
    "text": "or somebody gives you\nthe right f theta, generating samples is expensive.",
    "start": "949210",
    "end": "954829"
  },
  {
    "text": "So that's the price you pay. You have a very flexible\nmodel but sampling from it is expensive.",
    "start": "954830",
    "end": "961319"
  },
  {
    "text": "And note that if\nyou wanted to train a model by contrastive\ndivergence, you have to generate samples\nover and over during training.",
    "start": "961320",
    "end": "968379"
  },
  {
    "text": "So it's not just something you\nhave to do during inference time but even during training.",
    "start": "968380",
    "end": "974487"
  },
  {
    "text": "If you wanted to use\ncontrastive divergence, you would have to somehow\nuse this procedure. So very, very expensive\nand very, very difficult.",
    "start": "974487",
    "end": "984560"
  },
  {
    "text": "A slightly better\nversion which was just proposed of this\nprocedure is something",
    "start": "984560",
    "end": "991790"
  },
  {
    "text": "called Langevin dynamics which\nis essentially a special case of what we've seen before.",
    "start": "991790",
    "end": "997459"
  },
  {
    "text": "And it basically works\nthe same in the sense that you start by initializing\nthis process somehow,",
    "start": "997460",
    "end": "1004089"
  },
  {
    "text": "let's say, a random image, and\nthen you still do your steps.",
    "start": "1004090",
    "end": "1010365"
  },
  {
    "text": "You still an iterative\nprocedure where you're trying to locally change\nyour sample into something",
    "start": "1010365",
    "end": "1016720"
  },
  {
    "text": "better. But the way you\ndo it is by trying",
    "start": "1016720",
    "end": "1022120"
  },
  {
    "text": "to go in a direction that\nincreases-- that should increase",
    "start": "1022120",
    "end": "1028510"
  },
  {
    "text": "the probability of your sample. So what you do is\nthe way you produce",
    "start": "1028510",
    "end": "1035380"
  },
  {
    "text": "this perturbed version\nof xt is by doing",
    "start": "1035380",
    "end": "1040449"
  },
  {
    "text": "a step of noisy gradient\nascent where you modify xt",
    "start": "1040450",
    "end": "1048260"
  },
  {
    "text": "in the direction of the\ngradient of the log likelihood. Here I'm assuming\nthat x is continuous.",
    "start": "1048260",
    "end": "1053480"
  },
  {
    "text": "This only works on\ncontinuous state spaces. And so the gradient of the\nlog likelihood evaluated at xt",
    "start": "1053480",
    "end": "1063679"
  },
  {
    "text": "tells you in which direction\nyou should perturb your sample if you want it to increase\nthe likelihood most rapidly.",
    "start": "1063680",
    "end": "1071150"
  },
  {
    "text": "And then you basically\nfollow the gradient but you add a\nlittle bit of noise. And the reason is that\njust like before, we",
    "start": "1071150",
    "end": "1078520"
  },
  {
    "text": "don't want to be greedy. We don't want to always\noptimize the likelihood. We want to also explore.",
    "start": "1078520",
    "end": "1083900"
  },
  {
    "text": "So we want to\noccasionally take moves that decrease the\nprobability of our sample",
    "start": "1083900",
    "end": "1090010"
  },
  {
    "text": "just because we want to\nbe able to move around and explore the space\nof possible images.",
    "start": "1090010",
    "end": "1095350"
  },
  {
    "text": "But essentially, it is\nreally take your sample, follow the gradient, and add\na little bit of Gaussian noise",
    "start": "1095350",
    "end": "1102010"
  },
  {
    "text": "at every step\nrescaled in some way. ",
    "start": "1102010",
    "end": "1108600"
  },
  {
    "text": "And you always accept\nthe transition, at least in this version\nof the algorithm. There is also a version of this\nwhere you accept and reject",
    "start": "1108600",
    "end": "1115920"
  },
  {
    "text": "kind of like the previous\nalgorithm I described. But it turns out you don't\neven have to accept or reject.",
    "start": "1115920",
    "end": "1123389"
  },
  {
    "text": "You can always move to\nxt plus 1 regardless of whether you land\nin a state that has",
    "start": "1123390",
    "end": "1131280"
  },
  {
    "text": "a higher or lower probability\nthan where you start from. And you can prove that under\nsome technical conditions,",
    "start": "1131280",
    "end": "1138270"
  },
  {
    "text": "again, this procedure\nconverges to a sample from the distribution defined\nby the energy-based model",
    "start": "1138270",
    "end": "1145260"
  },
  {
    "text": "in the limit of a large\nnumber of iterations. Yeah?",
    "start": "1145260",
    "end": "1150272"
  },
  {
    "text": "Epsilon on both the actual\ngradient and the noise should be-- Yeah.",
    "start": "1150272",
    "end": "1155750"
  },
  {
    "text": "So the reason\nwe're using epsilon is that that controls\nthe step size. So it's the step size in\ngradient ascent or descent.",
    "start": "1155750",
    "end": "1164280"
  },
  {
    "text": "And it turns out that for things\nto work, you have to balance--",
    "start": "1164280",
    "end": "1169446"
  },
  {
    "text": "the amount of noise\nthat you add has to be scaled with respect to\nhow much you scale the gradient.",
    "start": "1169446",
    "end": "1178000"
  },
  {
    "text": "So the signal to noise has to\nscale in that way for things too.",
    "start": "1178000",
    "end": "1183191"
  },
  {
    "text": "[INAUDIBLE] where the\nsquare root of 2 is?",
    "start": "1183192",
    "end": "1189240"
  },
  {
    "text": "Yeah. So it basically needs to keep\nthe ratio between the amount of noise-- the signal to noise.",
    "start": "1189240",
    "end": "1195679"
  },
  {
    "text": "Gradient to noise\nratio has to be scaled that way to\nbe able to guarantee this kind of condition.",
    "start": "1195680",
    "end": "1203450"
  },
  {
    "text": "[INAUDIBLE] very small? In theory, yes. So it's only guaranteed to work\nin the limit of basically a step",
    "start": "1203450",
    "end": "1211920"
  },
  {
    "text": "size is going through zero.  In practice, you would\nuse a small step size",
    "start": "1211920",
    "end": "1217770"
  },
  {
    "text": "and hope that it works. Is that [INAUDIBLE] step size\nof near 0 due to the noise?",
    "start": "1217770",
    "end": "1224730"
  },
  {
    "text": "We move the noise and\ninstead, we have a higher-- So the step size because we are\nnot doing accept or reject here,",
    "start": "1224730",
    "end": "1232299"
  },
  {
    "text": "so if you remember\nthis version here, sometimes we stay where\nwe are and sometimes",
    "start": "1232300",
    "end": "1239370"
  },
  {
    "text": "we accept or reject\nbased on that. If you wanted, you can think--",
    "start": "1239370",
    "end": "1245550"
  },
  {
    "text": "basically here, I\ndidn't really say how I produced this\nperturbed version.",
    "start": "1245550",
    "end": "1252630"
  },
  {
    "text": "I just said add noise. But in practice, it\nturns out you can do it any way you want and it still\ngives you a valid algorithm",
    "start": "1252630",
    "end": "1259679"
  },
  {
    "text": "basically. So if you define a way you\nadd noise to it by saying, I follow the gradient\nand I add a little bit",
    "start": "1259680",
    "end": "1265650"
  },
  {
    "text": "of Gaussian noise, that defines\na valid procedure of proposing new data points.",
    "start": "1265650",
    "end": "1271570"
  },
  {
    "text": "And as long as you\nbalance it, then you would have a valid\nprocedure regardless,",
    "start": "1271570",
    "end": "1276660"
  },
  {
    "text": "even when epsilon is large. I mean you would still have\nthe problem that basically you",
    "start": "1276660",
    "end": "1284720"
  },
  {
    "text": "might accept-- you need to make-- then\nyou have accept and reject. So sometimes you\nget stuck where you",
    "start": "1284720",
    "end": "1289910"
  },
  {
    "text": "are so you don't want\nto take too much of a-- If the step size\nis too large, you",
    "start": "1289910",
    "end": "1296029"
  },
  {
    "text": "might be-- the Taylor\nexpansion is no longer accurate and so the probability\nmight actually go down.",
    "start": "1296030",
    "end": "1301050"
  },
  {
    "text": "And so then you might\nget stuck where you are. So it's still\nnon-trivial but you can-- I guess, yeah, this is called\nthe unadjusted version.",
    "start": "1301050",
    "end": "1308870"
  },
  {
    "text": "That is the adjusted\nversion which is basically you accept and reject and that\none can work with finite step",
    "start": "1308870",
    "end": "1315220"
  },
  {
    "text": "sizes.  Cool.",
    "start": "1315220",
    "end": "1320789"
  },
  {
    "text": "Oh, question. Is this faster than\njust regular morning? Or why would we use this\nover the previous one?",
    "start": "1320790",
    "end": "1327960"
  },
  {
    "text": "So great question. And in general, I mean\nit still, in theory,",
    "start": "1327960",
    "end": "1334350"
  },
  {
    "text": "can require a larger\nnumber of steps and the convergence is only\nguaranteed to be in the limit.",
    "start": "1334350",
    "end": "1339549"
  },
  {
    "text": "But in practice, you can imagine\nthat it's a much better proposal because you are following the--\nyou have a lot more information.",
    "start": "1339550",
    "end": "1347250"
  },
  {
    "text": "Before, we were blindly\nmaking changes to the image. Well, now we're saying,\nOK, if you have access",
    "start": "1347250",
    "end": "1353430"
  },
  {
    "text": "to the gradient information,\nit can be much more informed in the way you make\nproposed moves.",
    "start": "1353430",
    "end": "1360640"
  },
  {
    "text": "And in practice,\nthis is much better in terms of the number of steps\nthat you need to converge.",
    "start": "1360640",
    "end": "1367410"
  },
  {
    "text": " And the good thing is that\neven though the log likelihood",
    "start": "1367410",
    "end": "1376790"
  },
  {
    "text": "depends on the partition\nfunction-- or maybe I don't have it here. But if you work\nout the expression,",
    "start": "1376790",
    "end": "1386660"
  },
  {
    "text": "you will see that\nthe Z theta depends on-- the partition\nfunction depends on theta but does not depend on x.",
    "start": "1386660",
    "end": "1393110"
  },
  {
    "text": "So all x's have the\nsame partition function. So when you take the\ngradient with respect to x,",
    "start": "1393110",
    "end": "1399530"
  },
  {
    "text": "you just get the gradient of the\nenergy of the neural network. And so computing the gradient\nof the log likelihood",
    "start": "1399530",
    "end": "1407600"
  },
  {
    "text": "is actually easy even when you\nhave an energy-based model. ",
    "start": "1407600",
    "end": "1413690"
  },
  {
    "text": "And so this kind of\nsampling procedure is very suitable for EBMs.",
    "start": "1413690",
    "end": "1420920"
  },
  {
    "text": "And I mean, it's\nstill problematic. In theory at least, the\nmore dimensions you have,",
    "start": "1420920",
    "end": "1427950"
  },
  {
    "text": "the slower things tend to be. And this kind of thing\nis reasonable to do",
    "start": "1427950",
    "end": "1436250"
  },
  {
    "text": "at inference time. But even if you maybe need,\nlet's say, 1,000 steps, or maybe 10,000\nsteps, or something",
    "start": "1436250",
    "end": "1444289"
  },
  {
    "text": "like that of this procedure\nto generate a sample, it might be something\ntolerable at inference time.",
    "start": "1444290",
    "end": "1451700"
  },
  {
    "text": "If you're generating, let's\nsay, a million pixels, it's fine to do 1,000\nsteps of this procedure.",
    "start": "1451700",
    "end": "1458000"
  },
  {
    "text": "That might require you to\nevaluate a big neural network, let's say, 1,000 times. Might not be too bad.",
    "start": "1458000",
    "end": "1463740"
  },
  {
    "text": "But if you have to do\nit during training, then things become\nvery, very expensive. So training energy-based\nmodels by sampling",
    "start": "1463740",
    "end": "1471409"
  },
  {
    "text": "in an inner loop where you're\ndoing gradient ascent on the log likelihood is actually\nvery, very expensive.",
    "start": "1471410",
    "end": "1478010"
  },
  {
    "text": "And even though this\nis a reasonable way of sampling from an\nenergy-based model, it's just not fast enough.",
    "start": "1478010",
    "end": "1484720"
  },
  {
    "text": "If you want to plug\nthis is in this kind of contrastive\ndivergence subroutine",
    "start": "1484720",
    "end": "1491850"
  },
  {
    "text": "where for every training data\npoint you have to generate a sample from the model, you\nhave to generate the sample,",
    "start": "1491850",
    "end": "1497220"
  },
  {
    "text": "you have to run a Langevin\nchain with 1,000 steps. Things will become just\ntoo expensive basically.",
    "start": "1497220",
    "end": "1504330"
  },
  {
    "text": "So what we're going to\nsee today are other ways of training energy-based\nmodels that do not basically",
    "start": "1504330",
    "end": "1511170"
  },
  {
    "text": "require sampling. Yeah? Could you go one slide back?",
    "start": "1511170",
    "end": "1517820"
  },
  {
    "text": "I don't see how point 2 is true. Why is that equivalence true?",
    "start": "1517820",
    "end": "1523400"
  },
  {
    "text": "Which one? So the gradient of the log p\ntheta equal to the gradient.",
    "start": "1523400",
    "end": "1528740"
  },
  {
    "text": "Yeah, sure. So let's see. When we have it\nhere, this expression",
    "start": "1528740",
    "end": "1536760"
  },
  {
    "text": "here is the gradient\nof the log likelihood. Sorry, just the log\nlikelihood, f theta minus",
    "start": "1536760",
    "end": "1542910"
  },
  {
    "text": "log Z, which is just the\nlog of this expression. Now if you take the gradient\nwith respect to x of this thing,",
    "start": "1542910",
    "end": "1549809"
  },
  {
    "text": "log Z theta does not\ndepend on x, and so it's 0, and so it drops out.",
    "start": "1549810",
    "end": "1555580"
  },
  {
    "text": "And so that's why\nbasically this is true.",
    "start": "1555580",
    "end": "1562140"
  },
  {
    "text": " Great. And so the plan is to\nessentially introduce",
    "start": "1562140",
    "end": "1570700"
  },
  {
    "text": "ways of training\nenergy-based models that do not require sampling\nduring training at least.",
    "start": "1570700",
    "end": "1577220"
  },
  {
    "text": "And so think of\nthem as alternatives to contrastive\ndivergence which was",
    "start": "1577220",
    "end": "1583450"
  },
  {
    "text": "an approximation to the\nKL divergence between data and model. So an approximation to\nmaximum likelihood training.",
    "start": "1583450",
    "end": "1590750"
  },
  {
    "text": "That's how we introduced\ncontrastive divergence. What we'll see is\nthe usual trick that",
    "start": "1590750",
    "end": "1596590"
  },
  {
    "text": "is going to be some\nother kind of divergence, some other way of\ncomparing model to data that does\nnot involve the--",
    "start": "1596590",
    "end": "1603690"
  },
  {
    "text": "where the loss\nfunction basically does not involve the\npartition function. And if we train\nby that instead of",
    "start": "1603690",
    "end": "1610730"
  },
  {
    "text": "by approximating the\nKL divergence then we get much faster\ntraining procedures.",
    "start": "1610730",
    "end": "1616440"
  },
  {
    "text": "And so we'll see a few of them. We'll see score matching, which\nis the key building block also",
    "start": "1616440",
    "end": "1621809"
  },
  {
    "text": "behind diffusion models,\nnoise contrastive estimation, and adversarial training.",
    "start": "1621810",
    "end": "1629350"
  },
  {
    "text": "So recall that we have an\nenergy-based model which is defined like that.",
    "start": "1629350",
    "end": "1634940"
  },
  {
    "text": "And if you take the\nlog of that expression, back until we get this\nsort of difference",
    "start": "1634940",
    "end": "1641860"
  },
  {
    "text": "between the energy, which is\nwhatever neural network you're using to model the\ndistribution and then",
    "start": "1641860",
    "end": "1646960"
  },
  {
    "text": "you have the log\npartition function. And the key thing\nis that the score",
    "start": "1646960",
    "end": "1652240"
  },
  {
    "text": "function or the gradient of\nthe log likelihood with respect to x. So note this is not\nthe gradient of the log",
    "start": "1652240",
    "end": "1659140"
  },
  {
    "text": "likelihood with respect\nto theta, which are the parameters of the model. This is the gradient\nwith respect to x.",
    "start": "1659140",
    "end": "1664660"
  },
  {
    "text": "So this is basically how\ndoes the probability change if I were to make small\nchanges to the sample itself.",
    "start": "1664660",
    "end": "1673930"
  },
  {
    "text": "Not how the likelihood\nwould change if I were to make\nchanges to the parameters of the neural network.",
    "start": "1673930",
    "end": "1679880"
  },
  {
    "text": "So this is gradient with respect\nto x, not with respect to theta. This is also a function of x in\nthe sense that at every axis,",
    "start": "1679880",
    "end": "1688570"
  },
  {
    "text": "there is going to be different\ngradients and a function of theta because\nthe log likelihood itself is parameterized by a\nneural network with weights",
    "start": "1688570",
    "end": "1695800"
  },
  {
    "text": "theta. And just kind of\nlike what we just saw before, the gradient\nof the log likelihood",
    "start": "1695800",
    "end": "1704559"
  },
  {
    "text": "does not depend on the\npartition function. So here I guess it's\nshowing a little bit better",
    "start": "1704560",
    "end": "1710289"
  },
  {
    "text": "than what I was trying to\nshow before but if the log likelihood is the difference\nof these two terms,",
    "start": "1710290",
    "end": "1716139"
  },
  {
    "text": "the log partition function\nis the same for every x. It depends on theta but\nit does not depend on x.",
    "start": "1716140",
    "end": "1722990"
  },
  {
    "text": "And so when you take the\ngradient with respect to x, the log partition\nfunction doesn't change.",
    "start": "1722990",
    "end": "1729040"
  },
  {
    "text": "And so the gradient is 0. And so that's why we were\nable to use the score",
    "start": "1729040",
    "end": "1737590"
  },
  {
    "text": "function or the gradient\nof the log likelihood in the previous\nsampling procedure. It's easy to compute if you have\naccess to the energy function f",
    "start": "1737590",
    "end": "1746679"
  },
  {
    "text": "theta. And you can see it here,\nthis kind of idea in play.",
    "start": "1746680",
    "end": "1756360"
  },
  {
    "text": "If you have a Gaussian\ndistribution where as usual the parameters would be the\nmean and the standard deviation,",
    "start": "1756360",
    "end": "1762730"
  },
  {
    "text": "remember the partition function\nis this normalization constant that you have in\nfront that guarantees",
    "start": "1762730",
    "end": "1769210"
  },
  {
    "text": "that the integral of this\nfunction is actually 1. If you take the\nlog, you're going",
    "start": "1769210",
    "end": "1774460"
  },
  {
    "text": "to get the log of the\nnormalization constant and then you get the\nlog of this exponential.",
    "start": "1774460",
    "end": "1779980"
  },
  {
    "text": "And then when you take the\nderivative with respect to x, you get, again, a function of x\nand the parameters of the model,",
    "start": "1779980",
    "end": "1786770"
  },
  {
    "text": "which is relatively simple. It's just like x minus the\nmean scaled by the variance.",
    "start": "1786770",
    "end": "1795889"
  },
  {
    "text": "And if you have a\ngamma distribution, again, some potentially nasty\nnormalization constant in front.",
    "start": "1795890",
    "end": "1805029"
  },
  {
    "text": "But the moment you\ntake the score, that's normalization\nconstant disappears",
    "start": "1805030",
    "end": "1810100"
  },
  {
    "text": "and you get a much simpler\nfunction to work with.",
    "start": "1810100",
    "end": "1815280"
  },
  {
    "text": "And so the intuition is that\nS theta, which is the score,",
    "start": "1815280",
    "end": "1820820"
  },
  {
    "text": "provides you an alternative\nview of the original function",
    "start": "1820820",
    "end": "1827210"
  },
  {
    "text": "where you are looking at\nthings from the perspective of the gradient\ninstead of looking at things from the perspective\nof the likelihood itself.",
    "start": "1827210",
    "end": "1834750"
  },
  {
    "text": "So if you imagine you have\na p theta which is just a mixture of two Gaussians,\nlet's say, in 2D,",
    "start": "1834750",
    "end": "1840920"
  },
  {
    "text": "so there is a Gaussian here\nand a Gaussian up here, so it's a mixture of two. So you have this kind of fairly\ncomplicated level curves.",
    "start": "1840920",
    "end": "1849290"
  },
  {
    "text": "The likelihood is just\na scalar function. For every x, it\ngives you a scalar, which is the height\nof this curve where",
    "start": "1849290",
    "end": "1856820"
  },
  {
    "text": "you can imagine you have\ntwo bell curves, one centered here and one here.",
    "start": "1856820",
    "end": "1862110"
  },
  {
    "text": "The score is basically the\ngradient at every point. It's a function that every\nx gives you the gradient",
    "start": "1862110",
    "end": "1869100"
  },
  {
    "text": "of the log likelihood. And so it's a vector field. You can imagine that every\npoint there is an arrow",
    "start": "1869100",
    "end": "1874680"
  },
  {
    "text": "and the arrow tells you what is\nthe direction that you should follow if you wanted to increase\nthe log likelihood most rapidly.",
    "start": "1874680",
    "end": "1881610"
  },
  {
    "text": "And so as expected, you can see\nthat these arrows are pointing towards the means\nof the Gaussian,",
    "start": "1881610",
    "end": "1887559"
  },
  {
    "text": "which is what you\nsee here in the sense that if you are at a data\npoint and you want to increase",
    "start": "1887560",
    "end": "1892680"
  },
  {
    "text": "the likelihood, you should\npush it towards the mean if the model is a Gaussian.",
    "start": "1892680",
    "end": "1899200"
  },
  {
    "text": "[INAUDIBLE] fixing theta-- the\nmodel parameters are fixed?",
    "start": "1899200",
    "end": "1904627"
  },
  {
    "text": "Well, they are not\nnecessarily fixed. So we're still\ngoing to learn them. But when we take gradients,\nwe take gradients with respect",
    "start": "1904628",
    "end": "1910630"
  },
  {
    "text": "to x and so theta\ndoes not depend on x. And so when you take the\ngradient with respect to x,",
    "start": "1910630",
    "end": "1918340"
  },
  {
    "text": "the log partition\nfunction disappears. But we're still going\nto be learning theta.",
    "start": "1918340",
    "end": "1924050"
  },
  {
    "text": "So here, of course, I'm\njust showing a snapshot where theta is fixed\nand theta would",
    "start": "1924050",
    "end": "1929200"
  },
  {
    "text": "represent the means and\nthe variances of these two Gaussians. And if you change\nthose, the score",
    "start": "1929200",
    "end": "1934929"
  },
  {
    "text": "function itself would change. And you can see it here, it's\nstill a function of theta",
    "start": "1934930",
    "end": "1939940"
  },
  {
    "text": "but it's a simple\nfunction of theta that does not depend on\nthe normalization constant. So you can compute it without\nknowing the relative--",
    "start": "1939940",
    "end": "1949600"
  },
  {
    "text": "you don't need to\nknow relative-- Remember that the\ngradient is telling you how the likelihood changes.",
    "start": "1949600",
    "end": "1955440"
  },
  {
    "text": "But if you were to make\nsmall changes to x and we know how to compare the\nprobabilities of two data points",
    "start": "1955440",
    "end": "1960690"
  },
  {
    "text": "in an energy-based\nmodels so it makes sense that it does not depend\non the partition function.",
    "start": "1960690",
    "end": "1967630"
  },
  {
    "text": "Yeah? Yeah, in this case,\nthe score function is basically a vector field\nrepresenting the gradients.",
    "start": "1967630",
    "end": "1973809"
  },
  {
    "text": "In general, is it always\nlike a vector field or what is it supposed to\nrepresent in general? Yeah, good question.",
    "start": "1973810",
    "end": "1979610"
  },
  {
    "text": "So the score function\nas defined is always a vector field in the sense\nrepresenting the gradient because by definition,\nit's just the gradient",
    "start": "1979610",
    "end": "1986500"
  },
  {
    "text": "of f theta with respect to x. And so in general, f theta\nwould be much more complicated",
    "start": "1986500",
    "end": "1992260"
  },
  {
    "text": "than a mixture of two Gaussians. And so you can imagine\nthat these arrows would be much more complicated.",
    "start": "1992260",
    "end": "1998050"
  },
  {
    "text": "And if you have probability mass\nspread out in a complicated way, the gradient could be--",
    "start": "1998050",
    "end": "2004040"
  },
  {
    "text": "I mean, it's still going\nto be a vector field. It might not have\nthat simple structure where it's just pointing you\ntowards these two points.",
    "start": "2004040",
    "end": "2011918"
  },
  {
    "text": "But it's still always going to\nbe a vector field of gradient. [INAUDIBLE]",
    "start": "2011918",
    "end": "2017120"
  },
  {
    "text": "Or it can be a vector field\nof some other quantity? So it's a vector\nfield of gradients if it's defined like this\nbecause it's actually",
    "start": "2017120",
    "end": "2023630"
  },
  {
    "text": "a conservative vector\nfield because there is an actual underlying\nenergy function. When we talk about\nscore-based models,",
    "start": "2023630",
    "end": "2029540"
  },
  {
    "text": "we'll see that we'll just use\nan arbitrary neural network to model this. But for now we're assuming\nthat there is an underlying",
    "start": "2029540",
    "end": "2036049"
  },
  {
    "text": "f theta, an energy function, and\nthis is just the vector field. So if you like\nanalogies with physics,",
    "start": "2036050",
    "end": "2041780"
  },
  {
    "text": "you can think of f theta as\nbeing an electric potential and S theta as being\nthe gradient of that,",
    "start": "2041780",
    "end": "2051989"
  },
  {
    "text": "which is like a field\nbasically, an electric field. And they describe\nthe same object",
    "start": "2051989",
    "end": "2058579"
  },
  {
    "text": "but in slightly different ways. And so there is no\nloss of information. We're just thinking of things\nin a slightly different--",
    "start": "2058580",
    "end": "2065870"
  },
  {
    "text": "taking a slightly\ndifferent view that is going to be beneficial\nfrom a computational reason because we don't have to worry\nabout the partition function.",
    "start": "2065870",
    "end": "2072600"
  },
  {
    "text": " So how do we do--",
    "start": "2072600",
    "end": "2079388"
  },
  {
    "text": "a key observation is the\nscore function gradient of the log likelihood\nwith respect to the inputs",
    "start": "2079389",
    "end": "2085480"
  },
  {
    "text": "is independent of the\npartition function. And so the idea is that we're\ngoing to define a training",
    "start": "2085480",
    "end": "2092649"
  },
  {
    "text": "objective where we're going\nto compare two probability distributions or two\nprobability densities p and q",
    "start": "2092650",
    "end": "2100900"
  },
  {
    "text": "by comparing their respective\nvector field of gradients. So the idea is that if p\nand q are similar, then",
    "start": "2100900",
    "end": "2111310"
  },
  {
    "text": "they should also have similar\nvector field of gradients. If p and q are similar,\na different axis",
    "start": "2111310",
    "end": "2119140"
  },
  {
    "text": "would have similar gradients. So one reasonable\nway of comparing",
    "start": "2119140",
    "end": "2124270"
  },
  {
    "text": "how similar p and\nq are is to say what is the average L2\ndifference between the score",
    "start": "2124270",
    "end": "2133750"
  },
  {
    "text": "of p and the score of q. So at every point,\nwe look at what",
    "start": "2133750",
    "end": "2139250"
  },
  {
    "text": "is the direction that you should\nfollow if you wanted to increase the likelihood of\np most rapidly, what is the direction that you\nshould follow if you wanted",
    "start": "2139250",
    "end": "2145750"
  },
  {
    "text": "to increase the likelihood\nof q most rapidly, and we check how\ndifferent they are. So it's a vector.",
    "start": "2145750",
    "end": "2151290"
  },
  {
    "text": "So to turn it into a scalar,\nwe take the norm of this vector and then we're averaging with\nrespect to p in this case.",
    "start": "2151290",
    "end": "2161529"
  },
  {
    "text": "And what I claim is\nthat you can imagine",
    "start": "2161530",
    "end": "2167110"
  },
  {
    "text": "that this is a reasonable\nloss function because if p is actually equal to q,\nthen the gradients are",
    "start": "2167110",
    "end": "2173380"
  },
  {
    "text": "going to be the same. So gradient of log p is going\nto be the same as gradient of log q.",
    "start": "2173380",
    "end": "2178660"
  },
  {
    "text": "This vector is going\nto be 0 everywhere. And the norm is going to be 0. The average is going to be 0.",
    "start": "2178660",
    "end": "2184599"
  },
  {
    "text": "And so what's called the\nFisher divergence between p and Q is also going to be 0.",
    "start": "2184600",
    "end": "2189670"
  },
  {
    "text": "So it's a reasonable way\nof checking how p and q are",
    "start": "2189670",
    "end": "2195010"
  },
  {
    "text": "different from each other. And crucially, the\nreason we're doing it is that at the end\nof the day, we're",
    "start": "2195010",
    "end": "2203060"
  },
  {
    "text": "interested in training\nan energy-based model so let's say p is\ngoing to be the data, q is going to be the model.",
    "start": "2203060",
    "end": "2210050"
  },
  {
    "text": "But crucially this loss function\nonly involves the scores, it only involves this gradient\nwhich we do not depend",
    "start": "2210050",
    "end": "2216620"
  },
  {
    "text": "on the partition function. And so this might give\nus a loss function that is actually very suitable\nfor energy-based models",
    "start": "2216620",
    "end": "2223070"
  },
  {
    "text": "because it does not require\nyou to know the log partition function of the model. That's like why we're\nlooking at this.",
    "start": "2223070",
    "end": "2231143"
  },
  {
    "text": "[INAUDIBLE]  So it's a different\nloss function.",
    "start": "2231143",
    "end": "2237160"
  },
  {
    "text": "It's a different way of\ncomparing probability density functions. They're actually\nrelated to each other.",
    "start": "2237160",
    "end": "2243200"
  },
  {
    "text": "So in a certain sense,\nthe Fisher divergence is the derivative of the KL\ndivergence in a certain way.",
    "start": "2243200",
    "end": "2250670"
  },
  {
    "text": "So if you take two densities,\nand you convolve them with Gaussian noise, and you\ntake the derivative of that",
    "start": "2250670",
    "end": "2257050"
  },
  {
    "text": "with respect to the\nsize of the noise, it turns out that that's\nthe Fisher divergence. But just think of it as a\ndifferent kind of divergence.",
    "start": "2257050",
    "end": "2266176"
  },
  {
    "text": "[INAUDIBLE] p theta the ground\ntruth, why do we need a model? Yeah. So let's see how--",
    "start": "2266176",
    "end": "2272160"
  },
  {
    "text": "it's not going to be as\neasy but that's the idea, is that let's define a\nloss in terms of the score",
    "start": "2272160",
    "end": "2277423"
  },
  {
    "text": "because we know how\nto compute the score and we don't know how to\ncompute the log likelihood. ",
    "start": "2277423",
    "end": "2285420"
  },
  {
    "text": "So that's the score\nmatching idea. p is going to be pdata.",
    "start": "2285420",
    "end": "2290550"
  },
  {
    "text": "q is going to be the\nenergy-based model which is parameterized by\nthis energy function.",
    "start": "2290550",
    "end": "2297090"
  },
  {
    "text": "And then if you evaluate\nthat Fisher divergence between the data density\nand the model density,",
    "start": "2297090",
    "end": "2303599"
  },
  {
    "text": "you get this kind of\nthing or equivalently this sort of thing, where you\ntake an expectation with respect",
    "start": "2303600",
    "end": "2310589"
  },
  {
    "text": "to the data distribution of the\ndifference between the gradient of the true data\ngenerating process",
    "start": "2310590",
    "end": "2317970"
  },
  {
    "text": "and what's given by the model. [INAUDIBLE] assume that\ntheta is continuous?",
    "start": "2317970",
    "end": "2324320"
  },
  {
    "text": "Yes, this only works with\ncontinuous densities, yes. ",
    "start": "2324320",
    "end": "2330310"
  },
  {
    "text": "And so basically we're comparing\nthe gradients of the true data distribution with the\ngradients of the model, which",
    "start": "2330310",
    "end": "2339080"
  },
  {
    "text": "are things we can compute. And even though p theta\nis an energy-based model, this loss function only\ndepends on the score",
    "start": "2339080",
    "end": "2347150"
  },
  {
    "text": "which we know we can\ncompute efficiently without having to worry about\nthe normalization constant.",
    "start": "2347150",
    "end": "2352744"
  },
  {
    "text": " So that's the idea.",
    "start": "2352745",
    "end": "2357930"
  },
  {
    "text": "Now as was pointed out, it\nfeels like it's not very useful because it involves the\ngradient of the log data density",
    "start": "2357930",
    "end": "2367990"
  },
  {
    "text": "which we don't know. It seems like a reasonable loss\nfunction but not exactly one we can evaluate or optimize\nbecause although we have access",
    "start": "2367990",
    "end": "2375660"
  },
  {
    "text": "to samples from pdata so\npresumably you can approximate this expectation with respect\nto pdata with samples,",
    "start": "2375660",
    "end": "2382560"
  },
  {
    "text": "it looks like we need to know\nthe gradient of the log data density which is unknown.",
    "start": "2382560",
    "end": "2388890"
  },
  {
    "text": "If we knew what log\npdata is for every x, then we wouldn't have to\nbuild a generative model.",
    "start": "2388890",
    "end": "2395286"
  },
  {
    "text": "Why would [INAUDIBLE]\nwith respect to theta from the first [INAUDIBLE]?",
    "start": "2395287",
    "end": "2400980"
  },
  {
    "text": "It's a square. We'll see that there\nis a square there that creates a\ncoupling unfortunately. But it turns out that\nit's almost easy to do.",
    "start": "2400980",
    "end": "2408539"
  },
  {
    "text": "[INAUDIBLE] is just that-- Yeah. Well, not as easy as that. But it turns out that--",
    "start": "2408540",
    "end": "2414990"
  },
  {
    "text": "so that's sort of\nthe expression. And the problem is that we\nonly have samples from pdata. And so it looks like\nthat first term,",
    "start": "2414990",
    "end": "2423109"
  },
  {
    "text": "the score of the data\ndistribution is unknown. So we don't know how to optimize\nthat objective function and try",
    "start": "2423110",
    "end": "2431530"
  },
  {
    "text": "to make it as small as\npossible as a function of theta because we cannot compute\nthis first term here.",
    "start": "2431530",
    "end": "2437110"
  },
  {
    "text": " We only have access\nto samples from pdata. That's the usual setting in our\ngenerative modeling problem.",
    "start": "2437110",
    "end": "2445770"
  },
  {
    "text": "But it turns out that you can\nrewrite this loss function into an equivalent one\nthat no longer depends",
    "start": "2445770",
    "end": "2453330"
  },
  {
    "text": "on the unknown score function\nof the data distribution by using integration by parts.",
    "start": "2453330",
    "end": "2461240"
  },
  {
    "text": "And so just to see\nhow this works, let's start with\nthe univariate case. So x is just a one-dimensional,\nscalar random variable",
    "start": "2461240",
    "end": "2471960"
  },
  {
    "text": "so the gradients are\nactually just derivatives. And just because\nintegration by parts",
    "start": "2471960",
    "end": "2478560"
  },
  {
    "text": "is a little bit easier\nto see that way so I'm still using the\ngradient notation but these are\nactually derivatives.",
    "start": "2478560",
    "end": "2484260"
  },
  {
    "text": "And then we don't have to worry\nabout the norm of the vector",
    "start": "2484260",
    "end": "2490220"
  },
  {
    "text": "because again, the\nderivatives are just scalars and so the square norm is just\nthe difference of these two",
    "start": "2490220",
    "end": "2496010"
  },
  {
    "text": "scalars squared. So that's what the\nloss function looks like when x is just a single\nscalar random variable.",
    "start": "2496010",
    "end": "2504590"
  },
  {
    "text": "This basically is the\nsame exact expression, except that it's\nno longer a vector. It's just the difference\nof two scalars",
    "start": "2504590",
    "end": "2510710"
  },
  {
    "text": "and that's what's\nhappening there. And then we can expand this\nby just explicitly writing",
    "start": "2510710",
    "end": "2521300"
  },
  {
    "text": "this out as an expectation\nwith respect to the data distribution. So you go through every x\nthat can possibly happen,",
    "start": "2521300",
    "end": "2527930"
  },
  {
    "text": "you weight it with\nthe data density, and then you look\nat the difference between the derivatives of\nthe log data distribution",
    "start": "2527930",
    "end": "2535220"
  },
  {
    "text": "and the log model\ndistribution at every point. So you kind of have\nthese two curves.",
    "start": "2535220",
    "end": "2540870"
  },
  {
    "text": "You look at the slopes at every\npoint and you compare them. ",
    "start": "2540870",
    "end": "2546390"
  },
  {
    "text": "And you can expand the square. It's a square of a difference\nand so if you expand it,",
    "start": "2546390",
    "end": "2552869"
  },
  {
    "text": "you're going to get three terms. You're going to get a\nblue term which is just the square of this first,\ngradient of the log data density",
    "start": "2552870",
    "end": "2560040"
  },
  {
    "text": "squared. Then you have the gradient of\nthe log model density squared. And then you have this red term\nwhere you have basically the dot",
    "start": "2560040",
    "end": "2569760"
  },
  {
    "text": "product between-- the cross\nproduct between model and data.",
    "start": "2569760",
    "end": "2574950"
  },
  {
    "text": "And you can see that the first\nterm does not depend on theta.",
    "start": "2574950",
    "end": "2580060"
  },
  {
    "text": "So we can ignore it. For the purposes of optimization\nwith respect to theta we can ignore the blue term.",
    "start": "2580060",
    "end": "2585690"
  },
  {
    "text": "The green term is easy. It just depends on the model. So again, we're good.",
    "start": "2585690",
    "end": "2591280"
  },
  {
    "text": "The problem is the red\nterm because that one still involves this gradient\nof the log data density",
    "start": "2591280",
    "end": "2600440"
  },
  {
    "text": "in some non-trivial way. And what we're going to do is\nwe're going to use integration",
    "start": "2600440",
    "end": "2606559"
  },
  {
    "text": "by parts, which is usually,\nremember from basic calculus, it's a way to write the\nintegral of the f prime g",
    "start": "2606560",
    "end": "2614240"
  },
  {
    "text": "in terms of the\nintegral of g prime f. Basically switch which function\nyou're taking derivative",
    "start": "2614240",
    "end": "2621300"
  },
  {
    "text": "with respect to and we apply\nto that red term, which",
    "start": "2621300",
    "end": "2627140"
  },
  {
    "text": "is the annoying term. Recall that this is an\nexpectation with respect to the data of the gradient log\ndata density gradient of the log",
    "start": "2627140",
    "end": "2634609"
  },
  {
    "text": "model density. Now what is the gradient\nof the log of pdata?",
    "start": "2634610",
    "end": "2641250"
  },
  {
    "text": "Gradient of log is the\nargument of the log-- 1 over the argument\ntimes the derivative",
    "start": "2641250",
    "end": "2647369"
  },
  {
    "text": "of the argument of the log. So it should look like this.",
    "start": "2647370",
    "end": "2652770"
  },
  {
    "text": "Just by expanding out,\nthis gradient of log pdata 1 over pdata times\nthe derivative of pdata.",
    "start": "2652770",
    "end": "2660470"
  },
  {
    "text": "And the reason we're doing it\nis that now this pdata here and this pdata here will cancel.",
    "start": "2660470",
    "end": "2667470"
  },
  {
    "text": "And now it looks something\nwhere we can apply integration by parts. So this is the\nderivative of pdata",
    "start": "2667470",
    "end": "2675480"
  },
  {
    "text": "times the derivative\nof the log p model. And we can apply\nintegration by parts",
    "start": "2675480",
    "end": "2682530"
  },
  {
    "text": "and rewrite it in\nterms of pdata.",
    "start": "2682530",
    "end": "2687830"
  },
  {
    "text": "So here we had a\nderivative of pdata. So we rewrite it in terms of\njust the-- instead of f prime,",
    "start": "2687830",
    "end": "2694750"
  },
  {
    "text": "we go to f. So pdata prime,\nit becomes pdata. And then we take\nan extra derivative",
    "start": "2694750",
    "end": "2702670"
  },
  {
    "text": "of the log on the\nscore of the model. ",
    "start": "2702670",
    "end": "2708880"
  },
  {
    "text": "And so we've\nbasically rewritten it in terms of an\nexpectation with respect",
    "start": "2708880",
    "end": "2714930"
  },
  {
    "text": "to the data distribution of a\nsecond derivative of the model",
    "start": "2714930",
    "end": "2720240"
  },
  {
    "text": "score essentially. Now we still have to deal with\nthis the term here, fg which",
    "start": "2720240",
    "end": "2727609"
  },
  {
    "text": "is the integrand evaluated\nat the two extremes. And under some\nreasonable assumption,",
    "start": "2727610",
    "end": "2735320"
  },
  {
    "text": "you can assume that\nin the limit as x goes to plus and minus\ninfinity, this pdata goes to 0.",
    "start": "2735320",
    "end": "2744890"
  },
  {
    "text": "It's a density so there cannot\nbe too much probability mass at the boundaries. And if you are willing\nto make that assumption,",
    "start": "2744890",
    "end": "2752420"
  },
  {
    "text": "this simplifies into\nsomething that now basically no longer depends on the\nscore of the data density.",
    "start": "2752420",
    "end": "2760190"
  },
  {
    "text": "It only depends on\nthings we can manage. It's still an expectation with\nrespect to the data density",
    "start": "2760190",
    "end": "2766730"
  },
  {
    "text": "but it only involves the-- it no longer involves the score. ",
    "start": "2766730",
    "end": "2773790"
  },
  {
    "text": "And so that's\nbasically the trick. If you can assume-- if you are willing to assume\nthat this term here is 0,",
    "start": "2773790",
    "end": "2782090"
  },
  {
    "text": "basically that the data\ndistribution decays sufficiently fast, then you can use\nintegration by parts",
    "start": "2782090",
    "end": "2788240"
  },
  {
    "text": "and you can rewrite this thing,\nthe original score matching loss.",
    "start": "2788240",
    "end": "2793790"
  },
  {
    "text": "Recall, it had three pieces. If we apply that trick\nto rewrite the red term",
    "start": "2793790",
    "end": "2802490"
  },
  {
    "text": "into this brown term that we\njust derived using integration by parts, now we get a loss\nfunction that we can actually",
    "start": "2802490",
    "end": "2810440"
  },
  {
    "text": "evaluate and we can optimize\nas a function of theta. We have the first term which is\nconstant with respect to theta",
    "start": "2810440",
    "end": "2817020"
  },
  {
    "text": "so we can ignore it. We have an expectation\nwith respect to pdata of the\nderivative squared.",
    "start": "2817020",
    "end": "2823337"
  },
  {
    "text": "And then we have an\nexpectation with respect to pdata of the second\nderivative of the log likelihood.",
    "start": "2823337",
    "end": "2830710"
  },
  {
    "text": "And so this is\nbasically what the-- you can write the\ntwo expectations as a single expectation\nand now we basically derive",
    "start": "2830710",
    "end": "2839349"
  },
  {
    "text": "the loss function that is\nequivalent up to a constant to where we started from\nbut now it only involves",
    "start": "2839350",
    "end": "2844990"
  },
  {
    "text": "things we have access to. It only involves the model\nscore and the further derivative",
    "start": "2844990",
    "end": "2851829"
  },
  {
    "text": "of the model score, which is\nthe second derivative of the log likelihood. But again, derivatives are\nalways with respect to x.",
    "start": "2851830",
    "end": "2860244"
  },
  {
    "text": " And so that's where\nthe magic happens.",
    "start": "2860245",
    "end": "2866050"
  },
  {
    "text": "This is how you get\nrid of that dependence on the score of the data\ndensity and write it down using elementary calculus\ninto an expression that",
    "start": "2866050",
    "end": "2875520"
  },
  {
    "text": "is now something we\ncan actually optimize. You can evaluate and optimize\nas a function of theta.",
    "start": "2875520",
    "end": "2881290"
  },
  {
    "text": "So that's sort of like at\nleast in the one d case.",
    "start": "2881290",
    "end": "2886430"
  },
  {
    "text": " And it turns out that\nthere is something,",
    "start": "2886430",
    "end": "2893505"
  },
  {
    "text": "you might have seen it,\nin multivariate calculus, there is an equivalent\nof integration by parts.",
    "start": "2893505",
    "end": "2899980"
  },
  {
    "text": "That's actually\nGauss's theorem where you can basically do\nthe same trick for when you have a vector--",
    "start": "2899980",
    "end": "2906760"
  },
  {
    "text": "so when x is a vector and\nyou really have gradients, you can basically\nuse the same trick",
    "start": "2906760",
    "end": "2912570"
  },
  {
    "text": "and you derive\nsomething very similar where instead of looking at\nthe square of the derivative,",
    "start": "2912570",
    "end": "2918220"
  },
  {
    "text": "you have the L2 norm\nof the gradient. And instead of having just the\nsecond derivative of the log",
    "start": "2918220",
    "end": "2926060"
  },
  {
    "text": "likelihood, you have the trace\nof the Hessian of the log probability.",
    "start": "2926060",
    "end": "2931620"
  },
  {
    "text": "So again, you have to look\nat second order derivatives. But things become a little\nbit more complicated when you have the\nvector valued function.",
    "start": "2931620",
    "end": "2941740"
  },
  {
    "text": "So the Hessian is\nbasically this matrix, n by n if you have n\nvariables where you have all",
    "start": "2941740",
    "end": "2948600"
  },
  {
    "text": "the mixed second derivatives. Partial derivatives of the log\np theta x with respect to xi,",
    "start": "2948600",
    "end": "2956310"
  },
  {
    "text": "xj for all pairs of variables\nthat you have access to.",
    "start": "2956310",
    "end": "2962520"
  },
  {
    "text": "So again, kind of like a Taylor\nexpansion up to second order if you want. [INAUDIBLE] that's\ntrace operator?",
    "start": "2962520",
    "end": "2969089"
  },
  {
    "text": "And that's the trace operator. Oh, so just take all the-- Elements on the diagonal, yeah. So all the second derivatives.",
    "start": "2969090",
    "end": "2978240"
  },
  {
    "text": "So it's also return a vector? The trace will return\na scalar [INAUDIBLE]..",
    "start": "2978240",
    "end": "2983914"
  },
  {
    "start": "2983914",
    "end": "2989020"
  },
  {
    "text": "And so that's how basically\nusing the same derivation we're using integration\nby parts, you again",
    "start": "2989020",
    "end": "2996440"
  },
  {
    "text": "write it down in terms of a\nquantity that no longer depends on the score of pdata.",
    "start": "2996440",
    "end": "3003530"
  },
  {
    "text": "And that's an objective function\nthat we can now optimize. If you're willing to approximate\nthis expectation with a sample",
    "start": "3003530",
    "end": "3012890"
  },
  {
    "text": "average, we always have\naccess to samples from pdata so we can approximate that\nexpectation using samples.",
    "start": "3012890",
    "end": "3020180"
  },
  {
    "text": "Then you get an algorithm or\na loss that looks like this. You have samples of data\npoints that you sample",
    "start": "3020180",
    "end": "3029030"
  },
  {
    "text": "from pdata, training data. And then you can estimate\nthe score matching loss",
    "start": "3029030",
    "end": "3034570"
  },
  {
    "text": "with the sample mean,\nwhich would look like this. So you go through\nindividual data points,",
    "start": "3034570",
    "end": "3043500"
  },
  {
    "text": "you evaluate the gradient of\nthe energy at each data point, you look at the square of\nthe norm of that vector,",
    "start": "3043500",
    "end": "3051009"
  },
  {
    "text": "and then you need to look at the\ntrace of the Hessian of the log likelihood, which is\nthis, again, Hessian",
    "start": "3051010",
    "end": "3059880"
  },
  {
    "text": "of f theta in this case,\nwhich is the model. And then this is now\na function of theta",
    "start": "3059880",
    "end": "3068589"
  },
  {
    "text": "that you can try to optimize and\nminimize with respect to theta. You recall, we're\ntrying to minimize--",
    "start": "3068590",
    "end": "3074100"
  },
  {
    "text": "this is equivalent up to a\nshift independent from theta. It's equivalent to\nthe Fisher divergence.",
    "start": "3074100",
    "end": "3080510"
  },
  {
    "text": "So if you're able to make\nthis as small as possible with respect to\ntheta, you're trying to match the scores of the\ndata distribution and the model",
    "start": "3080510",
    "end": "3088840"
  },
  {
    "text": "distribution. [INAUDIBLE] any\nbetter so getting",
    "start": "3088840",
    "end": "3094810"
  },
  {
    "text": "the Hessian of some\nmodel or even the trace of the Hessian for that matter\nis not very trivial, is it?",
    "start": "3094810",
    "end": "3100630"
  },
  {
    "text": "It's not trivial. Yeah, that's a good point. And I think it's\ngoing to come up soon. It still has issues with\nrespect to very high dimensional",
    "start": "3100630",
    "end": "3109570"
  },
  {
    "text": "settings, like the\ntrace of the Hessian, I know it requires higher\norder differentiation and it's somewhat expensive.",
    "start": "3109570",
    "end": "3116500"
  },
  {
    "text": "But there's going to be\nways to approximate it. The key takeaway is that it\ndoes not require you to sample",
    "start": "3116500",
    "end": "3122530"
  },
  {
    "text": "from the energy-based model. This is the kind of loss where\nyou just need to training data,",
    "start": "3122530",
    "end": "3127700"
  },
  {
    "text": "you evaluate your\nneural network, and you don't need to sample\nfrom the energy-based model",
    "start": "3127700",
    "end": "3132710"
  },
  {
    "text": "during a training loop,\nwhich is key if you want to get something efficient. ",
    "start": "3132710",
    "end": "3140290"
  },
  {
    "text": "And the last function\nactually have-- this is what you just brought\nup that indeed, the Hessian is",
    "start": "3140290",
    "end": "3146560"
  },
  {
    "text": "tricky. But it has a reasonable flavor. If you think about it,\nwhat is this loss saying?",
    "start": "3146560",
    "end": "3154000"
  },
  {
    "text": "You try to minimize this\nquantity as a function of theta. So what you're saying is that\nyou should look at your data",
    "start": "3154000",
    "end": "3159580"
  },
  {
    "text": "points and you should look\nat the gradient of the log likelihood evaluated\nat every data point",
    "start": "3159580",
    "end": "3164950"
  },
  {
    "text": "and you're trying to make that\nsmall, which basically means that you're trying\nto make the data points stationary points\nfor the log likelihood.",
    "start": "3164950",
    "end": "3173120"
  },
  {
    "text": "So the data points should either\nbe local maxima or local minima for the log likelihood because\nthe gradients at the data points",
    "start": "3173120",
    "end": "3180400"
  },
  {
    "text": "should be small. So you should not be able to\nsomehow perturb the data points",
    "start": "3180400",
    "end": "3186220"
  },
  {
    "text": "by a little bit and increase\nthe likelihood by a lot because the gradients\nshould be very small",
    "start": "3186220",
    "end": "3191350"
  },
  {
    "text": "evaluated at the data. That's what this piece is doing. And this piece is\nsay, loosely trying",
    "start": "3191350",
    "end": "3199808"
  },
  {
    "text": "to make sure that\nthe data points are local maxima instead of local\nminima of the log likelihood.",
    "start": "3199808",
    "end": "3205700"
  },
  {
    "text": "And to do that, you need to look\nat the second order derivative and that's what\nthat term is doing.",
    "start": "3205700",
    "end": "3211320"
  },
  {
    "text": "Which is very reasonable. It's saying if you\nwant to fit the model, try to choose parameters so that\nthe data points are local maxima",
    "start": "3211320",
    "end": "3218150"
  },
  {
    "text": "somehow of the log likelihood. And that can be\nevaluated just by looking",
    "start": "3218150",
    "end": "3224000"
  },
  {
    "text": "at first order gradients\nand second order gradients. Yeah?",
    "start": "3224000",
    "end": "3229472"
  },
  {
    "text": "So [INAUDIBLE] trace\nof [INAUDIBLE] could it be figure out this local\nminima, maxima when you start",
    "start": "3229472",
    "end": "3234506"
  },
  {
    "text": "looking at points\nof value, and seeing if they're part of a whole? Essentially, yeah. So that's essentially what we're\ngoing to do, is we're going to--",
    "start": "3234507",
    "end": "3241220"
  },
  {
    "text": "there's two ways of doing it. One is to, I guess,\nsomething called slice score matching where you're\ntaking random directions",
    "start": "3241220",
    "end": "3249650"
  },
  {
    "text": "and you're checking\nwhether the likelihood goes up or down along those\ndirections, which is the same as--",
    "start": "3249650",
    "end": "3254750"
  },
  {
    "text": "if you know about\nthe Hutchinson trick for estimating the\nHessian, it's basically the same thing where\nit's an estimator",
    "start": "3254750",
    "end": "3261890"
  },
  {
    "text": "for the trace of a matrix that\nlooks at a random projection around or a random\ndirection around it.",
    "start": "3261890",
    "end": "3268452"
  },
  {
    "text": "And the other thing is\ndenoising score matching which also has this flavor of\nadding a little bit of noise",
    "start": "3268452",
    "end": "3274112"
  },
  {
    "text": "and checking whether\nthe likelihood goes up or down in the\nneighborhood of a data point. And so it has that\nflavor basically.",
    "start": "3274113",
    "end": "3282680"
  },
  {
    "text": "And those things are going\nto be scalable with respect to the dimension. ",
    "start": "3282680",
    "end": "3289960"
  },
  {
    "text": "Yeah? Does the Hessian have\na fixed analytical form",
    "start": "3289960",
    "end": "3296596"
  },
  {
    "text": "when you're taking\nderivative with respect to x? So it doesn't in general. So the question has the\nHessian an analytical form",
    "start": "3296596",
    "end": "3302500"
  },
  {
    "text": "if f theta is a neural network? You can't. There is no close-- I mean, you have to use autodiff\nto basically compute it.",
    "start": "3302500",
    "end": "3311120"
  },
  {
    "text": "The problem is that it\nneeds many backward passes. Because you're\nnot computing just",
    "start": "3311120",
    "end": "3316390"
  },
  {
    "text": "a single partial\nderivative, you're computing n partial derivatives\nwith respect to every input",
    "start": "3316390",
    "end": "3323230"
  },
  {
    "text": "because you have to compute\nall the diagonal elements of the Hessian and we don't know\nof an efficient way of doing",
    "start": "3323230",
    "end": "3329710"
  },
  {
    "text": "it other than doing backprop\nbasically n times, which is also expensive when n is large.",
    "start": "3329710",
    "end": "3336385"
  },
  {
    "text": " But the good thing is\nthis avoids sampling",
    "start": "3336385",
    "end": "3344190"
  },
  {
    "text": "and this is going to be the key\nbuilding block also for training diffusion models.",
    "start": "3344190",
    "end": "3350600"
  },
  {
    "text": "But more of this in\nthe next lecture.  Oh, yeah, question?",
    "start": "3350600",
    "end": "3357650"
  },
  {
    "text": "So this would converge with\n[INAUDIBLE] a sharper point peak rather than--",
    "start": "3357650",
    "end": "3363530"
  },
  {
    "text": "so there might be a\nreally sharp thing that's pretty low and\nthen a smoother higher.",
    "start": "3363530",
    "end": "3370082"
  },
  {
    "text": "It doesn't happen in the\nsense that I just proved you that this is equivalent\nto the Fisher divergence",
    "start": "3370082",
    "end": "3375950"
  },
  {
    "text": "and the Fisher\ndivergence is 0 if and only if the\ndistributions match. So even though you\nmight think that this",
    "start": "3375950",
    "end": "3383359"
  },
  {
    "text": "is not quite doing the right-- it's not quite the\nright objective, in the limit of\ninfinite data, this",
    "start": "3383360",
    "end": "3389240"
  },
  {
    "text": "would be giving you exactly\nthe-- if you were to optimize it globally, this would give you\nexactly the data distribution.",
    "start": "3389240",
    "end": "3396922"
  },
  {
    "text": "Because it's really just\nthe equivalent up to a shift to the true Fisher divergence\nthat we started with,",
    "start": "3396922",
    "end": "3402470"
  },
  {
    "text": "which is this thing here\nwhich is 0 only basically",
    "start": "3402470",
    "end": "3407840"
  },
  {
    "text": "if the densities match. ",
    "start": "3407840",
    "end": "3412890"
  },
  {
    "text": "Cool. Now the other cool technique\nthat you can use for training--",
    "start": "3412890",
    "end": "3418279"
  },
  {
    "text": "so the takeaway so far is that\nKL divergence-- approximations",
    "start": "3418280",
    "end": "3423980"
  },
  {
    "text": "to KL divergence [INAUDIBLE]\nrequire sampling, too expensive. But if you are willing\nto instead measure",
    "start": "3423980",
    "end": "3430860"
  },
  {
    "text": "similarity up here using\nthis Fisher divergence, then again, you get a loss\nfunction that is much more--",
    "start": "3430860",
    "end": "3437430"
  },
  {
    "text": "that is very suitable for\ntraining energy-based models because it does not\nrequire you to--",
    "start": "3437430",
    "end": "3442560"
  },
  {
    "text": "even though it looks tricky\nto compute and optimize, it actually can be rewritten\nin terms of something that",
    "start": "3442560",
    "end": "3448590"
  },
  {
    "text": "only depends on the model\nand you can optimize as a function of theta.",
    "start": "3448590",
    "end": "3453900"
  },
  {
    "text": "Now there is another way of\ntraining energy-based models which is going to be somewhat\nloosely similar to generative",
    "start": "3453900",
    "end": "3461390"
  },
  {
    "text": "adversarial networks\nwhich is essentially a way to fit an energy-based model\nby instead of contrasting data",
    "start": "3461390",
    "end": "3472810"
  },
  {
    "text": "to samples to from\nthe model, we're going to contrast the data\nto samples from some noise",
    "start": "3472810",
    "end": "3479440"
  },
  {
    "text": "distribution which\nis not necessarily the model distribution itself.",
    "start": "3479440",
    "end": "3486230"
  },
  {
    "text": "So that's how it works. You have the data distribution. And then there's going to be\na noise distribution which",
    "start": "3486230",
    "end": "3492760"
  },
  {
    "text": "is any distribution\nyou can sample from and for which you can\nevaluate probabilities.",
    "start": "3492760",
    "end": "3500870"
  },
  {
    "text": "And what we're going to\ndo is we're essentially going to go back through,\nagain, idea of training",
    "start": "3500870",
    "end": "3507130"
  },
  {
    "text": "a discriminator to distinguish\nbetween data samples and noise",
    "start": "3507130",
    "end": "3514150"
  },
  {
    "text": "samples. So far there is no\nenergy-based models. Just the usual\nGAN-like objective.",
    "start": "3514150",
    "end": "3523990"
  },
  {
    "text": "And the reason I'm\nbringing this up is that if you had the\noptimal discriminator, then",
    "start": "3523990",
    "end": "3530110"
  },
  {
    "text": "you would somehow\nget these density ratios between the noise\ndistribution and the data distribution.",
    "start": "3530110",
    "end": "3536770"
  },
  {
    "text": "So recall that if you train\na discriminator optimally by minimizing cross-entropy\nand so if you're",
    "start": "3536770",
    "end": "3543390"
  },
  {
    "text": "trying to discriminate\nbetween real data and samples",
    "start": "3543390",
    "end": "3549059"
  },
  {
    "text": "from the noise\ndistribution, what is the optimal discriminator?",
    "start": "3549060",
    "end": "3554910"
  },
  {
    "text": "It has to basically give\nyou the density ratio. For every x, it has\nto be able to know how likely x is under data and\nhow likely x is under the noise",
    "start": "3554910",
    "end": "3564240"
  },
  {
    "text": "distribution. So useful recap for the midterm.",
    "start": "3564240",
    "end": "3569539"
  },
  {
    "text": "This is the optimal\ndiscriminator, is the density ratio between--",
    "start": "3569540",
    "end": "3575122"
  },
  {
    "text": "for every x, you\nneed to figure out how likely it is under the\ndata versus how likely it is under the data and the\nalternative noise distribution.",
    "start": "3575122",
    "end": "3585030"
  },
  {
    "text": "And the reason I'm\nbringing this up because what we\ncould try to do is we",
    "start": "3585030",
    "end": "3591350"
  },
  {
    "text": "could try to\nbasically parameterize the discriminator in terms\nof our generative model",
    "start": "3591350",
    "end": "3599400"
  },
  {
    "text": "which could be an\nenergy-based model. So we know that the\noptimal discriminator",
    "start": "3599400",
    "end": "3604410"
  },
  {
    "text": "has this form, pdata over\npdata plus noise distribution. So we could try to just\ndefine a discriminator.",
    "start": "3604410",
    "end": "3613330"
  },
  {
    "text": "So instead of having\nwhatever MLP, whatever neural network you want to\ndiscriminate between data",
    "start": "3613330",
    "end": "3620790"
  },
  {
    "text": "versus noise, we're\ngoing to define a special type of discriminator\nwhere when we evaluate",
    "start": "3620790",
    "end": "3628710"
  },
  {
    "text": "the probability of\nx being real data,",
    "start": "3628710",
    "end": "3633720"
  },
  {
    "text": "we get the number--\ninstead of just feeding x through a neural\nnetwork arbitrarily, we get it by evaluating the\nlikelihood of x under a model p",
    "start": "3633720",
    "end": "3643830"
  },
  {
    "text": "theta versus the\nprobability under the noise",
    "start": "3643830",
    "end": "3650130"
  },
  {
    "text": "distribution, which\nagain, we're assuming is known because we're\ngenerating the noise distribution, the noise\ndata points ourselves.",
    "start": "3650130",
    "end": "3659400"
  },
  {
    "text": "And so the good thing is that\nif you could somehow come up",
    "start": "3659400",
    "end": "3664760"
  },
  {
    "text": "with the optimal discriminator\nthat distinguishes data versus noise, we know that\nthe optimal discriminator will",
    "start": "3664760",
    "end": "3672680"
  },
  {
    "text": "have this form and\nthis has to match the pdata or pdata plus noise.",
    "start": "3672680",
    "end": "3679480"
  },
  {
    "text": "And so you can see that\nsomehow if this classifier is doing very well at\ndistinguishing data from noise,",
    "start": "3679480",
    "end": "3685980"
  },
  {
    "text": "it has to learn-- basically p theta\nhas to match pdata. ",
    "start": "3685980",
    "end": "3693060"
  },
  {
    "text": "So the classifier is\nforced to make decisions based on the likelihood\nof x under p theta.",
    "start": "3693060",
    "end": "3699210"
  },
  {
    "text": "And then if it's able\nto make good decisions, then this p theta has to match\nthe data distribution basically.",
    "start": "3699210",
    "end": "3706280"
  },
  {
    "text": " That's essentially the trick\nthat we're leveraging here.",
    "start": "3706280",
    "end": "3715083"
  },
  {
    "text": "And then what we're\ngoing to do is we're going to actually\nparameterize the p theta using an energy-based model. ",
    "start": "3715083",
    "end": "3723539"
  },
  {
    "text": "But that's the key idea. Instead of using an\narbitrary neural network",
    "start": "3723540",
    "end": "3729870"
  },
  {
    "text": "as the discriminator, as\nyou would do in a GAN, we're defining a\ndiscriminator in terms",
    "start": "3729870",
    "end": "3735270"
  },
  {
    "text": "of another generative model. ",
    "start": "3735270",
    "end": "3741059"
  },
  {
    "text": "And the idea is that by training\nthe discriminator the usual way by minimizing\ncross-entropy loss,",
    "start": "3741060",
    "end": "3747600"
  },
  {
    "text": "we're forcing it to learn a\np theta that matches the data",
    "start": "3747600",
    "end": "3754080"
  },
  {
    "text": "distribution because that's\nthe only way it can do well at this binary\nclassification task.",
    "start": "3754080",
    "end": "3760549"
  },
  {
    "text": "It really needs to know which\nx's are likely under pdata to get good cross-entropy loss.",
    "start": "3760550",
    "end": "3766430"
  },
  {
    "text": "And that's only possible\nwhen p theta matches pdata. ",
    "start": "3766430",
    "end": "3771950"
  },
  {
    "text": "And we're going to see that\nthis is suitable when p theta is defined up to a constant.",
    "start": "3771950",
    "end": "3776990"
  },
  {
    "text": "[INAUDIBLE] p theta is going\nto be an energy-based model. So well, maybe let me skip this\nsince we're running out of time.",
    "start": "3776990",
    "end": "3786630"
  },
  {
    "text": "But you can also use the\nclassifiers to correct the noise distribution. But for now, let's assume that p\ntheta is an energy-based model.",
    "start": "3786630",
    "end": "3797260"
  },
  {
    "text": "So we're going to\nparameterize p theta in that previous expression in\nterms of an energy, use a trick.",
    "start": "3797260",
    "end": "3804619"
  },
  {
    "text": "Let's define up to a constant. And what we're going to\nfurther do is in general,",
    "start": "3804620",
    "end": "3813330"
  },
  {
    "text": "this normalization\nconstant Z theta is a function of the\nparameters f theta",
    "start": "3813330",
    "end": "3819000"
  },
  {
    "text": "and it's a complicated\nfunction because we don't know how to compute\nthat integral, that sum over all possible\nthings that can happen.",
    "start": "3819000",
    "end": "3826636"
  },
  {
    "text": "And so what we're\ngoing to do is we're going to treat Z theta as\nbeing an additional trainable",
    "start": "3826636",
    "end": "3833000"
  },
  {
    "text": "parameter. So not only we're going\nto optimize f theta,",
    "start": "3833000",
    "end": "3838710"
  },
  {
    "text": "but we're going to\ntreat Z theta itself as an additional trainable\nparameter which is not",
    "start": "3838710",
    "end": "3843810"
  },
  {
    "text": "explicitly constrained to take\nthe value of the normalization constant.",
    "start": "3843810",
    "end": "3848920"
  },
  {
    "text": "It's going to be some\nother scalar parameter that we can optimize over. And so if you do that,\nthen basically the density",
    "start": "3848920",
    "end": "3857470"
  },
  {
    "text": "model that we're going\nto use in the classifier now depends on theta\nand depends on Z.",
    "start": "3857470",
    "end": "3864440"
  },
  {
    "text": "And then we just plug this-- the idea is that basically\nif we plug in this expression",
    "start": "3864440",
    "end": "3872420"
  },
  {
    "text": "into the classifier, into the\ndiscriminator and we train the discriminator the usual way\nby minimizing cross-entropy,",
    "start": "3872420",
    "end": "3881260"
  },
  {
    "text": "we know that under the\noptimal parameters, this classifier will have--",
    "start": "3881260",
    "end": "3888160"
  },
  {
    "text": "the density model\nthat we're using to build the\nclassifier we'll have to match the data distribution.",
    "start": "3888160",
    "end": "3893930"
  },
  {
    "text": "And what this means is that the\noptimal theta and the optimal Z are going to be such that\nthe energy-based model is",
    "start": "3893930",
    "end": "3902690"
  },
  {
    "text": "equal to the data distribution. But crucially now, Z is\njust a learnable parameter.",
    "start": "3902690",
    "end": "3909539"
  },
  {
    "text": "It happens to be the correct\npartition function in the limit because you take the integral\nof both sides with respect",
    "start": "3909540",
    "end": "3917579"
  },
  {
    "text": "to x, you're going to\nsee that the integral of this optimal\nenergy-based model",
    "start": "3917580",
    "end": "3923970"
  },
  {
    "text": "is equal to the integral of the\ndata, which is 1 by definition. So even though we treat Z\nas a learnable parameter,",
    "start": "3923970",
    "end": "3933360"
  },
  {
    "text": "in the limit of learning\nan optimal classifier, this learnable\nparameter that is not",
    "start": "3933360",
    "end": "3939839"
  },
  {
    "text": "constrained to be the\nactual partition function will take the value of the true\npartition function of the model",
    "start": "3939840",
    "end": "3947359"
  },
  {
    "text": "because that's what the\noptimal classifier should do if it does really well\nwith this binary cross-entropy",
    "start": "3947360",
    "end": "3954740"
  },
  {
    "text": "classification of loss. This case is like a-- It's not an [INAUDIBLE].",
    "start": "3954740",
    "end": "3960680"
  },
  {
    "text": "Actually, so the loss\nfunction ends up being-- which ends up being let's\nsee something like this.",
    "start": "3960680",
    "end": "3968279"
  },
  {
    "text": "So if you plug it in, recall,\nwe're basically saying,",
    "start": "3968280",
    "end": "3973790"
  },
  {
    "text": "instead of picking an\narbitrary neural network for the discriminator\nlike in a GAN, we're going to pick\na neural network that",
    "start": "3973790",
    "end": "3979970"
  },
  {
    "text": "has a very specific\nfunctional form so that when you evaluate\nwhat is the probability that x",
    "start": "3979970",
    "end": "3985160"
  },
  {
    "text": "is real, you have to get it\nthrough this kind of computation where you have an energy-based\nmodel that tells you",
    "start": "3985160",
    "end": "3991550"
  },
  {
    "text": "how likely x is under the model. Where both f theta and Z\nare learnable parameters.",
    "start": "3991550",
    "end": "4000240"
  },
  {
    "text": "And then if you just multiply\nnumerator and denominator by Z, you get an expression\nthat, again, as it should,",
    "start": "4000240",
    "end": "4007380"
  },
  {
    "text": "it depends on f theta, and Z,\nAnd the noise distribution which is known. pn, the noise\ndistribution is, again,",
    "start": "4007380",
    "end": "4014220"
  },
  {
    "text": "something that we are deciding. You can pick whatever you\nwant as long as you can sample from it and you can\nevaluate probabilities",
    "start": "4014220",
    "end": "4020630"
  },
  {
    "text": "under the noise distribution. And then literally\nwhat we do is we still",
    "start": "4020630",
    "end": "4026330"
  },
  {
    "text": "train the classifier by\ndoing binary classification with cross-entropy loss.",
    "start": "4026330",
    "end": "4032369"
  },
  {
    "text": "So we have just like in a GAN,\nwe have data, we have real data. We have fake data\nwhich is generated",
    "start": "4032370",
    "end": "4038660"
  },
  {
    "text": "by this noise distribution\nwhich we decide ourselves. So this is different\nfrom, again, the fake data is coming from\na fixed noise distribution.",
    "start": "4038660",
    "end": "4048029"
  },
  {
    "text": "So we're contrasting\nthe real data to fake samples generated\nby the noise distribution",
    "start": "4048030",
    "end": "4055570"
  },
  {
    "text": "and we're training\nthe classifier to distinguish\nbetween these two. The classifier has this very\nspecific functional form",
    "start": "4055570",
    "end": "4063170"
  },
  {
    "text": "where it's defined in terms\nof an energy based model where the partition function is\nitself a learnable parameter.",
    "start": "4063170",
    "end": "4072510"
  },
  {
    "text": "And then we optimize\nthis with respect to both theta and Z trying\nto do as well as we can",
    "start": "4072510",
    "end": "4078390"
  },
  {
    "text": "at this classification task. Yeah? With the scheme,\nhow will the samples",
    "start": "4078390",
    "end": "4085410"
  },
  {
    "text": "you end up generating\nin the end be good? It doesn't seem like it would\nbe very hard to discriminate between even a crappy\ngenerated sample and noise.",
    "start": "4085410",
    "end": "4092590"
  },
  {
    "text": "Yeah. So what happens is\nthat in theory, this",
    "start": "4092590",
    "end": "4098040"
  },
  {
    "text": "works regardless of what\nis the noise distribution. In practice, what you\nwant is you want a noise",
    "start": "4098040",
    "end": "4104759"
  },
  {
    "text": "distribution that is very\nclose to the data distribution so that the classifier\nis really forced",
    "start": "4104760",
    "end": "4110609"
  },
  {
    "text": "to learn what makes\nfor a good sample, what makes for the real--",
    "start": "4110609",
    "end": "4115679"
  },
  {
    "text": "what kind of structures\ndo the real samples have. At the end of the\nday, what you learn is",
    "start": "4115680",
    "end": "4120810"
  },
  {
    "text": "you learn an energy-based model. So you learn an f theta and\nyou learn a partition function. And in the limit of infinite\ndata, perfect optimization,",
    "start": "4120810",
    "end": "4130810"
  },
  {
    "text": "then if you optimize\nthis loss perfectly, the energy-based model\nmatches the data distribution",
    "start": "4130810",
    "end": "4136179"
  },
  {
    "text": "and the partition\nfunction, which is just the value of these\nlearnable parameters Z that you get, actually is\nthe true partition function",
    "start": "4136180",
    "end": "4144330"
  },
  {
    "text": "of the energy-based model. So even though we're\njust training it in an unconstrained way so\nthere is no relationship here",
    "start": "4144330",
    "end": "4150719"
  },
  {
    "text": "between theta and Z,\nit just so happens that the best thing to do is\nto actually properly normalize",
    "start": "4150720",
    "end": "4157028"
  },
  {
    "text": "the model where Z theta\nbecomes the partition function of the energy-based model.",
    "start": "4157029",
    "end": "4163509"
  },
  {
    "text": "So in principle, this\ndoes the right thing. In practice, it heavily\ndepends on how good",
    "start": "4163510",
    "end": "4169710"
  },
  {
    "text": "the noise distribution is. We're not really explicitly\ntraining a discriminator.",
    "start": "4169710",
    "end": "4175399"
  },
  {
    "text": "We're just adding a new\ntrainable parameters to our agenda? So we are training an actual--\nso there is no generator.",
    "start": "4175399",
    "end": "4184500"
  },
  {
    "text": "The generator is fixed or you\ncan think of it as being fixed. So the noise\ndistribution, it would be the generator and that's fixed.",
    "start": "4184500",
    "end": "4191770"
  },
  {
    "text": "We are training a\ndiscriminator but it's a very special discriminator. So you are not allowed to\ntake x and then feed it",
    "start": "4191770",
    "end": "4198940"
  },
  {
    "text": "through a ConvNet\nor an MLP and then map it to a probability\nof being real versus fake.",
    "start": "4198940",
    "end": "4204310"
  },
  {
    "text": "You have to get the probability\nby using this expression. Yeah. Just [INAUDIBLE] the f\ntheta is just [INAUDIBLE]..",
    "start": "4204310",
    "end": "4215250"
  },
  {
    "text": "That's [INAUDIBLE]. Yeah. In that sense, yes. There is only a discriminator. Once you've trained it, you can\nextract an energy-based model,",
    "start": "4215250",
    "end": "4223330"
  },
  {
    "text": "which is the f theta,\nfrom the discriminator.",
    "start": "4223330",
    "end": "4228415"
  },
  {
    "text": "[INAUDIBLE] noise\ndistribution or you can sample the noise distribution? Yeah.",
    "start": "4228415",
    "end": "4233680"
  },
  {
    "text": "So in this flavor which\nis the simpler version, the noise distribution is fixed. We'll see if we have time\nin a few couple of slides",
    "start": "4233680",
    "end": "4241150"
  },
  {
    "text": "that indeed, it makes sense to\nchange the noise distribution and trying to adapt\nit and make it",
    "start": "4241150",
    "end": "4247030"
  },
  {
    "text": "as close as possible to the\ndata or the current best guess of the model distribution.",
    "start": "4247030",
    "end": "4252890"
  },
  {
    "text": "So that's an improvement\nover this basic version of things where the noise\ndistribution is fixed for now.",
    "start": "4252890",
    "end": "4261260"
  },
  {
    "text": "How would you sample\nin this procedure? So we're assuming that the\nnoise distribution is something",
    "start": "4261260",
    "end": "4267560"
  },
  {
    "text": "you can sample from efficiently\nso you can always basically get--",
    "start": "4267560",
    "end": "4273220"
  },
  {
    "text": "do some kind of stochastic\ngradient ascent here on this. Once you train them on--\nso the learning is fine.",
    "start": "4273220",
    "end": "4279579"
  },
  {
    "text": "It's just efficient. As long as pn is\nefficient to sample from, you never have to\nsample from p theta.",
    "start": "4279580",
    "end": "4285830"
  },
  {
    "text": "Once you've trained a\nmodel, you have an EBM. And so if you want to\ngenerate samples from it,",
    "start": "4285830",
    "end": "4291679"
  },
  {
    "text": "you have to go through\nthe MCMC, Langevin. So at inference time, you\ndon't get any benefit.",
    "start": "4291680",
    "end": "4298190"
  },
  {
    "text": "This is just at training time. This loss function does not\ninvolve sampling from the model.",
    "start": "4298190",
    "end": "4303690"
  },
  {
    "text": "So why can we not allow\nZ0 to be identical? Why is that fair deal?",
    "start": "4303690",
    "end": "4309500"
  },
  {
    "text": "It's fair game in the sense only\nto the extent that in the limit,",
    "start": "4309500",
    "end": "4314910"
  },
  {
    "text": "you will learn the\npartition function. In general, you will not. And so the solution to\nthis optimization problem",
    "start": "4314910",
    "end": "4320960"
  },
  {
    "text": "will give you a Z, in practice,\nthat is not the true partition function of the model. It's just going\nto be an estimate.",
    "start": "4320960",
    "end": "4327020"
  },
  {
    "text": "And you're going to end up\nwith an energy-based model that is suboptimal because\nyou're short of the Z",
    "start": "4327020",
    "end": "4333560"
  },
  {
    "text": "that you estimated is\nnot the true partition function for that model. So when you have finite\ndata, imperfect optimization,",
    "start": "4333560",
    "end": "4343370"
  },
  {
    "text": "you pay a price for\nthis approximation. But in the limit of\nthings being perfect,",
    "start": "4343370",
    "end": "4350150"
  },
  {
    "text": "this is not an issue basically. So pn, p theta\n[INAUDIBLE] probably",
    "start": "4350150",
    "end": "4355250"
  },
  {
    "text": "converge to the integral? Yeah. So if you have infinite\ndata and somehow you're",
    "start": "4355250",
    "end": "4362540"
  },
  {
    "text": "able to perfectly\noptimize over theta and Z, then we know that the optimal\nsolution over theta and Z",
    "start": "4362540",
    "end": "4369510"
  },
  {
    "text": "will be one where this\nmatches the data distribution. And so the only way that for\nthat to happen is for Z star",
    "start": "4369510",
    "end": "4377550"
  },
  {
    "text": "to be the true\npartition function of that energy-based model. But in practice, this\nis not going to happen.",
    "start": "4377550",
    "end": "4383890"
  },
  {
    "text": "So you just get an estimate. Yeah? So if it's not the true\npartition function,",
    "start": "4383890",
    "end": "4390110"
  },
  {
    "text": "you will have a valid\nprobability distribution for pdata, is that fine? So yeah.",
    "start": "4390110",
    "end": "4395445"
  },
  {
    "text": "So that's a great question. So if it's not a true\npartition function, you still have an\nenergy-based model",
    "start": "4395445",
    "end": "4401510"
  },
  {
    "text": "for which there is going to\nbe a real partition function. It's just not the\none you've estimated.",
    "start": "4401510",
    "end": "4406550"
  },
  {
    "text": "So f theta still defines a\nvalid energy-based model. It's just that the partition\nfunction for that model",
    "start": "4406550",
    "end": "4412730"
  },
  {
    "text": "is not going to be the\nsolution to this optimization problem over Z. So it's not\ngoing to satisfy the constraint.",
    "start": "4412730",
    "end": "4420962"
  },
  {
    "text": "But there's going\nto be a partition function for that\nf theta so that's going to be a valid\nenergy-based model. ",
    "start": "4420962",
    "end": "4428460"
  },
  {
    "text": "Implementationally,\nthis seems like-- because you're letting go of the\nconstraints and all these sorts",
    "start": "4428460",
    "end": "4434610"
  },
  {
    "text": "of things, so\nimplementationally, this must be a harder optimization\nproblem compared to something",
    "start": "4434610",
    "end": "4440010"
  },
  {
    "text": "like a score-based model\nor implementationally, somehow it works?",
    "start": "4440010",
    "end": "4445500"
  },
  {
    "text": "So this is the implementation\nthat's actually not to-- we'll see soon. And then you can ask again\nif how it's implemented.",
    "start": "4445500",
    "end": "4453330"
  },
  {
    "text": "It's a relatively simple loss\nto optimize and write down. It's actually\ntrivial to implement.",
    "start": "4453330",
    "end": "4458640"
  },
  {
    "text": "[INAUDIBLE] because you are\nalmost guaranteed that you're going to get a\nsuboptimal f theta,",
    "start": "4458640",
    "end": "4464700"
  },
  {
    "text": "xi because your Z theta is\n[INAUDIBLE] approximation. So my question is\nthat if I train",
    "start": "4464700",
    "end": "4471809"
  },
  {
    "text": "this in a score-based\nmodel, am I guaranteed that the\nscore-based model for the extra effort\nI put in there",
    "start": "4471810",
    "end": "4477480"
  },
  {
    "text": "is going to be a better model? So it turns out that they are\nactually very much related.",
    "start": "4477480",
    "end": "4482850"
  },
  {
    "text": "And then if the\nnoise distribution is what you get by\nperturbing data,",
    "start": "4482850",
    "end": "4490020"
  },
  {
    "text": "by adding a little bit of\nGaussian noise essentially, then this turns out to\nbe exactly denoising",
    "start": "4490020",
    "end": "4495090"
  },
  {
    "text": "score matching. So it very much depends\non the noise distribution",
    "start": "4495090",
    "end": "4500220"
  },
  {
    "text": "that you choose. But there are\ninstances where this becomes exactly\nscore matching so I",
    "start": "4500220",
    "end": "4505890"
  },
  {
    "text": "don't think it's fair to\nsay that this is always bad. It's just a different thing. ",
    "start": "4505890",
    "end": "4513030"
  },
  {
    "text": "Yeah? So we are going back a bit. Is the partition function\nsomething you can normally compute for\nenergy-based models or--",
    "start": "4513030",
    "end": "4519600"
  },
  {
    "text": "No, you can't. Yeah, that's the problem. And so generally [INAUDIBLE]\nusing these different methods?",
    "start": "4519600",
    "end": "4528440"
  },
  {
    "text": "So either you do\ncontrastive divergence where you would sample from\nit and so in some sense,",
    "start": "4528440",
    "end": "4533823"
  },
  {
    "text": "it involves the\npartition function in the sense that you would\nestimate the gradient of the log partition function by using\nsamples from the model",
    "start": "4533823",
    "end": "4539950"
  },
  {
    "text": "but that's also too expensive. Or that's exactly what\nwe're doing right now. Let's come up with a training\nobjective that does not depend",
    "start": "4539950",
    "end": "4546340"
  },
  {
    "text": "on the partition function. So it's going to be efficient. ",
    "start": "4546340",
    "end": "4552969"
  },
  {
    "text": "Cool. And so then for\nnumerical stability, let me see what do I have here.",
    "start": "4552970",
    "end": "4560409"
  },
  {
    "text": "So that's the objective. And then you plug\nin the expression for the discriminator\nin here and you get",
    "start": "4560410",
    "end": "4568469"
  },
  {
    "text": "a loss that looks like this. And you have the log\nof sum of two things.",
    "start": "4568470",
    "end": "4573580"
  },
  {
    "text": "And so for numerical\nstability, it's actually easier to use the log sumexp trick\nwhere the log of e of f theta",
    "start": "4573580",
    "end": "4582960"
  },
  {
    "text": "plus Zpn which is what you\nhave in the denominator, it's more numerically stable\nto write as a log sumexp.",
    "start": "4582960",
    "end": "4591270"
  },
  {
    "text": "But then practically\nspeaking, the implementation is very simple. You start with a\nbatch of data points.",
    "start": "4591270",
    "end": "4598679"
  },
  {
    "text": "You have a batch\nof noise samples. And basically, you\nhave this classifier",
    "start": "4598680",
    "end": "4607500"
  },
  {
    "text": "which has a very\nspecific functional form. And just you evaluate\nthe cross-entropy loss of that classifier on\nthis mini batch which",
    "start": "4607500",
    "end": "4614910"
  },
  {
    "text": "happens to have this\nkind of functional form. And then you optimize it as\na function of theta and Z.",
    "start": "4614910",
    "end": "4623795"
  },
  {
    "text": "And that's just basically\nwhat we had before. So you're evaluating the loss of\nthe classifier where these two",
    "start": "4623795",
    "end": "4631350"
  },
  {
    "text": "batches are real\nand fake or real and samples from the\nnoise distribution.",
    "start": "4631350",
    "end": "4636450"
  },
  {
    "text": "And then you try to maximize\nthese as a function of theta and Z. And stochastic\ngradient ascent with respect",
    "start": "4636450",
    "end": "4644670"
  },
  {
    "text": "to theta and Z. And\nagain, key thing you don't need to sample\nfrom the model.",
    "start": "4644670",
    "end": "4650580"
  },
  {
    "text": " And you can see that\nthe dependence on Z",
    "start": "4650580",
    "end": "4655920"
  },
  {
    "text": "is non-trivial in the\nsense that sometimes, it's not optimal to just make Z\nas small as possible or as",
    "start": "4655920",
    "end": "4661920"
  },
  {
    "text": "big as possible. It depends on Z on\nsome non-trivial way and so there is some interesting\nlearning happening here",
    "start": "4661920",
    "end": "4669090"
  },
  {
    "text": "over both theta and Z. But at the end of\nthe day, you end up",
    "start": "4669090",
    "end": "4676560"
  },
  {
    "text": "with an estimate of the\nenergy of the model f theta and an estimate of the\nlog partition function.",
    "start": "4676560",
    "end": "4682110"
  },
  {
    "text": "And everything can be\ntrained without using samples from the energy-based model.",
    "start": "4682110",
    "end": "4688360"
  },
  {
    "text": "So it looks a lot like a GAN,\nGenerative Adversarial Network,",
    "start": "4688360",
    "end": "4693630"
  },
  {
    "text": "in the sense that in both cases,\nyou are training a discriminator with binary cross-entropy. So that part is the same.",
    "start": "4693630",
    "end": "4699540"
  },
  {
    "text": " Both are likelihood free. We don't have\nlikelihoods in EBM.",
    "start": "4699540",
    "end": "4706179"
  },
  {
    "text": "So it better be. There is never a need\nto evaluate likelihoods under the EBM or under\nthe data distribution",
    "start": "4706180",
    "end": "4714900"
  },
  {
    "text": "because we don't\nhave either of them. So it's all just a standard\ncross-entropy loss basically",
    "start": "4714900",
    "end": "4720060"
  },
  {
    "text": "on a classification task reduced\nto a discriminative modeling-- generative model\nto discriminative",
    "start": "4720060",
    "end": "4726210"
  },
  {
    "text": "classifier training. The key difference\nis that in a GAN,",
    "start": "4726210",
    "end": "4732179"
  },
  {
    "text": "you actually have a minimax\noptimization where you are also training the noise, you're\ntraining the generator.",
    "start": "4732180",
    "end": "4737949"
  },
  {
    "text": "Here we are not. Here this is table. It's easy to train. The noise distribution is fixed.",
    "start": "4737950",
    "end": "4743280"
  },
  {
    "text": "And you're just maximizing\nthat objective function as a function of theta. It's non-convex but\nthere is no minimax.",
    "start": "4743280",
    "end": "4750400"
  },
  {
    "text": "There is no instability. It's actually relatively\nstable to train. ",
    "start": "4750400",
    "end": "4757170"
  },
  {
    "text": "And the slight difference\nis that in noise contrastive estimation, you need\nto be able to evaluate",
    "start": "4757170",
    "end": "4764130"
  },
  {
    "text": "the likelihoods of the\ncontrastive samples that you generate from the noise\ndistribution while in a GAN,",
    "start": "4764130",
    "end": "4770280"
  },
  {
    "text": "you just need to be able to\nsample from the generator. So if you look at\nthe loss here we need to be able to\nevaluate when we generate",
    "start": "4770280",
    "end": "4777469"
  },
  {
    "text": "from pn, from the\nnoise distribution, we also need to be\nable to evaluate how likely these noisy samples are.",
    "start": "4777470",
    "end": "4783770"
  },
  {
    "text": "In a GAN, you don't have to. You just need to be able\nto generate them fast. So that's slightly different.",
    "start": "4783770",
    "end": "4790588"
  },
  {
    "text": "And when you're\ntrain the NCE model,",
    "start": "4790588",
    "end": "4795670"
  },
  {
    "text": "you just train\nthe discriminator. And then from the\ndiscriminator, you get an energy function which\ndefines an energy-based model.",
    "start": "4795670",
    "end": "4802360"
  },
  {
    "text": "While in a GAN, you're actually\ntraining deterministic sample generator.",
    "start": "4802360",
    "end": "4807920"
  },
  {
    "text": "So the outcome of the learning\nis going to be different. ",
    "start": "4807920",
    "end": "4814720"
  },
  {
    "text": "And maybe the last\nthing that I'll say is what was\nsuggested before,",
    "start": "4814720",
    "end": "4819760"
  },
  {
    "text": "is that it might make sense to\nadapt the noise distribution",
    "start": "4819760",
    "end": "4825199"
  },
  {
    "text": "as you go during training. And so instead of keeping\na fixed noise distribution,",
    "start": "4825200",
    "end": "4831889"
  },
  {
    "text": "we can try to learn it jointly\nwith the discriminator. So recall we need an energy--\nwe need a noise distribution",
    "start": "4831890",
    "end": "4838760"
  },
  {
    "text": "that we can sample\nfrom efficiently and we can evaluate\nprobabilities over efficiently.",
    "start": "4838760",
    "end": "4843910"
  },
  {
    "text": "And so the natural candidate\nis a flow-based model for this.",
    "start": "4843910",
    "end": "4849340"
  },
  {
    "text": "And intuitively, we're\ntraining the noise distribution to make the classification\nproblem as hard as possible",
    "start": "4849340",
    "end": "4858590"
  },
  {
    "text": "so that the noise distribution\nis close to pdata. And so the flow\ncontrastive estimation",
    "start": "4858590",
    "end": "4864490"
  },
  {
    "text": "is basically this idea\nwhere the noise distribution is defined by a normalizing\nflow with parameters phi.",
    "start": "4864490",
    "end": "4872720"
  },
  {
    "text": "And then it's\nbasically the same, except that now\nthe discriminator",
    "start": "4872720",
    "end": "4878565"
  },
  {
    "text": "depends on the noise\ndistribution which is a flow model. So it will depend on the\nparameters of the flow.",
    "start": "4878565",
    "end": "4884387"
  },
  {
    "text": "Flow model, you can\nsample from efficiently. You can evaluate\nlikelihoods efficiently. So it fits with\nthis kind of API.",
    "start": "4884387",
    "end": "4891289"
  },
  {
    "text": "And then now we optimize\nthe discriminator over theta and Z the usual way by noise\ncontrastive estimation.",
    "start": "4891290",
    "end": "4899239"
  },
  {
    "text": "And then what they propose\nis to train the flow model",
    "start": "4899240",
    "end": "4905060"
  },
  {
    "text": "in a minimax way,\nso it goes back to GANs in some way by\ntrain the flow model",
    "start": "4905060",
    "end": "4911210"
  },
  {
    "text": "to confuse the discriminator\nas much as possible. So that's their proposal.",
    "start": "4911210",
    "end": "4919505"
  },
  {
    "text": "Really curious. In the end does the flow\nmodel perform better or does [INAUDIBLE]? In the end, they\nuse the flow model.",
    "start": "4919505",
    "end": "4925660"
  },
  {
    "text": "So here are some samples\nand they are actually generated from the flow model. [CHUCKLES] Although,\ntechnically, they get both.",
    "start": "4925660",
    "end": "4931535"
  },
  {
    "text": "They get an energy-based model\nand they get a flow model. And they show that\nfor some things, you're better off using\nthe energy-based model.",
    "start": "4931535",
    "end": "4938350"
  },
  {
    "text": "But you get both at\nthe end of the day. It's more [INAUDIBLE]. It's more like a GAN, yeah.",
    "start": "4938350",
    "end": "4944058"
  },
  {
    "text": " So basically, noise\ncontrastive estimation",
    "start": "4944058",
    "end": "4949630"
  },
  {
    "text": "where the noise\ndistribution is a flow that is learned adversarially. Recall that the inside\nthis max here, inside",
    "start": "4949630",
    "end": "4957760"
  },
  {
    "text": "is basically the loss of\na discriminator in a GAN. It tells you how confused\nthe discriminator is.",
    "start": "4957760",
    "end": "4965060"
  },
  {
    "text": "Well, not how confused. How not confused. And so by minimizing\nit, you're trying",
    "start": "4965060",
    "end": "4971218"
  },
  {
    "text": "to make the life of\nthe discriminator as hard as possible. And so you're learning something\nby minimizing a two-sample test",
    "start": "4971218",
    "end": "4977590"
  },
  {
    "text": "essentially. And so it's the same as\nthe usual GAN training. And then here are some samples\nthat they generated in a model.",
    "start": "4977590",
    "end": "4985160"
  },
  {
    "text": "And I think this is probably\na good time to stop. I think we're out of time. ",
    "start": "4985160",
    "end": "4994000"
  }
]
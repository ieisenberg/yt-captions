[
  {
    "start": "0",
    "end": "10000"
  },
  {
    "start": "0",
    "end": "9800"
  },
  {
    "text": "INSOP SONG: My name is Insop. So today, I'd like to go over\nagentic AI, agentic language",
    "start": "9800",
    "end": "17630"
  },
  {
    "start": "10000",
    "end": "110000"
  },
  {
    "text": "model as a progression\nof language model usage. So here is the outline\nof today's talk.",
    "start": "17630",
    "end": "24660"
  },
  {
    "text": "We'll go over the overview of\nlanguage model and how we use, and then the common limitations,\nand then some of the methods",
    "start": "24660",
    "end": "33680"
  },
  {
    "text": "that can prove towards\nthis common limitation. And then we'll transition into\nwhat is the agentic language",
    "start": "33680",
    "end": "41210"
  },
  {
    "text": "model and its design patterns. So a language model\nis a machine learning",
    "start": "41210",
    "end": "49520"
  },
  {
    "text": "model that predicts the next\ncoming word given the input text. As in this example, if the input\nis the students open their,",
    "start": "49520",
    "end": "59559"
  },
  {
    "text": "then language model\ncan predict what's the most likely word\ncoming next as a next word.",
    "start": "59560",
    "end": "68079"
  },
  {
    "text": "So if the language model is\ntrained with a large corpus, it is predict--",
    "start": "68080",
    "end": "74430"
  },
  {
    "text": "it is generating the\nprobability of next coming word. In this example, you can\nsee, books and laptops",
    "start": "74430",
    "end": "83040"
  },
  {
    "text": "have a higher probability than\nother words in the vocabulary.",
    "start": "83040",
    "end": "88630"
  },
  {
    "text": "So the completion of\nthis whole sentence could be the students\nopen their books.",
    "start": "88630",
    "end": "94990"
  },
  {
    "text": "And then if you want to\nkeep generating the what's coming next, then we can\nturn them in as an input",
    "start": "94990",
    "end": "101430"
  },
  {
    "text": "and then put it into\nthe language model, and then language model\ncontinuously generating",
    "start": "101430",
    "end": "107340"
  },
  {
    "text": "the next coming word. Then how these language\nmodels are trained?",
    "start": "107340",
    "end": "114360"
  },
  {
    "start": "110000",
    "end": "150000"
  },
  {
    "text": "Largely two parts-- pre-training\npart and then post training",
    "start": "114360",
    "end": "119860"
  },
  {
    "text": "part. And then first\npre-training portion is the one that\nlanguage models are",
    "start": "119860",
    "end": "126219"
  },
  {
    "text": "trained with large corpus,\ntexts collected from internet",
    "start": "126220",
    "end": "132220"
  },
  {
    "text": "or books, or different types of\ntexts, publicly available text, and then trained with the next\ntoken or next word prediction",
    "start": "132220",
    "end": "140830"
  },
  {
    "text": "objectives. So once the models is finished\nin this pre-training stage,",
    "start": "140830",
    "end": "146630"
  },
  {
    "text": "models are fairly\ngood at predicting any words coming next as\na word given the inputs.",
    "start": "146630",
    "end": "155379"
  },
  {
    "start": "150000",
    "end": "240000"
  },
  {
    "text": "However, the pre-trained model\nitself is not easy to use.",
    "start": "155380",
    "end": "162860"
  },
  {
    "text": "So hence, the post\ntraining steps are coming. And then these\npost training stage",
    "start": "162860",
    "end": "170680"
  },
  {
    "text": "would include instruction\nfollowing training, as well as the reinforcement\nlearning with human feedback.",
    "start": "170680",
    "end": "176640"
  },
  {
    "text": "And what this\ntraining stage means is we could prepare\na data set in such",
    "start": "176640",
    "end": "185300"
  },
  {
    "text": "a way that specific\ninstruction or question. And then the answers\nor the generated output",
    "start": "185300",
    "end": "192420"
  },
  {
    "text": "that is what the user\nwould expect or more",
    "start": "192420",
    "end": "199580"
  },
  {
    "text": "related to the\nquestions and answers. So that's how the\nmodels are trained",
    "start": "199580",
    "end": "205130"
  },
  {
    "text": "so that it's easier to use. And then also, it will\nrespond to a specific styles.",
    "start": "205130",
    "end": "210569"
  },
  {
    "text": "And then once this is done, and\nthen additional training method",
    "start": "210570",
    "end": "216500"
  },
  {
    "text": "is aligning to human preference\nby using reinforcement learning",
    "start": "216500",
    "end": "222650"
  },
  {
    "text": "with human feedback, which is\nusing human preference to align",
    "start": "222650",
    "end": "228590"
  },
  {
    "text": "the model by using\nrewards schemes. And let's take a\nquick look, really",
    "start": "228590",
    "end": "236140"
  },
  {
    "text": "quick look on the\ninstruction data set. This is the template\nthat we will",
    "start": "236140",
    "end": "242890"
  },
  {
    "start": "240000",
    "end": "340000"
  },
  {
    "text": "use to train the model in\ninstruction following training phase. As you can see, there is\na specific instructions",
    "start": "242890",
    "end": "250239"
  },
  {
    "text": "will be substituted in. And then expected output\nwill be substituted in. And then this is\nfed to the model.",
    "start": "250240",
    "end": "256430"
  },
  {
    "text": "And the model is only\ntrained on the response part that is generating the\noutput based on the given",
    "start": "256430",
    "end": "266200"
  },
  {
    "text": "instructions. So language model that is\ntrained on pre-training stage,",
    "start": "266200",
    "end": "273849"
  },
  {
    "text": "as well as\npost-training stage, is quite capable of generating\ntext given instruction.",
    "start": "273850",
    "end": "283810"
  },
  {
    "text": "Essentially, it has a\nlot of world knowledge that could easily\ngenerate the outputs.",
    "start": "283810",
    "end": "290050"
  },
  {
    "text": "So these are rapidly developing. And then these models are used\nin various application domains",
    "start": "290050",
    "end": "298100"
  },
  {
    "text": "that we use day-to-day\nwork such as AI coding",
    "start": "298100",
    "end": "304850"
  },
  {
    "text": "assistance or\ndomain-specific AI copilots or most widely known\nChatGPT and related",
    "start": "304850",
    "end": "312259"
  },
  {
    "text": "conversational interfaces. And then in order to\nuse these type of models",
    "start": "312260",
    "end": "318440"
  },
  {
    "text": "as for your applications\nor specific tools,",
    "start": "318440",
    "end": "326580"
  },
  {
    "text": "you could use the cloud-based\nAPI calls towards the model",
    "start": "326580",
    "end": "333860"
  },
  {
    "text": "provider or the model\nservers, or some other ways that you could also host the\nmodels on your local machines",
    "start": "333860",
    "end": "344000"
  },
  {
    "start": "340000",
    "end": "410000"
  },
  {
    "text": "or even mobile\nmachines for the models that are small enough\nto host on this compute",
    "start": "344000",
    "end": "352020"
  },
  {
    "text": "constrained environments. So what does it mean\nby using API calls?",
    "start": "352020",
    "end": "359230"
  },
  {
    "text": "So we step back. The language model is taking the\ninput, natural language input",
    "start": "359230",
    "end": "366840"
  },
  {
    "text": "text, and then\ngenerating the output. So that means we need to\nprepare a certain form",
    "start": "366840",
    "end": "374130"
  },
  {
    "text": "of free-form text,\nnatural language text as an instruction or\na question, and then",
    "start": "374130",
    "end": "380370"
  },
  {
    "text": "put them in a specific format\nthat you could make an API call towards the model provider.",
    "start": "380370",
    "end": "387100"
  },
  {
    "text": "And then the model\nprovider takes that usually on a cloud environment, and\nthen generate the output",
    "start": "387100",
    "end": "393690"
  },
  {
    "text": "and then respond to your API\ncalls with the generated output.",
    "start": "393690",
    "end": "398980"
  },
  {
    "text": "Then your software\naround, that software that based on this model,\nwill parse the output.",
    "start": "398980",
    "end": "405389"
  },
  {
    "text": "And then use it as\nis, or maybe you could make a follow\nup LLM API calls",
    "start": "405390",
    "end": "414669"
  },
  {
    "start": "410000",
    "end": "540000"
  },
  {
    "text": "to further generate the output. ",
    "start": "414670",
    "end": "420340"
  },
  {
    "text": "So the input to the model\nis again free-form text.",
    "start": "420340",
    "end": "427550"
  },
  {
    "text": "So how you prepare your input,\nalso known as a prompting is critical.",
    "start": "427550",
    "end": "434090"
  },
  {
    "text": "So there are well-known\nbest practices strategy,",
    "start": "434090",
    "end": "440290"
  },
  {
    "text": "how you prepare your prompt. And here are some of them. And such as write a clear and\nvery descriptive and detailed",
    "start": "440290",
    "end": "449380"
  },
  {
    "text": "instructions that\nwill help the model to generate the\noutput that you want.",
    "start": "449380",
    "end": "454850"
  },
  {
    "text": "And you could include\na couple of examples. The form that you want to\nsee as in the style or form.",
    "start": "454850",
    "end": "463400"
  },
  {
    "text": "And also, you could provide\nthe provide the references",
    "start": "463400",
    "end": "468860"
  },
  {
    "text": "or context such a way that\nmodel rely on that context that you provide.",
    "start": "468860",
    "end": "475520"
  },
  {
    "text": "And instead of just ask the\nmodel to answer right away,",
    "start": "475520",
    "end": "480960"
  },
  {
    "text": "you could ask\nmodel to give model to time to think about\nit, such as reasoning,",
    "start": "480960",
    "end": "488600"
  },
  {
    "text": "enable reasoning, or using\nchain of thought or COT method.",
    "start": "488600",
    "end": "493820"
  },
  {
    "text": "And the next one is\ninstead of asking model",
    "start": "493820",
    "end": "499040"
  },
  {
    "text": "really complex task, you\ncould break them down and then ask them chain in sequence,\nalso chain the complex prompts.",
    "start": "499040",
    "end": "510530"
  },
  {
    "text": "And the last one\nis something that is a good engineering practice.",
    "start": "510530",
    "end": "516479"
  },
  {
    "text": "Have a good way of systemic\ntrace and logging will help you. And also, automated\nevaluation is always",
    "start": "516480",
    "end": "524700"
  },
  {
    "text": "helpful to develop\nyour essential, to develop your progress\non your application.",
    "start": "524700",
    "end": "530519"
  },
  {
    "text": "So let's take a quick look at\non each items, what that means,",
    "start": "530520",
    "end": "536340"
  },
  {
    "text": "to get more familiar with. So write clear and\ndescriptive instruction.",
    "start": "536340",
    "end": "543120"
  },
  {
    "start": "540000",
    "end": "670000"
  },
  {
    "text": "As an example on the left,\ninstead of asking short request,",
    "start": "543120",
    "end": "549040"
  },
  {
    "text": "you could describe in\ndetail so that model knows what you are\nasking because model",
    "start": "549040",
    "end": "556110"
  },
  {
    "text": "doesn't understand. Model cannot read your mind so\nthat means you need to describe",
    "start": "556110",
    "end": "561990"
  },
  {
    "text": "what you want the model to\ngenerate the output for you.",
    "start": "561990",
    "end": "567820"
  },
  {
    "text": "So this is always useful for\nusing language model in general.",
    "start": "567820",
    "end": "575250"
  },
  {
    "text": "And include few shot examples. So meaning that give keep model\nthe example input and output",
    "start": "575250",
    "end": "584210"
  },
  {
    "text": "that you would expect. As in this case, you have some\ntype of consistent style output.",
    "start": "584210",
    "end": "591990"
  },
  {
    "text": "Then what is the\nconsistent style? You provide an input as an\nexample input and example output",
    "start": "591990",
    "end": "599960"
  },
  {
    "text": "that you would ask. And then finally, you ask\nyour original questions.",
    "start": "599960",
    "end": "605070"
  },
  {
    "text": "Then it's going to be-- the model will generate the\noutput based on your input.",
    "start": "605070",
    "end": "610620"
  },
  {
    "text": "So few shot examples is always\nhelpful to generate the output that you would want to generate.",
    "start": "610620",
    "end": "619880"
  },
  {
    "text": "So provide relevant\ncontext and references. This is really helpful\nfor many of the cases that",
    "start": "619880",
    "end": "628430"
  },
  {
    "text": "are related to\ngenerating text-based on some factual information.",
    "start": "628430",
    "end": "635340"
  },
  {
    "text": "So LLM can easily generate some\nincorrect output, also known",
    "start": "635340",
    "end": "641460"
  },
  {
    "text": "as a hallucination. For those topics that it\ndoesn't know or is not",
    "start": "641460",
    "end": "648420"
  },
  {
    "text": "too confident about, so\nfor those type of cases, providing context or\nreferences would always help.",
    "start": "648420",
    "end": "656430"
  },
  {
    "text": "So here is the example\nprompt template that you would want to use\nin cases such as retrieval",
    "start": "656430",
    "end": "665490"
  },
  {
    "text": "augmented generation that we'll\nlook at in the following slides. Saying that only answer based on\nthe input, based on the article",
    "start": "665490",
    "end": "676199"
  },
  {
    "start": "670000",
    "end": "820000"
  },
  {
    "text": "that you provide, you could\nsubstitute your related reference. And then only answer\nbased on these references.",
    "start": "676200",
    "end": "685200"
  },
  {
    "text": "If the model cannot\nfind the answer, you could just say that\ncannot find the answer.",
    "start": "685200",
    "end": "691000"
  },
  {
    "text": "Then model will likely\ngenerate the answer based on your references. ",
    "start": "691000",
    "end": "700660"
  },
  {
    "text": "So this is important part that\nkeep models time to think.",
    "start": "700660",
    "end": "706370"
  },
  {
    "text": "In other words, instead\nask direct question, you ask model to\nthink through it",
    "start": "706370",
    "end": "712780"
  },
  {
    "text": "or come up with\nits own solution. And then finally, compare\nand generate the output.",
    "start": "712780",
    "end": "720670"
  },
  {
    "text": "So this is also known\nas a chain of thought. So here is one example\nthat might not work",
    "start": "720670",
    "end": "730660"
  },
  {
    "text": "in some medium-sized model. You could ask model saying that\nevaluate the student's solution",
    "start": "730660",
    "end": "741490"
  },
  {
    "text": "is correct or not, and then\nprovide a solution description. And then finally give\nstudent solution.",
    "start": "741490",
    "end": "748910"
  },
  {
    "text": "And since the system prompt\nor your original request",
    "start": "748910",
    "end": "754660"
  },
  {
    "text": "is saying that just answer\nit is correct or wrong. Model might not get it right.",
    "start": "754660",
    "end": "760770"
  },
  {
    "text": "However, for the\nsame model, that might not get the\nright answer for this",
    "start": "760770",
    "end": "765930"
  },
  {
    "text": "if you prepare your prompt\nin a way that you could ask.",
    "start": "765930",
    "end": "771260"
  },
  {
    "text": "First, work out your own\nsolution to the problem first, and then\ncompare your solution",
    "start": "771260",
    "end": "776660"
  },
  {
    "text": "to the student solution. Then by doing this, model will\ngenerate its own solution,",
    "start": "776660",
    "end": "782640"
  },
  {
    "text": "and then as it does, it\nwill have an opportunity to provide good attention\nto all these inputs",
    "start": "782640",
    "end": "790550"
  },
  {
    "text": "that it's from the original\ninput as well as the output",
    "start": "790550",
    "end": "795920"
  },
  {
    "text": "that it generated, and then\nturn towards the right answers. So reasoning chain\nof thought is always",
    "start": "795920",
    "end": "803630"
  },
  {
    "text": "helpful to generate the generate\noutput that you want to see.",
    "start": "803630",
    "end": "811850"
  },
  {
    "text": "So here's an interesting\none, probably easy to implement\nfor your application.",
    "start": "811850",
    "end": "818020"
  },
  {
    "text": "So instead of asking\nyour request, that includes, say, multiple\ntasks in one request,",
    "start": "818020",
    "end": "824890"
  },
  {
    "start": "820000",
    "end": "990000"
  },
  {
    "text": "you could prepare your prompt\nin small, simple stages.",
    "start": "824890",
    "end": "831130"
  },
  {
    "text": "So how you do is\nprepare a simple prompt",
    "start": "831130",
    "end": "836370"
  },
  {
    "text": "and then generate the output. And then prepend the output\nto the next stage two prompt.",
    "start": "836370",
    "end": "843970"
  },
  {
    "text": "And then generate the output. And then again, prepend the\noutput from the previous stage.",
    "start": "843970",
    "end": "850290"
  },
  {
    "text": "And then generate the output\nin a third stage, like here. And then finally,\ngenerate the output",
    "start": "850290",
    "end": "855540"
  },
  {
    "text": "that you would want to see. So by doing this, you may\nneed to do it manually,",
    "start": "855540",
    "end": "861280"
  },
  {
    "text": "or this can be done\nby LLM as we'll",
    "start": "861280",
    "end": "866340"
  },
  {
    "text": "see in the following slides. But having a simple, clear\ntask per each request",
    "start": "866340",
    "end": "873940"
  },
  {
    "text": "would be a good way to do it. ",
    "start": "873940",
    "end": "881269"
  },
  {
    "text": "So this may not be obvious. But because many type of--",
    "start": "881270",
    "end": "890920"
  },
  {
    "text": "as with many engineering\napplication or development having a good way\nof keeping, tracing,",
    "start": "890920",
    "end": "898990"
  },
  {
    "text": "logging will definitely be\nhelpful for your development for debugging as\nwell as auditing.",
    "start": "898990",
    "end": "904820"
  },
  {
    "text": "So same principle\napplies to language model-based development. So keep track of the\nlog is always good.",
    "start": "904820",
    "end": "912710"
  },
  {
    "text": "And so that also\nrelates to having",
    "start": "912710",
    "end": "919510"
  },
  {
    "text": "a automated evaluation from the\nearly stage of your development will definitely help you.",
    "start": "919510",
    "end": "925970"
  },
  {
    "text": "In other words, you need to\nprepare question and answer pair, ground truth answer pair\nso that you could compare that",
    "start": "925970",
    "end": "935630"
  },
  {
    "text": "against the generated output. And you could use a\nhuman to evaluate that.",
    "start": "935630",
    "end": "942720"
  },
  {
    "text": "But that's usually a\ncostly and time-consuming. So you may use to use--",
    "start": "942720",
    "end": "949740"
  },
  {
    "text": "you may use a language\nmodel as a judge. Meaning that you could ask\nlanguage model to evaluate",
    "start": "949740",
    "end": "957889"
  },
  {
    "text": "model-generated output as\nwell with ground truth output",
    "start": "957890",
    "end": "963120"
  },
  {
    "text": "so that model can score the\ngenerated output's quality so that you can use that against\nyour currently developed,",
    "start": "963120",
    "end": "971870"
  },
  {
    "text": "your own applications. This will help. This will be very important\nbecause the language models are",
    "start": "971870",
    "end": "980540"
  },
  {
    "text": "continuously and\nrapidly improving, as well as the\nmethodology and the tools",
    "start": "980540",
    "end": "986300"
  },
  {
    "text": "that you are using for\ndeveloping language model is also rapidly developing.",
    "start": "986300",
    "end": "992590"
  },
  {
    "start": "990000",
    "end": "1230000"
  },
  {
    "text": "In other words, without\nclear evaluation, it is hard to make\nforward progress",
    "start": "992590",
    "end": "999100"
  },
  {
    "text": "or even hard to\nchange the model, change the different\ntype of models.",
    "start": "999100",
    "end": "1004200"
  },
  {
    "text": "Because the models are\nrapidly developing also",
    "start": "1004200",
    "end": "1009930"
  },
  {
    "text": "means that some models\nare rapidly deprecated, which means you may need to\nforce to change your language",
    "start": "1009930",
    "end": "1017760"
  },
  {
    "text": "model that you are using\nin your application. So having a good evaluation\nmethodology upfront",
    "start": "1017760",
    "end": "1025290"
  },
  {
    "text": "from the beginning\nwill definitely help. ",
    "start": "1025290",
    "end": "1030990"
  },
  {
    "text": "So this is simple\nidea, but will be helpful for many applications.",
    "start": "1030990",
    "end": "1039010"
  },
  {
    "text": "So instead of taking your input\nprompt as is and then process it, you may have some\nsoftware or some model",
    "start": "1039010",
    "end": "1048099"
  },
  {
    "text": "that you could\ndetect the intention and then send it to a\ndifferent prompt handlers.",
    "start": "1048099",
    "end": "1053780"
  },
  {
    "text": "Or this is also known\nas prompt router. So based on the\ninput query type,",
    "start": "1053780",
    "end": "1061759"
  },
  {
    "text": "you may need to use\nsimple prompt together with simple language model. And then this will both help\nin terms of operation costs",
    "start": "1061760",
    "end": "1072490"
  },
  {
    "text": "as well as generate a\nmore appropriate output together with a more relevant\nprompt with the language",
    "start": "1072490",
    "end": "1083260"
  },
  {
    "text": "model that is more capable\nof that type of query. ",
    "start": "1083260",
    "end": "1092030"
  },
  {
    "text": "So maybe Petra, if this may be\na good moment that we could take",
    "start": "1092030",
    "end": "1100640"
  },
  {
    "text": "question if you could see. PETRA: Thank you so much,\nInsop, and such an inspirational",
    "start": "1100640",
    "end": "1108380"
  },
  {
    "text": "talk already. Thank you so much. We will get to more details\nabout agentic AI just shortly.",
    "start": "1108380",
    "end": "1114860"
  },
  {
    "text": "We did want to provide\nyou with some background and the progression what has\nbeen going on in the field.",
    "start": "1114860",
    "end": "1121640"
  },
  {
    "text": "But I think maybe let's ask\none question that came up.",
    "start": "1121640",
    "end": "1126793"
  },
  {
    "text": "It's a little bit\nspecific, but it might be what more people\nare wondering about. And is there any\noptimal amount of data",
    "start": "1126793",
    "end": "1133820"
  },
  {
    "text": "to perform a good training\nor anything that you could advise people\naround the data available",
    "start": "1133820",
    "end": "1141320"
  },
  {
    "text": "or data being used?  INSOP SONG: Maybe\nI'll be short on this.",
    "start": "1141320",
    "end": "1148700"
  },
  {
    "text": "So I assume the training\nhere is meaning that fine tuning the LLMs in additional\ntraining on top of open source",
    "start": "1148700",
    "end": "1159260"
  },
  {
    "text": "language model. Yeah, depends on your task.",
    "start": "1159260",
    "end": "1166150"
  },
  {
    "text": "It would definitely\nvary because it's hard to say one or the other. But if you have enough\ndata set or text",
    "start": "1166150",
    "end": "1178530"
  },
  {
    "text": "that you would want\nto see, then you may come up with\na simple question and answer pair or instruction\nfollowing data set format.",
    "start": "1178530",
    "end": "1186309"
  },
  {
    "text": "And then you could also\nmake use of language model to further generate more\nif you need it more.",
    "start": "1186310",
    "end": "1193720"
  },
  {
    "text": "But I would think\nyou would start with, say, tens of data--\nsamples of data set first,",
    "start": "1193720",
    "end": "1202320"
  },
  {
    "text": "and then see whether that\nmakes the model behave what you actually see it to behave.",
    "start": "1202320",
    "end": "1209049"
  },
  {
    "text": "And then you could add based\non the result or signals from the initial quick test.",
    "start": "1209050",
    "end": "1215590"
  },
  {
    "text": "Then you could additionally\nadd more data set or data set samples\npossibly used",
    "start": "1215590",
    "end": "1222309"
  },
  {
    "text": "language model to augment\nit or synthetic data that you could create. Great question.",
    "start": "1222310",
    "end": "1227840"
  },
  {
    "text": "PETRA: Thank you so much. I see questions started\ncoming in, which is wonderful.",
    "start": "1227840",
    "end": "1232990"
  },
  {
    "start": "1230000",
    "end": "1310000"
  },
  {
    "text": "I think we will pause\nthe question for now, and we will try to get to as\nmany as we can at the end. But please keep them coming.",
    "start": "1232990",
    "end": "1239480"
  },
  {
    "text": "Definitely makes the\nsession more engaging and also let us know what\nyou are interested in. Thank you. INSOP SONG: Thank you, Petra.",
    "start": "1239480",
    "end": "1246710"
  },
  {
    "text": "So so far, we've been looking\nat overview of language model.",
    "start": "1246710",
    "end": "1252640"
  },
  {
    "text": "Great. Very powerful models\nthat are out there, many models out there,\nand then how we use.",
    "start": "1252640",
    "end": "1259870"
  },
  {
    "text": "However, even there\nare still limitations",
    "start": "1259870",
    "end": "1265720"
  },
  {
    "text": "for models that\nare available, that are listed here,\nsuch as hallucination",
    "start": "1265720",
    "end": "1271720"
  },
  {
    "text": "is a well-known issue that\nmodels can sometimes oftentimes",
    "start": "1271720",
    "end": "1280580"
  },
  {
    "text": "generate incorrect or\nincorrect information, particularly if it's\nrelated to some computation",
    "start": "1280580",
    "end": "1287450"
  },
  {
    "text": "or some other specific area. So this is a problem\nthat we want to avoid",
    "start": "1287450",
    "end": "1296690"
  },
  {
    "text": "in your application domain. And other thing is there's\nalways a knowledge cut up",
    "start": "1296690",
    "end": "1302809"
  },
  {
    "text": "in data set preparation. So model creator\nprepare data set.",
    "start": "1302810",
    "end": "1308789"
  },
  {
    "text": "However, they need\nto, at some point, cut up their data set\ncollection and then use it.",
    "start": "1308790",
    "end": "1315419"
  },
  {
    "start": "1310000",
    "end": "1440000"
  },
  {
    "text": "So model may have not seen\nthe recent information",
    "start": "1315420",
    "end": "1321920"
  },
  {
    "text": "or news as part of their\npre-training data set.",
    "start": "1321920",
    "end": "1326960"
  },
  {
    "text": "Lack of attribution--\nso model can answer a lot of world\nknowledge questions",
    "start": "1326960",
    "end": "1332720"
  },
  {
    "text": "and can answer those type\nof general questions. However, it may not tell--",
    "start": "1332720",
    "end": "1338720"
  },
  {
    "text": "it's not going to\ntell you where they drew this, the answer from\nparticular specific data source.",
    "start": "1338720",
    "end": "1348910"
  },
  {
    "text": "Data privacy is one\nfact that model creator,",
    "start": "1348910",
    "end": "1354520"
  },
  {
    "text": "you prepare the data set using\npublicly available data source.",
    "start": "1354520",
    "end": "1361330"
  },
  {
    "text": "That means model have not\nseen your proprietary data set",
    "start": "1361330",
    "end": "1366340"
  },
  {
    "text": "from your organization\nor particular domain. And limited context length--",
    "start": "1366340",
    "end": "1374500"
  },
  {
    "text": "although it's a\nrapidly increasing, however, it's fine balance\nbecause providing longer context",
    "start": "1374500",
    "end": "1388480"
  },
  {
    "text": "will give more context\ninformation to the model. However, it comes with\noperational cost as well as",
    "start": "1388480",
    "end": "1397520"
  },
  {
    "text": "the speed of the latency\nin text generations.",
    "start": "1397520",
    "end": "1404900"
  },
  {
    "text": "So in order to address\nthese common limitations,",
    "start": "1404900",
    "end": "1412190"
  },
  {
    "text": "retrieval augmented\ngeneration is one way to handle\nthis, such as it could",
    "start": "1412190",
    "end": "1418100"
  },
  {
    "text": "reduce the\nhallucination by using the actual relevant reference.",
    "start": "1418100",
    "end": "1424790"
  },
  {
    "text": "It also address the citation\nbecause it knows where",
    "start": "1424790",
    "end": "1431510"
  },
  {
    "text": "this reference is coming from. And then this will allow you\nas an application developer",
    "start": "1431510",
    "end": "1439549"
  },
  {
    "text": "or a system developer\nto prepare systems so that you could use\nyour own proprietary data",
    "start": "1439550",
    "end": "1447409"
  },
  {
    "start": "1440000",
    "end": "1760000"
  },
  {
    "text": "set or the text. And then you could use good use\nof small number of context links",
    "start": "1447410",
    "end": "1456420"
  },
  {
    "text": "because it only select\nrelevant data set. So how it works is you could\npre-index your own data set",
    "start": "1456420",
    "end": "1468450"
  },
  {
    "text": "or your own text by turn them\ninto smaller chunk, chunk",
    "start": "1468450",
    "end": "1475860"
  },
  {
    "text": "of text, and then convert them\ninto an embedding space using embedding model,\nand then stage them",
    "start": "1475860",
    "end": "1484110"
  },
  {
    "text": "as part of your database\nor vector database. And then when the\nrequest or query came,",
    "start": "1484110",
    "end": "1491500"
  },
  {
    "text": "you could turn this query\ninto embedding space so that you could do nearest\nneighboring search and then",
    "start": "1491500",
    "end": "1499470"
  },
  {
    "text": "select top K relevant\ninformation, relevant chunk,",
    "start": "1499470",
    "end": "1505169"
  },
  {
    "text": "text chunk, and then place\nthem as part of your prompt. Some of the slide\nthat we see previously",
    "start": "1505170",
    "end": "1512450"
  },
  {
    "text": "is you put the reference\nas part of the prompt, and then use that as the model.",
    "start": "1512450",
    "end": "1519070"
  },
  {
    "text": "Only make use of this reference. So this is one good\nway to make use",
    "start": "1519070",
    "end": "1526510"
  },
  {
    "text": "of your own proprietary data. And then similar method can be\nused in the actual AI search",
    "start": "1526510",
    "end": "1536530"
  },
  {
    "text": "so that instead of\nusing index data set, you could also rely on web\nsearch or different type",
    "start": "1536530",
    "end": "1542920"
  },
  {
    "text": "of search so that you could\nprovide the information as part of the index.",
    "start": "1542920",
    "end": "1548680"
  },
  {
    "text": "And one of the thing\nalso mentioned here is there are many methods or\nideas for retrieval augmented",
    "start": "1548680",
    "end": "1559450"
  },
  {
    "text": "generation. More commonly used\nmethod is something that we've just mentioned.",
    "start": "1559450",
    "end": "1566510"
  },
  {
    "text": "We've just talked about,\nmeaning turn the text chunk into embedding space. And then do a nearest\nneighbor search.",
    "start": "1566510",
    "end": "1573120"
  },
  {
    "text": "However, there are many methods. And then you could also\nuse knowledge graph base.",
    "start": "1573120",
    "end": "1579900"
  },
  {
    "text": "So if you could generate a\nknowledge graph from your text source, and then that\ncould also help to extract",
    "start": "1579900",
    "end": "1588049"
  },
  {
    "text": "the more relevant information. Also known as graph\nRAG is one part of it.",
    "start": "1588050",
    "end": "1595110"
  },
  {
    "text": "However, there are\nmany methods and then you may need to look into the\nright method or if right method,",
    "start": "1595110",
    "end": "1604280"
  },
  {
    "text": "make use of those.  Tool usage-- so language model\nbeing most widely used form",
    "start": "1604280",
    "end": "1614270"
  },
  {
    "text": "is a text in and text output,\nwhich means that it could answer many type of queries.",
    "start": "1614270",
    "end": "1622080"
  },
  {
    "text": "However, it's not going to\nexecute or extract information",
    "start": "1622080",
    "end": "1628649"
  },
  {
    "text": "from the external. So that's where\nthis tool usage came to rescue or also known\nas a function calling.",
    "start": "1628650",
    "end": "1636700"
  },
  {
    "text": "So with this method, you could\nget real-time information,",
    "start": "1636700",
    "end": "1642639"
  },
  {
    "text": "or you could actually\ndo a computation by generating software\nor computer code.",
    "start": "1642640",
    "end": "1650200"
  },
  {
    "text": "So what does it mean is-- let's look at an example here.",
    "start": "1650200",
    "end": "1655750"
  },
  {
    "text": "So if you have AI\nchatbot that if you",
    "start": "1655750",
    "end": "1662100"
  },
  {
    "text": "ask what is the weather\nin, say, San Francisco, then model will not\nknow it in itself.",
    "start": "1662100",
    "end": "1668500"
  },
  {
    "text": "So however, if you\ntell model previously,",
    "start": "1668500",
    "end": "1674760"
  },
  {
    "text": "as part of the prompt,\nsaying that if you ask weather-related question\ngenerated output form",
    "start": "1674760",
    "end": "1682080"
  },
  {
    "text": "that the software that parse\nthe output can make an API call.",
    "start": "1682080",
    "end": "1688210"
  },
  {
    "text": "So as in this example, model\nwill generate the output",
    "start": "1688210",
    "end": "1693940"
  },
  {
    "text": "in a way that, hey, this\nis the case for tool usage. So it generates an output as\nin the form here, get weather,",
    "start": "1693940",
    "end": "1705100"
  },
  {
    "text": "and then input argument to\nthis API call or function call is the place that we ask.",
    "start": "1705100",
    "end": "1711559"
  },
  {
    "text": "So then software receives this\ntext output from the model, and then parse.",
    "start": "1711560",
    "end": "1717200"
  },
  {
    "text": "And then actually\nmake an API call towards the weather\nprovider, and then get",
    "start": "1717200",
    "end": "1723580"
  },
  {
    "text": "the weather information. And then again, provide\nback to langpack back",
    "start": "1723580",
    "end": "1729549"
  },
  {
    "text": "to the language model. And then language\nmodel will generate more human-friendly or\nhelpful output based",
    "start": "1729550",
    "end": "1737110"
  },
  {
    "text": "on this API-based result.\nAnd for some cases,",
    "start": "1737110",
    "end": "1744840"
  },
  {
    "text": "model can also generate\na software code that can be executed as part of the\nsandbox outside of the language",
    "start": "1744840",
    "end": "1754530"
  },
  {
    "text": "model by the software\nthat is coordinating all these activities. ",
    "start": "1754530",
    "end": "1762580"
  },
  {
    "start": "1760000",
    "end": "2160000"
  },
  {
    "text": "So agentic language model-- so there can be\nmany definitions.",
    "start": "1762580",
    "end": "1770280"
  },
  {
    "text": "One definition is it could\ninteract with environment. So compared to simple\nlanguage model usage,",
    "start": "1770280",
    "end": "1778590"
  },
  {
    "text": "generally use simple\nlanguage model usage",
    "start": "1778590",
    "end": "1784230"
  },
  {
    "text": "as you seen here, text\ninput and text output. Agentic language\nmodel usage could",
    "start": "1784230",
    "end": "1792630"
  },
  {
    "text": "be language model could do\nsomething with the environment by generating tool usage\nor retrieval request.",
    "start": "1792630",
    "end": "1801880"
  },
  {
    "text": "And then from the\nenvironment, anything outside of language model could\nprovide an output,",
    "start": "1801880",
    "end": "1810800"
  },
  {
    "text": "could provide an information\nthat can be fed back to language",
    "start": "1810800",
    "end": "1816490"
  },
  {
    "text": "model as an observation. And then the whole thing,\nthe agentic language model,",
    "start": "1816490",
    "end": "1823040"
  },
  {
    "text": "which includes language\nmodel at its core with the software around\nit, will process it,",
    "start": "1823040",
    "end": "1830540"
  },
  {
    "text": "and then also put\nthem in a memory, and as with its\nconversational history,",
    "start": "1830540",
    "end": "1838669"
  },
  {
    "text": "which can be taken as a memory. So this is one way of definition\nof agentic language model.",
    "start": "1838670",
    "end": "1848770"
  },
  {
    "text": "The other way to\nlook at it is this. Agentic language\nmodel usage can be",
    "start": "1848770",
    "end": "1858350"
  },
  {
    "text": "defined as it could reason\nas well as it could action. It could do an action, so also\ncalled ReAct, reason and action.",
    "start": "1858350",
    "end": "1867270"
  },
  {
    "text": "So reasoning part is something\nthat you could encourage model",
    "start": "1867270",
    "end": "1872450"
  },
  {
    "text": "to reason about by using a\nmethod such as chain of dots,",
    "start": "1872450",
    "end": "1878690"
  },
  {
    "text": "and then doing an action using\na method that we have seen",
    "start": "1878690",
    "end": "1883700"
  },
  {
    "text": "in previous slides, as in\nretrieval or search engine, or actually using calculator\nby making an API call",
    "start": "1883700",
    "end": "1891140"
  },
  {
    "text": "or different type of API calls,\nsuch as weather API that we have seen, and also\ngenerating a Python code",
    "start": "1891140",
    "end": "1899600"
  },
  {
    "text": "so that you could run as\npart of your sandboxes. So by combining these\nreasoning and action,",
    "start": "1899600",
    "end": "1907340"
  },
  {
    "text": "model can do a lot\nmore complex task than simple input and\noutput type of interaction.",
    "start": "1907340",
    "end": "1915236"
  },
  {
    "text": " So let's look at a little\nmore detail on this.",
    "start": "1915236",
    "end": "1923880"
  },
  {
    "text": "What does it mean by\nreasoning and action? So reasoning part, instead of\ndoing the task that is asked,",
    "start": "1923880",
    "end": "1934169"
  },
  {
    "text": "you could prepare your\nprompt in such a way that ask model to break down the\ntask and then make a plan.",
    "start": "1934170",
    "end": "1942570"
  },
  {
    "text": "So instead of breaking\ndown the task by yourself,",
    "start": "1942570",
    "end": "1948340"
  },
  {
    "text": "as we've seen in the previous\nchaining the prompt slide, you could ask model\nto break down and then",
    "start": "1948340",
    "end": "1956730"
  },
  {
    "text": "prepare your task so in other\nwords, plan the actions.",
    "start": "1956730",
    "end": "1962710"
  },
  {
    "text": "And then based on\nthat breaking down, model can generate\ndifferent actions",
    "start": "1962710",
    "end": "1968429"
  },
  {
    "text": "by making API\ncalls or tool usage so that it could extract or\ncollect additional information",
    "start": "1968430",
    "end": "1979000"
  },
  {
    "text": "from the external world. And then by combining all\nthese, put them in a memory",
    "start": "1979000",
    "end": "1984940"
  },
  {
    "text": "so that it knows, model\nknows what's been happening. And then based on that,\nfinally draw an answer for you.",
    "start": "1984940",
    "end": "1993490"
  },
  {
    "text": "So let's look at a\nconcrete example here. So if you have a customer\nsupport AI agent,",
    "start": "1993490",
    "end": "2003000"
  },
  {
    "text": "then how it might look? How it might work? So as a customer, ask, can I\nget a refund for product full?",
    "start": "2003000",
    "end": "2015040"
  },
  {
    "text": "Then agentic system will\nbreak down this task, break down this request\ntask into the following four",
    "start": "2015040",
    "end": "2023700"
  },
  {
    "text": "different type of actions. Check the refund policy, check\nthe customer information,",
    "start": "2023700",
    "end": "2029759"
  },
  {
    "text": "and then check the products. And then finally, collect\nand then decide what to do.",
    "start": "2029760",
    "end": "2036400"
  },
  {
    "text": "In each step language model\nwill spit out the API calls",
    "start": "2036400",
    "end": "2042470"
  },
  {
    "text": "so that it could\ncollect the information. For example, check\nthe refund policy,",
    "start": "2042470",
    "end": "2048440"
  },
  {
    "text": "a language model could\nask a retrieval system against the pre-indexed\ncompany policy, refund policy.",
    "start": "2048440",
    "end": "2057879"
  },
  {
    "text": "And from there, it could\nretrack the information, and then put them\nin its own context. And then using that, also\nrequest the customer order",
    "start": "2057880",
    "end": "2067119"
  },
  {
    "text": "information. It could either ask\ncustomer, in the chat format,",
    "start": "2067120",
    "end": "2072789"
  },
  {
    "text": "collect more information. Or it could look\nit up in the system because it depends on how\nthis chat system is prepared.",
    "start": "2072790",
    "end": "2083080"
  },
  {
    "text": "The same thing for\nthe product so that it could collect more information. And then finally,\ndraw the conclusion",
    "start": "2083080",
    "end": "2090230"
  },
  {
    "text": "based on the policy, and\nthen product information, as well as the customer\norder information.",
    "start": "2090230",
    "end": "2096919"
  },
  {
    "text": "And then send the request to the\nfollow-up system as an API call",
    "start": "2096920",
    "end": "2104359"
  },
  {
    "text": "as well as the send,\nprepare, say, response draft.",
    "start": "2104360",
    "end": "2109740"
  },
  {
    "text": "And then that's going to be\nhandled by final approval. ",
    "start": "2109740",
    "end": "2117870"
  },
  {
    "text": "So workflow is\ngenerally like this. So in a sense, agentic\nlanguage model system",
    "start": "2117870",
    "end": "2125869"
  },
  {
    "text": "is generally language model\nis making iterative calls",
    "start": "2125870",
    "end": "2132140"
  },
  {
    "text": "by reviewing the\ndocument or task and then making\nexternal tool calls.",
    "start": "2132140",
    "end": "2137450"
  },
  {
    "text": " An example, if you want\nto do some research",
    "start": "2137450",
    "end": "2145430"
  },
  {
    "text": "of certain matters, you\ncould prepare your agent to do a research, web search\nor different type of search,",
    "start": "2145430",
    "end": "2153490"
  },
  {
    "text": "and then summarize them\niteratively, and then finally prepare the report\nto you or to your system.",
    "start": "2153490",
    "end": "2163540"
  },
  {
    "start": "2160000",
    "end": "2640000"
  },
  {
    "text": "Another example could be\nsoftware assistant agent that you could ask this software\nagent or free agent that",
    "start": "2163540",
    "end": "2176530"
  },
  {
    "text": "ask the issues of certain type\nof software bug or issues. Then this agent will look\nit up and review this issue,",
    "start": "2176530",
    "end": "2185330"
  },
  {
    "text": "and then collect the relevant\npiece of code or files,",
    "start": "2185330",
    "end": "2190820"
  },
  {
    "text": "and then review them and\nthen propose the output. Or it could also execute\nin its sandbox environment,",
    "start": "2190820",
    "end": "2198520"
  },
  {
    "text": "and then test the fix,\nand then get the output.",
    "start": "2198520",
    "end": "2204080"
  },
  {
    "text": "And then iteratively\ntry to find the fix. And then finally, pulls the\npull request or the changes",
    "start": "2204080",
    "end": "2212780"
  },
  {
    "text": "to users or developers.",
    "start": "2212780",
    "end": "2217880"
  },
  {
    "text": "These are the ways that\nwe can use language model in agent format and by doing\ninteractive language model",
    "start": "2217880",
    "end": "2227300"
  },
  {
    "text": "calls.  So the main reasons\nand difference",
    "start": "2227300",
    "end": "2238940"
  },
  {
    "text": "why these agentic language model\nusage is getting more widely",
    "start": "2238940",
    "end": "2245150"
  },
  {
    "text": "used is given that if you have\nthe same model, if you ask just",
    "start": "2245150",
    "end": "2252710"
  },
  {
    "text": "direct request to\nthe model, model may not be able to handle it.",
    "start": "2252710",
    "end": "2258380"
  },
  {
    "text": "However, if you put your task\nin this type of agentic format",
    "start": "2258380",
    "end": "2264029"
  },
  {
    "text": "or patterns, then model\nwill do more complex tasks,",
    "start": "2264030",
    "end": "2269700"
  },
  {
    "text": "even using a model that\nmay not be able to do it if you don't do this way.",
    "start": "2269700",
    "end": "2275640"
  },
  {
    "text": "So that's one of the reasons\nthat agentic language model is pushing the boundaries,\nso that the things that we",
    "start": "2275640",
    "end": "2283829"
  },
  {
    "text": "can do with AI agent is more\ncomplex or different domains",
    "start": "2283830",
    "end": "2290010"
  },
  {
    "text": "that we can rely on. ",
    "start": "2290010",
    "end": "2295990"
  },
  {
    "text": "So here are the\nreal-world applications-- software development, code\ngeneration or bug fixing",
    "start": "2295990",
    "end": "2303359"
  },
  {
    "text": "or this type of development\nis widely investigated",
    "start": "2303360",
    "end": "2310830"
  },
  {
    "text": "or being researched by\ndifferent organizations as well as there\nare companies that",
    "start": "2310830",
    "end": "2316260"
  },
  {
    "text": "are trying to provide\nthese services as decision on the right side, and\nresearch and analysis that",
    "start": "2316260",
    "end": "2323740"
  },
  {
    "text": "gather information, synthesize\nit, and then provide a summary for the users.",
    "start": "2323740",
    "end": "2329270"
  },
  {
    "text": "And then task automation\nis one of the areas that agentic method\ncould be used.",
    "start": "2329270",
    "end": "2337515"
  },
  {
    "text": " So to make it more clear, here\nare some of the design patterns",
    "start": "2337515",
    "end": "2348910"
  },
  {
    "text": "that you could use\nagentic language model. Planning is critical\nbecause by asking a model",
    "start": "2348910",
    "end": "2359710"
  },
  {
    "text": "to break down the task to make\nit simpler task or clear task",
    "start": "2359710",
    "end": "2366280"
  },
  {
    "text": "so that language model\nlater can make an API call or use the tool usage.",
    "start": "2366280",
    "end": "2372980"
  },
  {
    "text": "So planning is critical. Then reflection is\nsomething that model",
    "start": "2372980",
    "end": "2378970"
  },
  {
    "text": "can generate in the cell. And then the next model\ncall can criticize",
    "start": "2378970",
    "end": "2389690"
  },
  {
    "text": "the output that actually\ncame from the same model. So by doing this, the\noutput could be improved.",
    "start": "2389690",
    "end": "2397289"
  },
  {
    "text": "And then two usages is something\nthat something that outside",
    "start": "2397290",
    "end": "2403250"
  },
  {
    "text": "of the language\nmodel that you need, the real-time information or\ndifferent type of information,",
    "start": "2403250",
    "end": "2409050"
  },
  {
    "text": "then you can use this. And then multi-agent\ncollaboration is one way to handle this.",
    "start": "2409050",
    "end": "2416120"
  },
  {
    "text": "Reflection is a pattern\nthat quick to implement and then leads to\na good performance.",
    "start": "2416120",
    "end": "2423630"
  },
  {
    "text": "And let's use a\nconcrete example here. So if you want to refactor\na programming code,",
    "start": "2423630",
    "end": "2430820"
  },
  {
    "text": "instead of asking model\nto improve it right away, if you do this pattern,\nas in this example,",
    "start": "2430820",
    "end": "2437520"
  },
  {
    "text": "saying that you\nasked ask a model saying that here is the\ncode, and then check the code",
    "start": "2437520",
    "end": "2442920"
  },
  {
    "text": "and provide\nconstructive feedback. And then take that feedback\nto the second prompt,",
    "start": "2442920",
    "end": "2451810"
  },
  {
    "text": "as in this example. You could also\nprepare prompts saying that here is the code\nand the feedback,",
    "start": "2451810",
    "end": "2458710"
  },
  {
    "text": "which came from\nthe model itself. And then ask the\nmodel to refactor it.",
    "start": "2458710",
    "end": "2464320"
  },
  {
    "text": "And then this way of\nreflection will likely generate better output or\nbetter fix for the code",
    "start": "2464320",
    "end": "2473730"
  },
  {
    "text": "that you are asking\nto the model. Tool usage is something that\nwe've seen before, ask model",
    "start": "2473730",
    "end": "2482069"
  },
  {
    "text": "to generate the API\npatterns so that you can use this API function\nprototype to make",
    "start": "2482070",
    "end": "2489660"
  },
  {
    "text": "an actual code. Or if the task is related\nto actual computation",
    "start": "2489660",
    "end": "2496430"
  },
  {
    "text": "or some different\nform, you could also ask the model to generate\na program as an output,",
    "start": "2496430",
    "end": "2503550"
  },
  {
    "text": "and then you can run that on\na safe sandbox environment that your software or software\nscaffolding around the language",
    "start": "2503550",
    "end": "2514010"
  },
  {
    "text": "model can execute and\nthen provide an input, provide the execution\noutput back to the model",
    "start": "2514010",
    "end": "2521309"
  },
  {
    "text": "so that model can synthesize it. So multi-agent is\nan interesting way",
    "start": "2521310",
    "end": "2530060"
  },
  {
    "text": "to implement or accomplish\nyour complex task. So you could split up the task--",
    "start": "2530060",
    "end": "2539300"
  },
  {
    "text": "or you could split\nup your task and then assign those tasks in a\ndifferent agent that are",
    "start": "2539300",
    "end": "2545090"
  },
  {
    "text": "dedicated for specific task. And then this agent, in\nthis case, in this context,",
    "start": "2545090",
    "end": "2554339"
  },
  {
    "text": "could be just as a different\nprompt or different persona. So the prompt usually\nconsists of helpful AI agent.",
    "start": "2554340",
    "end": "2566080"
  },
  {
    "text": "You could change that\ninto a different persona to a different agent. And also, you may or may\nnot use the same model",
    "start": "2566080",
    "end": "2574570"
  },
  {
    "text": "or the different model\nbased on the task. So let's use a\nconcrete example here.",
    "start": "2574570",
    "end": "2580330"
  },
  {
    "text": "So if you build a multi-agent\nsystem for smart home automation, you could create a\ndifferent agent, climate control",
    "start": "2580330",
    "end": "2589020"
  },
  {
    "text": "agent, lighting control\nagent, and so on.",
    "start": "2589020",
    "end": "2594280"
  },
  {
    "text": "And then these are\nthe software piece that includes a different\nprompt with a persona",
    "start": "2594280",
    "end": "2600540"
  },
  {
    "text": "as well as handling\nexternal triggers. And then those are the ones\nthat work internally, and then",
    "start": "2600540",
    "end": "2608250"
  },
  {
    "text": "that coordinate these agents\nessentially a model prompt",
    "start": "2608250",
    "end": "2613480"
  },
  {
    "text": "together with software\nscaffolding around it coordinates the whole activity. ",
    "start": "2613480",
    "end": "2620900"
  },
  {
    "text": "So that brings up\nto our summary. So the agentic\nlanguage model usage",
    "start": "2620900",
    "end": "2631330"
  },
  {
    "text": "is a progression or extension to\na existing language modal usage",
    "start": "2631330",
    "end": "2636550"
  },
  {
    "text": "method. So for the best\npractice that you have used in language model\nfor simple cases, most of them",
    "start": "2636550",
    "end": "2647710"
  },
  {
    "start": "2640000",
    "end": "2860000"
  },
  {
    "text": "are applicable. However, you could use\ndifferent additional methods such as more retrieval\nsearch tool usage,",
    "start": "2647710",
    "end": "2656170"
  },
  {
    "text": "and then prepare\ndifferent type of prompts. And then workflow\nso that you could",
    "start": "2656170",
    "end": "2662410"
  },
  {
    "text": "use language model in its core\nas a reasoning or smart intern.",
    "start": "2662410",
    "end": "2668210"
  },
  {
    "text": "And then you could use a tool\nusage or other retrieval method",
    "start": "2668210",
    "end": "2674180"
  },
  {
    "text": "to interact with\nthe external world, and then combine these\nresults such a way",
    "start": "2674180",
    "end": "2682280"
  },
  {
    "text": "that you could achieve a complex\ntask instead of simple input",
    "start": "2682280",
    "end": "2690170"
  },
  {
    "text": "and output type of\nlanguage model usage. And that said, Petra?",
    "start": "2690170",
    "end": "2696572"
  },
  {
    "text": "PETRA: Thank you so much, Insop. It has been really great. So much information.",
    "start": "2696572",
    "end": "2702330"
  },
  {
    "text": "Hopefully, this is\nuseful for everybody. We keep collecting\nthe questions. We got so many.",
    "start": "2702330",
    "end": "2707970"
  },
  {
    "text": "We will try to get\nas many as we can. But yeah, please feel\nfree to keep them coming.",
    "start": "2707970",
    "end": "2713570"
  },
  {
    "text": "Maybe the first\nquestion for you, Insop, and let's focus\non the agentic AI.",
    "start": "2713570",
    "end": "2719240"
  },
  {
    "text": "It's about the evaluation. And do you have\nsome recommendations for a good strategy for\nevaluating agents beyond just",
    "start": "2719240",
    "end": "2727340"
  },
  {
    "text": "using an LLM as a judge? It seems it should be a little\nbit more complicated to do the evaluation on agents.",
    "start": "2727340",
    "end": "2733600"
  },
  {
    "text": "At least, that's the general\nnotion, the questions, and people are wondering\nhow that could be done. ",
    "start": "2733600",
    "end": "2740359"
  },
  {
    "text": "INSOP SONG: I think this\nis a great question. So just to make a quick\ncontext, LLM as a judge",
    "start": "2740360",
    "end": "2748230"
  },
  {
    "text": "is commonly used method\nthat you actually use LLM to evaluate the\nmodel-generated output",
    "start": "2748230",
    "end": "2755550"
  },
  {
    "text": "against the ground truth answer\nor some type of reference information, which works great.",
    "start": "2755550",
    "end": "2761410"
  },
  {
    "text": "And then why do we use-- and also, why we use\nthat as well for the--",
    "start": "2761410",
    "end": "2767760"
  },
  {
    "text": "I think one thing that\nI've recently tried is agentic judging\nmethod, meaning",
    "start": "2767760",
    "end": "2778080"
  },
  {
    "text": "that I use reflection\ntype of pattern",
    "start": "2778080",
    "end": "2783420"
  },
  {
    "text": "that we have seen previously. Instead of just ask one question\nright away to LLM as a judge,",
    "start": "2783420",
    "end": "2791180"
  },
  {
    "text": "I ask first LLMs,\nprovide initial reference",
    "start": "2791180",
    "end": "2797859"
  },
  {
    "text": "and then feedback. And then I also ask\nagain another LLM call",
    "start": "2797860",
    "end": "2804099"
  },
  {
    "text": "or different prompt\nsaying that, hey, this is a feedback from\nyour junior engineer.",
    "start": "2804100",
    "end": "2811720"
  },
  {
    "text": "If you are a senior\nengineer, how would you compare the\njunior engineer's evaluation",
    "start": "2811720",
    "end": "2817390"
  },
  {
    "text": "against the output that\nyou are evaluating? So I find that this\nreflection pattern",
    "start": "2817390",
    "end": "2824530"
  },
  {
    "text": "was helpful to get the better\nevaluation instead of just one shot LLM as a judge output.",
    "start": "2824530",
    "end": "2832869"
  },
  {
    "text": "However, I think there\ncan be more creative way to improve your evaluation\nstage using agent",
    "start": "2832870",
    "end": "2841120"
  },
  {
    "text": "patterns because the evaluation,\nit is really, really important.",
    "start": "2841120",
    "end": "2847050"
  },
  {
    "text": "I can't emphasize\nmore because that",
    "start": "2847050",
    "end": "2852230"
  },
  {
    "text": "will help you to advance\nfast or change models and different type of\nchanging the prompt",
    "start": "2852230",
    "end": "2859110"
  },
  {
    "text": "and so on and so forth. So I think that was\na great question. PETRA: Thank you so much, Insop.",
    "start": "2859110",
    "end": "2865790"
  },
  {
    "start": "2860000",
    "end": "3000000"
  },
  {
    "text": "We got a few questions about\naugmenting the AI agents",
    "start": "2865790",
    "end": "2871700"
  },
  {
    "text": "for specific uses\nand making sure that they get shaped in a way\nyou need for your application.",
    "start": "2871700",
    "end": "2878460"
  },
  {
    "text": "Like on the technological\nside, what is there to do? What is there to use? We got many questions\ngoing to this idea.",
    "start": "2878460",
    "end": "2886650"
  },
  {
    "text": "So if you have some\nkind of information that would be helpful. INSOP SONG: Again, I think\nthis is a great question.",
    "start": "2886650",
    "end": "2894263"
  },
  {
    "text": " So first thing\ncame up to my mind",
    "start": "2894263",
    "end": "2901790"
  },
  {
    "text": "is if you have a\ntask which is simple,",
    "start": "2901790",
    "end": "2908150"
  },
  {
    "text": "then you just use language\nmodel, simple use cases. However, if you see a little\nmore involved or complex tasks,",
    "start": "2908150",
    "end": "2916010"
  },
  {
    "text": "you could experiment with\nsimple agentic tasks. Even if it's a agentic\nlanguage model usage could be--",
    "start": "2916010",
    "end": "2928150"
  },
  {
    "text": "You can define\nagentic language model in many, many different ways. But if you have a little\nmore involved task,",
    "start": "2928150",
    "end": "2935809"
  },
  {
    "text": "you could do an iterative\nlanguage model call. Even that could\nimprove your output.",
    "start": "2935810",
    "end": "2942619"
  },
  {
    "text": "So I think it all depends on\nyour actual application domain.",
    "start": "2942620",
    "end": "2951440"
  },
  {
    "text": "But instead of trying to look\nfor the task that you could",
    "start": "2951440",
    "end": "2957310"
  },
  {
    "text": "apply language model,\nturn that around, that how this task cannot be\nsolved with a simple cases,",
    "start": "2957310",
    "end": "2965490"
  },
  {
    "text": "so simple language model usage. So try to apply simple\nusage first, and then",
    "start": "2965490",
    "end": "2973430"
  },
  {
    "text": "try to improve it using\ndifferent patterns.",
    "start": "2973430",
    "end": "2978920"
  },
  {
    "text": "Same for I think a\nslightly tangential but fine-tuning cases.",
    "start": "2978920",
    "end": "2985440"
  },
  {
    "text": "Also, if you could have a task-- if you have a task\nthat you want to solve,",
    "start": "2985440",
    "end": "2993200"
  },
  {
    "text": "try to use the existing model\nfirst whether it makes sense or not. And then from there, you\ncould decide how to do it.",
    "start": "2993200",
    "end": "3000980"
  },
  {
    "start": "3000000",
    "end": "3290000"
  },
  {
    "text": "Then you could prepare\nsmall data samples and then try it and\nthen make a progress.",
    "start": "3000980",
    "end": "3007400"
  },
  {
    "text": "And then really quick\niteration instead of trying to invest upfront too much.",
    "start": "3007400",
    "end": "3013050"
  },
  {
    "text": " PETRA: Thank you, Insop. A few questions came in.",
    "start": "3013050",
    "end": "3020450"
  },
  {
    "text": "And this is a giant\nquestion on its own. So I will let you choose how\nyou want to respond to that.",
    "start": "3020450",
    "end": "3028050"
  },
  {
    "text": "But a lot of questions about\nethical considerations, how to avoid hallucinations,\nhow to avoid",
    "start": "3028050",
    "end": "3034549"
  },
  {
    "text": "using data that might\nbe unethical or there might be something\nkind of behind them.",
    "start": "3034550",
    "end": "3041900"
  },
  {
    "text": "What would be your\nrecommendation? Again, this question is so big,\nbut maybe looking for something",
    "start": "3041900",
    "end": "3047150"
  },
  {
    "text": "that you would say about this. INSOP SONG: Yeah,\nanother great question.",
    "start": "3047150",
    "end": "3054050"
  },
  {
    "text": "Yes, due to its probabilistic\ngeneration in nature,",
    "start": "3054050",
    "end": "3062550"
  },
  {
    "text": "hallucination is always there,\nalthough a lot of people are working on it.",
    "start": "3062550",
    "end": "3067770"
  },
  {
    "text": "So it's a problem As\nwell as the contents",
    "start": "3067770",
    "end": "3074750"
  },
  {
    "text": "output could be concerning. So I think a model\nprovider themselves",
    "start": "3074750",
    "end": "3082650"
  },
  {
    "text": "is checking the generated output\nin terms of different categories",
    "start": "3082650",
    "end": "3088260"
  },
  {
    "text": "as well as your application,\nprovide application builder yourself.",
    "start": "3088260",
    "end": "3094140"
  },
  {
    "text": "Also add some guardrails. Guardrails being checking the\noutput, using small language",
    "start": "3094140",
    "end": "3102599"
  },
  {
    "text": "model so that you\ncould quickly check the output or some\ntype of I guess",
    "start": "3102600",
    "end": "3108570"
  },
  {
    "text": "criteria using classifier\nor some type of thing so that you could actually\nfilter them out to see.",
    "start": "3108570",
    "end": "3114600"
  },
  {
    "text": "It could be either on the\nfinal generation stage, or it could be in\nthe input stage",
    "start": "3114600",
    "end": "3122910"
  },
  {
    "text": "that the query comes in so that\nyou could actually avoid it. This can backfire.",
    "start": "3122910",
    "end": "3129700"
  },
  {
    "text": "But I think as an\nenterprise or business, you may be on the safer\nside so they're making sure",
    "start": "3129700",
    "end": "3138220"
  },
  {
    "text": "generated input,\ngenerated output, as well as the inputs queries\nthat are being requested",
    "start": "3138220",
    "end": "3146109"
  },
  {
    "text": "could be more safe\nor reasonable cases.",
    "start": "3146110",
    "end": "3151880"
  },
  {
    "text": "So this is evolving. But I think fundamentally,\nit is something that check the output using type\nof classifier or even decoder",
    "start": "3151880",
    "end": "3161620"
  },
  {
    "text": "type model to check it. PETRA: Thank you so much.",
    "start": "3161620",
    "end": "3166700"
  },
  {
    "text": "And a little plug-in. We do have generative\nAI program that also covers a lot of the\nethical aspects of LLMs.",
    "start": "3166700",
    "end": "3174680"
  },
  {
    "text": "It's not a technical\nprogram, but I'm reaching to people who\nare asking about this very important questions.",
    "start": "3174680",
    "end": "3182140"
  },
  {
    "text": "Maybe last question\nInsop for you. And we are not going\nto be endorsing,",
    "start": "3182140",
    "end": "3188270"
  },
  {
    "text": "of course, at Stanford. But a question is like,\nhow to get started? Are there any open source\nmodels you recommend?",
    "start": "3188270",
    "end": "3194700"
  },
  {
    "text": "Is there anything people can\ndo to start testing this out, like start playing with this?",
    "start": "3194700",
    "end": "3201092"
  },
  {
    "text": "INSOP SONG: Great question. So one thing that as a\ntake home message here",
    "start": "3201092",
    "end": "3210890"
  },
  {
    "text": "is start simple, and\nthen experiment it, and then iterate it.",
    "start": "3210890",
    "end": "3215910"
  },
  {
    "text": "And also, agentic language\nmodel sounds complex, fancy,",
    "start": "3215910",
    "end": "3221099"
  },
  {
    "text": "but it is a progression and\nextension of language model usage. So to start, I think you could--",
    "start": "3221100",
    "end": "3231830"
  },
  {
    "text": "there are many language model\nusage framework and also agentic framework\nthat you could use.",
    "start": "3231830",
    "end": "3240030"
  },
  {
    "text": "However, to start,\nI would suggest to use playground\ntype of environment.",
    "start": "3240030",
    "end": "3248060"
  },
  {
    "text": "Say, model provider generally\nhave their playground that you could type your\nprompt or input so that you",
    "start": "3248060",
    "end": "3256750"
  },
  {
    "text": "can see the output right away\nso that you can experiment it really quickly. And then once you\nget familiar with it,",
    "start": "3256750",
    "end": "3264259"
  },
  {
    "text": "and then use the\nAPI to make a call from your code, your program,\nand then see what's going on.",
    "start": "3264260",
    "end": "3272170"
  },
  {
    "text": "In that way, you gain\ninsights as well as practice best practices\nfor prompt preparing.",
    "start": "3272170",
    "end": "3281510"
  },
  {
    "text": "So once you have that,\nyou could intelligently decide whether it\nmakes sense for you",
    "start": "3281510",
    "end": "3288250"
  },
  {
    "text": "to actually continue\nyour own code base or make use of widely\navailable libraries.",
    "start": "3288250",
    "end": "3294260"
  },
  {
    "start": "3290000",
    "end": "3420000"
  },
  {
    "text": "So in short, start simple,\nwork on a playground first, and then make\na simple API calls,",
    "start": "3294260",
    "end": "3300800"
  },
  {
    "text": "and then decide whether you want\nto use more extended libraries or just continue your own way.",
    "start": "3300800",
    "end": "3307240"
  },
  {
    "text": "This applies for language\nmodel usage as well as agentic language\nmodel usage as well",
    "start": "3307240",
    "end": "3315330"
  },
  {
    "text": "because there's also\nmany agentic language model framework out there.",
    "start": "3315330",
    "end": "3321820"
  },
  {
    "text": "PETRA: Thank you so much. And to close us out\nin this session,",
    "start": "3321820",
    "end": "3327260"
  },
  {
    "text": "in the last minute, Insop, the\nfield is progressing so fast. There is so much happening.",
    "start": "3327260",
    "end": "3333210"
  },
  {
    "text": "Basically, every\nweek, we see news about something new coming\nup in any of these fields.",
    "start": "3333210",
    "end": "3338840"
  },
  {
    "text": "Are there any resources\nyou study, you follow, anything you would\nrecommend people to keep track of, to stay\nup to date in LLMs agentic",
    "start": "3338840",
    "end": "3347795"
  },
  {
    "text": "AI in this field? ",
    "start": "3347795",
    "end": "3353394"
  },
  {
    "text": "INSOP SONG: Difficult\nquestion, but great question. ",
    "start": "3353394",
    "end": "3360510"
  },
  {
    "text": "I think it's a little hard,\nbut I picked some experts",
    "start": "3360510",
    "end": "3368220"
  },
  {
    "text": "who are known in this field. I follow them either in formerly\nTwitter or YouTube channel,",
    "start": "3368220",
    "end": "3376660"
  },
  {
    "text": "and then from there, I get\nmore updated information and then do my own digging.",
    "start": "3376660",
    "end": "3383370"
  },
  {
    "text": "But I think find out a good\nstarting point is a good thing.",
    "start": "3383370",
    "end": "3388900"
  },
  {
    "text": "And then I think reference\nhere, you can screenshot it. Then this can be a\ngood starting point",
    "start": "3388900",
    "end": "3396570"
  },
  {
    "text": "because it includes some\nagentic usage courses",
    "start": "3396570",
    "end": "3402600"
  },
  {
    "text": "as well as a good\ntype of courses, either from Stanford as\nwell as different places.",
    "start": "3402600",
    "end": "3408760"
  },
  {
    "text": "So, yeah. PETRA: Thank you so much, Insop. This has been really great.",
    "start": "3408760",
    "end": "3414700"
  },
  {
    "text": "So much helpful information. And you're absolutely the\nbest person to hear this from. Thank you so much\nfor taking the time.",
    "start": "3414700",
    "end": "3421300"
  },
  {
    "start": "3420000",
    "end": "3426000"
  },
  {
    "text": "Thank you also everyone\nwho joined us live. Thank you for your time.",
    "start": "3421300",
    "end": "3426470"
  }
]
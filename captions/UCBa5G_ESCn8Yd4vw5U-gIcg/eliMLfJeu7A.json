[
  {
    "start": "0",
    "end": "27000"
  },
  {
    "text": "Now, we are going to talk about embedding entire graphs.",
    "start": "4130",
    "end": "8910"
  },
  {
    "text": "So rather than embedding individual nodes,",
    "start": "8910",
    "end": "11415"
  },
  {
    "text": "we're going to talk about how do you embed,",
    "start": "11415",
    "end": "13950"
  },
  {
    "text": "or find an embedding for an entire graph.",
    "start": "13950",
    "end": "16275"
  },
  {
    "text": "And the method we are going to talk about is based on anonymous, uh, random walks.",
    "start": "16275",
    "end": "20869"
  },
  {
    "text": "So we are going to continue the theme of, uh,",
    "start": "20870",
    "end": "23835"
  },
  {
    "text": "random walks, but this random walks will be anonymous.",
    "start": "23835",
    "end": "27160"
  },
  {
    "start": "27000",
    "end": "58000"
  },
  {
    "text": "So let me explain. All right?",
    "start": "27160",
    "end": "28830"
  },
  {
    "text": "The goal now is to embed a sub-graph or",
    "start": "28830",
    "end": "31760"
  },
  {
    "text": "an entire graph into the embedding space, uh, z. Um,",
    "start": "31760",
    "end": "36290"
  },
  {
    "text": "and, uh, you may wanna do these because you may wanna do for example,",
    "start": "36290",
    "end": "39830"
  },
  {
    "text": "molecule classification to predict which molecules are toxic versus which are non-toxic.",
    "start": "39830",
    "end": "44790"
  },
  {
    "text": "Or you wanna do some kind of graph anomaly detection,",
    "start": "44790",
    "end": "47700"
  },
  {
    "text": "um, and you want to do this in the embedding space.",
    "start": "47700",
    "end": "50370"
  },
  {
    "text": "So the goal is to embed an entire graph or you can think of it",
    "start": "50370",
    "end": "53960"
  },
  {
    "text": "also as embedding a subset of the nodes in the graph.",
    "start": "53960",
    "end": "58220"
  },
  {
    "start": "58000",
    "end": "174000"
  },
  {
    "text": "So first idea, that is very simple and people have tried.",
    "start": "58220",
    "end": "62705"
  },
  {
    "text": "So the idea is that you run standard node embedding,",
    "start": "62705",
    "end": "65885"
  },
  {
    "text": "uh, uh, technique, uh,",
    "start": "65885",
    "end": "67440"
  },
  {
    "text": "like we- what- like we already dis- discussed in terms of node to walk or, uh, deep walk.",
    "start": "67440",
    "end": "72465"
  },
  {
    "text": "And then, just sum up or average, uh,",
    "start": "72465",
    "end": "75750"
  },
  {
    "text": "node embeddings, either in the entire graph,",
    "start": "75750",
    "end": "78130"
  },
  {
    "text": "or in the sub-graph, right?",
    "start": "78130",
    "end": "79450"
  },
  {
    "text": "So the idea is, um, to say,",
    "start": "79450",
    "end": "81835"
  },
  {
    "text": "the embedding of the graph is simply a sum of the embeddings of the nodes in that graph.",
    "start": "81835",
    "end": "87205"
  },
  {
    "text": "And for example, this method was used in 2016, to classify,",
    "start": "87205",
    "end": "91430"
  },
  {
    "text": "uh, molecules, uh, based on the graph structure,",
    "start": "91430",
    "end": "94160"
  },
  {
    "text": "and it was very, um- very successful.",
    "start": "94160",
    "end": "96365"
  },
  {
    "text": "So even though simplistic,",
    "start": "96365",
    "end": "97909"
  },
  {
    "text": "um, uh, works quite well in practice.",
    "start": "97910",
    "end": "100900"
  },
  {
    "text": "An improvement over this initial idea of averaging node embeddings is",
    "start": "100900",
    "end": "106580"
  },
  {
    "text": "to introduce a virtual node to represent an entire graph or a sub-graph,",
    "start": "106580",
    "end": "111785"
  },
  {
    "text": "and then run a standard graph embedding or node embedding technique,",
    "start": "111785",
    "end": "116225"
  },
  {
    "text": "uh, and then think of the- this virtual node as the embedding for the graph.",
    "start": "116225",
    "end": "120575"
  },
  {
    "text": "So let me explain.",
    "start": "120575",
    "end": "122060"
  },
  {
    "text": "Uh, here is the idea, right?",
    "start": "122060",
    "end": "123770"
  },
  {
    "text": "I will create these virtual node.",
    "start": "123770",
    "end": "125585"
  },
  {
    "text": "I will connect it to the set of nodes I want to embed.",
    "start": "125585",
    "end": "128795"
  },
  {
    "text": "Now I can run node to walk on this,",
    "start": "128795",
    "end": "131790"
  },
  {
    "text": "uh- on this, um- on this graph to determine the embedding of this virtual node.",
    "start": "131790",
    "end": "137780"
  },
  {
    "text": "And, uh, now the embedding of the- of the- of the let's say set of nodes s,",
    "start": "137780",
    "end": "142760"
  },
  {
    "text": "is simply the embedding of this, uh, virtual node,",
    "start": "142760",
    "end": "146424"
  },
  {
    "text": "um, in the embedding space as computed by deep walk or,",
    "start": "146425",
    "end": "150180"
  },
  {
    "text": "uh, node to walk.",
    "start": "150180",
    "end": "151305"
  },
  {
    "text": "And of course, if I would want to embed the entire graph, then this,",
    "start": "151305",
    "end": "154310"
  },
  {
    "text": "uh, virtual node would connect to all other nodes in the network.",
    "start": "154310",
    "end": "158235"
  },
  {
    "text": "I'd run, uh, deep walk,",
    "start": "158235",
    "end": "159990"
  },
  {
    "text": "uh, or an node to walk over this,",
    "start": "159990",
    "end": "161670"
  },
  {
    "text": "determine the embedding of the virtual node and",
    "start": "161670",
    "end": "164000"
  },
  {
    "text": "represent the embedding of the entire graph as the embedding,",
    "start": "164000",
    "end": "167160"
  },
  {
    "text": "uh, of the red node.So that's,",
    "start": "167160",
    "end": "168960"
  },
  {
    "text": "um, idea number, uh, 2.",
    "start": "168960",
    "end": "171825"
  },
  {
    "text": "Now, for idea number 3,",
    "start": "171825",
    "end": "174834"
  },
  {
    "start": "174000",
    "end": "302000"
  },
  {
    "text": "we are going to define this notion of anonymous, uh, walks.",
    "start": "174835",
    "end": "179035"
  },
  {
    "text": "And the way we will think of this is that states in",
    "start": "179035",
    "end": "182450"
  },
  {
    "text": "the anonymous walk correspond to the indexes",
    "start": "182450",
    "end": "185750"
  },
  {
    "text": "of the first time when a given node was- was visited,",
    "start": "185750",
    "end": "189380"
  },
  {
    "text": "uh, on the walk.",
    "start": "189380",
    "end": "190610"
  },
  {
    "text": "So for example, here is a- here is a graph,",
    "start": "190610",
    "end": "193860"
  },
  {
    "text": "uh, uh, you know, a small subpart of the graph of interest.",
    "start": "193860",
    "end": "196520"
  },
  {
    "text": "Then here are a few random walks on this graph.",
    "start": "196520",
    "end": "199400"
  },
  {
    "text": "For example, from A we go to B,",
    "start": "199400",
    "end": "201275"
  },
  {
    "text": "C, B, uh, and C,",
    "start": "201275",
    "end": "203390"
  },
  {
    "text": "or another random walk starts at C, goes to D,",
    "start": "203390",
    "end": "206030"
  },
  {
    "text": "goes to B, goes to D,",
    "start": "206030",
    "end": "207650"
  },
  {
    "text": "and back to B.",
    "start": "207650",
    "end": "208730"
  },
  {
    "text": "But then we are not going to represent the random walk as a sequence of nodes it visits,",
    "start": "208730",
    "end": "214595"
  },
  {
    "text": "but a sequence of times when node was first visited.",
    "start": "214595",
    "end": "218430"
  },
  {
    "text": "So for example, these two random walks,",
    "start": "218430",
    "end": "220265"
  },
  {
    "text": "one and two here, get the- get the same representation.",
    "start": "220265",
    "end": "223565"
  },
  {
    "text": "It is one because A was visited at step 1,",
    "start": "223565",
    "end": "226970"
  },
  {
    "text": "then it's two because B was visited at step 2.",
    "start": "226970",
    "end": "230070"
  },
  {
    "text": "Then it's three because node C was visited at step 3,",
    "start": "230070",
    "end": "234300"
  },
  {
    "text": "then we visited B again,",
    "start": "234300",
    "end": "235920"
  },
  {
    "text": "but B was already visited so it doesn't get a new- new,",
    "start": "235920",
    "end": "239194"
  },
  {
    "text": "uh, index, but it gets value 2.",
    "start": "239195",
    "end": "241655"
  },
  {
    "text": "And then we went back to C. So, um,",
    "start": "241655",
    "end": "244430"
  },
  {
    "text": "so again, um, we have, uh, number 3.",
    "start": "244430",
    "end": "247594"
  },
  {
    "text": "And then this other random walk that started at C went to D,",
    "start": "247595",
    "end": "251510"
  },
  {
    "text": "B, D, B, um,",
    "start": "251510",
    "end": "253455"
  },
  {
    "text": "gets actually the same sequence, right?",
    "start": "253455",
    "end": "254930"
  },
  {
    "text": "C gets one, uh,",
    "start": "254930",
    "end": "256340"
  },
  {
    "text": "D gets two, B gets three.",
    "start": "256340",
    "end": "258620"
  },
  {
    "text": "Then we go back to D. So it's again two,",
    "start": "258620",
    "end": "261109"
  },
  {
    "text": "and then we go to B and it's again three.",
    "start": "261110",
    "end": "263414"
  },
  {
    "text": "And then for example, this other random walk now has",
    "start": "263415",
    "end": "266690"
  },
  {
    "text": "a different anonymous representation because we go from A to B to A to B to D, right?",
    "start": "266690",
    "end": "272670"
  },
  {
    "text": "So it's 1, 2, 1, 2, uh,",
    "start": "272670",
    "end": "275055"
  },
  {
    "text": "3 because at time 3 or, uh,",
    "start": "275055",
    "end": "277875"
  },
  {
    "text": "node D was visited as a third node, uh, in the graph.",
    "start": "277875",
    "end": "281515"
  },
  {
    "text": "So, uh, this anonymous walks,",
    "start": "281515",
    "end": "285005"
  },
  {
    "text": "uh, basically this is,",
    "start": "285005",
    "end": "286310"
  },
  {
    "text": "uh- this is- they are agnostic to the identity of the nose,",
    "start": "286310",
    "end": "289294"
  },
  {
    "text": "of the nodes visited.",
    "start": "289295",
    "end": "290555"
  },
  {
    "text": "That's why they're called anonymous.",
    "start": "290555",
    "end": "292505"
  },
  {
    "text": "Um, and this means that node- that random nodes that have visited the different nodes,",
    "start": "292505",
    "end": "297650"
  },
  {
    "text": "but kind of in the same order that get the same anonymous walk representation.",
    "start": "297650",
    "end": "303610"
  },
  {
    "start": "302000",
    "end": "352000"
  },
  {
    "text": "Now, uh, you may wonder how- how does the number of walks,",
    "start": "303610",
    "end": "307995"
  },
  {
    "text": "uh, increase with the length?",
    "start": "307995",
    "end": "310095"
  },
  {
    "text": "The number of possible anonymous walks increases exponentially.",
    "start": "310095",
    "end": "313740"
  },
  {
    "text": "Uh, here's- here's the graphic for example,",
    "start": "313740",
    "end": "316880"
  },
  {
    "text": "for- there are five anonymous walks of length 3. You know, here they are.",
    "start": "316880",
    "end": "322145"
  },
  {
    "text": "You can basically stay at the same node three times.",
    "start": "322145",
    "end": "325824"
  },
  {
    "text": "You can go- you can stay two times at the same node and then navigate to the second node.",
    "start": "325825",
    "end": "330110"
  },
  {
    "text": "You can go from first node to the second,",
    "start": "330110",
    "end": "332389"
  },
  {
    "text": "back to the first.",
    "start": "332390",
    "end": "333700"
  },
  {
    "text": "You can go from first to the second, stay on the second,",
    "start": "333700",
    "end": "336725"
  },
  {
    "text": "or you navigate from node 1 to node 2 to node 3.",
    "start": "336725",
    "end": "340040"
  },
  {
    "text": "And these are the five possible anonymous walks of length 3.",
    "start": "340040",
    "end": "343715"
  },
  {
    "text": "And then, you know, of length 4, uh,",
    "start": "343715",
    "end": "345810"
  },
  {
    "text": "it will be- it will be more,",
    "start": "345810",
    "end": "347130"
  },
  {
    "text": "that would be 15.",
    "start": "347130",
    "end": "348225"
  },
  {
    "text": "And of length 12, that would be,",
    "start": "348225",
    "end": "349920"
  },
  {
    "text": "I know, four million as it shows here.",
    "start": "349920",
    "end": "352365"
  },
  {
    "start": "352000",
    "end": "429000"
  },
  {
    "text": "So how are we going now to embed a graph?",
    "start": "352365",
    "end": "355639"
  },
  {
    "text": "One idea is to simply simulate anonymous walks of length L, uh,",
    "start": "355640",
    "end": "361040"
  },
  {
    "text": "and record their counts and then represent",
    "start": "361040",
    "end": "363440"
  },
  {
    "text": "the graph as a probability distribution over these walks.",
    "start": "363440",
    "end": "366700"
  },
  {
    "text": "So for example, if I pick anonymous walks of length 3,",
    "start": "366700",
    "end": "371509"
  },
  {
    "text": "then we can represent a graph as a five dimensional vector",
    "start": "371509",
    "end": "374810"
  },
  {
    "text": "because there are five different anonymous walks of length 3.",
    "start": "374810",
    "end": "378514"
  },
  {
    "text": "As I explained earlier,",
    "start": "378515",
    "end": "379745"
  },
  {
    "text": "where, uh, you know,",
    "start": "379745",
    "end": "380900"
  },
  {
    "text": "the embedding of the graph, uh,",
    "start": "380900",
    "end": "382680"
  },
  {
    "text": "the ith coordinate of that embedding is simply the probability that anon-, uh,",
    "start": "382680",
    "end": "387800"
  },
  {
    "text": "the probability or the fraction of times anonimou-",
    "start": "387800",
    "end": "390900"
  },
  {
    "text": "anonymous walk of type I has occurred in",
    "start": "390900",
    "end": "393870"
  },
  {
    "text": "the graph G. So now this would basically mean that we are",
    "start": "393870",
    "end": "396770"
  },
  {
    "text": "embedding a graph as a five dimensional representation.",
    "start": "396770",
    "end": "400280"
  },
  {
    "text": "Now if you want higher number of dimensions,",
    "start": "400280",
    "end": "402455"
  },
  {
    "text": "you increase the length, uh,",
    "start": "402455",
    "end": "403789"
  },
  {
    "text": "of the anonymous, uh, walk.",
    "start": "403790",
    "end": "406135"
  },
  {
    "text": "That's the idea for the- for the anonymous walks, uh,",
    "start": "406135",
    "end": "410940"
  },
  {
    "text": "and how you can basically count them and then have a probability distribution over the,",
    "start": "410940",
    "end": "416300"
  },
  {
    "text": "uh, fraction of times each anonymous walk occurs on your graph.",
    "start": "416300",
    "end": "419330"
  },
  {
    "text": "You, uh, uh, said that the dimensionality of the presentation by basically setting,",
    "start": "419330",
    "end": "424909"
  },
  {
    "text": "uh, the- the length of the,",
    "start": "424910",
    "end": "426950"
  },
  {
    "text": "uh, anonymous, uh, walk.",
    "start": "426950",
    "end": "429510"
  },
  {
    "start": "429000",
    "end": "507000"
  },
  {
    "text": "Now, of course the question also becomes,",
    "start": "429570",
    "end": "432835"
  },
  {
    "text": "how- how many random walks do you need?",
    "start": "432835",
    "end": "436375"
  },
  {
    "text": "And that is very nice mathematical formula that",
    "start": "436375",
    "end": "439840"
  },
  {
    "text": "tells you how many anonymous walks you wanna",
    "start": "439840",
    "end": "443290"
  },
  {
    "text": "sample such that your estimates in",
    "start": "443290",
    "end": "447040"
  },
  {
    "text": "the frequency or the probabilities of occurrence are, uh, accurate.",
    "start": "447040",
    "end": "451375"
  },
  {
    "text": "And you can quantify accuracy by two parameters,",
    "start": "451375",
    "end": "455155"
  },
  {
    "text": "Epsilon, um, and, um, and Delta, uh,",
    "start": "455155",
    "end": "459205"
  },
  {
    "text": "where basically we say we want the distribution of these, uh, uh,",
    "start": "459205",
    "end": "463330"
  },
  {
    "text": "probabilities of anonymous walks to have error of no more than Epsilon,",
    "start": "463330",
    "end": "467485"
  },
  {
    "text": "with probability, uh, less than Delta.",
    "start": "467485",
    "end": "469824"
  },
  {
    "text": "You can plug in these two numbers into",
    "start": "469825",
    "end": "471850"
  },
  {
    "text": "the following equation and that will tell you the number of,",
    "start": "471850",
    "end": "475150"
  },
  {
    "text": "uh, anonymous walks you may wanna,",
    "start": "475150",
    "end": "477400"
  },
  {
    "text": "uh, you may need to sample.",
    "start": "477400",
    "end": "479410"
  },
  {
    "text": "So for example, if you consider anonymous walk of length 7,",
    "start": "479410",
    "end": "483025"
  },
  {
    "text": "there is 877 of them.",
    "start": "483025",
    "end": "485560"
  },
  {
    "text": "If you set the Epsilon to 0.1 and Delta to, uh, 0.01,",
    "start": "485560",
    "end": "490180"
  },
  {
    "text": "then you would need to sample about 120,000, uh,",
    "start": "490180",
    "end": "494740"
  },
  {
    "text": "random walks that you can estimate this probability distribution over this,",
    "start": "494740",
    "end": "498720"
  },
  {
    "text": "er, 877, uh, different, uh, anonymous walks.",
    "start": "498720",
    "end": "503025"
  },
  {
    "text": "So that's the idea in terms of anonymous walks.",
    "start": "503025",
    "end": "506655"
  },
  {
    "text": "And, um, we can further, um,",
    "start": "506655",
    "end": "510215"
  },
  {
    "start": "507000",
    "end": "839000"
  },
  {
    "text": "enhance this idea, uh,",
    "start": "510215",
    "end": "512620"
  },
  {
    "text": "to actually learn embeddings of the walks themselves.",
    "start": "512620",
    "end": "516729"
  },
  {
    "text": "So let me explain how we can do this.",
    "start": "516730",
    "end": "518800"
  },
  {
    "text": "So rather than simply representing each walk by the fraction of time it occurs,",
    "start": "518800",
    "end": "524529"
  },
  {
    "text": "we can learn an embedding Z_i of anonymous walk W_i.",
    "start": "524530",
    "end": "529930"
  },
  {
    "text": "And then we can learn also our graph embedding",
    "start": "529930",
    "end": "532960"
  },
  {
    "text": "Z- Z_G together with the anonymous walk, uh, embeddings.",
    "start": "532960",
    "end": "538090"
  },
  {
    "text": "So this means, uh,",
    "start": "538090",
    "end": "539560"
  },
  {
    "text": "for a- for a- we are going to learn- the number of embeddings we're going to learn,",
    "start": "539560",
    "end": "544090"
  },
  {
    "text": "will be the number of anonymous walks plus 1 because",
    "start": "544090",
    "end": "547600"
  },
  {
    "text": "we are learning an embedding for every anonymous walk plus the embedding,",
    "start": "547600",
    "end": "551110"
  },
  {
    "text": "uh, for the graph.",
    "start": "551110",
    "end": "552954"
  },
  {
    "text": "Right? So again, how are we going to learn",
    "start": "552955",
    "end": "556180"
  },
  {
    "text": "these embeddings of graph and the anonymous walks?",
    "start": "556180",
    "end": "559135"
  },
  {
    "text": "We can- we do this in a very similar way to what we did for DeepWalk or node2vec.",
    "start": "559135",
    "end": "564295"
  },
  {
    "text": "We wanna embed walks so that,",
    "start": "564295",
    "end": "566709"
  },
  {
    "text": "uh, walks adjacent to it can be predicted.",
    "start": "566710",
    "end": "569425"
  },
  {
    "text": "So let me explain the idea.",
    "start": "569425",
    "end": "571240"
  },
  {
    "text": "So the idea is that again,",
    "start": "571240",
    "end": "572920"
  },
  {
    "text": "we will have this vector G that describes the graph.",
    "start": "572920",
    "end": "576144"
  },
  {
    "text": "We are going to have the, uh,",
    "start": "576145",
    "end": "578080"
  },
  {
    "text": "and this will be the embedding of the entire graph we are going to learn.",
    "start": "578080",
    "end": "581420"
  },
  {
    "text": "Let's say we start from some no- node 1 and we sample anonymous,",
    "start": "581420",
    "end": "585600"
  },
  {
    "text": "uh, random walks from it.",
    "start": "585600",
    "end": "587084"
  },
  {
    "text": "So then the idea is to learn to predict walks that co-occur in some, uh, uh,",
    "start": "587085",
    "end": "594240"
  },
  {
    "text": "uh, Delta window size, um, um,",
    "start": "594240",
    "end": "597730"
  },
  {
    "text": "around as we are sampling this random walks,",
    "start": "597730",
    "end": "600310"
  },
  {
    "text": "uh, from a given node.",
    "start": "600310",
    "end": "601465"
  },
  {
    "text": "So the idea is that the objective function is we wanna go,",
    "start": "601465",
    "end": "605065"
  },
  {
    "text": "um, over this window size Delta,",
    "start": "605065",
    "end": "607045"
  },
  {
    "text": "where this W_t are random wa- are anonymous random walks that all start at,",
    "start": "607045",
    "end": "613720"
  },
  {
    "text": "uh, at a starting node 1 and,",
    "start": "613720",
    "end": "616569"
  },
  {
    "text": "uh, Z_G is the embedding of the graph.",
    "start": "616570",
    "end": "619870"
  },
  {
    "text": "And now we basically sum these-",
    "start": "619870",
    "end": "622315"
  },
  {
    "text": "these objective over all starting nodes, uh, in the graph.",
    "start": "622315",
    "end": "626455"
  },
  {
    "text": "So the idea is that we will run T different random walks from each, uh,",
    "start": "626455",
    "end": "632875"
  },
  {
    "text": "node u of length l. So now our notion of neighborhood is not a set of nodes,",
    "start": "632875",
    "end": "638680"
  },
  {
    "text": "but it's a set of anonymous,",
    "start": "638680",
    "end": "641665"
  },
  {
    "text": "uh, random walks, uh,",
    "start": "641665",
    "end": "643690"
  },
  {
    "text": "here labeled by W. And then we want to learn to predict walks",
    "start": "643690",
    "end": "647200"
  },
  {
    "text": "that co-occur in a window of size, uh, Delta.",
    "start": "647200",
    "end": "650785"
  },
  {
    "text": "So the idea is that you wanna em- em- estimate",
    "start": "650785",
    "end": "653560"
  },
  {
    "text": "the embedding Z_i on anony- of anonymous walks W_i,",
    "start": "653560",
    "end": "657190"
  },
  {
    "text": "um, and then, uh,",
    "start": "657190",
    "end": "659200"
  },
  {
    "text": "maximize these given objective where basically we go over, uh,",
    "start": "659200",
    "end": "663100"
  },
  {
    "text": "er, all the random walks that we run from the- from the- from the given node.",
    "start": "663100",
    "end": "667990"
  },
  {
    "text": "Uh, this- this is a sequence of random walks that occ- or anonymous walks that occurred.",
    "start": "667990",
    "end": "672580"
  },
  {
    "text": "Our goal is to find the embedding of the graph as well as the embeddings of",
    "start": "672580",
    "end": "677260"
  },
  {
    "text": "the anonymous walks so that we can predict what is the next anonymous walk,",
    "start": "677260",
    "end": "682270"
  },
  {
    "text": "what is the identity of the next anonymous walk that is going, uh,",
    "start": "682270",
    "end": "686320"
  },
  {
    "text": "to occur in these, uh,",
    "start": "686320",
    "end": "687955"
  },
  {
    "text": "in these sampling of anonymous walks.",
    "start": "687955",
    "end": "690655"
  },
  {
    "text": "So essentially this is the same objective function as we used in note to record DeepWalk,",
    "start": "690655",
    "end": "696055"
  },
  {
    "text": "but the difference is the following,",
    "start": "696055",
    "end": "697885"
  },
  {
    "text": "is that when we are defining this notion of neighborhood,",
    "start": "697885",
    "end": "700525"
  },
  {
    "text": "we don't define neighborhood over the nodes that are visited,",
    "start": "700525",
    "end": "704245"
  },
  {
    "text": "but we define it over the, uh,",
    "start": "704245",
    "end": "707695"
  },
  {
    "text": "anonymous walks that occur,",
    "start": "707695",
    "end": "710560"
  },
  {
    "text": "uh, starting from node u.",
    "start": "710560",
    "end": "712255"
  },
  {
    "text": "So here W is an entire anonymous walk,",
    "start": "712255",
    "end": "716065"
  },
  {
    "text": "it's an ID of an anonymous walk.",
    "start": "716065",
    "end": "718570"
  },
  {
    "text": "If you want more details and, uh,",
    "start": "718570",
    "end": "720730"
  },
  {
    "text": "and read more there was- there is a paper link",
    "start": "720730",
    "end": "723970"
  },
  {
    "text": "down here that you can read for further details.",
    "start": "723970",
    "end": "727615"
  },
  {
    "text": "But the idea here is right that- now that we have learned",
    "start": "727615",
    "end": "730390"
  },
  {
    "text": "both the embedding of the node as well as the embedding of the walks,",
    "start": "730390",
    "end": "734050"
  },
  {
    "text": "we can- sorry, as we learn the embedding of the graph,",
    "start": "734050",
    "end": "736644"
  },
  {
    "text": "you can use these, er, er,",
    "start": "736645",
    "end": "738460"
  },
  {
    "text": "Z_G as a- as",
    "start": "738460",
    "end": "740440"
  },
  {
    "text": "a descriptor of the graph and we can use it in downstream prediction task, right?",
    "start": "740440",
    "end": "746785"
  },
  {
    "text": "So to summarize, we obtain the graph embedding, uh, Z_G,",
    "start": "746785",
    "end": "751285"
  },
  {
    "text": "which is learnable after this optimization,",
    "start": "751285",
    "end": "754360"
  },
  {
    "text": "and then we can use Z_G to make predictions for example, for graph classification.",
    "start": "754360",
    "end": "759505"
  },
  {
    "text": "We can use, uh,",
    "start": "759505",
    "end": "761125"
  },
  {
    "text": "the dot product the same way as we were using so far,",
    "start": "761125",
    "end": "764425"
  },
  {
    "text": "or we could use a neural network that takes, er, er,",
    "start": "764425",
    "end": "767875"
  },
  {
    "text": "Z_G as an- as an input into our classifier and tries to predict some label this,",
    "start": "767875",
    "end": "773920"
  },
  {
    "text": "uh, graph G. Uh, both options,",
    "start": "773920",
    "end": "776995"
  },
  {
    "text": "uh, are, er, feasible in this case.",
    "start": "776995",
    "end": "779845"
  },
  {
    "text": "So in this, ah, part of the lecture,",
    "start": "779845",
    "end": "783175"
  },
  {
    "text": "we discussed three ideas about how to embed entire graphs.",
    "start": "783175",
    "end": "787300"
  },
  {
    "text": "First was simply average or sum up embeddings of the nodes in",
    "start": "787300",
    "end": "792610"
  },
  {
    "text": "the graph where the embeddings of the nodes are computed by DeepWalk or, um, node2vec.",
    "start": "792610",
    "end": "798445"
  },
  {
    "text": "The second idea was to create a super-node that spans",
    "start": "798445",
    "end": "802330"
  },
  {
    "text": "the subgraph of interest and that embed that super-node.",
    "start": "802330",
    "end": "807325"
  },
  {
    "text": "And then the idea number 3 was to use this notion of anonymous walk embeddings,",
    "start": "807325",
    "end": "812140"
  },
  {
    "text": "uh, where do we sample anonymous, uh,",
    "start": "812140",
    "end": "814720"
  },
  {
    "text": "walks, um, to represent graph as a fraction of times each anonymous walk occurs,",
    "start": "814720",
    "end": "820735"
  },
  {
    "text": "so that's one idea.",
    "start": "820735",
    "end": "822204"
  },
  {
    "text": "And the second more complex idea was to embed anonymous walks and then,",
    "start": "822205",
    "end": "827485"
  },
  {
    "text": "um, either, for example,",
    "start": "827485",
    "end": "828880"
  },
  {
    "text": "concatenate their embeddings or use these Z- Z_G to define the notion,",
    "start": "828880",
    "end": "835555"
  },
  {
    "text": "uh, of the embedding of the entire graph.",
    "start": "835555",
    "end": "839270"
  },
  {
    "start": "839000",
    "end": "872000"
  },
  {
    "text": "What we are going to, um,",
    "start": "839280",
    "end": "842245"
  },
  {
    "text": "consider in the future is also more, um,",
    "start": "842245",
    "end": "845560"
  },
  {
    "text": "er, different approaches to graph embeddings, and in particular,",
    "start": "845560",
    "end": "849295"
  },
  {
    "text": "many times graphs tend to have this type of community or",
    "start": "849295",
    "end": "852459"
  },
  {
    "text": "cluster structure so it becomes a good question how do we hierarchically aggregate,",
    "start": "852460",
    "end": "857770"
  },
  {
    "text": "um, the- the network, er,",
    "start": "857770",
    "end": "860110"
  },
  {
    "text": "to obtain the embedding,",
    "start": "860110",
    "end": "861940"
  },
  {
    "text": "uh, of the entire graph.",
    "start": "861940",
    "end": "863375"
  },
  {
    "text": "And later in Lecture 8,",
    "start": "863375",
    "end": "864950"
  },
  {
    "text": "I'm going to discuss such a- such an approach that uses,",
    "start": "864950",
    "end": "868805"
  },
  {
    "text": "uh, graph neural networks,",
    "start": "868805",
    "end": "870170"
  },
  {
    "text": "uh, to be able to do this.",
    "start": "870170",
    "end": "872144"
  },
  {
    "start": "872000",
    "end": "981000"
  },
  {
    "text": "So, um, to- to conclude,",
    "start": "872145",
    "end": "875660"
  },
  {
    "text": "to keep kind of towards- moving towards the ends of the lecture,",
    "start": "875660",
    "end": "878644"
  },
  {
    "text": "the next question is,",
    "start": "878645",
    "end": "879800"
  },
  {
    "text": "you know, how do we use these embeddings Z_i of the node for example?",
    "start": "879800",
    "end": "884285"
  },
  {
    "text": "Um, you can use them, for example,",
    "start": "884285",
    "end": "886310"
  },
  {
    "text": "to cluster, uh, the points.",
    "start": "886310",
    "end": "888410"
  },
  {
    "text": "Basically, you take the graph, compute the embeddings,",
    "start": "888410",
    "end": "891079"
  },
  {
    "text": "and then run a clustering algorithm over the embeddings, for example,",
    "start": "891080",
    "end": "894700"
  },
  {
    "text": "the do community detection or any kind of social rolling identification.",
    "start": "894700",
    "end": "899090"
  },
  {
    "text": "Uh, you can use these embeddings for a node classification.",
    "start": "899090",
    "end": "901910"
  },
  {
    "text": "Simply predict the label of node i based off it- it's embedding Z. Um,",
    "start": "901910",
    "end": "906694"
  },
  {
    "text": "and you can also use them for, uh,",
    "start": "906695",
    "end": "908330"
  },
  {
    "text": "link prediction where basically you can think nodes, uh,",
    "start": "908330",
    "end": "911270"
  },
  {
    "text": "i and j and you can concatenate their embeddings and then,",
    "start": "911270",
    "end": "915080"
  },
  {
    "text": "uh, based on the concatenation,",
    "start": "915080",
    "end": "916835"
  },
  {
    "text": "uh, you can make a prediction.",
    "start": "916835",
    "end": "919020"
  },
  {
    "text": "When, um, when you are combining this node embeddings,",
    "start": "919020",
    "end": "923405"
  },
  {
    "text": "you have several options.",
    "start": "923405",
    "end": "924710"
  },
  {
    "text": "As I said, one is simply concatenating them, uh,",
    "start": "924710",
    "end": "927740"
  },
  {
    "text": "another option would be to combine them by doing per coordinate product.",
    "start": "927740",
    "end": "931770"
  },
  {
    "text": "Uh, this is- this is nice for undirected graphs because this operation is commutative.",
    "start": "931770",
    "end": "936515"
  },
  {
    "text": "Um, you can also sum or average them.",
    "start": "936515",
    "end": "939575"
  },
  {
    "text": "Another communi- commutative operation meaning that, you know,",
    "start": "939575",
    "end": "942875"
  },
  {
    "text": "probability of link from i to j is the same as from j to i. Um,",
    "start": "942875",
    "end": "946990"
  },
  {
    "text": "or you could measure some kind of L2 distance and then make a prediction",
    "start": "946990",
    "end": "950570"
  },
  {
    "text": "based on these kind of different aggregations of the two- of the two embeddings.",
    "start": "950570",
    "end": "954440"
  },
  {
    "text": "If you wanna make predictions in directed graphs,",
    "start": "954440",
    "end": "957020"
  },
  {
    "text": "then concatenation is nice because you are able to",
    "start": "957020",
    "end": "959450"
  },
  {
    "text": "output a different probability depending on,",
    "start": "959450",
    "end": "962045"
  },
  {
    "text": "you know, is it from i to j or from j to i?",
    "start": "962045",
    "end": "964964"
  },
  {
    "text": "For graph classification, node embedding,",
    "start": "964965",
    "end": "968515"
  },
  {
    "text": "uh, ah, can be computed via aggregating, uh,",
    "start": "968515",
    "end": "971135"
  },
  {
    "text": "node embeddings or through anonymous walks or through this anonymous walk embedding plus,",
    "start": "971135",
    "end": "977300"
  },
  {
    "text": "uh, the graph, ah,",
    "start": "977300",
    "end": "978515"
  },
  {
    "text": "embedding approach, uh, that we have discussed.",
    "start": "978515",
    "end": "981690"
  },
  {
    "start": "981000",
    "end": "1084000"
  },
  {
    "text": "So, uh, to summarize,",
    "start": "981690",
    "end": "983889"
  },
  {
    "text": "today, we discussed, um,",
    "start": "983889",
    "end": "986235"
  },
  {
    "text": "graph representation learning as a way to learn node and graph embeddings, uh,",
    "start": "986235",
    "end": "991430"
  },
  {
    "text": "independent of downstream prediction tasks and without any manual feature engineering.",
    "start": "991430",
    "end": "998279"
  },
  {
    "text": "We had discussed this encoder decoder framework, where encoder,",
    "start": "998280",
    "end": "1002380"
  },
  {
    "text": "you simply an embedding lookup and decoder",
    "start": "1002380",
    "end": "1005680"
  },
  {
    "text": "predicts the score or network-based similarity,",
    "start": "1005680",
    "end": "1009279"
  },
  {
    "text": "uh, based on the pos- the embeddings of the nodes.",
    "start": "1009280",
    "end": "1012235"
  },
  {
    "text": "Um, and we defined, uh,",
    "start": "1012235",
    "end": "1014935"
  },
  {
    "text": "notion of node similarity based on the random walks.",
    "start": "1014935",
    "end": "1018985"
  },
  {
    "text": "We discussed two methods,",
    "start": "1018985",
    "end": "1020825"
  },
  {
    "text": "DeepWalk and node2vec that use the same optimization problem,",
    "start": "1020825",
    "end": "1025180"
  },
  {
    "text": "the same negative sampling approach, uh,",
    "start": "1025180",
    "end": "1027480"
  },
  {
    "text": "but DeepWalk uses a very simple random walk,",
    "start": "1027480",
    "end": "1030120"
  },
  {
    "text": "basically a first-order random walk while node2vec",
    "start": "1030120",
    "end": "1033270"
  },
  {
    "text": "uses a second-order random walk that can- where you can kind of,",
    "start": "1033270",
    "end": "1037345"
  },
  {
    "text": "uh, fine tune the way the network is explored.",
    "start": "1037345",
    "end": "1041360"
  },
  {
    "text": "Um, and then we also discussed extensions, uh,",
    "start": "1041360",
    "end": "1044865"
  },
  {
    "text": "to, uh, graph embeddings, um,",
    "start": "1044865",
    "end": "1047939"
  },
  {
    "text": "which means that we can simply aggregate",
    "start": "1047940",
    "end": "1050230"
  },
  {
    "text": "node embeddings and we also talked about anonymous, er, random walks,",
    "start": "1050230",
    "end": "1054945"
  },
  {
    "text": "where the anonymous random walk represents the walk not by the identities of the nodes,",
    "start": "1054945",
    "end": "1060580"
  },
  {
    "text": "but by the time or by the index at",
    "start": "1060580",
    "end": "1064169"
  },
  {
    "text": "what ti- at what time a given node was first, uh, visited.",
    "start": "1064170",
    "end": "1068595"
  },
  {
    "text": "So, uh, these are- this is a set of approaches,",
    "start": "1068595",
    "end": "1071744"
  },
  {
    "text": "um, I wanted to, uh, discuss today.",
    "start": "1071744",
    "end": "1074410"
  },
  {
    "text": "Um, and thank you very much for watching and,",
    "start": "1074410",
    "end": "1077085"
  },
  {
    "text": "uh, attending the lecture.",
    "start": "1077085",
    "end": "1079330"
  }
]
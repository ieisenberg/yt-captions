[
  {
    "start": "0",
    "end": "6600"
  },
  {
    "text": "Hello, it's fun to be here. So the work I'm presenting\ntoday, the title of it",
    "start": "6600",
    "end": "14759"
  },
  {
    "text": "is Attention Approximates\nSparse Distributed Memory, and this was done\nin collaboration with Cengiz Pehlevan, and my\nPhD advisor was Gabriel Kreiman.",
    "start": "14760",
    "end": "24540"
  },
  {
    "text": "So why should you\ncare about this work? We show that the heuristic\nattention operation can be implemented\nwith simple properties",
    "start": "24540",
    "end": "31260"
  },
  {
    "text": "of high dimensional vectors in a\nbiologically plausible fashion. So the transformer and\nattention, as you know,",
    "start": "31260",
    "end": "37580"
  },
  {
    "text": "are incredibly powerful,\nbut they were heuristically developed, and the softmax\noperation in attention",
    "start": "37580",
    "end": "43950"
  },
  {
    "text": "is particularly important\nbut also heuristic. And so, we show that the\nintersection of hyperspheres",
    "start": "43950",
    "end": "50730"
  },
  {
    "text": "that is used in sparse\ndistributed memory closely approximates the softmax\nand attention more broadly,",
    "start": "50730",
    "end": "57370"
  },
  {
    "text": "both in theory and with\nsome experiments on train transformers. So you can see SDM,\nSparse Distributed Memory,",
    "start": "57370",
    "end": "64378"
  },
  {
    "text": "as preempting attention\nby approximately 30 years. It was developed back in 1988,\nand what's exciting about this",
    "start": "64379",
    "end": "71290"
  },
  {
    "text": "is that it meets a high bar\nfor biological plausibility. Hopefully, I have\ntime to actually get into the wiring\nof the cerebellum,",
    "start": "71290",
    "end": "76727"
  },
  {
    "text": "and how you can\nmap each operation to part of the circuit there.",
    "start": "76727",
    "end": "81770"
  },
  {
    "text": "So first, I'm going to give an\noverview of Sparse Distributed Memory. I have a transformer\nattention summary,",
    "start": "81770",
    "end": "88840"
  },
  {
    "text": "but I assume that you guys\nalready know all of that. We can get there and then decide\nhow deep we want to go into it.",
    "start": "88840",
    "end": "95270"
  },
  {
    "text": "I'll then talk about how\nactually attention approximates SDM. Interpret the transformer more\nbroadly, and then hopefully,",
    "start": "95270",
    "end": "103210"
  },
  {
    "text": "there's time to go into SDM's\nbiological plausibility. Also, I'm going\nto keep everything",
    "start": "103210",
    "end": "108280"
  },
  {
    "text": "high level visual intuition,\nand then go into the math. But stop me, and please ask\nquestions, literally, whenever.",
    "start": "108280",
    "end": "115899"
  },
  {
    "text": "OK. So Sparse Distributed\nMemory is motivated by the question of how the\nbrain can read and write",
    "start": "115900",
    "end": "121630"
  },
  {
    "text": "memories in order to later\nretrieve the correct one. And some considerations\nthat it takes into account",
    "start": "121630",
    "end": "127090"
  },
  {
    "text": "are high memory capacity,\nrobustness to query noise, biological plausibility, and\nsome notion of fault tolerance.",
    "start": "127090",
    "end": "134590"
  },
  {
    "text": "SDM is unique from other\nassociative memory models that you may be familiar\nwith, like hopfield networks.",
    "start": "134590",
    "end": "140230"
  },
  {
    "text": "Insomuch as it's\nsparse, so it operates at a very high\ndimensional vector space,",
    "start": "140230",
    "end": "145840"
  },
  {
    "text": "and the neurons that\nexist in this space only occupy a very small\nportion of possible locations.",
    "start": "145840",
    "end": "152560"
  },
  {
    "text": "It's also distributed, so\nall read and write operations apply to all nearby neurons.",
    "start": "152560",
    "end": "160040"
  },
  {
    "text": "It is actually, as a side\nnote, hopfield networks, if you're familiar with\nthem, are a special case of sparse distributed memory.",
    "start": "160040",
    "end": "166415"
  },
  {
    "text": "I'm not going to go\ndeep into that now, but I have a blog post on it.",
    "start": "166415",
    "end": "172069"
  },
  {
    "text": "OK. So first, we're going to look at\nthe write operation for sparse distributed memory.",
    "start": "172070",
    "end": "177159"
  },
  {
    "text": "We're in this high dimensional\nbinary vector space. We're using hamming distance\nas our metric for now,",
    "start": "177160",
    "end": "183430"
  },
  {
    "text": "we'll move to continuous later. And we have this\ngreen pattern, which",
    "start": "183430",
    "end": "190120"
  },
  {
    "text": "is represented by the solid\ndot, and the hollow circles are these hypothetical neurons. Also, think of everything\nquite abstractly,",
    "start": "190120",
    "end": "197350"
  },
  {
    "text": "and then we'll map\nto biology later. So this pattern\nhas a write radius, which is some hamming distance.",
    "start": "197350",
    "end": "204040"
  },
  {
    "text": "It activates all of the neurons\nwithin that hamming distance, and then here I just denote\nthat each of those neurons",
    "start": "204040",
    "end": "211780"
  },
  {
    "text": "are now storing\nthat green pattern, and the green pattern\nhas disappeared. So I'm keeping track\nof its location",
    "start": "211780",
    "end": "217630"
  },
  {
    "text": "with this kind of\nfuzzy hollow circle. That will be relevant later. So we're writing in another\npattern, this orange one,",
    "start": "217630",
    "end": "224380"
  },
  {
    "text": "and note here that neurons can\nstore multiple patterns inside of them. And formally, this is actually\na superposition or just",
    "start": "224380",
    "end": "231100"
  },
  {
    "text": "a summation of these\nhigh dimensional vectors. Because they're\nhigh dimensional, you don't have that\nmuch crosstalk, so you can get away with it.",
    "start": "231100",
    "end": "236329"
  },
  {
    "text": "But for now, you can\neven just think of it as a neuron can store\nmultiple patterns.",
    "start": "236330",
    "end": "242360"
  },
  {
    "text": "Finally, we have a third\npattern, this blue one. We're writing in\nanother location. And yeah, so again,\nwe're keeping",
    "start": "242360",
    "end": "250013"
  },
  {
    "text": "track of the original\npattern locations, and they can be--\nbut they can be triangulated from the nearby\nneurons that are storing them.",
    "start": "250013",
    "end": "257359"
  },
  {
    "text": "And so we've written\nin three patterns. Now we want to read\nfrom the system. So I have this pink stars side.",
    "start": "257360",
    "end": "263470"
  },
  {
    "text": "It appears-- it has a\ngiven It's represented by a given vector, which\nhas a location in the space.",
    "start": "263470",
    "end": "269380"
  },
  {
    "text": "It activates nearby\nneurons again, but now the neurons\noutput the patterns",
    "start": "269380",
    "end": "275710"
  },
  {
    "text": "that they've stored previously. And so you can see that\nbased upon its location,",
    "start": "275710",
    "end": "280910"
  },
  {
    "text": "it's getting four blue patterns,\ntwo orange, and one green. And it then does a\nmajority rule operation,",
    "start": "280910",
    "end": "287620"
  },
  {
    "text": "where it updates\ntowards whatever pattern it sees the most. So in this case because\nblue is actually a majority,",
    "start": "287620",
    "end": "294790"
  },
  {
    "text": "it's just going to update\ncompletely towards blue. Again, I'll formalize\nthis more in a bit, but this is really\nto give you intuition",
    "start": "294790",
    "end": "301360"
  },
  {
    "text": "for the core operations of SDM. So the key thing to relate\nthis back to attention",
    "start": "301360",
    "end": "310000"
  },
  {
    "text": "is actually to abstract\naway the neurons that are operating under the hood,\nand just consider these circle",
    "start": "310000",
    "end": "315340"
  },
  {
    "text": "intersections. And so what each of\nthese intersections between the pink circle and\neach of the write circles means",
    "start": "315340",
    "end": "323260"
  },
  {
    "text": "is the intersection\nis the neurons that both store that pattern\nwhen it was written in,",
    "start": "323260",
    "end": "328660"
  },
  {
    "text": "and are now being read\nfrom by the query. And the size of\nthat intersection",
    "start": "328660",
    "end": "334570"
  },
  {
    "text": "corresponds to how\nmany patterns the query is then going to read. ",
    "start": "334570",
    "end": "343090"
  },
  {
    "text": "And so formally, we\ndefine the number of neurons in this\ncircle intersection as the cardinality between\nnumber of neurons in pattern,",
    "start": "343090",
    "end": "352000"
  },
  {
    "text": "number of neurons in query\nand their intersection. ",
    "start": "352000",
    "end": "358669"
  },
  {
    "text": "OK. Are there any questions\nat a high level before I get more into the math?",
    "start": "358670",
    "end": "365300"
  },
  {
    "text": "I don't know if I can check. Is it easy for me to check Zoom? Nah, sorry, Zoom people,\nI'm not going to check.",
    "start": "365300",
    "end": "370355"
  },
  {
    "text": "OK. Are the neurons just randomly\ndistributed in the space? Yes. Yeah, yeah, yeah. And there's later-- there's more\nrecent work that they can learn",
    "start": "370355",
    "end": "379507"
  },
  {
    "text": "and update their location\nto [INAUDIBLE] manifold, but in this, you can assume\nthat they're randomly initialized binary high\ndimensional vectors.",
    "start": "379507",
    "end": "387440"
  },
  {
    "text": "OK. So this is the full\nSDM update rule.",
    "start": "387440",
    "end": "394160"
  },
  {
    "text": "I'm going to break it down. So the first thing that you do. So this is for\nreading, to be clear.",
    "start": "394160",
    "end": "400280"
  },
  {
    "text": "So you've already written\npatterns into your neurons. So the first thing you do\nis you weight each pattern",
    "start": "400280",
    "end": "406070"
  },
  {
    "text": "by the size of its\ncircle intersection. So the circle intersection\nthere for each pattern.",
    "start": "406070",
    "end": "413280"
  },
  {
    "text": "Then you sum over all of\nthe patterns that have been written into the space.",
    "start": "413280",
    "end": "418580"
  },
  {
    "text": "So you're just doing a\nweighted summation of them. And then there's\nthis normalization",
    "start": "418580",
    "end": "423900"
  },
  {
    "text": "by the total number of\nintersections that you have.",
    "start": "423900",
    "end": "429389"
  },
  {
    "text": "And finally, because\nat least for now we're working in this binary space,\nyou map back to binary,",
    "start": "429390",
    "end": "434840"
  },
  {
    "text": "just seeing if the values\nare greater than one half. ",
    "start": "434840",
    "end": "441040"
  },
  {
    "text": "OK. How familiar are\npeople with attention? I looked at like the\nprevious talks you've had,",
    "start": "441040",
    "end": "446230"
  },
  {
    "text": "they seem quite high level. Like, can you guys write the\nattention equation for me?",
    "start": "446230",
    "end": "451360"
  },
  {
    "text": "Is that like-- can I get\nthumbs up if you can do that?",
    "start": "451360",
    "end": "456900"
  },
  {
    "text": "Yeah. OK, I'm not like-- I'll go through this, but\nI'll probably go through it",
    "start": "456900",
    "end": "462300"
  },
  {
    "text": "faster than otherwise. So when I first made\nthis presentation, like, this was the state of the\nart for transformers, which",
    "start": "462300",
    "end": "468180"
  },
  {
    "text": "was like [INAUDIBLE] alphafold. And so it's kind of funny\nhow far things have come now.",
    "start": "468180",
    "end": "474390"
  },
  {
    "text": "I don't need to tell you that\ntransformers are important. So yeah.",
    "start": "474390",
    "end": "480380"
  },
  {
    "text": "I'm going to work\nwith this example. Well, OK, I'm going to work\nwith this example here, the cat sat on the blank.",
    "start": "480380",
    "end": "487020"
  },
  {
    "text": "And so in this setting,\nwe're predicting the next token,\nwhich hypothetically",
    "start": "487020",
    "end": "492710"
  },
  {
    "text": "is the word \"mat.\" And so there are four things\nthat the attention operation",
    "start": "492710",
    "end": "497810"
  },
  {
    "text": "is doing. The first one up here\nis it's generating what are called keys\nvalues and queries. And again, I'll get into\nthe math in a second,",
    "start": "497810",
    "end": "504212"
  },
  {
    "text": "I'm just trying to keep\nit high level first. And then we're going\nto compare our query",
    "start": "504213",
    "end": "510110"
  },
  {
    "text": "with each of the keys. So the word \"the,\" which is\nclosest to the word we're next predicting is our\nquery, and we're",
    "start": "510110",
    "end": "517159"
  },
  {
    "text": "seeing how similar is\neach of the key vectors.",
    "start": "517159",
    "end": "522979"
  },
  {
    "text": "We then, based upon\nthat similarity, do this softmax normalization\nso that all of the attention",
    "start": "522980",
    "end": "530779"
  },
  {
    "text": "weights sum to 1. And then we sum\ntogether their value vectors to use to\npropagate to the next layer",
    "start": "530780",
    "end": "538730"
  },
  {
    "text": "or uses our prediction. And so at a high\nlevel, you can think",
    "start": "538730",
    "end": "544399"
  },
  {
    "text": "of this as, like,\nthe query word \"the\" is looking for nouns and\ntheir associated verbs.",
    "start": "544400",
    "end": "550070"
  },
  {
    "text": "And so hypothetically,\nit has a high similarity with words like cat and\nsat or they're keys.",
    "start": "550070",
    "end": "557070"
  },
  {
    "text": "So this then gives\nlarge weight to the cat and sat value vectors,\nwhich get moved",
    "start": "557070",
    "end": "562220"
  },
  {
    "text": "to the next part of the network. And the cat value\nvector, hypothetically, contains a superposition\nof other animals,",
    "start": "562220",
    "end": "568860"
  },
  {
    "text": "like mice and maybe words\nthat rhyme with mat. And the sat vector\nalso contains things",
    "start": "568860",
    "end": "575089"
  },
  {
    "text": "that are sat on, including mat. And so what you actually\nget from the value",
    "start": "575090",
    "end": "580100"
  },
  {
    "text": "vectors of paying attention to\ncat and sat are like, 3 times",
    "start": "580100",
    "end": "585259"
  },
  {
    "text": "mat plus 1 times mouse\nplus 1 times sofa. This is again, like, a\ntotally hypothetical example,",
    "start": "585260",
    "end": "591050"
  },
  {
    "text": "but I'm trying to make the\npoint that you can extract from your value vectors\nthings useful for predicting",
    "start": "591050",
    "end": "599240"
  },
  {
    "text": "the next token by paying\nattention to specific keys. ",
    "start": "599240",
    "end": "606960"
  },
  {
    "text": "So-- and I guess-- yeah, another thing here is\nlike what you pay attention to. So cat and stat might\nbe different from what",
    "start": "606960",
    "end": "612389"
  },
  {
    "text": "you're actually extracting. If you're paying\nattention to your keys, but you're getting\nyour value vectors out. OK, so here is the full\nattention equation.",
    "start": "612390",
    "end": "620339"
  },
  {
    "text": "The top line, I'm separating\nout the projection matrices, W subscript V [INAUDIBLE] and\nq, and then the second one,",
    "start": "620340",
    "end": "627150"
  },
  {
    "text": "I just collapsed them into the\nequation you are going to see. And yeah, so\nbreaking this apart,",
    "start": "627150",
    "end": "634529"
  },
  {
    "text": "the first step here\nis we compare-- we do a dot product between\nour query vector and our keys.",
    "start": "634530",
    "end": "641610"
  },
  {
    "text": "This should actually\nbe a small q and capital Q. Sorry for that. And so yeah, we're doing\nthis dot product between them",
    "start": "641610",
    "end": "648810"
  },
  {
    "text": "to see-- get a notion of similarity. We then apply the\nsoftmax operation,",
    "start": "648810",
    "end": "654839"
  },
  {
    "text": "which is an exponential\nover a sum of exponentials. The way to think of\nthe softmax is it just",
    "start": "654840",
    "end": "660149"
  },
  {
    "text": "makes large values larger. And this will be\nimportant for the relation",
    "start": "660150",
    "end": "665920"
  },
  {
    "text": "to SDM, so I'll\nspend a minute on it. At the top here, I have\nsome hypothetical items--",
    "start": "665920",
    "end": "672310"
  },
  {
    "text": "index from 0 to 9. And then the values for\neach of those items.",
    "start": "672310",
    "end": "677530"
  },
  {
    "text": "In the second row, I just do\nlike a normal normalization of them. And so the top item\ngoes to a 30% value.",
    "start": "677530",
    "end": "685310"
  },
  {
    "text": "But if I instead\ndo a softmax, it depends on the beta\n[INAUDIBLE],, the softmax. But the value becomes 0.6.",
    "start": "685310",
    "end": "691870"
  },
  {
    "text": "So it just-- it makes your\ndistributions peak year, is kind of one way\nof thinking of it. And this is useful for\nattention, because you only",
    "start": "691870",
    "end": "698770"
  },
  {
    "text": "want to pay attention to\nthe most important things, or the things that are nearby. And kind of ignore\nstuff further away.",
    "start": "698770",
    "end": "706930"
  },
  {
    "text": "And so, once we've\napplied our softmax, we then just do a\nweighted summation",
    "start": "706930",
    "end": "714060"
  },
  {
    "text": "of our value vector,\nwhich actually get extracted and propagate\nto the next layer.",
    "start": "714060",
    "end": "721605"
  },
  {
    "text": " OK, so here's the full equation.",
    "start": "721605",
    "end": "730020"
  },
  {
    "text": "I went through that\na little bit quickly. I'm happy to answer\nquestions on it, but I think half of you of you\nknow it, half of you don't.",
    "start": "730020",
    "end": "735766"
  },
  {
    "text": " OK, so how does transformer\nattention approximate sparse",
    "start": "735767",
    "end": "743180"
  },
  {
    "text": "distributed memory? This 30-year-old thing that I've\nsaid is biologically plausible.",
    "start": "743180",
    "end": "749820"
  },
  {
    "text": "So yeah? It's, like, reasonable to accept\nthat that SDM is biologically",
    "start": "749820",
    "end": "755540"
  },
  {
    "text": "[INAUDIBLE]? So I'm going to get to\nthat at the end, yeah. And attention is also, like in\nthe sense of like all attention",
    "start": "755540",
    "end": "762020"
  },
  {
    "text": "mechanisms. Is that like it was\ninvented by [INAUDIBLE]?? I think the attention\nequation I'm showing here",
    "start": "762020",
    "end": "768410"
  },
  {
    "text": "was developed-- I mean, attention is all\nyou need was the highlight. But Bengio has a\npaper from 2015,",
    "start": "768410",
    "end": "775220"
  },
  {
    "text": "where it was actually\nfirst written in this way. Correct me if I'm wrong,\nbut I'm pretty sure--",
    "start": "775220",
    "end": "780920"
  },
  {
    "text": "Yeah, I mean, I guess\nlike this particular one. That's why I was asking\nthe question, because-- No, it's a good question.",
    "start": "780920",
    "end": "787620"
  },
  {
    "text": "Like you show that two\ndifferent methods that could be classified as\nlike attention proposals,",
    "start": "787620",
    "end": "794000"
  },
  {
    "text": "right, are like the same. And like you said, one\nof them is indifferent.",
    "start": "794000",
    "end": "801270"
  },
  {
    "text": "Yes, exactly, so I'll show\nthat has really nice mappings to a circuit in the cerebellum\nat the neuronal level.",
    "start": "801270",
    "end": "807990"
  },
  {
    "text": "And then, there's right now,\nit's this link to attention. And I guess you make a\ngood point that there",
    "start": "807990",
    "end": "813540"
  },
  {
    "text": "are other attention mechanisms. This is the one that\nhas been dominant. But I don't think that's\njust a coincidence.",
    "start": "813540",
    "end": "819330"
  },
  {
    "text": "There's been a\nbunch of-- computing your softmax is\nexpensive, and there's been a bunch of work like\nthe Linformer, et cetera,",
    "start": "819330",
    "end": "825102"
  },
  {
    "text": "et cetera, that tries to get\nrid of the softmax operation. And it's just done really badly. Like there's a bunch of jokes\non Twitter now that it's like",
    "start": "825103",
    "end": "831900"
  },
  {
    "text": "a black hole for people to\ntry and get rid of softmax, and you can't. And so it seems like this--\nand like other versions of it,",
    "start": "831900",
    "end": "838860"
  },
  {
    "text": "transformers just don't scale\nas well in the same way. And so there's something\nimportant about this particular",
    "start": "838860",
    "end": "844830"
  },
  {
    "text": "attention equation. But it goes the\nother way, right? Which is like, if this is\nreally important, then like SDM",
    "start": "844830",
    "end": "852569"
  },
  {
    "text": "is like actually like this. ",
    "start": "852570",
    "end": "857580"
  },
  {
    "text": "So the thing that I\nthink is important is that you have this\nexponential weighting, where you're really paying\nattention to the things",
    "start": "857580",
    "end": "863460"
  },
  {
    "text": "that matter and you're\nignoring everything else. And that is what\nSDM approximates.",
    "start": "863460",
    "end": "869190"
  },
  {
    "text": "There might be better\nequations, but the point I was just trying to make\nthere is like the softmax does",
    "start": "869190",
    "end": "875430"
  },
  {
    "text": "seem to be important,\nand this equation does seem to be very successful. And we haven't come up with\nbetter formulations for it.",
    "start": "875430",
    "end": "884350"
  },
  {
    "text": "Yeah, no, that's\na great question. OK, so it turns out that\nsparse distributed memory,",
    "start": "884350",
    "end": "890590"
  },
  {
    "text": "as you move your query and your\npattern away from each other-- so you pull these circles apart,\nthe read and write circles--",
    "start": "890590",
    "end": "898270"
  },
  {
    "text": "the number of neurons that\nare in this intersection, in a sufficiently\nhigh-dimensional space, decays approximately\nexponentially.",
    "start": "898270",
    "end": "905920"
  },
  {
    "text": "And so on this\nright plot here, I am pulling apart-- the\nx-axis is me pulling apart",
    "start": "905920",
    "end": "911470"
  },
  {
    "text": "the blue and the pink circles. And the y-axis is on a log\nscale the number of neurons",
    "start": "911470",
    "end": "918430"
  },
  {
    "text": "that are in the intersection. And so to the extent that\nthis is a linear plot on a log",
    "start": "918430",
    "end": "923920"
  },
  {
    "text": "scale, it's exponential. And this is for a\nparticular setting,",
    "start": "923920",
    "end": "930430"
  },
  {
    "text": "where I have my 64\ndimensional vectors, because I used in GPT2, it holds across\na lot of different settings,",
    "start": "930430",
    "end": "938240"
  },
  {
    "text": "particularly higher\ndimensions, which are now used for bigger transformers.",
    "start": "938240",
    "end": "943510"
  },
  {
    "text": "OK, so I have this shorthand\nfor the circle intersection equation.",
    "start": "943510",
    "end": "949430"
  },
  {
    "text": "And what I'll show is how\nthe circle intersection is approximately exponential.",
    "start": "949430",
    "end": "956450"
  },
  {
    "text": "So we can write it with two\nconstants, c subscript 1 and subscript 2. With the one outside, because\nyou're normalizing-- softmax",
    "start": "956450",
    "end": "965780"
  },
  {
    "text": "is exponential over\nsome exponentials-- that will cancel. The thing that\nmatters is c2, and you can approximate that nicely\nwith the beta coefficient that's",
    "start": "965780",
    "end": "973310"
  },
  {
    "text": "used in the softmax. And so yeah, I\nguess, as well, I'll",
    "start": "973310",
    "end": "980480"
  },
  {
    "text": "focus first on the binary\noriginal version of SDM. But then we also develop\na continuous version.",
    "start": "980480",
    "end": "987560"
  },
  {
    "text": "OK, so yeah, the two things\nthat you need for this circle intersection, and\nthe exponential decay",
    "start": "987560",
    "end": "993319"
  },
  {
    "text": "to work, or to map\nit to attention, is you need some notion\nof continuous space.",
    "start": "993320",
    "end": "999090"
  },
  {
    "text": "And so you can use this equation\nhere to map Hamming distances, to discretize cosine\nsimilarity values, where",
    "start": "999090",
    "end": "1007450"
  },
  {
    "text": "the hats over the vectors\nare L2 nominalizations. And you can then write the\ncircle intersection equation",
    "start": "1007450",
    "end": "1015940"
  },
  {
    "text": "on the left as this exponential\nwith these two concepts",
    "start": "1015940",
    "end": "1023470"
  },
  {
    "text": "that you need to learn. And then rewrite this\nby converting c2 to c-- you can write this as\na beta coefficient.",
    "start": "1023470",
    "end": "1032410"
  },
  {
    "text": "Let me get to some plots. Yeah, so you need the\ncorrect coefficient. But you can fit this with a log\nlinear regression in a closed",
    "start": "1032410",
    "end": "1039099"
  },
  {
    "text": "form.  I want to show a plot here. Yeah, OK, so in the blue\nis our circle intersection",
    "start": "1039099",
    "end": "1048790"
  },
  {
    "text": "for two different\nHamming distances, both using 64 dimensional vectors. And the orange is our actual\nsoftmax attention operation",
    "start": "1048790",
    "end": "1057280"
  },
  {
    "text": "where we fit the beta\ncoefficient, such that it will-- the Hamming distance\nused by attention",
    "start": "1057280",
    "end": "1063910"
  },
  {
    "text": "is equivalent to the Hamming\ndistance used by SDM. And you can see-- so the main\nplot is the normalized weights,",
    "start": "1063910",
    "end": "1072220"
  },
  {
    "text": "so just summed up and\nundivided, so this one, and then I've logged plots here.",
    "start": "1072220",
    "end": "1077770"
  },
  {
    "text": "And you can see that\nin not log space, the curves agree quite nicely.",
    "start": "1077770",
    "end": "1084770"
  },
  {
    "text": "You can see that for\nthe higher dimensional-- sorry, the larger Hamming\ndistance, the log plot",
    "start": "1084770",
    "end": "1090010"
  },
  {
    "text": "you see this drop off here\nwhere the circle intersection stops being exponential.",
    "start": "1090010",
    "end": "1095139"
  },
  {
    "text": "But it turns out this\nactually isn't a problem, because the point\nat which the drop-- the exponential breaks down,\nyou're at approximately 0.20",
    "start": "1095140",
    "end": "1104890"
  },
  {
    "text": "here. And you're basically\npaying negligible attention to any of those points.",
    "start": "1104890",
    "end": "1110000"
  },
  {
    "text": "And so in the regime where the\nexponential really matters, this approximation holds true.",
    "start": "1110000",
    "end": "1116760"
  },
  {
    "text": "Yeah? [INAUDIBLE] Yeah. Yeah, the [INAUDIBLE]?",
    "start": "1116760",
    "end": "1123200"
  },
  {
    "text": "Yeah, yeah, no, I just wanted\nto actually show a figure to get some intuition before--",
    "start": "1123200",
    "end": "1130010"
  },
  {
    "text": "yeah. So all we're doing\nhere is we're just-- we're in a binary space\nwith the original SDM,",
    "start": "1130010",
    "end": "1136682"
  },
  {
    "text": "and we're just using this\nmapping to cosine similarity. And then, what you need to do is\njust have the beta coefficient",
    "start": "1136682",
    "end": "1144929"
  },
  {
    "text": "split. And you can view\nyour beta coefficient in attention as determining\nhow [INAUDIBLE] things are, and this relates\ndirectly to the Hamming",
    "start": "1144930",
    "end": "1151850"
  },
  {
    "text": "distance of your circles\nthat you're using for read and write on version. ",
    "start": "1151850",
    "end": "1158650"
  },
  {
    "text": "And so, yeah, it's\nlike mathematically to show this now, on this\nslide, I'm not using any tricks.",
    "start": "1158650",
    "end": "1163750"
  },
  {
    "text": "I'm just rewriting attention\nusing the SDM notation of patterns and queries.",
    "start": "1163750",
    "end": "1169160"
  },
  {
    "text": "So this little box down\nhere is doing that mapping. ",
    "start": "1169160",
    "end": "1177110"
  },
  {
    "text": "And this is the money slide\nwhere we're updating our query,",
    "start": "1177110",
    "end": "1182540"
  },
  {
    "text": "and on the left, we have\nour attention equation written in SDM notation.",
    "start": "1182540",
    "end": "1187820"
  },
  {
    "text": "We expand our softmax. And then, the main\nstatement is that this is closely approximated\nby if we swap out",
    "start": "1187820",
    "end": "1194960"
  },
  {
    "text": "our exponential with the SDM\ncircle intersection equation. ",
    "start": "1194960",
    "end": "1210179"
  },
  {
    "text": "So and again, the two things\nthat you need for this to work are one, your attention\nvectors, your keys and queries",
    "start": "1210180",
    "end": "1218120"
  },
  {
    "text": "need to be normalized,\nso I have hats on them. And then, you want--",
    "start": "1218120",
    "end": "1224270"
  },
  {
    "text": "if you decide to give a\nHamming distance for SDM, and I'll get into what\nHamming distances are good for different\nthings, then you",
    "start": "1224270",
    "end": "1231259"
  },
  {
    "text": "need to have a beta\ncoefficient that relates to it. But again, that's just\nhow many things are you",
    "start": "1231260",
    "end": "1237110"
  },
  {
    "text": "trying to pay attention to. ",
    "start": "1237110",
    "end": "1244309"
  },
  {
    "text": "So yeah, just as\na quick side note, you can write SDM using\ncontinuous vectors,",
    "start": "1244310",
    "end": "1249580"
  },
  {
    "text": "and then not need this\nmapping to cosine similarity. And so here, I have the\nplots again, but with this.",
    "start": "1249580",
    "end": "1256960"
  },
  {
    "text": "And I've added-- but the orange\nand the green are flipped,",
    "start": "1256960",
    "end": "1263080"
  },
  {
    "text": "so I've added the continuous\napproximation here, too. ",
    "start": "1263080",
    "end": "1269800"
  },
  {
    "text": "And what's nice about\nthe continuous version is you can actually then\nwrite sparse distributed memory as a multi-layer\nperceptron with slightly",
    "start": "1269800",
    "end": "1276760"
  },
  {
    "text": "different assumptions. And I'm not going to\ntalk about that now, but this is featured\nin Sparks III--",
    "start": "1276760",
    "end": "1283300"
  },
  {
    "text": "Memories of a Continual\nLearner, which was added to the\nadditional readings. And it'll be in-- sorry, this shouldn't say\nICML, this should say ICLEAR.",
    "start": "1283300",
    "end": "1291310"
  },
  {
    "text": "It's just been accepted\nto ICLEAR for this year. OK, so do train transformers\nuse these beta coefficients",
    "start": "1291310",
    "end": "1300940"
  },
  {
    "text": "that I've said are\nsimilar to those for SDM? And so, it shouldn't\nbe surprising",
    "start": "1300940",
    "end": "1307867"
  },
  {
    "text": "that depending on the\nHamming distance you've set, SDM is better for\ncertain things. For example, you\njust want to store",
    "start": "1307867",
    "end": "1314148"
  },
  {
    "text": "as many memories as\npossible, and you're assuming that your queries aren't noisy. Or you're assuming your\nqueries are really noisy,",
    "start": "1314148",
    "end": "1320865"
  },
  {
    "text": "so you can't store\nas much, but you can retrieve from a long distance. And if attention\nof the transformer",
    "start": "1320865",
    "end": "1327500"
  },
  {
    "text": "is implementing sparse\ndistributed memory, we should expect to see\nthat the beta coefficients that the transformer\nuses correspond",
    "start": "1327500",
    "end": "1334130"
  },
  {
    "text": "to these good instances of SDM. And so we have some weak\nevidence that that's the case.",
    "start": "1334130",
    "end": "1341580"
  },
  {
    "text": "So this is the key\nquery normalized variant of attention, where you actually\nlearn your beta coefficient.",
    "start": "1341580",
    "end": "1347419"
  },
  {
    "text": "Normally in\ntransformers, you don't. But you don't L2\nnorm your vectors, and so you can kind of have\nthis effective beta coefficient.",
    "start": "1347420",
    "end": "1354655"
  },
  {
    "text": "So in this case, it's just\na cleaner instance where we're actually learning beta. And this was trained on a number\nof different translation tasks.",
    "start": "1354655",
    "end": "1362870"
  },
  {
    "text": "We take the learned\nbeta coefficients across layers and across tasks\nand plot them as a histogram.",
    "start": "1362870",
    "end": "1368980"
  },
  {
    "text": "And the red-dotted\nlines correspond to three different notions of\nsparse distributed memory that",
    "start": "1368980",
    "end": "1374580"
  },
  {
    "text": "are optimal for\ndifferent things. And again, this is weak\nevidence, insomuch as",
    "start": "1374580",
    "end": "1380970"
  },
  {
    "text": "to derive the optimal\nSDM beta coefficients, or corresponding\nHamming distances.",
    "start": "1380970",
    "end": "1387000"
  },
  {
    "text": "We need to assume\nrandom patterns in this high dimensional space. And obviously, real\nworld data isn't random.",
    "start": "1387000",
    "end": "1394330"
  },
  {
    "text": "However, it is nice to see one,\nall of the beta coefficients fall within the bounds. And two, they skew towards\nthe max query noise, which",
    "start": "1394330",
    "end": "1404002"
  },
  {
    "text": "makes more sense\nif you're dealing with complicated real world\ndata where the next data points you see might be\nout of distribution,",
    "start": "1404003",
    "end": "1410070"
  },
  {
    "text": "based on what you've\nseen in the past. The maxmemory capacity variant\nassumes no query noise at all.",
    "start": "1410070",
    "end": "1415930"
  },
  {
    "text": "And so it's like, how\nmany things can I pack in, assuming that the questions\nI'm asking the system",
    "start": "1415930",
    "end": "1421080"
  },
  {
    "text": "are perfectly formed?  OK, just talking a little bit\nabout transformer components",
    "start": "1421080",
    "end": "1430330"
  },
  {
    "text": "more broadly. So I've mentioned that you can\nwrite the feedforward layer",
    "start": "1430330",
    "end": "1435940"
  },
  {
    "text": "as a version of SDM, that has\na sort of notion of longer term memory.",
    "start": "1435940",
    "end": "1443230"
  },
  {
    "text": "There's also LayerNorm, which\nis crucial in transformers. And it's not quite\nthe same, but it",
    "start": "1443230",
    "end": "1448270"
  },
  {
    "text": "can be related to the\nL2 normalization that's required by SDM. There's also the key query\nnormalization variant",
    "start": "1448270",
    "end": "1455080"
  },
  {
    "text": "that explicitly does\nthis L2 normalization. And it does get slightly\nbetter performance, at least on the small tests\nthat they did.",
    "start": "1455080",
    "end": "1461830"
  },
  {
    "text": "I don't know if this would\nscale to larger models. And so, I guess this work\nis interesting in so much as",
    "start": "1461830",
    "end": "1470045"
  },
  {
    "text": "like the biological\nplausibility, which I'm about to get to. And then, the links\nto transformers.",
    "start": "1470045",
    "end": "1475450"
  },
  {
    "text": "It hasn't, to date, improved\ntransformer architectures. But that doesn't mean that this\nlens couldn't be used or be",
    "start": "1475450",
    "end": "1481000"
  },
  {
    "text": "useful in some way. So yeah, I list a\nfew other things that SDM is related to that\ncould be used to funnel in.",
    "start": "1481000",
    "end": "1488740"
  },
  {
    "text": "And actually, in the new work\nwhere SDM is continual learner, we kind of expand the\ncerebellar circuit,",
    "start": "1488740",
    "end": "1494228"
  },
  {
    "text": "look at components of it,\nparticularly inhibitory interneurons. Implement those in a\ndeep learning model,",
    "start": "1494228",
    "end": "1499720"
  },
  {
    "text": "and it then becomes much\nbetter at continual learning. So that was kind of a fun way of\nactually using this link to get",
    "start": "1499720",
    "end": "1505780"
  },
  {
    "text": "better bottom line performance. OK, so a summary of this\nsection is basically",
    "start": "1505780",
    "end": "1513460"
  },
  {
    "text": "just the intersection\nbetween two hyperspheres approximates an exponential.",
    "start": "1513460",
    "end": "1519370"
  },
  {
    "text": "And this allows SDM's\nread and write operations to approximate\nattention, both in theory",
    "start": "1519370",
    "end": "1524470"
  },
  {
    "text": "and our limited tests. And so kind of like big\npicture research questions",
    "start": "1524470",
    "end": "1529899"
  },
  {
    "text": "that could come out of this is,\nfirst, is the transformer so successful because it's\nperforming some key cognitive",
    "start": "1529900",
    "end": "1535899"
  },
  {
    "text": "operation? The cerebellum is a\nvery old brain region used by most organisms,\nincluding fruit flies, maybe",
    "start": "1535900",
    "end": "1544269"
  },
  {
    "text": "even cephalopods, through like\ndivergent, but now convergent evolution.",
    "start": "1544270",
    "end": "1549529"
  },
  {
    "text": "And then, given that\nthe transformer has been so successful\nempirically, is SDM actually",
    "start": "1549530",
    "end": "1555770"
  },
  {
    "text": "the correct theory for\ncerebellar function? And that's still\nan open question.",
    "start": "1555770",
    "end": "1562392"
  },
  {
    "text": "As we learn more and more\nabout the cerebellum, there's nothing that yet\ndisproves SDM as working there.",
    "start": "1562392",
    "end": "1567650"
  },
  {
    "text": "And I think it's-- I'll go out on a\nlimb, and say it's like one of the more compelling\ntheories for how the cerebellum is actually working.",
    "start": "1567650",
    "end": "1573950"
  },
  {
    "text": "Yeah, and so I think this\nwork kind of motivates looking more of these questions--\nboth of these questions",
    "start": "1573950",
    "end": "1578960"
  },
  {
    "text": "more seriously.  Do we have time?",
    "start": "1578960",
    "end": "1584340"
  },
  {
    "text": "Cool. So here's the circuit\nthat implements SDM.",
    "start": "1584340",
    "end": "1590900"
  },
  {
    "text": "At the bottom, we have patterns\ncoming in for either reading or writing.",
    "start": "1590900",
    "end": "1596450"
  },
  {
    "text": "And they're going to actually\nbreak down into these slides. OK, yeah, so first, we\nhave patterns that come in.",
    "start": "1596450",
    "end": "1602630"
  },
  {
    "text": "And every neuron\nhere-- these are the dendrites of each neuron. And they're deciding\nwhether or not",
    "start": "1602630",
    "end": "1608240"
  },
  {
    "text": "they're going to fire for\nthe input that comes in. ",
    "start": "1608240",
    "end": "1614040"
  },
  {
    "text": "Then, if the neuron\ndoes fire, and you're writing in that pattern,\nthen you simultaneously--",
    "start": "1614040",
    "end": "1620788"
  },
  {
    "text": "and I'm going to\nexplain this to you, you're going to be\nlike this is crazy, the brain doesn't do this. And then, I'm going to\nhopefully show you it does.",
    "start": "1620788",
    "end": "1625873"
  },
  {
    "text": "You not only need to have\nthe thing the pattern that activates\nneurons, but you need",
    "start": "1625873",
    "end": "1631350"
  },
  {
    "text": "to have a separate line that\ntells the neuron what to store. And just like you have this\ndifference between keys",
    "start": "1631350",
    "end": "1637650"
  },
  {
    "text": "and values, where they can be\ndifferent vectors representing different things,\nhere, you can have a key that comes in and tells\nthe neuron when to activate.",
    "start": "1637650",
    "end": "1646050"
  },
  {
    "text": "And the value for what\nit should actually store, and [INAUDIBLE]. This is called hetero\nassociative mapping.",
    "start": "1646050",
    "end": "1653520"
  },
  {
    "text": "And then, once you're\nreading from the system, you also have your query come\nin here, activate neurons,",
    "start": "1653520",
    "end": "1661650"
  },
  {
    "text": "and those neurons then\noutput whatever they stored. And the neurons vector\nis this particular column",
    "start": "1661650",
    "end": "1669240"
  },
  {
    "text": "that it's stored. And it's, as a\nreminder, it's storing patterns in superposition.",
    "start": "1669240",
    "end": "1674940"
  },
  {
    "text": "And then, it will dump whatever\nit stored across these output lines.",
    "start": "1674940",
    "end": "1680399"
  },
  {
    "text": "And then, you have this\nG majority bit operation to convert to a 0 or 1, decide\nif the neuron is going to fire",
    "start": "1680400",
    "end": "1687900"
  },
  {
    "text": "or not. And so, here is\nthe same circuit,",
    "start": "1687900",
    "end": "1694190"
  },
  {
    "text": "but where I overlay cell\ntypes in the cerebellum.",
    "start": "1694190",
    "end": "1699840"
  },
  {
    "text": "And so I'll come\nback to this slide, because most people probably\naren't familiar with cerebellar",
    "start": "1699840",
    "end": "1705260"
  },
  {
    "text": "circuitry. Let me just-- it's in water.",
    "start": "1705260",
    "end": "1711680"
  },
  {
    "text": "OK, so the way\nthat the cerebellum is pretty homogeneous,\nin that it follows",
    "start": "1711680",
    "end": "1717350"
  },
  {
    "text": "this pattern throughout. Also fun fact, 70% of\nall neurons in the brain are in the cerebellum.",
    "start": "1717350",
    "end": "1723015"
  },
  {
    "text": "They're small, so\nyou wouldn't know it, but the cerebellum is\nvery underappreciated, and there's a bunch\nof evidence that it",
    "start": "1723015",
    "end": "1728275"
  },
  {
    "text": "has closed loop systems with\nmost higher order cognitive processing now. If your cerebellum\nis damaged, you",
    "start": "1728275",
    "end": "1733850"
  },
  {
    "text": "are more likely to have\nautism, et cetera, et cetera. So it does a lot more than\njust fine motor coordination. Which a lot of people\nhave assumed in the past.",
    "start": "1733850",
    "end": "1741440"
  },
  {
    "text": "OK, so inputs come in through\nthe muscle fibers here. They interface\nwith granule cells. This is a major up\nprojection, where you have",
    "start": "1741440",
    "end": "1748490"
  },
  {
    "text": "tons and tons of granule cells. Each granule cell has what are\ncalled parallel fibers, which",
    "start": "1748490",
    "end": "1753770"
  },
  {
    "text": "are incredibly long\nand thin axons that branch out in this T-structure.",
    "start": "1753770",
    "end": "1759440"
  },
  {
    "text": "And then, they're hit\nby the purkinje cells,",
    "start": "1759440",
    "end": "1764509"
  },
  {
    "text": "which will receive up to\n100,000 parallel fiber inputs.",
    "start": "1764510",
    "end": "1769590"
  },
  {
    "text": "It's the highest connectivity\nof any neuron in the brain. And then, the purkinje cell will\ndecide whether or not to fire,",
    "start": "1769590",
    "end": "1776880"
  },
  {
    "text": "and send its output\ndownwards here. So that's the whole system\nwhere patterns come in",
    "start": "1776880",
    "end": "1782498"
  },
  {
    "text": "and the neurons decide\nif they fire or not. And the way that they\nthen output their output. You then have a\nseparate right line,",
    "start": "1782498",
    "end": "1789150"
  },
  {
    "text": "which is the climbing biopsy. So the climbing fibers\ncome up, and they're pretty amazing in that\nthese connections here, you",
    "start": "1789150",
    "end": "1794840"
  },
  {
    "text": "kind of know are\nnot as important. The one that really matters is\nthat they're not very strong, either. Or what really\nmatters is it goes up",
    "start": "1794840",
    "end": "1800510"
  },
  {
    "text": "and it wraps around\nindividual purkinje cells. And the mapping is\nclose to one to one,",
    "start": "1800510",
    "end": "1806240"
  },
  {
    "text": "between climbing fibers\nand purkinje cells. And leads to very strong\naction potentials.",
    "start": "1806240",
    "end": "1811610"
  },
  {
    "text": "They're connecting to us here? In these-- Yes, in the stuff\noff to the side?",
    "start": "1811610",
    "end": "1816710"
  },
  {
    "text": "Yeah, right, these two lines. They're [INAUDIBLE]. Oh, so they're separate neurons\ncoming from separate areas.",
    "start": "1816710",
    "end": "1823730"
  },
  {
    "text": "Purkinje cells go into\ndeep cerebellar nuclei, kind of in the core\nof the cerebellum. And that then feeds\ninto thalamus,",
    "start": "1823730",
    "end": "1831057"
  },
  {
    "text": "like back to high\norder brain regions, or like down the muscle\nmovement, et cetera.",
    "start": "1831057",
    "end": "1836113"
  },
  {
    "text": "A lot of people will think\nof the cerebellum as kind of like a fine-tuning lookup\ntable, where you've already",
    "start": "1836113",
    "end": "1841950"
  },
  {
    "text": "decided the muscle\nmovement you want to do, but the cerebellum will then\ndo a bunch of adjustments.",
    "start": "1841950",
    "end": "1847059"
  },
  {
    "text": "So that it's much more accurate. But it seems like\nthis also applies to next word prediction.",
    "start": "1847060",
    "end": "1853049"
  },
  {
    "text": "Like we have fMRI data for this. A neuroscientist once said to\nme that a dirty little secret of fMRI is that the cerebellum\nlights up for everything.",
    "start": "1853050",
    "end": "1861810"
  },
  {
    "text": "So OK, going back to\nthis circuit here, then.",
    "start": "1861810",
    "end": "1868710"
  },
  {
    "text": "Yeah-- Timescales, are these\noperating again? I mean, how long\nis the information stored and retrieved?",
    "start": "1868710",
    "end": "1875390"
  },
  {
    "text": "Do we have any idea about this? Like it's just like a\ncouple of milliseconds,",
    "start": "1875390",
    "end": "1880940"
  },
  {
    "text": "or is this information\nmore persistent? So the main theory\nis that you have",
    "start": "1880940",
    "end": "1887390"
  },
  {
    "text": "updating through time-dependent\nplasticity, where your climbing",
    "start": "1887390",
    "end": "1894050"
  },
  {
    "text": "fiber will either-- which is\ndoing what you want right then, will fire either just before or\njust after your granule cells",
    "start": "1894050",
    "end": "1901880"
  },
  {
    "text": "fire. And so that, then,\nupdates the purkinje cell synapses for long term\ndepression or potentiation.",
    "start": "1901880",
    "end": "1909200"
  },
  {
    "text": "So whatever timescale\nthat's happening on. The climbing fiber makes very\nlarge vector potentials--",
    "start": "1909200",
    "end": "1914690"
  },
  {
    "text": "or it leads to very large vector\npotentials within the cell. And so I do think you could get\npretty fast synaptic updates.",
    "start": "1914690",
    "end": "1921020"
  },
  {
    "text": "And they're also\npersistent for a long time? I think so, yeah. The synapses are steady for\nlike the rest of your life?",
    "start": "1921020",
    "end": "1927660"
  },
  {
    "text": "Yeah, yeah. So what's really unique\nabout this circuit",
    "start": "1927660",
    "end": "1933120"
  },
  {
    "text": "is the fact that you have these\ntwo orthogonal inputs, where you have the mossy fibers\nbringing information.",
    "start": "1933120",
    "end": "1940020"
  },
  {
    "text": "And then it's decided if the\nneurons are going to fire or not. But then the totally\nseparate fiber lines that can update\nspecific neurons,",
    "start": "1940020",
    "end": "1947700"
  },
  {
    "text": "and what they're storing\nand will later output. And then, the purkinje\ncell is so important,",
    "start": "1947700",
    "end": "1952920"
  },
  {
    "text": "it's kind of doing this pooling\nacross every single neuron. And each neuron, remember,\nit's storing a vector this way.",
    "start": "1952920",
    "end": "1960010"
  },
  {
    "text": "And so the purkinje cell is\ndoing element wise, summation, and then deciding\nwhether it fires or not.",
    "start": "1960010",
    "end": "1966640"
  },
  {
    "text": "And this allows for you to store\nyour vectors in superposition, and then later denoise them. ",
    "start": "1966640",
    "end": "1976437"
  },
  {
    "text": "The theory [INAUDIBLE]\nmaps quite well to the Marr and Albus theories\nof cerebellar function, which",
    "start": "1976437",
    "end": "1981530"
  },
  {
    "text": "are still quite dominant,\nif anyone's familiar and wants to dive\ndeep into those. Yeah? So the analogy of the neuron\nin SDM you introduced before,",
    "start": "1981530",
    "end": "1989179"
  },
  {
    "text": "was that basically each\nneuron in purkinje cell? In this setting? Each neuron is a granule cell. ",
    "start": "1989180",
    "end": "1996170"
  },
  {
    "text": "And then, yeah, so the\nlocation of the neuron, those hollow circles,\ncorresponds to the granule cell",
    "start": "1996170",
    "end": "2002230"
  },
  {
    "text": "dendrites here, where\nthe patterns that pop in correspond to the activations\nof the muscle fibers.",
    "start": "2002230",
    "end": "2007510"
  },
  {
    "text": "And then, the afferent\npostsynaptic connections",
    "start": "2007510",
    "end": "2013000"
  },
  {
    "text": "are with the purkinje cell. So that's actually\nwhat it's storing is in the synaptic\nconnections with the--",
    "start": "2013000",
    "end": "2020140"
  },
  {
    "text": "and purkinje cells\nat that interface. And then, the purkinje\ncell does the majority",
    "start": "2020140",
    "end": "2025550"
  },
  {
    "text": "of the operation in deciding\nif it wants to fire or not. ",
    "start": "2025550",
    "end": "2037080"
  },
  {
    "text": "Got about five minutes. Can we ask you questions? Yeah, yeah, I think we're\nbasically into question time. So yeah, thanks a lot.",
    "start": "2037080",
    "end": "2043500"
  },
  {
    "start": "2043500",
    "end": "2050989"
  },
  {
    "text": "So I have a question. I don't know anything\nabout SDM, but it",
    "start": "2050989",
    "end": "2056270"
  },
  {
    "text": "seems, as understood, it's\nvery good for long-term memory. And I have a question--\nwhat's your hypothesis of what",
    "start": "2056270",
    "end": "2065638"
  },
  {
    "text": "we should be doing\nfor short-term memory. Because it seems that--",
    "start": "2065639",
    "end": "2071540"
  },
  {
    "text": "so if you have this\nlink of transformers having long-term memory, what's\ngood for short-term memory?",
    "start": "2071540",
    "end": "2078309"
  },
  {
    "text": "Because for me, it\nseems like we are doing this in the prompt\ncontext right now.",
    "start": "2078310",
    "end": "2083320"
  },
  {
    "text": "But how could we incorporate\nthese two together? Yeah, so this work\nactually focuses more",
    "start": "2083320",
    "end": "2090070"
  },
  {
    "text": "on the short-term memory. Where it relates to the\nattention operation. But you can rewrite SDM.",
    "start": "2090070",
    "end": "2097030"
  },
  {
    "text": "It's almost more natural to\ninterpret it as a multi-layer perceptron, that does like a\nsoftmax activation across--",
    "start": "2097030",
    "end": "2103270"
  },
  {
    "text": "or a top-K activation\nacross its neurons. It's like a little bit\nmore complicated than that. But yeah, so the--",
    "start": "2103270",
    "end": "2112078"
  },
  {
    "text": "yeah, the most\ninteresting thing here is the fact that I just\nhave a bunch of neurons, and inactivating nearby neurons\nin this high dimensional space,",
    "start": "2112078",
    "end": "2120100"
  },
  {
    "text": "you get this\nexponential weighting, which is the softmax. And then, because it's an\nassociative memory where",
    "start": "2120100",
    "end": "2125470"
  },
  {
    "text": "you have keys and\nvalues, it is attention. And yeah, I guess like\nthe thing I most want",
    "start": "2125470",
    "end": "2132920"
  },
  {
    "text": "to drive home from this is\nlike it's actually surprisingly easy for the brain to implement\nthe attention operation,",
    "start": "2132920",
    "end": "2138829"
  },
  {
    "text": "the attention equation. Just using\nhigh-dimensional vectors,",
    "start": "2138830",
    "end": "2143900"
  },
  {
    "text": "and activating your mappings. So it's good for short term?",
    "start": "2143900",
    "end": "2148940"
  },
  {
    "text": "Yes, if you were actually\nused SDM for attention,",
    "start": "2148940",
    "end": "2154280"
  },
  {
    "text": "yeah-- so let me go all\nthe way back real quick. This is important. There are two ways of\nSDM, and I don't think",
    "start": "2154280",
    "end": "2160340"
  },
  {
    "text": "you were here for the talk. I think I saw you come in a bit\nlater, which is totally fine.  I was listening, but\ndidn't get this part.",
    "start": "2160340",
    "end": "2166155"
  },
  {
    "text": "Oh, cool, cool, cool. Yeah, OK, so there are two\nways of looking at SDM.",
    "start": "2166155",
    "end": "2171230"
  },
  {
    "text": "There's the neuron perspective,\nwhich is this one here. And this is actually\nwhat's going",
    "start": "2171230",
    "end": "2177050"
  },
  {
    "text": "on in the brain, of course. And so the only thing\nthat is actually constant is the neurons, the\npatterns are ephemeral.",
    "start": "2177050",
    "end": "2184280"
  },
  {
    "text": "And then, there's the\npattern-based perspective, which is actually what\nattention is doing.",
    "start": "2184280",
    "end": "2189539"
  },
  {
    "text": "And so here, you're\nabstracting away the neurons, or assuming they're\noperating under the hood. But what you're\nactually computing",
    "start": "2189540",
    "end": "2195560"
  },
  {
    "text": "is the distance between\nthe true location of your pattern [INAUDIBLE].",
    "start": "2195560",
    "end": "2200660"
  },
  {
    "text": "And there are pros and\ncons to both of these. The pro to this is you get much\nhigher fidelity distances--",
    "start": "2200660",
    "end": "2208820"
  },
  {
    "text": "like you know exactly\nhow far the query is from the original patterns. And that's really\nimportant when you're",
    "start": "2208820",
    "end": "2214430"
  },
  {
    "text": "deciding what to update for. It's like you really want\nto know what is closest and what is further away,\nand be able to apply",
    "start": "2214430",
    "end": "2220940"
  },
  {
    "text": "the exponential\nweighting correctly. The problem is, you need to\nstore all of your pattern locations in memory.",
    "start": "2220940",
    "end": "2227160"
  },
  {
    "text": "And so this is why transformers\nhave limited context windows. The other perspective is this\nlong-term memory one, where",
    "start": "2227160",
    "end": "2234170"
  },
  {
    "text": "you forget about the patterns. And you just look\nat where you just have your neurons that store\na bunch of patterns in them,",
    "start": "2234170",
    "end": "2240920"
  },
  {
    "text": "in this noisy superposition. And so you can't really-- you can triangulate the\noriginal pattern, but not quite.",
    "start": "2240920",
    "end": "2247670"
  },
  {
    "text": "And it's all much noisier. But you can store\ntons of patterns and you're not constrained\nby a context window.",
    "start": "2247670",
    "end": "2253760"
  },
  {
    "text": "You can think of any\nMLP layer as storing like the entire data set in a\nnoisy superposition of states.",
    "start": "2253760",
    "end": "2261830"
  },
  {
    "text": "Yeah, hopefully that kind\nof answers your question. I think there's one here first. Yeah?",
    "start": "2261830",
    "end": "2268670"
  },
  {
    "text": "So I guess my question is like-- so I guess like you\nkind of have shown",
    "start": "2268670",
    "end": "2275270"
  },
  {
    "text": "that like modern\nself-attention mechanism maps onto this SDM mechanism, that\nlike seems possible in some",
    "start": "2275270",
    "end": "2286310"
  },
  {
    "text": "of the modern contemporary\ntheories of common brain coule",
    "start": "2286310",
    "end": "2291470"
  },
  {
    "text": "implement SDM. And I guess my question\nis, to what degree has that",
    "start": "2291470",
    "end": "2297770"
  },
  {
    "text": "been experimentally verified? Versus you were mentioning\nearlier that it might actually",
    "start": "2297770",
    "end": "2303830"
  },
  {
    "text": "be easier to have\ndone this using an MLP layer, in some sense,\nthan like [INAUDIBLE]..",
    "start": "2303830",
    "end": "2311510"
  },
  {
    "text": "And so how do\nexperimentalists actually distinguish between\ncompeting hypotheses?",
    "start": "2311510",
    "end": "2317600"
  },
  {
    "text": "Like for instance,\none thing that I wasn't entirely clear\nabout is even if the brain",
    "start": "2317600",
    "end": "2325380"
  },
  {
    "text": "could do attention, or SDM, that\ndoesn't actually mean it would, because maybe it\ncan't do [INAUDIBLE]..",
    "start": "2325380",
    "end": "2333809"
  },
  {
    "text": "So like how do you-- how does this get\nactually tested? Totally, yeah. So on the backprop\npoint, you wouldn't",
    "start": "2333810",
    "end": "2343589"
  },
  {
    "text": "have to do it here because you\nhave the climbing fibers that can directly give\ntraining signals to what",
    "start": "2343590",
    "end": "2350430"
  },
  {
    "text": "the neuron should store. So in this case, it's like a\nsupervised learning task where",
    "start": "2350430",
    "end": "2356190"
  },
  {
    "text": "the climbing fiber knows\nwhat it wants to write in, or how it should be updated,\nthe purkinje cell synapses.",
    "start": "2356190",
    "end": "2362370"
  },
  {
    "text": "But for your broader point, you\nbasically need to test this,",
    "start": "2362370",
    "end": "2368010"
  },
  {
    "text": "you need to be able to\ndo real time learning. The Drosophila mushroom\nbody is basically",
    "start": "2368010",
    "end": "2373410"
  },
  {
    "text": "identical to the cerebellum, and\nthe fly and the brain data set has done most of the\nindividual neuron connectivity.",
    "start": "2373410",
    "end": "2379829"
  },
  {
    "text": "But what you would\nreally want to do is like in vitro,\nreal time, super--",
    "start": "2379830",
    "end": "2386210"
  },
  {
    "text": "super, super high frames\nper second calcium imaging.",
    "start": "2386210",
    "end": "2392270"
  },
  {
    "text": "And be able to see how\nsynapses change over time. And so for an associative\nlearning task,",
    "start": "2392270",
    "end": "2399950"
  },
  {
    "text": "hear a sound move left, hear\nanother sound move right, or smells, or whatever.",
    "start": "2399950",
    "end": "2405079"
  },
  {
    "text": "Present one of those, trace-- figure out the small\nsubset of neurons",
    "start": "2405080",
    "end": "2410210"
  },
  {
    "text": "that fire, which we\nknow is a small subset. So that already fits\nwith the interpretation.",
    "start": "2410210",
    "end": "2415309"
  },
  {
    "text": "See how the synapses\nhere update, and how the outputs\nof that correspond",
    "start": "2415310",
    "end": "2420589"
  },
  {
    "text": "to changes in motor action. And then, extinguish\nthat memory.",
    "start": "2420590",
    "end": "2425880"
  },
  {
    "text": "So write in a new one, and\nthen watch it go away again. And our cameras are\ngetting fast enough,",
    "start": "2425880",
    "end": "2433549"
  },
  {
    "text": "and our calcium and\nvoltage indicators are getting to be really good. So hopefully in the\nnext three to five years",
    "start": "2433550",
    "end": "2439220"
  },
  {
    "text": "we can do some of those tasks. But I think that would\nbe very definitive. Yeah.",
    "start": "2439220",
    "end": "2444536"
  },
  {
    "text": " Yeah, do we have\nany other questions? I think there one more,\nand then I should--",
    "start": "2444536",
    "end": "2451322"
  },
  {
    "text": " How you map the neuron in SDM,\nlike this final hypothetical",
    "start": "2451322",
    "end": "2459220"
  },
  {
    "text": "biological\nimplementation, what is",
    "start": "2459220",
    "end": "2465130"
  },
  {
    "text": "the range of your circle\nthat you're mapping around? Is that like the [INAUDIBLE]?",
    "start": "2465130",
    "end": "2473750"
  },
  {
    "text": "I was trying to understand\nhow that [INAUDIBLE].. Yeah, so I wouldn't get\nconfused with multi-headedness,",
    "start": "2473750",
    "end": "2481720"
  },
  {
    "text": "because that's different\nattention heads all doing their own attention operation. It's funny, though, the\ncerebellum has microzones,",
    "start": "2481720",
    "end": "2488920"
  },
  {
    "text": "which you can think of as\nlike separate attention heads in a way. I don't want to take\nthat analogy too far,",
    "start": "2488920",
    "end": "2494890"
  },
  {
    "text": "but it is somewhat interesting. So the way you relate\nthis is in attention,",
    "start": "2494890",
    "end": "2502329"
  },
  {
    "text": "you have your beta coefficient. That is an effective\nbeta coefficient",
    "start": "2502330",
    "end": "2507500"
  },
  {
    "text": "because the vector norms\nof your keys and queries aren't constrained.",
    "start": "2507500",
    "end": "2513259"
  },
  {
    "text": "That corresponds to\na Hamming distance. And here, that corresponds\nto the number of neurons that",
    "start": "2513260",
    "end": "2520130"
  },
  {
    "text": "are on for any given input. And the Hamming\ndistance you want,",
    "start": "2520130",
    "end": "2526970"
  },
  {
    "text": "I had that the slide before,\nthe Hamming distance you want depends upon what you're\nactually trying to do.",
    "start": "2526970",
    "end": "2532562"
  },
  {
    "text": "And if you're not trying to\nstore that many memories, for example, you can have\na higher Hamming distance, because you can get\na higher fidelity",
    "start": "2532562",
    "end": "2539090"
  },
  {
    "text": "calculation for the\nnumber of neurons in that noisy intersection. Yeah.",
    "start": "2539090",
    "end": "2546430"
  },
  {
    "text": "Cool, yeah, thanks a lot. [INAUDIBLE] ",
    "start": "2546430",
    "end": "2552850"
  },
  {
    "text": "So as a disclaimer,\nso as a disclaimer",
    "start": "2552850",
    "end": "2558200"
  },
  {
    "text": "before I introduce\nour next speaker, the person who was\nscheduled unfortunately had to cancel last\nminute due to faculty. Interviews so our next\nspeaker has very graciously",
    "start": "2558200",
    "end": "2564800"
  },
  {
    "text": "agreed to present\nat very last minute, but we are very grateful to him. So I'd like to introduce\neverybody to Will.",
    "start": "2564800",
    "end": "2570230"
  },
  {
    "text": "So Will is a computational\nneuroscience machine learning PhD student at\nthe University College London at their Gatsby unit.",
    "start": "2570230",
    "end": "2576317"
  },
  {
    "text": "So I don't know if anybody\nhas heard about the Gatsby a-- I'm a bit of a history\nbuff, or a history nerd, depending on\nhow you phrase it.",
    "start": "2576317",
    "end": "2581960"
  },
  {
    "text": "The Gatsby unit was actually\nthis incredible powerhouse in the 1990s and 2000s. So Hinton used to be there,\nZoubin Ghahramani used",
    "start": "2581960",
    "end": "2587890"
  },
  {
    "text": "to be there. He's now in charge\nof Google research. I think they've done a\ntremendous amount of good work.",
    "start": "2587890",
    "end": "2592970"
  },
  {
    "text": "Anyways, and now,\nI'd like to invite Will to talk about how\nto build a cognitive map. Did you want to\nshare your screen?",
    "start": "2592970",
    "end": "2598860"
  },
  {
    "text": "Yeah. OK, can you stand\nin front of here? Let me stop sharing. OK, so I'm going to be\npresenting this work.",
    "start": "2598860",
    "end": "2607590"
  },
  {
    "text": "It's all about how a model\nthat people in the group that I work with, to study the\nhippocampal entorhinal system,",
    "start": "2607590",
    "end": "2615450"
  },
  {
    "text": "completely\nindependently turned out to look a bit like\na transformer. So that's this paper\nthat I'm going to talk",
    "start": "2615450",
    "end": "2620940"
  },
  {
    "text": "about is describing that link. And so the paper\nthat builds this link is by these three people.",
    "start": "2620940",
    "end": "2626160"
  },
  {
    "text": "James is a postdoc\nhalf at Stanford. Tim is a professor at\nOxford and in London. And Joe's a PhD\nstudent in London.",
    "start": "2626160",
    "end": "2632130"
  },
  {
    "text": "So three of them. So this is the problem\nthat this model",
    "start": "2632130",
    "end": "2640198"
  },
  {
    "text": "of the hippocampal\nentorhinal system, which we'll talk more\nabout, is supposed to solve. It's basically the\nobservation there's a lot of structure in the\nworld, and generally, we",
    "start": "2640198",
    "end": "2647370"
  },
  {
    "text": "should use it in order\nto generalize quickly between tasks. So the kind of thing\nI mean by that is you know 2D space works, because\nof your long experience",
    "start": "2647370",
    "end": "2654900"
  },
  {
    "text": "living in the world. And so if you start at this\ngreenhouse, and step north, this orange one, then to this\nred one, then this pink one,",
    "start": "2654900",
    "end": "2660960"
  },
  {
    "text": "because of the\nstructure of 2D space, you can think to\nyourself, oh, what will happen if I step left?",
    "start": "2660960",
    "end": "2666330"
  },
  {
    "text": "And you know that you'll end\nup back at the green one, because loops of this\ntype close in 2D space.",
    "start": "2666330",
    "end": "2671550"
  },
  {
    "text": "And this is-- perhaps patterns\nis a new city you've just arrived in. This is like a zero\nshot generalization,",
    "start": "2671550",
    "end": "2677610"
  },
  {
    "text": "because you somehow realized\nthat the structure applies more broadly and use\nit in a new context.",
    "start": "2677610",
    "end": "2683810"
  },
  {
    "text": "Yeah, and there's\ngenerally a lot of these kinds of situations\nwhere there structures reappear in the world. So there can be\nlots of instances",
    "start": "2683810",
    "end": "2689815"
  },
  {
    "text": "where the same structure will be\nuseful to doing these zero shot generalizations to predict\nwhat you're going to see next.",
    "start": "2689815",
    "end": "2696830"
  },
  {
    "text": "And so, you might be able\nto see how we're already going to start mapping this\nonto some kind of sequence prediction task that feels a\nbit transformer-esque, which",
    "start": "2696830",
    "end": "2704329"
  },
  {
    "text": "is, you receive this\nsequence of observations, and in this case, actions,\nmovements in space.",
    "start": "2704330",
    "end": "2710720"
  },
  {
    "text": "And your job is, given a\nnew action, step left here, you have to try and predict\nwhat you're going to see.",
    "start": "2710720",
    "end": "2715890"
  },
  {
    "text": "So that's the kind of sequence\nprediction version of it. And the way we're going\nto try and solve this",
    "start": "2715890",
    "end": "2721410"
  },
  {
    "text": "is based on factorization. It's like, you can't\ngo into one environment and just learn from the\nexperiences in that one",
    "start": "2721410",
    "end": "2726468"
  },
  {
    "text": "environment, you\nhave to separate out the structure and\nthe experiences you're having, so that you\ncan reuse the structural part,",
    "start": "2726468",
    "end": "2731765"
  },
  {
    "text": "which appears very\noften in the world. And so separating\nmemories from structure.",
    "start": "2731765",
    "end": "2737079"
  },
  {
    "text": "And so, you know, here's\nour separation of the two. We have our dude wandering\naround this like 2D grid world.",
    "start": "2737080",
    "end": "2744640"
  },
  {
    "text": "And you want to separate out\nthe fact that there's 2D space, and it's 2D space that has\nthese rules underlying it.",
    "start": "2744640",
    "end": "2750973"
  },
  {
    "text": "And in a particular instance, in\nthe environment that you're in, you need to be able to recall\nwhich objects are at which",
    "start": "2750973",
    "end": "2756220"
  },
  {
    "text": "locations in the environment. So in this case, it's\nlike oh, this position has an orange house,\nthis position--",
    "start": "2756220",
    "end": "2761740"
  },
  {
    "text": "that's green, sorry,\norange, red, and pink. And so you have\nto bind those two, you have to be like, whenever\nyou realize that you're back",
    "start": "2761740",
    "end": "2767140"
  },
  {
    "text": "in this position, recall that\nis the observation you're going to see there. And so this model that\nwe're going to build",
    "start": "2767140",
    "end": "2774760"
  },
  {
    "text": "is some model that\ntries to achieve this. New task-- and so\nwhen you enter it, imagine you enter\na new environment",
    "start": "2774760",
    "end": "2780670"
  },
  {
    "text": "with the same structure, you\nwander around and realize it's the same structure. All you have to do is\nbind the new things that you see to the locations,\nand then you're done.",
    "start": "2780670",
    "end": "2787390"
  },
  {
    "text": "Task done. You know how the world works. So this is what neuroscientists\nmean by a cognitive map,",
    "start": "2787390",
    "end": "2793730"
  },
  {
    "text": "is this idea of separating\nout and understanding the structure that you can\nreuse in new situations. And yeah, this model that\nwas built in the lab,",
    "start": "2793730",
    "end": "2802537"
  },
  {
    "text": "is a model of this\nprocess happening, of this separation\nbetween the two of them and how you use them\nto do new inferences. And this is the\nbit that's supposed",
    "start": "2802538",
    "end": "2809457"
  },
  {
    "text": "looked like a transformer. So that's a general\nintroduction, and then we'll dive into\nit a little more now. Makes sense, though,\nthe broad picture?",
    "start": "2809457",
    "end": "2816220"
  },
  {
    "text": "Good, silence I'll\nassume is good. So we'll start off\nwith some brain stuff.",
    "start": "2816220",
    "end": "2822910"
  },
  {
    "text": "So there's a long\nstream of evidence from spatial navigation\nthat the brain is doing something like this.",
    "start": "2822910",
    "end": "2828829"
  },
  {
    "text": "I mean, I think you can probably\nimagine how you, yourself, are doing this already when\nyou go to a new city,",
    "start": "2828830",
    "end": "2834352"
  },
  {
    "text": "or you're like\ntrying to understand a new task that has some\nstructure that you recognize from previously. You can see how\nthis is something",
    "start": "2834352",
    "end": "2839410"
  },
  {
    "text": "that you're probably doing. But spatial navigation is\nan area in neuroscience which had like a huge stream\nof discoveries over the last 50",
    "start": "2839410",
    "end": "2845349"
  },
  {
    "text": "years. And a lot of evidence\nof the neural basis of this computation. So we're going to talk through\nsome of those examples.",
    "start": "2845350",
    "end": "2851830"
  },
  {
    "text": "The earliest of these,\npsychologists like Tolman, who were showing that\nrats, in this case,",
    "start": "2851830",
    "end": "2857559"
  },
  {
    "text": "can do this kind of path\nintegration of structure. So the way this work is they\ngot put at a start position here, down at the bottom\nS, and they got trained",
    "start": "2857560",
    "end": "2864610"
  },
  {
    "text": "that this route up\nhere got your reward. So this is the maze\nthey had to run around. Then they were asked--",
    "start": "2864610",
    "end": "2870220"
  },
  {
    "text": "they were put in this new-- the same thing, but\nthey blocked off this path that takes\nthis long, winding route,",
    "start": "2870220",
    "end": "2875657"
  },
  {
    "text": "and given instead a selection\nof all these arms to go down. And they look at which\npath the rat goes down. And the finding is\nthat the rat goes down",
    "start": "2875657",
    "end": "2882500"
  },
  {
    "text": "the one that corresponds to\nheading off in this direction. So the rat has somehow\nnot just learned--",
    "start": "2882500",
    "end": "2887600"
  },
  {
    "text": "one option of this is like\nblind memorization of actions that I need to take in\norder to route around. Instead, no, it's\nlearning actually",
    "start": "2887600",
    "end": "2893780"
  },
  {
    "text": "that embedding the reward and\nits understanding of 2D space, and taking the direct route\nthere even though it's never taken it before.",
    "start": "2893780",
    "end": "2899510"
  },
  {
    "text": "So there's evidence that rats\nare doing this as well as us. And then, a series\nof neural discoveries",
    "start": "2899510",
    "end": "2904670"
  },
  {
    "text": "about the basis of this,\nso John O'Keefe stuck an electrode in the hippocampus,\nwhich is a brain area we'll",
    "start": "2904670",
    "end": "2911180"
  },
  {
    "text": "talk more about, and found\nthese things called place cells. So what I'm plotting\nhere is each of these columns\nis a single neuron,",
    "start": "2911180",
    "end": "2918500"
  },
  {
    "text": "and the mouse or rat,\nI can't remember, is running around a\nsquare environment. The black lines are the path the\nrodent traces out through time,",
    "start": "2918500",
    "end": "2927380"
  },
  {
    "text": "and you put a red dot\ndown every time you see this individual neuron spike. And then, the\nbottom plot of this is just a smooth\nversion of that spike.",
    "start": "2927380",
    "end": "2934340"
  },
  {
    "text": "So that firing rate. Which you can think of as\nlike the activity of a neuron and neural network. That's the analogy that\npeople usually draw.",
    "start": "2934340",
    "end": "2939920"
  },
  {
    "text": "And so these ones are\ncalled place cells, because they're\nneurons that respond in a particular\nposition in space. And in the '70s, this\nwas huge excitement.",
    "start": "2939920",
    "end": "2946097"
  },
  {
    "text": "People had been studying mainly\nlike sensory systems and motor output. And suddenly, a deep\ncognitive variable place, something you never--\nyou don't have a signaler,",
    "start": "2946097",
    "end": "2953300"
  },
  {
    "text": "but somehow there's\nthis signal for what looks like position in the brain\nin very understandable ways.",
    "start": "2953300",
    "end": "2959890"
  },
  {
    "text": "The next step in-- the biggest step, I guess,\nin this chain of discovery, is the Moser lab which\nis a group in Norway,",
    "start": "2959890",
    "end": "2966970"
  },
  {
    "text": "they stuck an electron in a\ndifferent area of the brain, the medial entorhinal cortex. And so this is the\nhippocampal entorhinal system",
    "start": "2966970",
    "end": "2972300"
  },
  {
    "text": "we're going to be talking about. And they found this\nneuron called a grid cell. So again, the same\nplot structure that I'm showing here,\nbut instead, these neurons",
    "start": "2972300",
    "end": "2978340"
  },
  {
    "text": "respond not in one\nposition in a room, but at a hexagonal lattice\nof positions in a room.",
    "start": "2978340",
    "end": "2984100"
  },
  {
    "text": "So these two, I guess I'm\nshowing to you, because they really motivate the underlying\nneural basis of this kind",
    "start": "2984100",
    "end": "2991510"
  },
  {
    "text": "of spatial cognition,\nembodying the structure of this space in some way. That's a very\nsurprising finding,",
    "start": "2991510",
    "end": "2997570"
  },
  {
    "text": "why are neurons choosing\nto represent things with this hexagonal lattice? It's like yeah, provoked\na lot of research since.",
    "start": "2997570",
    "end": "3003420"
  },
  {
    "text": "And broadly, there's been many\nmore discoveries in this area. So there's place cells\nI've talked to you",
    "start": "3003420",
    "end": "3008820"
  },
  {
    "text": "about, grid cells,\ncells that respond based on the location of not yourself\nbut another animal, cells that",
    "start": "3008820",
    "end": "3014190"
  },
  {
    "text": "respond when your head is facing\na particular direction, cells that respond to when you're\na particular distance away",
    "start": "3014190",
    "end": "3019600"
  },
  {
    "text": "from an object. So like I'm one step south of\nan object, that kind of cell.",
    "start": "3019600",
    "end": "3024819"
  },
  {
    "text": "Cells that respond\nto a reward position. Cells respond to\nvectors, to boundaries, cells respond to\n[INAUDIBLE],, so there's",
    "start": "3024820",
    "end": "3030100"
  },
  {
    "text": "like all sorts, all\nkinds of structure that this pair of\nbrain structures,",
    "start": "3030100",
    "end": "3035290"
  },
  {
    "text": "the hippocampus\nhere, this red area, and the entorhinal cortex\nthis blue area here, which",
    "start": "3035290",
    "end": "3040570"
  },
  {
    "text": "is conserved across-- a lot\nof species are represented. There's also finally one\nfinding in this that's fun,",
    "start": "3040570",
    "end": "3047160"
  },
  {
    "text": "is they did an fMRI experiment\non London taxi cab drivers. And I don't know\nif you know this,",
    "start": "3047160",
    "end": "3053220"
  },
  {
    "text": "but the London\ntaxicab drivers, they do a thing called\nthe knowledge, which is a two-year long test\nwhere they have to learn",
    "start": "3053220",
    "end": "3058830"
  },
  {
    "text": "every street in London. And the idea is, the\ntests go something like, oh, there's a traffic jam\nhere, and a roadwork here,",
    "start": "3058830",
    "end": "3064980"
  },
  {
    "text": "and I need to get from like\nCamden Town down to Wandsworth in the quickest way possible. What route would you go?",
    "start": "3064980",
    "end": "3070660"
  },
  {
    "text": "And they have to\ntell you which route they're going be able to\ntake through all the roads, and how they would\nre-plan if they found a stop-- those kind of things.",
    "start": "3070660",
    "end": "3076030"
  },
  {
    "text": "So it's like\nintense, you see them like driving around sometimes\nlearning all of these routes with little maps.",
    "start": "3076030",
    "end": "3081090"
  },
  {
    "text": "They're being made a little\nbit obsolete by Google Maps, but you know, luckily\nthey got them before--",
    "start": "3081090",
    "end": "3086190"
  },
  {
    "text": "this experiment was done\nbefore that was true. And so they've got\nhere is a measure of the size of your\nhippocampus using",
    "start": "3086190",
    "end": "3092010"
  },
  {
    "text": "fMRI, versus how long\nyou've been a taxi cab driver in months. And the claim is basically\nthe longer you're a taxi cab driver, the bigger\nyour hippocampus,",
    "start": "3092010",
    "end": "3097950"
  },
  {
    "text": "because the more\nyou're having to do this kind of spatial reasoning. So that's a big set of\nevidence that these brain areas",
    "start": "3097950",
    "end": "3104110"
  },
  {
    "text": "are doing something\nto do with space. But there's a lot of evidence\nthat there's something more than that, something non-spatial\ngoing on in these areas.",
    "start": "3104110",
    "end": "3111575"
  },
  {
    "text": "And we're going to\nbuild these together to make the broader claim about\nthis underlying structural",
    "start": "3111575",
    "end": "3116869"
  },
  {
    "text": "inference. And so I'm going to talk\nthrough a couple of those. The first one of these is\na guy called patient HM--",
    "start": "3116870",
    "end": "3123700"
  },
  {
    "text": "this is the most studied\npatient in medical history. He had epilepsy, and to\ncure intractable epilepsy,",
    "start": "3123700",
    "end": "3131898"
  },
  {
    "text": "you have to cut out\nthe brain region that's causing these seizure-like\nevents in your brain.",
    "start": "3131898",
    "end": "3136970"
  },
  {
    "text": "And in this case, the\nepilepsy was coming from the guy's hippocampus. So they bilaterally\nlesioned his hippocampus--",
    "start": "3136970",
    "end": "3142760"
  },
  {
    "text": "they cut out both\nof his hippocampi. And it turned out that this\nguy then had terrible amnesia.",
    "start": "3142760",
    "end": "3148059"
  },
  {
    "text": "He never formed\nanother memory again. And he could only recall\nmemories from a long time before the surgery happened.",
    "start": "3148060",
    "end": "3154390"
  },
  {
    "text": "But yeah, so experiments\nshowed a lot of this stuff about how we understand\nthe neural basis of memory.",
    "start": "3154390",
    "end": "3161220"
  },
  {
    "text": "Things like he could\nlearn to do motor tasks-- so somehow the motor tasks\nare being [INAUDIBLE].. For example, they gave him\nsome very difficult motor",
    "start": "3161220",
    "end": "3167420"
  },
  {
    "text": "coordination tasks that people\ncan't generally do, but can with a lot of practice, and\nhe got very good at this. Eventually, and was as\ngood as other people",
    "start": "3167420",
    "end": "3173840"
  },
  {
    "text": "at learning to do that, he had\nno recollection of ever doing the task. So he'd go into the\ndo this new task, and be like, I've\nnever seen this before.",
    "start": "3173840",
    "end": "3179310"
  },
  {
    "text": "I have no idea what\nyou're asking me to do. And you do it amazingly. And be like-- yeah. So there's some evidence\nthere that the hippocampus",
    "start": "3179310",
    "end": "3185185"
  },
  {
    "text": "is involved in at least\nsome parts of memory, which seems a bit separate to\nthis stuff about space that I've been\ntalking to you about.",
    "start": "3185185",
    "end": "3190910"
  },
  {
    "text": "The second of these\nis imagining things. So this is actually a\npaper by Demis Hassabis, who, before he was DeepMind\nhead, was a neuroscientist.",
    "start": "3190910",
    "end": "3199280"
  },
  {
    "text": "And here, maybe you\ncan't read that, I'll read some of these out. You're asked to imagine you're\nlying on a white sandy beach",
    "start": "3199280",
    "end": "3205910"
  },
  {
    "text": "in a beautiful tropical bay. And so the control, this\nbottom one says things like, it's very hot, and the\nsun is beating down on me,",
    "start": "3205910",
    "end": "3211042"
  },
  {
    "text": "the sand underneath me\nis almost unbearably hot. I can hear the sounds of small\nwavelets lapping on the beach. The sea is gorgeous,\naquamarine color.",
    "start": "3211042",
    "end": "3216920"
  },
  {
    "text": "You know, like so a\nnice, lucid description of this beachy scene. Whereas the person with a\nhippocampal damage says,",
    "start": "3216920",
    "end": "3224660"
  },
  {
    "text": "as for seeing, I can't really,\napart from just the sky. I can hear the sound of\nseagulls, and of the sea.",
    "start": "3224660",
    "end": "3230090"
  },
  {
    "text": "I could feel the grain of\nsand beneath my fingers. And then, like yeah,\nstruggles, basically.",
    "start": "3230090",
    "end": "3236000"
  },
  {
    "text": "Really struggles to do\nthis, imagine this scenario. Some of the things really\nare very surprising. So the last of these is this\ntransitive inference task.",
    "start": "3236000",
    "end": "3246059"
  },
  {
    "text": "So transitive\ninference-- A is greater than B, B is greater than C,\ntherefore, A is greater than C.",
    "start": "3246060",
    "end": "3251359"
  },
  {
    "text": "And the way they convert this\ninto a rodent experiment, is you get given two\npots of food that have different smells.",
    "start": "3251360",
    "end": "3257040"
  },
  {
    "text": "And your job is to go\nto the pot of food-- you learn which pot\nof food has-- sorry, which pot with the\nsmell has the food.",
    "start": "3257040",
    "end": "3263660"
  },
  {
    "text": "And so these are colored by\nthe two pots by their smell. And the rodent has to learn\nto go to a particular pot,",
    "start": "3263660",
    "end": "3270292"
  },
  {
    "text": "in this case, the one\nthat smells like A. And they do two of these. They do A has the food when\nit's presented in a pair with B,",
    "start": "3270292",
    "end": "3276289"
  },
  {
    "text": "and B has the food when it's\npresented in a pair with C. And then they test,\nwhat does a mouse do when presented with A and C\nin a completely new situation?",
    "start": "3276290",
    "end": "3283070"
  },
  {
    "text": "And if they have a\nhippocampus, they'll go for A over C. They'll\ndo transitive inference. If they don't have\none, they can't.",
    "start": "3283070",
    "end": "3289500"
  },
  {
    "text": "And so, there's a\nmuch more broad-- this is like oh, I've\nshown you how hippocampus is used for this spatial\nstuff, that people",
    "start": "3289500",
    "end": "3294620"
  },
  {
    "text": "have been excited about. But there's also all of this\nkind of relational stuff, imagining new situations, some\nslightly more complex story",
    "start": "3294620",
    "end": "3301430"
  },
  {
    "text": "here. The last of these\nI'm going to do is how the entorhinal\ncortex, as well. So that's where, if you remember\nhippocampus was these guys,",
    "start": "3301430",
    "end": "3308480"
  },
  {
    "text": "and cortex was these\ngrid cells, was how entorhinal cortex was\nappearing to do some broader stuff, as well.",
    "start": "3308480",
    "end": "3314078"
  },
  {
    "text": "This is all motivation\nfor the model. We're just trying to build\nall of these things together. So in this one, this is called\nthe stretchy birds' task.",
    "start": "3314078",
    "end": "3322339"
  },
  {
    "text": "So you put people\nin an fMRI machine, and you make them navigate,\nbut navigate in bird space.",
    "start": "3322340",
    "end": "3327920"
  },
  {
    "text": "And what bird\nspace means is it's a two-dimensional\nspace of images. And each image is\none of these birds.",
    "start": "3327920",
    "end": "3334700"
  },
  {
    "text": "And as you vary along\nthe x dimension, the birds legs get\nlonger and shorter. And as you vary along\nthe y direction,",
    "start": "3334700",
    "end": "3340160"
  },
  {
    "text": "the bird's neck gets\nlonger and shorter. And the patients sit there,\nor subjects sit there,",
    "start": "3340160",
    "end": "3346880"
  },
  {
    "text": "and just watch the\nbird images change, so that it traces out\nsome path in 2D space. But they never see the 2D space.",
    "start": "3346880",
    "end": "3352070"
  },
  {
    "text": "They just see the images. And the claim is\nbasically-- and then they're asked to do\nsome navigational tasks.",
    "start": "3352070",
    "end": "3357300"
  },
  {
    "text": "They're like, oh,\nwhenever you're in this place in\n2D space, you show Santa Claus next to the bird.",
    "start": "3357300",
    "end": "3363079"
  },
  {
    "text": "And so the participants have\nto pin that particular bird image, that particular place\nin 2D space to the Santa Claus.",
    "start": "3363080",
    "end": "3368720"
  },
  {
    "text": "And you're asked to go and\nfind the Santa Claus again, using some non-directional\ncontroller. And they navigate\ntheir way back.",
    "start": "3368720",
    "end": "3375170"
  },
  {
    "text": "And the claim is that these\npeople use grid cells. So the entorhinal\ncortex is active in how",
    "start": "3375170",
    "end": "3380450"
  },
  {
    "text": "these people are navigating this\nabstract cognitive bird space. And the way you test\nthat claim is you",
    "start": "3380450",
    "end": "3386390"
  },
  {
    "text": "look at the fMRI signal\nin the entorhinal cortex as the participants head at some\nparticular angle in bird space.",
    "start": "3386390",
    "end": "3394200"
  },
  {
    "text": "And because of the\nsix-fold symmetry of the hexagonal lattice, you\nget this six-fold symmetric waving up and down of the\nentorhinal cortex activity",
    "start": "3394200",
    "end": "3401770"
  },
  {
    "text": "as you head in particular\ndirections in 2D space. There's evidence\nthat this system is being used not just for\nnavigation in 2D space,",
    "start": "3401770",
    "end": "3408369"
  },
  {
    "text": "but any cognitive task with\nsome underlying structure that you can extract. You use it to do these tasks.",
    "start": "3408370",
    "end": "3415060"
  },
  {
    "text": "Is there significance to bird\nspace also being to here? Yes, yes. Like people try this\nwith multiple dimensions",
    "start": "3415060",
    "end": "3421600"
  },
  {
    "text": "variability? People haven't done\nthat experiment. But people have done things\nlike look at how grid cells--",
    "start": "3421600",
    "end": "3429280"
  },
  {
    "text": "have they even done that. They've done things\nlike 3D space, but not like cognitive 3D space.",
    "start": "3429280",
    "end": "3435340"
  },
  {
    "text": "They've done like literally like\nmake-- they've done it in bats, they stick electrodes in bats\nand make the bats fly around the room and look at how\nthe grid cells respond.",
    "start": "3435340",
    "end": "3441940"
  },
  {
    "text": "Yeah, but definitely, I\nthink they've done it-- ah, they've done it\nin sequence space.",
    "start": "3441940",
    "end": "3449589"
  },
  {
    "text": "So in this case,\nyou hear a sequence of sounds with\nhierarchical structure. So it's like how there's\nmonths, weeks, days,",
    "start": "3449590",
    "end": "3455440"
  },
  {
    "text": "and meals, something like that. So like weeks have a\nperiodic structure, months have a\nperiodic structure, days have a periodic\nstructure, and meals",
    "start": "3455440",
    "end": "3461630"
  },
  {
    "text": "have a periodic structure. And so you hear a\nsequence of sounds with exactly the same\nkind of structure as that hierarchy of sequences.",
    "start": "3461630",
    "end": "3467060"
  },
  {
    "text": "And you look at\nthe representation in the entorhinal\ncortex through fMRI. And you see exactly\nthe same thing-- that the structure is all\nrepresented like that.",
    "start": "3467060",
    "end": "3473090"
  },
  {
    "text": "Even more than\nthat, you actually see in the entorhinal cortex\na array of length scales. So at one end of the\nentorhinal cortex,",
    "start": "3473090",
    "end": "3479450"
  },
  {
    "text": "you've got very large\nlength scale grid cells that are like responding\nto large variations in space. The other end, you've\ngot very small ones,",
    "start": "3479450",
    "end": "3485180"
  },
  {
    "text": "and you see the same\nthing recapitulated there. The meals cycle, that\ncycles a lot more quicker, is represented in one end of\nthe entorhinal cortex and fMRI,",
    "start": "3485180",
    "end": "3492260"
  },
  {
    "text": "and the month cycle\nis at the other end, with a [INAUDIBLE]\nscale in between. So there's some\nevidence to that end.",
    "start": "3492260",
    "end": "3498950"
  },
  {
    "text": "All right, so I've\nbeen talking about MEC, the medial entorhinal cortex. Another brain area that\npeople don't look at it",
    "start": "3498950",
    "end": "3504568"
  },
  {
    "text": "as much is the LEC, the\nlaterl entorhinal cortex, that will then be\nimportant for this model. And basically, the\nonly that you should",
    "start": "3504568",
    "end": "3510255"
  },
  {
    "text": "be aware of before\nwe get to the model, is that it seems to represent\nvery high level the similarity structure in the lateral cortex.",
    "start": "3510255",
    "end": "3516650"
  },
  {
    "text": "Seems to be a very high\nlevel semantic one. For example, you\npresent some images, and you look at how the\nvisual cortex, things are more",
    "start": "3516650",
    "end": "3523430"
  },
  {
    "text": "similarly represented\nif they look similar. But by the time you get to\nthe lateral entorhinal cortex, things look more similar\nbased on their usage.",
    "start": "3523430",
    "end": "3529277"
  },
  {
    "text": "For example, like an\nironing board and an iron will be represented similarly. Even though they\nlook very different, because they are somehow\nlike semantically linked.",
    "start": "3529277",
    "end": "3536330"
  },
  {
    "text": "OK, so that's the\nrole that the LEC is going to play in this model. So yeah, basically,\nthe claim is this",
    "start": "3536330",
    "end": "3543170"
  },
  {
    "text": "is for more than just 2D space. So the neural implementation\nof this cognitive map, which is for not only 2D space,\nwhich this cartoon is supposed",
    "start": "3543170",
    "end": "3549683"
  },
  {
    "text": "to represent, but also\nthings any other structure. So some structures like\ntransitive inference, this one",
    "start": "3549683",
    "end": "3555542"
  },
  {
    "text": "is faster than that\nand faster than that. Or family trees, like this\nperson's my mother's brother,",
    "start": "3555542",
    "end": "3560810"
  },
  {
    "text": "and is therefore my uncle,\nthose kind of things. These broader\nstructural inferences that you want to be able\nto use in many situations,",
    "start": "3560810",
    "end": "3566835"
  },
  {
    "text": "so it's basically\nthe same problem. Great, that was a\nload of neuroscience. And now we're going to\nget on to the model that",
    "start": "3566835",
    "end": "3572550"
  },
  {
    "text": "tries to summarize\nall of these things. And that's going to be\nthe model that will end up looking like a transformer.",
    "start": "3572550",
    "end": "3577720"
  },
  {
    "text": "So yeah, we basically\nwant the separation. These diagrams here are\nsupposed to represent",
    "start": "3577720",
    "end": "3583545"
  },
  {
    "text": "a particular environment\nthat you're wandering around. It has an underlying\ngrid structure, and you see a set of\nstimuli at each point",
    "start": "3583545",
    "end": "3589090"
  },
  {
    "text": "on these grid, which are\nthese little cartoon things. And you want to try and create\na thing that separates out this like 2D structural grid\nfrom the actual experiences",
    "start": "3589090",
    "end": "3596130"
  },
  {
    "text": "you're seeing. And then mapping\nto the things I've been showing you is\nthat this grid like code is actually the grid cells, and\nthe medial entorhinal cortex,",
    "start": "3596130",
    "end": "3603210"
  },
  {
    "text": "are somehow abstracting\nthe structure. The lateral entorhinal cortex,\nencoding these semantically meaningful similarities, will be\nthe objects that you're seeing.",
    "start": "3603210",
    "end": "3610787"
  },
  {
    "text": "So it's just like this is\nwhat I'm seeing in the world. And the combination\nof the two of them will be the hippocampus.",
    "start": "3610788",
    "end": "3618930"
  },
  {
    "text": "So yeah, in more\ndiagrams we've got G, the structural code, the\ngrid code, and MEC, the LEC--",
    "start": "3618930",
    "end": "3624670"
  },
  {
    "text": "is someone asking a question? Since morning, so\nnow it's lunchtime. Yeah. ",
    "start": "3624670",
    "end": "3633130"
  },
  {
    "text": "Sorry, I can't hear you, if\nyou're asking a question. How do I mute\nsomeone if they're-- ",
    "start": "3633130",
    "end": "3643380"
  },
  {
    "text": "Maybe type it in the\nchat if there is one. ",
    "start": "3643380",
    "end": "3650450"
  },
  {
    "text": "Nice. So yeah, we got the\nhippocampus in the middle, which is going to be our binding\nof the two of them together.",
    "start": "3650450",
    "end": "3657202"
  },
  {
    "text": " So I'm going to step through\neach of these three parts on their own, and\nhow they do the job",
    "start": "3657202",
    "end": "3663692"
  },
  {
    "text": "that I've assigned to them. And then, come back together\nand show the full model. So lateral entorhinal cortex\nencodes what you're seeing.",
    "start": "3663692",
    "end": "3671850"
  },
  {
    "text": "So this is like these\nimages, or the houses we were looking at before. And that would just be some\nvector XT that's different.",
    "start": "3671850",
    "end": "3677792"
  },
  {
    "text": "So a random vector,\ndifferent for every signal. The medial entorhinal cortex\nis the one that tells you",
    "start": "3677792",
    "end": "3684210"
  },
  {
    "text": "where you are in space. And it has the job\nof path-integrating. So this means receiving\na sequence of actions",
    "start": "3684210",
    "end": "3690300"
  },
  {
    "text": "that you've taken in space,\nfor example, went north, east, and south, and telling you\nwhere in 2D space that you are. So somehow the bit that embeds\nthe structure of the world.",
    "start": "3690300",
    "end": "3698160"
  },
  {
    "text": "And the way that we'll\ndo that is this g of T, this vector of activities\nin this brain area, will be updated by a\nmatrix that depends",
    "start": "3698160",
    "end": "3706050"
  },
  {
    "text": "on the actions you've taken. OK, so if you step north,\nyou update the representation with the step north matrix.",
    "start": "3706050",
    "end": "3712087"
  },
  {
    "text": "And those matrices are going\nto have to obey some rules. For example, if you step\nnorth and step south, you haven't moved, and\nso the step north matrix,",
    "start": "3712087",
    "end": "3718440"
  },
  {
    "text": "the step south matrix, have\nto be inverses of one another. So that the activity\nstays the same and represents the structure\nof the world somehow.",
    "start": "3718440",
    "end": "3726600"
  },
  {
    "text": "OK, so that's the\nworld structure part. Finally, the memory,\nbecause we have",
    "start": "3726600",
    "end": "3732309"
  },
  {
    "text": "to memorize which things we\nfound at which positions, going to happen in\nthe hippocampus, and that's going to be through\na version of these things",
    "start": "3732310",
    "end": "3739083"
  },
  {
    "text": "called the Hopfield\nnetworks, that you heard mentioned in the last talk. So this is like a content\naddressable memory,",
    "start": "3739083",
    "end": "3744670"
  },
  {
    "text": "and it's biologically\nplausible, this claim. The way it works is you\nhave a set of activities, p,",
    "start": "3744670",
    "end": "3750069"
  },
  {
    "text": "which are the activities\nof all these neurons. And when it receives-- and it just like\nrecurrently updates itself.",
    "start": "3750070",
    "end": "3756680"
  },
  {
    "text": "So there's some weight\nmatrix in here, w-- and some non-linearity, and\nyou roll it forward in time. And it just settles into\nthis dynamical system.",
    "start": "3756680",
    "end": "3763000"
  },
  {
    "text": "It settles into some\nattractor state. And the way you\nmake it do memory is through the weight matrix.",
    "start": "3763000",
    "end": "3768940"
  },
  {
    "text": "So you make it like a sum of\nouter products of these pi mu, each chi is some\nmemory, some pattern",
    "start": "3768940",
    "end": "3774480"
  },
  {
    "text": "that you want to recall. And then, this is just\nwriting it in there. The update pattern is like that.",
    "start": "3774480",
    "end": "3780670"
  },
  {
    "text": "And the claim is basically\nthat if p, the memory-- the activity of the neurons,\nthe hippocampal neurons,",
    "start": "3780670",
    "end": "3787210"
  },
  {
    "text": "is close to some\nmemory, say chi mu, then this dot product\nwill be much larger",
    "start": "3787210",
    "end": "3792220"
  },
  {
    "text": "than all of the\nother dot products with all the other memories. So the sum over all\nof them will basically be dominated by this\none term, chi mu.",
    "start": "3792220",
    "end": "3800290"
  },
  {
    "text": "And so your\nattractor set network will basically settle\ninto that one chi mu. And maybe the preemption sum,\nthat kind of comes later,",
    "start": "3800290",
    "end": "3807440"
  },
  {
    "text": "you can see how this\nsimilarity between points is-- yeah, pairwise similarity. And then adding\nsome-- adding them up,",
    "start": "3807440",
    "end": "3813970"
  },
  {
    "text": "weighted by this\nsimilarity is the bit that's going to turn out\nlooking a bit like attention.",
    "start": "3813970",
    "end": "3820170"
  },
  {
    "text": "And so some of the cool things\nyou can do with these systems is like here's a set of\nimages that someone's encoded in a Hopfield network.",
    "start": "3820170",
    "end": "3826510"
  },
  {
    "text": "And then someone's presented\nthis image to the network, and asked it to just run to\nit's like dynamical attractor",
    "start": "3826510",
    "end": "3832540"
  },
  {
    "text": "minima, and it recreates\nall of the memory that it's got stored there. So like completes the\nrest of the image.",
    "start": "3832540",
    "end": "3839780"
  },
  {
    "text": "So that's our system. Yeah? I'm sorry if I'm [INAUDIBLE],,\nthat's like where the--",
    "start": "3839780",
    "end": "3848366"
  },
  {
    "text": "[INAUDIBLE] I've heard that\nthis interpretation is like the modern\ninterpretation of a Hopfield",
    "start": "3848366",
    "end": "3854720"
  },
  {
    "text": "network? This one is actually-- which interpretation, sorry? That like it's\neffectively [INAUDIBLE]..",
    "start": "3854720",
    "end": "3861160"
  },
  {
    "text": "Is that a [INAUDIBLE]? Yeah, it's only the\nlink to transformers",
    "start": "3861160",
    "end": "3866360"
  },
  {
    "text": "will basically only\nbe through the fact. There's classic\nHopfield networks, and then there's modern ones\nthat were invented like 2016.",
    "start": "3866360",
    "end": "3871880"
  },
  {
    "text": "And the link between\nattention and modern is precise the link with like\nclassic is not as precise.",
    "start": "3871880",
    "end": "3878180"
  },
  {
    "text": "Yeah, I mean-- yeah. That's why I was suspecting-- Yeah, yeah, yeah. The modern Hopfield network\nis the continuous version of",
    "start": "3878180",
    "end": "3885302"
  },
  {
    "text": "[INAUDIBLE]. With the change in the\nnon-linearity, yeah?",
    "start": "3885302",
    "end": "3893299"
  },
  {
    "text": "Because then you have to do\nthe exponentiation thing. When we get to this\nlater, you can tell me-- I'm sorry. I don't mean to rail off.",
    "start": "3893300",
    "end": "3898792"
  },
  {
    "text": "No, no, more questions are good. We'll get-- yeah. Maybe separate energy function.",
    "start": "3898792",
    "end": "3904809"
  },
  {
    "text": "And I think the exponential\nis in that, [INAUDIBLE]..",
    "start": "3904810",
    "end": "3910050"
  },
  {
    "text": "OK, thanks. No worries. So that's basically how our\nsystem is going to work.",
    "start": "3910050",
    "end": "3915280"
  },
  {
    "text": "But this\nTolman-Eichenbaum machine, that's what the name of\nthis thing is, and so you--",
    "start": "3915280",
    "end": "3920980"
  },
  {
    "text": "the patterns you want to\nstore in the hippocampus, so these memories that\nwe want to embed, are a combination of the\nposition and the input.",
    "start": "3920980",
    "end": "3927130"
  },
  {
    "text": "And like half of\nHomer's face here, if you then have\ndecided you're going to end up at a\nparticular position,",
    "start": "3927130",
    "end": "3932428"
  },
  {
    "text": "you can recall the stimulus\nthat you saw there, and predict that as your next observation. Or vice versa.",
    "start": "3932428",
    "end": "3938320"
  },
  {
    "text": "If you like see a new thing,\nyou can infer, oh, I [INAUDIBLE] wrong, I must actually be here.",
    "start": "3938320",
    "end": "3943630"
  },
  {
    "text": "Assuming there's usually\nmore than one thing in the world that might\nbe in different position. ",
    "start": "3943630",
    "end": "3950210"
  },
  {
    "text": "Yeah, that's the whole system. Does the whole\nTolman-Eichenbaum machine make sense, roughly,\nwhat it's doing?",
    "start": "3950210",
    "end": "3957220"
  },
  {
    "text": "OK, cool. And basically, this last bit\nis saying it's really good.",
    "start": "3957220",
    "end": "3962230"
  },
  {
    "text": "So what I'm showing here, this\nis on the 2D navigation task, and so it's a big grid.",
    "start": "3962230",
    "end": "3967440"
  },
  {
    "text": "I think they use like, I don't\nknow, 11 by 11, or something. And it's like wandering\naround, and have to predict what it's going to\nsee in some new environment.",
    "start": "3967440",
    "end": "3973407"
  },
  {
    "text": "And on here, this is the\nnumber of nodes in that graph that you've visited. And on the y-axis is how\nmuch you correctly predict.",
    "start": "3973407",
    "end": "3980590"
  },
  {
    "text": "And each of these\nlines is based on how many of those type\nof environments I've seen before, how\nquickly do I learn?",
    "start": "3980590",
    "end": "3986350"
  },
  {
    "text": "And the basic\nphenomenon it's showing is, over time, as you see more\nand more of these environments, you learn to learn.",
    "start": "3986350",
    "end": "3991900"
  },
  {
    "text": "So you learn the structure\nof the world, and eventually, able to quickly generalize\nto the new situation and predict what\nyou're going to see.",
    "start": "3991900",
    "end": "3997810"
  },
  {
    "text": "And this scales not\nwith the number of edges that you've visited, which would\nbe the learn-everything option.",
    "start": "3997810",
    "end": "4003498"
  },
  {
    "text": "You know, predict--\nbecause if you're trying to predict\nwhich state I'm going to see given my\ncurrent state and action, and in a dumb way,\nyou just need to see",
    "start": "4003498",
    "end": "4009725"
  },
  {
    "text": "all states and\naction, so all edges. But this thing is able to do it\nmuch more cleverly because it only needs to visit all\nnodes, and just memorize",
    "start": "4009725",
    "end": "4016070"
  },
  {
    "text": "what is at each position. And you can see\nthat its learning curve follows the number of\nnodes visited learning curve.",
    "start": "4016070",
    "end": "4021800"
  },
  {
    "text": "So it's doing well. For neuroscience, this\nis also exciting is that the neural patterns of\nresponse in these modal regions",
    "start": "4021800",
    "end": "4030400"
  },
  {
    "text": "match the ones\nobserved in the brain. So in the hippocampal\nsection, you get place cell-like\nactivities-- this hexagon",
    "start": "4030400",
    "end": "4038350"
  },
  {
    "text": "is the grid of the environment\nthat it's exploring. And plotted is the firing\nrate of that neuron. Whereas, the ones in the\nmedial entorhinal cortex",
    "start": "4038350",
    "end": "4045850"
  },
  {
    "text": "show this grid-like\nfiring pattern. Yeah? This exactly compare operates\non discrete spaces, essentially?",
    "start": "4045850",
    "end": "4055040"
  },
  {
    "text": "Do you have any thoughts\nabout how that transfers into real world things? We think that we'll just like\nmap representations into a very",
    "start": "4055040",
    "end": "4062390"
  },
  {
    "text": "nicely discretizable space? Or do you think [INAUDIBLE]\nmore complicated going on? Yeah, I imagine there's\nsomething more complicated",
    "start": "4062390",
    "end": "4068750"
  },
  {
    "text": "going on. I guess this--  And so it's like a super high--",
    "start": "4068750",
    "end": "4074270"
  },
  {
    "text": "No, no, no, yeah,\nmaybe you can make-- maybe you can make arguments\nthat they, as I was saying, there's these\ndifferent modules that",
    "start": "4074270",
    "end": "4080059"
  },
  {
    "text": "operate at different scales. You can see this already here,\nlike grid cells at one scale, grid cells at another scale. And so you could imagine how\nthat could be useful for-- one",
    "start": "4080060",
    "end": "4088553"
  },
  {
    "text": "of them operates at the\nhighest level, mixed-- one of them operates\nat the lowest level, and like adaptable. They seem to scale up or down\ndepending on your environment.",
    "start": "4088553",
    "end": "4096064"
  },
  {
    "text": "And so like an adaptable\nset of length scales that you can use\nto do prediction. But that's quite speculative. So-- OK, sorry.",
    "start": "4096064",
    "end": "4104080"
  },
  {
    "text": "Yeah? So make sure I understand\nif, you go up-- OK, one more?",
    "start": "4104080",
    "end": "4110099"
  },
  {
    "text": "Yeah, so you have your-- what's the key and\nwhat's the value?",
    "start": "4110100",
    "end": "4116700"
  },
  {
    "text": "Yeah, so the-- And Hopfield networks\nare always auto instead of petro-associated,\nso how are you--",
    "start": "4116700",
    "end": "4124242"
  },
  {
    "text": "The memories that\nwe're going to put in, so the patterns,\nlet's say, chi mu, is going to be some outer\nproduct of the position",
    "start": "4124243",
    "end": "4131700"
  },
  {
    "text": "at a given time. And the flattened-- so\nyeah, take the outer product",
    "start": "4131700",
    "end": "4142220"
  },
  {
    "text": "of those, so every element in\nx gets the every element of g. Front nose out, and that's your\nvector that goes [INAUDIBLE]..",
    "start": "4142220",
    "end": "4147229"
  },
  {
    "text": "Does that makes sense? Yeah. Sorry, I should\nhave put that on.  Yeah, and then you do\nthe same operation,",
    "start": "4147229",
    "end": "4153670"
  },
  {
    "text": "except you flatten with an\nidentity in the-- let's say you're at a position you\nwant to print what you see. You set x to the identity,\nyou do this operation,",
    "start": "4153670",
    "end": "4160359"
  },
  {
    "text": "it creates a very\nbig vector from g. You put that in, and you\nlet it run its dynamics, and it recalls the pattern. And you learn a network\nthat like traces",
    "start": "4160359",
    "end": "4166990"
  },
  {
    "text": "out the x from that. And the figures you show,\nif you go down a bit,",
    "start": "4166990",
    "end": "4174770"
  },
  {
    "text": "it's hard to see, but what's\non the x-axis and what's-- like what-- are you training\na Hopfield network with this",
    "start": "4174770",
    "end": "4184750"
  },
  {
    "text": "flattened outer product of the-- OK. Yeah, the actual\ntraining that's going on is more in the\nstructure of the world.",
    "start": "4184750",
    "end": "4191345"
  },
  {
    "text": "Because it has to\nlearn those matrices. All it gets told is which\naction type it's taking, and it has to learn the\nfact that stepping east",
    "start": "4191345",
    "end": "4197200"
  },
  {
    "text": "is the opposite\nof stepping west. So a lot of the\nlearning of stuff is in those matrices, learning\nto get the right structure.",
    "start": "4197200",
    "end": "4203358"
  },
  {
    "text": "There's also-- I mean, because\nthe Hopfield network learning, the Hopfield network is\nlike re-initialize every environment. And you're just\nshoving memories in.",
    "start": "4203358",
    "end": "4209980"
  },
  {
    "text": "So it's less like-- that's less\nthe bit that's-- it's causing this, certainly, but it's\nnot causing this shift up.",
    "start": "4209980",
    "end": "4216350"
  },
  {
    "text": "Which is as training progresses\nin many different environments, you get better at the task. Because it's learning the\nstructure of the task.",
    "start": "4216350",
    "end": "4223370"
  },
  {
    "text": "OK. And the link to-- and this is all just\nmodern Hopfield networks?",
    "start": "4223370",
    "end": "4231225"
  },
  {
    "text": "The initial paper was actually\nclassic Hopfield networks. But yeah, now the\nnew versions of it are modern Hopfield\nnetworks, yeah.",
    "start": "4231225",
    "end": "4236720"
  },
  {
    "text": "Right, and then, insomuch\nas modern Hopfield networks equal attention--",
    "start": "4236720",
    "end": "4243139"
  },
  {
    "text": "Is it a trap? Yeah. But then, you're-- OK, and then you have some\nresults looking at activations.",
    "start": "4243140",
    "end": "4252800"
  },
  {
    "text": "Well, these are recordings\nin the brain, or-- No, these are actually in TEM. So this is-- the left ones\nare neurons in the G section,",
    "start": "4252800",
    "end": "4260659"
  },
  {
    "text": "in the medial entorhinal\ncortex part of TEM, as you vary position. Cool, OK. Yeah, and we're going to get--\nmy last section is about how",
    "start": "4260660",
    "end": "4268520"
  },
  {
    "text": "these TEM is like-- [INAUDIBLE] So we'll get to--\nhopefully it will be clear, the links between\nthe two after that.",
    "start": "4268520",
    "end": "4273605"
  },
  {
    "text": "OK, we're happy with\nthat, though, hopefully. Cool, term is approximately\nequal to transformer, yeah. So you seem to know all of this.",
    "start": "4273605",
    "end": "4281850"
  },
  {
    "text": "But I guess my notation, at\nleast we can clarify that. You got your data, which is\nmaybe your tokens coming in,",
    "start": "4281850",
    "end": "4287940"
  },
  {
    "text": "and you got your\npositional embedding. And the positional embedding\nwill play a very big role here. That's the E, and together,\nthey make this vector H.",
    "start": "4287940",
    "end": "4295409"
  },
  {
    "text": "And these arrive over time. Yeah, and you got\nyour attention updates that you see some similarity\nbetween the key and the query,",
    "start": "4295410",
    "end": "4302190"
  },
  {
    "text": "and then you add up weighted\nvalues with those similarities. So we're all happy with that?",
    "start": "4302190",
    "end": "4307760"
  },
  {
    "text": "And here's the stacked version. So the basic intuition about how\nthese parts map onto each other",
    "start": "4307760",
    "end": "4314889"
  },
  {
    "text": "is that the G is the\npositioning coding, as you may have been able to predict. The x, or the input tokens.",
    "start": "4314890",
    "end": "4321280"
  },
  {
    "text": "This guy, when you\nput in the memory, and you try and recall which\nmemory it's most similar to,",
    "start": "4321280",
    "end": "4326679"
  },
  {
    "text": "that's the attention part. And maybe some--\nyeah, you attend,",
    "start": "4326680",
    "end": "4333160"
  },
  {
    "text": "you compare the current GT\nto all of the previous GTs, and you recall the ones with\nhigh similarity structure.",
    "start": "4333160",
    "end": "4340030"
  },
  {
    "text": "And return the corresponding x. I've still got 10\nminutes, right? Yeah. OK.",
    "start": "4340030",
    "end": "4345822"
  },
  {
    "text": "Maybe some differences-- so I\nthink I'm going to go through this between how\nyou would maybe--",
    "start": "4345822",
    "end": "4351010"
  },
  {
    "text": "like the normal transformer, and\nhow to make it map onto this, are the following. So the first of\nthese is the keys",
    "start": "4351010",
    "end": "4356890"
  },
  {
    "text": "and the queries are the\nsame at all time points. So there's no\ndifference in the matrix that maps from tokens\nto keys and tokens",
    "start": "4356890",
    "end": "4364000"
  },
  {
    "text": "to queries, same matrix. And it only depends on\nthe positional encoding. OK, so you only recall\nmemories based on how similar",
    "start": "4364000",
    "end": "4371430"
  },
  {
    "text": "their positions are. So yeah, this is key at time\ntau equals query at time tau",
    "start": "4371430",
    "end": "4378540"
  },
  {
    "text": "equals some matrix applied only\nto the positional embedding of time tau.",
    "start": "4378540",
    "end": "4383580"
  },
  {
    "text": "Then, the values depend\nonly on this x part. So some like\nfactorization of the two,",
    "start": "4383580",
    "end": "4388843"
  },
  {
    "text": "which is that value at time\ntau is like some value matrix. Only apply to that x part. So that's the only bit you\nwant to recall, I guess.",
    "start": "4388843",
    "end": "4396030"
  },
  {
    "text": "Is that right? That's right. And then, it's a causal\ntransformer in that you only",
    "start": "4396030",
    "end": "4401210"
  },
  {
    "text": "do attention at things\nthat have arrived at time points in the past. Make sense?",
    "start": "4401210",
    "end": "4407295"
  },
  {
    "text": "And finally, the perhaps\nlike weird and interesting difference is that there's\nthis path integration going on in the positional encodings.",
    "start": "4407295",
    "end": "4413740"
  },
  {
    "text": "So these are the\nequivalent of the grid cells, the G from\nthe previous bit, and they're going to be updated\nthrough this matrix that",
    "start": "4413740",
    "end": "4418960"
  },
  {
    "text": "depends on the actions that\nyou're taking in the world. ",
    "start": "4418960",
    "end": "4424310"
  },
  {
    "text": "Yeah, so that's basically\nthe correspondence. I'm going to go through a little\nbit about how the Hopfield network is approximately\nlike doing attention",
    "start": "4424310",
    "end": "4431150"
  },
  {
    "text": "over previous tokens. So yeah, I was describing to\nyou before the classic Hopfield",
    "start": "4431150",
    "end": "4436159"
  },
  {
    "text": "network, which if you remove the\nnon-linearity, looks like this. And the mapping, I guess, is\nlike the hippocampal activity.",
    "start": "4436160",
    "end": "4443330"
  },
  {
    "text": "The current neural\nactivity is query. The set of memories,\nthemselves, are the key.",
    "start": "4443330",
    "end": "4449842"
  },
  {
    "text": "You're doing this dot product\nto get the current similarity between the query and the key. And then you're summing\nthem up, weighted",
    "start": "4449842",
    "end": "4455208"
  },
  {
    "text": "by that dot product, all of\nthe memories that are values.",
    "start": "4455208",
    "end": "4460240"
  },
  {
    "text": "So that's the simple version. But actually, these Hopfield\nnetworks are quite bad. They like-- in some\nsenses, they tend to fail.",
    "start": "4460240",
    "end": "4467190"
  },
  {
    "text": "They have low memory\ncapacity for N neurons. They have something-- they can\nonly embed like naught 114 n",
    "start": "4467190",
    "end": "4474210"
  },
  {
    "text": "memories. Just like a big result\nfrom statistical physics in the '80s. But it's OK, people\nhave improved this.",
    "start": "4474210",
    "end": "4480948"
  },
  {
    "text": "The reason that\nthey're bad, it seems to be basically that the\noverlap between your query and the memories is too big for\ntoo many memories, you know?",
    "start": "4480948",
    "end": "4488820"
  },
  {
    "text": "You basically look too\nsimilar to too many things. So how do you do that? You like sharpen your\nsimilarity function.",
    "start": "4488820",
    "end": "4494508"
  },
  {
    "text": "And the way we're\ngoing to sharpen it is through this function,\nand this function is going to be softmax. So it's going to\nbe like, oh, how",
    "start": "4494508",
    "end": "4500623"
  },
  {
    "text": "similar am I to this\nparticular pattern, weighted exponentiated? And then over how similar am\nI to all of the other ones?",
    "start": "4500623",
    "end": "4507010"
  },
  {
    "text": "So that's our new\nmeasure of similarity. And that's the my understanding\nof the modern Hopfield. ",
    "start": "4507010",
    "end": "4514190"
  },
  {
    "text": "And then, you can\nsee how this thing-- yeah, it's basically doing\nthe attention mechanism.",
    "start": "4514190",
    "end": "4519630"
  },
  {
    "text": "And it's also\nbiologically plausible. We'll quickly run\nthrough that, is",
    "start": "4519630",
    "end": "4525200"
  },
  {
    "text": "that you have some\nset of activity, PT, this like neural activity. And you're going to compare\nthat to each chi mu.",
    "start": "4525200",
    "end": "4531883"
  },
  {
    "text": "And that's through\nthese memory neurons. So there's a set of memory\nneurons, one for each pattern that you've memorized, mu. And the weights to this memory\nneuron will be this chi mu.",
    "start": "4531883",
    "end": "4540830"
  },
  {
    "text": "And then the activity\nof this neuron will be this dot product. And then you're going to\ndo divisive normalization",
    "start": "4540830",
    "end": "4546500"
  },
  {
    "text": "to run this operation\nbetween these neurons. So like to make them\ncompete with one another,",
    "start": "4546500",
    "end": "4551600"
  },
  {
    "text": "and only recall\nthe memories that are most similar through--\nthe most activated according to this like softmax operation.",
    "start": "4551600",
    "end": "4556610"
  },
  {
    "text": "And then they'll\nproject back to the PT, and produce the\noutput by summing up the memories weighted\nby this thing, times the chi mu,\nwhich is the weights.",
    "start": "4556610",
    "end": "4563309"
  },
  {
    "text": "So the weights out\nto the memory neurons and back to the\nhippocampus of both chi mu.",
    "start": "4563310",
    "end": "4569190"
  },
  {
    "text": "And so that's how you can\nbiologically plausibly run this modern Hopfield network.",
    "start": "4569190",
    "end": "4575160"
  },
  {
    "text": "And so, sorry, yeah? Any thoughts as to what the\nmemories that are inputted are?",
    "start": "4575160",
    "end": "4580610"
  },
  {
    "text": "Like do you attend over every\nmemory you've ever made? Probably not. Probably not, yeah.",
    "start": "4580610",
    "end": "4585679"
  },
  {
    "text": "I guess somehow, you\nhave to have knowledge. In this case, it works\nnicely, because we like wiped this poor\nagent's memory every time,",
    "start": "4585680",
    "end": "4591620"
  },
  {
    "text": "and only memorize things\nfrom the environment. And so you need\nsomething that gates it, so that it only looks for things\nin the current environment",
    "start": "4591620",
    "end": "4598248"
  },
  {
    "text": "somehow. How that happens, I'm not sure. There are claims that there's\nthis just shift over time.",
    "start": "4598248",
    "end": "4606530"
  },
  {
    "text": "The claim is basically that\nsomehow, as time passes, the representations just slowly\nlike rotate, or something.",
    "start": "4606530",
    "end": "4613070"
  },
  {
    "text": "And then, they're also\nembedding something like a time similarity, as well. Because the closer\nin time you are, the more you're like in\nthe same rotated thingy.",
    "start": "4613070",
    "end": "4619880"
  },
  {
    "text": "So maybe that's a mechanism\nto pass a certain time you don't recall things. But the evidence and\ndebate a lot around that.",
    "start": "4619880",
    "end": "4627430"
  },
  {
    "text": "So other mechanisms like\nit, I'm sure are happening.",
    "start": "4627430",
    "end": "4633115"
  },
  {
    "text": "Maybe context is\nanother one, actually. We'll briefly talk about that. You know, if you know\nyou're in the same context,",
    "start": "4633115",
    "end": "4638160"
  },
  {
    "text": "then you can send a\nsignal, like somehow in the prefrontal cortex,\nwork out what kind of setting am I in? You can send that\nsignal back and be like,",
    "start": "4638160",
    "end": "4644110"
  },
  {
    "text": "oh, make sure you attend\nto these ones that are in the same context. So yeah, there we go. Tim Transformer does the job.",
    "start": "4644110",
    "end": "4651038"
  },
  {
    "text": "A path integrates its\npositional encodings, which is kind of fun. It computes similarity using\nthese positional encodings.",
    "start": "4651038",
    "end": "4657360"
  },
  {
    "text": "And it only compares\nto past memories. But otherwise, it looks a\nbit like a transformer setup. And here's the setup we had--",
    "start": "4657360",
    "end": "4663270"
  },
  {
    "text": "MEC, LEC, hippocampus,\nand places. Some, yeah, so here's a brief--",
    "start": "4663270",
    "end": "4668755"
  },
  {
    "text": "the last thing I\nthink I'm going to say is that this extends TEM\nnicely, because it allows",
    "start": "4668755",
    "end": "4674080"
  },
  {
    "text": "it-- previously you had\nto do this outer product and flatten, that's a\nvery dimensionality is like terrible scaling\nwith like-- for example,",
    "start": "4674080",
    "end": "4680080"
  },
  {
    "text": "if you want to do position, what\nI saw in the context signal, suddenly you have to turn\nouter product, three vectors, and flatten that.",
    "start": "4680080",
    "end": "4685410"
  },
  {
    "text": "That's a much, much bigger\nscaling, like N cubed, right? Rather than what you'd\nlike to do is just like 3M.",
    "start": "4685410",
    "end": "4691050"
  },
  {
    "text": "And so this version of TEM\nwith this new modern Hopfield network does scale nicely to\nadding a context input, as just",
    "start": "4691050",
    "end": "4697240"
  },
  {
    "text": "another input in what\nwas previously this like modern Hopfield network. So yeah, there's some--",
    "start": "4697240",
    "end": "4702772"
  },
  {
    "text": "so yeah, our\nconclusions is there's like proved somewhat interesting\nas a two-way relationship from the AI to the neuro site.",
    "start": "4702772",
    "end": "4710050"
  },
  {
    "text": "We use this new memory model,\nthis modern Hopfield network, that has all of\nthis bit is supposed",
    "start": "4710050",
    "end": "4715668"
  },
  {
    "text": "to be in the hippocampus. Whereas previously, we just\nhad these like memory bits in the classic Hopfield\nnetwork in hippocampus. So it makes kind of\ninteresting predictions",
    "start": "4715668",
    "end": "4721809"
  },
  {
    "text": "about different cell\nstructures in the hippocampus, and it just sped\nup the code a lot.",
    "start": "4721810",
    "end": "4727780"
  },
  {
    "text": "From the neuro-- maybe\nthere's a few things that are slightly different,\nthis like learnable recurrent position encoding.",
    "start": "4727780",
    "end": "4733390"
  },
  {
    "text": "So people do some of this-- I think they get like\nposition encodings and learn an RNN\nthat updates them. But maybe this is like\nsome motivation to try.",
    "start": "4733390",
    "end": "4740378"
  },
  {
    "text": "For example, they don't\nknow the weight matrices, and these weight matrices\nare very biased towards-- because they're\ninvertible, generally.",
    "start": "4740378",
    "end": "4746290"
  },
  {
    "text": "And things like\nthat, they're very biased towards representing\nthese very clean structures, like 2D space. So it might be\ninteresting there.",
    "start": "4746290",
    "end": "4752453"
  },
  {
    "text": "The other thing is this is\nlike one attention layer, only. And so like somehow, by\nusing nice recommendations",
    "start": "4752453",
    "end": "4759100"
  },
  {
    "text": "making the task very easy,\nin terms of processing X, and using the right\npositional encoding, you've got to solve the\ntask with just one of these.",
    "start": "4759100",
    "end": "4765760"
  },
  {
    "text": "Also, kind of nice,\nand maybe it's like a nice interpretation, is\nthat you can go in and really probe what these neurons\nare doing in this network,",
    "start": "4765760",
    "end": "4771700"
  },
  {
    "text": "and really understand it. We know that the position\nencoding looks like grid cells, we have a very\ndeep understanding of why grid cells\nare a useful thing",
    "start": "4771700",
    "end": "4777640"
  },
  {
    "text": "to have if you're doing\nthis path integration. So it hopefully helps\ninterpret all these things. Oh, yeah, and if\nthere was time, I",
    "start": "4777640",
    "end": "4783400"
  },
  {
    "text": "was going to tell you all\nabout grid cells, which are my hobbyhorse. But don't think there's\ntime, so I'll stop there. Excellent.",
    "start": "4783400",
    "end": "4788508"
  },
  {
    "text": " Any questions?",
    "start": "4788508",
    "end": "4794401"
  },
  {
    "text": " OK--",
    "start": "4794401",
    "end": "4800320"
  },
  {
    "text": "A very base question. So in the very\nbeginning, those breeds are linked into one neuron,\nor a population of neurons?",
    "start": "4800320",
    "end": "4808050"
  },
  {
    "text": "These ones? Those ones? Yeah, that's one\nneuron's response. Just one neuron? Yeah.",
    "start": "4808050",
    "end": "4813733"
  },
  {
    "text": "Wild, it's wild. Let me tell you more about\nthe grid cell system. And you can know-- how can you know\nthat it's one neuron?",
    "start": "4813733",
    "end": "4819469"
  },
  {
    "text": "How do you measure it? Because you got an electrode\nstuck in here, right? And they generally have the\nclassic measuring technique",
    "start": "4819470",
    "end": "4826790"
  },
  {
    "text": "is a tetrode, which\nis four wires. And they receive\nthese spikes, which are like electrical fluctuations\nas a result of the neuron",
    "start": "4826790",
    "end": "4832880"
  },
  {
    "text": "firing. And they can triangulate\nat that particular spike that they measured, because\nof the pattern of activity on the four wires has to have\nonly come from one position.",
    "start": "4832880",
    "end": "4839497"
  },
  {
    "text": "So they can work\nout which neuron sent that particular spike. But a set of neurons that\nhave grid cell patterns.",
    "start": "4839497",
    "end": "4847780"
  },
  {
    "text": "Lots of neurons have patterns\nthat are just translated versions of one another. So the same grid like\nshifted in space.",
    "start": "4847780",
    "end": "4852940"
  },
  {
    "text": "That's called a module. And then, there are\nsets of modules, which are the same types of\nneurons, but with a lattice",
    "start": "4852940",
    "end": "4858262"
  },
  {
    "text": "that's much bigger\nor much smaller. And in rats, there's\nroughly seven. So this is a very surprising\ncrystalline structure",
    "start": "4858262",
    "end": "4863680"
  },
  {
    "text": "of these seven modules,\nwithin each module, each neuron is just a translated\nversion of one another. Which, yeah, there's a lot of\ntheory work about why that's",
    "start": "4863680",
    "end": "4870280"
  },
  {
    "text": "a very sensible thing to do, if\nyou want to do path integration and work out where you are\nin the environment based on your velocity signals.",
    "start": "4870280",
    "end": "4877980"
  },
  {
    "text": "Nice.  Just this thing, you said\nthis was really fascinating",
    "start": "4877980",
    "end": "4883730"
  },
  {
    "text": "about the template thing. This is a product of evolution,\nor a product of learning?",
    "start": "4883730",
    "end": "4890870"
  },
  {
    "text": "Evolution. It emerges like 10 days after-- in a baby rat's life,\nafter being born.",
    "start": "4890870",
    "end": "4898340"
  },
  {
    "text": "So certainly, that\nstructure seems to be very biased\nto being creative.",
    "start": "4898340",
    "end": "4904370"
  },
  {
    "text": "Unclear-- we were\ntalking about how it was being co-opted\nto encode other things, and so it's debatable\nhow flexible it is,",
    "start": "4904370",
    "end": "4912370"
  },
  {
    "text": "or how hard-wired it is. But it seems-- the evidence\nsuggests that there's some more flexibility in the system.",
    "start": "4912370",
    "end": "4918020"
  },
  {
    "text": "Unclear quite how\nit's coding it. But it'd be cool to get neural\nrecordings of it and see.",
    "start": "4918020",
    "end": "4923057"
  },
  {
    "text": "Well, actually, let's\ngive our speaker another round of applause. ",
    "start": "4923057",
    "end": "4933000"
  }
]
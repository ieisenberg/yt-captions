[
  {
    "start": "0",
    "end": "58000"
  },
  {
    "start": "0",
    "end": "4672"
  },
  {
    "text": "CHRIS POTTS: Hello, everyone.",
    "start": "4672",
    "end": "5880"
  },
  {
    "text": "Welcome to part 4 of our\nseries on supervised sentiment",
    "start": "5880",
    "end": "8180"
  },
  {
    "text": "analysis.",
    "start": "8180",
    "end": "8750"
  },
  {
    "text": "This is the second screencast\nin the series that is focused",
    "start": "8750",
    "end": "11360"
  },
  {
    "text": "on a dataset for sentiment.",
    "start": "11360",
    "end": "13700"
  },
  {
    "text": "And that dataset is DynaSent.",
    "start": "13700",
    "end": "15530"
  },
  {
    "text": "This video could be\nconsidered an optional element",
    "start": "15530",
    "end": "17630"
  },
  {
    "text": "in the series.",
    "start": "17630",
    "end": "18650"
  },
  {
    "text": "I'm offering it for\ntwo reasons really.",
    "start": "18650",
    "end": "20539"
  },
  {
    "text": "First, this is a new data\nset that I helped produce.",
    "start": "20540",
    "end": "23540"
  },
  {
    "text": "And I would love it if\npeople worked on it.",
    "start": "23540",
    "end": "25520"
  },
  {
    "text": "It would be great to see some\nnew models, new insights.",
    "start": "25520",
    "end": "28650"
  },
  {
    "text": "All of that would help\npush this project forward",
    "start": "28650",
    "end": "30650"
  },
  {
    "text": "in interesting ways.",
    "start": "30650",
    "end": "32060"
  },
  {
    "text": "The second reason\nis more practical.",
    "start": "32060",
    "end": "33560"
  },
  {
    "text": "I think that this data\nset could be useful to you",
    "start": "33560",
    "end": "35750"
  },
  {
    "text": "as you work on the assignment\nand the associated bake-off.",
    "start": "35750",
    "end": "38750"
  },
  {
    "text": "You could use the\ndata set itself",
    "start": "38750",
    "end": "40400"
  },
  {
    "text": "for supplementary training data.",
    "start": "40400",
    "end": "42530"
  },
  {
    "text": "You could use it to\nevaluate your system.",
    "start": "42530",
    "end": "44511"
  },
  {
    "text": "And as you'll see,\nthere are a few points",
    "start": "44512",
    "end": "46220"
  },
  {
    "text": "of conceptual connection\nbetween this data set",
    "start": "46220",
    "end": "49370"
  },
  {
    "text": "and the brand new dev and test\nsets of restaurant sentences",
    "start": "49370",
    "end": "53449"
  },
  {
    "text": "that are part of the\nbake-off this year.",
    "start": "53450",
    "end": "57552"
  },
  {
    "text": "So let's dive in.",
    "start": "57552",
    "end": "58260"
  },
  {
    "start": "58000",
    "end": "117000"
  },
  {
    "text": "Here's a project overview.",
    "start": "58260",
    "end": "59343"
  },
  {
    "text": "First, all the data, code, and\nmodels are available on GitHub",
    "start": "59343",
    "end": "62309"
  },
  {
    "text": "at this link.",
    "start": "62310",
    "end": "64239"
  },
  {
    "text": "This dataset itself consists\nof about 122,000 sentences.",
    "start": "64239",
    "end": "68540"
  },
  {
    "text": "They are across two rounds.",
    "start": "68540",
    "end": "70160"
  },
  {
    "text": "And I'm going to cover\nwhat each round means.",
    "start": "70160",
    "end": "72440"
  },
  {
    "text": "And each of the sentences has\nfive gold labels in addition",
    "start": "72440",
    "end": "75560"
  },
  {
    "text": "to an inferred majority\nlabel where there is one.",
    "start": "75560",
    "end": "77797"
  },
  {
    "text": "And I'll return to that as well.",
    "start": "77797",
    "end": "79130"
  },
  {
    "text": "I think that's an interesting\naspect to this kind of data",
    "start": "79130",
    "end": "81979"
  },
  {
    "text": "collection.",
    "start": "81980",
    "end": "83390"
  },
  {
    "text": "The associated paper\nis Potts et al.",
    "start": "83390",
    "end": "85201"
  },
  {
    "text": "2020, which I\nencourage you to read",
    "start": "85202",
    "end": "86660"
  },
  {
    "text": "if you want to learn even more\nabout this dataset and how,",
    "start": "86660",
    "end": "89690"
  },
  {
    "text": "in particular, it relates to\nthe Stanford Sentiment Treebank,",
    "start": "89690",
    "end": "93080"
  },
  {
    "text": "our other core dataset.",
    "start": "93080",
    "end": "95870"
  },
  {
    "text": "And another ingredient\nhere, as you'll",
    "start": "95870",
    "end": "97820"
  },
  {
    "text": "see when we get to round\ntwo, is that this is partly",
    "start": "97820",
    "end": "100850"
  },
  {
    "text": "an effort in model in the loop\nadversarial data set creation.",
    "start": "100850",
    "end": "104960"
  },
  {
    "text": "For round two, crowd\nworkers interacted",
    "start": "104960",
    "end": "107810"
  },
  {
    "text": "with the model\nattempting to fool it",
    "start": "107810",
    "end": "109880"
  },
  {
    "text": "and, thereby, creating sentences\nthat are really difficult",
    "start": "109880",
    "end": "112399"
  },
  {
    "text": "and are going to challenge\nour models in what we hope",
    "start": "112400",
    "end": "114608"
  },
  {
    "text": "are exciting and\nproductive ways.",
    "start": "114608",
    "end": "117330"
  },
  {
    "start": "117000",
    "end": "198000"
  },
  {
    "text": "So here's a complete\nproject overview.",
    "start": "117330",
    "end": "118938"
  },
  {
    "text": "Let me walk through it quickly.",
    "start": "118938",
    "end": "120230"
  },
  {
    "text": "And then we'll dive\ninto the details.",
    "start": "120230",
    "end": "122120"
  },
  {
    "text": "We begin with what we've\ncalled Model 0, which",
    "start": "122120",
    "end": "124460"
  },
  {
    "text": "is a RoBERTa model that's\nfine-tuned on a bunch of very",
    "start": "124460",
    "end": "127460"
  },
  {
    "text": "large, sentiment\nbenchmark data sets.",
    "start": "127460",
    "end": "130789"
  },
  {
    "text": "The primary utility\nof Model 0 is",
    "start": "130789",
    "end": "132920"
  },
  {
    "text": "that we're going to use it as\na device to find challenging,",
    "start": "132920",
    "end": "136069"
  },
  {
    "text": "naturally occurring sentences\nout in a large corpus.",
    "start": "136070",
    "end": "140390"
  },
  {
    "text": "And then we human validate those\nto get actual labels for them.",
    "start": "140390",
    "end": "143870"
  },
  {
    "text": "The result of that\nprocess is what",
    "start": "143870",
    "end": "145580"
  },
  {
    "text": "we hope is a really challenging\nround 1 dataset of naturally",
    "start": "145580",
    "end": "149870"
  },
  {
    "text": "occurring sentences that are\nhard for a very good sentiment",
    "start": "149870",
    "end": "153349"
  },
  {
    "text": "model like Model 0.",
    "start": "153350",
    "end": "155780"
  },
  {
    "text": "On that basis, we\nthen train a Model 1,",
    "start": "155780",
    "end": "158750"
  },
  {
    "text": "which is similar to Model 0 but\nnow extended with that round 1",
    "start": "158750",
    "end": "162620"
  },
  {
    "text": "training data.",
    "start": "162620",
    "end": "163390"
  },
  {
    "text": "So we hope that, in\nbringing in that new data",
    "start": "163390",
    "end": "165860"
  },
  {
    "text": "and combining it with\nthe sentiment benchmarks,",
    "start": "165860",
    "end": "168500"
  },
  {
    "text": "we get an even stronger model.",
    "start": "168500",
    "end": "170900"
  },
  {
    "text": "That is the model that\ncrowd workers interacted",
    "start": "170900",
    "end": "173390"
  },
  {
    "text": "with on the Dynabench\nplatform to try",
    "start": "173390",
    "end": "175430"
  },
  {
    "text": "to create examples\nthat are adversarial",
    "start": "175430",
    "end": "177980"
  },
  {
    "text": "with respect to Model 1.",
    "start": "177980",
    "end": "179330"
  },
  {
    "text": "So they ought to be\nreally difficult.",
    "start": "179330",
    "end": "181260"
  },
  {
    "text": "We feed those through exactly\nthe same human validation",
    "start": "181260",
    "end": "183769"
  },
  {
    "text": "pipeline.",
    "start": "183770",
    "end": "184340"
  },
  {
    "text": "And that gives us our\nsecond round of data.",
    "start": "184340",
    "end": "187312"
  },
  {
    "text": "So two rounds of data\nthat can be thought",
    "start": "187312",
    "end": "189019"
  },
  {
    "text": "of as separate problems\nare merged together",
    "start": "189020",
    "end": "191360"
  },
  {
    "text": "into a larger data set.",
    "start": "191360",
    "end": "192750"
  },
  {
    "text": "I think we're kind\nof still deciding",
    "start": "192750",
    "end": "194540"
  },
  {
    "text": "how best to conceptualize\nthese various data aspects.",
    "start": "194540",
    "end": "199200"
  },
  {
    "start": "198000",
    "end": "252000"
  },
  {
    "text": "So let's look at round 1\nin a little more detail.",
    "start": "199200",
    "end": "201390"
  },
  {
    "text": "This is where we\nbegin with Model 0,",
    "start": "201390",
    "end": "203270"
  },
  {
    "text": "and try to harvest interesting\nnaturally occurring sentences.",
    "start": "203270",
    "end": "207770"
  },
  {
    "text": "We sort of run Model 0 as\na RoBERTa-based classifier.",
    "start": "207770",
    "end": "210920"
  },
  {
    "text": "And its training data are\nfrom customer reviews,",
    "start": "210920",
    "end": "214470"
  },
  {
    "text": "which is small, the IMDB\ndataset, which I linked to",
    "start": "214470",
    "end": "217730"
  },
  {
    "text": "in an earlier\nscreencast, SST-3, which",
    "start": "217730",
    "end": "220459"
  },
  {
    "text": "you saw in the previous\nscreencast, and then these two",
    "start": "220460",
    "end": "222710"
  },
  {
    "text": "very large external benchmarks\nof product and service reviews",
    "start": "222710",
    "end": "227330"
  },
  {
    "text": "from Yelp and Amazon.",
    "start": "227330",
    "end": "228650"
  },
  {
    "text": "You can see that\nthey're very big indeed.",
    "start": "228650",
    "end": "231170"
  },
  {
    "text": "And the performance of\nModel 0 on the datasets,",
    "start": "231170",
    "end": "234285"
  },
  {
    "text": "these are our three\nexternal data sets.",
    "start": "234285",
    "end": "235910"
  },
  {
    "text": "It's pretty good.",
    "start": "235910",
    "end": "236618"
  },
  {
    "text": "They range from the\nlow 70s, for SST-3,",
    "start": "236618",
    "end": "240170"
  },
  {
    "text": "to the high 70s for\nYelp and Amazon.",
    "start": "240170",
    "end": "242670"
  },
  {
    "text": "So this is a solid model.",
    "start": "242670",
    "end": "243800"
  },
  {
    "text": "And I will say,\nimpressionistically,",
    "start": "243800",
    "end": "245750"
  },
  {
    "text": "if you download Model 0\nand play around with it,",
    "start": "245750",
    "end": "248030"
  },
  {
    "text": "you will find that it is a very\ngood sentiment model indeed.",
    "start": "248030",
    "end": "252500"
  },
  {
    "start": "252000",
    "end": "295000"
  },
  {
    "text": "So we used Model 0 to\nharvest what we hope",
    "start": "252500",
    "end": "255110"
  },
  {
    "text": "are challenging sentences.",
    "start": "255110",
    "end": "256338"
  },
  {
    "text": "And for this, we used\nthe Yelp academic dataset",
    "start": "256339",
    "end": "258739"
  },
  {
    "text": "which is a very large collection\nof about 8 million reviews.",
    "start": "258740",
    "end": "261907"
  },
  {
    "text": "And our heuristic\nis that we're going",
    "start": "261908",
    "end": "263449"
  },
  {
    "text": "to favor in our sampling\nprocess harvesting sentences",
    "start": "263450",
    "end": "266810"
  },
  {
    "text": "where the review was one\nstar, so it's very low,",
    "start": "266810",
    "end": "270350"
  },
  {
    "text": "and Model 0 predicted\npositive for a given sentence",
    "start": "270350",
    "end": "273620"
  },
  {
    "text": "and, conversely, where\nthe review is five stars,",
    "start": "273620",
    "end": "276139"
  },
  {
    "text": "and Model 0 predicted negative.",
    "start": "276140",
    "end": "278420"
  },
  {
    "text": "We are hoping that that at least\ncreates a bias for sentences",
    "start": "278420",
    "end": "281570"
  },
  {
    "text": "that are very\nchallenging for Model 0,",
    "start": "281570",
    "end": "283220"
  },
  {
    "text": "where it's actually\nmaking a wrong prediction.",
    "start": "283220",
    "end": "285260"
  },
  {
    "text": "We're not going to depend\non that assumption.",
    "start": "285260",
    "end": "287135"
  },
  {
    "text": "Because we'll have\na validation step.",
    "start": "287135",
    "end": "288740"
  },
  {
    "text": "But we're hoping that this\nis as kind of as adversarial",
    "start": "288740",
    "end": "291770"
  },
  {
    "text": "as we can be without actually\nhaving labels to begin with.",
    "start": "291770",
    "end": "295979"
  },
  {
    "start": "295000",
    "end": "330000"
  },
  {
    "text": "This is a picture of the\nvalidation interface.",
    "start": "295980",
    "end": "298240"
  },
  {
    "text": "You can see that there were some\nexamples given and a little bit",
    "start": "298240",
    "end": "301289"
  },
  {
    "text": "of training about how\nto use the labels.",
    "start": "301290",
    "end": "303360"
  },
  {
    "text": "And then, fundamentally,\nwhat crowd workers did is",
    "start": "303360",
    "end": "305520"
  },
  {
    "text": "they were prompted\nfor a sentence,",
    "start": "305520",
    "end": "306936"
  },
  {
    "text": "and they made one of four\nchoices, positive, negative,",
    "start": "306937",
    "end": "309960"
  },
  {
    "text": "no sentiment, which is our\nnotion of neutral, and mixed",
    "start": "309960",
    "end": "313080"
  },
  {
    "text": "sentiment, which is\nindicating a sentence that",
    "start": "313080",
    "end": "315539"
  },
  {
    "text": "has a balance of positive and\nnegative sentiments expressed",
    "start": "315540",
    "end": "318360"
  },
  {
    "text": "in it.",
    "start": "318360",
    "end": "318944"
  },
  {
    "text": "I think that's an important\ncategory to single out.",
    "start": "318945",
    "end": "321070"
  },
  {
    "text": "We're not going to try\nto model those sentences.",
    "start": "321070",
    "end": "323340"
  },
  {
    "text": "But we certainly\nwant crowd workers",
    "start": "323340",
    "end": "324900"
  },
  {
    "text": "to register that kind of mixing\nof emotions where it appears.",
    "start": "324900",
    "end": "330430"
  },
  {
    "start": "330000",
    "end": "422000"
  },
  {
    "text": "So here's the resulting dataset.",
    "start": "330430",
    "end": "331900"
  },
  {
    "text": "And because we got five gold\nlabels for every sentence,",
    "start": "331900",
    "end": "335710"
  },
  {
    "text": "there are two perspectives\nthat you can take.",
    "start": "335710",
    "end": "338080"
  },
  {
    "text": "The first one I've called\ndistributional train.",
    "start": "338080",
    "end": "340082"
  },
  {
    "text": "And this is where,\nessentially, we",
    "start": "340083",
    "end": "341500"
  },
  {
    "text": "take each one of the\nexamples and reproduce it",
    "start": "341500",
    "end": "344350"
  },
  {
    "text": "five times for each of\nthe labels that it got.",
    "start": "344350",
    "end": "347440"
  },
  {
    "text": "So if an individual sentence\ngot three positive labels, two",
    "start": "347440",
    "end": "351100"
  },
  {
    "text": "negative, then we would have\nfive examples, three labeled",
    "start": "351100",
    "end": "354520"
  },
  {
    "text": "positive and three\nlabeled negative,",
    "start": "354520",
    "end": "356139"
  },
  {
    "text": "with the actual text of the\nexample repeated five times.",
    "start": "356140",
    "end": "359500"
  },
  {
    "text": "What that is doing\nis essentially",
    "start": "359500",
    "end": "361870"
  },
  {
    "text": "simulating having a\ndistribution over the labels.",
    "start": "361870",
    "end": "364750"
  },
  {
    "text": "And for many\nclassifier models, that",
    "start": "364750",
    "end": "366850"
  },
  {
    "text": "is literally the\nsame as training",
    "start": "366850",
    "end": "368440"
  },
  {
    "text": "on a distribution of the labels\nas given by our crowd workers.",
    "start": "368440",
    "end": "371920"
  },
  {
    "text": "I think this is an exciting\nway to bring in uncertainty",
    "start": "371920",
    "end": "375658"
  },
  {
    "text": "and capture the fact\nthat there might",
    "start": "375658",
    "end": "377199"
  },
  {
    "text": "be kind of inherent disagreement\namong the crowd workers",
    "start": "377200",
    "end": "379810"
  },
  {
    "text": "that we want our model\nto at least grapple with.",
    "start": "379810",
    "end": "382510"
  },
  {
    "text": "And in the paper,\nas we discuss, this",
    "start": "382510",
    "end": "385270"
  },
  {
    "text": "gives better models than\ntraining on just the majority",
    "start": "385270",
    "end": "388479"
  },
  {
    "text": "labels.",
    "start": "388480",
    "end": "389380"
  },
  {
    "text": "But you can take a\nmore traditional view.",
    "start": "389380",
    "end": "391340"
  },
  {
    "text": "So majority label here\nmeans that at least three",
    "start": "391340",
    "end": "393340"
  },
  {
    "text": "of the five workers\nchose that label.",
    "start": "393340",
    "end": "396250"
  },
  {
    "text": "That gives you 94,000 or\n95,000 sentences for training.",
    "start": "396250",
    "end": "400180"
  },
  {
    "text": "And then these dev and test\nsets have 3,600 samples each.",
    "start": "400180",
    "end": "403360"
  },
  {
    "text": "And presumably, we would\npredict just the majority label",
    "start": "403360",
    "end": "405969"
  },
  {
    "text": "for them.",
    "start": "405970",
    "end": "407050"
  },
  {
    "text": "What's more open is how\nwe train these systems.",
    "start": "407050",
    "end": "410590"
  },
  {
    "text": "And in the end, what we found\nis that 47% of these examples",
    "start": "410590",
    "end": "413680"
  },
  {
    "text": "are adversarial with\nrespect to Model 0.",
    "start": "413680",
    "end": "416350"
  },
  {
    "text": "And as you'll see,\nthe dev and test set",
    "start": "416350",
    "end": "418195"
  },
  {
    "text": "are designed so that Model 0\nperforms at chance on them.",
    "start": "418195",
    "end": "422104"
  },
  {
    "start": "422000",
    "end": "483000"
  },
  {
    "text": "Yeah, that's the Model\n0 versus the human.",
    "start": "422104",
    "end": "424410"
  },
  {
    "text": "So here's a summary\nof the performance.",
    "start": "424410",
    "end": "426250"
  },
  {
    "text": "I showed you these\ncategories before.",
    "start": "426250",
    "end": "428550"
  },
  {
    "text": "And I'm just signaling that\nwe have, by design, ensured",
    "start": "428550",
    "end": "431270"
  },
  {
    "text": "that Model 0 performs\nat chance on round zero.",
    "start": "431270",
    "end": "435069"
  },
  {
    "text": "We could compare that\nto our human baseline.",
    "start": "435070",
    "end": "437140"
  },
  {
    "text": "For this, we kind of\nsynthesized five annotators",
    "start": "437140",
    "end": "440440"
  },
  {
    "text": "and did pairwise\nF1 scoring for them",
    "start": "440440",
    "end": "442690"
  },
  {
    "text": "to get an estimate\nof human performance",
    "start": "442690",
    "end": "444400"
  },
  {
    "text": "that is on the same scale\nas what we got from Model 0",
    "start": "444400",
    "end": "447729"
  },
  {
    "text": "up here.",
    "start": "447730",
    "end": "448450"
  },
  {
    "text": "And we put that estimate of\n88% for the dev and test sets.",
    "start": "448450",
    "end": "452140"
  },
  {
    "text": "I think that's a good\nconservative number.",
    "start": "452140",
    "end": "454150"
  },
  {
    "text": "I think if you got close to\nit, that would be a signal",
    "start": "454150",
    "end": "456550"
  },
  {
    "text": "that we had kind of\nsaturated this round.",
    "start": "456550",
    "end": "458680"
  },
  {
    "text": "And we'd like to think about\nadditional dataset creation.",
    "start": "458680",
    "end": "461422"
  },
  {
    "text": "I do want to signal,\nthough, that I",
    "start": "461422",
    "end": "462880"
  },
  {
    "text": "think this is a conservative\nestimate of how humans do.",
    "start": "462880",
    "end": "465760"
  },
  {
    "text": "And one indicator of\nthat is that, actually,",
    "start": "465760",
    "end": "467860"
  },
  {
    "text": "614 of the roughly 1,200\npeople who worked on this task",
    "start": "467860",
    "end": "472120"
  },
  {
    "text": "for validation never disagreed\nwith the majority label, which",
    "start": "472120",
    "end": "475990"
  },
  {
    "text": "sort of starts to suggest\nthat there are humans who",
    "start": "475990",
    "end": "478630"
  },
  {
    "text": "are performing\nperfectly at this task,",
    "start": "478630",
    "end": "480910"
  },
  {
    "text": "putting the set at\npretty low bound.",
    "start": "480910",
    "end": "483320"
  },
  {
    "start": "483000",
    "end": "576000"
  },
  {
    "text": "And here are some\nexample sentences.",
    "start": "483320",
    "end": "484840"
  },
  {
    "text": "These are fully randomly\nsampled with the only bias",
    "start": "484840",
    "end": "487510"
  },
  {
    "text": "being that I set a length\nrestriction, so that the slide",
    "start": "487510",
    "end": "489850"
  },
  {
    "text": "would be manageable.",
    "start": "489850",
    "end": "490910"
  },
  {
    "text": "These are the same\nexamples that appear",
    "start": "490910",
    "end": "492670"
  },
  {
    "text": "in the paper, where\nwe needed to fit them",
    "start": "492670",
    "end": "494740"
  },
  {
    "text": "all into a pretty small table.",
    "start": "494740",
    "end": "496389"
  },
  {
    "text": "I think this is\nilluminating though.",
    "start": "496390",
    "end": "497890"
  },
  {
    "text": "So it's showing all\nthe different ways",
    "start": "497890",
    "end": "499473"
  },
  {
    "text": "that Model 0 could get\nconfused with respect",
    "start": "499473",
    "end": "501490"
  },
  {
    "text": "to the majority response.",
    "start": "501490",
    "end": "503188"
  },
  {
    "text": "And I would like to\nhighlight for you",
    "start": "503188",
    "end": "504729"
  },
  {
    "text": "that there is a real discrepancy\nhere on the neutral category.",
    "start": "504730",
    "end": "508390"
  },
  {
    "text": "What we find is that,\nbecause Model 0 was trained",
    "start": "508390",
    "end": "511030"
  },
  {
    "text": "on large external benchmarks,\nits notion of neutral",
    "start": "511030",
    "end": "514719"
  },
  {
    "text": "actually mixes\ntogether things that",
    "start": "514720",
    "end": "516579"
  },
  {
    "text": "are mixed sentiment\nand things that",
    "start": "516580",
    "end": "518740"
  },
  {
    "text": "are highly uncertain about the\nsentiment that is expressed,",
    "start": "518740",
    "end": "521558"
  },
  {
    "text": "for whatever reason.",
    "start": "521559",
    "end": "522510"
  },
  {
    "text": "So you get a lot of borderline\ncases and a lot of cases",
    "start": "522510",
    "end": "525220"
  },
  {
    "text": "where humans are\nkind of inherently",
    "start": "525220",
    "end": "527290"
  },
  {
    "text": "having a hard time agreeing\nabout what the fixed sentiment",
    "start": "527290",
    "end": "530589"
  },
  {
    "text": "label would be.",
    "start": "530590",
    "end": "532440"
  },
  {
    "text": "I think that DynaSent\nis doing a better",
    "start": "532440",
    "end": "534190"
  },
  {
    "text": "job of capturing some\nnotion of neutral",
    "start": "534190",
    "end": "536380"
  },
  {
    "text": "in these labels over here.",
    "start": "536380",
    "end": "537880"
  },
  {
    "text": "And we should be a little wary\nof treating three-star reviews",
    "start": "537880",
    "end": "540970"
  },
  {
    "text": "and things like that as a\ntrue proxy for neutrality.",
    "start": "540970",
    "end": "546329"
  },
  {
    "text": "This is a good point to signal\nthat the validation and test",
    "start": "546330",
    "end": "549580"
  },
  {
    "text": "sets for the bake off of\nthe restaurant sentences",
    "start": "549580",
    "end": "553330"
  },
  {
    "text": "were validated in the\nsame way as DynaSent.",
    "start": "553330",
    "end": "556540"
  },
  {
    "text": "So those sentences will have\nthe same kind of neutrality",
    "start": "556540",
    "end": "559930"
  },
  {
    "text": "that DynaSent has,\nwhich could be opposed",
    "start": "559930",
    "end": "562750"
  },
  {
    "text": "to the sense of neutrality\nthat you get from the Stanford",
    "start": "562750",
    "end": "565240"
  },
  {
    "text": "Sentiment Treebank, which\nwas, of course, underlying we",
    "start": "565240",
    "end": "567970"
  },
  {
    "text": "kind of gathered in\nthis setting of having",
    "start": "567970",
    "end": "570040"
  },
  {
    "text": "a fixed five-star rating scale.",
    "start": "570040",
    "end": "574540"
  },
  {
    "text": "So that's round 1.",
    "start": "574540",
    "end": "575440"
  },
  {
    "text": "That's all naturally\noccurring sentences.",
    "start": "575440",
    "end": "577240"
  },
  {
    "start": "576000",
    "end": "594000"
  },
  {
    "text": "Let's turn to round 2.",
    "start": "577240",
    "end": "578560"
  },
  {
    "text": "So recall that we benefit\nfrom round 1 at this point",
    "start": "578560",
    "end": "581140"
  },
  {
    "text": "by training a brand new model\non all those external datasets",
    "start": "581140",
    "end": "584230"
  },
  {
    "text": "plus the round 1 dataset.",
    "start": "584230",
    "end": "586269"
  },
  {
    "text": "And then we have workers\non Dynabench interact",
    "start": "586270",
    "end": "589450"
  },
  {
    "text": "with this model\nto try to fool it.",
    "start": "589450",
    "end": "591430"
  },
  {
    "text": "And we validate the\nresulting sentences",
    "start": "591430",
    "end": "593320"
  },
  {
    "text": "to get our round 2 data set.",
    "start": "593320",
    "end": "595150"
  },
  {
    "start": "594000",
    "end": "681000"
  },
  {
    "text": "So Model 1 is, again, a\nRoBERTa-based classifier.",
    "start": "595150",
    "end": "597582"
  },
  {
    "text": "What we've done for\nour training here is,",
    "start": "597582",
    "end": "599290"
  },
  {
    "text": "more or less, carry over what\nwe did for the first round.",
    "start": "599290",
    "end": "602560"
  },
  {
    "text": "Except, we have upsampled the\nSST to give it more weight.",
    "start": "602560",
    "end": "605990"
  },
  {
    "text": "And we have\ndramatically upsampled",
    "start": "605990",
    "end": "607870"
  },
  {
    "text": "the distributional labels\nfrom our round 1 dataset,",
    "start": "607870",
    "end": "610930"
  },
  {
    "text": "effectively, trying to\ngive it equal weight as all",
    "start": "610930",
    "end": "613839"
  },
  {
    "text": "of these other datasets combined\nin the training procedure.",
    "start": "613840",
    "end": "616690"
  },
  {
    "text": "So we're trying to get a\nmodel that, as a priority,",
    "start": "616690",
    "end": "619810"
  },
  {
    "text": "does really well on\nour round one dataset.",
    "start": "619810",
    "end": "623700"
  },
  {
    "text": "Here is a look at the\nperformance of this model.",
    "start": "623700",
    "end": "626940"
  },
  {
    "text": "And first, I would\njust note that it's",
    "start": "626940",
    "end": "628560"
  },
  {
    "text": "doing well on round 1.",
    "start": "628560",
    "end": "629800"
  },
  {
    "text": "We're at about 81%, which\nis a little below humans",
    "start": "629800",
    "end": "633330"
  },
  {
    "text": "but certainly much better\nthan the chance performance,",
    "start": "633330",
    "end": "635580"
  },
  {
    "text": "by design, that we\nset up for Model 0.",
    "start": "635580",
    "end": "638220"
  },
  {
    "text": "I do want to signal,\nthough, that we",
    "start": "638220",
    "end": "639720"
  },
  {
    "text": "have a kind of\ndrop in performance",
    "start": "639720",
    "end": "641399"
  },
  {
    "text": "for a few of these categories.",
    "start": "641400",
    "end": "642930"
  },
  {
    "text": "You can see that especially\nfor Yelp and Amazon,",
    "start": "642930",
    "end": "645149"
  },
  {
    "text": "where Model 0 was at about,\nfor example, 80 here.",
    "start": "645150",
    "end": "648930"
  },
  {
    "text": "Model 1 dropped down to 73.",
    "start": "648930",
    "end": "650940"
  },
  {
    "text": "And it's a similar\npicture for dev.",
    "start": "650940",
    "end": "652920"
  },
  {
    "text": "And, more or less, that's\nrepeated for Amazon with a drop",
    "start": "652920",
    "end": "655500"
  },
  {
    "text": "from about 76 to 73 and\n77 to 73, similarly.",
    "start": "655500",
    "end": "660820"
  },
  {
    "text": "So we have a trade\noff in performance",
    "start": "660820",
    "end": "662790"
  },
  {
    "text": "that I believe\ntraces to the fact",
    "start": "662790",
    "end": "664680"
  },
  {
    "text": "that we are performing some\nchanges to the underlying",
    "start": "664680",
    "end": "667649"
  },
  {
    "text": "semantics of the labels.",
    "start": "667650",
    "end": "669478"
  },
  {
    "text": "But that's something\nto keep in mind.",
    "start": "669478",
    "end": "671020"
  },
  {
    "text": "And you can see that\nthere's a tension here",
    "start": "671020",
    "end": "672812"
  },
  {
    "text": "as we try to do well at our\ndataset versus continuing",
    "start": "672812",
    "end": "676440"
  },
  {
    "text": "to do well on these fixed\nexternal benchmarks.",
    "start": "676440",
    "end": "681240"
  },
  {
    "start": "681000",
    "end": "688000"
  },
  {
    "text": "Here is the Dynabench interface.",
    "start": "681240",
    "end": "682573"
  },
  {
    "text": "And there's one thing that\nI want to note about it.",
    "start": "682573",
    "end": "684698"
  },
  {
    "text": "This is the stock interface.",
    "start": "684698",
    "end": "685920"
  },
  {
    "text": "But we've actually\nconcentrated on a condition",
    "start": "685920",
    "end": "688200"
  },
  {
    "start": "688000",
    "end": "768000"
  },
  {
    "text": "that we call the prompt\ncondition, where workers,",
    "start": "688200",
    "end": "690930"
  },
  {
    "text": "instead of having to just write\na sentence as a blank slate,",
    "start": "690930",
    "end": "693990"
  },
  {
    "text": "sit down to an empty buffer\nand try to fool the model,",
    "start": "693990",
    "end": "696870"
  },
  {
    "text": "they were given an\ninspirational prompt, which",
    "start": "696870",
    "end": "698970"
  },
  {
    "text": "was an attested sentence from\nthe Yelp academic data set,",
    "start": "698970",
    "end": "702329"
  },
  {
    "text": "and invited to modify that\nsentence if they chose in order",
    "start": "702330",
    "end": "705510"
  },
  {
    "text": "to achieve their goal of fooling\nthe model in a particular way.",
    "start": "705510",
    "end": "709140"
  },
  {
    "text": "And this proved to be\nvastly more productive.",
    "start": "709140",
    "end": "711015"
  },
  {
    "text": "It led to more diverse\nand realistic sentences.",
    "start": "711015",
    "end": "714060"
  },
  {
    "text": "I think we've essentially\nfreed the crowd workers",
    "start": "714060",
    "end": "716610"
  },
  {
    "text": "from the creative burden of\nhaving each time to come up",
    "start": "716610",
    "end": "720000"
  },
  {
    "text": "with a completely new sentence.",
    "start": "720000",
    "end": "721500"
  },
  {
    "text": "And we're hoping that\nthis procedure leads",
    "start": "721500",
    "end": "723750"
  },
  {
    "text": "to fewer artifacts,\nmore diversity, and more",
    "start": "723750",
    "end": "726810"
  },
  {
    "text": "realism for this adversarial\ndataset collection procedure.",
    "start": "726810",
    "end": "732610"
  },
  {
    "text": "Our validation pipeline was\nexactly the same as round 1.",
    "start": "732610",
    "end": "735970"
  },
  {
    "text": "And here is the\nresulting data set.",
    "start": "735970",
    "end": "737569"
  },
  {
    "text": "It's a little bit\nsmaller because this kind",
    "start": "737570",
    "end": "739362"
  },
  {
    "text": "of adversarial dataset\ncollection is hard.",
    "start": "739362",
    "end": "741460"
  },
  {
    "text": "And you can see how\ngood Model 1 is.",
    "start": "741460",
    "end": "743845"
  },
  {
    "text": "It was actually pretty\nhard for crowd workers",
    "start": "743845",
    "end": "745720"
  },
  {
    "text": "to fool this model.",
    "start": "745720",
    "end": "746800"
  },
  {
    "text": "They did so only\nabout 19% of the time.",
    "start": "746800",
    "end": "750279"
  },
  {
    "text": "Here's the dataset for\ndistributional training.",
    "start": "750280",
    "end": "752260"
  },
  {
    "text": "You have about 93,000 sentences.",
    "start": "752260",
    "end": "754540"
  },
  {
    "text": "And if you go for the\nmajority-label training,",
    "start": "754540",
    "end": "756670"
  },
  {
    "text": "you have about 19,000.",
    "start": "756670",
    "end": "758440"
  },
  {
    "text": "And the dev and test\nsets are smaller.",
    "start": "758440",
    "end": "760318"
  },
  {
    "text": "But again, the reason\nthey're smaller",
    "start": "760318",
    "end": "761860"
  },
  {
    "text": "is that they are designed to\nset Model 1 as having chance",
    "start": "761860",
    "end": "765339"
  },
  {
    "text": "performance on this data set.",
    "start": "765340",
    "end": "767615"
  },
  {
    "text": "And so that's what\nI'll flesh out here.",
    "start": "767615",
    "end": "769240"
  },
  {
    "start": "768000",
    "end": "864000"
  },
  {
    "text": "You can see that this\nmodel chance performance,",
    "start": "769240",
    "end": "771630"
  },
  {
    "text": "I showed you before that it's\ndoing pretty well on round one.",
    "start": "771630",
    "end": "774420"
  },
  {
    "text": "And we had that kind of tension\nwith the external benchmarks.",
    "start": "774420",
    "end": "777899"
  },
  {
    "text": "In terms of human\nperformance, we're at about 90",
    "start": "777900",
    "end": "780720"
  },
  {
    "text": "using that procedure\nof synthesized,",
    "start": "780720",
    "end": "783209"
  },
  {
    "text": "kind of averaged F1 values.",
    "start": "783210",
    "end": "785495"
  },
  {
    "text": "And I would just note,\nagain, that that's certainly",
    "start": "785495",
    "end": "787620"
  },
  {
    "text": "conservative.",
    "start": "787620",
    "end": "788400"
  },
  {
    "text": "In that, almost\nhalf of the workers",
    "start": "788400",
    "end": "790740"
  },
  {
    "text": "never disagreed with\nthe majority label.",
    "start": "790740",
    "end": "792930"
  },
  {
    "text": "So it is certainly within the\ncapacity of individual humans",
    "start": "792930",
    "end": "796350"
  },
  {
    "text": "to perform essentially\nperfectly on this data set.",
    "start": "796350",
    "end": "799500"
  },
  {
    "text": "But 90 is, nonetheless,\na good signpost for us",
    "start": "799500",
    "end": "802230"
  },
  {
    "text": "as we think about hill\nclimbing and launching",
    "start": "802230",
    "end": "804449"
  },
  {
    "text": "subsequent rounds of DynaSent.",
    "start": "804450",
    "end": "806670"
  },
  {
    "text": "And here are some\nshort examples.",
    "start": "806670",
    "end": "808079"
  },
  {
    "text": "And I think they\nmake the same point",
    "start": "808080",
    "end": "809580"
  },
  {
    "text": "that our neutral category is\nmore aligned with the semantics",
    "start": "809580",
    "end": "812160"
  },
  {
    "text": "of what we mean when we\nidentify neutral sentences",
    "start": "812160",
    "end": "814470"
  },
  {
    "text": "and less heterogeneous than you\nget from naturally occurring,",
    "start": "814470",
    "end": "818610"
  },
  {
    "text": "neutral sentences derived\nfrom star rating metadata",
    "start": "818610",
    "end": "821100"
  },
  {
    "text": "and so forth.",
    "start": "821100",
    "end": "821949"
  },
  {
    "text": "So I'm hopeful\nthat this is a kind",
    "start": "821950",
    "end": "823470"
  },
  {
    "text": "of positive step toward\ngetting true ternary sentiment.",
    "start": "823470",
    "end": "826709"
  },
  {
    "text": "But we should be aware\nthat this label shift has",
    "start": "826710",
    "end": "829260"
  },
  {
    "text": "happened in these data sets.",
    "start": "829260",
    "end": "831140"
  },
  {
    "text": "And the final thing I want to\nsay is just to reiterate that,",
    "start": "831140",
    "end": "833640"
  },
  {
    "text": "if people do exciting\nwork with this dataset",
    "start": "833640",
    "end": "835950"
  },
  {
    "text": "and start to make real progress\non the existing rounds, that",
    "start": "835950",
    "end": "839430"
  },
  {
    "text": "would be our cue to\nlaunch new rounds.",
    "start": "839430",
    "end": "841649"
  },
  {
    "text": "The Dyna in DynaSent\nis that we would",
    "start": "841650",
    "end": "843930"
  },
  {
    "text": "like to have an evolving\nbenchmark, not one that's",
    "start": "843930",
    "end": "846300"
  },
  {
    "text": "static but rather\nresponsive to progress",
    "start": "846300",
    "end": "848700"
  },
  {
    "text": "that's made in the field\nand the evolving needs",
    "start": "848700",
    "end": "851100"
  },
  {
    "text": "of people who are trying to\ndevelop practical sentiment",
    "start": "851100",
    "end": "853709"
  },
  {
    "text": "analysis systems.",
    "start": "853710",
    "end": "855210"
  },
  {
    "text": "So do let us know what\nkind of progress you make",
    "start": "855210",
    "end": "858000"
  },
  {
    "text": "and what you discover.",
    "start": "858000",
    "end": "859910"
  },
  {
    "start": "859910",
    "end": "864000"
  }
]
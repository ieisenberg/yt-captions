[
  {
    "start": "0",
    "end": "180000"
  },
  {
    "text": "Our next application of",
    "start": "4250",
    "end": "6795"
  },
  {
    "text": "multi-objective least squares is something called regularized data fitting.",
    "start": "6795",
    "end": "10490"
  },
  {
    "text": "It's a very powerful method to improve, uh, fitting models.",
    "start": "10490",
    "end": "15584"
  },
  {
    "text": "So let's start with the motivation.",
    "start": "15585",
    "end": "18060"
  },
  {
    "text": "So let's consider fitting a data model, uh uh ,",
    "start": "18060",
    "end": "21740"
  },
  {
    "text": "that of some relationship that we guess holds like,",
    "start": "21740",
    "end": "24660"
  },
  {
    "text": "you know, y is about equal to f of x,",
    "start": "24660",
    "end": "26369"
  },
  {
    "text": "f is some unknown function.",
    "start": "26370",
    "end": "27990"
  },
  {
    "text": "And what we'll do is we'll use a linear in",
    "start": "27990",
    "end": "29910"
  },
  {
    "text": "the parameters model, and that looks like this.",
    "start": "29910",
    "end": "31785"
  },
  {
    "text": "We will choose, um,",
    "start": "31785",
    "end": "34005"
  },
  {
    "text": "basis functions f_1 through f_p of x. Um,",
    "start": "34005",
    "end": "37980"
  },
  {
    "text": "and then what we'll do then is we'll fit to the data, uh,",
    "start": "37980",
    "end": "41975"
  },
  {
    "text": "the parameters in the model, uh,",
    "start": "41975",
    "end": "44420"
  },
  {
    "text": "that multiply these basis functions,",
    "start": "44420",
    "end": "45995"
  },
  {
    "text": "that's going to be Theta_1 up to Theta_p here.",
    "start": "45995",
    "end": "48774"
  },
  {
    "text": "So that's a- that's going to be th- the idea.",
    "start": "48775",
    "end": "51960"
  },
  {
    "text": "And we're going to assume here that f_1 of x is 1.",
    "start": "51960",
    "end": "54920"
  },
  {
    "text": "It's the constant, that's very- that's very common.",
    "start": "54920",
    "end": "56839"
  },
  {
    "text": "And that means that this first term in the model is just Theta_1.",
    "start": "56840",
    "end": "59900"
  },
  {
    "text": "People refer to that as the offset in the model.",
    "start": "59900",
    "end": "62635"
  },
  {
    "text": "Okay. Now recall that one- one interpretation of what Theta_i is- is,",
    "start": "62635",
    "end": "68570"
  },
  {
    "text": "it's how sensitive our prediction f hat of x is to f_i of x. Um, so for example,",
    "start": "68570",
    "end": "75200"
  },
  {
    "text": "if I told you that Theta_3 equals 0,",
    "start": "75200",
    "end": "79534"
  },
  {
    "text": "you would conclude that in fact,",
    "start": "79535",
    "end": "82190"
  },
  {
    "text": "f_3 of x has no effect whatsoever on our prediction.",
    "start": "82190",
    "end": "86315"
  },
  {
    "text": "Um, on the other hand, if Theta_4 were for example, extremely large,",
    "start": "86315",
    "end": "90485"
  },
  {
    "text": "that would mean that for just small changes in- for very small changes in f_4 of x,",
    "start": "90485",
    "end": "96510"
  },
  {
    "text": "uh, in the fourth,",
    "start": "96510",
    "end": "98130"
  },
  {
    "text": "um, uh, basis function.",
    "start": "98130",
    "end": "100680"
  },
  {
    "text": "Um, very small changes that would lead to very big changes in the prediction.",
    "start": "100680",
    "end": "106610"
  },
  {
    "text": "Um, in other words, it would be very sensitive,",
    "start": "106610",
    "end": "108769"
  },
  {
    "text": "our prediction would be very sensitive.",
    "start": "108769",
    "end": "110545"
  },
  {
    "text": "Now, the idea here is that that's a bad idea.",
    "start": "110545",
    "end": "114530"
  },
  {
    "text": "Um, oh, I should mention one thing.",
    "start": "114530",
    "end": "116735"
  },
  {
    "text": "There is an exception.",
    "start": "116735",
    "end": "118085"
  },
  {
    "text": "If we looked at Theta- if we look at i equals 1, Theta_1 multiplies, uh,",
    "start": "118085",
    "end": "123555"
  },
  {
    "text": "something, uh, a- a- a basis function",
    "start": "123555",
    "end": "126930"
  },
  {
    "text": "that's constant and- which is absolutely constant, it doesn't change.",
    "start": "126930",
    "end": "130490"
  },
  {
    "text": "So Theta_1, which is the offset in the model,",
    "start": "130490",
    "end": "133835"
  },
  {
    "text": "cannot, you know, we don't interpret that as a sensitivity.",
    "start": "133835",
    "end": "137560"
  },
  {
    "text": "Okay. So the conclusion of all this,",
    "start": "137560",
    "end": "140280"
  },
  {
    "text": "and this is ex- all very rough.",
    "start": "140280",
    "end": "141709"
  },
  {
    "text": "It's just basic intuition insists is,",
    "start": "141710",
    "end": "144170"
  },
  {
    "text": "we do not want Theta_2 up to Theta_p to be large.",
    "start": "144170",
    "end": "148075"
  },
  {
    "text": "Um, and if someone says,",
    "start": "148075",
    "end": "150120"
  },
  {
    "text": "\"Why don't you want them to be large?\"",
    "start": "150120",
    "end": "151409"
  },
  {
    "text": "You say, \"Well, that makes- the larger they are,",
    "start": "151410",
    "end": "153530"
  },
  {
    "text": "the more sensitive my model is to what the values of these,",
    "start": "153530",
    "end": "156530"
  },
  {
    "text": "um, basis functions is.\"",
    "start": "156530",
    "end": "158610"
  },
  {
    "text": "Okay. That's the idea.",
    "start": "158610",
    "end": "159675"
  },
  {
    "text": "Well, we don't care about Theta_1.",
    "start": "159675",
    "end": "160850"
  },
  {
    "text": "Theta_ 1 is can be whatever it wants to be.",
    "start": "160850",
    "end": "163430"
  },
  {
    "text": "Okay? This is all vague,",
    "start": "163430",
    "end": "164900"
  },
  {
    "text": "but this is the motivation for regularization.",
    "start": "164900",
    "end": "167170"
  },
  {
    "text": "And so what we're gonna do in regularization is- is just to have two objectives.",
    "start": "167170",
    "end": "171275"
  },
  {
    "text": "One is going to be the traditional least squares fit uh, on- on your data.",
    "start": "171275",
    "end": "175894"
  },
  {
    "text": "And the second is gonna be that we would like Theta_2 to Theta_p to be small.",
    "start": "175895",
    "end": "180505"
  },
  {
    "start": "180000",
    "end": "443000"
  },
  {
    "text": "Okay. So let's suppose we have a- a- a training dataset.",
    "start": "180505",
    "end": "185850"
  },
  {
    "text": "Um, and what we're gonna do is we are going to express",
    "start": "185850",
    "end": "189965"
  },
  {
    "text": "the error on this training dataset as ATheta minus y.",
    "start": "189965",
    "end": "194349"
  },
  {
    "text": "These are capital N vectors, uh, here.",
    "start": "194350",
    "end": "196845"
  },
  {
    "text": "So, uh, these are the N vectors consisting",
    "start": "196845",
    "end": "199575"
  },
  {
    "text": "of y_1 through y_n on the right-hand side, that's this one.",
    "start": "199575",
    "end": "203220"
  },
  {
    "text": "And, um, and this-on the l- this thing is y hat evaluated at x_1 up to x_n.",
    "start": "203220",
    "end": "210840"
  },
  {
    "text": "Okay. And the matrix A remember is",
    "start": "210840",
    "end": "213605"
  },
  {
    "text": "something like the basis functions evaluated at the data points.",
    "start": "213605",
    "end": "216800"
  },
  {
    "text": "All right. So, uh,",
    "start": "216800",
    "end": "218540"
  },
  {
    "text": "regularized data fitting goes like this.",
    "start": "218540",
    "end": "220715"
  },
  {
    "text": "You start- the primary objective is usually least squares objective, it's this.",
    "start": "220715",
    "end": "225614"
  },
  {
    "text": "That, [NOISE] that's the sum of the squares- of the prediction errors.",
    "start": "225615",
    "end": "229425"
  },
  {
    "text": "So that's- we obviously want that small.",
    "start": "229425",
    "end": "231660"
  },
  {
    "text": "And in fact, in least squares,",
    "start": "231660",
    "end": "233330"
  },
  {
    "text": "simple least squares data fitting,",
    "start": "233330",
    "end": "234935"
  },
  {
    "text": "you simply make that small.",
    "start": "234935",
    "end": "236495"
  },
  {
    "text": "That's what least squares data fitting is.",
    "start": "236495",
    "end": "238644"
  },
  {
    "text": "We're gonna add- we're gonna make a bi-criterion problem,",
    "start": "238645",
    "end": "241800"
  },
  {
    "text": "we're gonna add a second- a second objective.",
    "start": "241800",
    "end": "243900"
  },
  {
    "text": "And the second is, this one says,",
    "start": "243900",
    "end": "246095"
  },
  {
    "text": "this is the obj- this is the- the- the,",
    "start": "246095",
    "end": "249110"
  },
  {
    "text": "um, sum square o- of the prediction errors.",
    "start": "249110",
    "end": "252865"
  },
  {
    "text": "This one says at the same time,",
    "start": "252865",
    "end": "254975"
  },
  {
    "text": "I would like the coefficients Theta_2 up to Theta_p to be small, then we do this.",
    "start": "254975",
    "end": "259730"
  },
  {
    "text": "And Lambda is called the regularization parameter here.",
    "start": "259730",
    "end": "262895"
  },
  {
    "text": "This is called regularizing the data fit- data fitting procedure.",
    "start": "262895",
    "end": "267190"
  },
  {
    "text": "Okay. Um, we'll talk about how you would choose Lambda, uh, in a minute.",
    "start": "267190",
    "end": "273165"
  },
  {
    "text": "Um, now, for a regression model,",
    "start": "273165",
    "end": "276405"
  },
  {
    "text": "um, this turns out,",
    "start": "276405",
    "end": "278325"
  },
  {
    "text": "uh, this has a very simple look.",
    "start": "278325",
    "end": "280095"
  },
  {
    "text": "Um, it simply here y hat is explicitly x transpose,",
    "start": "280095",
    "end": "284300"
  },
  {
    "text": "Beta x is the, uh,",
    "start": "284300",
    "end": "285875"
  },
  {
    "text": "data matrix plus Nu times 1.",
    "start": "285875",
    "end": "289020"
  },
  {
    "text": "Uh, that's the one- the vector of all ones here.",
    "start": "289020",
    "end": "292085"
  },
  {
    "text": "And what we minimize is this,",
    "start": "292085",
    "end": "293630"
  },
  {
    "text": "that's- that's the vector of y hats.",
    "start": "293630",
    "end": "296090"
  },
  {
    "text": "Um, and then here what we do is Theta_1 is v. And we don't- that we don't regularize,",
    "start": "296090",
    "end": "303680"
  },
  {
    "text": "but we do regularize the other which is Beta.",
    "start": "303680",
    "end": "305840"
  },
  {
    "text": "So we simply make this thing up here.",
    "start": "305840",
    "end": "308105"
  },
  {
    "text": "Now, here let's mention a couple of things of what happens, right?",
    "start": "308105",
    "end": "311450"
  },
  {
    "text": "When, um, when Lambda is 0,",
    "start": "311450",
    "end": "314745"
  },
  {
    "text": "you recover just least squares data fitting, period, that's it.",
    "start": "314745",
    "end": "317580"
  },
  {
    "text": "You just- you minimize the sum of the squares of the prediction errors. End of story.",
    "start": "317580",
    "end": "321289"
  },
  {
    "text": "When Lambda gets really big, this whole thing,",
    "start": "321290",
    "end": "325225"
  },
  {
    "text": "it- you're basically- you're basically saying I put a huge cost",
    "start": "325225",
    "end": "329285"
  },
  {
    "text": "on- on having the coefficients Theta_2 to Theta_p being non-zero.",
    "start": "329285",
    "end": "333725"
  },
  {
    "text": "And so basically as Lambda goes to infinity,",
    "start": "333725",
    "end": "336370"
  },
  {
    "text": "Theta goes to, uh,",
    "start": "336370",
    "end": "338639"
  },
  {
    "text": "that Theta_2 to p goes to- goes to 0.",
    "start": "338640",
    "end": "341595"
  },
  {
    "text": "And Theta_1, uh, actually is going to go to the mean of the data.",
    "start": "341595",
    "end": "345935"
  },
  {
    "text": "Because what it means is that when Lambda is really big,",
    "start": "345935",
    "end": "348845"
  },
  {
    "text": "this reverts to the constant model.",
    "start": "348845",
    "end": "352220"
  },
  {
    "text": "And remember that the best constant model of,",
    "start": "352220",
    "end": "354920"
  },
  {
    "text": "uh, some data is the mean.",
    "start": "354920",
    "end": "356810"
  },
  {
    "text": "Um, and by the way,",
    "start": "356810",
    "end": "358340"
  },
  {
    "text": "the mean-square prediction error is the, uh,",
    "start": "358340",
    "end": "361610"
  },
  {
    "text": "the- is the square of the RMS value of y.",
    "start": "361610",
    "end": "365389"
  },
  {
    "text": "Okay. So that's- that's what that does.",
    "start": "365390",
    "end": "368235"
  },
  {
    "text": "Oh, ah, another word for regularization is shrinkage.",
    "start": "368235",
    "end": "371675"
  },
  {
    "text": "That's used in statistics.",
    "start": "371675",
    "end": "373354"
  },
  {
    "text": "And the reason is pretty clear,",
    "start": "373355",
    "end": "375680"
  },
  {
    "text": "what it does is this serves to shrink the coefficients,",
    "start": "375680",
    "end": "379509"
  },
  {
    "text": "uh, to make them smaller than they would be if you didn't have that term.",
    "start": "379510",
    "end": "383665"
  },
  {
    "text": "Okay. Now, how do you choose Lambda?",
    "start": "383665",
    "end": "386790"
  },
  {
    "text": "We- well, here there's a very good way to do it.",
    "start": "386790",
    "end": "389180"
  },
  {
    "text": "What you typically do is you would actually",
    "start": "389180",
    "end": "391370"
  },
  {
    "text": "build your model this way and you- you'd work this, you know,",
    "start": "391370",
    "end": "393919"
  },
  {
    "text": "you do this for 20-30 different values of Lambda, um,",
    "start": "393920",
    "end": "396900"
  },
  {
    "text": "traditionally and just as a practical matter,",
    "start": "396900",
    "end": "399050"
  },
  {
    "text": "those are spread over a very large range,",
    "start": "399050",
    "end": "401495"
  },
  {
    "text": "and they're also typically logarithmically spaced.",
    "start": "401495",
    "end": "404185"
  },
  {
    "text": "Um, so you would work out,",
    "start": "404185",
    "end": "406130"
  },
  {
    "text": "you'd get 20 different models, 30,",
    "start": "406130",
    "end": "408020"
  },
  {
    "text": "something like that, with different values of Lambda,",
    "start": "408020",
    "end": "409940"
  },
  {
    "text": "you get a completely different model.",
    "start": "409940",
    "end": "411997"
  },
  {
    "text": "Then what you do is you go and take that model and you",
    "start": "411997",
    "end": "414730"
  },
  {
    "text": "evaluate every single one of those on the test data set.",
    "start": "414730",
    "end": "418265"
  },
  {
    "text": "And then you look for, uh,",
    "start": "418265",
    "end": "420745"
  },
  {
    "text": "you look for the point which has the best test error.",
    "start": "420745",
    "end": "423895"
  },
  {
    "text": "Um, actually honestly what people do a lot of times is",
    "start": "423895",
    "end": "426460"
  },
  {
    "text": "they choose lambda a little bit bigger than that,",
    "start": "426460",
    "end": "429039"
  },
  {
    "text": "because all other things being equal, uh,",
    "start": "429040",
    "end": "431380"
  },
  {
    "text": "the larger lambda is kind of the smaller that theta two to P is,",
    "start": "431380",
    "end": "435355"
  },
  {
    "text": "and therefore the less sensitive your model is, right?",
    "start": "435355",
    "end": "438755"
  },
  {
    "text": "And that's just always a good thing,",
    "start": "438755",
    "end": "440290"
  },
  {
    "text": "to have an insensitive model.",
    "start": "440290",
    "end": "441850"
  },
  {
    "text": "Okay. [NOISE] So we're gonna look at an example,",
    "start": "441850",
    "end": "445180"
  },
  {
    "start": "443000",
    "end": "534000"
  },
  {
    "text": "it's a very simple example.",
    "start": "445180",
    "end": "446680"
  },
  {
    "text": "Um, it goes like this,",
    "start": "446680",
    "end": "448360"
  },
  {
    "text": "um, we have, uh, a, um,",
    "start": "448360",
    "end": "451449"
  },
  {
    "text": "we have a truth- in this case it's all made up,",
    "start": "451450",
    "end": "453880"
  },
  {
    "text": "so we have a truth function,",
    "start": "453880",
    "end": "455105"
  },
  {
    "text": "f y equals f of x,",
    "start": "455105",
    "end": "456685"
  },
  {
    "text": "um, actually, plus a little bit of noise.",
    "start": "456685",
    "end": "459220"
  },
  {
    "text": "Um, so the truth function is this uh,",
    "start": "459220",
    "end": "462715"
  },
  {
    "text": "something that has this form with a sinusoid, okay?",
    "start": "462715",
    "end": "465100"
  },
  {
    "text": "With certain values of theta 1 up to theta 5, okay?",
    "start": "465100",
    "end": "468445"
  },
  {
    "text": "So theta- so we- we generate it,",
    "start": "468445",
    "end": "470395"
  },
  {
    "text": "and this black curve shows that,",
    "start": "470395",
    "end": "472435"
  },
  {
    "text": "um, the training data is not much, actually it's crazy.",
    "start": "472435",
    "end": "477040"
  },
  {
    "text": "It's these blue dots,",
    "start": "477040",
    "end": "478280"
  },
  {
    "text": "so it has just a couple, 1,",
    "start": "478280",
    "end": "480040"
  },
  {
    "text": "2, 3, 4, 5,",
    "start": "480040",
    "end": "481840"
  },
  {
    "text": "6, 7, 8, 9, 10.",
    "start": "481840",
    "end": "483895"
  },
  {
    "text": "So we're gonna train on- on those points.",
    "start": "483895",
    "end": "486504"
  },
  {
    "text": "Now, look, let me make a couple of things pretty clear here um,",
    "start": "486505",
    "end": "490810"
  },
  {
    "text": "for those blue points.",
    "start": "490810",
    "end": "492235"
  },
  {
    "text": "Um, notice that we don't have any data suggesting this big dip in the function.",
    "start": "492235",
    "end": "497110"
  },
  {
    "text": "Not a bit. We don't have any data [LAUGHTER] suggesting it goes like that.",
    "start": "497110",
    "end": "502189"
  },
  {
    "text": "Um, so I- I mean,",
    "start": "502190",
    "end": "505295"
  },
  {
    "text": "this is pretty crazy, uh, to- to- uh,",
    "start": "505295",
    "end": "507880"
  },
  {
    "text": "to- to- to fit this.",
    "start": "507880",
    "end": "509575"
  },
  {
    "text": "Um, okay.",
    "start": "509575",
    "end": "510970"
  },
  {
    "text": "So what we're gonna do is uh,",
    "start": "510970",
    "end": "512969"
  },
  {
    "text": "we'll- we'll fit - we'll fit a model using the- the uh, train,",
    "start": "512970",
    "end": "517599"
  },
  {
    "text": "the blue point- 10 blue points,",
    "start": "517600",
    "end": "519055"
  },
  {
    "text": "and we'll evaluate it on the 20 points which are the red points, okay?",
    "start": "519055",
    "end": "523520"
  },
  {
    "text": "Um, and the model is gonna have uh, this form.",
    "start": "523520",
    "end": "526690"
  },
  {
    "text": "Um, and it doesn't matter that the basis functions are sinusoid- are sinusoids.",
    "start": "526690",
    "end": "530735"
  },
  {
    "text": "It just- it just doesn't- that's not relevant.",
    "start": "530735",
    "end": "533089"
  },
  {
    "text": "Okay. So here's what happens,",
    "start": "533090",
    "end": "536045"
  },
  {
    "start": "534000",
    "end": "854000"
  },
  {
    "text": "and this is something actually you have- take a-",
    "start": "536045",
    "end": "537925"
  },
  {
    "text": "you have to take a good look at it to kind of figure out,",
    "start": "537925",
    "end": "539980"
  },
  {
    "text": "make sure what- that works.",
    "start": "539980",
    "end": "541745"
  },
  {
    "text": "Um, now when lambda is super small over here,",
    "start": "541745",
    "end": "544779"
  },
  {
    "text": "we're basically doing least squares.",
    "start": "544780",
    "end": "547405"
  },
  {
    "text": "That's it, least square data fitting.",
    "start": "547405",
    "end": "549365"
  },
  {
    "text": "And it's not bad, you know,",
    "start": "549365",
    "end": "551080"
  },
  {
    "text": "we get, you know, um,",
    "start": "551080",
    "end": "552790"
  },
  {
    "text": "I don't know what that is,",
    "start": "552790",
    "end": "554019"
  },
  {
    "text": "like that's about 0.2,",
    "start": "554020",
    "end": "555695"
  },
  {
    "text": "so that's about 0.05.",
    "start": "555695",
    "end": "556925"
  },
  {
    "text": "So basically our, um,",
    "start": "556925",
    "end": "559175"
  },
  {
    "text": "RMS error o- on the training, uh,",
    "start": "559175",
    "end": "562060"
  },
  {
    "text": "on- on the training set is quite low,",
    "start": "562060",
    "end": "564390"
  },
  {
    "text": "it's maybe 0.05, um,",
    "start": "564390",
    "end": "566545"
  },
  {
    "text": "on the test set it's 0.2,",
    "start": "566545",
    "end": "569160"
  },
  {
    "text": "um, which is okay, that's what it is.",
    "start": "569160",
    "end": "572014"
  },
  {
    "text": "Um, but then you see something interesting as we",
    "start": "572015",
    "end": "574700"
  },
  {
    "text": "increase lambda that's moving along here, um,",
    "start": "574700",
    "end": "578000"
  },
  {
    "text": "or and you can see this is a good example where I said that we- we would",
    "start": "578000",
    "end": "581285"
  },
  {
    "text": "vary lambda over a very wide range on a logarithmically spaced scale.",
    "start": "581285",
    "end": "585040"
  },
  {
    "text": "Okay. So what happens there is, you know,",
    "start": "585040",
    "end": "588245"
  },
  {
    "text": "basically as you increase lambda,",
    "start": "588245",
    "end": "589900"
  },
  {
    "text": "nothing really happens [LAUGHTER] to the model until around 10 to the minus 1.",
    "start": "589900",
    "end": "593590"
  },
  {
    "text": "And what's happening is the coefficients are now shrinking and of course,",
    "start": "593590",
    "end": "596695"
  },
  {
    "text": "the training error gets worse,",
    "start": "596695",
    "end": "598370"
  },
  {
    "text": "that's how by objective optimization works, right?",
    "start": "598370",
    "end": "601060"
  },
  {
    "text": "That if you- when you- when you crank up lambda,",
    "start": "601060",
    "end": "604590"
  },
  {
    "text": "the second objective gets smaller and the first objective gets bigger.",
    "start": "604590",
    "end": "608755"
  },
  {
    "text": "And indeed it goes up,",
    "start": "608755",
    "end": "609880"
  },
  {
    "text": "and then roughly speaking for lambda bigger than 100 or so.",
    "start": "609880",
    "end": "613790"
  },
  {
    "text": "Thi- this is basically the k- this is just basically the constant model.",
    "start": "613790",
    "end": "618024"
  },
  {
    "text": "Um, so I would presume that these are in fact the,",
    "start": "618025",
    "end": "623630"
  },
  {
    "text": "um, standard deviations of the training the test set.",
    "start": "623630",
    "end": "627910"
  },
  {
    "text": "Okay, so that's that.",
    "start": "627910",
    "end": "629944"
  },
  {
    "text": "Um, but now, let's take- let's focus on and see what happens.",
    "start": "629945",
    "end": "633555"
  },
  {
    "text": "The- the training error,",
    "start": "633555",
    "end": "635630"
  },
  {
    "text": "of course, always g- gets worse as you increase lambda.",
    "start": "635630",
    "end": "638200"
  },
  {
    "text": "Here's something amazing, um,",
    "start": "638200",
    "end": "640460"
  },
  {
    "text": "not amazing, and it kind of makes sense.",
    "start": "640460",
    "end": "642175"
  },
  {
    "text": "Here you see this dip, very characteristic.",
    "start": "642175",
    "end": "645130"
  },
  {
    "text": "Sometimes it's much more,",
    "start": "645130",
    "end": "646450"
  },
  {
    "text": "uh, it's much more pronounced,",
    "start": "646450",
    "end": "647865"
  },
  {
    "text": "that is it, we really get a much better model,",
    "start": "647865",
    "end": "650020"
  },
  {
    "text": "uh, with some regularization.",
    "start": "650020",
    "end": "651470"
  },
  {
    "text": "In this case, you've got a slightly better- uh,",
    "start": "651470",
    "end": "653105"
  },
  {
    "text": "somewhat better model actually with regularization.",
    "start": "653105",
    "end": "656170"
  },
  {
    "text": "And what this does is it suggests you should choose lambda around 0.1.",
    "start": "656170",
    "end": "661610"
  },
  {
    "text": "As I said, um,",
    "start": "661610",
    "end": "663295"
  },
  {
    "text": "sometimes you just take the- the one that gave you the best test error.",
    "start": "663295",
    "end": "666214"
  },
  {
    "text": "But in fact, usually people kind of s-, uh,",
    "start": "666215",
    "end": "668705"
  },
  {
    "text": "skew it to a little bit larger, because,",
    "start": "668705",
    "end": "671350"
  },
  {
    "text": "you know, the more- the less sensitive your model is, the better.",
    "start": "671350",
    "end": "674165"
  },
  {
    "text": "Okay. And- and that's it.",
    "start": "674165",
    "end": "675910"
  },
  {
    "text": "So we choose that value and then what this shows, um,",
    "start": "675910",
    "end": "678649"
  },
  {
    "text": "this is called, uh,",
    "start": "678650",
    "end": "680495"
  },
  {
    "text": "this is called the regularization path.",
    "start": "680495",
    "end": "683500"
  },
  {
    "text": "So here we think of the coefficients theta one through theta five, um,",
    "start": "683500",
    "end": "689850"
  },
  {
    "text": "as being functions of lambda and then that means that they- they-",
    "start": "689850",
    "end": "693190"
  },
  {
    "text": "they trace out a path or a curve.",
    "start": "693190",
    "end": "696895"
  },
  {
    "text": "And so- and we just plot it.",
    "start": "696895",
    "end": "698625"
  },
  {
    "text": "So here's lambda and here you go.",
    "start": "698625",
    "end": "701145"
  },
  {
    "text": "You can see, oh,",
    "start": "701145",
    "end": "702310"
  },
  {
    "text": "I should explain this figure a bit.",
    "start": "702310",
    "end": "704315"
  },
  {
    "text": "The- th- these uh,",
    "start": "704315",
    "end": "706165"
  },
  {
    "text": "dash lines show the- the value- the true value of the parameters.",
    "start": "706165",
    "end": "712055"
  },
  {
    "text": "Now, this is all a completely fake made up data, because, you know,",
    "start": "712055",
    "end": "715620"
  },
  {
    "text": "and so there is such a thing as the true values of the parameters,",
    "start": "715620",
    "end": "718085"
  },
  {
    "text": "they're shown as a dashed lines.",
    "start": "718085",
    "end": "719560"
  },
  {
    "text": "Um, so if your estimation method did really well,",
    "start": "719560",
    "end": "722800"
  },
  {
    "text": "we would be right on top of those dashed lines.",
    "start": "722800",
    "end": "725140"
  },
  {
    "text": "Now, let me point out the model has",
    "start": "725140",
    "end": "727030"
  },
  {
    "text": "five parameters and we- [LAUGHTER] we fit it on 10 data points.",
    "start": "727030",
    "end": "729940"
  },
  {
    "text": "So, you know, that's- we should not expect to do that well,",
    "start": "729940",
    "end": "733935"
  },
  {
    "text": "but nevertheless, here's what happens.",
    "start": "733935",
    "end": "735675"
  },
  {
    "text": "Um, up to about lambda equals, I don't know,",
    "start": "735675",
    "end": "739105"
  },
  {
    "text": "10 to the minus 3 or 2 or something like that,",
    "start": "739105",
    "end": "742125"
  },
  {
    "text": "it's- it's the same.",
    "start": "742125",
    "end": "743930"
  },
  {
    "text": "Something super interesting happens right in here,",
    "start": "743930",
    "end": "746515"
  },
  {
    "text": "right where this is,",
    "start": "746515",
    "end": "747640"
  },
  {
    "text": "which is where we- what we wanna do.",
    "start": "747640",
    "end": "749560"
  },
  {
    "text": "Uh, we think about 0.1, and if we look at- if we go up here and look at 0.1,",
    "start": "749560",
    "end": "753865"
  },
  {
    "text": "you see something actually kind of amazing.",
    "start": "753865",
    "end": "756365"
  },
  {
    "text": "What you see is right at about where that dip in",
    "start": "756365",
    "end": "759610"
  },
  {
    "text": "the red- in- in- in the- in the test error,",
    "start": "759610",
    "end": "763810"
  },
  {
    "text": "uh, dips to its lowest point, right about there,",
    "start": "763810",
    "end": "767045"
  },
  {
    "text": "actually weirdly our parameters kind of get weirdly close to the true parameters.",
    "start": "767045",
    "end": "772750"
  },
  {
    "text": "So that's kind of the idea,",
    "start": "772750",
    "end": "774245"
  },
  {
    "text": "and this is what regularization does.",
    "start": "774245",
    "end": "776160"
  },
  {
    "text": "Um, this is not a very dramatic uh, example.",
    "start": "776160",
    "end": "779250"
  },
  {
    "text": "Sometimes if you have a lot of data,",
    "start": "779250",
    "end": "780730"
  },
  {
    "text": "you don't really need regularization.",
    "start": "780730",
    "end": "782785"
  },
  {
    "text": "But I don't know the um,",
    "start": "782785",
    "end": "784884"
  },
  {
    "text": "so, I've- I've heard friends say things like,",
    "start": "784885",
    "end": "787300"
  },
  {
    "text": "you know, friends don't let friends fit models without regularization, right?",
    "start": "787300",
    "end": "792235"
  },
  {
    "text": "Because it's just a good idea, uh,",
    "start": "792235",
    "end": "794365"
  },
  {
    "text": "to do some regu- and if it turns out they don't need much regularization,",
    "start": "794365",
    "end": "797110"
  },
  {
    "text": "that simply means that you end up choosing, you know,",
    "start": "797110",
    "end": "800360"
  },
  {
    "text": "a value of lambda that's 10 to the minus 5, then that's just 5.",
    "start": "800360",
    "end": "804459"
  },
  {
    "text": "But in many cases it will enhance a model- uh,",
    "start": "804460",
    "end": "806810"
  },
  {
    "text": "the performance of a model very substantially.",
    "start": "806810",
    "end": "809955"
  },
  {
    "text": "All right, so that's regularized uh, data- data fitting.",
    "start": "809955",
    "end": "813575"
  },
  {
    "text": "Um, I- I should say that this is really, uh, you know,",
    "start": "813575",
    "end": "816845"
  },
  {
    "text": "once you know about least squares data fitting with regularization,",
    "start": "816845",
    "end": "821389"
  },
  {
    "text": "your- you're in- you- you- I mean,",
    "start": "821390",
    "end": "824000"
  },
  {
    "text": "you can be very effective at- at building- building models,",
    "start": "824000",
    "end": "827375"
  },
  {
    "text": "um, building prediction models.",
    "start": "827375",
    "end": "829000"
  },
  {
    "text": "And uh, so- I mean,",
    "start": "829000",
    "end": "831245"
  },
  {
    "text": "this is really, uh,",
    "start": "831245",
    "end": "833005"
  },
  {
    "text": "this- this is enough for you to actually go out and really do well at this kind of stuff.",
    "start": "833005",
    "end": "838580"
  },
  {
    "text": "Um, I mean, and there's a whole lot more for you to learn.",
    "start": "838580",
    "end": "841220"
  },
  {
    "text": "Um, a lot of this stuff will be interpreted statistically when you take the- you know,",
    "start": "841220",
    "end": "845415"
  },
  {
    "text": "a course on that and all sorts of other stuff.",
    "start": "845415",
    "end": "847634"
  },
  {
    "text": "But this is kind of the basics.",
    "start": "847635",
    "end": "850450"
  }
]
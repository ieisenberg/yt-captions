[
  {
    "start": "0",
    "end": "148000"
  },
  {
    "text": "Hello, so welcome to the\nnext section of CS 229. So what we're going to talk\nabout in the next series",
    "start": "5150",
    "end": "12200"
  },
  {
    "text": "of about four lectures is the\nstart of unsupervised and kind of less supervised learning,\nand I'll make that concrete.",
    "start": "12200",
    "end": "18700"
  },
  {
    "text": "And kind of the plan is\nwhat you're going to see is you're going to see\na bunch of things that look various different\nways of dealing",
    "start": "18700",
    "end": "25150"
  },
  {
    "text": "with this fundamental\nproblem of what do we do when we don't have labels. So we're first going to look\nat an algorithm called k-means,",
    "start": "25150",
    "end": "31189"
  },
  {
    "text": "and then we're going to\nlook at this algorithm called GMM, this\nGaussian Mixture Model. Those will both happen today.",
    "start": "31189",
    "end": "36500"
  },
  {
    "text": "And we'll try and\nput those algorithms on kind of solid footing in the\nmaximum likelihood framework.",
    "start": "36500",
    "end": "42239"
  },
  {
    "text": "We'll then see a couple\nof more algorithms that have to do with this\nunsupervised way of viewing the world.",
    "start": "42240",
    "end": "47360"
  },
  {
    "text": "One of them you're going to use\nin your homework called ICA. It's actually-- the\nreason I teach it, it's kind of a fun algorithm.",
    "start": "47360",
    "end": "54050"
  },
  {
    "text": "It's a weird bit of\nsetup, but it's probably people's favorite\nhomework problems when we look through\nthe kind of feedback.",
    "start": "54050",
    "end": "60280"
  },
  {
    "text": "It's a fun problem. If you remember the cocktail\nproblem from the first day where you have people\ntalking in a party,",
    "start": "60280",
    "end": "66000"
  },
  {
    "text": "and you have microphones\nscattered around the edge, and you want to\nknow who said what. You want to do what's called\nsometimes source-separation",
    "start": "66000",
    "end": "71939"
  },
  {
    "text": "and understand the sources. So we'll do that\nin the ICA section.",
    "start": "71939",
    "end": "77270"
  },
  {
    "text": "And then we'll talk about\na more advanced topic called weak supervision. Week supervision is industrially\nused to create large training",
    "start": "77270",
    "end": "85700"
  },
  {
    "text": "sets for big, deep learning\nmodels, which you've just come out of that. But these are labels\nthat are lower quality",
    "start": "85700",
    "end": "91048"
  },
  {
    "text": "than the traditional\nsupervised labels. And then finally we'll talk\nabout self-supervised learning,",
    "start": "91049",
    "end": "96060"
  },
  {
    "text": "which is really\nexciting and is one of the big revolutions in\nmachine learning, where we train on something simple\nlike predicting the next word.",
    "start": "96060",
    "end": "103210"
  },
  {
    "text": "And if we train\non enough data, we can use it for all of these\nother-- sometimes called downstream tasks. So that's kind of the program\nfor the next four or five",
    "start": "103210",
    "end": "110100"
  },
  {
    "text": "lectures. And today we're going to\nstart with those basics. So we're going to start with\nthe basics as unsupervised",
    "start": "110100",
    "end": "116450"
  },
  {
    "text": "and work our way up to\npretty modern stuff. And I will say historically-- I would say five\nyears ago, I kind of",
    "start": "116450",
    "end": "123219"
  },
  {
    "text": "didn't like teaching\nunsupervised because it felt kind\nof squishy and weird, to be honest with you. It didn't have the\nbeautiful theory--",
    "start": "123220",
    "end": "128600"
  },
  {
    "text": "or maybe even 10\nyears ago-- didn't have the beautiful theory\nof supervised learning where you could say\nthis is the right model, and we go find it\nin a lot of cases.",
    "start": "128600",
    "end": "135530"
  },
  {
    "text": "But that's been where almost\nall of the research activity, not only in my group\nbut kind of from AI, over the last\nthree or four years",
    "start": "135530",
    "end": "141810"
  },
  {
    "text": "has been in this\nunsupervised realm. So we'll start with\nsome of the classics and get our way to something\nreally, really exciting.",
    "start": "141810",
    "end": "147920"
  },
  {
    "text": "So the classic and\nprobably an algorithm you already know or probably you\ncan guess kind of how it works",
    "start": "147920",
    "end": "153220"
  },
  {
    "start": "148000",
    "end": "517000"
  },
  {
    "text": "is this algorithm\ncalled k-means. And then we'll get\nto these other ones, but this is the one we're\ngoing to start with first.",
    "start": "153220",
    "end": "158540"
  },
  {
    "text": "So what's the difference? So in the supervised\nsetting, we get points. And the key issue is that\nthe points come with labels.",
    "start": "158540",
    "end": "165370"
  },
  {
    "text": "You have labeled these plus and\nthese minus, as we were doing. And we would draw a line or\na boundary in between them.",
    "start": "165370",
    "end": "171110"
  },
  {
    "text": "That was the way we formalized a\nwide variety of learning tasks. And the point is those pluses\nand minuses, those are labels.",
    "start": "171110",
    "end": "181250"
  },
  {
    "text": "And unsupervised\nstarted in this setting. I give you the points, but\nI don't tell you any labels",
    "start": "181250",
    "end": "186870"
  },
  {
    "text": "underneath the covers. Now there are many things\non the spectrum between I give you the labels\nperfectly to I don't show",
    "start": "186870",
    "end": "194780"
  },
  {
    "text": "you any information\nabout the labels, and I just show you\nthe data points. And we're going to talk\nabout that spectrum, but now we're going to start\nin the cleanest setting",
    "start": "194780",
    "end": "200730"
  },
  {
    "text": "in unsupervised where we\njust see those points. Now the thing that you\nshould calibrate here",
    "start": "200730",
    "end": "210040"
  },
  {
    "text": "is, what can we\nexpect as an answer? So in the supervised\nsetting, as I said, it was super clear\nwhat we wanted.",
    "start": "210040",
    "end": "215569"
  },
  {
    "text": "We could talk about\nwhat this line is, and we can go deeper\nand deeper into why that's the right line, right\nthat's the right separating",
    "start": "215569",
    "end": "222030"
  },
  {
    "text": "hyperplane. In the unsupervised case,\nit's necessarily squishy. And we'll talk about the\nways in which it's squishy.",
    "start": "222030",
    "end": "227090"
  },
  {
    "text": "And what I mean by that is\nit's harder in some sense. So unsupervised\nlearning is harder. And what I really mean by that--",
    "start": "227090",
    "end": "234420"
  },
  {
    "text": "than supervised-- what I\nreally mean by that is we have to allow\nstronger assumptions.",
    "start": "234420",
    "end": "242360"
  },
  {
    "text": "Stronger assumptions. So one of the things that kind\nof pass by you without thinking",
    "start": "242360",
    "end": "249260"
  },
  {
    "text": "about it too much in\nthe supervised setting is you're like,\nthere's just some data, and there exists a separator. There exists some class.",
    "start": "249260",
    "end": "255510"
  },
  {
    "text": "That's pretty weak for what we\nhad to assume about the data. For unsupervised,\nwe're going to have to assume there are some kind\nof latent or hidden structure.",
    "start": "255510",
    "end": "262810"
  },
  {
    "text": "And a lot of the\nconversation is, hey, if that structure is there,\ncan I provably recover it? That's the kind of thing\nthat we're going to do.",
    "start": "262810",
    "end": "269130"
  },
  {
    "text": "And we're going\nto trade off kind of assuming more about our data\nand trying to find it robustly. And now compared to\nsupervised, we're",
    "start": "269130",
    "end": "277680"
  },
  {
    "text": "also going to accept\nweaker guarantees. So weaker guarantees.",
    "start": "277680",
    "end": "283200"
  },
  {
    "text": "So in supervised learning,\nand in many cases that we cared about-- weaker guarantees--\nwe would say,",
    "start": "283200",
    "end": "289840"
  },
  {
    "text": "we got exactly the right answer. This was the right model. We could say there\nwere some theta",
    "start": "289840",
    "end": "295340"
  },
  {
    "text": "star out there that was just the\nright thing we were looking at. As we'll see, and I'll come-- I'll show in some\nexamples in a second.",
    "start": "295340",
    "end": "301000"
  },
  {
    "text": "In this unsupervised\nworld, it's not super clear what the right answer\nshould be all the time.",
    "start": "301000",
    "end": "307060"
  },
  {
    "text": "If I just show you\nthis picture and say, how many clusters are there? Some of you say, well,\nthere's two clusters? Some of you say, well,\nwhy aren't there six?",
    "start": "307060",
    "end": "313401"
  },
  {
    "text": "There are six points. Why isn't each one\nin its own cluster? And it we'll see\nin some examples,",
    "start": "313401",
    "end": "318560"
  },
  {
    "text": "It's not really\nclear what there is. We have to make some\nassumption or do some modeling to understand and kind of get\nto the bottom of our data.",
    "start": "318560",
    "end": "325120"
  },
  {
    "text": "And so that's what I mean by\nweaker guarantees and stronger assumptions. And we'll see those\nmathematically, but just keep them in the\nback of your head.",
    "start": "325120",
    "end": "330990"
  },
  {
    "text": "We're going to be more\ncomfortable saying, what if our data are\ngenerated this way? That's going to be a\nstronger assumption. And then we're going to say,\nwe can recover something that's",
    "start": "330990",
    "end": "337880"
  },
  {
    "text": "pretty good some of the time. All right this is\nless jarring to you than it was historically,\nhonestly because historically",
    "start": "337880",
    "end": "345229"
  },
  {
    "text": "we would teach the first\npart of supervised learning without things like neural\nnets and all the rest. And neural nets you kind of\ngot comfortable with the fact",
    "start": "345229",
    "end": "351340"
  },
  {
    "text": "that, hey, maybe it's\ncomputing something useful. Maybe it's not. We don't know. We just run it\nfor a long enough. This used to be a little\nbit more disturbing.",
    "start": "351340",
    "end": "357070"
  },
  {
    "text": "So if you look at\nthe literature, you'll see that in it. So let's start with our\nfirst version of this.",
    "start": "357070",
    "end": "363870"
  },
  {
    "text": "All right, so what\nwe're going to be doing is we're going to\nbe given some data. It's not very-- it\ndoesn't look very nice.",
    "start": "363870",
    "end": "370159"
  },
  {
    "text": "This is our given data-- given. And we have some points. And this is basically me\njust introducing notation",
    "start": "370160",
    "end": "377620"
  },
  {
    "text": "and copying what we\nhad before, all right? We're also, here as I mentioned\nthat stronger structure,",
    "start": "377620",
    "end": "384250"
  },
  {
    "text": "we're going to also be\ngiven a parameter which says how many clusters\nwe think there are. So the game is\ngoing to be-- here",
    "start": "384250",
    "end": "389919"
  },
  {
    "text": "I'm going to write\ndown k is equal to 2. And our goal is that\nwhat we want to do here is find a good clustering.",
    "start": "389919",
    "end": "396060"
  },
  {
    "text": "And so our do is,\nwe want to use two-- I'll use colors here. Apologies. Hopefully it'll be obvious.",
    "start": "396060",
    "end": "402030"
  },
  {
    "text": "You don't need to know\nwhat the colors are. But we'll kind of find\ntwo colors like this. Say like, in what sense is\nthis kind of intuitively good?",
    "start": "402030",
    "end": "407849"
  },
  {
    "text": "This is the same thing we're\ndoing in supervised learning. We're like, this is an\nintuitively good thing. We talked about\ndifferent loss functions.",
    "start": "407849",
    "end": "413810"
  },
  {
    "text": "And you're kind of\nan old hat at that, so you can kind of imagine\nwhat we're going to do. Like, oh, the loss in\nsome way from some object",
    "start": "413810",
    "end": "420560"
  },
  {
    "text": "shouldn't be too far away. Now the k-means is\nhinting at that object is going to be the mean or\nthe center of that cluster.",
    "start": "420560",
    "end": "427310"
  },
  {
    "text": "You kind of want to minimize\nthat center cluster. That's not obvious? We'll come back to it. So this is what we're given.",
    "start": "427310",
    "end": "432729"
  },
  {
    "text": "We're given data. We're given this k parameter. And our goal is to\ncreate some clustering that we're going to talk about. So we need a little\nbit more notation.",
    "start": "432729",
    "end": "440260"
  },
  {
    "text": "Now this guy we'll\ncall at some point x1. We'll call this point, say, x3.",
    "start": "440260",
    "end": "445270"
  },
  {
    "text": "And that's just the\nnotation that's there. I'm going to write the\nnotation formally in a second. But before I do that,\nis it clear kind",
    "start": "445270",
    "end": "450440"
  },
  {
    "text": "of what the setup is? You give me some points. You don't tell me any labels. You'll also tell me how many\nclusters you're looking for.",
    "start": "450440",
    "end": "455730"
  },
  {
    "text": "And then it's my job to find\nthem, find those clusters, and we'll talk about how to\nmake that precise and informal in a second.",
    "start": "455730",
    "end": "461419"
  },
  {
    "text": "Awesome. So I'll just write\ndown some notation. And if there are any\nquestions, please pop in there.",
    "start": "461419",
    "end": "467190"
  },
  {
    "text": "There is one question. Why are you going [INAUDIBLE] I'll show you that notation\nin just one second.",
    "start": "467190",
    "end": "474168"
  },
  {
    "text": "So yeah, let me write\nthe notation down, then I'll come back to\nwhat I'm calling there. Great question. Also on the ed thread--\nsorry that I forgot to do it",
    "start": "474169",
    "end": "480979"
  },
  {
    "text": "earlier-- someone's asking, what\nabout the unknown k case. We'll come back how\nto select k later. Some of our algorithms,\nas we'll see just",
    "start": "480979",
    "end": "487620"
  },
  {
    "text": "to go ahead, some\nof our algorithms will actually have a\nnatural test for k, will be able to basically\ntry all the different ks",
    "start": "487620",
    "end": "494599"
  },
  {
    "text": "and pick one. Some of them will not. And it will be a\nmodeling decision. And let's come back to that\nquestion for how k is unknown.",
    "start": "494599",
    "end": "501150"
  },
  {
    "text": "It's not, by the way,\nit's not super unrealistic that k isn't known. You may know by\nlooking at your data",
    "start": "501150",
    "end": "506220"
  },
  {
    "text": "that roughly you think there\nare about three or four products or something that\npeople are talking about or various different\ntopics, and those",
    "start": "506220",
    "end": "511500"
  },
  {
    "text": "are the kinds of situations you\nwill need kind of k means in. But let's come back to it. Great question on the ed thread.",
    "start": "511500",
    "end": "516789"
  },
  {
    "text": "All right, so let me give\nyou some proper notation so we can actually talk about\nthis maybe a little bit more",
    "start": "516789",
    "end": "522640"
  },
  {
    "start": "517000",
    "end": "710000"
  },
  {
    "text": "mathematically. We won't be super\nheavy on that today. So what we're given in\ngeneral is sum x1 to xn",
    "start": "522640",
    "end": "530399"
  },
  {
    "text": "that live in some vector space. And here we're\ngiven some k which is the number of clusters.",
    "start": "530399",
    "end": "537800"
  },
  {
    "text": "Number of clusters.",
    "start": "537800",
    "end": "543709"
  },
  {
    "text": "We need one bit of\nnotation to do this. So how am I going to make\nthese colors into notation?",
    "start": "543709",
    "end": "549300"
  },
  {
    "text": "Well, I'm going to\nintroduce this thing. We're going to find an assign--\noops-- find an assignment",
    "start": "549300",
    "end": "557560"
  },
  {
    "text": "of points to clusters. Of points to clusters.",
    "start": "557560",
    "end": "566760"
  },
  {
    "text": "So how do we do that\nto the k clusters? So what we're going\nto have is we're going to have a map\nthat's called Ci equals",
    "start": "566760",
    "end": "571970"
  },
  {
    "text": "j means point i to cluster j.",
    "start": "571970",
    "end": "581329"
  },
  {
    "text": "So here i is going\nto run from 1 to n. And j is going to\nbe from 1 to k.",
    "start": "581329",
    "end": "590029"
  },
  {
    "text": "These are the same. This k and this k are the same. So back to this, I was drawing.",
    "start": "590029",
    "end": "595300"
  },
  {
    "text": "I got a little ahead of myself. I started to draw the\nnotation before giving it. This is just saying we can call\nthis point x1, this point x3.",
    "start": "595300",
    "end": "601290"
  },
  {
    "text": "I'm just noting down what\nthe points themselves are. And then what our\ngoal is to find this map that I drew by kind\nof this highlighted color.",
    "start": "601290",
    "end": "609040"
  },
  {
    "text": "And that's going to be\nthe Cik character here. So this is-- I'll highlight it in\nyellow for reasons--",
    "start": "609040",
    "end": "614149"
  },
  {
    "text": "not really sure why\nI picked yellow. So for example, C 3\nequals 2 encodes this fact",
    "start": "614149",
    "end": "625089"
  },
  {
    "text": "that C3 is in cluster 2. And I made the green cluster 2. So point 3 in cluster 2.",
    "start": "625089",
    "end": "633829"
  },
  {
    "text": "OK, this will sound kind\nof opaque at the moment.",
    "start": "633830",
    "end": "640170"
  },
  {
    "text": "But this is a hard assignment. We're saying every point\nbelongs to exactly one cluster. And the reason I'm\nsignaling that is",
    "start": "640170",
    "end": "645399"
  },
  {
    "text": "in the end of the lecture, we'll\ntalk about a soft assignment where we have a different\nversion of this. But that's what this is.",
    "start": "645400",
    "end": "653190"
  },
  {
    "text": "Anything that's obtuse\nabout the setup? All right, let's\nsee an algorithm.",
    "start": "653190",
    "end": "660600"
  },
  {
    "text": "All right, so let\nme copy this piece.",
    "start": "660600",
    "end": "666160"
  },
  {
    "text": "All right, drag it over there.",
    "start": "666160",
    "end": "671920"
  },
  {
    "text": "All right, and get rid\nof these characters because we don't see them. And this is our input.",
    "start": "671920",
    "end": "677750"
  },
  {
    "text": "So the question\nwe want to ask is, how do we find the clusters?",
    "start": "677750",
    "end": "682769"
  },
  {
    "text": "Find the clusters. Now there are many\nways to do this.",
    "start": "682770",
    "end": "688920"
  },
  {
    "text": "And if you're a complexity kind\nof nerd, then you would say, is there a polynomial\ntime algorithm for this?",
    "start": "688920",
    "end": "694959"
  },
  {
    "text": "And the answer is no. Actually it turns out\nthere's an NP hard problem. So we're going to have to use\na heuristic-based algorithm",
    "start": "694959",
    "end": "701420"
  },
  {
    "text": "to do this. And let's see the most natural\nkind of iterative approach here.",
    "start": "701420",
    "end": "709440"
  },
  {
    "text": "So how does it work? OK, so here's the idea. We're going to start by randomly\npicking cluster centers.",
    "start": "709440",
    "end": "717410"
  },
  {
    "text": "And then what we're\ngoing to try and do is the way we're\nthinking about k-means is we're going to try and\nfind our clusters as two--",
    "start": "717410",
    "end": "722660"
  },
  {
    "text": "that are described by\ntwo cluster centers. So intuitively-- let\nme just jump back-- sorry about this-- jump back. We'll kind of try and\nfind a point, say, here",
    "start": "722660",
    "end": "729410"
  },
  {
    "text": "and a point here that\nare good cluster centers. And they're cluster\ncenters in the sense that all the points\nin their cluster",
    "start": "729410",
    "end": "734519"
  },
  {
    "text": "are closer to the center than\nthey are to any other center. And that's how we're going\nto construct our Cij.",
    "start": "734519",
    "end": "742720"
  },
  {
    "text": "So we'll start by\npicking these means. The means we-- where\nare we going to pick?",
    "start": "742720",
    "end": "747910"
  },
  {
    "text": "Well, if we knew where to pick\nthem optimally, we'd be done. So we just pick them\nrandomly to start with. So I'll pick the cluster\ncenter for 2 up here,",
    "start": "747910",
    "end": "755350"
  },
  {
    "text": "and I'll pick the cluster\ncenter for 1 down-- oops. I'm going to use a different\ncolor for deep-seeded reasons.",
    "start": "755350",
    "end": "761870"
  },
  {
    "text": "No, for no reason. I just like different colors. Sound good? So I just picked those points.",
    "start": "761870",
    "end": "767760"
  },
  {
    "text": "Maybe I want to\nmove this one just to make my life a\nlittle bit easier. And delete that,\nand drag it over. You say, why are you\ndragging it over?",
    "start": "767760",
    "end": "773860"
  },
  {
    "text": "Because it's like a cooking\nshow, and I want to make it just look a little nicer\nwhen I draw the pictures.",
    "start": "773860",
    "end": "779779"
  },
  {
    "text": "[INAUDIBLE] list of points\nthat we have, and they can be-- No, were not list of points.",
    "start": "779779",
    "end": "784820"
  },
  {
    "text": "These are just two\nrandom initialized points in the plane. I just randomly\npicked them in RD. We'll talk about a smarter way\nto initialize them in a second.",
    "start": "784820",
    "end": "791480"
  },
  {
    "text": "But just for the moment,\nthey're just random points. They are not points. They do not have to be\npoints in that you are given.",
    "start": "791480",
    "end": "798110"
  },
  {
    "text": "We'll talk about how to\ninitialize them later. And you may not exactly\nwant to do that, but you want to do\nsomething similar.",
    "start": "798110",
    "end": "805110"
  },
  {
    "start": "804000",
    "end": "962000"
  },
  {
    "text": "So let's see how\nthe algorithm runs. So the first thing is,\nwhat would the clustering be if these were the centroids,\nthese were the center points?",
    "start": "805110",
    "end": "811149"
  },
  {
    "text": "Oh, go ahead. Oh, sorry, what is the\nname of the algorithm? k-means. Sorry, yeah, I\nwrote it above it.",
    "start": "811149",
    "end": "818709"
  },
  {
    "text": "This is called k-means. Great question. Please.",
    "start": "818710",
    "end": "823800"
  },
  {
    "text": "How do you-- I guess this is a\nsimple [INAUDIBLE]",
    "start": "823800",
    "end": "830279"
  },
  {
    "text": "So for the moment, k is going\nto be given to us as input. We'll come back,\nas I talked about, about how to select\nk in a minute.",
    "start": "830280",
    "end": "835399"
  },
  {
    "text": "But let's run\nthrough the algorithm once and see how it works. Then we'll talk about what goes\nwrong and how to extend it.",
    "start": "835399",
    "end": "840509"
  },
  {
    "text": "These are wonderful questions,\nreally great questions. Are there others? Awesome.",
    "start": "840509",
    "end": "846329"
  },
  {
    "text": "We'll come back to that. And please, both\nquestions, please come back to those, as I said. All right, so the first thing is\nwe have these randomly centered",
    "start": "846329",
    "end": "852290"
  },
  {
    "text": "cluster points. So this is our first\nstep of the algorithm is that we're randomly\ninitializing cluster points.",
    "start": "852290",
    "end": "858000"
  },
  {
    "text": "Randomly initialize mu Oops, got more than\nI bargained for.",
    "start": "858000",
    "end": "867790"
  },
  {
    "text": "And this one. Paste. So we just randomly initialize\nwhere those characters live.",
    "start": "867790",
    "end": "875420"
  },
  {
    "text": "Two, we then assign\neach point to a cluster.",
    "start": "875420",
    "end": "885180"
  },
  {
    "text": "And the way we do it is, which\npoint are you closest to?",
    "start": "885180",
    "end": "891459"
  },
  {
    "text": "So I think, if my drawing's OK,\nthose are all closer to mu 1.",
    "start": "891459",
    "end": "897949"
  },
  {
    "text": "And maybe this one and these\ncouple are closer to mu 2.",
    "start": "897949",
    "end": "903490"
  },
  {
    "text": "So you're clear enough\nwhat we've done? This is the cluster\nassignment, and I can write it kind of\nmathematically in one second.",
    "start": "903490",
    "end": "910690"
  },
  {
    "text": "If you'd like, I'll actually\nI'll vamp a little bit and say how I did\nthis more precisely.",
    "start": "910690",
    "end": "915940"
  },
  {
    "text": "Max over j, 1 to k. Oh, sorry, min.",
    "start": "915940",
    "end": "922459"
  },
  {
    "text": "Why did I write max? Augmin.",
    "start": "922460",
    "end": "928000"
  },
  {
    "text": "C or mu, write this clear.",
    "start": "928000",
    "end": "933339"
  },
  {
    "text": "What's going on? Mu k minus xi.",
    "start": "933339",
    "end": "939689"
  },
  {
    "text": "And we put a square there\njust because I like squares because we do it. Not really too problematic.",
    "start": "939689",
    "end": "945310"
  },
  {
    "text": "And they're the same distance. So this says Ci, where I'm\nmapping the i-th point,",
    "start": "945310",
    "end": "951370"
  },
  {
    "text": "well, I just find the closest\nmu j to it, my current mu j. That's the way I'm\ndoing the assignment.",
    "start": "951370",
    "end": "957350"
  },
  {
    "text": "Every point goes to\nits closest neighbor. And I'm arbitrarily saying\nthis guy is closer than mu 2, All right, now I have to improve\nmy clustering because remember",
    "start": "957350",
    "end": "965130"
  },
  {
    "start": "962000",
    "end": "1349000"
  },
  {
    "text": "it's iterative. So what do I do? I copy it, so you\ncan-- so I don't have",
    "start": "965130",
    "end": "970782"
  },
  {
    "text": "to overwrite it, what happens. Well, what do you\nthink I should do? I should probably take\nthe points that I have",
    "start": "970782",
    "end": "976360"
  },
  {
    "text": "and compute a new\ncenter, my new guess at the center of the clusters. So what I do is I compute\nnew cluster centers.",
    "start": "976360",
    "end": "984459"
  },
  {
    "text": "What does that mean? Cluster centers.",
    "start": "984459",
    "end": "991240"
  },
  {
    "text": "So I'm going to move. I look at mu here. What's the new cluster\ncenter for that?",
    "start": "991240",
    "end": "996459"
  },
  {
    "text": "Well, it looks like it\nshould be somewhere here. Right, this is where mu 1 goes.",
    "start": "996460",
    "end": "1002860"
  },
  {
    "text": "And where should mu 2 go? Well, probably\nsomewhere right here. That's kind of the mean of them.",
    "start": "1002860",
    "end": "1008330"
  },
  {
    "text": "Now you can compute\nthese things precisely, but I'm just drawing them\njust so you get an intuition.",
    "start": "1008330",
    "end": "1014639"
  },
  {
    "text": "And I'll write this notation\nbecause there's more notation. So now I have new\ncluster centers. Now what's the next step?",
    "start": "1014639",
    "end": "1020990"
  },
  {
    "text": "I repeat. So I go back and\nI assign every set",
    "start": "1020990",
    "end": "1026400"
  },
  {
    "text": "that's closer to mu 1 or mu 2. So now I have these\ncharacters, and I",
    "start": "1026400",
    "end": "1032289"
  },
  {
    "text": "have these characters there. OK, that's now doing\nstep two again.",
    "start": "1032290",
    "end": "1037980"
  },
  {
    "text": "I repeat step three. What's going to happen? They're going to jump to\nthe spot in the middle,",
    "start": "1037980",
    "end": "1043630"
  },
  {
    "text": "in the spot in the middle. Mu 1's going to be there, mu 2. And then there's\ngoing to be no more change if I were to continue\nrunning the algorithm forever.",
    "start": "1043630",
    "end": "1050890"
  },
  {
    "text": "So let me write that out\nmathematically while you digest that statement. But that's the entire algorithm. So what does this mean?",
    "start": "1050890",
    "end": "1056020"
  },
  {
    "text": "Mu j is going to\nequal 1 over sigma j.",
    "start": "1056020",
    "end": "1063050"
  },
  {
    "text": "It's going to be sum average\nover all the points in sigma j, xj such that--",
    "start": "1063050",
    "end": "1070570"
  },
  {
    "text": "sigma j is just\nthe set of points-- i such that Ci equals j.",
    "start": "1070570",
    "end": "1076789"
  },
  {
    "text": "This is just some\nnotation that says, these are all the points\nthat are close to-- closest",
    "start": "1076789",
    "end": "1082409"
  },
  {
    "text": "to the center j. And then I average\nover all of them. I just compute their\nmean, hence k-means.",
    "start": "1082410",
    "end": "1089500"
  },
  {
    "text": "I iterate this\nthing, and I repeat until no assignments change,\ntill nothing changes basically.",
    "start": "1089500",
    "end": "1096170"
  },
  {
    "text": "Repeat until nothing changes. Notice that if the labels\ndon't change in step two,",
    "start": "1096170",
    "end": "1102590"
  },
  {
    "text": "then the mean is not going\nto change because it's a function of the labels. It's a function of what I\nguessed was in each cluster. It's always their mean.",
    "start": "1102590",
    "end": "1109080"
  },
  {
    "text": "Any questions about\nthat, nothing changes? Please. [INAUDIBLE]",
    "start": "1109080",
    "end": "1114700"
  },
  {
    "text": "Yes, in [INAUDIBLE] and in\nmany, many different ways.",
    "start": "1114700",
    "end": "1121130"
  },
  {
    "text": "So let's talk about a couple\nof things that go right, and then we'll talk\nabout what goes wrong. So the first way it could go\nwrong is, does it terminate?",
    "start": "1121130",
    "end": "1128460"
  },
  {
    "text": "So if you imagine\nit was in some-- it's not obvious. I'm doing this kind\nof jumping around. It could oscillate wildly.",
    "start": "1128460",
    "end": "1134779"
  },
  {
    "text": "There's nothing that\nlike prevents it, at least at a high level when\nyou're thinking about this, of going like, oh, 1\nswitched from red to blue,",
    "start": "1134780",
    "end": "1140408"
  },
  {
    "text": "then it switched back\nfrom blue to red. And then the cluster\ncenters are jumping around, and they're in some unstable\nkind of equilibrium.",
    "start": "1140409",
    "end": "1146210"
  },
  {
    "text": "So that's something\nthat potentially could be bad that happens. So that's the first question. Does it terminate?",
    "start": "1146210",
    "end": "1151960"
  },
  {
    "text": "Does it terminate? All right, and it turns\nout this is great. Yes, it does.",
    "start": "1151960",
    "end": "1159799"
  },
  {
    "text": "Now why does it? The reason is that\nthis functional underneath the covers,",
    "start": "1159799",
    "end": "1174470"
  },
  {
    "text": "That is, the distance between\na point and its cluster center is actually\nmonotonically decreasing.",
    "start": "1174470",
    "end": "1180740"
  },
  {
    "text": "It's not increasing. So that oscillation\ncan happen basically. And you can basically view\nthe algorithm underneath this,",
    "start": "1180740",
    "end": "1187670"
  },
  {
    "text": "k-means, if you really want\nto be kind of super abstract, you can view it as basically\ndoing gradient descent on this object in\na particular way.",
    "start": "1187670",
    "end": "1195490"
  },
  {
    "text": "See the nodes for\nactually the convergence. So it converges to something. OK? Now in unsupervised learning,\nthat converges to something",
    "start": "1195490",
    "end": "1202140"
  },
  {
    "text": "is about as-- is kind\nof what we can hope for. In particular, you may also ask,\nOK, it converged to something.",
    "start": "1202140",
    "end": "1208100"
  },
  {
    "text": "Does it converge to\na global minimizer? Does it converge to\na global minimizer?",
    "start": "1208100",
    "end": "1214350"
  },
  {
    "text": "And if I did my job\nsetting this up, your intuition should say, no.",
    "start": "1214350",
    "end": "1219929"
  },
  {
    "text": "No, not necessarily. Now you may look at this and\nsay, well, not necessarily.",
    "start": "1219929",
    "end": "1225740"
  },
  {
    "text": "Maybe there's a better\nalgorithm out there that given this\nsetup of problem. Why did you pick this algorithm? It's a bad algorithm.",
    "start": "1225740",
    "end": "1231740"
  },
  {
    "text": "You should show me a better one. There isn't a better one\nbecause it's actually NP hard. If you don't know what\nthat means, don't worry.",
    "start": "1231740",
    "end": "1236830"
  },
  {
    "text": "There's no hardness\nproofs in this class, does not really matter. It just means we don't know-- humanity does not know\na better algorithm",
    "start": "1236830",
    "end": "1242500"
  },
  {
    "text": "for this that runs\nin polynomial time. OK? And we have reason to\nsuspect there isn't one. All right, so this algorithm,\nas I said, it's going to run.",
    "start": "1242500",
    "end": "1251370"
  },
  {
    "text": "But sometimes it\ncan end up doing things that are quite bad. In particular, it gets stuck\nby getting a cluster over",
    "start": "1251370",
    "end": "1257320"
  },
  {
    "text": "in a region where it\nshould have never been. And if it had more\ncarefully searched, potentially it could have\ngotten a lower cost solution.",
    "start": "1257320",
    "end": "1265000"
  },
  {
    "text": "All right, clear enough? Clear enough on its properties? Now this going to be\na hallmark of what",
    "start": "1265000",
    "end": "1271780"
  },
  {
    "text": "we do over the next\ncouple of lectures. Almost everything we do, with\nthe exception of one algorithm",
    "start": "1271780",
    "end": "1277059"
  },
  {
    "text": "that we'll talk about,\nhas this property that it doesn't\nnecessarily converge to a global optimized solution.",
    "start": "1277059",
    "end": "1283419"
  },
  {
    "text": "And as I said, this used to be\nmuch more disturbing to people. But now most of AI\nis in that mode, so people don't seem\nto care as much.",
    "start": "1283419",
    "end": "1289139"
  },
  {
    "text": "It used to be quite disturbing. When I started, it\nwas quite disturbing. Now no one cares. You guys-- you folks\nare old hats at this.",
    "start": "1289140",
    "end": "1296140"
  },
  {
    "text": "Go ahead. [INAUDIBLE] converge to\nthe global minimizer?",
    "start": "1296140",
    "end": "1302289"
  },
  {
    "text": "What happens in that situation? So you can imagine\nsituations-- for example, imagine our points that are\nreally far away and then",
    "start": "1302289",
    "end": "1309020"
  },
  {
    "text": "some other cluster\nof points here and that really there's enough\nkind of things in the middle that the optimal is\nactually closer to the line.",
    "start": "1309020",
    "end": "1317389"
  },
  {
    "text": "Then what you'll see is\nthat you could end up with some kind of\nlocal minimum where you pick a center\nway, way over here",
    "start": "1317390",
    "end": "1323929"
  },
  {
    "text": "and a center in\nthe middle of this. But you should have-- there was\na kind of a better one closer. So that's very hand wavy.",
    "start": "1323929",
    "end": "1329400"
  },
  {
    "text": "I can post some examples\nwhere you can actually run through and\nconvince yourself. All that I really care to\nget across in this lecture,",
    "start": "1329400",
    "end": "1335270"
  },
  {
    "text": "and I couldn't\nthink of how to get good examples to look at there,\nis that this is a possibility. You shouldn't expect it to\nget you a global minimizer,",
    "start": "1335270",
    "end": "1342309"
  },
  {
    "text": "and we have some\ntheoretical reason why we don't believe such an\nalgorithm could exist, even in the simple case.",
    "start": "1342309",
    "end": "1347750"
  },
  {
    "text": "Yeah, wonderful. OK, now a couple of side notes. So these questions\nalready came up.",
    "start": "1347750",
    "end": "1353559"
  },
  {
    "start": "1349000",
    "end": "1487000"
  },
  {
    "text": "So these are really great. So they're not even side notes. They're just responding--\nI'm just being responsive, but I was going to talk\nabout them no matter what.",
    "start": "1353560",
    "end": "1360070"
  },
  {
    "text": "The question was asked,\nhow did you initialize? How did you pick these points? And from my argument, as I\njust talked about, even very",
    "start": "1360070",
    "end": "1366630"
  },
  {
    "text": "intuitively and informally,\nthe initialization matters quite a bit, right? If you initialize way,\nway in crazy ways,",
    "start": "1366630",
    "end": "1373100"
  },
  {
    "text": "then you force k-mean\nto kind of jump back. And maybe there's\nonly one point. Imagine there's a\ncluster of points. And you throw one of your\ncenters way across the room,",
    "start": "1373100",
    "end": "1380620"
  },
  {
    "text": "it's going to potentially\npick off nothing. And then it's going to have\nto kind of crawl its way back in some sense.",
    "start": "1380620",
    "end": "1385970"
  },
  {
    "text": "So the point that I care about\nyou getting is how does the-- how does initialization matter?",
    "start": "1385970",
    "end": "1392809"
  },
  {
    "text": "And I won't go into\ntoo much detail. But I want to tell\nyou that there's one algorithm that was\ndeveloped by smart Stanford students a while ago--",
    "start": "1392809",
    "end": "1398820"
  },
  {
    "text": "maybe 12 years ago, I don't\nknow, 12, 15 years ago, maybe even-- called k-means-plus-plus.",
    "start": "1398820",
    "end": "1405158"
  },
  {
    "text": "And I'll just tell you what\nthey did from great Stanford",
    "start": "1405159",
    "end": "1410330"
  },
  {
    "text": "students. And basically what\nthey decided to do",
    "start": "1410330",
    "end": "1415919"
  },
  {
    "text": "is that they--\nwhere they compute kind of a density estimation. And then they place their\ncenters with respect",
    "start": "1415919",
    "end": "1421980"
  },
  {
    "text": "to the density to kind of\nspread them out in a nice way in k-means-plus-plus. And without going too much\ninto the details, what ends up",
    "start": "1421980",
    "end": "1428750"
  },
  {
    "text": "happening is they get an\nimproved approximation ratio. So if you don't care about\nthis kind of theory stuff, don't worry.",
    "start": "1428750",
    "end": "1434309"
  },
  {
    "text": "But they're able to show that\nif you initialize in this way, even though it's NP hard\nto find the exact solution, they can find kind of a low\ncost approximate algorithm",
    "start": "1434309",
    "end": "1442080"
  },
  {
    "text": "to it provably. So this is actually-- when we're\ntalking about what could go wrong-- this is something\nthat can go wrong.",
    "start": "1442080",
    "end": "1447340"
  },
  {
    "text": "And what people do in k-means\nis they used to just kind of run it many times. But if you run with\nthis initialization-- it's still a random\ninitialization--",
    "start": "1447340",
    "end": "1453549"
  },
  {
    "text": "but if you run it\na couple of times, you're going to get a\npretty good solution. And because you're\nalready kind of looking for an ill-defined\nkind of objective,",
    "start": "1453549",
    "end": "1460160"
  },
  {
    "text": "that turns out to be about OK. Now weirdly enough, I\nused to-- as I said, I didn't really like this stuff.",
    "start": "1460160",
    "end": "1465840"
  },
  {
    "text": "But I wrote a paper about\nusing some of it inside some of making these machine learning\nmodels robust maybe a year",
    "start": "1465840",
    "end": "1471760"
  },
  {
    "text": "or two ago. So it is something that I've\nactually used and care about. It does work, and\nyou use it as a way",
    "start": "1471760",
    "end": "1477799"
  },
  {
    "text": "to inspect your data often. You look at your data\nset, and you kind of do your k-means clustering. Then you can use\nthat to figure out",
    "start": "1477799",
    "end": "1484110"
  },
  {
    "text": "what are the different\ngroups that are inside. All right, this thing\nhere became the default",
    "start": "1484110",
    "end": "1490240"
  },
  {
    "start": "1487000",
    "end": "1939000"
  },
  {
    "text": "in scikit-learn, in sklearn. So these folks wrote\nthis beautiful paper.",
    "start": "1490240",
    "end": "1496020"
  },
  {
    "text": "They proved this nice result.\nAnd now if you run scikit-learn and run the k-means algorithm,\nit defaults to using",
    "start": "1496020",
    "end": "1501980"
  },
  {
    "text": "the-- excuse me-- defaults to\nusing the k-means-plus-plus initialization. OK, so pretty fun.",
    "start": "1501980",
    "end": "1509570"
  },
  {
    "text": "Sergei and folks did that. Anyway, all right, so now there\nwas another question which was, OK, how do you choose k?",
    "start": "1509570",
    "end": "1515700"
  },
  {
    "text": "Right, this came up\nboth in the ed thread, and it came up in the\nlecture hall itself.",
    "start": "1515700",
    "end": "1522250"
  },
  {
    "text": "How do you choose k? And here's the problem\nwith choosing k. There's no one right answer.",
    "start": "1522250",
    "end": "1531360"
  },
  {
    "text": "We'll see other\nunsupervised algorithms which do give a right answer,\nbut let me just illustrate this for you for one second.",
    "start": "1531360",
    "end": "1537630"
  },
  {
    "text": "Suppose I give\nyou this data set.",
    "start": "1537630",
    "end": "1543750"
  },
  {
    "text": "OK, there's two copies of it.",
    "start": "1543750",
    "end": "1551029"
  },
  {
    "text": "One reasonable\nclustering is this. Two clusters.",
    "start": "1551029",
    "end": "1560299"
  },
  {
    "text": "Equally reasonable-- excuse me-- is this one, four clusters.",
    "start": "1560299",
    "end": "1575130"
  },
  {
    "text": "Now if you think\nabout the algorithm as giving you the right answer\nof what structure is inside",
    "start": "1575130",
    "end": "1580669"
  },
  {
    "text": "your data, then you really\ndon't like this answer. You say, well,\nwhat's the right k? Well, it's not the right\nway to think about it maybe.",
    "start": "1580669",
    "end": "1587460"
  },
  {
    "text": "The right way to think about\nit is, given that you have a k, can you use this as a tool\nto find the clusters that are in there of different sizes?",
    "start": "1587460",
    "end": "1593350"
  },
  {
    "text": "So if you're looking\nfor five clusters, and you really only found-- you look at the five cluster\nand the four cluster map,",
    "start": "1593350",
    "end": "1598850"
  },
  {
    "text": "you have to make some judgment\nabout kind of which one is better underneath the covers. And that's why unsupervised\nlearning is kind of squishy,",
    "start": "1598850",
    "end": "1604778"
  },
  {
    "text": "but it also turns out to\nbe tremendously powerful. So we can automate the loop\nof finding the clusters. But which one is\ngood or bad, you're",
    "start": "1604779",
    "end": "1611419"
  },
  {
    "text": "going to have to use\ndomain knowledge for that in most situations. So this is really\nanother way of saying",
    "start": "1611420",
    "end": "1617370"
  },
  {
    "text": "this is a modeling question. So the one part-- even when I didn't\nreally care for-- I don't know I'm telling you\nthe history of how I feel about",
    "start": "1617370",
    "end": "1623540"
  },
  {
    "text": "lecture 11, but\nyou're getting it. But one of the things that I did\nlike about this lecture always",
    "start": "1623540",
    "end": "1628990"
  },
  {
    "text": "or this part of the\ncourse is that it forced machine learning folks\nto move out of the comfort zone of there's a right answer\nand optimization will find it,",
    "start": "1628990",
    "end": "1636440"
  },
  {
    "text": "which was very disturbing to me\nbecause that's not at all how machine learning works. And what you're doing, you're\nconstantly in this regime",
    "start": "1636440",
    "end": "1642320"
  },
  {
    "text": "where you're checking if your\nmodel works or breaks or does things. I don't know how much\nTengyu subjected you",
    "start": "1642320",
    "end": "1647480"
  },
  {
    "text": "to my crazy slides. But that is the way that you\nlive when you're building these kind of ML systems.",
    "start": "1647480",
    "end": "1654240"
  },
  {
    "text": "You build a model. You have no idea if it worked. You have to check it. You have to look at it. You have to inspect it. You have to measure it.",
    "start": "1654240",
    "end": "1660240"
  },
  {
    "text": "So this is kind of natural, and\nat least forces you to do that. OK, that's all I wanted\nto say about k-means. I want to jump to the\nnext algorithm, which",
    "start": "1660240",
    "end": "1666490"
  },
  {
    "text": "is building towards this\nlarger theory of what we did. And if you can kind\nof squint, you'll see that it parallels how we\ntaught the supervised learning",
    "start": "1666490",
    "end": "1672380"
  },
  {
    "text": "case. But any questions\nbefore I move on? Awesome. Please. Is this something you\nmight use if you're",
    "start": "1672380",
    "end": "1680760"
  },
  {
    "text": "doing supervised\nlearning but with labels that you're not sure about? Oh, awesome.",
    "start": "1680760",
    "end": "1685870"
  },
  {
    "text": "Yeah, great question. So let's say that\nyou're unsupervi-- so the way we were\nactually using it is exactly in that\nway in this paper.",
    "start": "1685870",
    "end": "1692278"
  },
  {
    "text": "What we were looking for-- I'll just to be\nreally concrete is-- we were looking for what are\ncalled hidden stratifications.",
    "start": "1692279",
    "end": "1697299"
  },
  {
    "text": "So these are times when a\nmachine learning model-- let's say that it's\nclassifying birds that are on the land versus\nbirds that are in the water.",
    "start": "1697299",
    "end": "1705320"
  },
  {
    "text": "I have more elaborate\nexamples on this. And it turns out that\nthe model sometimes gets confused by the background.",
    "start": "1705320",
    "end": "1710950"
  },
  {
    "text": "And so what you\nwant to do is you want to cluster some\nnotion of those feature descriptors\nunderneath the covers,",
    "start": "1710950",
    "end": "1716149"
  },
  {
    "text": "of like background descriptors\nthat the neural net has learned, to try and find a\ngroup which kind of looks like an oddball from the rest.",
    "start": "1716150",
    "end": "1722950"
  },
  {
    "text": "So it's like, oh, here's all the\nland birds on land backgrounds. I got them all right. And there's this other\nweird cluster there that I labeled as land\nbirds but actually are",
    "start": "1722950",
    "end": "1729889"
  },
  {
    "text": "water birds that happen to\nbe walking on land, right? And so that's the\nkind of thing you look into your\nlabels or your pseudo",
    "start": "1729890",
    "end": "1736250"
  },
  {
    "text": "labels or your predictions\nand try and find those. They can either be labels\nthat are given to you by a human or a neural net.",
    "start": "1736250",
    "end": "1741360"
  },
  {
    "text": "And that is one-- that was\nthe use case that I had is exactly what you thought about. Yeah, so that's one of them.",
    "start": "1741360",
    "end": "1748158"
  },
  {
    "text": "You'll typically also\nrun this when you have-- honestly when you have data\nyou don't really understand.",
    "start": "1748159",
    "end": "1753789"
  },
  {
    "text": "So you run an experiment\nwith search traffic or ad traffic or something, and you're\nlike, what the heck are people",
    "start": "1753789",
    "end": "1759740"
  },
  {
    "text": "asking about in this segment? And then you run kind of a\nclustering to figure it out and say, oh, this\nlooks like a topic",
    "start": "1759740",
    "end": "1765710"
  },
  {
    "text": "that people are talking\nabout x, y, or z, right? So those are the other\ntimes that you use it. But noisy labels\nis a good thing,",
    "start": "1765710",
    "end": "1771630"
  },
  {
    "text": "and that will be a theme\nfor next week's lectures. Great question.",
    "start": "1771630",
    "end": "1778070"
  },
  {
    "text": "Please. [INAUDIBLE] Yeah, so the question\nis, if you pick a larger",
    "start": "1778070",
    "end": "1783559"
  },
  {
    "text": "number of clusters, then-- if\nwe go to this example here, the problem is, how\ndescriptive does it get?",
    "start": "1783559",
    "end": "1790020"
  },
  {
    "text": "So in 4 and 2, you could kind\nof eyeball the 2 and the 4 and link them up. But if you start to\nreally jack k up to 1,000,",
    "start": "1790020",
    "end": "1796580"
  },
  {
    "text": "then it is kind of\nat the brink of what does it mean to find\nmeaningful concepts? So if you're looking\nfor 10 things,",
    "start": "1796580",
    "end": "1802610"
  },
  {
    "text": "and you know there\nare 10 things, you want to find\nthose 10 best groups. If you start to jack\nit up to 1,000, 10,000,",
    "start": "1802610",
    "end": "1808480"
  },
  {
    "text": "it no longer becomes\nhuman digestible. So that's where the\nmodeling thing comes in. It's kind of like\nthe bandwidth of what",
    "start": "1808480",
    "end": "1813580"
  },
  {
    "text": "you can look at and do this. And traditionally k-means was\nnot used in an automated loop. It was traditionally used as\na way to browse your data.",
    "start": "1813580",
    "end": "1820559"
  },
  {
    "text": "If the consumer of that is some\nneural net in the discussion we were talking about, then\nit kind of doesn't matter. You can jack it up\na little bit more.",
    "start": "1820560",
    "end": "1826750"
  },
  {
    "text": "The advantage of doing-- so the advantage of doing that\nis if you put too many centers, they may be too close together.",
    "start": "1826750",
    "end": "1832230"
  },
  {
    "text": "And sometimes what\npeople do is they'll just do kind of a\nfollow-on path where they merge some clusters\nthat look like they're kind of not informative of a\npruning heuristic at the end.",
    "start": "1832230",
    "end": "1839610"
  },
  {
    "text": "So your intuition is dead on. And that's the side\nyou want to err on. If you err on the side of two\nsmall clusters, what happens?",
    "start": "1839610",
    "end": "1845690"
  },
  {
    "text": "You lump two things\ntogether that you could have distinguished. And then you could get a\nweird cluster in the center. So clearly you're right.",
    "start": "1845690",
    "end": "1851180"
  },
  {
    "text": "The overprovision\nsetting is much nicer than the underprovision setting. Awesome. Sounds like folks got it.",
    "start": "1851180",
    "end": "1859648"
  },
  {
    "text": "Please. [INAUDIBLE] combined\nclusters [INAUDIBLE] to do the [INAUDIBLE] is there\nan algorithm for doing that?",
    "start": "1859649",
    "end": "1868309"
  },
  {
    "text": "Yeah, so I wish there\nwas one algorithm. So this is something that\npeople are writing, still writing, research papers on.",
    "start": "1868309",
    "end": "1873350"
  },
  {
    "text": "We had an ICLR paper on. There's another one coming\nout from some other-- from another group,\nwhich is great, that we're reading right now.",
    "start": "1873350",
    "end": "1879070"
  },
  {
    "text": "Basically what people\ntry to do in these things is that data point. So this is kind of an\nimpoverished setting, right?",
    "start": "1879070",
    "end": "1884289"
  },
  {
    "text": "We have data points\nthat are just in RD. That's their inner vector space. But those data points usually\ncorrespond to something real,",
    "start": "1884289",
    "end": "1889559"
  },
  {
    "text": "like there's an image or text. And so the more modern ways that\npeople do with this diagnosis, like what Sabri and\nfolks did and Maya did",
    "start": "1889559",
    "end": "1897370"
  },
  {
    "text": "and Domino was they said,\noh, we took those points. And we embedded the text\nthat's associated with an image and the image itself.",
    "start": "1897370",
    "end": "1903000"
  },
  {
    "text": "And we start to do\nkind of search queries on top to find the slices that\nare underneath the covers.",
    "start": "1903000",
    "end": "1908330"
  },
  {
    "text": "So this is the purest setting\nwhere you're just like, I have data from an\ninner vector space. But of course, with\nmodern methods,",
    "start": "1908330",
    "end": "1914419"
  },
  {
    "text": "there's an underlying object. It's a transaction or\nan image and a caption. And then you start to use some\nof the more modern techniques",
    "start": "1914419",
    "end": "1920980"
  },
  {
    "text": "to search through it. And then, of course, you\nvisualize it or monitor it. And there are a number of tools\nthat are out there to do this.",
    "start": "1920980",
    "end": "1926880"
  },
  {
    "text": "I wouldn't say it's solved,\nlike, oh, you just use x and you're done. But there are a number of tools.",
    "start": "1926880",
    "end": "1932049"
  },
  {
    "text": "But yeah, you do have\nto look at your data. There's nothing that\nreally obviates that. Awesome questions.",
    "start": "1932049",
    "end": "1938480"
  },
  {
    "text": "All right, so let's\ntalk about a slight-- what appears at first to\nbe a slight generalization.",
    "start": "1938480",
    "end": "1945980"
  },
  {
    "start": "1939000",
    "end": "2076000"
  },
  {
    "text": "Hopefully it feels like we\njust relax one little thing, but it gets us closer\nto a more fancy model",
    "start": "1945980",
    "end": "1956279"
  },
  {
    "text": "that will allow us to do\nsome really fun stuff. And this is actually pretty fun. So this is a toy\nexample from astronomy.",
    "start": "1956279",
    "end": "1962320"
  },
  {
    "text": "And if you know about\nastronomy, please don't humiliate me too badly. Feel free to correct me.",
    "start": "1962320",
    "end": "1968170"
  },
  {
    "text": "I have no idea what\nI'm talking about. But I read the paper,\nand I understood the math, so who cares? This is a toy example,\nand it's from a paper",
    "start": "1968170",
    "end": "1974540"
  },
  {
    "text": "from the University\nof Washington. So I can find the paper\nagain if people want. So here's the general setup\nof what they're doing.",
    "start": "1974540",
    "end": "1980909"
  },
  {
    "text": "They have this light detector,\nthis photon-counting thing.",
    "start": "1980910",
    "end": "1985980"
  },
  {
    "text": "And they're looking in the sky\nat various different things. And what they want to do is they\nhave, in this simplified model,",
    "start": "1985980",
    "end": "1992110"
  },
  {
    "text": "there's kind of two\ncelestial objects that could be out there. It could be a regular\nstar and a quasar, OK? And one of them is\ngoing to take the light,",
    "start": "1992110",
    "end": "1998679"
  },
  {
    "text": "and it's going to spread kind\nof evenly in all directions. And another is going to send out\nrelatively concentrated pulses,",
    "start": "1998679",
    "end": "2004320"
  },
  {
    "text": "OK? And what happens\nis unfortunately when those photons\ncome to Earth, they don't come with labels.",
    "start": "2004320",
    "end": "2009690"
  },
  {
    "text": "No one gets to like\naffix a metadata packet to every photon that hits us. We have to see the photons\nand figure out where the hell",
    "start": "2009690",
    "end": "2015429"
  },
  {
    "text": "did they come from, OK? So what happens is we\nget some data that looks like this, maybe like this.",
    "start": "2015429",
    "end": "2028830"
  },
  {
    "text": "And these are all our little\nphotons that are there,",
    "start": "2028830",
    "end": "2034039"
  },
  {
    "text": "so quasars and stars.",
    "start": "2034040",
    "end": "2040190"
  },
  {
    "text": "Now and both of these\nthings emit light, but all we get to observe\nare these photon hits.",
    "start": "2040190",
    "end": "2048810"
  },
  {
    "text": "All right, so now what we're\ngoing to do in our cell-- oh,",
    "start": "2048810",
    "end": "2056480"
  },
  {
    "text": "please go ahead. [INAUDIBLE] No, we don't have to assume\na linear decision boundary.",
    "start": "2056480",
    "end": "2063600"
  },
  {
    "text": "We just have to assume that\nit's close in distance. You can get nonlinear leads.",
    "start": "2063600",
    "end": "2068800"
  },
  {
    "text": "There's no notion of a decision\nboundary in particular anyway. You can draw a little\nVoronoi diagram, but we didn't talk about that.",
    "start": "2068800",
    "end": "2075169"
  },
  {
    "text": "Yeah, very nice question. Awesome, awesome. So we get these photon hits, OK?",
    "start": "2075169",
    "end": "2080868"
  },
  {
    "start": "2076000",
    "end": "2489000"
  },
  {
    "text": "So what we want to\ndo is kind of figure out what these different\nsources look like.",
    "start": "2080869",
    "end": "2088408"
  },
  {
    "text": "And so what our given-- this is what we're given. What we're going to do is try\nand find a soft assignment",
    "start": "2088409",
    "end": "2095320"
  },
  {
    "text": "of these things into Gaussians. So remember what\nGaussians look like. They're basically--\nit's a high probability",
    "start": "2095320",
    "end": "2100579"
  },
  {
    "text": "they look like ovals. They can be circles. That's what a two-dimensional\nGaussian looks like, right?",
    "start": "2100579",
    "end": "2106200"
  },
  {
    "text": "And the variance tells\nyou how stretched it is in each dimension, OK? So maybe there's a cluster\nhere, cluster here.",
    "start": "2106200",
    "end": "2113960"
  },
  {
    "text": "And this is a tight cluster. All right, so we'll\ntalk about that in more detail in one second.",
    "start": "2113960",
    "end": "2120660"
  },
  {
    "text": "But what we have to do\nis we want to assign each photon to a light source.",
    "start": "2120660",
    "end": "2130040"
  },
  {
    "text": "But of course, we don't--\nactually, in this case-- we don't have perfect\ninformation on the light sources either.",
    "start": "2130040",
    "end": "2136050"
  },
  {
    "text": "And so we're going\nto settle for what we call a soft assignment, OK? So this is the probability.",
    "start": "2136050",
    "end": "2142588"
  },
  {
    "text": "Prob that point i goes to\ncluster, goes to source j, OK?",
    "start": "2142589",
    "end": "2151700"
  },
  {
    "text": "And this is our soft assignment. This is called a\nsoft assignment. Why is it soft?",
    "start": "2151700",
    "end": "2157558"
  },
  {
    "text": "Because we didn't-- remember\nin k-means, we said, you must be in this setting.",
    "start": "2157559",
    "end": "2162759"
  },
  {
    "text": "Here we have some probability\ndistribution over it. So just compare\nthat with k-means.",
    "start": "2162760",
    "end": "2169049"
  },
  {
    "text": "All right, so what are\nthe challenges here?",
    "start": "2169050",
    "end": "2174790"
  },
  {
    "text": "The challenges that we're\ngoing to deal with here potentially are there\nare many sources.",
    "start": "2174790",
    "end": "2181609"
  },
  {
    "text": "If there were just one\nsource, life would be easy. We would kind of\nfit the Gaussian. You know how to\ndo that from GDA. You take the mean.",
    "start": "2181609",
    "end": "2187329"
  },
  {
    "text": "You find the variants. You're done. There are many sources here. But for now, we're going to\nassume we know the sources k.",
    "start": "2187330",
    "end": "2193670"
  },
  {
    "text": "We know k, which is\nthe number of sources. OK, let's solve the\nproblem in that setting.",
    "start": "2193670",
    "end": "2201940"
  },
  {
    "text": "And also, the other\nproblem is the sources have different\nintensities and shapes.",
    "start": "2201940",
    "end": "2210720"
  },
  {
    "text": "Intensities and shapes. So when I was wildly\ndrawing those ovals, the reason was,\nis like, oh, maybe",
    "start": "2210720",
    "end": "2216010"
  },
  {
    "text": "there's a Gaussian\nthat looks like this. Maybe there's a tight Gaussian. I don't assume I know\nthat ahead of time. I just know that they're somehow\nwell-described by Gaussians.",
    "start": "2216010",
    "end": "2222821"
  },
  {
    "text": "Please. I guess k is the [INAUDIBLE] Oh, no, great question.",
    "start": "2222821",
    "end": "2229619"
  },
  {
    "text": "So those are the\ntwo types of things. I need the number\nof celestial bodies. So one reasonable\nthing would be three.",
    "start": "2229619",
    "end": "2235490"
  },
  {
    "text": "There's one here, one\nhere, and one here. But k is still\ngoing to be picked by a modeling assumption.",
    "start": "2235490",
    "end": "2241350"
  },
  {
    "text": "So this curve is hard to\ngenerate with a Gaussian in our current setup.",
    "start": "2241350",
    "end": "2247010"
  },
  {
    "text": "So there's probably not--\nthere's probably more than one on that side, but\nthat's just intuition. There could be four\nthere, five there. I don't know.",
    "start": "2247010",
    "end": "2253620"
  },
  {
    "text": "So let me talk about\nthe assumptions. So we're going to assume\nit's well-modeled.",
    "start": "2253620",
    "end": "2261170"
  },
  {
    "text": "And here we're in-- most of what I'm going to do is\ngoing to be in one dimension. So I'm still just going to\nintroduce the notation in one",
    "start": "2261170",
    "end": "2266529"
  },
  {
    "text": "dimension by Gaussian. And you remember that a Gaussian\nmeans mu j sigma j squared.",
    "start": "2266530",
    "end": "2273578"
  },
  {
    "text": "So we're just one\ndimensions to make our lives similar in a second. But we do not assume we\nknow how many points,",
    "start": "2273579",
    "end": "2282530"
  },
  {
    "text": "but there's an equal\nnumber of points. Number of points is equal.",
    "start": "2282530",
    "end": "2288619"
  },
  {
    "text": "Now the reason is, in our\nsetup, the physical reason is at some point, sources are\nreally concentrated and strong,",
    "start": "2288619",
    "end": "2295760"
  },
  {
    "text": "and they shoot out\ntons of photons. And in other cases,\nthey'll shoot out diffuse photons over a region.",
    "start": "2295760",
    "end": "2301349"
  },
  {
    "text": "They may be farther\nor closer away, different energy\nlevels, whatever. Mathematically, what I\nmean is we don't know,",
    "start": "2301349",
    "end": "2307180"
  },
  {
    "text": "when we're going to talk\nabout these Gaussians, the shape may be a Gaussian. But it's only sampled\ninfrequently for source one",
    "start": "2307180",
    "end": "2313060"
  },
  {
    "text": "and sampled 90% of the\ntime for source two. This is formally known as\nan unknown mixture, OK?",
    "start": "2313060",
    "end": "2326569"
  },
  {
    "text": "Now one thing that's nice about\nthis problem in the physics setting is once I\nget the values out-- so what's the do here--",
    "start": "2326569",
    "end": "2333059"
  },
  {
    "text": "I have to get out\nthese cluster centers that we talked about before\nand these probabilities,",
    "start": "2333060",
    "end": "2338400"
  },
  {
    "text": "which I haven't given\nyou a notation for. But they're going to be\ncalled phi in a second. I can check that at how\nphysically plausible",
    "start": "2338400",
    "end": "2344599"
  },
  {
    "text": "that clustering is, right? So in the k-- the reason\nI like this example is-- in the k-means,\nyou're going to kind of have to eyeball it.",
    "start": "2344599",
    "end": "2350710"
  },
  {
    "text": "But here if I have\na physics model, I can compute how likely is\none clustering versus another, given the data sources\nthat I'm seeing.",
    "start": "2350710",
    "end": "2356750"
  },
  {
    "text": "Maybe have auxiliary information\nabout what celestial objects are in the sky in that\nparticular region, and so I can check\nthis information, OK?",
    "start": "2356750",
    "end": "2364880"
  },
  {
    "text": "And the physicists\nin this example could actually check\nthe information. Please. What's the range of j?",
    "start": "2364880",
    "end": "2370950"
  },
  {
    "text": "The range of what? Of j. j, oh, j is going to range-- the same is going to range\nover each number of sources.",
    "start": "2370950",
    "end": "2376010"
  },
  {
    "text": "So we're going to assume that\nwe have this k number of sources here. So j will range over k just\nlike it did in k-means.",
    "start": "2376010",
    "end": "2383240"
  },
  {
    "text": "So that;s fixed. That's a parameter\nof the problem. Someone's going to\ntell me-- basically what someone's going to tell\nme is there are k sources.",
    "start": "2383240",
    "end": "2389350"
  },
  {
    "text": "I don't tell you\nwhat their means are. I don't tell you what\ntheir variances are. So that's for each one of them. And I don't tell you how often.",
    "start": "2389350",
    "end": "2395930"
  },
  {
    "text": "That's this mixture. They emit light. So what percentage of the points\ngo to source A versus source B?",
    "start": "2395930",
    "end": "2404290"
  },
  {
    "text": "Please. [INAUDIBLE] the\nassumption [INAUDIBLE]",
    "start": "2404290",
    "end": "2416300"
  },
  {
    "text": "So for example, let's imagine\nthat we had a situation. Let me just draw it.",
    "start": "2416300",
    "end": "2422940"
  },
  {
    "text": "So let's say that we\nhad three points here. And then I'm not going to draw\nthem all but like 1,000 points",
    "start": "2422940",
    "end": "2428190"
  },
  {
    "text": "here. So there are three points here\nand 1,000 points here, right? So the clustering\nthat I would want out is one cluster here\nand one cluster here.",
    "start": "2428190",
    "end": "2436369"
  },
  {
    "text": "But I don't get to\nsee the 3 and 1,000. I'm assuming that\nthey're of unequal sizes.",
    "start": "2436370",
    "end": "2441610"
  },
  {
    "text": "So you could, for example,\nassume that all the clusters are equal sizes. I'm trying to-- and that\nwould be wrong in this--",
    "start": "2441610",
    "end": "2448079"
  },
  {
    "text": "it's not the way\nwe'd have the model. That's a fair assumption\nif you knew that, right, but that would make\nyour life a lot easier.",
    "start": "2448079",
    "end": "2453450"
  },
  {
    "text": "It doesn't make-- you have to\nsolve both of these two things. Awesome question. All right, please, yeah.",
    "start": "2453450",
    "end": "2462310"
  },
  {
    "text": "[INAUDIBLE] Yeah, we make that\nassumption kind of implicitly because we don't say how often--",
    "start": "2462310",
    "end": "2467990"
  },
  {
    "text": "there's no probabilistic model. But we do allow k to have 5\nneighbors and 500 neighbors,",
    "start": "2467990",
    "end": "2473510"
  },
  {
    "text": "right? Center cluster 1 could\nhave 5 neighbors, and another one could have 500. So it does parallel k-means. So in that sense, it's\nthe same assumption.",
    "start": "2473510",
    "end": "2480190"
  },
  {
    "text": "I'm calling it out here\nas an extra parameter that we didn't have to think\nabout last time, right?",
    "start": "2480190",
    "end": "2486280"
  },
  {
    "text": "Awesome questions. OK, let's see some 1D\nmixture of Gaussians.",
    "start": "2486280",
    "end": "2491660"
  },
  {
    "start": "2489000",
    "end": "2799000"
  },
  {
    "text": "Mixture of Gaussians is a\nvery fun and famous problem, by the way. People work on which ones you\ncan solve in theory still.",
    "start": "2491660",
    "end": "2501800"
  },
  {
    "text": "It's a fun-- it's actually a\nfun and interesting problem. We won't do that. All right, so I'm going\nto be in 1D for simplicity",
    "start": "2501800",
    "end": "2510480"
  },
  {
    "text": "here because it just\nmakes my notation and drawing easier because I\nhave to draw distributions.",
    "start": "2510480",
    "end": "2515619"
  },
  {
    "text": "All right, so just\nmake sure it's super clear what we're doing. I think folks sound\nlike they have it. So we have 1D.",
    "start": "2515619",
    "end": "2521369"
  },
  {
    "text": "This is going to be the\nplace where our points live. And then imagine there\nwere two Gaussians that",
    "start": "2521369",
    "end": "2532710"
  },
  {
    "text": "were generating data. Now when I say this\nis generating data,",
    "start": "2532710",
    "end": "2537790"
  },
  {
    "text": "this is the piece-- when I talked\nabout we were going to talk-- we're going to allow\nourselves to talk about models, we're going to imagine\nthat there's really",
    "start": "2537790",
    "end": "2543400"
  },
  {
    "text": "a model that's underneath our\ndata that's generating it. This is quite a\npowerful technique.",
    "start": "2543400",
    "end": "2550568"
  },
  {
    "text": "So how does it work? What we're going to do,\nor our idea for the model,",
    "start": "2550569",
    "end": "2556010"
  },
  {
    "text": "is we're going to pick cluster let's call it P-- or cluster 2 with probability 1\nminus P. If we pick cluster 1,",
    "start": "2556010",
    "end": "2563400"
  },
  {
    "text": "we then sample a point. Oops, let me get\na thicker thing.",
    "start": "2563400",
    "end": "2570380"
  },
  {
    "text": "Oops, that's probably too thick. And we get a series\nof points, OK?",
    "start": "2570380",
    "end": "2583090"
  },
  {
    "text": "That's the thought process\nthat we're going through. If we only knew\nthose parameters, we could sample from our model. If we knew the\nprobability to pick",
    "start": "2583090",
    "end": "2589599"
  },
  {
    "text": "cluster 1 versus cluster 2, and\nthen we would sample from it. And there's many different\nparameters, given that model,",
    "start": "2589599",
    "end": "2595599"
  },
  {
    "text": "that could have\ngenerated our data. And we're interested\nin recovering the ones that are most\nlikely, that most likely generated our data.",
    "start": "2595599",
    "end": "2601609"
  },
  {
    "text": "Now what we see\nunfortunately it's",
    "start": "2601609",
    "end": "2608609"
  },
  {
    "text": "just this, just the points. So this is the model over here.",
    "start": "2608610",
    "end": "2614599"
  },
  {
    "text": "This is what we observe. Oops, I've got to switch back.",
    "start": "2614599",
    "end": "2623529"
  },
  {
    "text": "Just the points in\nR. These are the xis.",
    "start": "2623529",
    "end": "2629910"
  },
  {
    "text": "Now one thing, and this is going\nto seem like a trivial piece,",
    "start": "2629910",
    "end": "2635750"
  },
  {
    "text": "but it actually makes our\nlife kind of interesting. What if we knew these points\nall came from cluster 1,",
    "start": "2635750",
    "end": "2643940"
  },
  {
    "text": "and these points\ncame from cluster 2? This is our first observation.",
    "start": "2643940",
    "end": "2649650"
  },
  {
    "text": "Well, if we knew the cluster\nlabels, what would algorithm would we run?",
    "start": "2649650",
    "end": "2656040"
  },
  {
    "text": "if we just ran\nsomething like GDA, we would just fit\nGaussians to this. We'd be done. So if we knew this, we could\njust solve this instantly,",
    "start": "2656040",
    "end": "2663720"
  },
  {
    "text": "solve and fit Gaussians. So we compute mu\ni, and mu 1, mu 2.",
    "start": "2663720",
    "end": "2676078"
  },
  {
    "text": "How do we do that? Well, we would just average\nup all the things in here, average up all the\nthings in here. That would be our mus.",
    "start": "2676079",
    "end": "2682030"
  },
  {
    "text": "And we could even compute\nthe sigmas and be done. The challenge is we\ndon't get to see them.",
    "start": "2682030",
    "end": "2687328"
  },
  {
    "text": "We don't get those labels. Challenge, we only\nsee this thing.",
    "start": "2687329",
    "end": "2699539"
  },
  {
    "text": "This is our first example\nof a latent model. There's something hidden\nthat we don't observe. And we're trying to estimate\nthe parameters of that latent",
    "start": "2699540",
    "end": "2705539"
  },
  {
    "text": "model. And that will be a theme for\nthe next couple of lectures. Please. [INAUDIBLE]",
    "start": "2705540",
    "end": "2710990"
  },
  {
    "text": "Sure, yeah. [INAUDIBLE] should the\ndata be more than 2",
    "start": "2710990",
    "end": "2721440"
  },
  {
    "text": "for this [INAUDIBLE] Oh, so this is, yeah, so this\nwas an example to motivate.",
    "start": "2721440",
    "end": "2728860"
  },
  {
    "text": "Like, hey, this is\nlike a nice picture to look at and kind of get\nyou thinking empirically about what happens. I'm going to walk through\nmost of these things in 1D",
    "start": "2728860",
    "end": "2736609"
  },
  {
    "text": "because it makes my\nnotation a lot easier. And so there's really\nno relationship between these points and the\npoints I showed you before.",
    "start": "2736609",
    "end": "2743599"
  },
  {
    "text": "Yeah, great question. Awesome. All right, so why am I doing it\nin this kind of piecemeal way?",
    "start": "2743599",
    "end": "2751859"
  },
  {
    "text": "It's because when I show\nyou the definition, then it has a bunch of\nnotation in it. And I want to show you\nthe simplest version",
    "start": "2751859",
    "end": "2757750"
  },
  {
    "text": "so that then you can generalize\nit and do all that fun stuff on your own. OK? All right, but is it\nclear what goes on here?",
    "start": "2757750",
    "end": "2765410"
  },
  {
    "text": "There's this notion I've\nintroduced and kind of sneaked into you, which is a model. There's some\nparameter P here that",
    "start": "2765410",
    "end": "2770510"
  },
  {
    "text": "picks this side or\nthis side, right, which is going to be called\ntheta, theta 1 and theta 2,",
    "start": "2770510",
    "end": "2776809"
  },
  {
    "text": "hinting later. I pick something, and\nthen I sample from it. If I knew where the points\ncame from, I could just solve.",
    "start": "2776809",
    "end": "2783869"
  },
  {
    "text": "But the problem is,\nI have this hidden-- how often is everything sampled? I don't know how many points\nshould be in each cluster.",
    "start": "2783869",
    "end": "2790570"
  },
  {
    "text": "And I don't know which\npoints are in the cluster. Not only do I not-- I don't know either\nof those facts. So we have to estimate\nthem somehow from data.",
    "start": "2790570",
    "end": "2797059"
  },
  {
    "text": "That's what we're going to do. OK, so let's see some notation. We can come back to\nthis example if there",
    "start": "2797059",
    "end": "2802280"
  },
  {
    "start": "2799000",
    "end": "3599000"
  },
  {
    "text": "are more questions about it. OK. So let me be a little\nbit more precise.",
    "start": "2802280",
    "end": "2810130"
  },
  {
    "text": "So we're given x1,\nxn, element of R,",
    "start": "2810130",
    "end": "2816068"
  },
  {
    "text": "and a positive integer k, and\nK, positive integer or number",
    "start": "2816069",
    "end": "2821571"
  },
  {
    "text": "of sources.",
    "start": "2821571",
    "end": "2826800"
  },
  {
    "text": "And our do-- what\nwe're given, what we have to do is we need to\nfind that probability function.",
    "start": "2826800",
    "end": "2833069"
  },
  {
    "text": "Find P such that for i equals",
    "start": "2833069",
    "end": "2841839"
  },
  {
    "text": "the clusters. This is the data. We have an estimate\nof P zi equals j.",
    "start": "2841839",
    "end": "2852030"
  },
  {
    "text": "This is our notion\nof soft assignment. OK, so that's what\nwe're responsible. And this is-- although it's\na function, it's discrete.",
    "start": "2852030",
    "end": "2857810"
  },
  {
    "text": "So I can write it down. I can just write down the\nprobabilities in a table. We'll later worry about cases.",
    "start": "2857810",
    "end": "2862859"
  },
  {
    "text": "That's not the case,\nbut for now, we do.",
    "start": "2862859",
    "end": "2871588"
  },
  {
    "text": "Make sense? [INAUDIBLE] No, so j is a cluster index,\nand k is the number of clusters.",
    "start": "2871589",
    "end": "2878680"
  },
  {
    "text": "So j here says-- this says the\nith point belongs to cluster J with some probability.",
    "start": "2878680",
    "end": "2885369"
  },
  {
    "text": "j ranges over 1 to k,\nso they are k clusters. [INAUDIBLE]",
    "start": "2885369",
    "end": "2892130"
  },
  {
    "text": "No, k was equal--\nwe never actually were precise about what k is. We had rough intuition that\nk should be at least 3.",
    "start": "2892130",
    "end": "2899200"
  },
  {
    "text": "And I don't think\nwe actually used j. Or if I did, I meant and\nscribbled it incorrectly, and I apologize. Probably was a wayward i.",
    "start": "2899200",
    "end": "2904650"
  },
  {
    "text": "I don't see it in my notes,\nbut apologies for that.",
    "start": "2904650",
    "end": "2911910"
  },
  {
    "text": "Sorry for the confusion. Please. [INAUDIBLE] of z of i\nmeans that the sample i",
    "start": "2911910",
    "end": "2918078"
  },
  {
    "text": "belongs to cluster z? Belongs or comes from, yeah,\nso I'll copy from here.",
    "start": "2918079",
    "end": "2924010"
  },
  {
    "text": "It's this sentence. Probably that point i belongs\nto, I think it should be--",
    "start": "2924010",
    "end": "2930480"
  },
  {
    "text": "I think is what\nI meant to write. I think that's better. Point i comes from source--",
    "start": "2930480",
    "end": "2937160"
  },
  {
    "text": "that makes more\nsense in English-- from source j. Yeah, source j is the\nparticular source, always",
    "start": "2937160",
    "end": "2946619"
  },
  {
    "text": "the particular source. So I is always the\ndata. j is always the label for the cluster. And k is always the\nnumber of clusters.",
    "start": "2946619",
    "end": "2953430"
  },
  {
    "text": "Please. [INAUDIBLE] That and x.",
    "start": "2953430",
    "end": "2958490"
  },
  {
    "text": "Oh, you mean from the-- Is that an x on-- [INAUDIBLE]",
    "start": "2958490",
    "end": "2964460"
  },
  {
    "text": "No, so, yeah, so zi\nis the assignment. So zi is the soft\nassignment itself.",
    "start": "2964460",
    "end": "2971568"
  },
  {
    "text": "xi is the data point. Yeah, sorry for\noverloading the notation. So the zis will always be the\nhidden piece that says, the--",
    "start": "2971569",
    "end": "2978800"
  },
  {
    "text": "so let me write the next\nsentence, the next piece. And then we'll come right\nback to your question. I can see why you'd\nbe confused by that.",
    "start": "2978800",
    "end": "2986030"
  },
  {
    "text": "So let me write the\nGMM model, and you'll see why these two things are\nbeing used according to the GMM",
    "start": "2986030",
    "end": "2991359"
  },
  {
    "text": "model. So zi is just the-- zi\nas the random variable that this probability,\nthat point belongs to it.",
    "start": "2991359",
    "end": "2997818"
  },
  {
    "text": "It's not the actual\npoint itself. So then for example, we can\ntalk about the probability of xi and zi.",
    "start": "2997819",
    "end": "3006109"
  },
  {
    "text": "This is the probability that\ngiven this point and the zi is that it belongs to\na particular cluster.",
    "start": "3006109",
    "end": "3012740"
  },
  {
    "text": "And we'll write down\nthe model in one second. So let me write down the\nmodel, and then it'll be clear what this\nnotation means.",
    "start": "3012740",
    "end": "3019780"
  },
  {
    "text": "OK. All right, this is just Bayes'\nrule, nothing fancy here.",
    "start": "3019780",
    "end": "3027069"
  },
  {
    "text": "I said nothing. There's no conten, OK? But I'll use it. Now zi is going to be\ndistributed as a multinomial",
    "start": "3027069",
    "end": "3034640"
  },
  {
    "text": "according to some parameter\nthat we'll call phi.",
    "start": "3034640",
    "end": "3040200"
  },
  {
    "text": "And phi as a multinomial is-- says that sum phi j--",
    "start": "3040200",
    "end": "3045760"
  },
  {
    "text": "j goes from 1 to k-- equals 1. And phi j is greater\nthan or equal to 0, OK?",
    "start": "3045760",
    "end": "3051940"
  },
  {
    "text": "So zj, if you like, is\nthat sampling probability. It's the likelihood that\nthis particular point",
    "start": "3051940",
    "end": "3057880"
  },
  {
    "text": "came from that place. And zi is going to be\npicked with this background probability that we're\ncalling P before.",
    "start": "3057880",
    "end": "3063430"
  },
  {
    "text": "So in our earlier example,\nthere was P and 1 minus P were the chance that I sampled\nfrom cluster 1 or cluster 2",
    "start": "3063430",
    "end": "3070310"
  },
  {
    "text": "above here. These are phi 1 and phi 2,\nso what I was hinting at. OK, and remember, in\nour model, I picked zi.",
    "start": "3070310",
    "end": "3079839"
  },
  {
    "text": "That told me where\nI was sampling. And then once I knew zi,\nxi given that zi equals j.",
    "start": "3079839",
    "end": "3089088"
  },
  {
    "text": "That means given that\nit was in cluster j, this is going to be\ndistributed like a Gaussian.",
    "start": "3089089",
    "end": "3096000"
  },
  {
    "text": "mu j sigma j squared. OK? So these are all Gaussians.",
    "start": "3096000",
    "end": "3103619"
  },
  {
    "text": "OK? Now let me highlight for you the\nparameters we have to estimate.",
    "start": "3103619",
    "end": "3112780"
  },
  {
    "text": "Highlighted parameters. OK, for this thing.",
    "start": "3112780",
    "end": "3119500"
  },
  {
    "text": "OK, all right, these\nare the same color.",
    "start": "3119500",
    "end": "3129510"
  },
  {
    "text": "So what's going on here? This is formalizing the model\nthat we talked about earlier. It's our first kind\nof hidden model.",
    "start": "3129510",
    "end": "3135010"
  },
  {
    "text": "We never see zi. We don't observe it in data. We don't get to see the labels.",
    "start": "3135010",
    "end": "3143190"
  },
  {
    "text": "The deity or whoever\nis generating this data generates a zi and\npicks one of the clusters.",
    "start": "3143190",
    "end": "3150260"
  },
  {
    "text": "That's its sample\nfor this point. And then it samples from\nthis normal distribution to generate xi.",
    "start": "3150260",
    "end": "3156569"
  },
  {
    "text": "And if you like, the\ndata we think about as being the remnants\nof this process. We don't get to see\nthis process run.",
    "start": "3156570",
    "end": "3162661"
  },
  {
    "text": "It gets run ahead of time, and\nthen the data is dropped there. And the reason we're\nthinking about this model is, we say, OK, assuming that\nthe model were like this,",
    "start": "3162661",
    "end": "3170750"
  },
  {
    "text": "could we recover the parameters? And so that's the sense\nin which we're assuming there's some structure.",
    "start": "3170750",
    "end": "3176660"
  },
  {
    "text": "And it's pretty reasonable. What it's saying is, look,\nI don't know how many points come from every cluster. That's because I\nhave a multinomial.",
    "start": "3176660",
    "end": "3183059"
  },
  {
    "text": "And two, I know that the points\nthat I-- the clusters that I have, they're Gaussian-shaped. But I don't know if\nthey're circles or ovals,",
    "start": "3183059",
    "end": "3189990"
  },
  {
    "text": "and I don't know where\ntheir centers are. And I'm assuming nothing\nelse about my structure.",
    "start": "3189990",
    "end": "3196240"
  },
  {
    "text": "Can you find it for me? That's your job. Does that make sense? You have to come up with--",
    "start": "3196240",
    "end": "3202069"
  },
  {
    "text": "we have to come up\nwith these parameters. We have to find the cluster\ncenters and the probabilities that each are sampled\nfrom observing the data.",
    "start": "3202069",
    "end": "3210800"
  },
  {
    "text": "Clearly if I pick one\nclustering, it's going to-- the data is going to be very\nunlikely to have to have been generated with those centers.",
    "start": "3210800",
    "end": "3216329"
  },
  {
    "text": "If I go back here, and I picked\na center over here and a center over here, that's less likely\nthan if I put the center here",
    "start": "3216329",
    "end": "3221950"
  },
  {
    "text": "in the center here. It would just explain\nthe data less well. We'll be able to formalize\nthat with maximum likelihood,",
    "start": "3221950",
    "end": "3228279"
  },
  {
    "text": "but I hope that\nintuition is clear. If it's not, please go\nahead, ask me a question.",
    "start": "3228280",
    "end": "3233940"
  },
  {
    "text": "I'm super happy to answer. [INAUDIBLE] Ah, so phi is basically just a\nbunch of numbers that sum to 1.",
    "start": "3233940",
    "end": "3241609"
  },
  {
    "text": "It's a multinomial. So this is a probability I-- if I have cluster 1--",
    "start": "3241609",
    "end": "3247770"
  },
  {
    "text": "so let's say this\nis going back here. Let's say this is cluster 1,\ncluster 2, cluster 3, or source",
    "start": "3247770",
    "end": "3253790"
  },
  {
    "text": "And lots of points\nare in source 1. So then maybe phi because they're like 70%\nof the data is there.",
    "start": "3253790",
    "end": "3262230"
  },
  {
    "text": "And 10% of the data is here. And 20% of the data is here. Then the numbers would\nbe 0.7, 0.1, 0.2 roughly.",
    "start": "3262230",
    "end": "3270410"
  },
  {
    "text": "Does that make sense? Yes. Awesome.",
    "start": "3270410",
    "end": "3275830"
  },
  {
    "text": "All right, so let me--\nlet's do one example. I just want to-- I'm trying-- let me see.",
    "start": "3275830",
    "end": "3282690"
  },
  {
    "text": "Call the zi latent because\nwe don't observe it. We didn't get to see it.",
    "start": "3282690",
    "end": "3288520"
  },
  {
    "text": "We just got to see the points. We didn't get to see which\nwas assigned to which cluster because it's not\ndirectly observable.",
    "start": "3288520",
    "end": "3294349"
  },
  {
    "text": "This concept, which seems at\nthis point kind of strange, I would think about a bunch.",
    "start": "3294350",
    "end": "3299880"
  },
  {
    "text": "And we'll see it\nagain and again. This is what we\nmean by structure. We're like, well, there's some\nwild collection of points, but there exists a\nsmall number of clusters",
    "start": "3299880",
    "end": "3306599"
  },
  {
    "text": "that are generating them. That's the mathematical\nembodiment of what-- this thing is the mathematical\nembodiment of that intuition.",
    "start": "3306599",
    "end": "3313130"
  },
  {
    "text": "That's all it is. And we say, if\nthat's the case, then we should be able to recover it.",
    "start": "3313130",
    "end": "3319099"
  },
  {
    "text": "We should be able to\nrecover those clusters in those situations. And in the physical\nsituation of light sources, that seems pretty\nplausible, right?",
    "start": "3319099",
    "end": "3326010"
  },
  {
    "text": "They have different intensities,\ndifferent shapes, and so on. All right, so let me\ngive you one more example",
    "start": "3326010",
    "end": "3332680"
  },
  {
    "text": "just to make sure that\nall these terms are-- this notation is there. And I want you to\nthink in sampling.",
    "start": "3332680",
    "end": "3339440"
  },
  {
    "text": "And let me just walk through,\nso hopefully these things make sense.",
    "start": "3339440",
    "end": "3344960"
  },
  {
    "text": "So phi one is going to be 0.7. Phi 2 is going to be 0.3. Why those numbers? Because I'm making\nthem up, that's why.",
    "start": "3344960",
    "end": "3350910"
  },
  {
    "text": "I don't have another reason. Phi one is going to be-- mu 1 is going to be 1. Mu 2 is going to be 2.",
    "start": "3350910",
    "end": "3356940"
  },
  {
    "text": "And I'm going to set sigma",
    "start": "3356940",
    "end": "3363700"
  },
  {
    "text": "So what does that\npicture look like? Here we go. There's 1.",
    "start": "3363700",
    "end": "3369920"
  },
  {
    "text": "There's 2. There's one thing here. If I draw it pretty well.",
    "start": "3369920",
    "end": "3378299"
  },
  {
    "text": "Maybe my drawing is off, but\nhopefully you get the point. This thing should be about 1/3. This distance\nshould be about 1/3. The fact that they're\nuneven is because I'm",
    "start": "3378299",
    "end": "3384450"
  },
  {
    "text": "a bad artist, not because that's\nthe intention of the thing. This is mu 1.",
    "start": "3384450",
    "end": "3392500"
  },
  {
    "text": "This is mu 2, OK? And this distance here should\nbe about 1/3, the 65% thing.",
    "start": "3392500",
    "end": "3398630"
  },
  {
    "text": "It's the standard deviation, OK? How do I sample from it? First I pick a cluster.",
    "start": "3398630",
    "end": "3404660"
  },
  {
    "text": "Pick 1, either 1 or I pick the first cluster\nwith probability 0.7,",
    "start": "3404660",
    "end": "3411619"
  },
  {
    "text": "the second with 0.3. Then I pick the relevant mean. So if I picked 2,\nI will use mu 2.",
    "start": "3411619",
    "end": "3418290"
  },
  {
    "text": "I go over here. Then I will sample\nfrom a Gaussian and generate myself a point. It'll be here.",
    "start": "3418290",
    "end": "3425220"
  },
  {
    "text": "Two, use the\nappropriate Gaussian. OK?",
    "start": "3425220",
    "end": "3432550"
  },
  {
    "text": "So imagine that this\nwere the process that were generating your data. You just get to see an\ninstance of the data.",
    "start": "3432550",
    "end": "3437720"
  },
  {
    "text": "Your goal is to say what's\nthe most likely process that generated it. OK, and that corresponds\nto this intuition.",
    "start": "3437720",
    "end": "3444310"
  },
  {
    "text": "There exists some clusters. So far, so good? Oh, and then you repeat.",
    "start": "3444310",
    "end": "3451789"
  },
  {
    "text": "Repeat. Yeah, please go ahead\nand ask questions. [INAUDIBLE]",
    "start": "3451790",
    "end": "3457710"
  },
  {
    "text": "No, yeah so, that would be\nif I wrote their probability",
    "start": "3457710",
    "end": "3462770"
  },
  {
    "text": "distributions entirely. These are still\nunit-normal Gaussians. This is a great question. I drew it as two Gaussians. I didn't draw the\nphi 1 and phi 2.",
    "start": "3462770",
    "end": "3469360"
  },
  {
    "text": "I incorporated them\njust in this first set. So I would pick phi 1, I would\npick one with probability 0.7.",
    "start": "3469360",
    "end": "3475670"
  },
  {
    "text": "Pick one 0.7. And you could imagine\nreweighting them",
    "start": "3475670",
    "end": "3481549"
  },
  {
    "text": "and normalizing them. But then it gets a little\nconfusing visually, and I'm not that\ngood of an artist.",
    "start": "3481549",
    "end": "3487309"
  },
  {
    "text": "Please. [INAUDIBLE] Because we don't know how many\npoints come from every source. So remember, going back\nto this one up here,",
    "start": "3487309",
    "end": "3493980"
  },
  {
    "text": "we had like the-- oops,\nI went way too far back. Here we had lots of points\nfrom this one source.",
    "start": "3493980",
    "end": "3500890"
  },
  {
    "text": "And this point, there\nare 70% coming from here.",
    "start": "3500890",
    "end": "3506510"
  },
  {
    "text": "And so they-- we're\njust not assuming that they have the same. If we force them all to\nhave equally-sized clusters,",
    "start": "3506510",
    "end": "3512619"
  },
  {
    "text": "we would probably put\ntwo cluster centers here if this were 70% of the points. And we would use that\nto explain our data.",
    "start": "3512619",
    "end": "3518240"
  },
  {
    "text": "And that would be, in\nthis case, suboptimal. That's just our modeling choice. We know that the clusters\nhave different number",
    "start": "3518240",
    "end": "3523390"
  },
  {
    "text": "of points in our application. So that's why we fit them. We can't assume\nthey're the same. If we knew them perfectly,\nwe knew their things,",
    "start": "3523390",
    "end": "3530440"
  },
  {
    "text": "we could sneak them in there. But we'll talk about where\nwe sneak them in later. So I guess following\nup on that, the phi",
    "start": "3530440",
    "end": "3542119"
  },
  {
    "text": "represents this cluster sizes,\nand new 1 and new 2 are-- and then we get this standard\ndeviation [INAUDIBLE]",
    "start": "3542119",
    "end": "3547720"
  },
  {
    "text": "The shape. That's the exact\ndistribution of [INAUDIBLE] The shape, really.",
    "start": "3547720",
    "end": "3553090"
  },
  {
    "text": "The shape. Yeah. Awesome. Sure. Oh, so basically\nwe have a problem.",
    "start": "3553090",
    "end": "3563319"
  },
  {
    "text": "Mu 1 is greater [INAUDIBLE] Because I'm a bad artist. Yeah. That's kind of good, man.",
    "start": "3563319",
    "end": "3569609"
  },
  {
    "text": "I mean-- Yeah, but should [INAUDIBLE]. Sorry about that. No, that's fine. [LAUGHTER]",
    "start": "3569609",
    "end": "3575559"
  },
  {
    "text": "I was messing around. Sorry about that. But should the second\npeak be actually shorter than the\nfirst peak because--",
    "start": "3575559",
    "end": "3581369"
  },
  {
    "text": "Yeah, that's a great question. So you could imagine folding\nthe phis in to try and make them both probability distribution\ndensity functions",
    "start": "3581369",
    "end": "3588020"
  },
  {
    "text": "where there was one\ndistribution density function. And then you would fold them in. I've drawn them crudely\nhaving the same height",
    "start": "3588020",
    "end": "3594859"
  },
  {
    "text": "and putting the probability\nfunction up front to say these are the Gaussians\nand then there's the height. But you've got it perfectly.",
    "start": "3594859",
    "end": "3600119"
  },
  {
    "text": "Yeah, that's another\nway to visualize it, which is if this is beyond\nmy artistic abilities, that's",
    "start": "3600119",
    "end": "3605670"
  },
  {
    "text": "regions beyond. So yeah, wonderful question. No, no, [LAUGHS] that's fine. I do not have a lot of\nmy ego tied up in that.",
    "start": "3605670",
    "end": "3612230"
  },
  {
    "text": "Yeah. I'm just kind of confused\non the processes. So at this point, this is\nafter we modeled our Gausians.",
    "start": "3612230",
    "end": "3618440"
  },
  {
    "text": "So now we have the Gausians,\nand we're evaluating? Yeah, awesome. So what's going on here, the\ntrick that we're going to do",
    "start": "3618440",
    "end": "3624430"
  },
  {
    "text": "is we're going to assume-- OK, so every time you\nset one of these values,",
    "start": "3624430",
    "end": "3630680"
  },
  {
    "text": "you give me a\ndistribution, right? That gives me a distribution. So now I have an infinite\nnumber of these things that are out there with\ndifferent settings of phi,",
    "start": "3630680",
    "end": "3637100"
  },
  {
    "text": "different cluster centers,\ndifferent samplings. So now imagine you had--\nlike I grabbed one of them, and then I did the\nsampling process.",
    "start": "3637100",
    "end": "3642680"
  },
  {
    "text": "And it generates some data. Great, so we\nunderstand that piece. Now what happens,\nthough, in our problem",
    "start": "3642680",
    "end": "3647789"
  },
  {
    "text": "is we're going to\ninvert that process. So we see some data,\njust the xis themselves. And now we want to\nselect among all",
    "start": "3647790",
    "end": "3654280"
  },
  {
    "text": "of those infinite things\nthat are out there, which are parameterized now by\nthese phis and mus and sigmas, which one is most likely the\none that generated our data.",
    "start": "3654280",
    "end": "3662029"
  },
  {
    "text": "And intuitively we\nknow, as I said, if the cluster centers\nare super far apart, and our data is\nall in the middle,",
    "start": "3662030",
    "end": "3667240"
  },
  {
    "text": "that one's probably less\nlikely than one that has the cluster centers closer. We're going to be precise in a\nsecond about how we fit that.",
    "start": "3667240",
    "end": "3673838"
  },
  {
    "text": "But you can kind of\nsee where it's going to come from is this model. So in the same way we\nuse maximum likelihood",
    "start": "3673839",
    "end": "3679280"
  },
  {
    "text": "before-- we'll get\nthere, we're going to do a little bit\nmore intuition-- we're going to say that the parameters\nthat generated our data",
    "start": "3679280",
    "end": "3684950"
  },
  {
    "text": "are the most likely ones\nafter we've seen the data. So we'll condition\non the data and try to invert it to find it.",
    "start": "3684950",
    "end": "3690500"
  },
  {
    "text": "So this thinking of the\nlatent forward process is super weird, right? And so yeah, you're\nexactly right.",
    "start": "3690500",
    "end": "3696130"
  },
  {
    "text": "Does that make sense, though? We think about the process. And then we're like,\noh, if we inverted it, that's kind of what\nit must have been.",
    "start": "3696130",
    "end": "3701660"
  },
  {
    "text": "Yeah, go ahead. [INAUDIBLE] Yeah, please. So we kind of almost\nguess parameters",
    "start": "3701660",
    "end": "3710030"
  },
  {
    "text": "and give us the various\nsets of different parameters like sigma 1 [INAUDIBLE] from\nthe most closely happens.",
    "start": "3710030",
    "end": "3715880"
  },
  {
    "text": "Exactly right. The thing is, is we want\nto be-- exactly right. We can just guess all the\nparameters or try all of them. Problem is there's\ninfinitely many.",
    "start": "3715880",
    "end": "3721319"
  },
  {
    "text": "So the question is, can we\nsolve them and find them faster than that? But if we could just in\ntheory, there's-- well,",
    "start": "3721319",
    "end": "3727140"
  },
  {
    "text": "in theory is a weird statement\nbecause it's uncountable many of them. But we could conceptually\ntry all of the parameters",
    "start": "3727140",
    "end": "3733160"
  },
  {
    "text": "and then see which one was\nclosest in probability, had the highest likelihood score.",
    "start": "3733160",
    "end": "3738650"
  },
  {
    "text": "And we're going to\ntry-- and that's going to be our gold standard\nof what we want to pull out. You got it perfectly. Please.",
    "start": "3738650",
    "end": "3744160"
  },
  {
    "text": "But there's only value\nfor B. [INAUDIBLE] I'm sorry, I didn't\ncatch the last piece.",
    "start": "3744160",
    "end": "3750470"
  },
  {
    "text": "B only has one value. Right. Always 100%. [INAUDIBLE]",
    "start": "3750470",
    "end": "3756049"
  },
  {
    "text": "Yeah, in that case if\nthere's only one value, then you know everything\ncame from one source and you're just\nfitting a Gaussian.",
    "start": "3756049",
    "end": "3762010"
  },
  {
    "text": "And the most likely\nestimate for a Gaussian is, as you saw from GDA\nand everything else, is average your data\nto compute the mean",
    "start": "3762010",
    "end": "3768010"
  },
  {
    "text": "and then can compute\nthe variance from that. And then you have it perfectly. Wonderful. Awesome, we've got this.",
    "start": "3768010",
    "end": "3773700"
  },
  {
    "text": "All right, so let's\nsee the algorithm that does this because it\nmirrors our friend, k-means.",
    "start": "3773700",
    "end": "3781390"
  },
  {
    "text": "OK, we're also studying\nthis, by the way, because this same pattern\nwill repeat itself",
    "start": "3781390",
    "end": "3788420"
  },
  {
    "text": "in our next lecture. It's a famous algorithm,\nso it's fun to know about.",
    "start": "3788420",
    "end": "3794920"
  },
  {
    "text": "And it's important\npedagogically. I don't know if you\nactually have to do anything with it in the class. And it mirrors k-means.",
    "start": "3794920",
    "end": "3800200"
  },
  {
    "text": "So like, why are you\nteaching me these two things? They seem to differ\nin small ways. And that difference--\nk-means seems a lot",
    "start": "3800200",
    "end": "3805568"
  },
  {
    "text": "more intuitive than this whole\ninfinite number of models that we're selecting among. But we want to get\nto that world view",
    "start": "3805569",
    "end": "3810859"
  },
  {
    "text": "so that we want to\nrelate the two, OK? So one, there's an E-step.",
    "start": "3810859",
    "end": "3817790"
  },
  {
    "text": "So this Em is very\nfamous, and we'll come back to that in a second. Here we guess-- just as\nyou put it perfectly--",
    "start": "3817790",
    "end": "3824180"
  },
  {
    "text": "we guess the latent\nvalues, which in this thing are the values of the zis.",
    "start": "3824180",
    "end": "3831480"
  },
  {
    "text": "So we guess all of the cluster\ncenters, their distributions by hook or crook.",
    "start": "3831480",
    "end": "3836740"
  },
  {
    "text": "We just figure it out. That's our first piece. We'll see how we do that\nin a more intuitive way. And then the m-step, we\nupdate the other parameters.",
    "start": "3836740",
    "end": "3849088"
  },
  {
    "text": "So if we knew the distributions,\nwe knew-- in my observation one, if we knew where\nevery point came from,",
    "start": "3849089",
    "end": "3855900"
  },
  {
    "text": "then we could just\nrun GDA on it. We could just run, find which\nGaussians are in each set. We just fit all of them.",
    "start": "3855900",
    "end": "3861859"
  },
  {
    "text": "There's a slight\ntwist that we're going to not know where\nprecisely every point is. We're going to know them-- distribution.",
    "start": "3861859",
    "end": "3867369"
  },
  {
    "text": "So we have to do something\na little bit more complicated but not too\nmuch more complicated. OK, this is our first example\nof a very famous algorithm.",
    "start": "3867369",
    "end": "3876180"
  },
  {
    "text": "The first example of Em. Em is like a very,\nvery famous algorithm",
    "start": "3876180",
    "end": "3881500"
  },
  {
    "text": "that people like\nused for decades.",
    "start": "3881500",
    "end": "3886809"
  },
  {
    "text": "I don't want to oversell it. I have a colleague\nand friend who says, you only run it when you\ndon't know what you're doing.",
    "start": "3886809",
    "end": "3892450"
  },
  {
    "text": "And he's right in the sense-- he's kind of a curmudgeon. He's a good dude. But he's right in\nthe sense that if you",
    "start": "3892450",
    "end": "3898700"
  },
  {
    "text": "knew exactly what\nyou were looking for, you wouldn't run this algorithm. But that's precisely\nwhere it's interesting, is when you run these\nkind of Em algorithms.",
    "start": "3898700",
    "end": "3904250"
  },
  {
    "text": "You know something\nabout the setup. All right, so let's\nsee mathematically what this looks like.",
    "start": "3904250",
    "end": "3909289"
  },
  {
    "text": "And in your head, you\nshould be thinking, how do I-- what did\nI do in k-means? The E-step.",
    "start": "3909289",
    "end": "3916420"
  },
  {
    "text": "So here we're given the data\nand current values, which",
    "start": "3916420",
    "end": "3926088"
  },
  {
    "text": "are guesses, for phi, mu,\nsigma, blah, blah, blah, blah, all the stuff.",
    "start": "3926089",
    "end": "3932759"
  },
  {
    "text": "Sigma 1, mu 1, mu 2, whatever,\nMu 1, all the parameters. OK?",
    "start": "3932760",
    "end": "3938140"
  },
  {
    "text": "And our do is we have to\npredict zi for i equals 1 to n,",
    "start": "3938140",
    "end": "3952190"
  },
  {
    "text": "Now I'm going to introduce\nsome notation here following our notes.",
    "start": "3952190",
    "end": "3966810"
  },
  {
    "text": "Given xi by mu sigma.",
    "start": "3966810",
    "end": "3973480"
  },
  {
    "text": "So what's going on? This is our goal. OK, so what do we want?",
    "start": "3973480",
    "end": "3980838"
  },
  {
    "text": "We want to compute these\nweights which I'm just giving a new notation to because\nzs will be changing as we run",
    "start": "3980839",
    "end": "3986720"
  },
  {
    "text": "and all the rest. We're given the data\npoint, conditioned on that. So we know the point\nwe're looking at.",
    "start": "3986720",
    "end": "3992839"
  },
  {
    "text": "We all the rest of\nthe parameters-- the likelihoods,\nthe frequencies, with which we're sampling\nfrom each one of them.",
    "start": "3992839",
    "end": "3999450"
  },
  {
    "text": "We have our current guess. We have our current\nguess of how-- where the center of every cluster\nsource is and its variance.",
    "start": "3999450",
    "end": "4008349"
  },
  {
    "text": "And now what we want\nto do is we want to compute how likely\na particular point is to belong to a cluster.",
    "start": "4008349",
    "end": "4014810"
  },
  {
    "text": "Intuitively, if\nit's really close, the probability should be\nhigh to the cluster center. If it's a really-- if it's a really far away,\nit should be close to zero.",
    "start": "4014810",
    "end": "4021710"
  },
  {
    "text": "But it's continuous. It's not going to be 0 itself\nbecause the Gaussian doesn't go to 0 anywhere.",
    "start": "4021710",
    "end": "4028030"
  },
  {
    "text": "So how do we do this? Well it's nothing more\nthan Bayes' rules.",
    "start": "4028030",
    "end": "4035779"
  },
  {
    "text": "Bayes' rule.",
    "start": "4035779",
    "end": "4042039"
  },
  {
    "text": "xi. Oops.",
    "start": "4042039",
    "end": "4048298"
  },
  {
    "text": "Sigma. Oops, over-- all right.",
    "start": "4048299",
    "end": "4063950"
  },
  {
    "text": "All right, so all I've done\nhere is something really simple.",
    "start": "4063950",
    "end": "4072359"
  },
  {
    "text": "I've taken Xi, which\nI've conditioned on it. And I've kind of divided it up. So this is kind\nof the likelihood of the data being generated with\nthis, which is a probability.",
    "start": "4072359",
    "end": "4080230"
  },
  {
    "text": "And then these two things\nbeing jointly done together. And then I'm going\nto factor them out",
    "start": "4080230",
    "end": "4085770"
  },
  {
    "text": "as I sum over all of the\ndifferent probabilities. So this is going to be\nequal to probability of xi--",
    "start": "4085770",
    "end": "4093630"
  },
  {
    "text": "oops, probability of xi. zi given j, probability\nof zi j over sum.",
    "start": "4093630",
    "end": "4105659"
  },
  {
    "text": "I have to you use\nl here instead of j because I don't want to\nconfuse what we're doing.",
    "start": "4105660",
    "end": "4113380"
  },
  {
    "text": "zi I equals l, comma,\nthe whole thing.",
    "start": "4113380",
    "end": "4119889"
  },
  {
    "text": "P zi equals l. OK, so the point is, we\nknow all of these functions.",
    "start": "4119890",
    "end": "4131849"
  },
  {
    "text": "Oh, sorry. And everything here, by\nthe way, has this stuff.",
    "start": "4131850",
    "end": "4137028"
  },
  {
    "text": "We know all that information. So that's everywhere. OK? So we know all of the\nestimates and our guess.",
    "start": "4137029",
    "end": "4145400"
  },
  {
    "text": "So what is this\nprobability right here? Well, if we knew that\nit was conditioned--",
    "start": "4145400",
    "end": "4151568"
  },
  {
    "text": "that we knew that this point\ncame from the cluster, well, it's just nothing more than our\nfriend, the Gaussian, right?",
    "start": "4151569",
    "end": "4156829"
  },
  {
    "text": "This character right here,\nwhich I'll highlight, this is just a Gaussian. We know that from\nthe model, right?",
    "start": "4156830",
    "end": "4163778"
  },
  {
    "text": "So is this. So I can be really\nexplicit about it.",
    "start": "4163779",
    "end": "4169231"
  },
  {
    "text": "It's like x above xi\nminus mu i squared",
    "start": "4169231",
    "end": "4174480"
  },
  {
    "text": "over 2 sigma i squared, times\nsome normalizing constant.",
    "start": "4174480",
    "end": "4184250"
  },
  {
    "text": "So we know what this is. What's this one?",
    "start": "4184250",
    "end": "4189338"
  },
  {
    "text": "Those are our phis. So this character here-- oops, I shouldn't\nuse that color.",
    "start": "4189339",
    "end": "4200520"
  },
  {
    "text": "This is phi j. This is phi l. So I decompose the\nproblem, once I know it,",
    "start": "4200520",
    "end": "4206890"
  },
  {
    "text": "into estimating all\nof these quantities, which I already\nkind of mechanically",
    "start": "4206890",
    "end": "4213050"
  },
  {
    "text": "know how to compute. So the key point is we\ncan compute all the terms.",
    "start": "4213050",
    "end": "4219940"
  },
  {
    "text": "Compute all the terms. Now this isn't super surprising. So maybe you'll look\nat this, and you're",
    "start": "4219940",
    "end": "4226250"
  },
  {
    "text": "like, wow, that's just a\nbunch of weird notation. What the heck is\nhe talking about? Look, this is just k-means. It's saying, in some kind\nof generalized sense,",
    "start": "4226250",
    "end": "4233199"
  },
  {
    "text": "it's saying I need to compute\na probability distribution function. OK, k-means doesn't\nneed to do that. But how does it do it?",
    "start": "4233199",
    "end": "4238340"
  },
  {
    "text": "It says, well, I\nconsider the probability that this xi was\ngenerated from this j. I know how likely it is\nthat the point came from it.",
    "start": "4238340",
    "end": "4245830"
  },
  {
    "text": "I know given how\nlikely, once I'm in the point, what the\nprobability of this data point is.",
    "start": "4245830",
    "end": "4251130"
  },
  {
    "text": "And then what I'm\ngoing to do is I'm going to compare it\nto the likelihood from every other cluster.",
    "start": "4251130",
    "end": "4257420"
  },
  {
    "text": "And that's the probability. Right That's all it's encoding. Instead of having\nthat hard assignment",
    "start": "4257420",
    "end": "4263170"
  },
  {
    "text": "and saying which one's closest? In k-means, this was just a map. It said, look at all\nthe other clusters,",
    "start": "4263170",
    "end": "4268500"
  },
  {
    "text": "and you pick the closest one. Now I'm going to\naverage over it, and I'm just averaging\nover it with Bayes' rule. And it looks like notation.",
    "start": "4268500",
    "end": "4275040"
  },
  {
    "text": "It's a bunch of notation,\nbut it's not super scary. It's just things you\nknow how to compute.",
    "start": "4275040",
    "end": "4280369"
  },
  {
    "text": "Go ahead. If the point is very\nclearly [INAUDIBLE]",
    "start": "4280370",
    "end": "4286860"
  },
  {
    "text": "and has no [INAUDIBLE] with\nother cluster functions,",
    "start": "4286860",
    "end": "4292639"
  },
  {
    "text": "then would the\nprobability [INAUDIBLE] They wouldn't be zero, but\nthey'd be very close to zero. So what would happen\nin that scenario. So in your point,\nlet's say xi is really",
    "start": "4292640",
    "end": "4299050"
  },
  {
    "text": "close to this particular j. So this thing is\nvery-- it's not going to be 1 because the height of\nthe thing is not exactly 1.",
    "start": "4299050",
    "end": "4304270"
  },
  {
    "text": "But it's going to\nbe some high number. Let's say 0.5 or something,\nso some big, big number.",
    "start": "4304270",
    "end": "4309860"
  },
  {
    "text": "Then over here, let's say phi j. That's the other term. So if phi j were equal\nacross all the clusters--",
    "start": "4309860",
    "end": "4317010"
  },
  {
    "text": "we'll come back to what happens\nwhen it's not in a second-- if it's equal across\nall the clusters, we get 0.5 times There's five clusters, 1/5.",
    "start": "4317010",
    "end": "4325290"
  },
  {
    "text": "And then we compare\nthat likelihood to the rest of these. And because you said these\nwere really, really far away,",
    "start": "4325290",
    "end": "4330370"
  },
  {
    "text": "what happens here? You get this term\nrepeated, right, so you get exactly that one\nterm plus a bunch of things",
    "start": "4330370",
    "end": "4335750"
  },
  {
    "text": "which are super close to zero. And so as a result, this thing\nwill be very, very close to 1. Yeah, does that make sense?",
    "start": "4335750",
    "end": "4341870"
  },
  {
    "text": "Now what happens, just\nin that inference, if phi j were very,\nvery close to 0?",
    "start": "4341870",
    "end": "4348080"
  },
  {
    "text": "So now there's this trade-off. If the point is-- there's the cluster\ncenter, and it's close.",
    "start": "4348080",
    "end": "4353510"
  },
  {
    "text": "But I think it's\nextremely unlikely. My phi j is like and I've only seen 1,000 points.",
    "start": "4353510",
    "end": "4358940"
  },
  {
    "text": "I still don't consider\nit very likely that this source actually\ngenerated something in that setting.",
    "start": "4358940",
    "end": "4364179"
  },
  {
    "text": "And that's all Bayes'\nrule does in general is trade-off those two things. Does that make sense?",
    "start": "4364179",
    "end": "4370480"
  },
  {
    "text": "Yeah, awesome. OK. All right, now back\nto the-- oh, please. I just have a question because\nI'm a bit confused on the fact that phi j and phi l, those\nare actual probabilities,",
    "start": "4370480",
    "end": "4378510"
  },
  {
    "text": "whereas the probability of xi\nis the probability density.",
    "start": "4378510",
    "end": "4385300"
  },
  {
    "text": "Yeah, so I use them-- so yes, so you can\ndo this because you can use the likelihood\nratios in this way.",
    "start": "4385300",
    "end": "4393150"
  },
  {
    "text": "And this is the correct\nthing to do from Bayes' rule, but it's a little bit sticky\nbecause this is just a PDF. But the fact that it's\nlike normalized up to it",
    "start": "4393150",
    "end": "4400350"
  },
  {
    "text": "allows this thing to go through. But yeah, you're exactly right. It's a little\nsquishy, but it works.",
    "start": "4400350",
    "end": "4406430"
  },
  {
    "text": "Wonderful question. Awesome. So I hope what you got\nfrom this is-- and also I",
    "start": "4406430",
    "end": "4412690"
  },
  {
    "text": "wanted to come back. So that whole weird rant about\nhow the data are generated is now mechanically\nthe way the math works.",
    "start": "4412690",
    "end": "4418470"
  },
  {
    "text": "That's why I keep\nranting about it. You pick a point. You generate the data.",
    "start": "4418470",
    "end": "4423780"
  },
  {
    "text": "That's like assigning\nthe likelihood score. When you wrote the\ngenerative model, you told me how\nlikely it was that",
    "start": "4423780",
    "end": "4430560"
  },
  {
    "text": "given you were in a\nparticular cluster that you would\ngenerate this point. That's the normal distribution.",
    "start": "4430560",
    "end": "4436140"
  },
  {
    "text": "And then you compare and bake\nthem off against each other. And that gave you a\nprobability distribution.",
    "start": "4436140",
    "end": "4441350"
  },
  {
    "text": "That's it. Awesome. Now there's the other stuff.",
    "start": "4441350",
    "end": "4452350"
  },
  {
    "text": "This stuff is much\nless interesting. So here we're given\nall those Wijs. J which is our\ncurrent estimate--",
    "start": "4452350",
    "end": "4460900"
  },
  {
    "text": "est of P zi equals j,\nfor i goes from 1 to n,",
    "start": "4460900",
    "end": "4471520"
  },
  {
    "text": "j goes from 1 to k. And what we have\nto do is estimate",
    "start": "4471520",
    "end": "4477059"
  },
  {
    "text": "the observed parameters,\nthe nonlatent parameters. Now, this is\nconceptually interesting",
    "start": "4477060",
    "end": "4483940"
  },
  {
    "text": "because we split our thing\ninto latent, which are not observed-- the zis\nare not observed,",
    "start": "4483940",
    "end": "4490810"
  },
  {
    "text": "what the probability\nis that you are in a particular\nclass-- and the things we did observe-- the frequency. You know how many\nare in each class.",
    "start": "4490810",
    "end": "4496310"
  },
  {
    "text": "You know their cluster\nsizes and all the rest. You can measure those things. And we'll do that using MLE\nbecause that's the tool we use.",
    "start": "4496310",
    "end": "4504270"
  },
  {
    "text": "By the way, we use MLE\na lot in this course. But it's not--\nit's very powerful, but it's not everything.",
    "start": "4504270",
    "end": "4510178"
  },
  {
    "text": "I'll come back to that later. But it's a principle. So for example, what is phi j?",
    "start": "4510179",
    "end": "4517030"
  },
  {
    "text": "What is the estimated frequency? Well, we sum over\nall the points. i goes from 1 to n of Wji.",
    "start": "4517030",
    "end": "4527199"
  },
  {
    "text": "They're our guess of the\nfraction of elements. And from cluster j.",
    "start": "4527200",
    "end": "4537040"
  },
  {
    "text": "We can make this a\nlittle bit more rigorous, and we'll do it next time. And the point is\nyou just do MLE.",
    "start": "4537040",
    "end": "4542340"
  },
  {
    "text": "I don't want to go\nthrough these calculations because they're kind of boring. But you go through\nthem at least once.",
    "start": "4542340",
    "end": "4548000"
  },
  {
    "text": "And we can make that rigorous. And we'll do that when\nwe do the MLE thing. So I'll do it in class. So don't worry if it\ndoesn't stick now.",
    "start": "4548000",
    "end": "4553500"
  },
  {
    "text": "We'll do it on Monday\nin a little bit more generalized setting. But what I hope you get\nhere is, if I know the Wijs, I have to compute the\nestimate of phi j.",
    "start": "4553500",
    "end": "4561840"
  },
  {
    "text": "And then I just average\nover the probabilities. And we'll make that-- we'll\ndo all the math to expand that out.",
    "start": "4561840",
    "end": "4567250"
  },
  {
    "text": "But you already\nknow how to do this. This is just the ML\nstuff that you've been doing for the last k weeks.",
    "start": "4567250",
    "end": "4578550"
  },
  {
    "text": "So far so good? Please. So you're going to do this,\nI believe, in next class?",
    "start": "4578550",
    "end": "4585350"
  },
  {
    "text": "Yeah. OK. No, we're going to--\nwe're not going to be-- this is the right answer. We're going to derive\nthis in more generality,",
    "start": "4585350",
    "end": "4591800"
  },
  {
    "text": "so you can solve for a larger\nclass of models on Monday. Oh, OK. So it's fraction of\nwhat from clusters?",
    "start": "4591800",
    "end": "4599409"
  },
  {
    "text": "Oh, fraction of points. Sorry, that's really terrible. I said elements, and\nthen I don't know why.",
    "start": "4599409",
    "end": "4605070"
  },
  {
    "text": "These are the points. Points from-- this\nshould be source. I kept using-- I was trying\nto make source and target",
    "start": "4605070",
    "end": "4611480"
  },
  {
    "text": "independent in my head, and\nI did not use them carefully in this lecture. Apologies. Fraction of points\nfrom source j.",
    "start": "4611480",
    "end": "4622190"
  },
  {
    "text": "Is the rough intuition\nof why this is k-means kind of similar to you? You pick a set of\nmeans, which are",
    "start": "4622190",
    "end": "4627230"
  },
  {
    "text": "like your sufficient statistics\nto describe your problem. Then you re-average over them. And what's going on here\nis, you're picking a set--",
    "start": "4627230",
    "end": "4634730"
  },
  {
    "text": "now instead of just\npicking centers, you're picking distributions. Then what you're doing is you're\nreweighting the distribution,",
    "start": "4634730",
    "end": "4640400"
  },
  {
    "text": "say, if that was really the\nbackground probability of all these linkages,\nthen this is what you're most likely\ncluster sizes would be.",
    "start": "4640400",
    "end": "4646560"
  },
  {
    "text": "This is how much points\nyou would have in each. OK, does that agree\nwith your guess? And you just cycle\nthat again and again",
    "start": "4646560",
    "end": "4652770"
  },
  {
    "text": "until you get back to\nthe guess, the same way you're doing k-means. Awesome. All right, so--",
    "start": "4652770",
    "end": "4659110"
  },
  {
    "text": "What other Em models\nare we going to study?",
    "start": "4659110",
    "end": "4668130"
  },
  {
    "text": "A bunch. [LAUGHS] Yeah, a bunch. Yeah, so basically\nan Em model can be applied whenever you\nhave a latent z like this,",
    "start": "4668130",
    "end": "4677080"
  },
  {
    "text": "and you want to do some\nkind of decomposition to it. [INAUDIBLE] Yeah, it's going to have\nthis two-step pattern where",
    "start": "4677080",
    "end": "4685790"
  },
  {
    "text": "you have a latent variable. And then, I mean, it's\nnot necessary-- there's no requirement that any\nof this be supervised.",
    "start": "4685790",
    "end": "4692699"
  },
  {
    "text": "In some sense, the\nlatent variable is your guest at supervision. We'll see ways to inform.",
    "start": "4692699",
    "end": "4697870"
  },
  {
    "text": "So for example, we'll\nsee an algorithm where the first way it was\nderived actually did use Em. But there's a more clever\nway to solve it provably.",
    "start": "4697870",
    "end": "4704760"
  },
  {
    "text": "But Em is the general form\nof, there's a latent variable that you don't see, and\nyou have a model for it.",
    "start": "4704760",
    "end": "4710139"
  },
  {
    "text": "You estimate that\nparameter, and then you solve a traditional\nsupervised machine learning or kind of estimation\nproblem under the covers.",
    "start": "4710139",
    "end": "4718139"
  },
  {
    "text": "And that's very, very general. Your latent variable\nhere is clusters. But we'll see. It could be distributions and\nall kinds of fancy stuff later.",
    "start": "4718139",
    "end": "4725520"
  },
  {
    "text": "Please. So in the other stuff, we see\nthat we estimate [INAUDIBLE]",
    "start": "4725520",
    "end": "4736190"
  },
  {
    "text": "how do we use the MLE? So I think [INAUDIBLE]\nalready assume",
    "start": "4736190",
    "end": "4743270"
  },
  {
    "text": "that we have an initial\ngrasp of [INAUDIBLE]",
    "start": "4743270",
    "end": "4748600"
  },
  {
    "text": "Yep, so no, so--\noh, great question. I see where the\nconfusion comes in. No, so here it's like we\nare almost memoryless. So we had those phi and sigma\nand all those other things.",
    "start": "4748600",
    "end": "4758420"
  },
  {
    "text": "And now just like in k-means,\nwe throw away some information. And we try to reconstruct it. And here, given\nour link of Pis, we",
    "start": "4758420",
    "end": "4765080"
  },
  {
    "text": "try to compute all of those\nobserved parameters, which are going to be the mus\nand the sigmas and the phis and blah, blah, blah, the rest\nof the observed parameters.",
    "start": "4765080",
    "end": "4772690"
  },
  {
    "text": "So it's like, given the linkage\nfunction, we do that again. And then what we would expect is\nthat those parameters will not move around so much\nover time, and that's",
    "start": "4772690",
    "end": "4779690"
  },
  {
    "text": "when it will converge, similar\nto the way k-means worked. Great, great question. Awesome. Please.",
    "start": "4779690",
    "end": "4785100"
  },
  {
    "text": "[INAUDIBLE] have better\nguesses for [INAUDIBLE]",
    "start": "4785100",
    "end": "4790700"
  },
  {
    "text": "Awesome. Yeah. There is not something that\nhas such a crisp solution, to my knowledge.",
    "start": "4790700",
    "end": "4796210"
  },
  {
    "text": "I don't actually know one. But that's a really\ngood question. How do you initialize this? And in what situations can\nyou better initialize it?",
    "start": "4796210",
    "end": "4802710"
  },
  {
    "text": "It seems natural enough\nto think about one, but I don't know\na proof for one. Yeah, it's a great question. You can post it on Ed,\nand I can dig around",
    "start": "4802710",
    "end": "4808270"
  },
  {
    "text": "and see if anyone did that. My suspicion is yes because\nk-means-plus-plus was such an important thing.",
    "start": "4808270",
    "end": "4814110"
  },
  {
    "text": "It's a wonderful idea. Other questions.",
    "start": "4814110",
    "end": "4820250"
  },
  {
    "text": "All right, OK, so\nlooking at this,",
    "start": "4820250",
    "end": "4826270"
  },
  {
    "text": "trying to think what\nI should tell you.",
    "start": "4826270",
    "end": "4831820"
  },
  {
    "text": "All right, so we have\nabout nine minutes left.",
    "start": "4831820",
    "end": "4841349"
  },
  {
    "text": "Let me see. All right, so what\nI want to do is I think I want to just tell\nyou the steps that we're going",
    "start": "4841350",
    "end": "4848000"
  },
  {
    "text": "to go through next time because\nI think over the weekend, this will be too much. Traditionally I teach\nit Monday, Wednesday.",
    "start": "4848000",
    "end": "4853500"
  },
  {
    "text": "But I want-- I'm going to\nwant to redo this, I think. That's what I think. So right now, what I want to do\nis have a detour into one thing",
    "start": "4853500",
    "end": "4860730"
  },
  {
    "text": "that we need, which is convexity\nand Jensen's inequality. So I'm just going to\ndraw the basics here.",
    "start": "4860730",
    "end": "4866870"
  },
  {
    "text": "And then I'll give\nyou a sense of what the Em algorithm looks like. Now the reason we need this\nis that this is a key result.",
    "start": "4866870",
    "end": "4873120"
  },
  {
    "text": "And it confuses\npeople every year. So I spend more time\non it, and hopefully it confuses them less.",
    "start": "4873120",
    "end": "4878771"
  },
  {
    "text": "Sometimes people\nsay it's trivial. And then I'm very, very happy. So if you think it's\ntrivial, then I did my job. OK?",
    "start": "4878771",
    "end": "4883940"
  },
  {
    "text": "All right, so what\nwe're going to need to do-- the reason\nI want to tell you this is, what we're\ngoing to have to do",
    "start": "4883940",
    "end": "4889710"
  },
  {
    "text": "is we're going to have to have\na mathematical abstraction of like this going\nback and forth and this guessing\nback and forth. And that's going to be basically\ntwo different functions.",
    "start": "4889710",
    "end": "4897150"
  },
  {
    "text": "One function is going to be a\nlower bound of the function-- there's going to\nbe the actual loss function for the totally crazy\nprobability distribution that",
    "start": "4897150",
    "end": "4905150"
  },
  {
    "text": "has all the infinite models and\neverything jointly together, OK, the actual\nlikelihood function.",
    "start": "4905150",
    "end": "4910460"
  },
  {
    "text": "And what we're\ngoing to do is we're going to have an\napproximation of it that says, given we have a particular\nguess of the zis, we're going to have\nthis lower bound.",
    "start": "4910460",
    "end": "4916780"
  },
  {
    "text": "And we're going to have to\nmove between the lower bound and the upper bound in the\nlower bounding function, and that is going to be\nfacilitated by something",
    "start": "4916780",
    "end": "4923650"
  },
  {
    "text": "called Jensen's inequality. And it's worth understanding\nbecause it's something that you can use. So I'll just get started\na little bit on it",
    "start": "4923650",
    "end": "4929960"
  },
  {
    "text": "and draw some pictures, and\nthen we'll pick it up next time. OK, the ab element of omega.",
    "start": "4929960",
    "end": "4937510"
  },
  {
    "text": "And I would certainly\nrather answer questions because we can cut\ninto later lectures.",
    "start": "4937510",
    "end": "4943420"
  },
  {
    "text": "We don't need to rush. ab is in omega.",
    "start": "4943420",
    "end": "4951199"
  },
  {
    "text": "So let me draw this. So something is convex if\nthe line joining them--",
    "start": "4951199",
    "end": "4956240"
  },
  {
    "text": "oops-- is inside them.",
    "start": "4956240",
    "end": "4961560"
  },
  {
    "text": "So if I take any two points\nin here, any a and b, and I draw the straight\nline between them. We're in Euclidean space,\nso it's a straight line.",
    "start": "4961560",
    "end": "4968690"
  },
  {
    "text": "Then if it's convex, then no\nmatter which points I pick, the line between them is\ngoing to remain in the set.",
    "start": "4968690",
    "end": "4974350"
  },
  {
    "text": "This is a convex object,\nso like an ellipse or a circle or\nsomething like that. In contrast, here if I\npick points a and b here,",
    "start": "4974350",
    "end": "4984050"
  },
  {
    "text": "this is not convex. And these are going to be--",
    "start": "4984050",
    "end": "4990780"
  },
  {
    "text": "yeah, we're going to care\nabout these quite a bit. So what does this\nmean in symbols?",
    "start": "4990780",
    "end": "4995850"
  },
  {
    "text": "In symbols, we have to\ncheck for all alpha--",
    "start": "4995850",
    "end": "5002020"
  },
  {
    "text": "for all ab in omega,\nwhich is our set, omega. Lambda a plus 1 minus-- oops--",
    "start": "5002020",
    "end": "5010980"
  },
  {
    "text": "the line between them-- is an element of omega. And lambda here is\nan element of 0.1",
    "start": "5010980",
    "end": "5018940"
  },
  {
    "text": "That's all this\npicture is saying. This picture and this\nmath are the same. And you need to check for all.",
    "start": "5018940",
    "end": "5024170"
  },
  {
    "text": "Right here, clearly, if\nI put a here and b here, there's a line between them. The reason it's not convex is\nthere exist one pair of a and b",
    "start": "5024170",
    "end": "5031670"
  },
  {
    "text": "for which I go out of this set. Now we're going to use it\nwhen this bottom piece is",
    "start": "5031670",
    "end": "5037460"
  },
  {
    "text": "a function. And we think about the function\ngoing up to infinity, the graph of the function being convex.",
    "start": "5037460",
    "end": "5042650"
  },
  {
    "text": "And what this tells us is\nif we look at chords, that is points between the\nfunction like this,",
    "start": "5042650",
    "end": "5047690"
  },
  {
    "text": "they should always be lower\nbounds to the function. And that would be a\nlittle bit opaque. But I feel like if you\nthink about a function that",
    "start": "5047690",
    "end": "5053060"
  },
  {
    "text": "looks like this, the\nx squared function, that set will be convex.",
    "start": "5053060",
    "end": "5058160"
  },
  {
    "text": "That's the canonical\nconvex function. All right, so what\nwe're going to see",
    "start": "5058160",
    "end": "5064730"
  },
  {
    "text": "is we're going to go from\nthese definitions of convexity on sets to convexity\non functions.",
    "start": "5064730",
    "end": "5070310"
  },
  {
    "text": "And that's going to allow\nus to basically prove the following statement, which\nwe will prove next time, which looks mysterious but is not.",
    "start": "5070310",
    "end": "5077770"
  },
  {
    "text": "You'll see this is\ngreater than f of E of x.",
    "start": "5077770",
    "end": "5084060"
  },
  {
    "text": "So there's going to be--\nwe're going to show next time. Just I want to give a\nlittle bit of a roadmap.",
    "start": "5084060",
    "end": "5089670"
  },
  {
    "text": "We're going to use this\ndefinition of a convexity to prove a theorem. This theorem is called\nJensen's theorem, and it's effectively\nimmediate from the definition.",
    "start": "5089670",
    "end": "5098940"
  },
  {
    "text": "Once you understand the\ndefinition of this four functions, if f is\nconvex, this is true. f convex.",
    "start": "5098940",
    "end": "5104820"
  },
  {
    "text": "A function is convex\nif its graph is convex. And We'll draw that out.",
    "start": "5104820",
    "end": "5109900"
  },
  {
    "text": "Once we know that-- we're going to need that for\nconvex and concave functions-- that's going to\nbe a key building block for what we do for\nthe next couple of lectures.",
    "start": "5109900",
    "end": "5117380"
  },
  {
    "text": "We've talked about\nconvexity once or twice in the supervised\nsetting, but now we're going to need it in a\nlittle bit more detail.",
    "start": "5117380",
    "end": "5123679"
  },
  {
    "text": "All right, so let me wrap up\nand tell you what we did today, so that you remember what\nI want you to take away.",
    "start": "5123679",
    "end": "5129860"
  },
  {
    "text": "So we started with this\nidea of the difference between supervised and\nunsupervised learning. We then went through\nk-means, which",
    "start": "5129860",
    "end": "5135560"
  },
  {
    "text": "was a really simple,\nheuristic algorithm, but in a hard problem that\nwould find these clusters.",
    "start": "5135560",
    "end": "5141370"
  },
  {
    "text": "We talked about\nthis idea that you needed to be able to model the\nproblem to be able to solve it. You had to input\neither k or something.",
    "start": "5141370",
    "end": "5147670"
  },
  {
    "text": "And you had to be able to check\nor at least visually inspect the answer. We then talked about\na generalization",
    "start": "5147670",
    "end": "5152850"
  },
  {
    "text": "of k-means which was called\nmixture of Gaussians. And the only\ngeneralization was rather than belonging to a single\ncluster deterministically,",
    "start": "5152850",
    "end": "5159969"
  },
  {
    "text": "you try to find this probability\ndistribution over everything. That led to a bunch of\nnotation, but the notation still",
    "start": "5159970",
    "end": "5166630"
  },
  {
    "text": "basically had this\ntwo-step procedure underneath the covers\nof guess the centers and then check how\nlikely they are.",
    "start": "5166630",
    "end": "5172840"
  },
  {
    "text": "The how likely they are and\nk-means was the distance. In GMM, it had this\nmore complicated probabilistic model.",
    "start": "5172840",
    "end": "5179139"
  },
  {
    "text": "We like that more complicated\nprobabilistic model because it's going\nto allow us to model even more sophisticated\nnotions of structure.",
    "start": "5179140",
    "end": "5184940"
  },
  {
    "text": "And then I think I'm just going\nto go through that on Wednesday so that you have all\nthe mathematical details there together.",
    "start": "5184940",
    "end": "5190139"
  },
  {
    "text": "And we'll do a review of that. Thanks so much for your\ntime and attention. Have a great day.",
    "start": "5190139",
    "end": "5193610"
  }
]
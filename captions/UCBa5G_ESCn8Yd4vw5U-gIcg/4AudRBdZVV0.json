[
  {
    "text": "thanks for having me so yeah I lead the autonomous robotics and perception group at Boulder it's a rather large Bay Oh a",
    "start": "11120",
    "end": "19940"
  },
  {
    "text": "large prehistoric Bay away from here and so and I'll be talking today a little",
    "start": "19940",
    "end": "26119"
  },
  {
    "text": "bit about some work that's going on in my group about robotic perception especially in challenging environments",
    "start": "26119",
    "end": "32240"
  },
  {
    "text": "like in caves but in also types the different types environments but before we do that we have to show a video about",
    "start": "32240",
    "end": "37430"
  },
  {
    "text": "some of the I mean everyone's seen this video it's like wow what can robots not",
    "start": "37430",
    "end": "42920"
  },
  {
    "text": "do right I mean who here's a robot assist a few of you okay that's what I",
    "start": "42920",
    "end": "48950"
  },
  {
    "text": "feel everyone I expect and we look at this and we're like okay well it must be sort of like hand engineered and stuff",
    "start": "48950",
    "end": "55340"
  },
  {
    "text": "like this and it probably is and state feedback is nearly perfect you have a lidar it's they only show their",
    "start": "55340",
    "end": "61400"
  },
  {
    "text": "successful events right so they probably had a hundred of these videos in which had failed previously and so this is but",
    "start": "61400",
    "end": "67700"
  },
  {
    "text": "still pretty impressive even like the arrogance that the platform can show by putting a chance in the air at the end",
    "start": "67700",
    "end": "72880"
  },
  {
    "text": "and if you look at other types of different examples for robotic autonomy",
    "start": "72880",
    "end": "78170"
  },
  {
    "text": "this is some work out of Georgia Tech's auto rally car fairly a few years old at this point using differential GPS to be",
    "start": "78170",
    "end": "84740"
  },
  {
    "text": "able to drift around corners on this small type of vehicle I think it's like",
    "start": "84740",
    "end": "89929"
  },
  {
    "text": "a 1/5 scale vehicle and they have essentially you know like a small",
    "start": "89929",
    "end": "95229"
  },
  {
    "text": "compute platform already on it and GPU it's all on board except for the GPS component for for its state estimation",
    "start": "95229",
    "end": "102259"
  },
  {
    "text": "and of course this has hit the news congratulations I mean this is so exciting to see really has captured the",
    "start": "102259",
    "end": "109159"
  },
  {
    "text": "attention and imagination of many people being able to do these kinds of aggressive maneuvers on full-size",
    "start": "109159",
    "end": "114409"
  },
  {
    "text": "vehicles is even more challenging than being able to do it on these toy vehicles like what we do in my group",
    "start": "114409",
    "end": "120049"
  },
  {
    "text": "this is some work that we did several years back about six years ago at this point being able to drive these small",
    "start": "120049",
    "end": "126439"
  },
  {
    "text": "ground vehicles on kind of terrain park types of environments and again every",
    "start": "126439",
    "end": "132050"
  },
  {
    "text": "person in in the room that has done any sort of research in robotics sees first okay pretty impressive maneuvers but",
    "start": "132050",
    "end": "138920"
  },
  {
    "text": "also they you can't help but look at the motion capture system and realize that even through these types of",
    "start": "138920",
    "end": "144500"
  },
  {
    "text": "Vence you know like being able to jump in everything like that that the mocap is providing us one kilohertz state",
    "start": "144500",
    "end": "149780"
  },
  {
    "text": "feedback at almost perfect accuracy what we would normally ground truth our perception algorithms against the hope",
    "start": "149780",
    "end": "157070"
  },
  {
    "text": "obviously is to be able to remove all of the different external types of state estimation capabilities from this type",
    "start": "157070",
    "end": "164870"
  },
  {
    "text": "of problem and be able to reproduce these results in wild environments",
    "start": "164870",
    "end": "170060"
  },
  {
    "text": "places where we haven't been before where maybe we have been but we don't have any kind of external ground",
    "start": "170060",
    "end": "175670"
  },
  {
    "text": "truthing or fiducia fiducial systems involved and the that is also a fairly",
    "start": "175670",
    "end": "181670"
  },
  {
    "text": "rosy picture so this is also fairly old work project tango about seven years ago",
    "start": "181670",
    "end": "187610"
  },
  {
    "text": "being able to do 3d reconstruction with a simple stereo camera on a cell phone",
    "start": "187610",
    "end": "192890"
  },
  {
    "text": "at real time and what we can see here is 3d models fully fused 3d models of the",
    "start": "192890",
    "end": "199190"
  },
  {
    "text": "environment things that you can then import into game engines and be able to simulate physics over right so we can",
    "start": "199190",
    "end": "205220"
  },
  {
    "text": "actually build models of the environment like what we have here and then be able to say how would a ball for instance",
    "start": "205220",
    "end": "210980"
  },
  {
    "text": "interact with this environment and if a ball then why not a car right so this is",
    "start": "210980",
    "end": "216709"
  },
  {
    "text": "the back end if you will to that whole control system that I was showing about",
    "start": "216709",
    "end": "222019"
  },
  {
    "text": "that car that was jumping on the ramps and doing the loops this is a physics environment being similar or simulating",
    "start": "222019",
    "end": "228739"
  },
  {
    "text": "this this model of a car over the 3d fused model that we had built from perception right but the huge like",
    "start": "228739",
    "end": "236810"
  },
  {
    "text": "gimmick here is that we're doing that state feedback through through motion capture and just to in case you're",
    "start": "236810",
    "end": "243049"
  },
  {
    "text": "wondering well how does this happen you see these lines sort of like you know just coming straight from the vehicle at",
    "start": "243049",
    "end": "249320"
  },
  {
    "text": "the front of it those are all different like simulated worlds what would happen if I just added a little bit more gas",
    "start": "249320",
    "end": "254360"
  },
  {
    "text": "turned maybe half a degree more to the right on this vehicle at this particular point in time those were we call control",
    "start": "254360",
    "end": "260870"
  },
  {
    "text": "candidates and we choose our best one in a in a sort of framework frequently called stochastic model predictive",
    "start": "260870",
    "end": "266510"
  },
  {
    "text": "control and that's that's all stuff that we many of us have seen before right and if you've been to Accra and this is or I",
    "start": "266510",
    "end": "273919"
  },
  {
    "text": "Ross these are these are different kinds of capabilities that have been developed for four years and yet we still don't see too many",
    "start": "273919",
    "end": "280750"
  },
  {
    "text": "places where we can we can migrate this to the wild in fact you know like I want",
    "start": "280750",
    "end": "288070"
  },
  {
    "text": "to show like this is actually fairly difficult to do it's not like mundane this is a human operator attempting to",
    "start": "288070",
    "end": "295330"
  },
  {
    "text": "drive the vehicle through this loop and here's a well-paid postdoc nearly",
    "start": "295330",
    "end": "300610"
  },
  {
    "text": "getting his head cut off because of this car that's going to run into him yeah and doing some superhuman",
    "start": "300610",
    "end": "306100"
  },
  {
    "text": "capabilities you know on his own as well so you know and just to recall for you",
    "start": "306100",
    "end": "313240"
  },
  {
    "text": "that's that's like that's a graduate student attempting to drive that car through that that loop a graduate",
    "start": "313240",
    "end": "318760"
  },
  {
    "text": "student who I promise you has spent a little bit too much time driving this car around because it's so much fun",
    "start": "318760",
    "end": "324729"
  },
  {
    "text": "whereas the computer can do it without any problem at all right very reliably and robustly so the question then",
    "start": "324729",
    "end": "332169"
  },
  {
    "text": "becomes where are these autonomous vehicles I've given you some indication that you know there's there's quite a bit of promise that we can see in the",
    "start": "332169",
    "end": "339160"
  },
  {
    "text": "field of autonomous robotics today we have perception and all of the great advances that have happened there we",
    "start": "339160",
    "end": "344860"
  },
  {
    "text": "have control and I've shown you some super human-like types of control and planning capabilities so where are these",
    "start": "344860",
    "end": "350440"
  },
  {
    "text": "autonomous vehicles and let me show you another video of you know maybe the",
    "start": "350440",
    "end": "355539"
  },
  {
    "text": "state of the art if you will where you know everyone's seen this video from the",
    "start": "355539",
    "end": "361180"
  },
  {
    "text": "DARPA Robotics Challenge the finals back in 2015 of some of the best teams that",
    "start": "361180",
    "end": "367360"
  },
  {
    "text": "build robots trying to field them in this really high-stakes environment and having failure modes and that they've",
    "start": "367360",
    "end": "374139"
  },
  {
    "text": "never seen before and not being able to really accomplish the challenges they would hope and you see graduate students",
    "start": "374139",
    "end": "379870"
  },
  {
    "text": "and postdocs in this video realizing that they have to work for years longer right degrees are pushed out that much",
    "start": "379870",
    "end": "386110"
  },
  {
    "text": "further and I mean the reason why I mean many of you probably work in different",
    "start": "386110",
    "end": "391180"
  },
  {
    "text": "areas here right some of you work in perception and you're gonna say these are all perception challenges or control",
    "start": "391180",
    "end": "397030"
  },
  {
    "text": "and say well inverted pendulum problems in uncertain or uneven terrain are very difficult some of you look at you know",
    "start": "397030",
    "end": "403900"
  },
  {
    "text": "different types of humans supervisory interfaces human factors the ways that humans are interacting with these robots",
    "start": "403900",
    "end": "410260"
  },
  {
    "text": "providing command sir planning methods these are all at fault right so I can't really blame just one of these components it's because the",
    "start": "410260",
    "end": "417560"
  },
  {
    "text": "interplay between these components is so complex and it's really a high dimensional world we're dealing with an",
    "start": "417560",
    "end": "422870"
  },
  {
    "text": "uncertain one at that that require us to you know give a little bit more research",
    "start": "422870",
    "end": "428360"
  },
  {
    "text": "and is is fairly the the human sort of autonomous robotics future is still very",
    "start": "428360",
    "end": "434990"
  },
  {
    "text": "far off of course is a perception person I'm interested actually in this",
    "start": "434990",
    "end": "440480"
  },
  {
    "text": "particular scene does anyone know it happened in this scene just take a look",
    "start": "440480",
    "end": "446110"
  },
  {
    "text": "yes excellent yeah so there was no",
    "start": "446110",
    "end": "456230"
  },
  {
    "text": "torque to balance the torque that they were applying and so they fell right over right and so to me this is kind of",
    "start": "456230",
    "end": "463940"
  },
  {
    "text": "at this interface between perception and control right it's clearly there's some there's some sensors here and the sensor",
    "start": "463940",
    "end": "471320"
  },
  {
    "text": "has got this robot to the red valve but the sensors maybe weren't in the right place one could argue or maybe they were",
    "start": "471320",
    "end": "478550"
  },
  {
    "text": "in the right place but no no there was some sort of behavioral tree issue or something like this that there was no",
    "start": "478550",
    "end": "484630"
  },
  {
    "text": "perception fed back into the controller that said make sure that your grasp is",
    "start": "484630",
    "end": "489860"
  },
  {
    "text": "actually on the red valve so it fell over and in autonomous vehicles which is something that you know it's near and",
    "start": "489860",
    "end": "496010"
  },
  {
    "text": "dear to my heart still you know we we look at problems like this where we say okay there's a camera and maybe multiple",
    "start": "496010",
    "end": "501650"
  },
  {
    "text": "cameras and lidar and everything else as a human we might be saying we could we could see that this looks fairly you",
    "start": "501650",
    "end": "508790"
  },
  {
    "text": "know mundane kind of driving situation but with a little bit closer because of this lens flare that happens right here",
    "start": "508790",
    "end": "515300"
  },
  {
    "text": "as you move forward then there are some weird effects of the auto exposure on the camera also revealing that there are",
    "start": "515300",
    "end": "521510"
  },
  {
    "text": "threats that exist ahead of us so there are just these little tiny like problems",
    "start": "521510",
    "end": "527210"
  },
  {
    "text": "associated with where are you looking how are you looking and are you actually taking into account the kinds of things",
    "start": "527210",
    "end": "532520"
  },
  {
    "text": "that could result in catastrophe for you okay so this is more motivational and",
    "start": "532520",
    "end": "539660"
  },
  {
    "text": "you know this is meant to be able to scale to environments of complexity so driving in India never",
    "start": "539660",
    "end": "546000"
  },
  {
    "text": "done it before everyone tells me it's absolute like you know just complete",
    "start": "546000",
    "end": "551940"
  },
  {
    "text": "sensory overload and what we have here is how would we be able to program an autonomous agent in an environment where",
    "start": "551940",
    "end": "557910"
  },
  {
    "text": "we have to like be modeling each of the possible future directions of this kind these agents here right so I was just",
    "start": "557910",
    "end": "565620"
  },
  {
    "text": "like sitting in a in a self-driving car yesterday and I was truly impressed at",
    "start": "565620",
    "end": "570839"
  },
  {
    "text": "the ability for that car to be able to identify all the pedestrians in the",
    "start": "570839",
    "end": "576029"
  },
  {
    "text": "scene like at one point there was like a head that was like going into a subterranean passageway and the car was",
    "start": "576029",
    "end": "583380"
  },
  {
    "text": "able to tell even in there like crazy rain that there was this person it was like 50 meters away like remarkable",
    "start": "583380",
    "end": "590370"
  },
  {
    "text": "right but try doing the sort of stochastic model predictive control over all future trajectories of these agents",
    "start": "590370",
    "end": "597450"
  },
  {
    "text": "right and then even going a step further asking questions like is this person angry can I apply rational models of",
    "start": "597450",
    "end": "604080"
  },
  {
    "text": "motion to this car that he is driving is this person paying attention is this sort of like you know on the phone or",
    "start": "604080",
    "end": "610320"
  },
  {
    "text": "just scratching his ear maybe these vehicles can't turn because they're weighed down by a certain amount",
    "start": "610320",
    "end": "615420"
  },
  {
    "text": "of load that limits their maneuverability and also questions like you know should I even listen to this",
    "start": "615420",
    "end": "622080"
  },
  {
    "text": "stop sign is it visible by are all parties and obeyed clearly not alright so what I mean to point out from all",
    "start": "622080",
    "end": "629339"
  },
  {
    "text": "this is that the world is not like this nice like model a bowl environment in",
    "start": "629339",
    "end": "634529"
  },
  {
    "text": "many ways the ways that we sort of look at stochastic model predictive control and the reduction of perception and",
    "start": "634529",
    "end": "641040"
  },
  {
    "text": "state estimation into the inputs to that control system so the world is not this",
    "start": "641040",
    "end": "646770"
  },
  {
    "text": "you know sort of nice drivable road where nothing's going to happen or maybe",
    "start": "646770",
    "end": "652589"
  },
  {
    "text": "very few things would happen right and I know that this next slide might be a",
    "start": "652589",
    "end": "658260"
  },
  {
    "text": "little bit difficult for you living in California but the world is more like this right where there's snow and where",
    "start": "658260",
    "end": "664890"
  },
  {
    "text": "different kinds of disabled vehicles might sit on the road and we have to start asking you know like can we",
    "start": "664890",
    "end": "670860"
  },
  {
    "text": "actually model every single scenario in which for instance two versus three versus five people are out pushing a",
    "start": "670860",
    "end": "676560"
  },
  {
    "text": "vehicle along the road okay and furthermore if we're driving in this how do we know",
    "start": "676560",
    "end": "682529"
  },
  {
    "text": "what kind of controller is to apply the stochastic model predictive control framework that I was talking about",
    "start": "682529",
    "end": "687930"
  },
  {
    "text": "before requires our knowing at least some idea about what our friction coefficients are for instance or how our",
    "start": "687930",
    "end": "694139"
  },
  {
    "text": "interactions between wheels and the ground are going to work and in really complicated scenarios for contact",
    "start": "694139",
    "end": "700320"
  },
  {
    "text": "granule granular media or other types of stick slip conditions like this that's actually really challenging to be able",
    "start": "700320",
    "end": "706589"
  },
  {
    "text": "to model okay and so I'm motivated now not by",
    "start": "706589",
    "end": "712230"
  },
  {
    "text": "self-driving cars but by what DARPA is paying me to be interested in which is",
    "start": "712230",
    "end": "717449"
  },
  {
    "text": "truly a remarkable in my opinion type of environment the subterranean environment and so I'm going to talk a little bit",
    "start": "717449",
    "end": "723540"
  },
  {
    "text": "about this now and hopefully connect all the ideas that I've talked about before with this so here's this you know",
    "start": "723540",
    "end": "730410"
  },
  {
    "text": "entrance to a cave a fairly standard cave that we might be required to enter for the subterranean challenge which",
    "start": "730410",
    "end": "737399"
  },
  {
    "text": "requires our putting teams of robots into mines tunnels urban underground and caves to be able to find certain",
    "start": "737399",
    "end": "744060"
  },
  {
    "text": "artifacts what DARPA has claimed is artifacts which might be things like red backpacks fire extinguishers survivors",
    "start": "744060",
    "end": "750690"
  },
  {
    "text": "things of this nature okay sure many of you look at this environment say I am super excited to",
    "start": "750690",
    "end": "757380"
  },
  {
    "text": "send robots into aqueous environments right the number one cause of",
    "start": "757380",
    "end": "762720"
  },
  {
    "text": "catastrophe at the subterranean challenge that just happened and",
    "start": "762720",
    "end": "767750"
  },
  {
    "text": "probably in the future ones was water falling on a computer and that just you",
    "start": "767750",
    "end": "773490"
  },
  {
    "text": "know the robot doesn't move after that so the environments look like this where",
    "start": "773490",
    "end": "778980"
  },
  {
    "text": "there might not be this sort of crawler in here but instead you know there's going to be small and large types of",
    "start": "778980",
    "end": "785310"
  },
  {
    "text": "obstacles that we have to negotiate in this environment you could imagine putting in a ground vehicle but maybe an",
    "start": "785310",
    "end": "791880"
  },
  {
    "text": "aerial vehicle would be a better choice remember we can send teams of robots in which means that we can choose what kind",
    "start": "791880",
    "end": "797490"
  },
  {
    "text": "of locomotion we would like even then if you ever do any kind of quadrotor flying",
    "start": "797490",
    "end": "803720"
  },
  {
    "text": "autonomous quadrotor flying and something like this you could imagine things like propwash and sort of you",
    "start": "803720",
    "end": "810300"
  },
  {
    "text": "know the small obstacles that you wouldn't be able to see necessarily with a light are even a very high-density light are",
    "start": "810300",
    "end": "815579"
  },
  {
    "text": "causing some issues right and I also want to in particular draw your",
    "start": "815579",
    "end": "820649"
  },
  {
    "text": "attention to a couple of features on this image right here this specular highlight up here as a result of a light",
    "start": "820649",
    "end": "827189"
  },
  {
    "text": "being too close to the geometry the the walls here and then also reflections as",
    "start": "827189",
    "end": "833550"
  },
  {
    "text": "a result of just specular specularity zhan surfaces things that really if you",
    "start": "833550",
    "end": "840509"
  },
  {
    "text": "work in vision then these should frighten you right these are places where we don't have very good models and",
    "start": "840509",
    "end": "846959"
  },
  {
    "text": "I'll talk more about that but before I do I want to motivate just a little bit more about this subterranean challenge",
    "start": "846959",
    "end": "853439"
  },
  {
    "text": "here we are and the system's competition we're in soap my team is in so-called",
    "start": "853439",
    "end": "858870"
  },
  {
    "text": "track a which is one of the DARPA funded teams we just finished this tunnel circuit which is going in environments",
    "start": "858870",
    "end": "864329"
  },
  {
    "text": "not too different than the one I just showed but then also that we have the so-called urban circuit next and then",
    "start": "864329",
    "end": "870449"
  },
  {
    "text": "finally a cave circuit six months after that this is going to be in February and then finally a year to sort of winnow",
    "start": "870449",
    "end": "876420"
  },
  {
    "text": "down our methods and then get them to assign a final systems test event and so",
    "start": "876420",
    "end": "882420"
  },
  {
    "text": "there's also a virtual competition we're not part of one of those we're just in this one little track up here just to",
    "start": "882420",
    "end": "888060"
  },
  {
    "text": "explain to you where this sort of competition is and my role on this team is to sort of help and chiefly solve",
    "start": "888060",
    "end": "896759"
  },
  {
    "text": "some of the perception challenges associated with operating in in these mines and the normal ways that I would",
    "start": "896759",
    "end": "902730"
  },
  {
    "text": "try to solve these problems are using sensor Suites like this one and techniques known as sensor fusion a",
    "start": "902730",
    "end": "909240"
  },
  {
    "text": "little bit more than just Kalman filtering we usually use optimization based approaches and if you again work",
    "start": "909240",
    "end": "914759"
  },
  {
    "text": "in this field then the difference between the two is is it's kind of",
    "start": "914759",
    "end": "920309"
  },
  {
    "text": "subtle I suppose but in the end it's taking all these different types of data",
    "start": "920309",
    "end": "926069"
  },
  {
    "text": "distilling them into data products that then we can do some sort of estimation over so cameras they obviously provide",
    "start": "926069",
    "end": "933600"
  },
  {
    "text": "us images which provide us information on both where we are how we're moving and what's around us it's very very",
    "start": "933600",
    "end": "940889"
  },
  {
    "text": "useful information GPS if available gives us only suit arranging positions encoders might",
    "start": "940889",
    "end": "947940"
  },
  {
    "text": "be on wheels or something or be able to tell sort of how to impute the way that the physical model of your robot would",
    "start": "947940",
    "end": "954030"
  },
  {
    "text": "be able to give motion prediction inertial measurement units which come in",
    "start": "954030",
    "end": "959850"
  },
  {
    "text": "all shapes and sizes but in general they're useful for rotation rates and acceleration and finally different types",
    "start": "959850",
    "end": "966330"
  },
  {
    "text": "of lidar solutions which give us direct depth estimate or measurements on surfaces in in a 3d space potentially 2d",
    "start": "966330",
    "end": "974880"
  },
  {
    "text": "space although we only use 3d lidar s in our environment in our environments again like self-driving cars are the",
    "start": "974880",
    "end": "981450"
  },
  {
    "text": "truth like a very motivational case right I mean they they sort of pushed the bounds of what is available for",
    "start": "981450",
    "end": "988260"
  },
  {
    "text": "sensor fusion using essentially everything that you could imagine they also have GPS on top of this sensor",
    "start": "988260",
    "end": "994290"
  },
  {
    "text": "suite here for different types of capabilities and the fusion of these capabilities provide that sort of really",
    "start": "994290",
    "end": "1000080"
  },
  {
    "text": "high highly accurate information right so that's kind of why I was mentioning that pedestrian example being able to",
    "start": "1000080",
    "end": "1007280"
  },
  {
    "text": "tell a pedestrian very far away may not be only dependent on a camera but also dependent on on lidar and so it's the",
    "start": "1007280",
    "end": "1014030"
  },
  {
    "text": "sort of tessellation of these different sensor nets and the ways that they all work together that we're interested in",
    "start": "1014030",
    "end": "1019160"
  },
  {
    "text": "now the one of the chief problems in in moving a robot in an unknown environment",
    "start": "1019160",
    "end": "1024970"
  },
  {
    "text": "removing that motion capture is being able to solve state estimation so in",
    "start": "1024970",
    "end": "1030410"
  },
  {
    "text": "order to do this one of the typical tools that's used and well known in the literature now is visual simultaneous",
    "start": "1030410",
    "end": "1037040"
  },
  {
    "text": "localization and mapping or slam now the visual part has a lot of different methods there are things known as",
    "start": "1037040",
    "end": "1042980"
  },
  {
    "text": "indirect methods sparse indirect methods which revolves around being able to",
    "start": "1042980",
    "end": "1048140"
  },
  {
    "text": "compute features in a computer vision frame being able to capture a frame from a camera calculate where there are",
    "start": "1048140",
    "end": "1054470"
  },
  {
    "text": "features being able to match those features in time and being able to as you can imagine estimate how you're",
    "start": "1054470",
    "end": "1060080"
  },
  {
    "text": "moving against those features in an environment similar to how we might be able to do navigation against corners in",
    "start": "1060080",
    "end": "1065690"
  },
  {
    "text": "this 3d environment let's say so up here is the sort of features and as they're",
    "start": "1065690",
    "end": "1071720"
  },
  {
    "text": "tracked across frames and then here is what we call a pose graph as well as",
    "start": "1071720",
    "end": "1076910"
  },
  {
    "text": "landmarks in this environment one could augment this with a little bit of that sensor",
    "start": "1076910",
    "end": "1082630"
  },
  {
    "text": "fusion technology that I was talking about to solve so-called visual inertial slam which involves both the vision and",
    "start": "1082630",
    "end": "1089890"
  },
  {
    "text": "the introduction of an IMU that helps us in places where let's say there aren't many features like on the ground right",
    "start": "1089890",
    "end": "1095920"
  },
  {
    "text": "here and also Bo is able to help us sort of work through places where we might not have any feature correspondences",
    "start": "1095920",
    "end": "1102220"
  },
  {
    "text": "between frames and the particular advantage here is if you get motion blur right okay so let's just take a take a",
    "start": "1102220",
    "end": "1110260"
  },
  {
    "text": "moment and appreciate those two sensors cameras provide us relative pose constraints that is frame to frame",
    "start": "1110260",
    "end": "1116620"
  },
  {
    "text": "tracking as well as information on structure that landmark data and I am use provide us some strong short-term",
    "start": "1116620",
    "end": "1123040"
  },
  {
    "text": "spatiotemporal constraints or the ability for us to be able to sort of forward propagate our state between",
    "start": "1123040",
    "end": "1128760"
  },
  {
    "text": "frames that that are collected and whether or not we may have dropped a frame because there are no features",
    "start": "1128760",
    "end": "1135310"
  },
  {
    "text": "because there's entirely motion blur or maybe it was overexposed those are examples of places that an IMU is",
    "start": "1135310",
    "end": "1140380"
  },
  {
    "text": "absolutely critical now there's this one little problem right and this is sort of",
    "start": "1140380",
    "end": "1146410"
  },
  {
    "text": "going to get us introduced into the world of sensor fusion and perception today which is that if you have an IMU",
    "start": "1146410",
    "end": "1152770"
  },
  {
    "text": "sitting somewhere arbitrarily on your robot body and you have a camera that is also sitting somewhere on that robot",
    "start": "1152770",
    "end": "1158770"
  },
  {
    "text": "body ideally there's going to be some static transform between the two right who here has done a sensor calibration",
    "start": "1158770",
    "end": "1164650"
  },
  {
    "text": "before okay so almost everybody sensor calibrations involve moving a rig right",
    "start": "1164650",
    "end": "1170620"
  },
  {
    "text": "and being able to determine moving a rig against this fiducial target and being",
    "start": "1170620",
    "end": "1176530"
  },
  {
    "text": "able to regress certain quantities of interest being able to get se3 offsets",
    "start": "1176530",
    "end": "1181660"
  },
  {
    "text": "XYZ roll pitch yaw translation orientation differences between the two sensors right being able to capture",
    "start": "1181660",
    "end": "1188020"
  },
  {
    "text": "maybe intrinsics of the camera as well lens coefficients for distortion maybe",
    "start": "1188020",
    "end": "1193990"
  },
  {
    "text": "focal point and central point as an example okay and this is like what",
    "start": "1193990",
    "end": "1200170"
  },
  {
    "text": "graduate students have to do every day let's say that they want to be able to run one of their perception rigs it's",
    "start": "1200170",
    "end": "1205390"
  },
  {
    "text": "it's extremely harrowing and time-consuming okay and you know so so",
    "start": "1205390",
    "end": "1211120"
  },
  {
    "text": "intrigued juice is perhaps one of the least sexy but also one of the most lucrative parts",
    "start": "1211120",
    "end": "1216370"
  },
  {
    "text": "of doing perception which is that nobody wants to do sensor calibration and",
    "start": "1216370",
    "end": "1221560"
  },
  {
    "text": "everyone needs to do it in order to use most multiple sensors so we made plenty",
    "start": "1221560",
    "end": "1226990"
  },
  {
    "text": "of papers and a group like different grants and cooperative research agreements between companies to be able",
    "start": "1226990",
    "end": "1233740"
  },
  {
    "text": "to solve these like very particular types of recalibration problems on the",
    "start": "1233740",
    "end": "1239470"
  },
  {
    "text": "fly and I'm gonna tell you about one of them right now but the reason why we would have to do this is okay fine let's",
    "start": "1239470",
    "end": "1245110"
  },
  {
    "text": "say you're okay with an engineer doing that whole sense of rigged dance what happens when someone out in the field",
    "start": "1245110",
    "end": "1252010"
  },
  {
    "text": "decides that they would like to move one of the cameras with respect to the other sensors on the platform or let's say",
    "start": "1252010",
    "end": "1258430"
  },
  {
    "text": "perhaps that you're doing some fairly you know aggressive maneuvers and now",
    "start": "1258430",
    "end": "1264070"
  },
  {
    "text": "you ran into something or you had a hard stop and that might actually result in a different kinds of different calibration",
    "start": "1264070",
    "end": "1269440"
  },
  {
    "text": "or change in calibration parameters or maybe something unexpected happens and as a result yardsale sensors fly and",
    "start": "1269440",
    "end": "1277270"
  },
  {
    "text": "what you don't want to do is have to send your car or your rig back to the shop to get recalibrated because it",
    "start": "1277270",
    "end": "1284170"
  },
  {
    "text": "needs to continue operating maybe not in this example but you can imagine so we",
    "start": "1284170",
    "end": "1289570"
  },
  {
    "text": "were interested in trying to solve a camera to IMU self-calibration problem this is very helpful for us as we're moving in the minds but also was helpful",
    "start": "1289570",
    "end": "1296200"
  },
  {
    "text": "all the way back when we were working with Toyota so in this case we want to compute this camera IMU rotation and",
    "start": "1296200",
    "end": "1302650"
  },
  {
    "text": "translation let's say that your camera intrinsics are nice and fine we're not going to change anything this is hard",
    "start": "1302650",
    "end": "1308500"
  },
  {
    "text": "because we don't have any calibration target as we're operating we need to do this in real time and ease the robust to these sorts of changes that happen on",
    "start": "1308500",
    "end": "1314890"
  },
  {
    "text": "the fly and the way that we solve this problem is by collecting the most informative motion segments to estimate",
    "start": "1314890",
    "end": "1320620"
  },
  {
    "text": "the parameters and then we detect an account for changes that negate older segments informativeness that is to say",
    "start": "1320620",
    "end": "1326470"
  },
  {
    "text": "we ask the question is this new information that we just got telling us something that disagrees with our",
    "start": "1326470",
    "end": "1332740"
  },
  {
    "text": "previous hypothesis for where what our sensor calibration parameters were okay",
    "start": "1332740",
    "end": "1338500"
  },
  {
    "text": "like I said we worked on this for a few years and this was the I think one of the more robust solutions that we can",
    "start": "1338500",
    "end": "1344610"
  },
  {
    "text": "up with which involves this we move our we are moving our robot right we're just kind of evolving and wherever we're sort",
    "start": "1344610",
    "end": "1351870"
  },
  {
    "text": "of moving through this environment and we capture a subsample of the motions of the robot and with those motions of the",
    "start": "1351870",
    "end": "1358890"
  },
  {
    "text": "robot we take an estimate as to what our calibration parameters are this involves some estimates of non-linear",
    "start": "1358890",
    "end": "1364710"
  },
  {
    "text": "optimization which results in some on some error right this error is indicative of what our uncertainty is on",
    "start": "1364710",
    "end": "1371850"
  },
  {
    "text": "that that those sets of calibration parameters what we're going to do with that is sort of store these three",
    "start": "1371850",
    "end": "1378090"
  },
  {
    "text": "motions and throw those motions as well as the estimate for the calibration parameters into a priority queue like",
    "start": "1378090",
    "end": "1384630"
  },
  {
    "text": "this and as we evolve the robot forward we're going to be collecting more and more motions some of which may not be",
    "start": "1384630",
    "end": "1390780"
  },
  {
    "text": "informative right you can imagine in this case it's not always that every motion that you take is actually going",
    "start": "1390780",
    "end": "1396450"
  },
  {
    "text": "to help you regress these parameters in sensor calibration and so here's one",
    "start": "1396450",
    "end": "1401700"
  },
  {
    "text": "example in which the information was not so great there's sort of wider spread on",
    "start": "1401700",
    "end": "1407190"
  },
  {
    "text": "what our estimation would have been for the calibration parameters but we throw those into the priority queue anyway and",
    "start": "1407190",
    "end": "1413040"
  },
  {
    "text": "we continue evolving so you could see that this works until the priority queue is full right after which we run an",
    "start": "1413040",
    "end": "1420840"
  },
  {
    "text": "estimation over all the different motions in this priority queue in order to get our calibration parameters now we",
    "start": "1420840",
    "end": "1426720"
  },
  {
    "text": "continue evolving a robot just normally operating and we ask the question since",
    "start": "1426720",
    "end": "1432030"
  },
  {
    "text": "our priority queue is full and we have this new motion information or this new motion sample how informative is this",
    "start": "1432030",
    "end": "1438090"
  },
  {
    "text": "motion sample against previous exam previous motion set of samples and in",
    "start": "1438090",
    "end": "1443429"
  },
  {
    "text": "this case we can say as you can see that the there's actually this one is slightly more narrowly peaked if you",
    "start": "1443429",
    "end": "1450360"
  },
  {
    "text": "will that is to say it's more informative it's less uncertain about the particular parameter that is then",
    "start": "1450360",
    "end": "1457770"
  },
  {
    "text": "one of the motion samples still in the priority queue so we bump that out and we throw it in and re-estimate this is a",
    "start": "1457770",
    "end": "1463740"
  },
  {
    "text": "way just one particular way that we came up with that involves being able to do this online self calibration okay and we",
    "start": "1463740",
    "end": "1471090"
  },
  {
    "text": "throw away other less informative samples as we go so the the key takeaway",
    "start": "1471090",
    "end": "1477030"
  },
  {
    "text": "here is that okay well we can actually run this robot in in this environment have somebody move this",
    "start": "1477030",
    "end": "1483490"
  },
  {
    "text": "move the sensor with respect to all the other sensors and then be able to say oh it turns out that all of our previous",
    "start": "1483490",
    "end": "1489940"
  },
  {
    "text": "sensor calibration or all of our previous motion samples are wrong that means the central sample sample now",
    "start": "1489940",
    "end": "1496330"
  },
  {
    "text": "is telling us that there's been a change and our calibration parameters need to be readjusted so you can see this is",
    "start": "1496330",
    "end": "1501520"
  },
  {
    "text": "actually does work in real time somebody went and adjusted that and we're still not losing tracking entirely we have",
    "start": "1501520",
    "end": "1507760"
  },
  {
    "text": "normally what you'd get at this point it's like a segfault like none of our calibration none of our slam solutions",
    "start": "1507760",
    "end": "1513850"
  },
  {
    "text": "are actually converging but in this case we were able to recalibrate and move forward but I'm gonna step back on a",
    "start": "1513850",
    "end": "1520900"
  },
  {
    "text": "meta level here right so maybe you don't care about sensor calibration like many",
    "start": "1520900",
    "end": "1526210"
  },
  {
    "text": "of us we just hope that it can be solved right but the key takeaway here is that perception and action inform one another",
    "start": "1526210",
    "end": "1532960"
  },
  {
    "text": "certain motions were helpful other motions were not okay and in doing that",
    "start": "1532960",
    "end": "1537970"
  },
  {
    "text": "we've sort of identified a region that tells us okay we need to move our",
    "start": "1537970",
    "end": "1543070"
  },
  {
    "text": "platform in a certain way in order for us to have robust perception okay not",
    "start": "1543070",
    "end": "1548890"
  },
  {
    "text": "just that but also probably we need to be able to get robust perception in order to know whether or not a certain",
    "start": "1548890",
    "end": "1555460"
  },
  {
    "text": "action is available let's say we don't have that there's there there's too much uncertainty on our map for instance and",
    "start": "1555460",
    "end": "1562270"
  },
  {
    "text": "that those map uncertainties will cascade into being able to not having a",
    "start": "1562270",
    "end": "1567400"
  },
  {
    "text": "very good guess as to how our platform will work in a certain environment so",
    "start": "1567400",
    "end": "1572890"
  },
  {
    "text": "stochastic npc then would fail so this is a fairly like general takeaway that",
    "start": "1572890",
    "end": "1577960"
  },
  {
    "text": "I'm using is sort of I'm using this one example that I provided is just one one",
    "start": "1577960",
    "end": "1583830"
  },
  {
    "text": "sort of tableau if you will for this lesson I'm gonna launch into another",
    "start": "1583830",
    "end": "1588990"
  },
  {
    "text": "example of this okay so hopefully if you if you're cool with you know sensor",
    "start": "1588990",
    "end": "1594160"
  },
  {
    "text": "calibration you kind of get it maybe keep this in mind as we go forward so",
    "start": "1594160",
    "end": "1599620"
  },
  {
    "text": "let's focus again on this subterranean environment so here's here's our sort of most commonly used robotic sort of",
    "start": "1599620",
    "end": "1607320"
  },
  {
    "text": "platform for prototyping it's this little what we call a park or car and it's driving in this environment",
    "start": "1607320",
    "end": "1613510"
  },
  {
    "text": "that's dark just like the mines that we expect to be operating in okay and what",
    "start": "1613510",
    "end": "1618520"
  },
  {
    "text": "we've done is we've attached a light on the top of the of the platform because",
    "start": "1618520",
    "end": "1623710"
  },
  {
    "text": "it needs to see where it's going right there's no light and what we've done is we've also have this camera and what you",
    "start": "1623710",
    "end": "1629410"
  },
  {
    "text": "see here is the first image is when the robot was sort of maybe a few meters",
    "start": "1629410",
    "end": "1635620"
  },
  {
    "text": "further away from it of this volleyball and now we've moved closer and what we've done is captured another image of",
    "start": "1635620",
    "end": "1642160"
  },
  {
    "text": "this of this volleyball a couple things have happened right we see now that",
    "start": "1642160",
    "end": "1647680"
  },
  {
    "text": "there's a very direct specular highlight on the volleyball which means that if we",
    "start": "1647680",
    "end": "1652780"
  },
  {
    "text": "were to look at this volleyball and say where are my computer vision features that might not be so useful you can",
    "start": "1652780",
    "end": "1657970"
  },
  {
    "text": "imagine because this looks like a white surface now we've sort of overexposed",
    "start": "1657970",
    "end": "1663280"
  },
  {
    "text": "all of the texture and features on this volleyball the second thing is so maybe",
    "start": "1663280",
    "end": "1669070"
  },
  {
    "text": "that's fine I mean because you're saying okay well I'm only looking at how this shifts in the image maybe the colors",
    "start": "1669070",
    "end": "1675040"
  },
  {
    "text": "will shift in the image the second is that the the way that the volleyball looks apparently is different right",
    "start": "1675040",
    "end": "1681490"
  },
  {
    "text": "which means that any kind of direct image matching that you would do being able to say how does my scene look as",
    "start": "1681490",
    "end": "1688210"
  },
  {
    "text": "I'm moving forward you can't really apply that anymore because the scene has changed merely by your motion in it",
    "start": "1688210",
    "end": "1694420"
  },
  {
    "text": "because you have that light on on top of you right and this is not an uncommon",
    "start": "1694420",
    "end": "1700450"
  },
  {
    "text": "circumstance in minds let me show you the same video of us walking through a",
    "start": "1700450",
    "end": "1705550"
  },
  {
    "text": "mine here this is the gold King mine in Colorado if any of you are familiar with that disaster what we've done is we've",
    "start": "1705550",
    "end": "1712060"
  },
  {
    "text": "taken one flashlight which is sort of diffused here walking through this mine here's another example of us walking",
    "start": "1712060",
    "end": "1720670"
  },
  {
    "text": "through a mine with a different flashlight lower setting we've reduced the brightness setting here where you",
    "start": "1720670",
    "end": "1726280"
  },
  {
    "text": "can see is a few more sort of shiny surfaces and a lot more texture okay but",
    "start": "1726280",
    "end": "1733420"
  },
  {
    "text": "what you also see is that the the throw of the light is not quite as great right so you can't really see so much about",
    "start": "1733420",
    "end": "1739150"
  },
  {
    "text": "the geometry further out and this this projector is sort you could see a little bit more than its sort of reducing some of that that",
    "start": "1739150",
    "end": "1746600"
  },
  {
    "text": "visibility range and the the final one is you know if you thought one light was",
    "start": "1746600",
    "end": "1751990"
  },
  {
    "text": "was just you know maybe will change the setting on one light for brightness here's two lights that you could use",
    "start": "1751990",
    "end": "1757700"
  },
  {
    "text": "sort of one that's focused down into the the cavern and then one that's sort of broader at a wider angle to be able to",
    "start": "1757700",
    "end": "1766220"
  },
  {
    "text": "hopefully capture both of them but that was even more confusing right we just were looking at that video and it's like",
    "start": "1766220",
    "end": "1771740"
  },
  {
    "text": "wow what's moving around me because lights are moving with respect to one another the way that the light plays",
    "start": "1771740",
    "end": "1777260"
  },
  {
    "text": "against the geometry here in order to create shadows as well as be able to as the image is being generated show",
    "start": "1777260",
    "end": "1784580"
  },
  {
    "text": "texture as well as different kinds of geometry is what we want to discuss so turns out no one's really looked at this",
    "start": "1784580",
    "end": "1792350"
  },
  {
    "text": "type of problem before because I believe no one wants to use visual methods and caves right I believe visual methods are",
    "start": "1792350",
    "end": "1798860"
  },
  {
    "text": "sort of what humans can use so I want to be able to apply those to robots so what",
    "start": "1798860",
    "end": "1804169"
  },
  {
    "text": "we did was what any good you know scientist does is say well if I'm going to be testing any of my methods that I'm",
    "start": "1804169",
    "end": "1811190"
  },
  {
    "text": "going to be developing here I'm going to first take a data set so the data set that we took was in three different",
    "start": "1811190",
    "end": "1817250"
  },
  {
    "text": "types of environments which I'll talk about shortly these sorts of caves and a",
    "start": "1817250",
    "end": "1822290"
  },
  {
    "text": "more urban environment and then an outdoor environment we also worked in",
    "start": "1822290",
    "end": "1828110"
  },
  {
    "text": "with different types of sensors so we captured the data with a real sense deep",
    "start": "1828110",
    "end": "1833270"
  },
  {
    "text": "435i which if you don't know is the real sense D 435 it gives us 8-bit gray scale",
    "start": "1833270",
    "end": "1839150"
  },
  {
    "text": "so 1280 by 720 we had two of these cameras hooked up 30 Hertz 30 frames per",
    "start": "1839150",
    "end": "1846140"
  },
  {
    "text": "second data on each one of those camera feeds the if you have worked with one of these cameras then you sort of know wait",
    "start": "1846140",
    "end": "1852440"
  },
  {
    "text": "there's an RGB as well but the RGB is rolling shutter so we throw that out we don't use that although we captured it",
    "start": "1852440",
    "end": "1858169"
  },
  {
    "text": "do you want it we have to I am use one of them is the one that's inherent on",
    "start": "1858169",
    "end": "1863780"
  },
  {
    "text": "the real sensitive 435i it sort of acts like the Bosh I am you in case you've ever used that one but we don't I've",
    "start": "1863780",
    "end": "1869510"
  },
  {
    "text": "never torn it apart so I don't know what's actually on it but it's sort of like that 250 Hertz and a gyro at 400",
    "start": "1869510",
    "end": "1875059"
  },
  {
    "text": "Hertz a much nicer I am you about thousand dollars 3dm gx5",
    "start": "1875059",
    "end": "1881210"
  },
  {
    "text": "15 from lurid micro strain gives us actually up to a thousand Hertz accelerometer and gyro but it's just",
    "start": "1881210",
    "end": "1888170"
  },
  {
    "text": "much more stable and lower bias drift as well as as much as we could some",
    "start": "1888170",
    "end": "1893330"
  },
  {
    "text": "position according to like a total station I'll talk about that in a sec as well as a light that we changed the",
    "start": "1893330",
    "end": "1900260"
  },
  {
    "text": "different lumination settings on and as you can see here what the sort of",
    "start": "1900260",
    "end": "1905360"
  },
  {
    "text": "examples of environments that we took this data set we're in we're a tunnel a mine a lab and an outdoor environment",
    "start": "1905360",
    "end": "1911950"
  },
  {
    "text": "and I'll show you videos of those in a second and okay so let's talk about it",
    "start": "1911950",
    "end": "1918770"
  },
  {
    "text": "here was the rig we have this like a prism up here in order for us to get ground truth for as long as the Leica",
    "start": "1918770",
    "end": "1924880"
  },
  {
    "text": "laser was available as you can imagine if we operate in mines and we're going around corners we can't actually move",
    "start": "1924880",
    "end": "1931280"
  },
  {
    "text": "the Leica station so that means that only portions of this pose graph will",
    "start": "1931280",
    "end": "1936320"
  },
  {
    "text": "actually have ground truth according to the Leica we have a computer on board we have the this camera the two cameras",
    "start": "1936320",
    "end": "1942650"
  },
  {
    "text": "right here batteries lots of batteries for all the computer and everything and then the IMU",
    "start": "1942650",
    "end": "1947840"
  },
  {
    "text": "both in here as well as the Lord microstrain behind it and to show you this this light here I mean this light",
    "start": "1947840",
    "end": "1953540"
  },
  {
    "text": "just a pretty typical LED with a massive heatsink that would create enough heats",
    "start": "1953540",
    "end": "1959390"
  },
  {
    "text": "to sort of heat the minds that we were in with the fan on the back to make sure that we didn't like overheat the LED",
    "start": "1959390",
    "end": "1965780"
  },
  {
    "text": "itself so this thing when it was cranked up was basically the light of day here",
    "start": "1965780",
    "end": "1971420"
  },
  {
    "text": "are the different environments that we were operating in here was a steam tunnel type of environment in our in our underground at the University of",
    "start": "1971420",
    "end": "1977600"
  },
  {
    "text": "Colorado and so this was taken at those different brightness settings different",
    "start": "1977600",
    "end": "1982850"
  },
  {
    "text": "lumens settings on the on the light and we tried to recreate the path as well as possible but as you can see we were",
    "start": "1982850",
    "end": "1989210"
  },
  {
    "text": "walking around in this environment and this this does have auto exposure enabled and the light will be is",
    "start": "1989210",
    "end": "1996890"
  },
  {
    "text": "calibrated and I'll show that in just a second so here's the the urban underground this is a tunnel cave type",
    "start": "1996890",
    "end": "2003910"
  },
  {
    "text": "of environment that we were operating in and then finally to make this the creepiest dataset ever collected",
    "start": "2003910",
    "end": "2010899"
  },
  {
    "text": "the Blair Witch Project style outdoors type of runs here so you can see that we",
    "start": "2010899",
    "end": "2017799"
  },
  {
    "text": "tried to capture a bunch of different scenarios in which one wanted to do active illumination and furthermore we",
    "start": "2017799",
    "end": "2024129"
  },
  {
    "text": "tried to capture those different settings with different types of motion blur types of characteristics so for",
    "start": "2024129",
    "end": "2030850"
  },
  {
    "text": "instance if you're operating at the brightest setting it might be that you don't get as much motion blur but at the",
    "start": "2030850",
    "end": "2036249"
  },
  {
    "text": "lower setting it might look like you have the same image but there's more motion blur so those are some sort of",
    "start": "2036249",
    "end": "2042159"
  },
  {
    "text": "uniquenesses about this data set the last thing like I mentioned is we did that light intrinsics calculation",
    "start": "2042159",
    "end": "2049179"
  },
  {
    "text": "because is if you're wondering what we're about to do is use the light model that we can actually try to back out as",
    "start": "2049179",
    "end": "2056138"
  },
  {
    "text": "a result of this sort of you know creepy I guess patterning here to understand",
    "start": "2056139",
    "end": "2063099"
  },
  {
    "text": "how the light is sort of focused in the scene and then understand how that plays against the geometry in the scene to",
    "start": "2063099",
    "end": "2069069"
  },
  {
    "text": "create images and so this is the normal setup that we did in mainz we sort of",
    "start": "2069069",
    "end": "2074349"
  },
  {
    "text": "sent these robots collected these data sets with this rig over here viewers are like a prism being or sorry like a total",
    "start": "2074349",
    "end": "2082000"
  },
  {
    "text": "station tracking the prism over here for as long as we could get it so here are the remarkable results we didn't just",
    "start": "2082000",
    "end": "2089169"
  },
  {
    "text": "take the data set we wanted to compare and see where there were current deficiencies associated with the visual",
    "start": "2089169",
    "end": "2095138"
  },
  {
    "text": "slam methods that are available today so many of you if you've used these technologies you know that there are",
    "start": "2095139",
    "end": "2100930"
  },
  {
    "text": "three major competing versions of this one of them is called okay this or maybe",
    "start": "2100930",
    "end": "2106690"
  },
  {
    "text": "Vin's mono then stereo these are visual inertial type of systems which all of them today rely on",
    "start": "2106690",
    "end": "2114190"
  },
  {
    "text": "this feature matching that I was talking about before the next is this orb orb",
    "start": "2114190",
    "end": "2120849"
  },
  {
    "text": "slam which is pretty much the most commonly used visual slam front-end today and that is no IMU only looking at",
    "start": "2120849",
    "end": "2129930"
  },
  {
    "text": "the only looking at the visual indirect",
    "start": "2129930",
    "end": "2135010"
  },
  {
    "text": "feature extraction types of matching stuff and I was talking about the third is this one known as direct sparse",
    "start": "2135010",
    "end": "2141910"
  },
  {
    "text": "odometry or DSL so direct sparse odometry issues the use of indirect sparse features and instead",
    "start": "2141910",
    "end": "2148330"
  },
  {
    "text": "looks at those those image intensities recall how that volleyball changed and shifted right then we would be tracking",
    "start": "2148330",
    "end": "2154180"
  },
  {
    "text": "that volleyball over time if you will and here is let me let me break this",
    "start": "2154180",
    "end": "2160089"
  },
  {
    "text": "down for you this plot up here so this is saying the number of successful runs",
    "start": "2160089",
    "end": "2165990"
  },
  {
    "text": "300 runs in total the number of successful runs for a particular method",
    "start": "2165990",
    "end": "2171130"
  },
  {
    "text": "where success is defined by the error in alignment which is essentially the number of meters off at the end the",
    "start": "2171130",
    "end": "2178480"
  },
  {
    "text": "result is right and so you can see that if success is defined by only being one",
    "start": "2178480",
    "end": "2184150"
  },
  {
    "text": "meter off at the end then these methods down here at DSO as well as orb single",
    "start": "2184150",
    "end": "2190450"
  },
  {
    "text": "orb slam with a single camera those don't perform so well in fact they perform they may never actually converge",
    "start": "2190450",
    "end": "2197530"
  },
  {
    "text": "even for half the runs which is pretty pretty interesting right also",
    "start": "2197530",
    "end": "2202960"
  },
  {
    "text": "interesting is that over here there's this differentiator where if you use a second sensor stereo or an IMU then you",
    "start": "2202960",
    "end": "2211690"
  },
  {
    "text": "have clearly better performance in more accurate performance over time with some saturation if you will so that that sort",
    "start": "2211690",
    "end": "2218800"
  },
  {
    "text": "of sort of comports with what we would probably all expect right we would say if you add another sensor it'll be more accurate let me show you the failure",
    "start": "2218800",
    "end": "2225280"
  },
  {
    "text": "modes in just a second of that what's also interesting though is it's not just the that adding another sensor is",
    "start": "2225280",
    "end": "2233470"
  },
  {
    "text": "helpful it's that if we run the same sequence forward versus backward in",
    "start": "2233470",
    "end": "2239369"
  },
  {
    "text": "running let's say like the sequence of images forward versus running the",
    "start": "2239369",
    "end": "2244630"
  },
  {
    "text": "sequence of images in Reverse you have different types of success rates now why would that be okay let's look at that",
    "start": "2244630",
    "end": "2253510"
  },
  {
    "text": "for a second so this is that direct sparse odometry and let's say that we're",
    "start": "2253510",
    "end": "2259839"
  },
  {
    "text": "starting over here and we're running our visual system forward visual slam system",
    "start": "2259839",
    "end": "2266619"
  },
  {
    "text": "forward and this is the sort of visualization of our map as we're building it so this is to the starting",
    "start": "2266619",
    "end": "2273580"
  },
  {
    "text": "point and over here is our ending point and you can see that even there's an apparent sort of enlarging",
    "start": "2273580",
    "end": "2280690"
  },
  {
    "text": "the cave that we are walking in this doesn't actually happen that's entirely a result of the errors in the method",
    "start": "2280690",
    "end": "2287020"
  },
  {
    "text": "right and over here this direct sparse odometry method if we're running it in",
    "start": "2287020",
    "end": "2292270"
  },
  {
    "text": "Reverse that is we're starting up here and then we're running the sequence of images backward that the scale drift",
    "start": "2292270",
    "end": "2297430"
  },
  {
    "text": "happens in the reverse direction and the reason why is because of this notion of",
    "start": "2297430",
    "end": "2303760"
  },
  {
    "text": "the what's called the brightness constancy assumption that is to say one of the most common things in visual slam",
    "start": "2303760",
    "end": "2310390"
  },
  {
    "text": "direct visual slam is this statement that if you have an image and it's has a",
    "start": "2310390",
    "end": "2316270"
  },
  {
    "text": "certain illumination on it you capture an image after that the illumination should be essentially the same and we",
    "start": "2316270",
    "end": "2322510"
  },
  {
    "text": "all know that's not the case when we have a light attached to the to this front end which means that pretty much",
    "start": "2322510",
    "end": "2327940"
  },
  {
    "text": "every method that you run direct on in this active illumination scenario will break so all of a sudden you know",
    "start": "2327940",
    "end": "2335440"
  },
  {
    "text": "there's this huge just gaping hole and the methods that exist okay and so",
    "start": "2335440",
    "end": "2342100"
  },
  {
    "text": "here's just this you know another way of visualizing these results what I may mean to show here is that DSO actually",
    "start": "2342100",
    "end": "2349570"
  },
  {
    "text": "has this nice like we would expect there to be better results perhaps if we were",
    "start": "2349570",
    "end": "2355330"
  },
  {
    "text": "looking at this dropping this brightness constancy assumption and of course if you introduced an IMU then you're sort",
    "start": "2355330",
    "end": "2362950"
  },
  {
    "text": "of golden right and or a second camera that sort of also stops this scale drift",
    "start": "2362950",
    "end": "2367990"
  },
  {
    "text": "from happening and yet direct methods are still very interesting to look at",
    "start": "2367990",
    "end": "2373450"
  },
  {
    "text": "from a research perspective we still want to be able to say okay what happens if we were to consider using direct",
    "start": "2373450",
    "end": "2378730"
  },
  {
    "text": "methods here so for instance there's this bar where this these are the number of times that orb slam failed in this",
    "start": "2378730",
    "end": "2387160"
  },
  {
    "text": "one area for ten runs it failed all ten times independent of the initial seed if",
    "start": "2387160",
    "end": "2393580"
  },
  {
    "text": "you will and the reason why orb slam Matar this even the stereo version fails",
    "start": "2393580",
    "end": "2398890"
  },
  {
    "text": "why there's this sort of on this slide this asymptotes up here below a hundred",
    "start": "2398890",
    "end": "2404650"
  },
  {
    "text": "percent success rate is because there's always going to be a few frames in which we have complete motion blur that is to",
    "start": "2404650",
    "end": "2411250"
  },
  {
    "text": "say we will never be able to capture and correlate different features from frame to frame so the point being here being",
    "start": "2411250",
    "end": "2418869"
  },
  {
    "text": "direct methods don't rely on that and yet direct methods have is their Achilles heel this brightness constancy",
    "start": "2418869",
    "end": "2424840"
  },
  {
    "text": "assumption so we want to be able to relax that just to show you this you know another visualization of the kinds",
    "start": "2424840",
    "end": "2431320"
  },
  {
    "text": "of ways these methods fail here's this plot this one's probably the most true to form as well as metric information",
    "start": "2431320",
    "end": "2438369"
  },
  {
    "text": "associated with one of the runs that we took and you can see we sort of start off here we go in then we go down then",
    "start": "2438369",
    "end": "2445840"
  },
  {
    "text": "back and then over here right and what you can see is that there's this sort of",
    "start": "2445840",
    "end": "2451590"
  },
  {
    "text": "enlargen it happens of this pose graph because of the scale drift from a",
    "start": "2451590",
    "end": "2456910"
  },
  {
    "text": "monocular system any monocular system will suffer from this okay with that in",
    "start": "2456910",
    "end": "2463180"
  },
  {
    "text": "mind we started looking at ways of addressing this what is this what is the",
    "start": "2463180",
    "end": "2468880"
  },
  {
    "text": "core of the problem it's that an image is going to be generated based on geometry lighting some albedo's or a",
    "start": "2468880",
    "end": "2475630"
  },
  {
    "text": "natural color in the scene as well as reflectance the ability for light to be reflected in a certain way against the",
    "start": "2475630",
    "end": "2481240"
  },
  {
    "text": "surface okay so what we essentially are setting up for ourselves is that we want",
    "start": "2481240",
    "end": "2488020"
  },
  {
    "text": "to be able to use RGB and depth to measurements that we would have in this environment in order to be able to do",
    "start": "2488020",
    "end": "2496150"
  },
  {
    "text": "this solve the slam problem as well as be able to reconstruct the geometry densely okay so if we look at the kinds",
    "start": "2496150",
    "end": "2504790"
  },
  {
    "text": "of methods like direct sparse odometry that exists today then what we have is this lightness constant or brightness",
    "start": "2504790",
    "end": "2511840"
  },
  {
    "text": "constancy assumption or lighting being the same throughout the scene okay here's a truth or what this really",
    "start": "2511840",
    "end": "2517960"
  },
  {
    "text": "should look like and using DSO as well as these typical techniques that assume",
    "start": "2517960",
    "end": "2523119"
  },
  {
    "text": "rightness to be constant what we've done is we see these sorts of artifacts and",
    "start": "2523119",
    "end": "2528460"
  },
  {
    "text": "these are not artifacts associated with the rendering these are artifacts associated with the reconstruction of",
    "start": "2528460",
    "end": "2533859"
  },
  {
    "text": "the surface itself okay things like just this kind of wavy behavior if any of you",
    "start": "2533859",
    "end": "2539290"
  },
  {
    "text": "have used anything like kinectfusion or elastic fusion dynamic fusion this is the kind of behavior that you get",
    "start": "2539290",
    "end": "2545359"
  },
  {
    "text": "when something moves in the scene it sort of falls off right in this kind of shaded way so a simple question to ask",
    "start": "2545359",
    "end": "2553339"
  },
  {
    "text": "is what happens if we actually estimate what how the the light plays against the surfaces we're gonna have the light",
    "start": "2553339",
    "end": "2559460"
  },
  {
    "text": "moving as we're operating in this environment so here's the truth we're",
    "start": "2559460",
    "end": "2564470"
  },
  {
    "text": "gonna go ahead and estimate albedo's that is the color of the surfaces and here we have a reconstruction which",
    "start": "2564470",
    "end": "2570440"
  },
  {
    "text": "looks kind of nasty I'm sure many of you would agree some of it's this black sort of these are rendering artifacts those",
    "start": "2570440",
    "end": "2576650"
  },
  {
    "text": "different shadings and drawings that are happening over the over the image but you see okay well maybe it's doing a",
    "start": "2576650",
    "end": "2583369"
  },
  {
    "text": "little bit better in order to sort of point out to you that I think that there's is a lot of research to be done",
    "start": "2583369",
    "end": "2588410"
  },
  {
    "text": "in this field let's look at the error in the geometry and time where the top is",
    "start": "2588410",
    "end": "2594079"
  },
  {
    "text": "with the brightness constancy assumption and the bottom is having sort of relaxed",
    "start": "2594079",
    "end": "2599210"
  },
  {
    "text": "that brightness constancy assumption to allow for a dynamic light source that's sitting on top of the platform and what",
    "start": "2599210",
    "end": "2605329"
  },
  {
    "text": "you can see is these lighter areas are where there are greater error from the ground truth in the geometry and you can",
    "start": "2605329",
    "end": "2611210"
  },
  {
    "text": "see that this is sort of just proliferating massively these errors whereas down here it sort of only exists",
    "start": "2611210",
    "end": "2617150"
  },
  {
    "text": "at the ridges which is actually where the geometry is most uncertain so there's a lot of promise in these sorts",
    "start": "2617150",
    "end": "2622549"
  },
  {
    "text": "of methods if only we could look at how we do light source estimation in a slightly more sophisticated way with",
    "start": "2622549",
    "end": "2629420"
  },
  {
    "text": "respect to these visual slam methods and what that means is in fact that I'm",
    "start": "2629420",
    "end": "2635569"
  },
  {
    "text": "going to recall for you this video what that means is that with better 3d reconstructions we can do better control",
    "start": "2635569",
    "end": "2640999"
  },
  {
    "text": "and planning right because we can do better reconstructions of how we're going to be interacting against the environment and so it's going to be more",
    "start": "2640999",
    "end": "2648559"
  },
  {
    "text": "reliable and be able to also fill in these gaps and such without having the",
    "start": "2648559",
    "end": "2653569"
  },
  {
    "text": "geometry if you will change under us as we're running an MVC it's huge and so",
    "start": "2653569",
    "end": "2659720"
  },
  {
    "text": "the last thing is we've been able to sort of do some other kinds of cool stuff with this including the estimation",
    "start": "2659720",
    "end": "2665390"
  },
  {
    "text": "of light source locations which is sort of doing the same thing as visual slam except allowing for that light source to",
    "start": "2665390",
    "end": "2672230"
  },
  {
    "text": "be able to be estimated in real time and what this has been able to do is so this is a sort of animation if",
    "start": "2672230",
    "end": "2678560"
  },
  {
    "text": "we'll of how those light sources those potential light sources are tessellated",
    "start": "2678560",
    "end": "2683870"
  },
  {
    "text": "in the environment we can do semantic segmentation and albedo estimation using fairly off-the-shelf type of deep neural",
    "start": "2683870",
    "end": "2690350"
  },
  {
    "text": "network techniques and be able to estimate shading and then lighting based on that which we found to be pretty cool",
    "start": "2690350",
    "end": "2696620"
  },
  {
    "text": "because now we can actually figure out where there are actual light sources in the scene and then understand how shadows are then cast in the environment",
    "start": "2696620",
    "end": "2704420"
  },
  {
    "text": "as well and in that case potentially even invert the shadows so again I mean",
    "start": "2704420",
    "end": "2709610"
  },
  {
    "text": "this is this is all going to this lesson of perception and action and forming one another moving a camera and a active",
    "start": "2709610",
    "end": "2716840"
  },
  {
    "text": "light source in this environment into a scene is going to be helpful for us it's if only we understand how that light",
    "start": "2716840",
    "end": "2723410"
  },
  {
    "text": "plays against the geometry okay there's one last example that I want to give to",
    "start": "2723410",
    "end": "2728630"
  },
  {
    "text": "you in this vein and it's related to this problem so here we have a fairly I",
    "start": "2728630",
    "end": "2735740"
  },
  {
    "text": "mean there's some texture on the ground but on the walls there may not be too much texture okay so if I'm interested",
    "start": "2735740",
    "end": "2742970"
  },
  {
    "text": "in using these indirect methods these feature based methods of tracking frame to frame we don't even know where we",
    "start": "2742970",
    "end": "2750050"
  },
  {
    "text": "should be looking right and so I'm going to use some some motivation from this",
    "start": "2750050",
    "end": "2755990"
  },
  {
    "text": "this chicken okay so the chicken is able to stabilize its head which is pretty",
    "start": "2755990",
    "end": "2762950"
  },
  {
    "text": "remarkable right okay we've all seen this before probably what many of us have where the chicken is there's actually an amazing",
    "start": "2762950",
    "end": "2769610"
  },
  {
    "text": "soundtrack to this movie that's not playing right now my apologies but yeah",
    "start": "2769610",
    "end": "2776450"
  },
  {
    "text": "I mean the chicken what is it doing anyone want to take a guess besides gimbley besides biological gimbley",
    "start": "2776450",
    "end": "2785319"
  },
  {
    "text": "anyone yeah yeah I mean in a sense it's",
    "start": "2786310",
    "end": "2793570"
  },
  {
    "text": "interested in this case and trying to focus on yeah mercedes-benz commercial for stability in cars interesting",
    "start": "2793570",
    "end": "2800650"
  },
  {
    "text": "perhaps - okay so what it's doing is its focusing on a certain feature set in the",
    "start": "2800650",
    "end": "2805990"
  },
  {
    "text": "environment okay so it doesn't really like motion blur the chicken doesn't",
    "start": "2805990",
    "end": "2811660"
  },
  {
    "text": "like motions or it just like our systems don't like motion blur right but the chicken is perfectly fine if it just",
    "start": "2811660",
    "end": "2817720"
  },
  {
    "text": "stays at at like it's gazes on one thing and it uses proprioceptive sensors to be",
    "start": "2817720",
    "end": "2823060"
  },
  {
    "text": "able to understand how it's moving with respect to that thing right because it understands how it moves its neck pretty",
    "start": "2823060",
    "end": "2830020"
  },
  {
    "text": "basic chickens are dumb okay so we thought okay well you know this is this",
    "start": "2830020",
    "end": "2836170"
  },
  {
    "text": "is a fairly you know this is one step in the right direction so here we have I'm just showing you this video because you",
    "start": "2836170",
    "end": "2842710"
  },
  {
    "text": "know it's the first step if you will here's this camera that's sitting on a",
    "start": "2842710",
    "end": "2847720"
  },
  {
    "text": "pan tilt unit and here's the visual slam solution up here and what you can see is that it's we're able to track features",
    "start": "2847720",
    "end": "2854830"
  },
  {
    "text": "on the robotic platform by doing this sort of surveying right but the chicken",
    "start": "2854830",
    "end": "2861040"
  },
  {
    "text": "head is not really like remarkable just because it can serve a well because the mechanical gimbal could do this sure",
    "start": "2861040",
    "end": "2866620"
  },
  {
    "text": "many of you have worked with those before or at least are familiar with them the chicken head is remarkable",
    "start": "2866620",
    "end": "2872860"
  },
  {
    "text": "because the chicken moves as it's looking at something and then it's a Cod's as its as its heads ability to",
    "start": "2872860",
    "end": "2881110"
  },
  {
    "text": "remain focused on something reaches its controlled limit right so in this case",
    "start": "2881110",
    "end": "2886660"
  },
  {
    "text": "the chicken sort of stabilizes head moves forward dramatically and then but",
    "start": "2886660",
    "end": "2892060"
  },
  {
    "text": "its body doesn't it doesn't stop moving right it has a mission to accomplish crossing a road presumably okay so",
    "start": "2892060",
    "end": "2899620"
  },
  {
    "text": "here's the idea right we put the chicken's head on on this platform here",
    "start": "2899620",
    "end": "2904840"
  },
  {
    "text": "and what we would like to do is be able to say stay focused on some set of",
    "start": "2904840",
    "end": "2910260"
  },
  {
    "text": "helpful features informative features in the environment landmarks that give me information on state right and then move",
    "start": "2910260",
    "end": "2919630"
  },
  {
    "text": "the car around to be able to do what as you want to do subordinates perception local planning against the",
    "start": "2919630",
    "end": "2926060"
  },
  {
    "text": "global mission right so now essentially what you could imagine is moving this this robot around and being able to",
    "start": "2926060",
    "end": "2931850"
  },
  {
    "text": "focus on things and that's the point of future work that we're working on right now but what I wanted to show is sort of",
    "start": "2931850",
    "end": "2938150"
  },
  {
    "text": "some of the simulations that we have in the formulation that we've taken on this problem so we've we've reduced our state",
    "start": "2938150",
    "end": "2945620"
  },
  {
    "text": "vector just a translation velocity and some biases on the gyro and interestingly and our interestingly for",
    "start": "2945620",
    "end": "2953120"
  },
  {
    "text": "us sorry biases on the IMU per time step kay and what we've done is we've reduced",
    "start": "2953120",
    "end": "2958880"
  },
  {
    "text": "the camera information to informativeness on our state vector as well as informative nasaan landmarks so",
    "start": "2958880",
    "end": "2966560"
  },
  {
    "text": "this is if you will our generative model for our camera measurements and over here sorry for this color that didn't",
    "start": "2966560",
    "end": "2972320"
  },
  {
    "text": "really turn out so well but here we have informativeness of the IMU which you could imagine as being just something",
    "start": "2972320",
    "end": "2978050"
  },
  {
    "text": "where we're saying well the IMU is going to give us information anyway so that means we're going to be moving the cameras field of view such that we're",
    "start": "2978050",
    "end": "2985340"
  },
  {
    "text": "complimenting the information we have from the IMU right and from this we can",
    "start": "2985340",
    "end": "2990770"
  },
  {
    "text": "say each landmark we can actually quantify the amount of information each landmark has as a result of this sort of",
    "start": "2990770",
    "end": "2996920"
  },
  {
    "text": "total information per measurement okay we can also do the same if you will for",
    "start": "2996920",
    "end": "3002770"
  },
  {
    "text": "some future time horizon H at time step K for each of our IMU measurements and",
    "start": "3002770",
    "end": "3009040"
  },
  {
    "text": "what you could you what we're going to be doing is saying okay that means our total information is our some of the",
    "start": "3009040",
    "end": "3015010"
  },
  {
    "text": "information per landmarks that are currently visible in this set s as well as the IMU information that we get for",
    "start": "3015010",
    "end": "3021220"
  },
  {
    "text": "free right the IMU is always going to be operating it doesn't matter what coordinate frame it's in so here's our",
    "start": "3021220",
    "end": "3027430"
  },
  {
    "text": "problem we're trying to take the maximum over possible sets of view subsets of us",
    "start": "3027430",
    "end": "3034330"
  },
  {
    "text": "within the field of view F subject to some Co visibility constraints during the fixation that is to say we're going",
    "start": "3034330",
    "end": "3040870"
  },
  {
    "text": "to fixate on certain types of regions s and we're taking the maximum over these regions s okay and in that region s",
    "start": "3040870",
    "end": "3049180"
  },
  {
    "text": "there are some landmarks that we can calculate the information on okay this requires the introduction of some sort",
    "start": "3049180",
    "end": "3055300"
  },
  {
    "text": "of information metric we use the log determinate information metric on this there are a lot of examples about different ways the",
    "start": "3055300",
    "end": "3061440"
  },
  {
    "text": "Fisher information matrix actually shows the amount of information that we might have log determinant we've been found we",
    "start": "3061440",
    "end": "3067859"
  },
  {
    "text": "found to be pretty useful for computational purposes as well as just use I mean it seems to represent a",
    "start": "3067859",
    "end": "3073740"
  },
  {
    "text": "volume of information rather than a major axis let's say so what we're trying to do is you know essentially say",
    "start": "3073740",
    "end": "3080460"
  },
  {
    "text": "if we were given this hallway scene look at all the features that are right here that might not be able to provide us",
    "start": "3080460",
    "end": "3086520"
  },
  {
    "text": "information for very long if we're moving in this direction but look at all the features maybe further down the",
    "start": "3086520",
    "end": "3091920"
  },
  {
    "text": "hallway or perhaps slightly to the left or right because they'll give us information that complement our IMU and",
    "start": "3091920",
    "end": "3097710"
  },
  {
    "text": "we're doing this in a three-dimensional environment of this so-called hallway as an example just because hallways are",
    "start": "3097710",
    "end": "3103980"
  },
  {
    "text": "nice and blank on some walls and have some features and others so here's here's a video of that running and what",
    "start": "3103980",
    "end": "3111839"
  },
  {
    "text": "we have is this simulated hallway trajectory in which we have a camera's frustum looking at these different",
    "start": "3111839",
    "end": "3117300"
  },
  {
    "text": "landmarks in this environment and here's the visualization in visual slam world",
    "start": "3117300",
    "end": "3123030"
  },
  {
    "text": "with the IMU being giving us information as well as the visual front-end actually",
    "start": "3123030",
    "end": "3128700"
  },
  {
    "text": "being the thing that's pretty that is processing the images that is the only component processing the images so we",
    "start": "3128700",
    "end": "3135240"
  },
  {
    "text": "are able to do here what's I mean many of you you know you you might look at this and you say what should I be what",
    "start": "3135240",
    "end": "3141329"
  },
  {
    "text": "should I be asking the question about here it's that these are the only landmarks in the scene everything else is blank right there's",
    "start": "3141329",
    "end": "3147990"
  },
  {
    "text": "no landmarks besides these tiny little panels that we've set up and we're still not losing tracking because we're able",
    "start": "3147990",
    "end": "3154290"
  },
  {
    "text": "to look at the panels as we're sort of flying across them so even in this extraordinarily visually sparse",
    "start": "3154290",
    "end": "3160950"
  },
  {
    "text": "environment we're able to still recreate slam paths or a state estimate reliably",
    "start": "3160950",
    "end": "3169220"
  },
  {
    "text": "okay so we think that's pretty cool and we're able to also do it by",
    "start": "3169220",
    "end": "3174390"
  },
  {
    "text": "selecting sub regions of images in fairly common tum datas tum indoor",
    "start": "3174390",
    "end": "3179819"
  },
  {
    "text": "dataset and being able to compare those rather than doing full count",
    "start": "3179819",
    "end": "3185520"
  },
  {
    "text": "relations of visual slam against the entire image which we find to be also sort of suggesting that these kinds of",
    "start": "3185520",
    "end": "3192840"
  },
  {
    "text": "psychotic methods are even more powerful than just say putting up a panoramic camera and so these are things that you",
    "start": "3192840",
    "end": "3200400"
  },
  {
    "text": "can see what's coming up next at the urban circuits so that's February 18th through the 27th we're gonna be",
    "start": "3200400",
    "end": "3205800"
  },
  {
    "text": "deploying to SATs op Business Park in Olympia Washington it's much colder",
    "start": "3205800",
    "end": "3211110"
  },
  {
    "text": "there snowing they're not heating the garage it's gonna be great and but",
    "start": "3211110",
    "end": "3216690"
  },
  {
    "text": "anyway so we'll be up there for 10 days and deploying teams of robots in similar",
    "start": "3216690",
    "end": "3222270"
  },
  {
    "text": "conditions to what we've done before we've had a lot of fun with doing this and I just want to remark that working",
    "start": "3222270",
    "end": "3227580"
  },
  {
    "text": "with DARPA and working on these sorts of projects has been very motivating for the team and for me it sort of allowed",
    "start": "3227580",
    "end": "3234270"
  },
  {
    "text": "us to pursue many different research directions at the same time to have undergrads and postdocs working with one",
    "start": "3234270",
    "end": "3240480"
  },
  {
    "text": "another building systems that are not just you know like caveman type systems",
    "start": "3240480",
    "end": "3245910"
  },
  {
    "text": "in my opinion they're really like sophisticated capabilities for mesh networking for being able to do joint",
    "start": "3245910",
    "end": "3252480"
  },
  {
    "text": "real local ization being able to do different kinds of task management etc and finally also just building out",
    "start": "3252480",
    "end": "3258510"
  },
  {
    "text": "robotic platforms something that unfortunately doesn't get done very often in our field right it's it takes",
    "start": "3258510",
    "end": "3264000"
  },
  {
    "text": "an enormous number of resources and hours to be able to build these platforms but it's been one of the joys",
    "start": "3264000",
    "end": "3270120"
  },
  {
    "text": "of my first few years of being an assistant professor at the University of Colorado to be able to to actually have",
    "start": "3270120",
    "end": "3275910"
  },
  {
    "text": "teams of students working together building these platforms and then running them not only in what DARPA is",
    "start": "3275910",
    "end": "3281190"
  },
  {
    "text": "interested in but also running them in agricultural settings different kinds of partnerships with boulder rescue wild",
    "start": "3281190",
    "end": "3288350"
  },
  {
    "text": "wildfire management services u.s. Forest Service hotshots etc which has been a",
    "start": "3288350",
    "end": "3294180"
  },
  {
    "text": "real fun fun time so yeah we're looking forward to going out there again just to",
    "start": "3294180",
    "end": "3299490"
  },
  {
    "text": "just to show off we did actually field some of our parkour cars in the first competition we sort of gave them nicer",
    "start": "3299490",
    "end": "3306210"
  },
  {
    "text": "wheels for for working in mud and here's a picture of our team and I'm gonna",
    "start": "3306210",
    "end": "3311580"
  },
  {
    "text": "conclude today by just showing off a video of our operating in this",
    "start": "3311580",
    "end": "3317610"
  },
  {
    "text": "environment which is a time-lapse we're not time-lapse it's the opposite it's reducing the video to once every",
    "start": "3317610",
    "end": "3323790"
  },
  {
    "text": "four frames here are some fiducials that we need to navigate against to make sure we're in DARPA as reference frame and",
    "start": "3323790",
    "end": "3329220"
  },
  {
    "text": "again like the whole mission was to find these sorts of different artifacts and things in this kind of look at all these",
    "start": "3329220",
    "end": "3335760"
  },
  {
    "text": "specular highlights different screwdrivers that are anywhere there's specular highlights and everything that",
    "start": "3335760",
    "end": "3341430"
  },
  {
    "text": "would normally cause issues with state estimators the sort of things that we've been able to do have really robust to",
    "start": "3341430",
    "end": "3347010"
  },
  {
    "text": "fied them against dark environments like this one and being able to operate over",
    "start": "3347010",
    "end": "3352350"
  },
  {
    "text": "at different types of terrain and and cooperate with one another as we're operating which has been like I said a",
    "start": "3352350",
    "end": "3358530"
  },
  {
    "text": "real joint you know we did fairly well in the first competition here's us two marble fourth-place and we hope to",
    "start": "3358530",
    "end": "3367140"
  },
  {
    "text": "continue moving up in the world Explorer is cm you know okay everyone here I'd",
    "start": "3367140",
    "end": "3374580"
  },
  {
    "text": "love to CMU apparently yeah okay and so yeah I look forward to you know doing",
    "start": "3374580",
    "end": "3380310"
  },
  {
    "text": "going to the next competition anyway but I'm happy to take questions and thanks for your attention",
    "start": "3380310",
    "end": "3387710"
  },
  {
    "text": "so I'm guessing we don't have time for questions yeah so right now we have only",
    "start": "3392300",
    "end": "3418280"
  },
  {
    "text": "pre-mapped environments that we're doing this against which you might say is kind of you know how exciting is that",
    "start": "3418280",
    "end": "3425100"
  },
  {
    "text": "but what we're planning on doing is being able to just have a very simple heuristic based on convolutional neural",
    "start": "3425100",
    "end": "3431640"
  },
  {
    "text": "networks in fact that are conditioned on the types of environments that we're in as a prior is different places that we",
    "start": "3431640",
    "end": "3436650"
  },
  {
    "text": "should be looking but it's the same we are looking over currently planned horizons so really all that's the",
    "start": "3436650",
    "end": "3442620"
  },
  {
    "text": "missing ingredient is where are the landmarks which can even easily be just like like I said a prior probabilistic",
    "start": "3442620",
    "end": "3448410"
  },
  {
    "text": "prior distribution of landmarks which is what we plan on doing but yeah we are currently doing planning over time horizons that",
    "start": "3448410",
    "end": "3455910"
  },
  {
    "text": "are given to us by planners so in fact this takes sort of a page out of the I",
    "start": "3455910",
    "end": "3461900"
  },
  {
    "text": "guess it's Luca Carlo Nate's work on attention and anticipation and visual inertial slam being able to say we have",
    "start": "3461900",
    "end": "3468750"
  },
  {
    "text": "a planner let's use it",
    "start": "3468750",
    "end": "3471770"
  },
  {
    "text": "[Applause]",
    "start": "3476680",
    "end": "3480930"
  }
]
[
  {
    "text": "All right. Let's get started. So as a reminder for those presenting, make sure to hook the microphone to your clothing",
    "start": "4400",
    "end": "11139"
  },
  {
    "text": "rather than holding it so that the audio is more consistent. And we have two mikes. So you don't have to [NOISE] switch off.",
    "start": "11140",
    "end": "17720"
  },
  {
    "text": "Yeah. And I will start with this first paper. [BACKGROUND]",
    "start": "17720",
    "end": "30780"
  },
  {
    "text": "Hi everyone. Uh, my name is Alex. This is Sotta and this is Hendrick. And today we'll be presenting a paper",
    "start": "30780",
    "end": "37545"
  },
  {
    "text": "called Meta-Learning of Unsupervised Learning Rules, done by a team at Google Brain about a year ago.",
    "start": "37545",
    "end": "44600"
  },
  {
    "text": "So here's an outline of what we'll be covering in the presentation. We'll keep it at the top right corner so you can stay oriented as to where we are.",
    "start": "51630",
    "end": "59810"
  },
  {
    "text": "So first let's, take, ah, a look at what unsupervised learning really means.",
    "start": "59930",
    "end": "66280"
  },
  {
    "text": "Uh, so in a sense, unsupervised learning allows us to learn a representation that will be useful for further supervised tasks at a later time.",
    "start": "66280",
    "end": "74719"
  },
  {
    "text": "Um, and some of the most common examples of those are variational autoencoders, which can learn a latent space representation of",
    "start": "74720",
    "end": "82015"
  },
  {
    "text": "a probability distribution so that we can later use that for discriminative or generative tasks.",
    "start": "82015",
    "end": "87335"
  },
  {
    "text": "And also GANs, which do something similar but can be used to transfer,",
    "start": "87335",
    "end": "92570"
  },
  {
    "text": "for example, the style of- of a famous artist to any given input photo.",
    "start": "92570",
    "end": "99055"
  },
  {
    "text": "But two of the major deficits of both of these approaches are that they tend to over-fit in",
    "start": "99055",
    "end": "105980"
  },
  {
    "text": "a sense to tha- the data that they are given so that they really can't generalize well to other types of data,",
    "start": "105980",
    "end": "113180"
  },
  {
    "text": "and that they require enormous amount more data to learn to, uh, solve another problem, another task.",
    "start": "113180",
    "end": "120104"
  },
  {
    "text": "So this basically brings up the question, uh, can we find some way to learn an unsupervised learning rule that can work well on a broad sense,",
    "start": "120105",
    "end": "128869"
  },
  {
    "text": "um, in a broad sense, ah, on a lot of given tasks and independent of the specific data that they're given.",
    "start": "128870",
    "end": "135560"
  },
  {
    "text": "Um, so the approach that this paper takes to solve this is,",
    "start": "135560",
    "end": "141250"
  },
  {
    "text": "uh, something called Semi-Supervised Few-Shot Classification. Which means it's not totally unsupervised,",
    "start": "141250",
    "end": "146795"
  },
  {
    "text": "but that it tries to solve a supervised task using the most efficient representation of some- some unlabeled data.",
    "start": "146795",
    "end": "156020"
  },
  {
    "text": "Um, so what this looks like is, we're basically given some unlabeled input as our train set,",
    "start": "156020",
    "end": "162575"
  },
  {
    "text": "and we tried to find some unsupervised rule to learn an encoder that can then take this supervised problem and,",
    "start": "162575",
    "end": "171860"
  },
  {
    "text": "uh, encode the- this labeled train set in the most efficient way to solve it.",
    "start": "171860",
    "end": "177215"
  },
  {
    "text": "Um, so in the sense, the supervised part actually consists of a small amount of data, uh,",
    "start": "177215",
    "end": "184535"
  },
  {
    "text": "but it's more used as a reference to make sure that the rule we're learning generalizes well. We'd actually use it, uh, solving a supervised problem.",
    "start": "184535",
    "end": "193350"
  },
  {
    "text": "So the question is, uh, can we find, ah, an unsupervised rule that can work well in a broad variety of supervised contexts,",
    "start": "193640",
    "end": "201725"
  },
  {
    "text": "supervised tasks, um, using meta-learning? And before we do this,",
    "start": "201725",
    "end": "209020"
  },
  {
    "text": "let's just take a step back and look at what an unsupervised rule would actually look like.",
    "start": "209020",
    "end": "214165"
  },
  {
    "text": "Um, so one supervised rule that we all know well is backprop. And what that does is basically tries to learn",
    "start": "214165",
    "end": "221050"
  },
  {
    "text": "some model parameters by finding the changes with those model parameters that will minimize some loss function.",
    "start": "221050",
    "end": "227510"
  },
  {
    "text": "But here, we don't really have a loss function. So we're trying to find more of a general rule that just given some made-up parameters,",
    "start": "227510",
    "end": "233965"
  },
  {
    "text": "and the last layer of a neural network, which is the architecture that's,",
    "start": "233965",
    "end": "239275"
  },
  {
    "text": "um, kind of constrained in this paper, um, that we can kind of update those, uh, weight rules automatically.",
    "start": "239275",
    "end": "246410"
  },
  {
    "text": "Um, so like a lot of meta-learning algorithms, this approach consists of an outer loop and an inner loop,",
    "start": "246470",
    "end": "254090"
  },
  {
    "text": "and the outer loop is supervised. We have this, um, what is kind of a loss function.",
    "start": "254090",
    "end": "259340"
  },
  {
    "text": "It's called the meta objective, but it's basically the sum of the losses for each of these supervised tasks that it's trying to perform well on.",
    "start": "259340",
    "end": "267320"
  },
  {
    "text": "And the inner loop basically gives the model the chance to go through lots of this unlabeled data and try to make sense of it,",
    "start": "267320",
    "end": "274980"
  },
  {
    "text": "uh, basically to find the most efficient way to encode this data so that it can perform well on these later supervised tasks.",
    "start": "274980",
    "end": "283400"
  },
  {
    "text": "So, um, let's- let's take a look at this in a little bit more detail. This is the high-level picture for how the algorithm is going to work.",
    "start": "283400",
    "end": "290600"
  },
  {
    "text": "It has sort of the components we're familiar with. We'll start with the inner loop. So the inner loop is what's modifying our base model.",
    "start": "290600",
    "end": "297320"
  },
  {
    "text": "The base model takes in raw data, produces feature representations, which can then be used for classification.",
    "start": "297320",
    "end": "304755"
  },
  {
    "text": "And this model is only- so in this step, in this inner loop step, we're only using unlabeled data to generate these,",
    "start": "304755",
    "end": "311884"
  },
  {
    "text": "uh, uh, feature representations. And the task is applying an unsupervised update algorithm",
    "start": "311885",
    "end": "318485"
  },
  {
    "text": "or a function to change the parameters inside the base model. In the outer loop, now we're going to take this base model and",
    "start": "318485",
    "end": "327770"
  },
  {
    "text": "the feature representations that it has learned to apply it on labeled data,",
    "start": "327770",
    "end": "333365"
  },
  {
    "text": "generate a, uh, you know, prediction for the classification of that labeled data, and then, uh,",
    "start": "333365",
    "end": "340490"
  },
  {
    "text": "compute the loss with respect to the error between the labeled data that we do have and the, and the predictions from the feature representations,",
    "start": "340490",
    "end": "348425"
  },
  {
    "text": "and then that'll be back propagated all the way through- through the unsupervised update.",
    "start": "348425",
    "end": "353940"
  },
  {
    "text": "So let's- let's think a little bit more about what this inner loop is doing. What question are we trying to solve here?",
    "start": "354470",
    "end": "360930"
  },
  {
    "text": "Well, we're given some encoder function which is parameterized by the task-specific parameters Phi.",
    "start": "360930",
    "end": "367375"
  },
  {
    "text": "And the challenge we're facing is to change the parameters Phi such that given unlabeled data,",
    "start": "367375",
    "end": "373985"
  },
  {
    "text": "we're able to produce efficient, compact representations of that data.",
    "start": "373985",
    "end": "379195"
  },
  {
    "text": "And, you know, it would be nice if we had some true loss function which",
    "start": "379195",
    "end": "385400"
  },
  {
    "text": "could tell us how well that those feature representations are useful for a classification task,",
    "start": "385400",
    "end": "390950"
  },
  {
    "text": "but we don't have that. So the idea that they propose is, well, what if we use another neural network parameterized by",
    "start": "390950",
    "end": "397730"
  },
  {
    "text": "the meta parameters Theta to generate those error signals internally.",
    "start": "397730",
    "end": "402810"
  },
  {
    "text": "So a little bit more of the mechanics. Let's see what's going on here. We're gonna have this base model,",
    "start": "403670",
    "end": "409730"
  },
  {
    "text": "which is parameterized as a- as a deep neural network with forward weights w for each of the layers.",
    "start": "409730",
    "end": "416090"
  },
  {
    "text": "And we're going to take our inputs, pass it through the network, generate all the intermediate activations,",
    "start": "416090",
    "end": "421400"
  },
  {
    "text": "and then at the final layer, output the feature representation of that input. We're going to hold onto those intermediate activations",
    "start": "421400",
    "end": "430190"
  },
  {
    "text": "and use them to generate the error signals. So these err- these intermediate activations are passed through a neural network,",
    "start": "430190",
    "end": "437120"
  },
  {
    "text": "parameterized by those meta parameters Theta to produce error signals, which will be used in a backward pass.",
    "start": "437120",
    "end": "443380"
  },
  {
    "text": "The way this process works is, you know, at the top you initialize your error with the output of, you know,",
    "start": "443380",
    "end": "448985"
  },
  {
    "text": "the top layer is NLP and then we're going to just backprop all the way through in the way that we're all familiar with,",
    "start": "448985",
    "end": "454190"
  },
  {
    "text": "where at each intermediate layer where getting the top-down error signal, and we're also linearly combining that with the,",
    "start": "454190",
    "end": "461510"
  },
  {
    "text": "uh, output from the error producing network.",
    "start": "461510",
    "end": "465630"
  },
  {
    "text": "So we can think a little bit about how these updates are made now that we have some way of producing,",
    "start": "467580",
    "end": "475075"
  },
  {
    "text": "internally, the error within the network. So phi are the base model parameters.",
    "start": "475075",
    "end": "482275"
  },
  {
    "text": "Those are the task specific parameters that are going to essentially learn how to build a representation per- uh,",
    "start": "482275",
    "end": "489580"
  },
  {
    "text": "yeah, build a representation of our raw data. Those are parameterized by W, V and all the biases.",
    "start": "489580",
    "end": "495834"
  },
  {
    "text": "And then, now that we've already computed those error function- error- error quantities, we can make local updates using just almost linear functions of those errors.",
    "start": "495834",
    "end": "505315"
  },
  {
    "text": "There's some small qualifications, in that the actual expression used to, uh,",
    "start": "505315",
    "end": "512034"
  },
  {
    "text": "take in the error quantity from the layer above as well as your internally generated error, uh,",
    "start": "512035",
    "end": "517719"
  },
  {
    "text": "and impose some non-linear functions on top of it to basically normalize, uh, as it propagates through the network.",
    "start": "517720",
    "end": "524900"
  },
  {
    "text": "So let's- let's think about what are the key points to take away from this inner loop process.",
    "start": "525960",
    "end": "531084"
  },
  {
    "text": "The first is that the- the error generating network is what drives",
    "start": "531085",
    "end": "536410"
  },
  {
    "text": "the- the unsupervised learning within this base model,",
    "start": "536410",
    "end": "541795"
  },
  {
    "text": "and it's supposed to resemble sort of what we're familiar with, with backpropagation.",
    "start": "541795",
    "end": "547160"
  },
  {
    "text": "These iterative updates that we make using the backpropagation like rule can be used to tune the model parameters,",
    "start": "547650",
    "end": "556225"
  },
  {
    "text": "spore some higher level objective. And that objective is defined by the outer loop, which changes the parameters of the error producing network in order to have",
    "start": "556225",
    "end": "566440"
  },
  {
    "text": "the unsupervised training explore different regions of its sort of,",
    "start": "566440",
    "end": "572215"
  },
  {
    "text": "uh, space of task specific parameters. There's actually some interesting connections you can draw",
    "start": "572215",
    "end": "578500"
  },
  {
    "text": "between what's going on here and, say, a reinforcement learning problem, where your task specific parameters,",
    "start": "578500",
    "end": "585070"
  },
  {
    "text": "phi, are sort of like the states of your state space. And the outer loop's role is to define a policy parameterized by theta,",
    "start": "585070",
    "end": "594010"
  },
  {
    "text": "which changes how your unsupervised learning algorithm navigates its state-space and comes to a final,",
    "start": "594010",
    "end": "600774"
  },
  {
    "text": "sort of final state, which is able to take in data and produce useful feature representations of that data.",
    "start": "600774",
    "end": "607045"
  },
  {
    "text": "So now let's look a little bit closer at what the outer loop is going to do.",
    "start": "607045",
    "end": "611839"
  },
  {
    "text": "Okay. So it's all gone, come together here in the outer loop.",
    "start": "613950",
    "end": "620919"
  },
  {
    "text": "So now, where we're at is we had some unlabeled support.",
    "start": "620919",
    "end": "626230"
  },
  {
    "text": "This was an inner loop, and we applied our unsupervised learning rule, which was parameterized by theta.",
    "start": "626230",
    "end": "632664"
  },
  {
    "text": "Okay. And we'll hold off like we'll- how do you actually learn theta? Well, we'll get to that. So we have now an encoder.",
    "start": "632664",
    "end": "638650"
  },
  {
    "text": "Now we move out to the outer loop, and we're going to use this encoder. So we have labeled support.",
    "start": "638650",
    "end": "644904"
  },
  {
    "text": "So support is the task specific training data, and the labeled query,",
    "start": "644905",
    "end": "650635"
  },
  {
    "text": "which is the task specific test data. And we apply this encoder to these vectors.",
    "start": "650635",
    "end": "657490"
  },
  {
    "text": "So you can imagine now we have a bunch of images, X_1, X_2, X_3, and X_4. That's for training images and we have two test images,",
    "start": "657490",
    "end": "665154"
  },
  {
    "text": "and we're doing few-shot uh, classification. And we get compact vectors,",
    "start": "665155",
    "end": "672084"
  },
  {
    "text": "one for each image if we're doing this on images. Now, we fit- wh- what they do specifically",
    "start": "672084",
    "end": "681040"
  },
  {
    "text": "is they fit a linear model for linear regression on those vectors, those green vectors, eh,",
    "start": "681040",
    "end": "687820"
  },
  {
    "text": "because we have labels here. Okay, so now we have fit a linear model in just a few examples.",
    "start": "687820",
    "end": "693745"
  },
  {
    "text": "And now we can apply this model on the label query and evaluate the model,",
    "start": "693745",
    "end": "699835"
  },
  {
    "text": "and we evaluate and get a mean squared error. Okay. Now you have this whole computation graph,",
    "start": "699835",
    "end": "710230"
  },
  {
    "text": "and to update theta in the top left corner, we can just backprop all the way through this computation graph.",
    "start": "710230",
    "end": "719660"
  },
  {
    "text": "Now, everything is not the opposite direction. And now you may wonder,",
    "start": "722190",
    "end": "727600"
  },
  {
    "text": "okay, but that inner loop, it's probably quite a few steps because we are applying this unsuper- these unsupervised updates.",
    "start": "727600",
    "end": "735369"
  },
  {
    "text": "And yes, that's like thousands of thousands of steps many times. So you- you- you can't backprop through that whole loop.",
    "start": "735369",
    "end": "743680"
  },
  {
    "text": "So what they do instead is truncate a backprop, which I won't go into the details of,",
    "start": "743680",
    "end": "749260"
  },
  {
    "text": "but basically what's going on is the unsupervised rule does ten steps of updating the encoder.",
    "start": "749260",
    "end": "758305"
  },
  {
    "text": "Then we apply the encoder, fit a linear model, evaluate the model, get a mean squared error,",
    "start": "758305",
    "end": "763764"
  },
  {
    "text": "backprop, and then we continue. So you do ten steps updates, go through the whole process,",
    "start": "763765",
    "end": "769569"
  },
  {
    "text": "backprop, ten steps update. So that- that's sort of the spirit of truncated backprop.",
    "start": "769570",
    "end": "776570"
  },
  {
    "text": "Okay. So how well does this do?",
    "start": "777300",
    "end": "781640"
  },
  {
    "text": "They meta-train using CIFAR data and ImageNet.",
    "start": "784290",
    "end": "790190"
  },
  {
    "text": "And then they evaluate how well does this generalize to other datasets?",
    "start": "790260",
    "end": "796480"
  },
  {
    "text": "So what that means is we learn an unsupervised learning rule, we meta learn an unsupervised learning rule on CIFAR10 and ImageNet,",
    "start": "796480",
    "end": "803440"
  },
  {
    "text": "and then we go to another dataset and see how it does this job. Then they explore how well does it do in other domains?",
    "start": "803440",
    "end": "811420"
  },
  {
    "text": "And that means taking this unsupervised learning rule that was meta-trained on image data and now apply that to text data,",
    "start": "811420",
    "end": "819565"
  },
  {
    "text": "specifically in this case. And then they also explore what if we apply",
    "start": "819565",
    "end": "825850"
  },
  {
    "text": "this unsupervised learning rule now to completely new network architectures. That- that means that the encoder has a different architecture.",
    "start": "825850",
    "end": "835134"
  },
  {
    "text": "Okay. So what's going on here?",
    "start": "835135",
    "end": "843265"
  },
  {
    "text": "We're evaluating our unsupervised learning rule on different datasets and compare it to other methods. They compare it to three other methods,",
    "start": "843265",
    "end": "849475"
  },
  {
    "text": "but we'll only focus on one other method right now. So that's a VAE, so that's in orange, the variational auto-encoder.",
    "start": "849475",
    "end": "857019"
  },
  {
    "text": "So in that case, that you have your unlabeled data, you apply your auto-encoder,",
    "start": "857020",
    "end": "863920"
  },
  {
    "text": "get a representation on which you do fit a linear model just like before. Okay. And then compare that to their learned- unsupervised learning rule.",
    "start": "863920",
    "end": "872875"
  },
  {
    "text": "So VAE is an unsupervised learning rule. Okay. And but-we're- we're comparing that to the learning rule that we have learned.",
    "start": "872875",
    "end": "882160"
  },
  {
    "text": "And it does better on these four image datasets, TinyMnist, Mnist, TinyFashionMnist, and FashionMnist.",
    "start": "882160",
    "end": "892040"
  },
  {
    "text": "Now, they tried generalization over domains, okay?",
    "start": "893970",
    "end": "899245"
  },
  {
    "text": "So they're evaluating the rule on two-way text classification. And if we focus our intention on the purple,",
    "start": "899245",
    "end": "906175"
  },
  {
    "text": "the 30 hours curve, what that means is, we did 30 hours on meta-training,",
    "start": "906175",
    "end": "911305"
  },
  {
    "text": "and now, we have an unsupervised learning rule. And now, we apply that to the case of two-way text classification.",
    "start": "911305",
    "end": "919808"
  },
  {
    "text": "And what you can see here is, if I apply my unsupervised learning rule for 1,000 steps,",
    "start": "919809",
    "end": "928180"
  },
  {
    "text": "I get a quite good representation such that I can get this accuracy. But if I apply my unsupervised learning rule for a bit longer,",
    "start": "928180",
    "end": "935050"
  },
  {
    "text": "for 2,000 steps, I can do even better, but then it levels off.",
    "start": "935050",
    "end": "940765"
  },
  {
    "text": "Okay. So that seems to be- it seems to have learned useful representation for text data.",
    "start": "940765",
    "end": "945805"
  },
  {
    "text": "So this, this is pretty cool. They- there was no text data involved in learning this unsupervised learning rule.",
    "start": "945805",
    "end": "951805"
  },
  {
    "text": "But then we can look at the 200 hours. What this one represent is, I meta-trained for 200 hours, got a rule.",
    "start": "951805",
    "end": "958985"
  },
  {
    "text": "Now, I'm applying this rule. This rule doesn't work well at all. And their explanation is something along the lines of- in this case,",
    "start": "958985",
    "end": "966690"
  },
  {
    "text": "we have meta over fitted to the specific- images basically.",
    "start": "966690",
    "end": "973290"
  },
  {
    "text": "Okay. So it's- this rule here in the red is not as general as the one in purple.",
    "start": "973290",
    "end": "981100"
  },
  {
    "text": "And then they explored generalization over networks. Okay. So and- what that means is,",
    "start": "981210",
    "end": "988630"
  },
  {
    "text": "so let's focus our attention to the most blue one here. Okay. So here's an unsupervised learning rule that was trained for 10,000 steps.",
    "start": "988630",
    "end": "1000915"
  },
  {
    "text": "And then they explore how well does this rule do for an encoder when the base model has different numbers of layers.",
    "start": "1000915",
    "end": "1010875"
  },
  {
    "text": "Basically what this says is, it generalizes. Okay, it does well. You can apply this rule.",
    "start": "1010875",
    "end": "1017355"
  },
  {
    "text": "But this rule is, you apply- you, you can have as many neurons as you want to or many layers as you want to because",
    "start": "1017355",
    "end": "1022649"
  },
  {
    "text": "this rule really operates on the neuron specific layer. Okay. And this light green here,",
    "start": "1022650",
    "end": "1032280"
  },
  {
    "text": "it's just as a comparison. Well, what if we- basically, how you just- a random rule.",
    "start": "1032280",
    "end": "1038655"
  },
  {
    "text": "And they try with number of units. So the first one was, was the depth,",
    "start": "1038655",
    "end": "1043905"
  },
  {
    "text": "this is width of the encoder. And they also explore wha- what if I have different activation function in our encoder?",
    "start": "1043905",
    "end": "1051510"
  },
  {
    "text": "Okay. Now, let's finalize here with some cri- critiques and limitations specifically that we identified.",
    "start": "1051510",
    "end": "1061304"
  },
  {
    "text": "Well, first of all, this is very computationally expensive. This is not for you at home basically,",
    "start": "1061305",
    "end": "1068730"
  },
  {
    "text": "like thi- this is- this took a long time to train. And this was after using many, many tricks.",
    "start": "1068730",
    "end": "1075030"
  },
  {
    "text": "So what one type of trick, which is hyperparameter tuning, and this is gradient clipping, and specific learning rates.",
    "start": "1075030",
    "end": "1081225"
  },
  {
    "text": "But also, how the actual sup- unsupervised learning rule",
    "start": "1081225",
    "end": "1087225"
  },
  {
    "text": "was parameterized and structured was very tricky. There were- we abstracted up way a bunch of details in this talk.",
    "start": "1087225",
    "end": "1095940"
  },
  {
    "text": "So that was- it's sort about also like a limitation that its- that's,",
    "start": "1095940",
    "end": "1101985"
  },
  {
    "text": "uh, it seems to be quite hard to get this working. And allege of that is,",
    "start": "1101985",
    "end": "1107490"
  },
  {
    "text": "that there is no ablative analysis. Meaning, we don't know- of all these tricks,",
    "start": "1107490",
    "end": "1113279"
  },
  {
    "text": "let- let's say there were 40 tricks in this paper probably. They were like an appendix that they were- it's a long appendix [LAUGHTER].",
    "start": "1113280",
    "end": "1120659"
  },
  {
    "text": "It's unclear what, what was the secret sauce. Were, were they all necessary or were,",
    "start": "1120660",
    "end": "1126135"
  },
  {
    "text": "were some tricks more important than the others? Also, reproducibility, like if we went to reproduce these paper.",
    "start": "1126135",
    "end": "1135899"
  },
  {
    "text": "There are many things that we weren't able to actually get from the paper. For instance, they're doing few-shot classification,",
    "start": "1135900",
    "end": "1141960"
  },
  {
    "text": "but how many label examples did they have? Like what was the K in their K shot,",
    "start": "1141960",
    "end": "1147690"
  },
  {
    "text": "and what was their N in there anyway? As well as how many unlabeled examples did they have on",
    "start": "1147690",
    "end": "1153135"
  },
  {
    "text": "each task, that we, we were not able to read that out from the paper. And that seems quite important to actually interpret the accuracy scores, for instance.",
    "start": "1153135",
    "end": "1162914"
  },
  {
    "text": "Now, given these limitations, we have some suggestions. First, we we could do an ablative analysis.",
    "start": "1162915",
    "end": "1171580"
  },
  {
    "text": "Uh, perhaps this, we were thinking that in this case they're sort of doing, um, truncated backprop.",
    "start": "1171580",
    "end": "1180150"
  },
  {
    "text": "Potentially, you could do something like implicit MAML instead. Let us know if that's true.",
    "start": "1180150",
    "end": "1187020"
  },
  {
    "text": "[LAUGHTER] Um, you could also, it'd be interesting to investigate beyond,",
    "start": "1187020",
    "end": "1193530"
  },
  {
    "text": "just and then like more network architectures such as CNN or attention-based models,",
    "start": "1193530",
    "end": "1199590"
  },
  {
    "text": "how generalized it is to those? Uh, is there a better way that like that enco- learning rule",
    "start": "1199590",
    "end": "1204990"
  },
  {
    "text": "was encoded in a very complex way. And like, is there a simple way of doing this?",
    "start": "1204990",
    "end": "1210975"
  },
  {
    "text": "And also, where we're curious, like is this learning rule fully expressive? Like can this, uh,",
    "start": "1210975",
    "end": "1217470"
  },
  {
    "text": "approach learn any potential learning rule? Uh, we don't know, but perhaps it can.",
    "start": "1217470",
    "end": "1222640"
  },
  {
    "text": "Um, and I think that was it. Thank you. [APPLAUSE]",
    "start": "1223070",
    "end": "1233100"
  },
  {
    "text": "So if you- how much time do we have? Negative two minutes. [LAUGHTER] That's right. So if you have any questions,",
    "start": "1233100",
    "end": "1239955"
  },
  {
    "text": "you can't ask them. [LAUGHTER] Right they can't, or can they ask?",
    "start": "1239955",
    "end": "1246300"
  },
  {
    "text": "No. [LAUGHTER] They can ask it offline. One more time. They can ask you offline now. Ah, perfect, offline apparently, you're allowed.",
    "start": "1246300",
    "end": "1254200"
  },
  {
    "text": "Thanks. So I'm Katherine and this is Saelig. And today, we'll be talking about, um, this, uh,",
    "start": "1257330",
    "end": "1265034"
  },
  {
    "text": "Bachman, Sordoni and Trischler paper, Learning Algorithms for Active Learning.",
    "start": "1265035",
    "end": "1270165"
  },
  {
    "text": "So this is basically ah, an extension of matching networks to an active learning case.",
    "start": "1270165",
    "end": "1275789"
  },
  {
    "text": "So I'll start by briefly reviewing matching networks. Um, so as Chelsea,",
    "start": "1275790",
    "end": "1281130"
  },
  {
    "text": "uh, discussed in a recent lecture, one way to think about matching networks is as a differentiable k-nearest neighbors,",
    "start": "1281130",
    "end": "1287415"
  },
  {
    "text": "um, over a learned embedding space. Um, so in a very simple setup like we have here, um,",
    "start": "1287415",
    "end": "1293430"
  },
  {
    "text": "we can imagine that we are going to embed each of our example items as well as our probe item,",
    "start": "1293430",
    "end": "1300120"
  },
  {
    "text": "um, using, uh, for example, a CNN. Uh, and then we want to compute the label for the probe item.",
    "start": "1300120",
    "end": "1308430"
  },
  {
    "text": "So to do that, we have, um, either an attention or a distance function that basically compares the similarity",
    "start": "1308430",
    "end": "1315315"
  },
  {
    "text": "of examples or embedded examples with the embedded probe item.",
    "start": "1315315",
    "end": "1320325"
  },
  {
    "text": "Um, and from that, we can take an average of the example labels weighted by their similarity with the probe.",
    "start": "1320325",
    "end": "1328090"
  },
  {
    "text": "Okay. So, um, in the previous case, we had, um, uh, basically shape as the distinguishing feature among the examples.",
    "start": "1329240",
    "end": "1339269"
  },
  {
    "text": "But in this task, um, color distinguishes them. So this motivates the idea that we might wanna be using a context sensitive encoder,",
    "start": "1339269",
    "end": "1348239"
  },
  {
    "text": "where the embedding of a given example depends on the other examples that are present for that task.",
    "start": "1348239",
    "end": "1355335"
  },
  {
    "text": "Um, so one way we might do this is using a contextual encoder like a bidirectional LSTM,",
    "start": "1355335",
    "end": "1362865"
  },
  {
    "text": "um, where, ah, again, each, um, example embedding depends on the other examples that are present.",
    "start": "1362865",
    "end": "1371470"
  },
  {
    "text": "Uh, similarly, we might want the embedding of our probe item to depend on the examples that are present.",
    "start": "1371840",
    "end": "1379380"
  },
  {
    "text": "Um, so the way that they do that in matching networks is they have an attention LSTM,",
    "start": "1379380",
    "end": "1385140"
  },
  {
    "text": "um, which, uh, in addition to conditioning on the examples, also allows the, um,",
    "start": "1385140",
    "end": "1390630"
  },
  {
    "text": "probe item encoder to do things like ignore some of the examples if they're like redundant or there are outliers present,",
    "start": "1390630",
    "end": "1398415"
  },
  {
    "text": "um, and also, uh, builds in variance to the order in which the examples come in.",
    "start": "1398415",
    "end": "1404500"
  },
  {
    "text": "Okay. So, um, that's like a bird's-eye view of matching networks.",
    "start": "1406010",
    "end": "1411900"
  },
  {
    "text": "Um, but now, imagine that we're operating in a case where we only have labels for some of our examples.",
    "start": "1411900",
    "end": "1418455"
  },
  {
    "text": "So, um, the area of active learning deals with this because there are like lots of real-world, um,",
    "start": "1418455",
    "end": "1425150"
  },
  {
    "text": "settings where we have plenty of unlabeled data, and then just a little bit of labeled data, um,",
    "start": "1425150",
    "end": "1430235"
  },
  {
    "text": "or it's very expensive to acquire. Um, so one example is like an- in medical imaging case,",
    "start": "1430235",
    "end": "1436505"
  },
  {
    "text": "it might be that you could acquire labels for scans through expert annotation, but it would be costly to get them.",
    "start": "1436505",
    "end": "1443490"
  },
  {
    "text": "So the idea, um, in the paper we're going to be describing today is that they use meta-learning to,",
    "start": "1443490",
    "end": "1450630"
  },
  {
    "text": "um, active learn strategies for a given task. Um, uh, so in other words, the,",
    "start": "1450630",
    "end": "1457530"
  },
  {
    "text": "the model is going to learn which labels it makes sense to request.",
    "start": "1457530",
    "end": "1463960"
  },
  {
    "text": "Okay. So Saelig will go into the details in a minute, but just a high-level overview of the model,",
    "start": "1465520",
    "end": "1472595"
  },
  {
    "text": "um, the idea is that we have a, um, controller, an LSTM controller,",
    "start": "1472595",
    "end": "1478935"
  },
  {
    "text": "um, that requests labels for, um, what come in as a completely unlabeled set of example items,",
    "start": "1478935",
    "end": "1486975"
  },
  {
    "text": "um, over a series of time steps. So, um, this is the, kind of, active learning phase, and that means that at a given time step,",
    "start": "1486975",
    "end": "1496170"
  },
  {
    "text": "the controller, you know, sees its unlabelled set, it requests the label for one of the as-yet unlabeled items.",
    "start": "1496170",
    "end": "1503249"
  },
  {
    "text": "It reads in that label along with the encoding of the example item. Um, and, uh, then it uses this information to",
    "start": "1503249",
    "end": "1512759"
  },
  {
    "text": "basically make predictions for the labels of the other currently unlabeled items in the set.",
    "start": "1512760",
    "end": "1519090"
  },
  {
    "text": "Um, it gets a reward for how well it does, um, and then proceeds to the next time separate can request another label.",
    "start": "1519090",
    "end": "1526545"
  },
  {
    "text": "Um, at the end of, um, T time steps, it takes all of the labeled items that it's acquired, um,",
    "start": "1526545",
    "end": "1534450"
  },
  {
    "text": "and uses a modified matching network to classify held-out probe item.",
    "start": "1534450",
    "end": "1540510"
  },
  {
    "text": "Um, so, ah, because it's making discrete choices as it requests labels as this is trained with reinforcement learning,",
    "start": "1540510",
    "end": "1548174"
  },
  {
    "text": "and the total reward is a combination of how well it does during that, kind of, intermediate rewards of the act of learning, um,",
    "start": "1548175",
    "end": "1554940"
  },
  {
    "text": "training part and how, how well it does pacifying the held-out probe item.",
    "start": "1554940",
    "end": "1560565"
  },
  {
    "text": "Um, one other thing to mention here is, you might ask like, well, why aren't you using the matching network,",
    "start": "1560565",
    "end": "1567135"
  },
  {
    "text": "um, at each time step? And the reason is that the kind of intermediate predictor that it uses is less computationally expensive,",
    "start": "1567135",
    "end": "1577005"
  },
  {
    "text": "so it doesn't use the full matching network on the probe item until the very end. [NOISE]",
    "start": "1577005",
    "end": "1584985"
  },
  {
    "text": "Oh, thanks Katherine. So now we'll dive a little bit deeper into the individual modules used in the diagram you saw on the previous slide,",
    "start": "1584985",
    "end": "1591090"
  },
  {
    "text": "and we also just had a picture up on the corner just for, ah, easy reference. So we start with the context free, uh, encoding.",
    "start": "1591090",
    "end": "1597120"
  },
  {
    "text": "So these you can think of like, for example, image data, you'd have a CNN, um, generate this, um, encoding which is kind of",
    "start": "1597120",
    "end": "1603720"
  },
  {
    "text": "independent of the context of the support set. And then using these, um, context free encodings,",
    "start": "1603720",
    "end": "1609210"
  },
  {
    "text": "we generate these context-sensitive encodings by essentially concatenating- concatenating, ah, these encodings together and then run a bi-directional LSTM.",
    "start": "1609210",
    "end": "1616665"
  },
  {
    "text": "That way they have an idea, what else is in the- on support set. Then we have the selection module.",
    "start": "1616665",
    "end": "1621799"
  },
  {
    "text": "So at each time step t, we essentially get a probability distribution, um, over all the unlabeled items and we have to figure out which one we wanna pick.",
    "start": "1621800",
    "end": "1629620"
  },
  {
    "text": "And so the way we do this is we use, um, a bunch of different features, the max, min, and mean cosine similarity features between, ah,",
    "start": "1629620",
    "end": "1636630"
  },
  {
    "text": "the item in- the controller-item and the item-item similarities. We concatenate these all into a single vector and",
    "start": "1636630",
    "end": "1642630"
  },
  {
    "text": "then use a gated linear combination of these features to figure out, um, which- which is like the maximum logit we want to select for the unlabeled label.",
    "start": "1642630",
    "end": "1650085"
  },
  {
    "text": "Um, then in the reading module it takes this label and the embedding for the item and simply concatenates them together, um,",
    "start": "1650085",
    "end": "1657809"
  },
  {
    "text": "and then applies a linear transformation, ah, which the controller then takes as input, um, and then applies a simple LSTM update like you can see on it right there.",
    "start": "1657810",
    "end": "1667090"
  },
  {
    "text": "So and then in terms of the prediction rewards- so on the top, you can kinda see, ah, what is the reward you're trying to optimize over?",
    "start": "1667250",
    "end": "1674490"
  },
  {
    "text": "So essentially, we want to maximize the log probability that the, um, label for the held-out item,",
    "start": "1674490",
    "end": "1680610"
  },
  {
    "text": "um, is given, ah, given that the, ah, from our held-out test item x, um,",
    "start": "1680610",
    "end": "1685845"
  },
  {
    "text": "and then the current hidden state, and the current support, um, vector at time t. Um,",
    "start": "1685845",
    "end": "1691020"
  },
  {
    "text": "and so the objective is to minimize, uh, maximize this at each time step. And the idea we wanna maximize this at each time step,",
    "start": "1691020",
    "end": "1697289"
  },
  {
    "text": "is to promote this, uh, anytime behavior so that even if you're gonna kind of stop midway, you perform as optimally as you can.",
    "start": "1697290",
    "end": "1704370"
  },
  {
    "text": "Um, but this is quite computationally intensive to calculate. So the authors actually suggest,",
    "start": "1704370",
    "end": "1710010"
  },
  {
    "text": "um, calculating what they have on the right, which is an approximation. And so now you can see there is two reward terms,",
    "start": "1710010",
    "end": "1715650"
  },
  {
    "text": "the left being the reward for, um, the unlabeled items and then the right being the reward for at the- at the very end across",
    "start": "1715650",
    "end": "1722130"
  },
  {
    "text": "the whole episode using the terminal and support in a terminal hidden state.",
    "start": "1722130",
    "end": "1727485"
  },
  {
    "text": "So on the left, to calculate the left reward term, we can use this mechanism, which they call fast prediction.",
    "start": "1727485",
    "end": "1733289"
  },
  {
    "text": "And essentially, the idea is that this is attention based prediction that uses the similarities between,",
    "start": "1733290",
    "end": "1738765"
  },
  {
    "text": "um, the unlabeled and labeled items. Um, and then they actually used this sharpening score, which they empirically found to work much better and get better performance.",
    "start": "1738765",
    "end": "1747375"
  },
  {
    "text": "Um, and then the idea is that the similarities, since they don't change with each time step, you can precompute them and therefore,",
    "start": "1747375",
    "end": "1753990"
  },
  {
    "text": "it's much faster, um, to use this computation. Then the slow prediction, which they use to calculate the right reward term,",
    "start": "1753990",
    "end": "1760245"
  },
  {
    "text": "um, they do once at the very end. And this is using a modified matching network which has",
    "start": "1760245",
    "end": "1765330"
  },
  {
    "text": "to pass through the full LSTM, um, and its condition on the active learning control state, um,",
    "start": "1765330",
    "end": "1771059"
  },
  {
    "text": "like h of t, um, at the terminal one at the very end as well. And so this is, um, because you have to go through the full LSTM,",
    "start": "1771060",
    "end": "1777480"
  },
  {
    "text": "this is why they call it the slow prediction. So just to reiterate like the full algorithm as Katherine was mentioning.",
    "start": "1777480",
    "end": "1785190"
  },
  {
    "text": "Um, so for each time step, we essentially select the next instance using our selection module.",
    "start": "1785190",
    "end": "1790440"
  },
  {
    "text": "Then we read this label instance concatenated with the label, and then apply an LSTM update.",
    "start": "1790440",
    "end": "1795555"
  },
  {
    "text": "Um, then based on the- now the- the labeled item pair we have, ah, we update our known and unknown, uh,",
    "start": "1795555",
    "end": "1801825"
  },
  {
    "text": "set and then perform the fa- fast prediction to calculate the reward term as you saw in the previous slide at every time step,",
    "start": "1801825",
    "end": "1808350"
  },
  {
    "text": "and then finally use the slow prediction to calculate the right reward term.",
    "start": "1808350",
    "end": "1813070"
  },
  {
    "text": "So in terms of task, so they wanna to basically test out their strategy on a couple of different tasks.",
    "start": "1813740",
    "end": "1819810"
  },
  {
    "text": "So they used the Omniglot, which we're all familiar with from our homework, and, uh, and so this is a bunch of these characters from 50 different alphabets.",
    "start": "1819810",
    "end": "1827008"
  },
  {
    "text": "Um, but they also wanted to test in a more practical setting. So they tested on the MovieLens dataset, uh, which is basically a dataset composed of many ratings by users given to movies.",
    "start": "1827009",
    "end": "1835664"
  },
  {
    "text": "And so kind of like the idea of this is, when a new user signs up, ah, for a movie, you don't really know their preferences.",
    "start": "1835665",
    "end": "1842039"
  },
  {
    "text": "So how- how can you get this cold-start, ah, kind of, um, thing where how can you figure out what their preferences are?",
    "start": "1842040",
    "end": "1848280"
  },
  {
    "text": "So one example is you can just show them random movies or popular movies and see how they rate and get their preference from that",
    "start": "1848280",
    "end": "1853770"
  },
  {
    "text": "but that's probably not the most optimal way. Um, so this is why they use this active learning approach in that case.",
    "start": "1853770",
    "end": "1860010"
  },
  {
    "text": "So in terms of the Omniglot, um, Baseline Models, they use two slightly different versions of,",
    "start": "1860010",
    "end": "1866309"
  },
  {
    "text": "uh, the matching network. And so in the first one, they used this random set, where essentially, uh,",
    "start": "1866310",
    "end": "1871680"
  },
  {
    "text": "to generate the support, they randomly sample across the images in classes. So this means that there probably isn't gonna be an even distribution.",
    "start": "1871680",
    "end": "1879419"
  },
  {
    "text": "Um, that even some classes may not even have any images in the dataset for them to train on. Um, then the matching- ah,",
    "start": "1879420",
    "end": "1886034"
  },
  {
    "text": "matching net on the balanced case is they actually ensure an even class distribution. So say five images per class or something like that.",
    "start": "1886035",
    "end": "1893385"
  },
  {
    "text": "And this is kind of like, you know, the optimistic, um, performance that you would- you would hope that the active learner, ah,",
    "start": "1893385",
    "end": "1900585"
  },
  {
    "text": "could kind of figure out to get as many uniquely levels to from each class as possible and make sure that no class is under represented or not represented at all,",
    "start": "1900585",
    "end": "1908700"
  },
  {
    "text": "which may be the case in the random. Ah, and then the last baseline, they used is kind of a heuristic, where it's like this Minimum-Maximum Cosine Similarity.",
    "start": "1908700",
    "end": "1916200"
  },
  {
    "text": "So basically, this is effectively choosing items that are most different from the items that you currently have. So how did this do?",
    "start": "1916200",
    "end": "1924419"
  },
  {
    "text": "So you can see that the, um, their active, um, MN network, um, beat the random one,",
    "start": "1924420",
    "end": "1930299"
  },
  {
    "text": "which you kind of hope it would do. Um, and then it came quite close to performance into the matching net balance,",
    "start": "1930300",
    "end": "1935789"
  },
  {
    "text": "which is kind of like I was saying, you know, something that you hope the active learner can learn. So it's more of an optimistic baseline.",
    "start": "1935790",
    "end": "1941850"
  },
  {
    "text": "Um, you can see that there is a 2% degradation on the 1-shot 10-way compared to the Active MN and the MN in the balanced case.",
    "start": "1941850",
    "end": "1949620"
  },
  {
    "text": "And this is kind of expected because in a 1-shot case, if you only have one image and you're trying to distinguish with,",
    "start": "1949620",
    "end": "1955320"
  },
  {
    "text": "like in a large N, I guess, with many different classes, that can be quite hard for the active learner to figure out it needs to",
    "start": "1955320",
    "end": "1960660"
  },
  {
    "text": "pick like a unique label from each class. And then as I was mentioning before,",
    "start": "1960660",
    "end": "1966480"
  },
  {
    "text": "we wanted to optimize both the performance and data efficiency, and so in terms of data efficiency on the top,",
    "start": "1966480",
    "end": "1972570"
  },
  {
    "text": "we can see the Omniglot performance and so the- the left plot is basically how is it generalizing beyond a 1-shot setting?",
    "start": "1972570",
    "end": "1979425"
  },
  {
    "text": "And so you can see that, like, as you get more and more labels requested, um, the policy in purple, um,",
    "start": "1979425",
    "end": "1985260"
  },
  {
    "text": "actually does much better than the MN balanced case in the 1-shot and approaches, um, in the 2-shot.",
    "start": "1985260",
    "end": "1991125"
  },
  {
    "text": "And as we get more labels, it does do better, which is, ah, what we'd expect. Um, and then on the right,",
    "start": "1991125",
    "end": "1996720"
  },
  {
    "text": "you can kinda see how does this generalize to situations where there is more classes in the test set than what was trained on.",
    "start": "1996720",
    "end": "2002840"
  },
  {
    "text": "So they do a comparison with 5, 10, 15, and 20 classes. And you can see even in the five class setting,",
    "start": "2002840",
    "end": "2009350"
  },
  {
    "text": "ah, it kind of, ah, it- it does reasonably well. It kind of approaches this, um, oracle policy where basically requests a unique label at every single timestamp,",
    "start": "2009350",
    "end": "2018304"
  },
  {
    "text": "which you'd hope is like what the active learner is trying to do. And we see that, you know, if it is in fact trained with 20 classes and that's when you test on,",
    "start": "2018305",
    "end": "2025610"
  },
  {
    "text": "um, it almost, uh, matches Oracle policy. Um, on the bottom, we see the MovieLens performance.",
    "start": "2025610",
    "end": "2031190"
  },
  {
    "text": "So on the y-axis, we have the root mean squared error. And so we're trying to minimize this. And so in this case,",
    "start": "2031190",
    "end": "2036860"
  },
  {
    "text": "the active MN- MN actually outperforms all the baselines. And so the way the- they use this baseline, so for example,",
    "start": "2036860",
    "end": "2043099"
  },
  {
    "text": "you have the popular entropy. So this is kinda what I was describing the heuristic like earlier. So basically, you just pick the popular movies",
    "start": "2043099",
    "end": "2050120"
  },
  {
    "text": "in your dataset and kind of show those to the users. And so these kind of baselines were, um, basically, ah,",
    "start": "2050120",
    "end": "2056105"
  },
  {
    "text": "replaced the selection module, ah, in the network and then they run the full thing end-to-end. And so this is kind of nice to see.",
    "start": "2056105",
    "end": "2062659"
  },
  {
    "text": "It kind of gives you an idea of the importance of the selection model- the selection module. So you see the importance of, you know,",
    "start": "2062660",
    "end": "2069679"
  },
  {
    "text": "how you're selecting things in the policy to do that. Um, and yeah, so as you can see, um, it does outperform all these baselines.",
    "start": "2069680",
    "end": "2077450"
  },
  {
    "text": "So in conclusion, um, they proposed a model that basically active- actively learns,",
    "start": "2077450",
    "end": "2083240"
  },
  {
    "text": "ah, a system end-to-end. Um, they showed that we pretty much approach optimistic performance on the Omniglot.",
    "start": "2083240",
    "end": "2089780"
  },
  {
    "text": "And we actually outperform baselines on the MovieLens dataset, which is a more practical setting. So maybe it shows promise for this work",
    "start": "2089780",
    "end": "2097280"
  },
  {
    "text": "actually being used in more real-world applications. And now on to Katherine, we'll talk a little bit more about their critique and discussion points.",
    "start": "2097280",
    "end": "2104855"
  },
  {
    "text": "Yes, so, um, we thought one of the kind of most apparent issues, ah, with the model is that the controller doesn't",
    "start": "2104855",
    "end": "2111470"
  },
  {
    "text": "actually condition its label requests on the probe item at all, which is kinda strange if you think about it. So, um, in this kind of contrived example we've created,",
    "start": "2111470",
    "end": "2120380"
  },
  {
    "text": "and we have a marmot probe item, and then one of the other examples is a highly similar image.",
    "start": "2120380",
    "end": "2126275"
  },
  {
    "text": "Um, and you might expect that, you know, you want to just request the label for the other marmot image,",
    "start": "2126275",
    "end": "2132545"
  },
  {
    "text": "given that the other items are not at all visually similar. Ah, but on this model, there is, um,",
    "start": "2132545",
    "end": "2139685"
  },
  {
    "text": "no way for this to happen since the controller hasn't actually seen the probe item, um, and, uh, that doesn't actually come in until the- the very end of the process.",
    "start": "2139685",
    "end": "2150170"
  },
  {
    "text": "Um, there is a related point in Matching Networks, ah, which is that the embeddings of the,",
    "start": "2150170",
    "end": "2156920"
  },
  {
    "text": "ah, examples don't depend on the probe item. So in Matching Networks, the examples depend on each other and the probe item depends on the examples,",
    "start": "2156920",
    "end": "2166279"
  },
  {
    "text": "but not vice versa. Okay, um, kind of stepping back though, ah,",
    "start": "2166279",
    "end": "2174085"
  },
  {
    "text": "we were thinking about the fact that active learning is useful in a case where data is really expensive to collect, but this model,",
    "start": "2174085",
    "end": "2181309"
  },
  {
    "text": "of course to meta-learn active learning policies, um, has to have a lot of labeled data, ah, to learn.",
    "start": "2181310",
    "end": "2190405"
  },
  {
    "text": "So we were trying to think about domains where, um, this would or wouldn't be a realistic scenario and we're curious if people had ideas.",
    "start": "2190405",
    "end": "2199030"
  },
  {
    "text": "[NOISE] So I think, um,",
    "start": "2199030",
    "end": "2207155"
  },
  {
    "text": "one positive use case might be like the medical imaging example that we gave at the beginning,",
    "start": "2207155",
    "end": "2212690"
  },
  {
    "text": "where it is possible to collect, ah, labels for scans. And maybe you already have a big database of those,",
    "start": "2212690",
    "end": "2219380"
  },
  {
    "text": "but you don't wanna to have like a label- a labeler having to continue labeling scans in the future.",
    "start": "2219380",
    "end": "2225185"
  },
  {
    "text": "So in that case, you'd have the data to train the model and then you could use it going forward.",
    "start": "2225185",
    "end": "2230825"
  },
  {
    "text": "Yeah. We have a few more discussion points, but do we have time to [BACKGROUND] - You've got 20 minutes.",
    "start": "2230825",
    "end": "2237050"
  },
  {
    "text": "Okay. One thing I would like to say is that large datasets in the medical is usually- so in the case of radiology is from radiology reports.",
    "start": "2237050",
    "end": "2246065"
  },
  {
    "text": "So that they're like letting those labels, so you could imagine a scenario where you have error-prone label to this,",
    "start": "2246065",
    "end": "2252590"
  },
  {
    "text": "but then you can request good labels. Right? Oh I understand. Yeah, and- and I guess, um,",
    "start": "2252590",
    "end": "2260119"
  },
  {
    "text": "kinda going forward that like, you know, say you, um, have like these NLP tasks, right? Um, so do- do you guys think that there is,",
    "start": "2260120",
    "end": "2268025"
  },
  {
    "text": "um, this approach could help in some NLP tasks? I guess in choosing, you know, maybe more relevant data or something that's,",
    "start": "2268025",
    "end": "2274700"
  },
  {
    "text": "you know, I guess more useful to the task?",
    "start": "2274700",
    "end": "2277470"
  },
  {
    "text": "So I guess like, uh, one, you know, one idea that we had was in basically choosing the more relevant sentences.",
    "start": "2286450",
    "end": "2293480"
  },
  {
    "text": "So maybe like a machine translation task, you have a bunch of different, uh, sentences in your data set and maybe some are more representative of,",
    "start": "2293480",
    "end": "2301445"
  },
  {
    "text": "you know, what the usual language is like, maybe some are more slang. And, you know, depending on the task, maybe you want to pick the ones that are more, um,",
    "start": "2301445",
    "end": "2308960"
  },
  {
    "text": "I guess more representative or I guess would better help in the translation. Um, and yeah, I guess like the last discussion point we had was,",
    "start": "2308960",
    "end": "2317645"
  },
  {
    "text": "um, so they actually did a couple of ablations, at least for the Omniglot. And so they found that the context-sensitive encoder that we were talking about,",
    "start": "2317645",
    "end": "2325069"
  },
  {
    "text": "where we have the LSTM run over all these contexts independent embeddings actually didn't have much of an effect.",
    "start": "2325070",
    "end": "2331790"
  },
  {
    "text": "Um, are they- and, I guess, like our reasoning for that is probably because in the Omniglot,",
    "start": "2331790",
    "end": "2337130"
  },
  {
    "text": "like all- all the images that, you know, CNN would probably do pretty well at getting the context and looking at what the other,",
    "start": "2337130",
    "end": "2344165"
  },
  {
    "text": "um, I guess characters are in the support probably isn't too irrelevant. Um, but maybe there are other applications like, you know,",
    "start": "2344165",
    "end": "2350810"
  },
  {
    "text": "say there were different colors then that would be really, uh, useful to know the context of other ones. Um, maybe there's other applications where this could be essential.",
    "start": "2350810",
    "end": "2359055"
  },
  {
    "text": "Yeah. So you like introduce more variability, like across tasks in example items,",
    "start": "2359055",
    "end": "2366160"
  },
  {
    "text": "you should expect to need context more. Yeah. I guess we are all right then.",
    "start": "2366160",
    "end": "2373000"
  },
  {
    "text": "[APPLAUSE].",
    "start": "2373000",
    "end": "2386380"
  },
  {
    "text": "Hi everyone, is this working? So I'm Megumi.",
    "start": "2386380",
    "end": "2391595"
  },
  {
    "text": "Ayush. I'm Kamil. And we're going to be presenting on one-shot imitation",
    "start": "2391595",
    "end": "2396619"
  },
  {
    "text": "from observing humans via domain adaptive meta-learning. Um, the authors of the paper are here today,",
    "start": "2396619",
    "end": "2404480"
  },
  {
    "text": "[LAUGHTER] which is great. Um, so let's get started.",
    "start": "2404480",
    "end": "2408840"
  },
  {
    "text": "So let's start with the general problem of imitation learning, um, where a robot must learn to do a task by observing human demonstrations.",
    "start": "2411460",
    "end": "2421040"
  },
  {
    "text": "So traditionally, this is done either through kinesthetic teaching, which is where a human directly manipulates the robot's arm,",
    "start": "2421040",
    "end": "2429890"
  },
  {
    "text": "for example, or through teleoperation where this manipulation is done remotely.",
    "start": "2429890",
    "end": "2435184"
  },
  {
    "text": "And in either of these cases, it requires a lot of grad student time and effort to be put",
    "start": "2435185",
    "end": "2441109"
  },
  {
    "text": "into this tedious task of carefully manipulating the robot. Uh, humans, on the other hand, um,",
    "start": "2441110",
    "end": "2448730"
  },
  {
    "text": "are able to- are also able to learn, ah, from demonstrations by others. But we can do this through visual input.",
    "start": "2448730",
    "end": "2455900"
  },
  {
    "text": "So the question is, what can robots do then? There are several different challenges,",
    "start": "2455900",
    "end": "2462440"
  },
  {
    "text": "um, with regards to this task. So the first one is that if we are trying to learn from raw visual input,",
    "start": "2462440",
    "end": "2470059"
  },
  {
    "text": "um, that requires a lot of data in the first place. And second, ah, there's this fundamental problem [BACKGROUND] of a domain shift.",
    "start": "2470060",
    "end": "2478714"
  },
  {
    "text": "So for one, um, it's very hard to learn the morphological correspondence between,",
    "start": "2478715",
    "end": "2486035"
  },
  {
    "text": "ah, a robot's body parts and human's body parts, a robotic arm and a human arm. Um, and this correspondence might not even exist in the first place for some robots.",
    "start": "2486035",
    "end": "2496279"
  },
  {
    "text": "Ah, and then on top of that, the robot must be able to generalize between different demonstrators, different objects,",
    "start": "2496279",
    "end": "2503538"
  },
  {
    "text": "and different backgrounds, um, and learn, ah, task specific parameters regardless of these other changing factors.",
    "start": "2503539",
    "end": "2512825"
  },
  {
    "text": "So the authors of this paper were motivated by these challenges to develop domain adoptive meta-learning.",
    "start": "2512825",
    "end": "2520250"
  },
  {
    "text": "And here's the idea. So the final goal is for the robot to be able to learn to do",
    "start": "2520250",
    "end": "2526535"
  },
  {
    "text": "a certain task just by observing one single human demonstration in the form of a video.",
    "start": "2526535",
    "end": "2532970"
  },
  {
    "text": "So this is the end goal. And in order to do that, we can provide the robot with, ah,",
    "start": "2532970",
    "end": "2540290"
  },
  {
    "text": "human demonstrations and robot demonstrations during meta-training, where a human demonstration, d_h,",
    "start": "2540290",
    "end": "2547025"
  },
  {
    "text": "is a sequence of observations, ah, and the robot demonstration d_r,",
    "start": "2547025",
    "end": "2552110"
  },
  {
    "text": "is a sequence of not only observations, but the robot state. So for example, the robots joint angles or some body configuration information,",
    "start": "2552110",
    "end": "2561470"
  },
  {
    "text": "as well as the robot actions. And so the idea here is that during meta-training,",
    "start": "2561470",
    "end": "2566555"
  },
  {
    "text": "we can learn how to infer a task specific policy, ah,",
    "start": "2566555",
    "end": "2571865"
  },
  {
    "text": "from a human demonstration by validating on the robot demonstrations,",
    "start": "2571865",
    "end": "2577085"
  },
  {
    "text": "which is much easier to do because you have access to the robots actions. And this is just an overview and we'll get into the details later.",
    "start": "2577085",
    "end": "2585830"
  },
  {
    "text": "Um, and so, um, just really quickly, this is very similar",
    "start": "2585830",
    "end": "2591260"
  },
  {
    "text": "to- this is an extension of the MAML algorithms. So you can see that the, um, thing inside the blue box,",
    "start": "2591260",
    "end": "2596990"
  },
  {
    "text": "ah, is the inner- is what we would call the inner loop, and the red is the outer loop. Ah, and you can see that the loss inside the inner loop,",
    "start": "2596990",
    "end": "2605180"
  },
  {
    "text": "ah, is computed on just the human demonstrations. Whereas for the meta-training part,",
    "start": "2605180",
    "end": "2610310"
  },
  {
    "text": "ah, in the outer loop, we can compute, ah, behavior cloning loss on the robot demonstrations.",
    "start": "2610310",
    "end": "2616800"
  },
  {
    "text": "So kind of getting more into, ah, what the algorithm is doing. Um, so during meta-training,",
    "start": "2617230",
    "end": "2623434"
  },
  {
    "text": "we first sample a task from the task distribution, and then we sample a human demonstration specifically of that task.",
    "start": "2623435",
    "end": "2631100"
  },
  {
    "text": "And then what we can do is, ah, compute policy parameters, ah, by using this loss L Psi on the human demonstration and during meta-training,",
    "start": "2631100",
    "end": "2641479"
  },
  {
    "text": "since we do have access to the robot demonstrations, we can sample a robot demonstration of that same task and we can",
    "start": "2641479",
    "end": "2648485"
  },
  {
    "text": "update our meta parameters using the loss calculated on the robot demonstrations.",
    "start": "2648485",
    "end": "2653780"
  },
  {
    "text": "And as mentioned- as I mentioned, ah, in the previous slide here we can use LBC, which is the behavioral cloning loss,",
    "start": "2653780",
    "end": "2660515"
  },
  {
    "text": "since we do have access to the robot's, ah, actions. In the output here, um,",
    "start": "2660515",
    "end": "2666125"
  },
  {
    "text": "are two, um, meta parameters. So there's Theta and there's Psi. Uh, Theta is something that we are probably all familiar with.",
    "start": "2666125",
    "end": "2674120"
  },
  {
    "text": "So during meta-test time, Theta acts as the initial policy parameters that you're doing, the gradient step from.",
    "start": "2674120",
    "end": "2681125"
  },
  {
    "text": "Um, and then something that might be new and I think there was a group that presented on something that  fits similar to this,",
    "start": "2681125",
    "end": "2688130"
  },
  {
    "text": "um, is we meta learn that inner loss. So there's L Psi, ah, and we're learning Psi, ah,",
    "start": "2688130",
    "end": "2695089"
  },
  {
    "text": "which parametizes this loss, ah, during meta-training. And, uh, Kamil will talk more about that later.",
    "start": "2695090",
    "end": "2703339"
  },
  {
    "text": "And then of course, ah, in the input to the meta-test algorithm, we have our single video of a human demonstration,",
    "start": "2703340",
    "end": "2709730"
  },
  {
    "text": "which we want to learn from. And the output is the policy parameters, ah, which we can compute from this learn loss.",
    "start": "2709730",
    "end": "2715940"
  },
  {
    "text": "[BACKGROUND]",
    "start": "2715940",
    "end": "2724280"
  },
  {
    "text": "Okay. Cool. So we talked about the architecture in detail. So we talked about the training step, the meta-training, and then also the meta-testing.",
    "start": "2724280",
    "end": "2730940"
  },
  {
    "text": "So we'll go over it in regards to this policy architecture. So as we talked about initially,",
    "start": "2730940",
    "end": "2736400"
  },
  {
    "text": "what we have is this initial parameter Theta and we wanna update Theta to be more specific to a new task that we're trying to generalize too.",
    "start": "2736400",
    "end": "2742924"
  },
  {
    "text": "So during meta-training initially, what we do is we feed in this human demonstration, which is of a new task that we're trying to update our task parameters,",
    "start": "2742925",
    "end": "2749840"
  },
  {
    "text": "uh, to be able to accomplish. And so one of the things that we think about is that as Megumi mentioned earlier,",
    "start": "2749840",
    "end": "2755330"
  },
  {
    "text": "we don't have access to human actions and they might not directly correspond to robot actions. So it's not enough to enforce a loss on- on this action like the human demonstration,",
    "start": "2755330",
    "end": "2765710"
  },
  {
    "text": "because that wouldn't give us enough- like we- first of all, we don't have access to those actions and number 2,",
    "start": "2765710",
    "end": "2770840"
  },
  {
    "text": "since those- since those actions might not have direct correspondence, it's not actually gonna inform us to make",
    "start": "2770840",
    "end": "2776030"
  },
  {
    "text": "any updates or supply any gradients to update these task parameters. So what they do instead is that they have this idea of a learned adaptation objective,",
    "start": "2776030",
    "end": "2783110"
  },
  {
    "text": "and we'll treat that as a black box for now and then we'll get into it later in the next slide. So what happens initially is we feed in",
    "start": "2783110",
    "end": "2788990"
  },
  {
    "text": "this human demonstrations through some perception layers. So a few convolutional layers of stride 2 and then two of stride 1.",
    "start": "2788990",
    "end": "2795920"
  },
  {
    "text": "And this outputs a feature vector which corresponds to, ah, the perception. Like it's- it's part of the perception output.",
    "start": "2795920",
    "end": "2802640"
  },
  {
    "text": "And then those features are concatenated with the last hiddens- hidden layer of the control layers.",
    "start": "2802640",
    "end": "2808505"
  },
  {
    "text": "So these are the ones that are used to predict the action and we concatenate these two vectors and we feed them into this learned adaptation objective.",
    "start": "2808505",
    "end": "2815465"
  },
  {
    "text": "And what this learned adaptation objective has to accomplish is that it has to understand based on this new task,",
    "start": "2815465",
    "end": "2820609"
  },
  {
    "text": "what the behavior- task specific behavior is, and as well as the objects that are necessary to execute that task.",
    "start": "2820610",
    "end": "2826265"
  },
  {
    "text": "And so one of the things that they theorized is that to- to understand what this learned adaptation objective should look like,",
    "start": "2826265",
    "end": "2832010"
  },
  {
    "text": "we have to have a temporal view of the human demonstration. This is because actions take- take place across",
    "start": "2832010",
    "end": "2837665"
  },
  {
    "text": "multiple frames and having a view of all the frames at once allows you to understand what motions needs to happen and",
    "start": "2837665",
    "end": "2843950"
  },
  {
    "text": "what needs to- what needs to be updated is not only the perceptual, ah, components of this network, but also the control components,",
    "start": "2843950",
    "end": "2850220"
  },
  {
    "text": "because it's both the perception and the control that influence the behavior for the new task. And so this learn adaptation objective,",
    "start": "2850220",
    "end": "2856580"
  },
  {
    "text": "which we'll talk about later, is the goal is to supply gradients back to both the control layers and the perception components of this network.",
    "start": "2856580",
    "end": "2863150"
  },
  {
    "text": "Such that we can generalize and we can go from this initial Theta to Phi, which is the new parameters for this new task.",
    "start": "2863150",
    "end": "2869805"
  },
  {
    "text": "So after we update these parameters, we feed in a robot demonstration, and this robot demonstration goes through",
    "start": "2869805",
    "end": "2875510"
  },
  {
    "text": "the same perceptual layers and then we have the robot configuration, which is the states, so the joints of the robots and the configuration of those joints.",
    "start": "2875510",
    "end": "2882920"
  },
  {
    "text": "We take those along with the perception features to predict the gripper pose and the gripper pose is",
    "start": "2882920",
    "end": "2888710"
  },
  {
    "text": "essentially whether the gripper should be open or closed. And so we have a squared error loss on this",
    "start": "2888710",
    "end": "2893840"
  },
  {
    "text": "to enforce that this- that this is done correctly. And then because actions are more complex than simply just opening a gripper,",
    "start": "2893840",
    "end": "2900470"
  },
  {
    "text": "we have to have- we have a few fully connected layers which go on to predict the action. And then we have a behavioral cloning loss based on",
    "start": "2900470",
    "end": "2906610"
  },
  {
    "text": "the robot actions that we also have access to during meta-training. So the combination of these two things,",
    "start": "2906610",
    "end": "2912980"
  },
  {
    "text": "does this one-shot imitation learning such that we feed in this human demonstration. We have one example of this.",
    "start": "2912980",
    "end": "2918275"
  },
  {
    "text": "And then we update the layers such that we have this new- we update the parameters such that we have this new Phi parameter which is specific to that task,",
    "start": "2918275",
    "end": "2925369"
  },
  {
    "text": "such that the robot demonstration can fulfill that task. So we'll go into this learned adaptation objective now.",
    "start": "2925370",
    "end": "2930535"
  },
  {
    "text": "So the way the learned adaptation objective works it takes into account the perceptual features that have been extracted from those earlier convolutional layers,",
    "start": "2930535",
    "end": "2937600"
  },
  {
    "text": "as well as the control, ah, the last hidden layers of the control layers. And so both of these control the perception and",
    "start": "2937600",
    "end": "2944750"
  },
  {
    "text": "the control of the robot and what we do is we feed these through temporal convolutions. So we- we have 1D convolutions across time and then we convolve this down, ah,",
    "start": "2944750",
    "end": "2952910"
  },
  {
    "text": "using 10 1D convolutions and then lastly, six 1 by 1 convolutions.",
    "start": "2952910",
    "end": "2958250"
  },
  {
    "text": "And then we do a matrix normalization to get a scalar value. And the goal is that when we update this loss,",
    "start": "2958250",
    "end": "2963694"
  },
  {
    "text": "when we- when we back prop on this loss, we compute this inner gradient step. It updates the parameters such that we're specific to this new task.",
    "start": "2963695",
    "end": "2971180"
  },
  {
    "text": "And then if you look back at this behavioral cloning loss that we talked about. Since the behavioral loss- behavior cloning loss has",
    "start": "2971180",
    "end": "2977030"
  },
  {
    "text": "this implicit loss that we're learning embedded inside of this as an inner loss, when we do this final gradient step on the behavioral cloning loss,",
    "start": "2977030",
    "end": "2983750"
  },
  {
    "text": "it also updates the weights of- of the Psi weights which are corresponding to this loss.",
    "start": "2983750",
    "end": "2988820"
  },
  {
    "text": "So we learn this loss through our meta learning procedure. Yes. And now, let's talk about some of the- uh, here we go.",
    "start": "2988820",
    "end": "2996190"
  },
  {
    "text": "Let's talk about some of the [NOISE] experiments that are being done that we're being compared to. Um, so the first one is the contextual policy,",
    "start": "2996190",
    "end": "3002280"
  },
  {
    "text": "where all you're feeding in is the last, um, image from a human demonstration, um, to identify the task and the robot state.",
    "start": "3002280",
    "end": "3009555"
  },
  {
    "text": "Uh, the DA-LSTM policy was, uh, talked about earlier, um, but it's,",
    "start": "3009555",
    "end": "3015035"
  },
  {
    "text": "um, it's basically you're getting, uh, the full human video demonstration, as well as the current robot stage break.",
    "start": "3015035",
    "end": "3021080"
  },
  {
    "text": "That current robot action and doing that over time steps, unrolling it. Uh, DAML with the linear loss is the same thing as what we presented,",
    "start": "3021080",
    "end": "3027839"
  },
  {
    "text": "except instead of using the temporal loss, they just do, uh, a single la- linear layer over the policy activations.",
    "start": "3027840",
    "end": "3034365"
  },
  {
    "text": "And then DAML temporal loss is the full network that we showed you before with a full temporal learned adaptation loss, um, there.",
    "start": "3034365",
    "end": "3042089"
  },
  {
    "text": "So just some, uh, I think it's great if we can visualize some of the results really quickly.",
    "start": "3042090",
    "end": "3047655"
  },
  {
    "text": "But the experiments that they were working with- um, I'm gonna change its speed. Um, so the first is, like, placing and you can compare,",
    "start": "3047655",
    "end": "3054840"
  },
  {
    "text": "like, as you can see, they're using different, um, objects and configurations at, uh, meta-train and meta-test time.",
    "start": "3054840",
    "end": "3060495"
  },
  {
    "text": "And you can see that models like the LSTM and contextual model were not able to perform nearly as well.",
    "start": "3060495",
    "end": "3065610"
  },
  {
    "text": "They misidentified the object, or they were not able to control- even if they identified the object correctly,",
    "start": "3065610",
    "end": "3070920"
  },
  {
    "text": "they were not able to control the object they're replacing into the right spot. Um, and they work with tasks like pushing, uh,",
    "start": "3070920",
    "end": "3078660"
  },
  {
    "text": "pick and place and just place where the object is already in the gripper or the hand. But qualitatively, you can see a lot more struggling with contextual and LSTM.",
    "start": "3078660",
    "end": "3087630"
  },
  {
    "text": "And linear loss is pretty well, but not as well as inputting the temporal loss. Uh, let's maybe look at it.",
    "start": "3087630",
    "end": "3093900"
  },
  {
    "text": "Brief, yes, so pick and place is when you actually have to pick up the object and also then place it into the container.",
    "start": "3093900",
    "end": "3099915"
  },
  {
    "text": "Um, so moving on to the first experiment and truly understanding qualita- quantitatively.",
    "start": "3099915",
    "end": "3105045"
  },
  {
    "text": "So the first one is placing, pushing, and pick and place using all three different, um, tasks. Uh, but with all- comparing the four layers,",
    "start": "3105045",
    "end": "3112305"
  },
  {
    "text": "I mean, sorry, the four networks, and you can see that, clearly, the temporal loss and the meta-learned, uh, adaptive objective was very useful,",
    "start": "3112305",
    "end": "3119190"
  },
  {
    "text": "and that there's sig- an extreme increase in accuracies in all three of these tasks. So temporal formation across the human demonstrations is",
    "start": "3119190",
    "end": "3127170"
  },
  {
    "text": "obviously going to be very important as according to this table you can see. Uh, the second experiment was the pushing task.",
    "start": "3127170",
    "end": "3135405"
  },
  {
    "text": "So we're just looking at one task of pushing, but exploring like the different backgrounds that could be placed, that you could use it, train it at",
    "start": "3135405",
    "end": "3141030"
  },
  {
    "text": "meta-train, and meta-test time. So in all these experiments, like they're varying the object from meta-train to meta-test time.",
    "start": "3141030",
    "end": "3146474"
  },
  {
    "text": "The objects that they're using, they have different sets of objects. But now, here, we're really focusing on backgrounds. So using the temporal loss,",
    "start": "3146475",
    "end": "3153465"
  },
  {
    "text": "the full model that we were talking about earlier, when it operates on a scene background in meta-test time,",
    "start": "3153465",
    "end": "3159380"
  },
  {
    "text": "it has an 81.8% accuracy. But on new backgrounds, you can see that it's significantly lower, uh,",
    "start": "3159380",
    "end": "3164855"
  },
  {
    "text": "more than 10% difference approximately. And actually, what's more interesting is if you analyze where the failures of,",
    "start": "3164855",
    "end": "3171185"
  },
  {
    "text": "er, the DAML occurs on the scene in novel backgrounds. You can see that some of the failures will occur",
    "start": "3171185",
    "end": "3177359"
  },
  {
    "text": "from not being able to identify what the task is, like not knowing which, uh, like the visual features, like which,",
    "start": "3177360",
    "end": "3183735"
  },
  {
    "text": "um, object to place it in. Uh, and some of the failures are- the second group of failures are even",
    "start": "3183735",
    "end": "3188760"
  },
  {
    "text": "if you know which object to place it in and you understand all the visual cues, you can't control the object that you are placing",
    "start": "3188760",
    "end": "3193800"
  },
  {
    "text": "or pushing to move it to the right spot. So- and in a background that's seen before, you see that you have only 1 out of 33 failures in task identification",
    "start": "3193800",
    "end": "3201300"
  },
  {
    "text": "which makes sense because you've seen that background before. But when you've seen new backgrounds, then you see a lot more failure percentages in task identification,",
    "start": "3201300",
    "end": "3209160"
  },
  {
    "text": "which is probably because of the, the different visual cues that you aren't used to. And overall, the failures from control seem relatively straight,",
    "start": "3209160",
    "end": "3216285"
  },
  {
    "text": "uh, relatively constant across these three background experiments. Um, and that probably makes sense because just controlling an object,",
    "start": "3216285",
    "end": "3223095"
  },
  {
    "text": "um, in different scenarios, um, it's difficult overall. So it should not change much with the, uh, introduction of a new background.",
    "start": "3223095",
    "end": "3230500"
  },
  {
    "text": "Um, and our third experiment is, uh, the third experiment presented in the paper was placing- uh,",
    "start": "3230540",
    "end": "3236640"
  },
  {
    "text": "doing the placing task but using the Sawyer arm instead of the other robotic configuration they had. And the whole point of this was to test on a different,",
    "start": "3236640",
    "end": "3243525"
  },
  {
    "text": "um, completely different framework. So this was like using kinesthetic teaching instead of teleoperation for the outer loss.",
    "start": "3243525",
    "end": "3250080"
  },
  {
    "text": "Um, and you use complete different- they use completely different robot here and  a different form of robotic demonstration.",
    "start": "3250080",
    "end": "3257204"
  },
  {
    "text": "So you can see that there is still a pretty good- success rate of 77.8% in placing. So basically, what this shows is that you can generalize the,",
    "start": "3257204",
    "end": "3264765"
  },
  {
    "text": "uh, algorithm to different, um, robotic configurations and different forms of supervision, whether that be teleoperational or kinesthetic.",
    "start": "3264765",
    "end": "3272385"
  },
  {
    "text": "And the final experiment was really comparing the- really understanding the role of the, um, temporal loss.",
    "start": "3272385",
    "end": "3280005"
  },
  {
    "text": "And here in this experiment, they didn't do any domain shift. It was on a simulation, um, robotics simulation, and, uh,",
    "start": "3280005",
    "end": "3286740"
  },
  {
    "text": "this simulated the pushing task with, again, like no domain shifts, so just really focusing on the loss.",
    "start": "3286740",
    "end": "3291915"
  },
  {
    "text": "And you can see that just using, um, the temporal loss and the meta imitation learning versus a linear loss,",
    "start": "3291915",
    "end": "3297450"
  },
  {
    "text": "there was a large improvement of over, again, like 13-14%. So the temporal loss is really important to use, uh,",
    "start": "3297450",
    "end": "3303525"
  },
  {
    "text": "to really identify the task and visual cu- cues well. [NOISE]",
    "start": "3303525",
    "end": "3312930"
  },
  {
    "text": "Yeah. Okay. So some of the strengths of the paper. So we'll go over the strengths and then we'll do a critique also on some of the limitations that we saw.",
    "start": "3312930",
    "end": "3319200"
  },
  {
    "text": "So the success is that we can do- we can learn new tasks using this one shot imitation from a visual input of just a human demonstration.",
    "start": "3319200",
    "end": "3326820"
  },
  {
    "text": "And so like we talked about, this as an extension of MAML such that you can, uh, define, there's like this learned- like with",
    "start": "3326820",
    "end": "3332819"
  },
  {
    "text": "the addition of this learned temporal adaptation objective. And so what they show is that they're able to update these parameters",
    "start": "3332820",
    "end": "3338820"
  },
  {
    "text": "for new tasks and they're able to do this with just one demonstration of a human, of a human demonstrating that new task.",
    "start": "3338820",
    "end": "3344369"
  },
  {
    "text": "And that's actually pretty impressive and we found that to be a really good strength. This idea of a learned temporal adaptation to incorporate temporal information to",
    "start": "3344370",
    "end": "3352230"
  },
  {
    "text": "understand behaviors and be able to translate those to update not only the perceptual components, but also the control components was also something we",
    "start": "3352230",
    "end": "3359310"
  },
  {
    "text": "found very interesting and a unique contribution to this paper. And one of the things that we also mentioned as a strength,",
    "start": "3359310",
    "end": "3364859"
  },
  {
    "text": "but we'll also mention later again as a limitation, is this idea that we can perform well even though we have,",
    "start": "3364860",
    "end": "3370305"
  },
  {
    "text": "uh, the amount of data per task is low. So one of the things that happens is that they have thousands of demonstrations that they use during meta training,",
    "start": "3370305",
    "end": "3376994"
  },
  {
    "text": "but the amount of data that they have per task is actually quite low. And what this shows is the fact that they can perform well",
    "start": "3376995",
    "end": "3382110"
  },
  {
    "text": "even with having less amount of data per task, is that they can actually generalize and adapt to a diverse range of tasks,",
    "start": "3382110",
    "end": "3387840"
  },
  {
    "text": "which is also something we counted as a strength. So to discuss some of the limitations, so one of the things that we saw is that they",
    "start": "3387840",
    "end": "3395040"
  },
  {
    "text": "have not demonstrated the ability to learn entirely new motions. So one of the things you'll see is that during meta-training and meta-test time,",
    "start": "3395040",
    "end": "3400710"
  },
  {
    "text": "so the behaviors that you will encounter during meta-training are structurally similar to the ones you'll account encounter during meta te- meta-test time.",
    "start": "3400710",
    "end": "3407309"
  },
  {
    "text": "And so it's not as if you're encountering completely new tasks that have- that are structurally, uh, completely different from those you'll encounter in meta-training.",
    "start": "3407310",
    "end": "3414510"
  },
  {
    "text": "And so one of the things that we, we thought would be very interesting to see is how, how I would generalize to entirely new sorts of motions.",
    "start": "3414510",
    "end": "3420599"
  },
  {
    "text": "Uh, one of the other things is that we need more data during meta-training time to enable- and we're wondering if that could maybe lead to better results.",
    "start": "3420600",
    "end": "3427200"
  },
  {
    "text": "So one of the things that we mentioned as a strength can also be seen as a limitation in the sense that getting more data per task might",
    "start": "3427200",
    "end": "3433530"
  },
  {
    "text": "also give us insight into how- maybe even how the learned adapt- adaptative loss can improve on like motions that are more complex,",
    "start": "3433530",
    "end": "3440730"
  },
  {
    "text": "and we'll talk about that as well. And then lastly, we still require robot demos. So you'll see in meta-training time,",
    "start": "3440730",
    "end": "3446160"
  },
  {
    "text": "we paired the human demonstrations with robot demonstrations, uh, in order to- in order to update these parameters and to,",
    "start": "3446160",
    "end": "3452490"
  },
  {
    "text": "and to learn from new tasks. So one of the things that we were curious about is since domain adaptation involves generalizing from different viewpoints,",
    "start": "3452490",
    "end": "3458535"
  },
  {
    "text": "different lighting conditions, and all sorts of domain shifts that might occur, can we do this simply with just human demonstrations?",
    "start": "3458535",
    "end": "3463860"
  },
  {
    "text": "Is it possible to have, for example, maybe a discriminator that can discriminate between varying lighting conditions,",
    "start": "3463860",
    "end": "3469140"
  },
  {
    "text": "uh, various domain shifts, and maybe send back like have a gradient reversal layer such that you can send back gradients that encourage an agnostic,",
    "start": "3469140",
    "end": "3476744"
  },
  {
    "text": "uh, representation of some of these things? So it's just something to think about is, uh, do we need these robot demos or can we do this even with just the human demonstrations?",
    "start": "3476744",
    "end": "3484050"
  },
  {
    "text": "Uh, so some of the discussions that we thought about, uh, when we were going through this paper was, how do we interpret this meta learned temporal adaptation objective?",
    "start": "3484050",
    "end": "3492164"
  },
  {
    "text": "So one of the things that they show is they show like obviously, this meta learn- this meta-learned temporal adaptation objective",
    "start": "3492165",
    "end": "3497550"
  },
  {
    "text": "is beneficial and it learns important- important, uh, semantic information regarding how to",
    "start": "3497550",
    "end": "3502860"
  },
  {
    "text": "update the perceptual components and the control components. But it'd be really- it would be really interesting to see if we can visualize this loss in terms of what it's actually learning.",
    "start": "3502860",
    "end": "3509880"
  },
  {
    "text": "If there's any- and one of the things that we leave open to discussion is how could we make this loss more interpretable?",
    "start": "3509880",
    "end": "3515250"
  },
  {
    "text": "And then maybe how could this loss be used in maybe other tasks that aren't robotic space? Uh, lastly, can this approach be extended to tasks with more complex actions?",
    "start": "3515250",
    "end": "3523550"
  },
  {
    "text": "So we saw pushing, we- we saw placing. These are very simple tasks, uh, obviously complex.",
    "start": "3523550",
    "end": "3529040"
  },
  {
    "text": "But like can we, can we, can we increase this, uh, this approach? Can we use this for tasks that might be more complex in nature,",
    "start": "3529040",
    "end": "3535155"
  },
  {
    "text": "such that it involve a myriad of things to happen before the task is completed. So is, is this idea of a temporal adaptation loss",
    "start": "3535155",
    "end": "3541820"
  },
  {
    "text": "sufficient to be able to generalize to actions that are very complex. So that's something we were also considering and so we'll leave that open to discussion as well.",
    "start": "3541820",
    "end": "3548885"
  },
  {
    "text": "Thank you. [APPLAUSE]",
    "start": "3548885",
    "end": "3558540"
  },
  {
    "text": "Does anyone have questions? [BACKGROUND] [inaudible] and so is a- what's the relationship between,",
    "start": "3558540",
    "end": "3564040"
  },
  {
    "text": "uh, the inner loss function and, uh, to, uh, for example, the reward function right from inward reinforcement learning?",
    "start": "3564040",
    "end": "3571590"
  },
  {
    "text": "Is there a connection between those? You mean between this and just substituting this with- With, uh, uh, so is,",
    "start": "3571590",
    "end": "3578750"
  },
  {
    "text": "is L5 somet- something similar to, uh, a reward function, uh, learned from reinforcement learning?",
    "start": "3578750",
    "end": "3585180"
  },
  {
    "text": "So I think what, what this learned adaptation objective is trying to do is this idea of like looking at a human demonstration,",
    "start": "3585180",
    "end": "3591390"
  },
  {
    "text": "looking at like the- like the actions that are occurring across multiple frames and trying to understand not only perceptually,",
    "start": "3591390",
    "end": "3597420"
  },
  {
    "text": "like which objects in the scene are important for a particular task, so this would be like identifying the objects in the scene, but then also thinking about how to like, uh,",
    "start": "3597420",
    "end": "3604190"
  },
  {
    "text": "update the control layers of the network to predict actions that can maneuver those for the new task. So I think this learned adaptation objective is,",
    "start": "3604190",
    "end": "3610160"
  },
  {
    "text": "is trying to look at that temporally and then update these different components of the layers. I can, I can see where like you could",
    "start": "3610160",
    "end": "3615845"
  },
  {
    "text": "update this with like some sort of reward function as well. But I think at least since we don't have human actions or any sort of, uh,",
    "start": "3615845",
    "end": "3621300"
  },
  {
    "text": "any other type of supervision, this is something that's learned through some of the gradients that get passed through this outer objective as well.",
    "start": "3621300",
    "end": "3627555"
  },
  {
    "text": "So update data, so. And you can't discretize like the human actions so that's why the loss to be learned. That's the main difference a standard represent- I mean, for reinforcement learning.",
    "start": "3627555",
    "end": "3635820"
  },
  {
    "text": "Yeah. So this is like implicitly learned as well. So this loss is learned during your meta-training. So since you're updating these layers across",
    "start": "3635820",
    "end": "3641579"
  },
  {
    "text": "time and then when you do this behavioral cloning loss, it also updates psi as the parameters of psi as well. So this loss is being learned over time as a way to improve,",
    "start": "3641580",
    "end": "3649875"
  },
  {
    "text": "uh, improve this generalization to new tasks.",
    "start": "3649875",
    "end": "3653320"
  },
  {
    "text": "All right. Um, okay. My name's Josh Melander, [NOISE] Uh,",
    "start": "3663850",
    "end": "3669410"
  },
  {
    "text": "I'm a third year neuroscience PhD student, um, [NOISE] and yeah. I'm going to be presenting on this paper, uh,",
    "start": "3669410",
    "end": "3675934"
  },
  {
    "text": "from Richard Zemel's lab. Uh, it's called Meta-learning for Semi-supervi- uh,",
    "start": "3675935",
    "end": "3681140"
  },
  {
    "text": "Supervised few shot classification. And, sorry, remind me how long do I have? Like [OVERLAPPING] Fifteen minutes.",
    "start": "3681140",
    "end": "3687829"
  },
  {
    "text": "Fifteen minutes? Okay. [NOISE] Um, okay, all right. So we all know that, uh, recent years have sort of ushered in this great success,",
    "start": "3687830",
    "end": "3696514"
  },
  {
    "text": "um, of supervised class- classification problems. Um, this is, you know, sort of uh,",
    "start": "3696514",
    "end": "3703400"
  },
  {
    "text": "engendered by this ImageNet data set, uh, which is this massive labeled data set.",
    "start": "3703400",
    "end": "3708785"
  },
  {
    "text": "Um, but, uh, you know, we know that in the real world and, you know, the way that humans get data, it's,",
    "start": "3708785",
    "end": "3715895"
  },
  {
    "text": "it's, it's not this bolus of labeled data, right? We have, um, maybe a few examples of, uh, labeled data,",
    "start": "3715895",
    "end": "3723515"
  },
  {
    "text": "maybe your mom tells you like that's a tree or something, and then [NOISE] you have a bunch of unlabeled examples.",
    "start": "3723515",
    "end": "3728720"
  },
  {
    "text": "So you see a bunch of trees when you're walking through the forest. Um, [NOISE] and so this is, this is sort of the,",
    "start": "3728720",
    "end": "3733930"
  },
  {
    "text": "the problem of semi-supervised learning. Um, [NOISE] and uh, I guess,",
    "start": "3733930",
    "end": "3739435"
  },
  {
    "text": "you know as, as someone who's studying neuroscience, I- I think it's a little bit more interesting than pure supervised learning because, you know this is what,",
    "start": "3739435",
    "end": "3747040"
  },
  {
    "text": "what biological systems are sort of uh, optimized to, to perform, [NOISE] right?",
    "start": "3747040",
    "end": "3753200"
  },
  {
    "text": "So, um, [NOISE] this paper, basically applies this new domain of semi-supervised learning to, you know,",
    "start": "3753200",
    "end": "3760595"
  },
  {
    "text": "this familiar problem [NOISE] of, of uh, multitask learning that we've been talking about and uh, right.",
    "start": "3760595",
    "end": "3766880"
  },
  {
    "text": "So to start off with the familiar problem that we all implemented, uh, solution to in our homework, um,",
    "start": "3766880",
    "end": "3773450"
  },
  {
    "text": "you're presented with uh, support sets. Uh, here we have a goldfish and a shark,",
    "start": "3773450",
    "end": "3778520"
  },
  {
    "text": "and then we get a new image and we have to basically say, which one is it?, right? And the whole point is that, uh, you know,",
    "start": "3778520",
    "end": "3786380"
  },
  {
    "text": "we need to come up with a solution that generalizes the unseen classes. Um, [NOISE] now the,",
    "start": "3786380",
    "end": "3792305"
  },
  {
    "text": "the new twist on this problem is in the support set, what if we're also given a bunch of unlabeled data, right?",
    "start": "3792305",
    "end": "3799940"
  },
  {
    "text": "So in addition to uh, the labeled shark and goldfish, we have a bunch of images of uh,",
    "start": "3799940",
    "end": "3807470"
  },
  {
    "text": "a bunch of other animals um, and that, that could include or not include images of sharks and goldfish, right?",
    "start": "3807470",
    "end": "3815089"
  },
  {
    "text": "But the, the question is, can we leverage uh, er, can we leverage this sort of um,",
    "start": "3815090",
    "end": "3822589"
  },
  {
    "text": "[NOISE] massive amount of unlabeled data uh, in order to improve our,",
    "start": "3822590",
    "end": "3827780"
  },
  {
    "text": "our, uh, um, multi-task learning, right? So um, I- yeah,",
    "start": "3827780",
    "end": "3833630"
  },
  {
    "text": "I guess just to underscore this, we would hope that because we're seeing more examples of images that we,",
    "start": "3833630",
    "end": "3840365"
  },
  {
    "text": "that we would be able to uh, learn something from that. [NOISE] Okay.",
    "start": "3840365",
    "end": "3846080"
  },
  {
    "text": "So what does this actually look like in terms of the, the task? Um, so at the top here we have",
    "start": "3846080",
    "end": "3853100"
  },
  {
    "text": "our support set which everyone's familiar with and on the right is the query set.",
    "start": "3853100",
    "end": "3858380"
  },
  {
    "text": "Uh, so three image- three classes and we, we see new examples of those three classes. Um, but in addition,",
    "start": "3858380",
    "end": "3865070"
  },
  {
    "text": "we're also gonna present to our model uh, this unlabeled data set. And here the, the green plusses represents uh,",
    "start": "3865070",
    "end": "3873230"
  },
  {
    "text": "unlabeled data that uh, that come from classes that are also part of the support test.",
    "start": "3873230",
    "end": "3879740"
  },
  {
    "text": "Um, so right, so we have like a little finch and this, this white dog and a piano.",
    "start": "3879740",
    "end": "3886685"
  },
  {
    "text": "But then you can see there's also these uh, these distractor classes which are labeled here with a red minus sign, all right?",
    "start": "3886685",
    "end": "3895309"
  },
  {
    "text": "[NOISE] Um, yeah. And so, so we have training and testing and,",
    "start": "3895310",
    "end": "3900680"
  },
  {
    "text": "and those classes are disparate. Um, [NOISE] and we- you know, one thing that these authors wanted to get out is, you know,",
    "start": "3900680",
    "end": "3906710"
  },
  {
    "text": "not only can we leverage this unlabeled data but the presence of distractors,",
    "start": "3906710",
    "end": "3912109"
  },
  {
    "text": "[NOISE] presents kind of a particular challenge for these networks and they're gonna try to present the way to overcome that challenge.",
    "start": "3912110",
    "end": "3919280"
  },
  {
    "text": "[NOISE] Um, yeah. [NOISE] Okay. So uh, this is just the setup of the problem, right?",
    "start": "3919280",
    "end": "3927260"
  },
  {
    "text": "And you can imagine that there are a lot of ways that you could go about trying to tackle it. Um, we've seen a lot of,",
    "start": "3927260",
    "end": "3933035"
  },
  {
    "text": "a lot of uh, multitask learning and meta-learning solutions. [NOISE] And um, I think any of these,",
    "start": "3933035",
    "end": "3940400"
  },
  {
    "text": "Siamese networks, matching networks, prototypical networks, um, any of these would be fine starting points.",
    "start": "3940400",
    "end": "3947465"
  },
  {
    "text": "Um, they- the authors of this paper sort of choose to uh, start from prototypical networks,",
    "start": "3947465",
    "end": "3954109"
  },
  {
    "text": "which I think were presented on last week, and uh, extend those models to a regime that would work for semi supervised [NOISE] learning.",
    "start": "3954110",
    "end": "3963785"
  },
  {
    "text": "Um, okay. So just a, a quick overview of the prototypical networks, um, right.",
    "start": "3963785",
    "end": "3971690"
  },
  {
    "text": "So the- these are, you know, very relatively simple models um, where,",
    "start": "3971690",
    "end": "3978710"
  },
  {
    "text": "you know, each class basically gets embedded into some space.",
    "start": "3978710",
    "end": "3984085"
  },
  {
    "text": "And then new examples are then uh, basically matched via some distance metric",
    "start": "3984085",
    "end": "3991125"
  },
  {
    "text": "to the embedding of previously seen classes, right? So in this case,",
    "start": "3991125",
    "end": "3996665"
  },
  {
    "text": "you know, you have um, a number- let's say we have five classes here in, in purple and we're gonna use the seen classes to generate an embedding",
    "start": "3996665",
    "end": "4006144"
  },
  {
    "text": "and then new examples can be embedded with that same embedding and uh,",
    "start": "4006144",
    "end": "4011740"
  },
  {
    "text": "sort of classified based on its distance to this prototype. So this, this vector here in this prototype vector is sort of generated from,",
    "start": "4011740",
    "end": "4021505"
  },
  {
    "text": "from labeled data in this sort of vanilla protoNets, right? And uh, in the original protoNet paper and in this paper,",
    "start": "4021505",
    "end": "4029484"
  },
  {
    "text": "um, the embedding is actually performed with a pretty simple uh, convolution neural network, um,",
    "start": "4029485",
    "end": "4036220"
  },
  {
    "text": "with three by three filters, Batchnorm, ReLU, Maxpool and it results in a 64D vector.",
    "start": "4036220",
    "end": "4042370"
  },
  {
    "text": "So that's the sort of embedding space, [NOISE] right. Okay. So you pass in a couple of images with known labels,",
    "start": "4042370",
    "end": "4048100"
  },
  {
    "text": "you compute uh, you compute your prototype. [NOISE] Um, and then in the vanilla sort of prototypical network uh, examples, you um,",
    "start": "4048100",
    "end": "4058315"
  },
  {
    "text": "pass in your, your sort of uh, your query set and just softmax over the distributions to the prototypes.",
    "start": "4058315",
    "end": "4066039"
  },
  {
    "text": "And then you can back-propagate the loss through that embedding network and that's really the only thing that's trained,",
    "start": "4066040",
    "end": "4072715"
  },
  {
    "text": "um, is that embedding. [NOISE] Um, right. And so they, they make a lot of points in this in the papers that it's,",
    "start": "4072715",
    "end": "4079885"
  },
  {
    "text": "it's a nice model because it has very, very little assumptions and very simple inductive bias.",
    "start": "4079885",
    "end": "4085930"
  },
  {
    "text": "And it's so simple that actually in the case of Euclidean distance which they use in this paper,",
    "start": "4085930",
    "end": "4091150"
  },
  {
    "text": "it, it, it reduces down to a linear model. [NOISE] So very simple. Okay. So now how do we extend this to the case of",
    "start": "4091150",
    "end": "4098365"
  },
  {
    "text": "unlabeled data and semi-supervised learning? Um, so what they're gonna do is here,",
    "start": "4098365",
    "end": "4104364"
  },
  {
    "text": "here you have uh, an example of the same kind of embedding plot as before. Um, the, the dotted examples are unlabeled data,",
    "start": "4104365",
    "end": "4113785"
  },
  {
    "text": "and the white examples are your testing data. So basically what they plan to do and what they will do in this paper is uh,",
    "start": "4113785",
    "end": "4122980"
  },
  {
    "text": "start out with the vanilla protoNet, embed um, embed the, uh, embed the labeled data in and get the sort of labeled prototypes.",
    "start": "4122980",
    "end": "4135009"
  },
  {
    "text": "And then using the unlabeled data, they're gonna refine those original prototypes to sort",
    "start": "4135010",
    "end": "4140799"
  },
  {
    "text": "of create new uh, classification boundaries. And of course, this um,",
    "start": "4140800",
    "end": "4148690"
  },
  {
    "text": "[NOISE] this will be uh, sort of more and less effective in the cases where you have distractors and so we'll talk a little bit about how they deal with that.",
    "start": "4148690",
    "end": "4155529"
  },
  {
    "text": "Um, okay. So, so you start with the labeled data that you're passing in and you're gonna generate the labeled prototypes,",
    "start": "4155530",
    "end": "4165174"
  },
  {
    "text": "um, but via the embedding which is just the mean of, of, of your embedding for all of,",
    "start": "4165175",
    "end": "4170755"
  },
  {
    "text": "all of your examples. Um, and then for each of the unlabeled inputs, you're going to give them a partial assignment to each cluster um,",
    "start": "4170755",
    "end": "4179725"
  },
  {
    "text": "using some distance metric and then incorporate those unlabeled data into the original prototype.",
    "start": "4179725",
    "end": "4186160"
  },
  {
    "text": "And now you have a new prototype that has incorporated the unlabeled data. [NOISE] Um, and this is very simple [NOISE] and done using- uh,",
    "start": "4186160",
    "end": "4195010"
  },
  {
    "text": "sort of soft K-means, which is differentiable uh, K-means, right? So um, basically if we have",
    "start": "4195010",
    "end": "4202060"
  },
  {
    "text": "this unlabeled support set that we're also passing in with the labeled uh, uh,",
    "start": "4202060",
    "end": "4207175"
  },
  {
    "text": "the labeled support set, then what we can do is sort of assign each of these unlabeled data sets- uh,",
    "start": "4207175",
    "end": "4215440"
  },
  {
    "text": "each of these unlabeled data points to one of the classes. This is just sort of a Softmax on the,",
    "start": "4215440",
    "end": "4221640"
  },
  {
    "text": "on the distance, um, of the unlabeled data to each of the original prototypes and then incorporate that into our new prototype.",
    "start": "4221640",
    "end": "4229135"
  },
  {
    "text": "So this is- it's just the prototypical networks but their performing K-means on the unlabeled data and uh,",
    "start": "4229135",
    "end": "4238120"
  },
  {
    "text": "uh, using that to update their new prototypes. [NOISE] Right? So um, yeah.",
    "start": "4238120",
    "end": "4243400"
  },
  {
    "text": "As I mentioned, this sort of breaks when you think through the logic when you incorporate a distractor class,",
    "start": "4243400",
    "end": "4250105"
  },
  {
    "text": "and uh, that's because you don't wanna be incorporating distractor classes into your [NOISE] updated prototypes.",
    "start": "4250105",
    "end": "4256855"
  },
  {
    "text": "So they offer two solutions for this. The first is to just add another prototype at the origin, uh,",
    "start": "4256855",
    "end": "4264145"
  },
  {
    "text": "so 000 up to 64, [NOISE] and this is just kind of like a buffer to capture all the distractions.",
    "start": "4264145",
    "end": "4271284"
  },
  {
    "text": "Um, but [NOISE] this sort of relies on this uh, assumption that all of these distractors are coming from one class.",
    "start": "4271285",
    "end": "4276324"
  },
  {
    "text": "Which [NOISE] we know is not gonna be the case, right? Um, you see lots of different classes that are confounding your inferences,",
    "start": "4276325",
    "end": "4283719"
  },
  {
    "text": "not just, just one, [NOISE] right? So uh, to, to deal with this,",
    "start": "4283720",
    "end": "4289060"
  },
  {
    "text": "they come up with er, also pretty simple strategy where they,",
    "start": "4289060",
    "end": "4294745"
  },
  {
    "text": "they do their soft means uh, prototype update on the unlabeled data and then they also have a small uh, 20 neuron uh,",
    "start": "4294745",
    "end": "4304510"
  },
  {
    "text": "20 neuron wide uh, single layer [NOISE] neural network that basically takes in the distance- s- some,",
    "start": "4304510",
    "end": "4313525"
  },
  {
    "text": "some sort of computed distance statistics. So the min-max variance scheme part of each image to each class.",
    "start": "4313525",
    "end": "4322755"
  },
  {
    "text": "And it's gonna take these in and basically give a threshold to each prototype.",
    "start": "4322755",
    "end": "4328824"
  },
  {
    "text": "So um, yeah. So, so now they have a differentiable way to,",
    "start": "4328825",
    "end": "4334000"
  },
  {
    "text": "to sort of uh, set um, boundaries on how aggressively the prototypes should be taking in the unlabeled data.",
    "start": "4334000",
    "end": "4343420"
  },
  {
    "text": "[NOISE] Uh, right and it's differentiable. So they can just train this end to end. [NOISE] Um,-",
    "start": "4343420",
    "end": "4348470"
  },
  {
    "text": "And I- I'll come back to this in a bit, uh, but it- it turns out to be quite useful.",
    "start": "4348960",
    "end": "4356185"
  },
  {
    "text": "Um, okay, so- so tha- that's the general strategy. They have this- this original Protonet with K-means and, uh,",
    "start": "4356185",
    "end": "4364270"
  },
  {
    "text": "in order to deal with the distractor classes, they have a little neural network that will basically tell you how aggressively to incorporate the unlabeled data.",
    "start": "4364270",
    "end": "4372985"
  },
  {
    "text": "Um, now they- they test these results on the Omniglot dataset as well as the miniImageNet dataset.",
    "start": "4372985",
    "end": "4379495"
  },
  {
    "text": "Uh, however, they also generate this new, uh, split of ImageNet, which they call tieredImageNet and,",
    "start": "4379495",
    "end": "4386380"
  },
  {
    "text": "uh, they- they seem to make a big deal about it in the paper. But the idea is that it's sort of more organized based on",
    "start": "4386380",
    "end": "4393880"
  },
  {
    "text": "higher nodes in the sort of semantic classification of the network. So whereas in miniImageNet you have",
    "start": "4393880",
    "end": "4400360"
  },
  {
    "text": "electric guitars in testing and acoustic guitars in training, in the tieredImageNet, uh,",
    "start": "4400360",
    "end": "4405400"
  },
  {
    "text": "it's sort of more uh, diverse. So- so your testing has musical instruments,",
    "start": "4405400",
    "end": "4410740"
  },
  {
    "text": "and your training has farming equipment. So you're actually seeing completely unseen, uh, [NOISE] classes of images.",
    "start": "4410740",
    "end": "4418255"
  },
  {
    "text": "Um, and basically across the board, they're gonna take 10% of- of their, uh,",
    "start": "4418255",
    "end": "4424329"
  },
  {
    "text": "training split for labeled data and 90% goes to unlabeled classes. And so it's important [NOISE] to point out that",
    "start": "4424330",
    "end": "4430540"
  },
  {
    "text": "because they're only labeling 10% of the data, they're actually getting uh, they're actually using much,",
    "start": "4430540",
    "end": "4435804"
  },
  {
    "text": "much less labels than sort of all of the previous work that we've been talking about. [NOISE] Um, and all the results that I'm gonna show you, uh,",
    "start": "4435805",
    "end": "4444070"
  },
  {
    "text": "they are using- it's basically a five way classification, and they are including five,",
    "start": "4444070",
    "end": "4452335"
  },
  {
    "text": "uh, five unlabeled, uh, examples as well. Um, and in the case of distraction,",
    "start": "4452335",
    "end": "4459804"
  },
  {
    "text": "they're gonna be including five, uh, unlabeled images, uh, from distractor classes as well.",
    "start": "4459805",
    "end": "4465850"
  },
  {
    "text": "[NOISE] Okay. So, uh, a couple of baselines before I show you the results.",
    "start": "4465850",
    "end": "4471880"
  },
  {
    "text": "So first, they just have the Vanilla Protonet. So ignore the- the unlabeled classes and just- just,",
    "start": "4471880",
    "end": "4477565"
  },
  {
    "text": "uh, do the Protonet thing. And then the second is a sort of semi-supervised inference.",
    "start": "4477565",
    "end": "4485800"
  },
  {
    "text": "So this is the Vanilla Protonet, the embedding generated from the Vanilla Protonet. But now they're actually doing the K-means during training.",
    "start": "4485800",
    "end": "4493525"
  },
  {
    "text": "Uh, so this is a way to test how much the embedding is- is changing with the unlabeled data.",
    "start": "4493525",
    "end": "4501250"
  },
  {
    "text": "And they find that, uh, they- they're able to get sort of uns- unsurpassed accuracy with, um,",
    "start": "4501250",
    "end": "4510585"
  },
  {
    "text": "their, uh, K-means clustering on the Protonet as well as the, sort of, this masked neural network, uh,",
    "start": "4510585",
    "end": "4518364"
  },
  {
    "text": "version of- of the K-means Protonets. And on the- on the left is just with unlabeled data from the same classes.",
    "start": "4518365",
    "end": "4526239"
  },
  {
    "text": "On the right, you have unlabeled data, um, with distractors. And what they find is that, across the board,",
    "start": "4526240",
    "end": "4532735"
  },
  {
    "text": "the- the sort of masked K-means Protonets do the best, um,",
    "start": "4532735",
    "end": "4538284"
  },
  {
    "text": "and especially they do the best across all three datasets in the distractor cases.",
    "start": "4538285",
    "end": "4544030"
  },
  {
    "text": "So, um, yeah. [NOISE] There's a few other baselines they look at, uh,",
    "start": "4544030",
    "end": "4549865"
  },
  {
    "text": "just like a linear regression and sort of a, uh, a one-way K-means with just the pixels and- but- I- I'm running out of time.",
    "start": "4549865",
    "end": "4558250"
  },
  {
    "text": "So I guess the last sort of novel thing that they found is that, um, you know, if you- if during the training if you now- so- so you've trained this network,",
    "start": "4558250",
    "end": "4569139"
  },
  {
    "text": "um, to embed, and now during testing, you're going to increase the amount of unlabeled data.",
    "start": "4569139",
    "end": "4575860"
  },
  {
    "text": "And what they find is that, as you start increasing- so you've frozen the network, you're no longer doing gradient updates.",
    "start": "4575860",
    "end": "4582820"
  },
  {
    "text": "But as you start increasing the amount of unlabeled data, um, the model starts to sort of out-perform the classic Protonet example.",
    "start": "4582820",
    "end": "4590500"
  },
  {
    "text": "So what- what they're claiming here is that these models learn to generalize from unlabeled data.",
    "start": "4590500",
    "end": "4596065"
  },
  {
    "text": "Um, in other words, uh, you- basically, you would imagine that their performance would, uh,",
    "start": "4596065",
    "end": "4602005"
  },
  {
    "text": "increase, uh, as you took the number of unlabeled examples and distractors out to infinity.",
    "start": "4602005",
    "end": "4608664"
  },
  {
    "text": "Um, and that's what they show here. And then they also sort of make a point about the fact that they have this- this-",
    "start": "4608665",
    "end": "4614485"
  },
  {
    "text": "you can really start to separate the models in the distractor case with the generalization. Okay. So right.",
    "start": "4614485",
    "end": "4621614"
  },
  {
    "text": "They achieve state-of-the-art performance over a couple logically proposed baselines on the three datasets.",
    "start": "4621615",
    "end": "4628490"
  },
  {
    "text": "Um, this K-means masked model performs best with the distractors, uh, and, uh,",
    "start": "4628490",
    "end": "4635530"
  },
  {
    "text": "they also show that their models are able to extrapolate to sort of make- make more efficient use of new unlabeled data.",
    "start": "4635530",
    "end": "4643310"
  },
  {
    "text": "Um, and not that interesting, but they- they also propose this sort of new benchmark dataset of this tieredImageNet.",
    "start": "4643310",
    "end": "4651550"
  },
  {
    "text": "[NOISE] Um, a- a few critiques. Uh, I- I didn't have a lot of,",
    "start": "4651550",
    "end": "4657120"
  },
  {
    "text": "uh, sort of nitpicky critiques. I- I think it was a relatively straightforward application",
    "start": "4657120",
    "end": "4662670"
  },
  {
    "text": "of this previous work from Protonets and, uh, you know, the beloved K-means clustering.",
    "start": "4662670",
    "end": "4668740"
  },
  {
    "text": "Um, so they, it- it makes sense to use them and- and it worked, um.",
    "start": "4668740",
    "end": "4674545"
  },
  {
    "text": "I- I think, you know, they- they chose this Protonet model and, uh, they claim that the reason they wanted to do this was because it",
    "start": "4674545",
    "end": "4681670"
  },
  {
    "text": "had very simple inductive bias, um, but it's not really clear exactly what they gained from that because they didn't actually",
    "start": "4681670",
    "end": "4688090"
  },
  {
    "text": "do any- anything that required having a very interpretable model. Um, and also I- I, you know,",
    "start": "4688090",
    "end": "4694764"
  },
  {
    "text": "compared to some of the other methods that everyone's presented, I- I think this- this particular approach doesn't really generalize",
    "start": "4694765",
    "end": "4701410"
  },
  {
    "text": "very well beyond classification [NOISE] problems, um, yeah. So, uh, I guess future directions,",
    "start": "4701410",
    "end": "4708819"
  },
  {
    "text": "I would be pretty interested to take this case to the next extreme which is now you don't have any, um, labeled data.",
    "start": "4708819",
    "end": "4717310"
  },
  {
    "text": "And [NOISE] , uh, so you're- you're just presented with images without labels. And you have to sort of figure out which images- w- what- which new, uh,",
    "start": "4717310",
    "end": "4725800"
  },
  {
    "text": "query images correspond to which unlabeled, uh, support images and, uh, right.",
    "start": "4725800",
    "end": "4731770"
  },
  {
    "text": "And so then, the model would need to not only learn how many classes there were, but also, um, to correctly classify them.",
    "start": "4731770",
    "end": "4738970"
  },
  {
    "text": "And I- I think that there's some pretty straightforward applications of some- some work done here in the Bay Area,",
    "start": "4738970",
    "end": "4745990"
  },
  {
    "text": "uh, sort of looking at unsupervised representations between images.",
    "start": "4745990",
    "end": "4751900"
  },
  {
    "text": "Um, so yeah, ah, it'd be cool to apply that here. Um, yeah. That's it.",
    "start": "4751900",
    "end": "4757330"
  },
  {
    "text": "[NOISE] Pretty simple paper. [APPLAUSE] [NOISE]",
    "start": "4757330",
    "end": "4763750"
  },
  {
    "text": "Questions? No? Okay. [inaudible]. Yeah. Ca- can you just to expand, uh,",
    "start": "4763750",
    "end": "4769960"
  },
  {
    "text": "on the last thing you talked about like the future directions. Yeah. So, uh, I- in- so this- Stella Yu,",
    "start": "4769960",
    "end": "4778240"
  },
  {
    "text": "uh, this- this paper is- is pretty cool and, uh, you should check it out if you're not familiar.",
    "start": "4778240",
    "end": "4784210"
  },
  {
    "text": "But they basically, uh, the idea is like you can pass in ImageNet with- without labels.",
    "start": "4784210",
    "end": "4790540"
  },
  {
    "text": "And they have this sort of embedding strategy where you can embed each image into this 128D Unit Sphere.",
    "start": "4790540",
    "end": "4798355"
  },
  {
    "text": "And basically from that, without labels, um, learn the- learn how many classes there are based on",
    "start": "4798355",
    "end": "4806470"
  },
  {
    "text": "the sort of di- differences between images and between classes, right? So, um, it's- it's like a way of creating",
    "start": "4806470",
    "end": "4816430"
  },
  {
    "text": "an embedding space that separates out different classes based on the sort of variability between,",
    "start": "4816430",
    "end": "4822730"
  },
  {
    "text": "um, between examples of the same class, um, in a way that's completely unsupervised.",
    "start": "4822730",
    "end": "4828820"
  },
  {
    "text": "So no labels, and, um, [NOISE] yeah. And- And they come up with some- w- what I don't understand there is,",
    "start": "4828820",
    "end": "4836695"
  },
  {
    "text": "let's say, I've 10 classes [inaudible]. Yeah. Like I- I could easily just for each class,",
    "start": "4836695",
    "end": "4842230"
  },
  {
    "text": "come up with the five subclass that- I- I don't understand how. How can you learn anything general without having any classes?",
    "start": "4842230",
    "end": "4851620"
  },
  {
    "text": "Um. [inaudible] separate things but- Yeah. Yeah, did you understand my question, there?",
    "start": "4851620",
    "end": "4857200"
  },
  {
    "text": "Um, how can you learn anything without having- [inaudible] ImageNet now. Le- let's say you have a dataset, there are 10 classes.",
    "start": "4857200",
    "end": "4863949"
  },
  {
    "text": "Yeah. The model managed to pick out those 10 classes unsupervised. Yeah. But I could go in now and say, ''No,",
    "start": "4863950",
    "end": "4868989"
  },
  {
    "text": "actually this dataset has 10- 20 classes.'' Like, number of classes that you sort of as a human,",
    "start": "4868990",
    "end": "4875900"
  },
  {
    "text": "um, in a way like we- we decide how many classes are there.",
    "start": "4875900",
    "end": "4881025"
  },
  {
    "text": "Yes. [inaudible] something objective really about- Yeah. -how many classes are in here. Yeah. No, I- I think that's a- I think that's a- a good point.",
    "start": "4881025",
    "end": "4889030"
  },
  {
    "text": "Other than the fact that there is something objective, uh, you know. Yeah. There- there is something objective in that these",
    "start": "4889030",
    "end": "4896410"
  },
  {
    "text": "are examples of specific classes of things. And, like, each class has its own set",
    "start": "4896410",
    "end": "4903055"
  },
  {
    "text": "of- like its own distribution of relationships within a class.",
    "start": "4903055",
    "end": "4908895"
  },
  {
    "text": "So I agree with that. I'm just thinking about then a class you could say, ''Oh, within this class you have 10 classes of cats.''",
    "start": "4908895",
    "end": "4915900"
  },
  {
    "text": "Yeah. [inaudible]. [NOISE] Yeah. It's a- yeah,",
    "start": "4915900",
    "end": "4921070"
  },
  {
    "text": "I think that's- that's- that's sort of more of a critique on- on this work- Yeah- yeah- yeah. that [OVERLAPPING].",
    "start": "4921070",
    "end": "4926410"
  },
  {
    "text": "But- but, yeah, it's a- it's a good point. Yeah. Thank you. Yeah, thanks.",
    "start": "4926410",
    "end": "4931760"
  }
]
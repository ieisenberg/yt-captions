[
  {
    "start": "0",
    "end": "22000"
  },
  {
    "text": "All right. Let's get started. Long time no see. I'm excited to be back and tell you guys about Bayesian networks.",
    "start": "5120",
    "end": "14355"
  },
  {
    "text": "Um, so before we dive in, I wanted to do a few announcements first. Um, there's four things that should be on your radar.",
    "start": "14355",
    "end": "20820"
  },
  {
    "text": "So the scheduling homework is due tomorrow. Hopefully, you guys are well aware of that. Um, the car assignment is, uh,",
    "start": "20820",
    "end": "27570"
  },
  {
    "start": "22000",
    "end": "131000"
  },
  {
    "text": "released today, and it'll be due next Tuesday. So there's some, um, conceptual challenges here, especially if you're not to- up to speed on your probability.",
    "start": "27570",
    "end": "36750"
  },
  {
    "text": "Uh, the section, uh, Thursday will, uh, really help you go over that. So please come to that.",
    "start": "36750",
    "end": "41810"
  },
  {
    "text": "Um, then there is a final project, ah, you guys have- hopefully, have all received your feedback, uh,",
    "start": "41810",
    "end": "47615"
  },
  {
    "text": "for your proposal and are actively making changes. So just to make sure that you guys are making progress,",
    "start": "47615",
    "end": "53390"
  },
  {
    "text": "there's a progress report that is due, um, next Tuesday. And for this one, the,",
    "start": "53390",
    "end": "59345"
  },
  {
    "text": "the guidelines are all on the, the website but just to kind of reemphasize, um, especially if you didn't, uh,",
    "start": "59345",
    "end": "65125"
  },
  {
    "text": "manage to get a baseline or Oracle, we- we really expect that you to have that now. And also, we expect you to have some sort of preliminary results with, you know,",
    "start": "65125",
    "end": "73240"
  },
  {
    "text": "some sort of implementation of your actual, um, [NOISE] procedure or algorithm or model. And definitely some description of what that is,",
    "start": "73240",
    "end": "80420"
  },
  {
    "text": "and be as concrete as possible, um, as you can. Um, and finally, the exam is in about, uh, two weeks.",
    "start": "80420",
    "end": "87590"
  },
  {
    "text": "Um, I would start, uh, looking at that. Um, and the- actually the best way I think to prepare for",
    "start": "87590",
    "end": "93620"
  },
  {
    "text": "the exam is to look at the old exam problems because there is a certain style, um, that you have to kind of get used to when taking the exam.",
    "start": "93620",
    "end": "101165"
  },
  {
    "text": "So I know this is a busy time, there's a lot of things going on. But hopefully, um, you guys will manage. Yeah?",
    "start": "101165",
    "end": "107100"
  },
  {
    "text": "Progress is due Tuesday or Thursday? It's Tuesday, I believe. But I could be wrong.",
    "start": "107100",
    "end": "112560"
  },
  {
    "text": "[inaudible] Uh, Tuesday but [inaudible] Yeah. Let's say it's Tuesday.",
    "start": "112560",
    "end": "117750"
  },
  {
    "text": "Whatever the website says. It's whatever the website says. Oh, that says Thursday?",
    "start": "117750",
    "end": "123090"
  },
  {
    "text": "Okay. Well, then we'll defer to the website on that. Okay. Um, okay so the next,",
    "start": "123090",
    "end": "129240"
  },
  {
    "text": "uh, agenda item is the Pac-Man competition. So many of you, uh, worked hard to submit,",
    "start": "129240",
    "end": "134870"
  },
  {
    "start": "131000",
    "end": "294000"
  },
  {
    "text": "um, various entries into this competition. In the end, only three could,",
    "start": "134870",
    "end": "141135"
  },
  {
    "text": "uh, make it to, uh, the top three. So, um, here are the winners of the Pac-Man",
    "start": "141135",
    "end": "147750"
  },
  {
    "text": "competition- because out of town but if- in the audience,",
    "start": "147750",
    "end": "156674"
  },
  {
    "text": "uh, maybe you guys could come down. Let's give them a round of applause.",
    "start": "156674",
    "end": "162480"
  },
  {
    "text": "[APPLAUSE] And we have these, uh, um,",
    "start": "162480",
    "end": "168194"
  },
  {
    "text": "prizes [NOISE] which are Pac-Man themed, uh, Cups [LAUGHTER], um, filled with candy in case you didn't get enough for Halloween.",
    "start": "168195",
    "end": "176435"
  },
  {
    "text": "So there you go. [NOISE] Congratulations. Thank you. Do you guys want to say a little bit about what was your secret sauce?",
    "start": "176435",
    "end": "184070"
  },
  {
    "text": "Sure, called Pacman and um, actually, the  fourth one is the stupidest of all.",
    "start": "184070",
    "end": "194460"
  },
  {
    "text": "And the third one is like, um, super messy. [NOISE] I had like all of these [inaudible] extracted from like the food, the capsule,",
    "start": "194460",
    "end": "204179"
  },
  {
    "text": "the hunting ghost, and the scaredy ghost [inaudible] and all that stuff. But it actually turned out to be not as useful as a very simple [NOISE] method",
    "start": "204179",
    "end": "214935"
  },
  {
    "text": "that- which is similar to how everybody plays Pac-Man if there's a hunting- uh if there's a scared ghost, then go chase it.",
    "start": "214935",
    "end": "221780"
  },
  {
    "text": "[NOISE] If there isn't then go for the capsule [NOISE] or else look for the food and dodge the hunt- uh, the hunting ghost.",
    "start": "221780",
    "end": "228395"
  },
  {
    "text": "And, um, also, um, I changed the- I think the distance to, um,",
    "start": "228395",
    "end": "234390"
  },
  {
    "text": "[inaudible] algorithm because the Manhattan distance is different from,",
    "start": "234390",
    "end": "240815"
  },
  {
    "text": "um, the [inaudible] [NOISE] algorithm.",
    "start": "240815",
    "end": "249495"
  },
  {
    "text": "So lesson is, keep it simple. Okay. [inaudible]. I recently experienced. There was a lot of variations that I went through.",
    "start": "249495",
    "end": "255239"
  },
  {
    "text": "And I know mine was best due to ending up being a very simple model [inaudible] the policy, you want to keep the ghost",
    "start": "255240",
    "end": "261785"
  },
  {
    "text": "Every once in awhile, the scared ghost is in play. And after, uh, eating all the capsules get included",
    "start": "261785",
    "end": "267500"
  },
  {
    "text": "as good as possible for you to get [inaudible] for tracking down at the speed of DFS search, which I use dynamic programming so that",
    "start": "267500",
    "end": "273470"
  },
  {
    "text": "everybody [inaudible] transitions and always catch that and have that robot- Great.",
    "start": "273470",
    "end": "278900"
  },
  {
    "text": "- [inaudible]. Yeah. Okay. Well, great. Well, congrats again. [inaudible] [LAUGHTER] [APPLAUSE] Okay. All right.",
    "start": "278900",
    "end": "288110"
  },
  {
    "text": "So keep it simple I guess is, uh, is a good, uh, lesson. Okay So back to our regular programming.",
    "start": "288110",
    "end": "293510"
  },
  {
    "text": "Um, last week, we started talking about factor graphs. Just a quick review of what factor graphs are.",
    "start": "293510",
    "end": "299155"
  },
  {
    "start": "294000",
    "end": "366000"
  },
  {
    "text": "Factor graphs consist a set of variables. These variables could denote colors of provinces of Australia or locations of,",
    "start": "299155",
    "end": "307450"
  },
  {
    "text": "uh, objects at different time steps. Factor graphs also include a set of factors which depend on certain sets of variables,",
    "start": "307450",
    "end": "315790"
  },
  {
    "text": "and these factors are meant to specify, uh, preferences or constraints on what values are good for these variables to take on.",
    "start": "315790",
    "end": "324324"
  },
  {
    "text": "And the weight of an assignment is the- simply the product of all of the factors, [NOISE] right?",
    "start": "324325",
    "end": "330600"
  },
  {
    "text": "So there's this theme that comes up in this class which is- I call it, uh, specify locally and optimize globally, right?",
    "start": "330600",
    "end": "337000"
  },
  {
    "text": "So it's very easy to think about how two variables might interact and how you want something local, um, to happen.",
    "start": "337000",
    "end": "344095"
  },
  {
    "text": "And these are defined in terms of the factors. But what you care about is some globally optimal solution.",
    "start": "344095",
    "end": "349780"
  },
  {
    "text": "So the weight is a global function of all the var- assignment to all the variables. And last time, we talked about various different types of algorithms",
    "start": "349780",
    "end": "357550"
  },
  {
    "text": "for finding the maximum weight assignment including backtracking search, beam search, Gibbs sampling,",
    "start": "357550",
    "end": "363129"
  },
  {
    "text": "and so forth and so forth. Okay. So, um, one example we looked at was object tracking.",
    "start": "363130",
    "end": "369235"
  },
  {
    "start": "366000",
    "end": "470000"
  },
  {
    "text": "And in this example, we have a set of variables corresponding to the location of,",
    "start": "369235",
    "end": "375000"
  },
  {
    "text": "an unobserved object at time step i. Um, and we looked at two types of factors that captured where this object might be.",
    "start": "375000",
    "end": "385410"
  },
  {
    "text": "There's transition factors which capture the intuition that across two successive time steps,",
    "start": "385410",
    "end": "391010"
  },
  {
    "text": "the object shouldn't move if you can't teleport, that has to remain close. And tran- observation factors then incorporate the information from the sensors.",
    "start": "391010",
    "end": "399440"
  },
  {
    "text": "At each position, there's going to be some factor that kind of, uh, encourages the position to be similar to what the sensor reading was.",
    "start": "399440",
    "end": "407645"
  },
  {
    "text": "So sensor readings are noisy so it's not a hard constraint but it's a- but a soft constraint. Um, and last time,",
    "start": "407645",
    "end": "413520"
  },
  {
    "text": "we saw, uh, this, uh, demo where you can define the factor graph and you clicked Run.",
    "start": "413520",
    "end": "419315"
  },
  {
    "text": "And you see all the factors which are represented in these, uh, tables. And when you multiply everything together, you get, um,",
    "start": "419315",
    "end": "426840"
  },
  {
    "text": "for every joint assignment to all the variables some number that corresponds to how good that w- uh assignment was.",
    "start": "426840",
    "end": "434330"
  },
  {
    "text": "And if you look at the maximum weight assignment, that's what the answer you would, uh, return is. Okay? So so far so good,",
    "start": "434330",
    "end": "441210"
  },
  {
    "text": "and you can- with this framework, you can do a lot with it already. You can define a bunch of factors, you can run all the algorithms that we looked at last week.",
    "start": "441210",
    "end": "449465"
  },
  {
    "text": "But, you know, what is- what do these factors mean and how do you come up with them?",
    "start": "449465",
    "end": "456180"
  },
  {
    "text": "Intuitively, you can define these factors just, you know, hack on a 2 if you like it, 1 if you don't like it.",
    "start": "456180",
    "end": "462215"
  },
  {
    "text": "But, you know, philosophically, maybe you should be a little bit bothered by this because, um, these factors are kind of just arbitrary in some sense.",
    "start": "462215",
    "end": "469835"
  },
  {
    "text": "So the goal of this, uh, lecture and, uh, um, next two will be to, um,",
    "start": "469835",
    "end": "476915"
  },
  {
    "start": "470000",
    "end": "549000"
  },
  {
    "text": "give more meaning to the factors, and we're gonna talk about Bayesian networks. There's a way to do that. So in one sentence,",
    "start": "476915",
    "end": "483020"
  },
  {
    "text": "Bayesian networks are factor graphs plus probability. Um, just take it, taking a step back.",
    "start": "483020",
    "end": "488915"
  },
  {
    "text": "Where have we been in this course? This course has been a lot about designing new modeling frameworks.",
    "start": "488915",
    "end": "495035"
  },
  {
    "text": "So we, uh, looked at state-based models which result in search problems and MDPs in games.",
    "start": "495035",
    "end": "501365"
  },
  {
    "text": "And this was, uh, useful tools for solving a lot of, uh, problems already.",
    "start": "501365",
    "end": "506525"
  },
  {
    "text": "Um, but then we looked at, uh, starting last week, cases where maybe the order of actions doesn't matter so much,",
    "start": "506525",
    "end": "513229"
  },
  {
    "text": "and it's more natural to think about a set of variables that you want to find some assignment in any order,",
    "start": "513230",
    "end": "518289"
  },
  {
    "text": "uh, uh, is, you know, permitted. Um, and you can think about that as going maybe stepping up in abstraction,",
    "start": "518290",
    "end": "527500"
  },
  {
    "text": "kind of going from assembly to maybe C++. And in this lecture, we're gonna talk about Bayesian networks.",
    "start": "527500",
    "end": "532880"
  },
  {
    "text": "You can think about loosely analog, analogizing going from C++ to Python.",
    "start": "532880",
    "end": "538100"
  },
  {
    "text": "It gives you, uh, a kind of a more high level language to think about modeling, um, it's just another tool in your, you know, toolkit.",
    "start": "538100",
    "end": "545880"
  },
  {
    "text": "Okay. So let's start with, uh, the basics. So just a quick review of probability.",
    "start": "546020",
    "end": "551759"
  },
  {
    "start": "549000",
    "end": "950000"
  },
  {
    "text": "Usually, we see probability sort of with outcome spaces. I'm gonna jump directly to random variables, assuming that you have, uh, basic,",
    "start": "551760",
    "end": "558500"
  },
  {
    "text": "um, um, CS109 knowledge. So random variables are things- in this example,",
    "start": "558500",
    "end": "566399"
  },
  {
    "text": "are sunshine and rain. So they're variables whose values are unknown.",
    "start": "566400",
    "end": "572285"
  },
  {
    "text": "And furthermore, there is a probability distribution over all the random variables that captures how they might interact.",
    "start": "572285",
    "end": "579965"
  },
  {
    "text": "And, um, so this is called a joint distribution. Um, so we write P,",
    "start": "579965",
    "end": "586440"
  },
  {
    "text": "uh, this blackboard P of, uh, the two random variables, S and R. And this is",
    "start": "586440",
    "end": "591500"
  },
  {
    "text": "this entire table which specify for every possible assignment to all the variables,",
    "start": "591500",
    "end": "596810"
  },
  {
    "text": "a single number which is its probability. So the probability that it's sunny and it's not rainy is 0.7, for example.",
    "start": "596810",
    "end": "604170"
  },
  {
    "text": "Now, so I want to distinguish, uh, um, two things. One is that we're gonna use uppercase letters to denote random variables,",
    "start": "604170",
    "end": "611930"
  },
  {
    "text": "and lower case letters to denote the values that the random variables can take. In addition, I wanna point out that when I write P,",
    "start": "611930",
    "end": "619010"
  },
  {
    "text": "S equals S R equals R, that quantity expression represents a single number which is a probability, for example, 0.7.",
    "start": "619010",
    "end": "626330"
  },
  {
    "text": "Whereas, if I write P of S and R, that expression denotes a whole distribution which is the table.",
    "start": "626330",
    "end": "632245"
  },
  {
    "text": "And I know these are kind of minor, uh, notation differences but I think it will,",
    "start": "632245",
    "end": "638045"
  },
  {
    "text": "uh, avoid a lot of confusion if you kind of pay attention to this. So from the do- joint distribution,",
    "start": "638045",
    "end": "644615"
  },
  {
    "text": "you can use the laws of probability to derive, uh, several quantities. One quantity is called the marginal distribution.",
    "start": "644615",
    "end": "651695"
  },
  {
    "text": "And in marginal distribution, you pick a subset of the variables that you care about; those are called the query variables,",
    "start": "651695",
    "end": "657845"
  },
  {
    "text": "and you induce a distribution over them. So in this case, I've picked S. And what I'm saying is I only care about the probability of S. Um,",
    "start": "657845",
    "end": "667910"
  },
  {
    "text": "I don't care about R. But R still has kind of influence on S. So I need to take R in to account somehow.",
    "start": "667910",
    "end": "674029"
  },
  {
    "text": "And the way I do this is I look at all possible values that S can take on,",
    "start": "674030",
    "end": "679175"
  },
  {
    "text": "so look at 0. And then I look over to the joint distribution [NOISE] and look at all the rows that match that particular,",
    "start": "679175",
    "end": "686065"
  },
  {
    "text": "uh, S. So here, I'm looking at S equals 0. So that's the first two rows. And then I look at those probabilities and I summed them up.",
    "start": "686065",
    "end": "693139"
  },
  {
    "text": "So 0.2 plus 0.08 is 0.28. And similarly, for S equals 1,",
    "start": "693140",
    "end": "698384"
  },
  {
    "text": "I look at all the rows that matched S equals 1 which is the last two rows, and that gives me 0.72.",
    "start": "698385",
    "end": "705085"
  },
  {
    "text": "Okay. So what I'm doing here is called marginally- marginalizing out R. Because I don't care about R,",
    "start": "705085",
    "end": "713160"
  },
  {
    "text": "I'm interested in the marginal distribution over S. So another concept which is gonna be really important is,",
    "start": "713160",
    "end": "720355"
  },
  {
    "text": "uh, the conditional distribution. And the conditional distribution arises when",
    "start": "720355",
    "end": "725710"
  },
  {
    "text": "your interests- when you have, um, some evidence. So assume- let's say I observe that it's raining.",
    "start": "725710",
    "end": "732760"
  },
  {
    "text": "So R equals 1. So I write P of S given R equals 1, to say this is the- I'm interested in distribution over S,",
    "start": "732760",
    "end": "740035"
  },
  {
    "text": "given that it's, uh, raining. And to compute this, um, I look at this condition R equals 1,",
    "start": "740035",
    "end": "746815"
  },
  {
    "text": "and I simply select all the rows which match that. So the second and the fourth rows.",
    "start": "746815",
    "end": "753490"
  },
  {
    "text": "So now these are numbers, now probabilities. They don't sum to 1, right? Because it's only a subset of the rows.",
    "start": "753490",
    "end": "760495"
  },
  {
    "text": "But what I'm gonna do is make them sum to 1 by normalizing. So normalizing means taking, uh,",
    "start": "760495",
    "end": "766870"
  },
  {
    "text": "the relevant numbers 0.08, 0.02, adding them up, and dividing by that number.",
    "start": "766870",
    "end": "772045"
  },
  {
    "text": "Okay? So I'm dividing by 0.1, which gives me the normalized distribution 0.8 and 0.2.",
    "start": "772045",
    "end": "779440"
  },
  {
    "text": "Okay? So these two concepts are gonna be really important, and if you remember from last week, uh,",
    "start": "779440",
    "end": "785395"
  },
  {
    "text": "there- we talked about marginalization as conditioning, later in this lecture I'll connect these, uh, two concepts.",
    "start": "785395",
    "end": "792505"
  },
  {
    "text": "Okay. Any questions about, uh, basic probability so far? Hopefully this is all uh, review.",
    "start": "792505",
    "end": "798829"
  },
  {
    "text": "Okay. Let's move on. So suppose I have a joint distribution over some set of variables.",
    "start": "803280",
    "end": "810610"
  },
  {
    "text": "So then in this example, it's, um, sunny, it's raining, whether there's traffic, and whether it's the autumn season.",
    "start": "810610",
    "end": "817675"
  },
  {
    "text": "Um, the way to think about this is a p- as a probabilistic, uh, database.",
    "start": "817675",
    "end": "823240"
  },
  {
    "text": "Um, for every possible assignment, I have a number that is either, uh, is- is between 0 and 1.",
    "start": "823240",
    "end": "829090"
  },
  {
    "text": "Um, so I can think of it as an oracle. This is like a source of, you know, truth. I don't know what any of these variables is,",
    "start": "829090",
    "end": "835690"
  },
  {
    "text": "but I know how they behave and how they operate, just like I know- I don't know what the outcome of a coin flip is gonna be,",
    "start": "835690",
    "end": "842620"
  },
  {
    "text": "but I know that it's half and half, heads and tails. So the main thing that we're gonna do with",
    "start": "842620",
    "end": "848095"
  },
  {
    "text": "a joint distribution is called perform probabilistic inference. Okay? So this is an important thing to,",
    "start": "848095",
    "end": "853405"
  },
  {
    "text": "you know, understand, um, because we're gonna spend the whole time during probabilistic inference, so it's good to know what it is.",
    "start": "853405",
    "end": "859045"
  },
  {
    "text": "So, um, probabilistic inference, the way to think about it is that, um, you observe some evidence.",
    "start": "859045",
    "end": "867010"
  },
  {
    "text": "You wake up and you see, uh, okay, it's- it's autumn, and, um, and it's a bay area so there's traffic outside.",
    "start": "867010",
    "end": "873940"
  },
  {
    "text": "So, uh, you're conditioning on some evidence, T equals 1 and A equals 1. Okay. That's what you know.",
    "start": "873940",
    "end": "880120"
  },
  {
    "text": "And what you like to find out, um, querying this oracle is, you know, whether it's raining.",
    "start": "880120",
    "end": "886285"
  },
  {
    "text": "So you're interested in some set of query variables. Okay. So the general form of a probabilistic inference, um,",
    "start": "886285",
    "end": "894235"
  },
  {
    "text": "a problem or task is probability of some set of query variables conditioned on some set of,",
    "start": "894235",
    "end": "901570"
  },
  {
    "text": "you know, conditioning variables which are set to particular values. And notice that there are some variables which are not mentioned in this query,",
    "start": "901570",
    "end": "908425"
  },
  {
    "text": "such as S, and those variables are the ones that are marginalized out. So you can think about this query as combining",
    "start": "908425",
    "end": "915550"
  },
  {
    "text": "both the marginalization and the conditioning from the previous slide. Okay? So this, without loss of generality,",
    "start": "915550",
    "end": "923350"
  },
  {
    "text": "just captures everything that we seek to do with, uh, distribution for the purposes of this class.",
    "start": "923350",
    "end": "930470"
  },
  {
    "text": "Okay. So at this point, you can actually just do probabilistic inference, right?",
    "start": "931620",
    "end": "936879"
  },
  {
    "text": "If I give you a joint distribution, um, which is this huge table with all the, uh, probabilities for all the assignments,",
    "start": "936880",
    "end": "944065"
  },
  {
    "text": "you can go and um, you can compute anything you want. So now, there's a, kind of, a slight problem here which is that,",
    "start": "944065",
    "end": "950995"
  },
  {
    "start": "950000",
    "end": "1728000"
  },
  {
    "text": "if you have N variables, and just suppose each variable takes on two values. How many possible- how many rows in a table are there?",
    "start": "950995",
    "end": "959990"
  },
  {
    "text": "Anyone? 2 to the N. Right? So that's exponential, that's a lot.",
    "start": "962190",
    "end": "967870"
  },
  {
    "text": "So if N is 100, then that's, I don't know, a lot. Um, so- so clearly,",
    "start": "967870",
    "end": "973210"
  },
  {
    "text": "we can't do this naively, right? So the first challenge is, how do you even write down this joint distribution compactly, right?",
    "start": "973210",
    "end": "980154"
  },
  {
    "text": "I don't want to write down 2 to the N numbers. So Bayesian networks is going to allow us to",
    "start": "980155",
    "end": "985420"
  },
  {
    "text": "define joint distribution using the language of factor graphs. So this is really cool because now I have a very compact way of specifying what is,",
    "start": "985420",
    "end": "994255"
  },
  {
    "text": "um, implicitly, something that's very, very large. The second challenge is algorithmic.",
    "start": "994255",
    "end": "1000480"
  },
  {
    "text": "How do you do inference, right? We wanna do- perform a probabilistic inference answering queries like this.",
    "start": "1000480",
    "end": "1006050"
  },
  {
    "text": "How do we do this efficiently? Again, you don't want to have to, uh,",
    "start": "1006050",
    "end": "1012125"
  },
  {
    "text": "go through to 2 to the N possibilities, because that would be really really slow. Um, and we'll see that variable elimination,",
    "start": "1012125",
    "end": "1018990"
  },
  {
    "text": "Gibbs sampling, particle filtering, which is the probabilistic analog of beam search, all these algorithms that we, uh,",
    "start": "1018990",
    "end": "1025454"
  },
  {
    "text": "talked about last week are actually going to come into play. And we're just gonna talk about the probabilistic analog of these,",
    "start": "1025455",
    "end": "1032280"
  },
  {
    "text": "as opposed to finding the maximum weight assignment. Okay. All right.",
    "start": "1032280",
    "end": "1038970"
  },
  {
    "text": "So now let's try to motivate why we need, uh, Bayesian networks with this following example.",
    "start": "1038970",
    "end": "1045135"
  },
  {
    "text": "So, um, here's a setting. So earthqua- earthquakes and burglaries are things in the world, they are bad things.",
    "start": "1045135",
    "end": "1052920"
  },
  {
    "text": "Um, but suppose that they're independent, right? That kinda makes sense. Um, but in your house you've ins- installed an alarm system,",
    "start": "1052920",
    "end": "1061410"
  },
  {
    "text": "which is going to detect either, uh, both earthquakes and alarms. Okay. So one day you wake up,",
    "start": "1061410",
    "end": "1067215"
  },
  {
    "text": "and you hear an alarm go off. Okay. So you should be alarmed. Um, but, uh, but then you turn on the radio and you hear that,",
    "start": "1067215",
    "end": "1075809"
  },
  {
    "text": "uh, there's actually an earthquake. Um, so how does that affect your beliefs about whether there was a burglary or not?",
    "start": "1075810",
    "end": "1083700"
  },
  {
    "text": "Okay. So okay. There's three options, does it increase the probability of a burglary?",
    "start": "1083700",
    "end": "1089475"
  },
  {
    "text": "Does it decrease the probability of burglary or it does not change anything at all? Okay. So how many of you think that hearing, uh,",
    "start": "1089475",
    "end": "1097125"
  },
  {
    "text": "the news about the earthquake on the radio increases the probability of a burglary?",
    "start": "1097125",
    "end": "1102135"
  },
  {
    "text": "So a few say it increases, how many of you say it decreases?",
    "start": "1102135",
    "end": "1107310"
  },
  {
    "text": "So many of you say it decreases. How many are saying it doesn't change? Okay. Almost as many say it doesn't change.",
    "start": "1107310",
    "end": "1115575"
  },
  {
    "text": "Okay. That's interesting. So we'll answer this question, but you know, keep on thinking about that in your back of your head.",
    "start": "1115575",
    "end": "1121320"
  },
  {
    "text": "And one thing I'll say is that, you know, I shouldn't- you shouldn't expect to necessarily find the right answer here just by kind of intuiting things.",
    "start": "1121320",
    "end": "1129450"
  },
  {
    "text": "And one of the points of making things codified in a Bayesian network is that you don't leave anything up to a, kind of, vagueness.",
    "start": "1129450",
    "end": "1136815"
  },
  {
    "text": "It's- you- it's- there's actually a correct answer that we can derive. Okay. So, um, let me talk about how to go about,",
    "start": "1136815",
    "end": "1145890"
  },
  {
    "text": "uh, modeling this as a Bayesian network. So with this core example, so there's four steps.",
    "start": "1145890",
    "end": "1151245"
  },
  {
    "text": "Um, the first step is defining what the variables are. Okay. Variables. Um, so",
    "start": "1151245",
    "end": "1161700"
  },
  {
    "text": "what are the variables here? Yeah. Burglary.",
    "start": "1161700",
    "end": "1167024"
  },
  {
    "text": "Okay. So there is a burglary- Earthquake. Earthquake. And alarm. And alarm. Okay, great.",
    "start": "1167025",
    "end": "1172815"
  },
  {
    "text": "So these are the three things that we don't know about that are mentioned. Okay. So the second step is,",
    "start": "1172815",
    "end": "1179370"
  },
  {
    "text": "um, you draw some edges. Okay. So these are gonna be directed edges,",
    "start": "1179370",
    "end": "1185625"
  },
  {
    "text": "that correspond to notions of influence. Um, and if you- if you want cause- causality.",
    "start": "1185625",
    "end": "1194205"
  },
  {
    "text": "But causality is a very, uh, more philosophical thing which we don't really need for this class.",
    "start": "1194205",
    "end": "1199935"
  },
  {
    "text": "Um, so, but I'll- but I'll use it anyway. So what causes what?",
    "start": "1199935",
    "end": "1205080"
  },
  {
    "text": "So this alarm cause burg- burglaries, no. Okay. I think it's the other way around, right?",
    "start": "1205080",
    "end": "1210900"
  },
  {
    "text": "So burglaries cause alarm, and similarly earthquakes cause alarm. Um, and these two aren't,",
    "start": "1210900",
    "end": "1217620"
  },
  {
    "text": "uh, or I said they're independent, so let's just leave that out. Okay. Okay. So now I have a direct a- acyclic graph",
    "start": "1217620",
    "end": "1224385"
  },
  {
    "text": "that shows how all the variables are related in somehow. Okay. So the third step is to define local conditional distributions.",
    "start": "1224385",
    "end": "1235590"
  },
  {
    "text": "So now I'm going to go one step further and say, um, how these, uh, what the probabilities of these, uh, variables are.",
    "start": "1235590",
    "end": "1246195"
  },
  {
    "text": "Because in the end, and remember I wanted to define a joint distribution of all the variables. Okay. So um, I'm going to define",
    "start": "1246195",
    "end": "1253380"
  },
  {
    "text": "a local conditional distribution for each of these variables. So here I have P of B,",
    "start": "1253380",
    "end": "1258930"
  },
  {
    "text": "P of E, and um, P of, uh, A given B and E. So in general,",
    "start": "1258930",
    "end": "1266850"
  },
  {
    "text": "a local conditional distribution is P of whatever that variable is, given its parents.",
    "start": "1266850",
    "end": "1273660"
  },
  {
    "text": "So the parents are the variables that directly point into it. So the parents of A are B and E. E has no parents,",
    "start": "1273660",
    "end": "1280620"
  },
  {
    "text": "and A, uh, B has no parents. Okay. So in particular,",
    "start": "1280620",
    "end": "1286590"
  },
  {
    "text": "what I'm going to do is now- let me flesh this out a little bit more. So what is P of B? P of B is a table that specifies only what's going on in this region of the space.",
    "start": "1286590",
    "end": "1296340"
  },
  {
    "text": "So I have B, and have P of B, and I just fill out this. What are the possible values of B? 0, 1.",
    "start": "1296340",
    "end": "1302490"
  },
  {
    "text": "0, 1. So let's say, uh, 0- 1 and 0. So let's say that probably of burglary is Epsilon.",
    "start": "1302490",
    "end": "1311055"
  },
  {
    "text": "Um, Epsilon generally denotes a small number, which you hope to be the case, um, here. Um, so this must be 1 minus Epsilon,",
    "start": "1311055",
    "end": "1317895"
  },
  {
    "text": "because it has to sum to 1. Um, and for simplicity, let's say that probability of earthquake is also Epsilon and 1 minus Epsilon,",
    "start": "1317895",
    "end": "1325995"
  },
  {
    "text": "just for simplicity. And then, okay. So this one's a little bit more complicated. So I'm gonna write the parents B,",
    "start": "1325995",
    "end": "1332779"
  },
  {
    "text": "E, and the variable itself, A. And I'm going to look at probability of A given B and E.",
    "start": "1332780",
    "end": "1340055"
  },
  {
    "text": "And now I'm gonna list out all the eight possible, uh, combinations here.",
    "start": "1340055",
    "end": "1346080"
  },
  {
    "text": "So it's 0 0 0, 0 0 1, uh, 0 1 0, 0 1 1, 1 0 0,",
    "start": "1346080",
    "end": "1352680"
  },
  {
    "text": "1 0 1, 1 1 0, 1 1 1. Okay? Okay. So for each of these I need to specify the probability.",
    "start": "1352680",
    "end": "1360509"
  },
  {
    "text": "So 0 0 0. Um, and I should say that this alarm system you bought was,",
    "start": "1360510",
    "end": "1368055"
  },
  {
    "text": "uh, is really good- really good. So it's, um, it detects earthquakes and burglaries, uh, perfectly.",
    "start": "1368055",
    "end": "1373634"
  },
  {
    "text": "Okay. So if there is no burglary and no earthquake, then the probability of the alarm not going off should be 1. Right? It's perfect.",
    "start": "1373635",
    "end": "1382245"
  },
  {
    "text": "And this is, uh, the failure case which is 0, because, um, if there is a burglary- no burglary and no earthquake,",
    "start": "1382245",
    "end": "1389190"
  },
  {
    "text": "the alarm shouldn't be going off. And, um, this is- I'm not gonna bother you with the details,",
    "start": "1389190",
    "end": "1396419"
  },
  {
    "text": "you can, uh, you can just fill in the rest of this. So there is a burglary and earthquake that should be, uh, maybe someone should check them during this, right?",
    "start": "1396420",
    "end": "1403590"
  },
  {
    "text": "Um, this should be a 1, this should be a 0, and this should be a 1. Something like that?",
    "start": "1403590",
    "end": "1412570"
  },
  {
    "text": "Okay? So now I've defined the local conditional distributions so remember I'm",
    "start": "1415070",
    "end": "1421019"
  },
  {
    "text": "not defining the joint distribution yet. I'm just defining in from zooming in on a particular variable.",
    "start": "1421020",
    "end": "1428700"
  },
  {
    "text": "How does it relate given its parents, right? And you can think about it like, you have a million nodes.",
    "start": "1428700",
    "end": "1434985"
  },
  {
    "text": "I'm only, each local distribution might be only touching like a very small part. Okay, so finally the fourth step is to define the joint distribution.",
    "start": "1434985",
    "end": "1444840"
  },
  {
    "text": "Okay, this is the thing we're all after, right? Which is, what is the joint distribution over",
    "start": "1444840",
    "end": "1450345"
  },
  {
    "text": "all three variables here and the joint distribution is going to be written with a black pen.",
    "start": "1450345",
    "end": "1457710"
  },
  {
    "text": "P is, um, B equals, uh, b, um, E equals e,",
    "start": "1457710",
    "end": "1464040"
  },
  {
    "text": "A equals a so random variables equals a particular possible value, and this is defined to be the product of all the,",
    "start": "1464040",
    "end": "1473850"
  },
  {
    "text": "uh, local conditional distributions. Okay? So P of b,",
    "start": "1473850",
    "end": "1479039"
  },
  {
    "text": "p of e and p of a given b and e. [NOISE] Okay?",
    "start": "1479040",
    "end": "1489029"
  },
  {
    "text": "So let me reveal the slide which hopefully should have the same content on this.",
    "start": "1489030",
    "end": "1494620"
  },
  {
    "text": "Um, one thing I'll, I'll point out is that, um,",
    "start": "1494720",
    "end": "1500505"
  },
  {
    "text": "there is a difference between the small p's and the big P's. So the small p's are local conditional distributions.",
    "start": "1500505",
    "end": "1508650"
  },
  {
    "text": "Um, these are things that you just define, right? There's no right or wrong there. You just define them.",
    "start": "1508650",
    "end": "1514605"
  },
  {
    "text": "They're just true. Um, and then there's this big P which is, um,",
    "start": "1514605",
    "end": "1519929"
  },
  {
    "text": "the joint distribution which is again defined to be just the product and then from this joint distribution,",
    "start": "1519930",
    "end": "1528210"
  },
  {
    "text": "you're going to read out things like marginals and conditionals, um, which might look like some of these local distributions but they're, uh,",
    "start": "1528210",
    "end": "1536475"
  },
  {
    "text": "right now I think about them as distinct objects. Yeah, question?",
    "start": "1536475",
    "end": "1541890"
  },
  {
    "text": "Can we find [inaudible] So the question is are we assuming b and e are, um, independent here?",
    "start": "1541890",
    "end": "1550320"
  },
  {
    "text": "Um, so let's see how do I answer that? So yes in this one b and e are, um, independent.",
    "start": "1550320",
    "end": "1558615"
  },
  {
    "text": "Um, and, uh, I'll show you a little bit further how we can kind of see them more clearly.",
    "start": "1558615",
    "end": "1565485"
  },
  {
    "text": "Yeah. Okay so these are Bayesian networks.",
    "start": "1565485",
    "end": "1575745"
  },
  {
    "text": "So what's the connection between this and factor graphs? Well, if you, um,",
    "start": "1575745",
    "end": "1583635"
  },
  {
    "text": "squint a little bit, you see that the right hand side here is a product of things and the left-hand side is this kind of joint,",
    "start": "1583635",
    "end": "1592875"
  },
  {
    "text": "uh, global thing and so what does this look like? Looks like weight equals product of vectors, right?",
    "start": "1592875",
    "end": "1598875"
  },
  {
    "text": "So let's go with that analogy and it's actually much deeper than just an analogy,",
    "start": "1598875",
    "end": "1604950"
  },
  {
    "text": "um, and let's draw this as an equivalent factor graph. Okay? So for every Bayesian network,",
    "start": "1604950",
    "end": "1612360"
  },
  {
    "text": "we can actually draw it as a factor graph. So here we have b, um, e and a and- okay so now it's, um,",
    "start": "1612360",
    "end": "1621060"
  },
  {
    "text": "you know, it's really important to note that how did the factors, uh, arise.",
    "start": "1621060",
    "end": "1627270"
  },
  {
    "text": "Through there's a local conditional distribution remember for every variable and that is a factor.",
    "start": "1627270",
    "end": "1632400"
  },
  {
    "text": "So for every variable, there is a factor right. It's tempting to look at these edges and draw factors on them but that's, that's wrong.",
    "start": "1632400",
    "end": "1641535"
  },
  {
    "text": "Okay? Remember, one factor per variable. Okay? So this variable has a factor.",
    "start": "1641535",
    "end": "1648659"
  },
  {
    "text": "That is P of B. This variable has a factor, that's P of E and this variable has a factor and,",
    "start": "1648660",
    "end": "1659759"
  },
  {
    "text": "uh, this-what does this depend on, what is its, uh, scope? B, and E, and A, right?",
    "start": "1659760",
    "end": "1673800"
  },
  {
    "text": "Okay. Now again, common mistake is to just put two factors here because it's really tempting.",
    "start": "1673800",
    "end": "1681495"
  },
  {
    "text": "But one way to think about it is that if you think about your, your parents they- they're married and connected.",
    "start": "1681495",
    "end": "1688860"
  },
  {
    "text": "So that's why these are your parents are connected. Actually the- um, I'm not making this up but there's, um,",
    "start": "1688860",
    "end": "1696655"
  },
  {
    "text": "some people call, uh, this process, um moralization. Um, yeah.",
    "start": "1696655",
    "end": "1703680"
  },
  {
    "text": "Can you guys use this system to compute the probability of alarm given just an earthquake or a probability of alarm given just a burglary.",
    "start": "1703680",
    "end": "1710419"
  },
  {
    "text": "Yeah so the question is, can you use this to compute probability of alarm given earthquake alone or burglary alone?",
    "start": "1710420",
    "end": "1716520"
  },
  {
    "text": "And the answer is you compute whatever you want and we'll- I'll show you how to do that. Okay. So single factor connects all the parents,",
    "start": "1716520",
    "end": "1725565"
  },
  {
    "text": "one factor per variable, okay? Got it? All right, so, um,",
    "start": "1725565",
    "end": "1731580"
  },
  {
    "start": "1728000",
    "end": "1845000"
  },
  {
    "text": "the joint distribution over all the variables, remember is the product of all the local conditional distributions and just for reference,",
    "start": "1731580",
    "end": "1738540"
  },
  {
    "text": "this is what it is. Um, and now you can go and answer questions about this.",
    "start": "1738540",
    "end": "1744765"
  },
  {
    "text": "So this is kind of the fun part and I'm not going to go through the details of how this is done but I'm just gonna show you kind of the interface,",
    "start": "1744765",
    "end": "1751979"
  },
  {
    "text": "um, what you would expect. So again, this is, um, the definition of an alarm network, um,",
    "start": "1751979",
    "end": "1760380"
  },
  {
    "text": "using the same machinery as a factor graph because it is a factor graph, um, and first we're gonna ask what is the probability of B?",
    "start": "1760380",
    "end": "1769200"
  },
  {
    "text": "So what is that? That says in the absence of any information, is there a burglary or not?",
    "start": "1769200",
    "end": "1774345"
  },
  {
    "text": "Okay? So what do you think that should be?  And epsilon here is 0.05.",
    "start": "1774345",
    "end": "1782830"
  },
  {
    "text": "So I think I heard it 0.05. Someone said that, okay?",
    "start": "1784070",
    "end": "1789539"
  },
  {
    "text": "So in D, the probability of a burglary is 0.05. Um, should be intuitive, um,",
    "start": "1789540",
    "end": "1796035"
  },
  {
    "text": "and now suppose I- uh, the alarm went off. Okay? So now what's the probability of burglary?",
    "start": "1796035",
    "end": "1803340"
  },
  {
    "text": "So what is P of B given A equals 1? Does it go up or down? Should go up if your alarm is working.",
    "start": "1803340",
    "end": "1811755"
  },
  {
    "text": "Um, and indeed we see that probability of burglary given alarm equals 1 is 0.51.",
    "start": "1811755",
    "end": "1817230"
  },
  {
    "text": "Okay? And now the moment of truth, what happens if we condition on the fact that there's also an earthquake?",
    "start": "1817230",
    "end": "1826755"
  },
  {
    "text": "So let's do this and you get 0.05.",
    "start": "1826755",
    "end": "1833865"
  },
  {
    "text": "So many of you are correct, um when you said that the probability of,",
    "start": "1833865",
    "end": "1838980"
  },
  {
    "text": "uh, earthquake goes down. And intuitively, you can think of, uh,",
    "start": "1838980",
    "end": "1844260"
  },
  {
    "text": "it makes sense from this phenomenon called explaining away.",
    "start": "1844260",
    "end": "1850335"
  },
  {
    "start": "1845000",
    "end": "2222000"
  },
  {
    "text": "So explaining away happens when you have structures that look like this, and you have- suppose you have two causes, positive influencing effect?",
    "start": "1850335",
    "end": "1859680"
  },
  {
    "text": "So by positive influence I mean that if you flip B equals from 0 to 1, then the probability of A goes up.",
    "start": "1859680",
    "end": "1866669"
  },
  {
    "text": "And, um- so explaining away says I conditioned on the fact,",
    "start": "1866670",
    "end": "1871890"
  },
  {
    "text": "conditioning on one cause reduces the probability of the other one. Okay? So at some level this makes sense because, you know,",
    "start": "1871890",
    "end": "1882030"
  },
  {
    "text": "this A is either B or, uh, uh, is either driven by B or E and I don't",
    "start": "1882030",
    "end": "1887985"
  },
  {
    "text": "know which one it is if I just heard an alarm go off. But each of these is very small proba- has very small probability.",
    "start": "1887985",
    "end": "1894809"
  },
  {
    "text": "So the moment I can kind of, uh, see that one of them explained this cause, see that one of them is true then I,",
    "start": "1894810",
    "end": "1903015"
  },
  {
    "text": "I can revert back to the my prior belief on the, you know, other one. Okay? So humans do this all the time when you're reasoning.",
    "start": "1903015",
    "end": "1910335"
  },
  {
    "text": "When you're thinking about like what, what the cause is and you find one, one cause and you discount all the other ones.",
    "start": "1910335",
    "end": "1916905"
  },
  {
    "text": "So um, now the thing that's kind of interesting here is that I did say that B and E are independent which is also true.",
    "start": "1916905",
    "end": "1927149"
  },
  {
    "text": "Right? So this might have led people to think like well, it shouldn't change because they are independent. So why should the probability change?",
    "start": "1927150",
    "end": "1933030"
  },
  {
    "text": "But the key thing is that when you condition on A, you actually changed, uh,",
    "start": "1933030",
    "end": "1939345"
  },
  {
    "text": "the independent structure of the model. So this is why writing things down really precisely",
    "start": "1939345",
    "end": "1946110"
  },
  {
    "text": "is helpful to kind of reconcile these seemingly, um, contradictory intuitions that you might get. [NOISE]",
    "start": "1946110",
    "end": "1954825"
  },
  {
    "text": "Okay, any questions about this? [NOISE]",
    "start": "1954825",
    "end": "1966300"
  },
  {
    "text": "All right, let's move on. So we've talked about the alarm network. This is your first example of a small Bayesian network.",
    "start": "1966300",
    "end": "1975225"
  },
  {
    "text": "Hopefully, you have an idea of the intuition behind this and now I'm going to generalize it. And the generalization shouldn't be surprising.",
    "start": "1975225",
    "end": "1982575"
  },
  {
    "text": "So in general I have n random variables usually denoted X_1 through X_n.",
    "start": "1982575",
    "end": "1988500"
  },
  {
    "text": "And the Bayesian networks is a directed acyclic graph over these variables and it defines",
    "start": "1988500",
    "end": "1995240"
  },
  {
    "text": "a joint distribution over all the variables like this, X_1 through X_n. And this is defined as a product of local conditional distributions,",
    "start": "1995240",
    "end": "2003805"
  },
  {
    "text": "one for each node. Okay, so this is a product of all n, X_i given X parents of i.",
    "start": "2003805",
    "end": "2010430"
  },
  {
    "text": "And this notation just means the values assigned to the parents of i.",
    "start": "2010430",
    "end": "2016290"
  },
  {
    "text": "Okay, so this is a very general framework. Um, and, uh, just like factor graphs are a very, you know, general framework.",
    "start": "2016870",
    "end": "2027215"
  },
  {
    "text": "But the key difference from factor graphs is the fact that these factors aren't arbitrary,",
    "start": "2027215",
    "end": "2033080"
  },
  {
    "text": "right, there are local conditional distributions. And what does that mean? That means all factors satisfy this property.",
    "start": "2033080",
    "end": "2041975"
  },
  {
    "text": "So if you pick up a factor for the i-th node, p of X_i given X parents is equal to",
    "start": "2041975",
    "end": "2047929"
  },
  {
    "text": "1 if you sum over all the possible values that X_i can take on.",
    "start": "2047930",
    "end": "2053000"
  },
  {
    "text": "Okay, that's what it means to be a, uh, probability distribution. And this is true for every setting of experiments.",
    "start": "2053000",
    "end": "2061919"
  },
  {
    "text": "So this property has two implications which I'll",
    "start": "2063160",
    "end": "2068899"
  },
  {
    "text": "discuss consistency of sub-Bayesian networks and consistency  conditional distributions.",
    "start": "2068900",
    "end": "2074119"
  },
  {
    "text": "Um, and these properties are going to allow us to really, uh, take advantage of the probabilistic structure when we're doing inference.",
    "start": "2074120",
    "end": "2084440"
  },
  {
    "text": "Okay, so the first thing is the question is suppose I have this Bayesian network, this alarm network.",
    "start": "2084440",
    "end": "2092135"
  },
  {
    "text": "And, um, I'm going to suppose I'm interested in",
    "start": "2092135",
    "end": "2097490"
  },
  {
    "text": "the marginal distribution of only B and E. Okay, I don't care about A.",
    "start": "2097490",
    "end": "2104475"
  },
  {
    "text": "So remember this is, um, the joint distribution and by laws of probability,",
    "start": "2104475",
    "end": "2111589"
  },
  {
    "text": "I can derive the, um, marginal distribution. Now, the question is what does this marginal distribution",
    "start": "2111589",
    "end": "2117500"
  },
  {
    "text": "have to do with the- the Bayesian network, the graph here? Okay, so let's go through some algebra to find out.",
    "start": "2117500",
    "end": "2124940"
  },
  {
    "text": "So this is a sum over all A and by definition this is just the product of all the local conditional distributions as we just discussed.",
    "start": "2124940",
    "end": "2134270"
  },
  {
    "text": "And now I notice that P of B and P of E don't depend on A which means that I",
    "start": "2134270",
    "end": "2140330"
  },
  {
    "text": "can pull this out and push the summation in. That's just, uh, algebraic manipulation.",
    "start": "2140330",
    "end": "2146405"
  },
  {
    "text": "And then what is this value? This value is just 1 because of the previous slide.",
    "start": "2146405",
    "end": "2152885"
  },
  {
    "text": "So I can just drop it. And now I have p of b times p of e. And lo and behold what is- what",
    "start": "2152885",
    "end": "2158900"
  },
  {
    "text": "is this? This is if you had just gone and defined a sub- miniature of Bayesian network over",
    "start": "2158900",
    "end": "2165710"
  },
  {
    "text": "B and E. This was exactly what you've written down. Okay, so that's kind of cool.",
    "start": "2165710",
    "end": "2171184"
  },
  {
    "text": "So the general idea here is that when you're marginalizing out, uh, a leaf node that yields a Bayesian network just without that node.",
    "start": "2171185",
    "end": "2181279"
  },
  {
    "text": "So marginalization produces this, um, this Bayesian network where you've just erased,",
    "start": "2181280",
    "end": "2187039"
  },
  {
    "text": "um, the very- the leaf node along with its incoming edges.",
    "start": "2187039",
    "end": "2192575"
  },
  {
    "text": "All right, so in other words, I've turned basically what was, would have been",
    "start": "2192575",
    "end": "2198860"
  },
  {
    "text": "a algebraic operation into a graphical one. And generally those are good moves",
    "start": "2198860",
    "end": "2204170"
  },
  {
    "text": "because it's much easier to kinda think graphically and, uh, make large operations then go through tons of algebra. Yeah.",
    "start": "2204170",
    "end": "2211155"
  },
  {
    "text": "Definition equals, it seems like it's from like the probability [inaudible].",
    "start": "2211155",
    "end": "2220600"
  },
  {
    "text": "Yeah, so the question is what about this first definition equals? What I mean here is by the laws of probability.",
    "start": "2220600",
    "end": "2226020"
  },
  {
    "start": "2222000",
    "end": "2734000"
  },
  {
    "text": "Um, so it's not technically a definition, it follows from the axioms of probability.",
    "start": "2226020",
    "end": "2231815"
  },
  {
    "text": "Yeah, thanks.",
    "start": "2231815",
    "end": "2238760"
  },
  {
    "text": "Okay. So notice that in this world,",
    "start": "2238760",
    "end": "2244880"
  },
  {
    "text": "P- B and E are independent. So this is one way you can kind of, uh, see that actually when you define the joint distribution,",
    "start": "2244880",
    "end": "2253984"
  },
  {
    "text": "in that joint distribution, um, two variables, B and E are independent.",
    "start": "2253984",
    "end": "2260490"
  },
  {
    "text": "So one thing to note is that if we looked at the factor graph,",
    "start": "2260650",
    "end": "2266630"
  },
  {
    "text": "um, which is this thing. And remember last time we talked about marginalization in fact- factor graphs.",
    "start": "2266630",
    "end": "2274040"
  },
  {
    "text": "And what does that look like? If you- what happens if you did marginalization in this factor graph?",
    "start": "2274040",
    "end": "2280215"
  },
  {
    "text": "Okay.",
    "start": "2280215",
    "end": "2282260"
  },
  {
    "text": "Yeah, you just remove A but this factor is, does it disappear?",
    "start": "2290800",
    "end": "2297390"
  },
  {
    "text": "No, it's- it doesn't, right, because factor graphs, remember that factor graphs don't know anything about this factor.",
    "start": "2298990",
    "end": "2305255"
  },
  {
    "text": "Other than that it, uh, returns non-negative numbers.",
    "start": "2305255",
    "end": "2310400"
  },
  {
    "text": "So you would have to keep, hold onto this factor. Right, so the moral of the story here is that if you're using factor graph,",
    "start": "2310400",
    "end": "2320359"
  },
  {
    "text": "if you convert the factor graphs too early, then you might lose out on opportunities that really simplify it. Whereas, if you look at this- the factor graph of this one,",
    "start": "2320360",
    "end": "2329270"
  },
  {
    "text": "there is no P of a given B and E. Right.",
    "start": "2329270",
    "end": "2334910"
  },
  {
    "text": "I mean just to go back here factor graphs will create a factor which is summation of A,",
    "start": "2334910",
    "end": "2340339"
  },
  {
    "text": "P of A given B and E and call that a factor. And we know because these are local conditional distributions that's just one,",
    "start": "2340340",
    "end": "2346970"
  },
  {
    "text": "so you can just drop it. Okay, so- so that's the first property.",
    "start": "2346970",
    "end": "2356090"
  },
  {
    "text": "Just summarize, if you marginalize out leaf nodes, uh, you get Bayesian networks by just dropping them from the graph.",
    "start": "2356090",
    "end": "2365900"
  },
  {
    "text": "So the second property is its consistency of local conditionals. As I alluded to before,",
    "start": "2365900",
    "end": "2372860"
  },
  {
    "text": "if you have P probability of D given A and B, there's two versions of this that you might be thinking about.",
    "start": "2372860",
    "end": "2379865"
  },
  {
    "text": "One is the local conditional distribution, which has again you just define it as such.",
    "start": "2379865",
    "end": "2385010"
  },
  {
    "text": "And then there is the corresponding quantity that comes about from probabilistic inference.",
    "start": "2385010",
    "end": "2390125"
  },
  {
    "text": "So this quantity is derived from taking the definitions,",
    "start": "2390125",
    "end": "2395165"
  },
  {
    "text": "forming the joint distribution, and then using the laws of probability to derive this particular quantity.",
    "start": "2395165",
    "end": "2401225"
  },
  {
    "text": "And this property says that don't worry about it, the two are equal. So, you know, it means that you can kind of",
    "start": "2401225",
    "end": "2410270"
  },
  {
    "text": "intuitively think about there just can be one notion of probability in your head.",
    "start": "2410270",
    "end": "2415369"
  },
  {
    "text": "But I wanna make this explicit but that this is- that doesn't come necessarily for free,",
    "start": "2415370",
    "end": "2420410"
  },
  {
    "text": "you have to kind of verify that this is true. I'm not gonna go through the verification step, it's in the,",
    "start": "2420410",
    "end": "2427220"
  },
  {
    "text": "uh, notes in the slides, but I'll just state it as such.",
    "start": "2427220",
    "end": "2431850"
  },
  {
    "text": "Okay. So let's do another example just to familiari- familiarize ourselves with Bayesian networks a little bit more.",
    "start": "2433870",
    "end": "2443630"
  },
  {
    "text": "Um, so the question here is that suppose you have, um,",
    "start": "2443630",
    "end": "2449029"
  },
  {
    "text": "you wake up and you are coughing and you have itchy eyes and you're wondering, do I have a cold or do l have allergies?",
    "start": "2449030",
    "end": "2456725"
  },
  {
    "text": "Okay, so let's follow this four-step procedure to define this Bayesian network. Okay, so step 1, what are the variables here?",
    "start": "2456725",
    "end": "2464369"
  },
  {
    "text": "There's, um, coughing, let's denote that as H,",
    "start": "2464470",
    "end": "2471050"
  },
  {
    "text": "and itchy eyes, and then cold, and allergies.",
    "start": "2471050",
    "end": "2477875"
  },
  {
    "text": "Okay, so four random variables. Um, how should I connect these things up?",
    "start": "2477875",
    "end": "2483900"
  },
  {
    "text": "Yeah, so H and I should be connected to C. So if you have a cold, you probably have, um,",
    "start": "2487750",
    "end": "2494000"
  },
  {
    "text": "uh, a cough and you probably have itchy eyes. And here you tap into your medical knowledge and,",
    "start": "2494000",
    "end": "2500900"
  },
  {
    "text": "um, what was that? Yeah, so generally, uh,",
    "start": "2500900",
    "end": "2507860"
  },
  {
    "text": "I'm no doctor but let's just assume for now that allergies don't really cause the",
    "start": "2507860",
    "end": "2513440"
  },
  {
    "text": "coughing, cause the itchy eyes. It's probably not true but let's just pretend it is. Um, okay, so just to make the network a little bit more interesting.",
    "start": "2513440",
    "end": "2523369"
  },
  {
    "text": "Okay, so those are the edges, and now I have to specify local conditional distributions over all these.",
    "start": "2523370",
    "end": "2530840"
  },
  {
    "text": "So what are the local conditional distributions? So I have P of C,",
    "start": "2530840",
    "end": "2538234"
  },
  {
    "text": "P of A, remember one for every node, um, and P of H given C and here over here is P of i given C and n, right.",
    "start": "2538235",
    "end": "2550385"
  },
  {
    "text": "So probability of a node given its parents. And then finally I have the joint distribution which is probability of C, A, H, I.",
    "start": "2550385",
    "end": "2562954"
  },
  {
    "text": "And this is by definition just a product of everything.",
    "start": "2562955",
    "end": "2568380"
  },
  {
    "text": "Um, for this example I'm not going to go through and define the actual tables because that's gonna take too much time.",
    "start": "2572470",
    "end": "2579050"
  },
  {
    "text": "But I'm gonna do it in this demo here. Okay, so this is a Bayesian network that I just drew on the board",
    "start": "2579050",
    "end": "2585755"
  },
  {
    "text": "and this is its- its associated factor graph.",
    "start": "2585755",
    "end": "2590890"
  },
  {
    "text": "Remember one factor per node. Yeah. The PowerPoint switches the allergies and cold.",
    "start": "2590890",
    "end": "2598905"
  },
  {
    "text": "C, A, oh, yeah, you're right. Um. I guess that makes sense.",
    "start": "2598905",
    "end": "2604835"
  },
  {
    "text": "Which one makes sense? [inaudible] Yeah. Okay, I got,",
    "start": "2604835",
    "end": "2610829"
  },
  {
    "text": "I got a little bit, uh, confused [NOISE] Okay.",
    "start": "2610830",
    "end": "2616200"
  },
  {
    "text": "So it should be like this and then I have to adjust things, um, okay.",
    "start": "2616200",
    "end": "2622214"
  },
  {
    "text": "So we're fixing this. I given a, um, and c and a, okay?",
    "start": "2622215",
    "end": "2631515"
  },
  {
    "text": "Just for the record, I'll just make this h given c and a and i given a, okay.",
    "start": "2631515",
    "end": "2638265"
  },
  {
    "text": "That wasn't too bad. Okay, thanks for catching that. Okay. So this is the factor graph, um,",
    "start": "2638265",
    "end": "2645510"
  },
  {
    "text": "and let me show you, uh, this demo. So you can click on this and you can see, uh,",
    "start": "2645510",
    "end": "2652530"
  },
  {
    "text": "this Bayesian network and this factor graph. Um, and to answer this question, what was the question?",
    "start": "2652530",
    "end": "2659220"
  },
  {
    "text": "The question was if I have, uh, if you are coughing and have itchy eyes or do you have cold or allergies.",
    "start": "2659220",
    "end": "2666525"
  },
  {
    "text": "So I conditioned on cough equals 1, uh, itchy eye equals 1,",
    "start": "2666525",
    "end": "2672135"
  },
  {
    "text": "and I am asking for, uh, the probability of, um, the cold.",
    "start": "2672135",
    "end": "2678089"
  },
  {
    "text": "Okay. And if you work it out, you see that the probability of a cold is 0.13.",
    "start": "2678090",
    "end": "2686800"
  },
  {
    "text": "Um, and, you know, so why does this- so- okay,",
    "start": "2687350",
    "end": "2694020"
  },
  {
    "text": "I guess I didn't really tell you enough about the actual prior probability. So the probability of a cold is, you know,",
    "start": "2694020",
    "end": "2700410"
  },
  {
    "text": "0.1, um, let's say and the probability of allergies is, you know, 0.2.",
    "start": "2700410",
    "end": "2705660"
  },
  {
    "text": "And then there's a, kind of, a noisy or where if you're, uh,",
    "start": "2705660",
    "end": "2712275"
  },
  {
    "text": "if you have, um, a cold or allergies then you,",
    "start": "2712275",
    "end": "2719384"
  },
  {
    "text": "you end up coughing. And, um, the- if you have, uh, itch, allergies and you have itchy eyes with probability 0.9.",
    "start": "2719385",
    "end": "2728580"
  },
  {
    "text": "Um, and what happened here is that, um, if you- oops.",
    "start": "2728580",
    "end": "2734609"
  },
  {
    "start": "2734000",
    "end": "2776000"
  },
  {
    "text": "Um, if you condition on, uh, your coughing and you have itchy eyes,",
    "start": "2734610",
    "end": "2741945"
  },
  {
    "text": "um, there's this, kind of, interesting explaining way happening here.",
    "start": "2741945",
    "end": "2747665"
  },
  {
    "text": "Um, where, you know, even though you didn't observe A, you observe evidence of A,",
    "start": "2747665",
    "end": "2754525"
  },
  {
    "text": "and that's enough to, kind of, uh, lower the probability that you have a cold. So this is- example show something a little bit more subtle how information can",
    "start": "2754525",
    "end": "2764580"
  },
  {
    "text": "kinda propagate along the Bayesian network in ways that if you try to do it just kind of intuitively, you will probably, um, not be able to.",
    "start": "2764580",
    "end": "2772330"
  },
  {
    "text": "Okay. So let me summarize so far what we've done.",
    "start": "2774250",
    "end": "2780930"
  },
  {
    "start": "2776000",
    "end": "2847000"
  },
  {
    "text": "So we've introduced Bayesian networks, where we have random variables that capture the state of the world.",
    "start": "2780930",
    "end": "2787710"
  },
  {
    "text": "And we have edges between those variables that represent dependencies between, um, those variables.",
    "start": "2787710",
    "end": "2794670"
  },
  {
    "text": "And, um, based on those dependencies, we go and define local conditional distributions,",
    "start": "2794670",
    "end": "2800475"
  },
  {
    "text": "you multiply all those local conditional distributions, you get a joint distribution. Now, with that joint distribution,",
    "start": "2800475",
    "end": "2806114"
  },
  {
    "text": "by laws of probability you can go and ask probabilistic inference queries and ask questions about the world, um, given evidence.",
    "start": "2806114",
    "end": "2813810"
  },
  {
    "text": "And we saw that this captures interesting reasoning patterns such as explaining a way.",
    "start": "2813810",
    "end": "2819930"
  },
  {
    "text": "And finally, all of this can be, uh, brought under the umbrella of",
    "start": "2819930",
    "end": "2825000"
  },
  {
    "text": "the factor graph interpretation which we will see is very useful for, um, actually doing probabilistic inference in general, in a bit.",
    "start": "2825000",
    "end": "2833370"
  },
  {
    "text": "Okay. So any questions before I move on to the next section?",
    "start": "2833370",
    "end": "2837970"
  },
  {
    "text": "Okay. So now, I'm gonna talk about probabilistic programs.",
    "start": "2844730",
    "end": "2850080"
  },
  {
    "start": "2847000",
    "end": "2862000"
  },
  {
    "text": "So this is going to be, um, kind of, a little bit of a whirlwind tour and hopefully give you different perspectives,",
    "start": "2850080",
    "end": "2857475"
  },
  {
    "text": "um, and open your eyes to, kind of, the possibilities of Bayesian networks. Um, so let's look at this alarm network again.",
    "start": "2857475",
    "end": "2866519"
  },
  {
    "start": "2862000",
    "end": "3040000"
  },
  {
    "text": "I can write it as on the board, um, just a product of all the local conditional probabilities,",
    "start": "2866520",
    "end": "2873030"
  },
  {
    "text": "basically use math or I can think about this as a probabilistic program.",
    "start": "2873030",
    "end": "2878055"
  },
  {
    "text": "Okay. So what I'm gonna write down is a program that it's a very simple program,",
    "start": "2878055",
    "end": "2883770"
  },
  {
    "text": "um, it has three lines, one for every, uh, variable. And the first line is B is,",
    "start": "2883770",
    "end": "2890415"
  },
  {
    "text": "uh, drawn from Bernoulli Epsilon. So this notation just means B is set to, uh,",
    "start": "2890415",
    "end": "2896549"
  },
  {
    "text": "a random value that has, uh, distribution Bernoulli Epsilon, and same with, uh, earthquake.",
    "start": "2896550",
    "end": "2902565"
  },
  {
    "text": "And then finally I set A equals B or E. Okay. Um, and, uh, so the idea here is that a probabilistic program is just",
    "start": "2902565",
    "end": "2912450"
  },
  {
    "text": "simply a program with randomness in it that when you run, sets the random variables.",
    "start": "2912450",
    "end": "2919079"
  },
  {
    "text": "So this is I, I think a really useful way to think about, um, Bayesian networks.",
    "start": "2919080",
    "end": "2924780"
  },
  {
    "text": "And just to be very concrete about this, so you can think about Bernoulli of Epsilon as just a Python program that just returns,",
    "start": "2924780",
    "end": "2933433"
  },
  {
    "text": "uh, true with a probability Epsilon. So here, random less than Epsilon,",
    "start": "2933434",
    "end": "2938730"
  },
  {
    "text": "the random is a number between 0 and 1, has a probability of Epsilon being less than Epsilon.",
    "start": "2938730",
    "end": "2944200"
  },
  {
    "text": "Okay. Any questions about the- what this is doing? Yeah.",
    "start": "2944240",
    "end": "2950880"
  },
  {
    "text": "Why does the randomness help rather than [inaudible] So the question is why does randomness help?",
    "start": "2950880",
    "end": "2957300"
  },
  {
    "text": "Um, the, the reason is that I want this program to be, put a distribution over possible assignments.",
    "start": "2957300",
    "end": "2965880"
  },
  {
    "text": "Every time I run the program, it's gonna produce a different assignment. And the distribution over that assignment is the distribution that I'm defining.",
    "start": "2965880",
    "end": "2975224"
  },
  {
    "text": "So, so, so this is a kind of an interesting philosophical point. So normally you run programs and wr- write",
    "start": "2975225",
    "end": "2981660"
  },
  {
    "text": "programs with the intention of running them and do, do something useful. But here the re- programs are just a kind of artif- artifact to define a distribution.",
    "start": "2981660",
    "end": "2992505"
  },
  {
    "text": "Uh, hopefully this will become a little bit clearer as I go through more examples. Yeah. Uh, if you want to define some distribution,",
    "start": "2992505",
    "end": "2999329"
  },
  {
    "text": "can you just, uh, can you find like hard-code the table instead of doing this. I mean you can just hard-code Epsilon into your table instead of like",
    "start": "2999330",
    "end": "3006875"
  },
  {
    "text": "maybe like writing this program [inaudible] Epsilon? Yeah. So the question is why don't you just, uh,",
    "start": "3006875",
    "end": "3012995"
  },
  {
    "text": "hard-code- define a table directly, um, instead of running this program?",
    "start": "3012995",
    "end": "3018230"
  },
  {
    "text": "So the intention here again is not to run this program because it's not an efficient way to do a probabilistic inference,",
    "start": "3018230",
    "end": "3024560"
  },
  {
    "text": "but it's more of a, a metaphor or a tool to help you get more intuition about,",
    "start": "3024560",
    "end": "3030170"
  },
  {
    "text": "um, probabilistic, uh, programs in Bayesian networks. So hopefully, we, we can, uh,",
    "start": "3030170",
    "end": "3035495"
  },
  {
    "text": "come back to this question after I go through a few more examples. So here's a more interesting probabilistic program.",
    "start": "3035495",
    "end": "3041930"
  },
  {
    "start": "3040000",
    "end": "3152000"
  },
  {
    "text": "So suppose you're doing object, um, tracking and you define a program which starts with X_0 equals 0, 0.",
    "start": "3041930",
    "end": "3050735"
  },
  {
    "text": "So the initial location is at the origin, and then for every time-step, um, so I'm writing the program in kind of pseudocode here.",
    "start": "3050735",
    "end": "3058099"
  },
  {
    "text": "Um, with probability Alpha, i set X_i equals X_i minus 1 plus 1, 0,",
    "start": "3058100",
    "end": "3063380"
  },
  {
    "text": "so I'm going to the right, and with probability 1 minus Alpha I'm going down. Okay. So, um, now this program, you know, that I just described, um,",
    "start": "3063380",
    "end": "3074464"
  },
  {
    "text": "it induces a particular Bayesian network structure where each x_i is only connected to x_i minus 1.",
    "start": "3074465",
    "end": "3082115"
  },
  {
    "text": "Okay. So what I'm trying to ge- get you to think about is there's multiple ways of thinking about the same object.",
    "start": "3082115",
    "end": "3088460"
  },
  {
    "text": "And I think when you get- when you can kind of internalize all these things, you kind of get a deeper understanding of what you're dealing with, right?",
    "start": "3088460",
    "end": "3096290"
  },
  {
    "text": "We have the probabilistic, uh, view, uh, viewpoint. You can look at the tables, you have, you know, your equations, you have this graph and now I'm giving you an additional tool, uh, the programs.",
    "start": "3096290",
    "end": "3105350"
  },
  {
    "text": "Okay. So just for fun, um, you can actually run this program. Again, this is not what you would do normally but,",
    "start": "3105350",
    "end": "3113750"
  },
  {
    "text": "um, I can run the program in any case. So every time I hit Enter, um, this gives you a different trajectory.",
    "start": "3113750",
    "end": "3121460"
  },
  {
    "text": "So this is a way to visualize the distribution over proba- uh,",
    "start": "3121460",
    "end": "3127025"
  },
  {
    "text": "X_1 through X, um, whatever how many of- many, uh, red squares are.",
    "start": "3127025",
    "end": "3133415"
  },
  {
    "text": "Okay. And if I change Alpha, that gives me distributions which are either skewed to one side or the other side.",
    "start": "3133415",
    "end": "3141110"
  },
  {
    "text": "Um, so that's the distribution over,",
    "start": "3141110",
    "end": "3145740"
  },
  {
    "text": "uh, um, programs, oh sorry, distribution over assignments.",
    "start": "3146530",
    "end": "3152120"
  },
  {
    "start": "3152000",
    "end": "3328000"
  },
  {
    "text": "Okay. So what does probabilistic inference look like in this setting? So remember, what is probabilistic inference?",
    "start": "3152120",
    "end": "3158330"
  },
  {
    "text": "I'm conditioning on some piece of evidence and I'm asking for the distribution over some other set of variables.",
    "start": "3158330",
    "end": "3164780"
  },
  {
    "text": "So in case, in this case I'm conditioning on the fact that I spotted X of the object at 8 ,2 at time step x_10, that's it.",
    "start": "3164780",
    "end": "3174185"
  },
  {
    "text": "And I'm interested where it could have been before that. So, um, here what I'm gonna do is I'm gonna run",
    "start": "3174185",
    "end": "3182270"
  },
  {
    "text": "the former program and I'm only gonna keep those trajectories and show it if X_10 equals 8,2.",
    "start": "3182270",
    "end": "3188870"
  },
  {
    "text": "So if I do that, I'm gonna- so this is 8 ,2. Um, I'm seeing that the set of,",
    "start": "3188870",
    "end": "3195980"
  },
  {
    "text": "uh, possible trajectories look like this. So this is the distribution over,",
    "start": "3195980",
    "end": "3201875"
  },
  {
    "text": "um, trajectories given X_10 equals 8, 2.",
    "start": "3201875",
    "end": "3207210"
  },
  {
    "text": "Okay. So it's important- what I'm trying to get you to think about is that Bayesian network or probabilistic program as,",
    "start": "3209450",
    "end": "3217380"
  },
  {
    "text": "what is the distribution? You can visualize the distributions by looking at samples from that distribution.",
    "start": "3217380",
    "end": "3224040"
  },
  {
    "text": "It's another way to think about it. Right, because distributions are, um, think about like, ah,",
    "start": "3224040",
    "end": "3230580"
  },
  {
    "text": "suppose you have a dish- I tell you I have a distribution over images, and how do you actually get a hold of that or understand that?",
    "start": "3230580",
    "end": "3237075"
  },
  {
    "text": "Well, probably the easier- easiest way is to draw samples from it and look at kind of the types of images that you get. Question?",
    "start": "3237075",
    "end": "3244494"
  },
  {
    "text": "Is this the way to specify a distribution, are they like- is this a way to specify distribution [inaudible].",
    "start": "3244495",
    "end": "3250460"
  },
  {
    "text": "Uh, so question is, is this way a way of specifying a joint distribution?",
    "start": "3250460",
    "end": "3256470"
  },
  {
    "text": "By this I mean- I guess you mean the- ah, so probabilistic programming in general.",
    "start": "3256470",
    "end": "3261780"
  },
  {
    "text": "It is so- so for every probabilistic pro-, um, program, it specifies a joint distribution",
    "start": "3261780",
    "end": "3270510"
  },
  {
    "text": "over the random variables that you set in that program. And vice versa. If I have a Bayesian network,",
    "start": "3270510",
    "end": "3277740"
  },
  {
    "text": "I can write down a probabilistic program. Um, one thing as you'll hopefully become clear is that,",
    "start": "3277740",
    "end": "3284400"
  },
  {
    "text": "the reason to think about in terms of programs is that you can inherit all the nice properties of programs like,",
    "start": "3284400",
    "end": "3291120"
  },
  {
    "text": "the ability to define functions, or even have recursion, or, you know, you could do a lot more,",
    "start": "3291120",
    "end": "3296655"
  },
  {
    "text": "um, fancy stuff with programs that you can't do what- I mean which will be hard to do.",
    "start": "3296655",
    "end": "3302835"
  },
  {
    "text": "You can think about Bayesian networks as another way to think about is like, okay you're basically writing assembly code right, for every, ah, um,",
    "start": "3302835",
    "end": "3310755"
  },
  {
    "text": "variable you specify its value, but if you have a million value- variables,",
    "start": "3310755",
    "end": "3316260"
  },
  {
    "text": "sometimes it's useful to be able to structure, um, your- your code in some way.",
    "start": "3316260",
    "end": "3322455"
  },
  {
    "text": "We- we'll see that over the next few examples. Okay. So this is going to be a march of I think around seven possible,",
    "start": "3322455",
    "end": "3328800"
  },
  {
    "start": "3328000",
    "end": "3375000"
  },
  {
    "text": "um or so possible examples, and I just wanna give you a flavor of types of probabilistic programs that we're talking about here.",
    "start": "3328800",
    "end": "3335535"
  },
  {
    "text": "So the first one is called, ah, just a Markov and- by- whenever I say probabilistic program think Bayesian networks or,",
    "start": "3335535",
    "end": "3342195"
  },
  {
    "text": "um, generalizations of that. So Markov model, um, so this has a lot of applications in,",
    "start": "3342195",
    "end": "3350085"
  },
  {
    "text": "um, you know, modeling language or time series. And, ah, the program works as follows,",
    "start": "3350085",
    "end": "3356670"
  },
  {
    "text": "for every position i through n, I'm gonna generate a particular, ah, word X_i, given the previous word.",
    "start": "3356670",
    "end": "3365025"
  },
  {
    "text": "Okay. So this is also happens to be the same type of program as for the object tracking.",
    "start": "3365025",
    "end": "3370289"
  },
  {
    "text": "Okay? So this is this Bayesian network structure. Um, so here's another one.",
    "start": "3370290",
    "end": "3375809"
  },
  {
    "start": "3375000",
    "end": "3478000"
  },
  {
    "text": "This is called the Hidden Markov model which, um, is, ah, was a very popular, ah,",
    "start": "3375810",
    "end": "3383250"
  },
  {
    "text": "model that was, um, used, ah, for all sorts of things like speech recognition notably before,",
    "start": "3383250",
    "end": "3390690"
  },
  {
    "text": "um, the rise of deep learning. Ah, so the idea here is that for every time step T equals 1 to",
    "start": "3390690",
    "end": "3398700"
  },
  {
    "text": "T. I'm gonna generate an object with location HT given the previous HT minus 1.",
    "start": "3398700",
    "end": "3404670"
  },
  {
    "text": "So this part is, just looks like a Markov model. Okay. But the- the reason",
    "start": "3404670",
    "end": "3411569"
  },
  {
    "text": "why it's called a Hidden Markov Model is that I'm not actually gonna observe HT, I'm gonna observe sensor readings ET at each time step T given,",
    "start": "3411570",
    "end": "3420060"
  },
  {
    "text": "ah, the hidden location. Okay. So this is what a hidden Markov model looks like.",
    "start": "3420060",
    "end": "3425609"
  },
  {
    "text": "Sequence of object locations [NOISE] which I don't observe and sensor readings which I do observe,",
    "start": "3425610",
    "end": "3431625"
  },
  {
    "text": "which depend respectively on the given object, ah, locations. And just as a convention,",
    "start": "3431625",
    "end": "3438390"
  },
  {
    "text": "whenever I shade a variable, that means I, you know, observe it and if it's not shaded, that means I don't observe it.",
    "start": "3438390",
    "end": "3445210"
  },
  {
    "text": "Okay. So this program defines a joint distribution over all of these variables.",
    "start": "3445550",
    "end": "3451845"
  },
  {
    "text": "And now you can ask a particular question, you can do probabilistic inference. And the most, um,",
    "start": "3451845",
    "end": "3458115"
  },
  {
    "text": "common thing that people do here is, given the sensor readings, where is this object?",
    "start": "3458115",
    "end": "3464595"
  },
  {
    "text": "Which is something we've already been exposed to through the lens of factor graphs but this is again a way to think about it,",
    "start": "3464595",
    "end": "3472230"
  },
  {
    "text": "um, through the lens of, um, vision algorithms. So now, ah, with this kind of programming metaphor,",
    "start": "3472230",
    "end": "3480210"
  },
  {
    "start": "3478000",
    "end": "3549000"
  },
  {
    "text": "you can actually do, ah, kinda more complicated things in a very kind of succinct way.",
    "start": "3480210",
    "end": "3485520"
  },
  {
    "text": "So to describe, uh, multiple object tracking, you can think about, ah,",
    "start": "3485520",
    "end": "3492135"
  },
  {
    "text": "there being two objects A and B, and each position, um,",
    "start": "3492135",
    "end": "3498945"
  },
  {
    "text": "at each time step and every object I'm gonna generate a location for the object, and this is going to be two independent, um,",
    "start": "3498945",
    "end": "3506730"
  },
  {
    "text": "Markov chains which are running, but the thing is that, at each time step,",
    "start": "3506730",
    "end": "3513180"
  },
  {
    "text": "I only observe one sensor reading and that sensor reading is going to be some combination- some function of the actual locations of objects at that particular time step.",
    "start": "3513180",
    "end": "3524085"
  },
  {
    "text": "Okay. So now hopefully you can see a little bit of the vantage of thinking in terms of a program because I can write this kind of very simple four-line program that,",
    "start": "3524085",
    "end": "3533099"
  },
  {
    "text": "um, very precisely nails down what the actual, you know, model is.",
    "start": "3533100",
    "end": "3538245"
  },
  {
    "text": "Um, and in particular this factorial HM, as it's called, is something that you're gonna be exploring in your- the car assignment.",
    "start": "3538245",
    "end": "3546520"
  },
  {
    "text": "Um, here's another example, so this is, ah, for- usually used for cla- classification.",
    "start": "3547250",
    "end": "3554609"
  },
  {
    "start": "3549000",
    "end": "4899000"
  },
  {
    "text": "It's called naive Bayes. Some of you might have heard of it. Um, and the program looks like this.",
    "start": "3554610",
    "end": "3559950"
  },
  {
    "text": "You first generate a label Y. Um, let's suppose you generate travel.",
    "start": "3559950",
    "end": "3565410"
  },
  {
    "text": "And now you're gonna- for every word in your, ah, document, you're gonna generate a word,",
    "start": "3565410",
    "end": "3571575"
  },
  {
    "text": "um, given that label. So if you generate travel, you may generate words like beach in Paris.",
    "start": "3571575",
    "end": "3577875"
  },
  {
    "text": "Um, so now the- that again specifies a distribution over all the variables, what are you typically interested in?",
    "start": "3577875",
    "end": "3586724"
  },
  {
    "text": "If you're interested in classification, you're given the words and now you wanna go back and,",
    "start": "3586725",
    "end": "3592259"
  },
  {
    "text": "uh, figure out what the, the-, um, the class is. You're given a text document, what is, ah, the label?",
    "start": "3592260",
    "end": "3600070"
  },
  {
    "text": "Um, here's a fancier, ah, model of documents called Latent Dirichlet allocation.",
    "start": "3600350",
    "end": "3606900"
  },
  {
    "text": "Um, so here instead of how to generate a single topic, I'm gonna generate a distribution over topics.",
    "start": "3606900",
    "end": "3614310"
  },
  {
    "text": "This is getting a little bit meta because this random variable in itself is actually a distribution but, you know, let's not worry too much about that.",
    "start": "3614310",
    "end": "3620880"
  },
  {
    "text": "So this- this is a distribution, um, and for every position I'm going to first generate a topic like travel or Europe.",
    "start": "3620880",
    "end": "3630420"
  },
  {
    "text": "And then for that, ah, topic I'm gonna generate a word given that topic.",
    "start": "3630420",
    "end": "3635745"
  },
  {
    "text": "Okay. So this allows you to model documents which talk about multiple things, for example, traveling Europe.",
    "start": "3635745",
    "end": "3643065"
  },
  {
    "text": "Okay. So this is also a very popular model that can be used to, if you're given a collection of documents trying to understand,",
    "start": "3643065",
    "end": "3650579"
  },
  {
    "text": "understand the, ah, latent structure inside it. Um, [NOISE] so here's one that's kinda a generalization of the, uh,",
    "start": "3650580",
    "end": "3659505"
  },
  {
    "text": "the medical diagnostics, um, um, uh, example on the board.",
    "start": "3659505",
    "end": "3664875"
  },
  {
    "text": "So in general let's say you have a bunch of diseases. Um, you generate the activity of a particular dis- disease in a patient,",
    "start": "3664875",
    "end": "3673095"
  },
  {
    "text": "um, according to some, you know, prior distribution. And now you- for every symptom that, um,",
    "start": "3673095",
    "end": "3679289"
  },
  {
    "text": "you might obs- observe or any sort of lab test you have the probability of some outcome of that symptom given the diseases.",
    "start": "3679290",
    "end": "3688635"
  },
  {
    "text": "And of course, the probabilistic inference question here is, if the patient has particular symptoms,",
    "start": "3688635",
    "end": "3695609"
  },
  {
    "text": "what kind of diseases, ah, does or problems does he or she have?",
    "start": "3695610",
    "end": "3701235"
  },
  {
    "text": "Okay? So I think this is f- maybe the final example. Um, here is a social network analysis example where,",
    "start": "3701235",
    "end": "3708510"
  },
  {
    "text": "um, you have, um, a set of people, each person has ah,",
    "start": "3708510",
    "end": "3714885"
  },
  {
    "text": "you know, qua- a type, maybe a politician or a scientist. Um, and these- for every pair of people,",
    "start": "3714885",
    "end": "3724620"
  },
  {
    "text": "ah, they can either interact or not interact. They might be connected or not connected,",
    "start": "3724620",
    "end": "3730980"
  },
  {
    "text": "let's say in a social network. And so in the end what you're given is a social network of, ah,",
    "start": "3730980",
    "end": "3738495"
  },
  {
    "text": "connectivity and you're asked, what kind of types of people are there?",
    "start": "3738495",
    "end": "3744410"
  },
  {
    "text": "So generally, you, you observe maybe some graph, and you want to understand, um, you know,",
    "start": "3744410",
    "end": "3750920"
  },
  {
    "text": "what kind of features or, ah, you know, what is- what is a concrete way of summarizing the types of people there are.",
    "start": "3750920",
    "end": "3758640"
  },
  {
    "text": "And there's- this called a stochastic block model but there's other kinda fancier models that are based on a similar idea.",
    "start": "3758640",
    "end": "3765250"
  },
  {
    "text": "So that was a very quick, um, you know, overview of different types of probabilistic programs or Bayesian networks.",
    "start": "3766190",
    "end": "3774090"
  },
  {
    "text": "And there- the point is that there are many many different types of models that can be written down in the literature.",
    "start": "3774090",
    "end": "3780359"
  },
  {
    "text": "Many things, generative models can be just written down in a probabilistic program or equivalently a Bayesian network.",
    "start": "3780360",
    "end": "3786960"
  },
  {
    "text": "Um, and all of them kind of have this kinda basic structure. If you observe carefully,",
    "start": "3786960",
    "end": "3792925"
  },
  {
    "text": "all of them kind of look like that whereas there's some set of variables H, um,",
    "start": "3792925",
    "end": "3798080"
  },
  {
    "text": "which you don't observe, and that generates or causes, um, a set of variables E,",
    "start": "3798080",
    "end": "3804829"
  },
  {
    "text": "which you do observe. So the mindset when you're designing Bayesian networks is,",
    "start": "3804830",
    "end": "3809990"
  },
  {
    "text": "you're coming up with stories of how the data which you- what you observed was generated through the quantities of interest, the output.",
    "start": "3809990",
    "end": "3819724"
  },
  {
    "text": "So this is probably kind of maybe counter-intuitive and for",
    "start": "3819725",
    "end": "3825060"
  },
  {
    "text": "those of you who are really used to thinking about just normal classification where you- it's the opposite.",
    "start": "3825060",
    "end": "3830340"
  },
  {
    "text": "You start with the input and you think about, what are things to do to the input that it can, ah, you know,",
    "start": "3830340",
    "end": "3836400"
  },
  {
    "text": "what kind of things can I do to get it to a point where I can, you know, classify the input precisely?",
    "start": "3836400",
    "end": "3843599"
  },
  {
    "text": "But Bayesian networks kind of go the opposite. Um, it starts with the output or the structure is interested in which",
    "start": "3843600",
    "end": "3850500"
  },
  {
    "text": "are presumably kinda more- kinda a platonic idea or something cleaner,",
    "start": "3850500",
    "end": "3856065"
  },
  {
    "text": "and then you're trying to describe how that clean data gets- gives rise to this kinda messy-sorry,",
    "start": "3856065",
    "end": "3864060"
  },
  {
    "text": "the clean structure give rise to the messy data that you observe. Question? Can you explain again why it's called the output?",
    "start": "3864060",
    "end": "3872265"
  },
  {
    "text": "Right. So- why is, uh, this called the output? Um, so I'm using input output here in-",
    "start": "3872265",
    "end": "3879540"
  },
  {
    "text": "to borrow terminology for when we talked about classification, where you're going from input to output.",
    "start": "3879540",
    "end": "3884625"
  },
  {
    "text": "Input is what you are given and output is what you're outputting, I guess, producing.",
    "start": "3884625",
    "end": "3892455"
  },
  {
    "text": "Right? And in the, the Bayesian network, you first define the model, kind of going from output to input.",
    "start": "3892455",
    "end": "3899849"
  },
  {
    "text": "So kind of the opposite of what you would normally do. And now, now there's a second stage,",
    "start": "3899850",
    "end": "3904859"
  },
  {
    "text": "where you do probablistic inference, which reverses that. And you go from the observations,",
    "start": "3904860",
    "end": "3910619"
  },
  {
    "text": "which are the input to the output which is right. [NOISE] Okay?",
    "start": "3910620",
    "end": "3919125"
  },
  {
    "text": "Any other questions about this? [NOISE] All right.",
    "start": "3919125",
    "end": "3928710"
  },
  {
    "text": "So now let's talk about inference. Um, this is also gonna be the topic of next lecture but I'm just gonna start,",
    "start": "3928710",
    "end": "3936390"
  },
  {
    "text": "[NOISE] um, [NOISE] playing around with this a little bit. So remember what is probabilistic inference?",
    "start": "3936390",
    "end": "3943725"
  },
  {
    "text": "We're given a Bayesian network, define some joint [NOISE] distribution. We're also given some setting of the variables,",
    "start": "3943725",
    "end": "3950775"
  },
  {
    "text": "which are the evidence, for example I saw that the alarm went off, um, and [NOISE] I'm interested in a subset of the variables.",
    "start": "3950775",
    "end": "3957900"
  },
  {
    "text": "[NOISE] Okay. So what I'm trying to ch- produce is, a probability of some query variables conditioned on evidence and what this really means,",
    "start": "3957900",
    "end": "3967380"
  },
  {
    "text": "is I want this for all values [NOISE] of, um, the query variables. Okay. So for example,",
    "start": "3967380",
    "end": "3975435"
  },
  {
    "text": "if I have coughing, I have itchy eyes or I have a cold. It's an example of a probabilistic inference query.",
    "start": "3975435",
    "end": "3980549"
  },
  {
    "text": "[NOISE] Okay. So let's start with this simple example.",
    "start": "3980550",
    "end": "3985665"
  },
  {
    "text": "Suppose I have this Markov model and I asked this query, what is the probability of X_3,",
    "start": "3985665",
    "end": "3990839"
  },
  {
    "text": "[NOISE] given X_2 equals 5? So condition X equals 5, I'm interested in X_3.",
    "start": "3990840",
    "end": "3996660"
  },
  {
    "text": "Um, so at this point, you already have the tools to do this, um,",
    "start": "3996660",
    "end": "4002060"
  },
  {
    "text": "and I'm gonna show you how you can just, uh, go through the calculations and then I'm gonna show you an easier way to do this.",
    "start": "4002060",
    "end": "4010115"
  },
  {
    "text": "So if you were just shown this right now, this is probably what you would, um,",
    "start": "4010115",
    "end": "4016055"
  },
  {
    "text": "do which might be a little bit tedious, uh, so by laws of probability, this,",
    "start": "4016055",
    "end": "4021770"
  },
  {
    "text": "uh, this conditioning is equal to the joint over this, um, marginal case.",
    "start": "4021770",
    "end": "4027470"
  },
  {
    "text": "[NOISE] This is just by definition [NOISE] of conditional probability. Um, and, uh, one thing I'm gonna do here is,",
    "start": "4027470",
    "end": "4038119"
  },
  {
    "text": "um, notice that I'm only interested in distributions of X_3. So from that perspective,",
    "start": "4038120",
    "end": "4043820"
  },
  {
    "text": "this blo- denominator is just a constant. [NOISE] It doesn't depend on X_3. So what I'm gonna [NOISE] write is this proportional to, which means that,",
    "start": "4043820",
    "end": "4052414"
  },
  {
    "text": "the actual value here is this thing on the right-hand side times some constant which, um, I don't care about.",
    "start": "4052415",
    "end": "4059300"
  },
  {
    "text": "And the reason I can do this and I don't care about is because I know that, um, the left-hand side is the distribution,",
    "start": "4059300",
    "end": "4065900"
  },
  {
    "text": "so whatever I get on the right-hand [NOISE] side, if it sums to 6 or something, then I just divide by 6 and I get a distribution.",
    "start": "4065900",
    "end": "4072590"
  },
  {
    "text": "Okay. So this is gonna save you a lot of work [NOISE] if you use a proportional to sign. But you have to use it carefully,",
    "start": "4072590",
    "end": "4079190"
  },
  {
    "text": "otherwise you can get wrong answers. [NOISE] Okay. So let's expand this.",
    "start": "4079190",
    "end": "4084380"
  },
  {
    "text": "So this is a marginal distribution of X_2 and X_3. Um, I can write it in terms of the joint,",
    "start": "4084380",
    "end": "4090410"
  },
  {
    "text": "where I sum over the variables that I don't care about. So there's again, laws of probability [NOISE] um,",
    "start": "4090410",
    "end": "4096859"
  },
  {
    "text": "and then the definition of the Bayesian network here, is a joint distribution is equal to the product or local conditional distributions.",
    "start": "4096860",
    "end": "4106580"
  },
  {
    "text": "So right now, I have a lowercase p now because there're local distributions.",
    "start": "4106580",
    "end": "4111665"
  },
  {
    "text": "Um, now I'm gonna do some algebraic manipulation. So notice that, um,",
    "start": "4111665",
    "end": "4117665"
  },
  {
    "text": "this stuff doesn't depend on X_4. So I can push the summation of X_4 over here and then these two first two terms,",
    "start": "4117665",
    "end": "4126845"
  },
  {
    "text": "um, [NOISE] uh, only these first two terms depend on X_1. So I can group this and to [NOISE] have the sum [NOISE] over X_1 apply here and then,",
    "start": "4126845",
    "end": "4138980"
  },
  {
    "text": "I can look over here and use, what does this sum to? One. So I can drop it and then, what is this?",
    "start": "4138980",
    "end": "4148220"
  },
  {
    "text": "Does this depend on X_3? Nope. So I can also drop that and I get a p of X_3 given X_2 equals 5.",
    "start": "4148220",
    "end": "4156665"
  },
  {
    "text": "Right? So this hopefully shouldn't be surprising to anyone because remember that slide where I said, uh,",
    "start": "4156665",
    "end": "4163790"
  },
  {
    "text": "consistency of local conditional distributions, this is- should be equal to this and this is just one way of verifying that.",
    "start": "4163790",
    "end": "4171214"
  },
  {
    "text": "That's actually the case for this example. Okay? Um, so, you know this was- you can do this.",
    "start": "4171215",
    "end": "4179600"
  },
  {
    "text": "I mean for this one, it's actually not that bad. Especially when you already know the answer. Um, but I promise you there are gonna be situations where you definitely don't want to",
    "start": "4179600",
    "end": "4186980"
  },
  {
    "text": "grind through all the math because you can fill up 10 pages of equations. Um, I'm gonna show you kind of a faster way to do this.",
    "start": "4186980",
    "end": "4194119"
  },
  {
    "text": "[NOISE] Um, and [NOISE] so let's start.",
    "start": "4194120",
    "end": "4199160"
  },
  {
    "text": "[NOISE] Okay. So this is going to be a five-step, [NOISE] uh, procedure.",
    "start": "4199160",
    "end": "4207110"
  },
  {
    "text": "But in many [NOISE] cases, not all the steps are necessary. Um, okay. So let me erase this.",
    "start": "4207110",
    "end": "4215700"
  },
  {
    "text": "And the key idea is going to be [NOISE] to use the structure of the Bayesian network,",
    "start": "4216490",
    "end": "4222650"
  },
  {
    "text": "um, and factor graphs, to simplify some of these operations. Okay? So, um, let's start with- okay,",
    "start": "4222650",
    "end": "4230540"
  },
  {
    "text": "so you have X_1, um, X_2, [NOISE] X_3, X_4.",
    "start": "4230540",
    "end": "4238340"
  },
  {
    "text": "Um, we just have four. Okay? All right. So- and I'm, um, [NOISE] conditioning on, um, X_2, right?",
    "start": "4238340",
    "end": "4246935"
  },
  {
    "text": "Okay. So X_2, uh, that takes on value 5. [NOISE] Okay. So [NOISE] um,",
    "start": "4246935",
    "end": "4253325"
  },
  {
    "text": "the f- and I'm interested in this, uh, query variable. So the first thing I want to do is,",
    "start": "4253325",
    "end": "4258710"
  },
  {
    "text": "[NOISE] I want to remove as many variables as I can. Um, I just- because that's gonna simplify [NOISE] my life.",
    "start": "4258710",
    "end": "4265070"
  },
  {
    "text": "So I'm going to remove or marginalize, um, non-ancestors [NOISE] of, uh,",
    "start": "4265070",
    "end": "4273500"
  },
  {
    "text": "the query and the variable I'm conditioning. [NOISE] So by non-ancestors,",
    "start": "4273500",
    "end": "4278990"
  },
  {
    "text": "I mean, um, anything that's upstream, I am gonna keep for now. Anything that's downstream, I can let go.",
    "start": "4278990",
    "end": "4285530"
  },
  {
    "text": "[NOISE] Okay. So what can I remove here? [NOISE]",
    "start": "4285530",
    "end": "4291920"
  },
  {
    "text": "X_4. X_4, right? So I can, um, let me show this.",
    "start": "4291920",
    "end": "4298655"
  },
  {
    "text": "So I can graphically just remove X_4. And that corresponds to on the slide,",
    "start": "4298655",
    "end": "4304340"
  },
  {
    "text": "basically the fact that this thing sums to 1. But I've done this again graphically, [NOISE] which hopefully should be, uh, more intuitive.",
    "start": "4304340",
    "end": "4311540"
  },
  {
    "text": "Okay. So the second step is, I'm going to [NOISE] convert to a factor graph [NOISE] um,",
    "start": "4311540",
    "end": "4322460"
  },
  {
    "text": "because, uh, one already takes care of- basically I'm exploiting the properties of Bayesian networks.",
    "start": "4322460",
    "end": "4332315"
  },
  {
    "text": "But after I've done one, um, [NOISE] I don't- it's simpler to think about as a factor graph,",
    "start": "4332315",
    "end": "4338450"
  },
  {
    "text": "where I want to think about [NOISE] the factors more explicitly as just arbitrary functions and not worry about",
    "start": "4338450",
    "end": "4345140"
  },
  {
    "text": "which way the conditioning is going because [NOISE] it's really easy to get confused by, um, Bayesian networks, where you're wondering like,",
    "start": "4345140",
    "end": "4351635"
  },
  {
    "text": "oh this is conditioning over here, wha- what's a marginal distribution and, um, factor graphs I think,",
    "start": "4351635",
    "end": "4357770"
  },
  {
    "text": "by actually [NOISE] removing the directionality and some semantics, actually make things a little bit easier.",
    "start": "4357770",
    "end": "4363845"
  },
  {
    "text": "Okay. So I'm gonna convert this into a factor graph, which means I have, um, let me actually just draw it down here again.",
    "start": "4363845",
    "end": "4371180"
  },
  {
    "text": "[NOISE] So here's a factor graph. Um, remember I have, uh, probability of X_1, um,",
    "start": "4371180",
    "end": "4378140"
  },
  {
    "text": "[NOISE] probability of X_2 given X_1, um. [NOISE]",
    "start": "4378140",
    "end": "4388060"
  },
  {
    "text": "So this might look like more, ah, work [NOISE] right now,",
    "start": "4388060",
    "end": "4393685"
  },
  {
    "text": "uh, because I'm making things explicit. Um, but you can actually do a lot of these things in your head",
    "start": "4393685",
    "end": "4399010"
  },
  {
    "text": "if you, um, get the hang of it. Okay? So remember, every variable has, uh,",
    "start": "4399010",
    "end": "4405610"
  },
  {
    "text": "is associated with a factor, um, okay. So now, I want to, um, you know,",
    "start": "4405610",
    "end": "4415290"
  },
  {
    "text": "condition [NOISE] on, on the, you know, evidence.",
    "start": "4415290",
    "end": "4421360"
  },
  {
    "text": "[NOISE] So I'm conditioning on x_2 equals 5. So remember what the conditioning does,",
    "start": "4421360",
    "end": "4427150"
  },
  {
    "text": "remember from last week's lecture. Conditioning just removes this, and changes the factors to be set to the value that,",
    "start": "4427150",
    "end": "4436540"
  },
  {
    "text": "that um, variable takes on. Yeah. Can [inaudible] x_4 in this? Sorry. Yeah. We shouldn't have x_4, good point. Okay.",
    "start": "4436540",
    "end": "4445255"
  },
  {
    "text": "We still have factor on that other side or, uh- This factor should be there. So x_4 is- this is the factor graph corresponding to that.",
    "start": "4445255",
    "end": "4453550"
  },
  {
    "text": "Yeah. Um, okay. So I'm conditioning on x_2,",
    "start": "4453550",
    "end": "4458650"
  },
  {
    "text": "so I wipe x_2 from the face of the earth, and I'm going to set this- change",
    "start": "4458650",
    "end": "4465310"
  },
  {
    "text": "this factor to be a partial evaluation of where I put our x equals to 5,",
    "start": "4465310",
    "end": "4470665"
  },
  {
    "text": "and this factor is x_2 equals 5 given x_1.",
    "start": "4470665",
    "end": "4476560"
  },
  {
    "text": "Okay? Um, so this connection is good. So now.",
    "start": "4476560",
    "end": "4481780"
  },
  {
    "text": "I, um, can marginalize out the disconnected components.",
    "start": "4481780",
    "end": "4486954"
  },
  {
    "text": "Um, and these are the components that I will- remember, I care about x_3.",
    "start": "4486955",
    "end": "4492805"
  },
  {
    "text": "So this stuff is disconnected so I don't care about it. So I'm just going to, um,",
    "start": "4492805",
    "end": "4498400"
  },
  {
    "text": "let's say you just cross it out. And that operation corresponds to the fact that,",
    "start": "4498400",
    "end": "4505915"
  },
  {
    "text": "you know, this thing over here. I just can drop because it's, uh, not related to x_3, it's just a constant.",
    "start": "4505915",
    "end": "4513020"
  },
  {
    "text": "Okay? So finally, um, the fifth step is actually,",
    "start": "4514680",
    "end": "4521409"
  },
  {
    "text": "uh, [NOISE] do work. Okay? So what does that mean?",
    "start": "4521410",
    "end": "4526920"
  },
  {
    "text": "Um, you might not be so likely to be left with just, you know, a single variable whether factor where,",
    "start": "4526920",
    "end": "4533970"
  },
  {
    "text": "where that's just the answer. Um, in that case, you actually have to, um,",
    "start": "4533970",
    "end": "4539890"
  },
  {
    "text": "actually compute, do the marginalization operations that we saw last week. In this case, we are fortunate that, um,",
    "start": "4539890",
    "end": "4547840"
  },
  {
    "text": "[NOISE] this factor, this actually represents a distribution of x_3, so that is just the answer to, you know, the problem.",
    "start": "4547840",
    "end": "4556344"
  },
  {
    "text": "Okay. But I'll go through some other examples where it's not as obvious.",
    "start": "4556345",
    "end": "4560930"
  },
  {
    "text": "Okay? So this is just a general strategy that I outlined on the board here.",
    "start": "4563910",
    "end": "4570025"
  },
  {
    "text": "And again, I think once you get kind of good at this, you can basically, the steps, um,",
    "start": "4570025",
    "end": "4578365"
  },
  {
    "text": "1 and 4 should be kind of very, um, kind of visual because you can just see,",
    "start": "4578365",
    "end": "4586405"
  },
  {
    "text": "uh, well, all everything downstream just to be clear, it doesn't matter. And when you see these,",
    "start": "4586405",
    "end": "4591700"
  },
  {
    "text": "um, [NOISE] these are, you know, conditioning things, you can kind of automatically just not ignore things and just jump directly to 5.",
    "start": "4591700",
    "end": "4599710"
  },
  {
    "text": "So that's the idea. I am just doing things that are more explicitly on the board so you can kind of see where things are coming from.",
    "start": "4599710",
    "end": "4606530"
  },
  {
    "text": "Okay. So, um, I'm gonna do another example. Um, this is the alarm.",
    "start": "4606750",
    "end": "4613300"
  },
  {
    "text": "[NOISE] So, uh, here, I have this vision network, and I- let's suppose I'm interested in probability of B.",
    "start": "4613300",
    "end": "4620590"
  },
  {
    "text": "Okay. So this should be an easy one. So s- start with one, marginalize out non-answers.",
    "start": "4620590",
    "end": "4626739"
  },
  {
    "text": "So which are the non-answers of B? So A and E, right?",
    "start": "4626740",
    "end": "4633925"
  },
  {
    "text": "So I just removed them from the face of the earth, and I'm just left with the single, uh, variable B.",
    "start": "4633925",
    "end": "4639849"
  },
  {
    "text": "And obviously, it has a factor of p of B, and then I'm done. Okay? Okay. So this one's maybe a little bit more,",
    "start": "4639850",
    "end": "4647889"
  },
  {
    "text": "um, you know, complicated. So this is the probability of earth,",
    "start": "4647890",
    "end": "4653429"
  },
  {
    "text": "uh, sorry, burglary, we've given A equals 1. Um, so let's go through this example.",
    "start": "4653430",
    "end": "4659550"
  },
  {
    "text": "[NOISE] Um, I'll try to do it quickly. All right.",
    "start": "4659550",
    "end": "4664800"
  },
  {
    "text": "[NOISE] So I have, um, B, E, and A. Um, okay.",
    "start": "4664800",
    "end": "4675075"
  },
  {
    "text": "So marginalize out non-ancestors. So what am I interested in? I'm interested in the probability of,",
    "start": "4675075",
    "end": "4680290"
  },
  {
    "text": "ah, B given A equals 1. Okay? So I have A and B that I care about.",
    "start": "4680290",
    "end": "4685390"
  },
  {
    "text": "So what are the [NOISE] non-ancestor of these variables? There's none. [NOISE] Right.",
    "start": "4685390",
    "end": "4691030"
  },
  {
    "text": "So this is the non ancestor of A, so I can't remove it. So I can't do anything there, too bad. Convert to your factor graph.",
    "start": "4691030",
    "end": "4697060"
  },
  {
    "text": "We've done this before. Probability of B, um, moralized the parents.",
    "start": "4697060",
    "end": "4706030"
  },
  {
    "text": "[NOISE] So this is probability of A given B and E, and then this is probability of E. Okay.",
    "start": "4706030",
    "end": "4714550"
  },
  {
    "text": "Um, condition on the evidence now. So I conditioned on A equals, uh, 1.",
    "start": "4714550",
    "end": "4720790"
  },
  {
    "text": "So I'm gonna remove this and change this factor to A equals 1 [NOISE] given, uh,",
    "start": "4720790",
    "end": "4726445"
  },
  {
    "text": "B and E. Uh, fourth step is marginalize out anything that's [NOISE] disconnected.",
    "start": "4726445",
    "end": "4732909"
  },
  {
    "text": "Uh, nothing's disconnected. So I can't do anything. And last, I have to do actual work. Okay. So what does actual work mean here?",
    "start": "4732910",
    "end": "4740875"
  },
  {
    "text": "I'm interested in the probability of B. So I need a marginalize out E. Now,",
    "start": "4740875",
    "end": "4745929"
  },
  {
    "text": "I have to do this kind of a hard way, um, based on last time, uh, last lecture. So, um, what I'm gonna do here is,",
    "start": "4745930",
    "end": "4753670"
  },
  {
    "text": "you know, what happens when I marginalize out E? I create a new factor. Let, let me actually replicate this down here,",
    "start": "4753670",
    "end": "4761995"
  },
  {
    "text": "so it doesn't get too confusing. Um, so I'll create a new factor, and this new factor that's called f of b,",
    "start": "4761995",
    "end": "4770574"
  },
  {
    "text": "um, which is the Markov [NOISE] negative E, there's only one other variable B. And this is going to be the product of",
    "start": "4770575",
    "end": "4778090"
  },
  {
    "text": "all the factors here that touched this variable that I'm marginalizing out.",
    "start": "4778090",
    "end": "4783730"
  },
  {
    "text": "And the only difference between this and what we are doing last time is before we had a max,",
    "start": "4783730",
    "end": "4789310"
  },
  {
    "text": "because we're doing maximum weight assignments, [NOISE] and here, I'm going to have a sum because we're doing probabilities in marginalizing.",
    "start": "4789310",
    "end": "4796554"
  },
  {
    "text": "So this is going to be, uh, a summation over E. Okay.",
    "start": "4796555",
    "end": "4801820"
  },
  {
    "text": "And then the final query is going to be, uh, just the product of those two things.",
    "start": "4801820",
    "end": "4808630"
  },
  {
    "text": "Okay. Um, I'm not gonna have time to actually drill down into expanding these values.",
    "start": "4808630",
    "end": "4815935"
  },
  {
    "text": "Um, but if you actually, uh, plug-in Epsilons into these, um,",
    "start": "4815935",
    "end": "4821140"
  },
  {
    "text": "then you'll find that the probability of B equals 1, given, um,",
    "start": "4821140",
    "end": "4829315"
  },
  {
    "text": "A equals 1 is 1 over 2 minus Epsilon which is,",
    "start": "4829315",
    "end": "4836005"
  },
  {
    "text": "um, remember, 0.51 is for Epsilon equals 0.05.",
    "start": "4836005",
    "end": "4841495"
  },
  {
    "text": "Okay. But this calculation, um, you know, you can look into the slides to see how this is actually done but it is just algebra.",
    "start": "4841495",
    "end": "4849115"
  },
  {
    "text": "Okay? Um, so the- there's another example which I'm gonna defer to section to talk about.",
    "start": "4849115",
    "end": "4855700"
  },
  {
    "text": "Um, I think in all of this, you just need to do some practice [NOISE] and get kind of comfortable doing these operations.",
    "start": "4855700",
    "end": "4862060"
  },
  {
    "text": "[NOISE] Um, to summarize, to find Bayesian networks, uh, there's this way of,",
    "start": "4862060",
    "end": "4867640"
  },
  {
    "text": "uh, defining models that, um, allow you to specify locally and optimize globally.",
    "start": "4867640",
    "end": "4874960"
  },
  {
    "text": "Once you have a Bayesian network you can do probabilistic inference where you condition on evidence and query variables of interest.",
    "start": "4874960",
    "end": "4880375"
  },
  {
    "text": "And next time, we're going to focus on number 5, and hopefully not do things completely",
    "start": "4880375",
    "end": "4886989"
  },
  {
    "text": "manually but do things more automatically. Okay. That's it.",
    "start": "4886990",
    "end": "4891350"
  }
]
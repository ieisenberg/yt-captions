[
  {
    "text": "Next, we're going to go\nto the IMDb document.",
    "start": "0",
    "end": "5640"
  },
  {
    "text": "Remember, the IMDb\nwere the movie reviews,",
    "start": "5640",
    "end": "8870"
  },
  {
    "text": "and so this is a task in\ndocument classification.",
    "start": "8870",
    "end": "13010"
  },
  {
    "text": "And again, Keras\nhas this data set.",
    "start": "13010",
    "end": "17600"
  },
  {
    "text": "We're going to use a dictionary\nof size 10,000 words.",
    "start": "17600",
    "end": "23240"
  },
  {
    "text": "And if you recall, the way\nthings work is we build a bag",
    "start": "23240",
    "end": "28460"
  },
  {
    "text": "of words model where we score\neach document for whether or not",
    "start": "28460",
    "end": "34100"
  },
  {
    "text": "the words in our dictionary\nappear in the document,",
    "start": "34100",
    "end": "37019"
  },
  {
    "text": "it's a binary vector, and we're\ngoing to limit it to the 10,000",
    "start": "37020",
    "end": "40670"
  },
  {
    "text": "most commonly used\nwords in the dictionary.",
    "start": "40670",
    "end": "43949"
  },
  {
    "text": "And when we extract\nthe data set,",
    "start": "43950",
    "end": "46700"
  },
  {
    "text": "we can straight\naway indicate that",
    "start": "46700",
    "end": "49280"
  },
  {
    "text": "and it'll truncate\neach little review",
    "start": "49280",
    "end": "52739"
  },
  {
    "text": "to just using those words.",
    "start": "52740",
    "end": "54720"
  },
  {
    "text": "This third line here is a\nshortcut using a kind of a sign",
    "start": "54720",
    "end": "59760"
  },
  {
    "text": "operator that takes\nthe IMDb data structure",
    "start": "59760",
    "end": "64110"
  },
  {
    "text": "and builds up a train test\nlist and also x and y.",
    "start": "64110",
    "end": "69040"
  },
  {
    "text": "So these are shortcuts we\nlearned from the Keras book.",
    "start": "69040",
    "end": "74930"
  },
  {
    "text": "Let's have a look at the\nindices for the first 12 words",
    "start": "74930",
    "end": "79010"
  },
  {
    "text": "in the first document.",
    "start": "79010",
    "end": "80690"
  },
  {
    "text": "So there they are.",
    "start": "80690",
    "end": "83380"
  },
  {
    "text": "So the words are indicated by\npositions in the dictionary",
    "start": "83380",
    "end": "87250"
  },
  {
    "text": "of 12,000.",
    "start": "87250",
    "end": "89960"
  },
  {
    "text": "So if you want to\nactually see the words,",
    "start": "89960",
    "end": "92510"
  },
  {
    "text": "we write a decode function,\nand the decode function",
    "start": "92510",
    "end": "98530"
  },
  {
    "text": "needs to take into account\ncertain padding words",
    "start": "98530",
    "end": "102670"
  },
  {
    "text": "like start and stop and unused,\nand so there's some details",
    "start": "102670",
    "end": "106960"
  },
  {
    "text": "here, we won't go\ninto it yet now,",
    "start": "106960",
    "end": "109060"
  },
  {
    "text": "but you can read more\ndetails in the lab",
    "start": "109060",
    "end": "112240"
  },
  {
    "text": "and that tells you the\nbeginning of that review.",
    "start": "112240",
    "end": "115640"
  },
  {
    "text": "So it translates the numbers\ninto the actual words.",
    "start": "115640",
    "end": "119210"
  },
  {
    "text": "So this form was just brilliant\ncasting, location, scenery,",
    "start": "119210",
    "end": "122140"
  },
  {
    "text": "story direction, everyone.",
    "start": "122140",
    "end": "123800"
  },
  {
    "text": "So it doesn't look like\nEnglish, but remember,",
    "start": "123800",
    "end": "126940"
  },
  {
    "text": "we limited ourselves to\nthis restricted dictionary.",
    "start": "126940",
    "end": "131480"
  },
  {
    "text": "And so now we write a\nfunction to one to hot encode",
    "start": "131480",
    "end": "137239"
  },
  {
    "text": "each document in a\nlist of documents,",
    "start": "137240",
    "end": "139520"
  },
  {
    "text": "and return a binary matrix\nin sparse matrix format.",
    "start": "139520",
    "end": "142850"
  },
  {
    "text": "So remember this.",
    "start": "142850",
    "end": "144350"
  },
  {
    "text": "What this is going to\ndo is for each document,",
    "start": "144350",
    "end": "147800"
  },
  {
    "text": "it's going to give\nyou a binary matrix,",
    "start": "147800",
    "end": "149810"
  },
  {
    "text": "and it's just going\nto be 0s or 1s,",
    "start": "149810",
    "end": "152480"
  },
  {
    "text": "according to which words were\npresent in the dictionary.",
    "start": "152480",
    "end": "155129"
  },
  {
    "start": "155130",
    "end": "157650"
  },
  {
    "text": "You see in the last line, we\nmade a call to the sparse matrix",
    "start": "157650",
    "end": "162640"
  },
  {
    "text": "function because this matrix is\nmostly 0s because any document",
    "start": "162640",
    "end": "167080"
  },
  {
    "text": "only has--",
    "start": "167080",
    "end": "168690"
  },
  {
    "text": "if the documents got 50 words\nor 100 words or whatever,",
    "start": "168690",
    "end": "173850"
  },
  {
    "text": "there's only going to be at\nmost 100 1s in the document--",
    "start": "173850",
    "end": "177360"
  },
  {
    "text": "in the sparse vector, and\nthe rest are going to be 0s.",
    "start": "177360",
    "end": "180990"
  },
  {
    "text": "We use a capital matrix\npackage and the sparse matrix",
    "start": "180990",
    "end": "184440"
  },
  {
    "text": "function to store this\nmatrix in a sparse format.",
    "start": "184440",
    "end": "190810"
  },
  {
    "text": "And so this code here is\nsetting things up to do that.",
    "start": "190810",
    "end": "195310"
  },
  {
    "text": "Next, we use the one\nhot encode function.",
    "start": "195310",
    "end": "199930"
  },
  {
    "text": "It's telling it that there's\na dictionary of length 10,000,",
    "start": "199930",
    "end": "206450"
  },
  {
    "text": "and so we'll just run that code.",
    "start": "206450",
    "end": "210670"
  },
  {
    "text": "So all the components of\nX ran get one hot encoded,",
    "start": "210670",
    "end": "214260"
  },
  {
    "text": "is that right?",
    "start": "214260",
    "end": "214950"
  },
  {
    "text": "Yeah, so this makes\nthese matrices that are--",
    "start": "214950",
    "end": "217955"
  },
  {
    "start": "217955",
    "end": "221320"
  },
  {
    "text": "I see.",
    "start": "221320",
    "end": "221990"
  },
  {
    "text": "I'm sorry.",
    "start": "221990",
    "end": "222500"
  },
  {
    "text": "I got a little lost\nin the code here.",
    "start": "222500",
    "end": "224480"
  },
  {
    "text": "So this is just a function\nto do the one hot encoding,",
    "start": "224480",
    "end": "228550"
  },
  {
    "text": "and it returns a sparse\nmatrix, and here we",
    "start": "228550",
    "end": "231880"
  },
  {
    "text": "run one hot on the\ntraining and the test.",
    "start": "231880",
    "end": "234315"
  },
  {
    "start": "234315",
    "end": "237660"
  },
  {
    "text": "And so we see that the dimension\nof the x that we have out is",
    "start": "237660",
    "end": "242280"
  },
  {
    "text": "25,000 by 10,000.",
    "start": "242280",
    "end": "247280"
  },
  {
    "text": "And if we look at the fraction\nof nonzeros, we see it's 1.3%.",
    "start": "247280",
    "end": "255300"
  },
  {
    "text": "We're going to sample a\nvalidation set of size 2,000",
    "start": "255300",
    "end": "260190"
  },
  {
    "text": "just so that we can\nmonitor progress,",
    "start": "260190",
    "end": "263325"
  },
  {
    "text": "and select tuning parameters.",
    "start": "263325",
    "end": "266720"
  },
  {
    "text": "So first, we will fit a lasso\nlogistic regression using glmnet",
    "start": "266720",
    "end": "271340"
  },
  {
    "text": "and evaluate performance\non the validation data,",
    "start": "271340",
    "end": "275150"
  },
  {
    "text": "and we'll plot its accuracy\nas a function of the shrinkage",
    "start": "275150",
    "end": "281000"
  },
  {
    "text": "parameter lambda.",
    "start": "281000",
    "end": "283660"
  },
  {
    "text": "In glmnet, it will take\nadvantage of the sparse matrix",
    "start": "283660",
    "end": "286540"
  },
  {
    "text": "format because this is a\npretty massive fix matrix.",
    "start": "286540",
    "end": "290840"
  },
  {
    "text": "But glmnet knows how to take\nadvantage of the sparsity.",
    "start": "290840",
    "end": "294910"
  },
  {
    "text": "It just knows\nbecause x train is--",
    "start": "294910",
    "end": "297460"
  },
  {
    "text": "you don't tell it,\nit figures it out.",
    "start": "297460",
    "end": "299979"
  },
  {
    "text": "Yes, so if one had to look\nat the class of X train,",
    "start": "299980",
    "end": "303460"
  },
  {
    "text": "you'd see it would\nbe a sparse matrix.",
    "start": "303460",
    "end": "307710"
  },
  {
    "text": "Should we do that?",
    "start": "307710",
    "end": "308590"
  },
  {
    "text": "Yeah.",
    "start": "308590",
    "end": "309090"
  },
  {
    "start": "309090",
    "end": "316930"
  },
  {
    "text": "So let's see.",
    "start": "316930",
    "end": "317930"
  },
  {
    "start": "317930",
    "end": "322430"
  },
  {
    "text": "What's it? x_--",
    "start": "322430",
    "end": "323620"
  },
  {
    "start": "323620",
    "end": "334460"
  },
  {
    "text": "[INAUDIBLE] matrix?",
    "start": "334460",
    "end": "335430"
  },
  {
    "text": "Yeah, so I forget what\nthese things, but it's",
    "start": "335430",
    "end": "338389"
  },
  {
    "text": "a column sparse matrix and\nfrom the package matrix.",
    "start": "338390",
    "end": "343210"
  },
  {
    "start": "343210",
    "end": "347546"
  },
  {
    "text": "So there is a call to glmnet.",
    "start": "347546",
    "end": "351610"
  },
  {
    "text": "We tell her to use a binomial\nbecause the response, remember,",
    "start": "351610",
    "end": "354639"
  },
  {
    "text": "is the sentiment of the\ndocument, and it was--",
    "start": "354640",
    "end": "361010"
  },
  {
    "text": "what was it?",
    "start": "361010",
    "end": "361940"
  },
  {
    "text": "Favorable or unfavorable.",
    "start": "361940",
    "end": "365480"
  },
  {
    "text": "And we tell it not to\nstandardize the matrix",
    "start": "365480",
    "end": "369750"
  },
  {
    "text": "because the matrix, the\nfeatures are all binary,",
    "start": "369750",
    "end": "373200"
  },
  {
    "text": "so they all in the same units.",
    "start": "373200",
    "end": "376050"
  },
  {
    "text": "Then we predict\non the test data,",
    "start": "376050",
    "end": "381240"
  },
  {
    "text": "in this case, the\nvalidation data,",
    "start": "381240",
    "end": "383940"
  },
  {
    "text": "and we compute the accuracy.",
    "start": "383940",
    "end": "387700"
  },
  {
    "text": "So let's get that running.",
    "start": "387700",
    "end": "390210"
  },
  {
    "start": "390210",
    "end": "393600"
  },
  {
    "text": "And it's done.",
    "start": "393600",
    "end": "394745"
  },
  {
    "start": "394745",
    "end": "399810"
  },
  {
    "text": "And in this case, we just\nmake a plot of the results",
    "start": "399810",
    "end": "404730"
  },
  {
    "text": "and we see the performance\non the validation data,",
    "start": "404730",
    "end": "411450"
  },
  {
    "text": "and it gets up to about 88%.",
    "start": "411450",
    "end": "414603"
  },
  {
    "start": "414603",
    "end": "420560"
  },
  {
    "text": "Now we're going to\nfit a neural network,",
    "start": "420560",
    "end": "422650"
  },
  {
    "text": "and we'll use two hidden\nlayers, each with 16 units.",
    "start": "422650",
    "end": "428919"
  },
  {
    "text": "So there's a specification.",
    "start": "428920",
    "end": "431450"
  },
  {
    "text": "So this is starting to\nlook familiar by now,",
    "start": "431450",
    "end": "434470"
  },
  {
    "text": "and tell it to optimizer, we\ntell it the epochs, batch sizes,",
    "start": "434470",
    "end": "440580"
  },
  {
    "text": "and so on.",
    "start": "440580",
    "end": "441310"
  },
  {
    "text": "So this is just a standard\ntwo layer neural network.",
    "start": "441310",
    "end": "444470"
  },
  {
    "start": "444470",
    "end": "449150"
  },
  {
    "text": "There it goes.",
    "start": "449150",
    "end": "449830"
  },
  {
    "start": "449830",
    "end": "455449"
  },
  {
    "text": "What do we see there, Rob?",
    "start": "455450",
    "end": "457070"
  },
  {
    "text": "We see overfitting pretty quick.",
    "start": "457070",
    "end": "458810"
  },
  {
    "text": "Pretty quick overfitting.",
    "start": "458810",
    "end": "460169"
  },
  {
    "start": "460170",
    "end": "464550"
  },
  {
    "text": "It gets up to about\n88-- just over 88%,",
    "start": "464550",
    "end": "468449"
  },
  {
    "text": "89% accuracy on the\ntest data, but it starts",
    "start": "468450",
    "end": "472950"
  },
  {
    "text": "overfitting fairly quickly.",
    "start": "472950",
    "end": "475640"
  },
  {
    "text": "And didn't have any dropout I\nsee maybe that we could have--",
    "start": "475640",
    "end": "478140"
  },
  {
    "text": "We didn't have dropout--",
    "start": "478140",
    "end": "479640"
  },
  {
    "text": "That could have--",
    "start": "479640",
    "end": "480450"
  },
  {
    "text": "Slowed the overfitting.",
    "start": "480450",
    "end": "481720"
  },
  {
    "text": "Yeah.",
    "start": "481720",
    "end": "482640"
  },
  {
    "text": "I do recall trying some\ndropout and other things here,",
    "start": "482640",
    "end": "486750"
  },
  {
    "text": "but it didn't seem to\nmake much difference.",
    "start": "486750",
    "end": "491490"
  },
  {
    "text": "We've just shown.",
    "start": "491490",
    "end": "492340"
  },
  {
    "text": "The validation accuracy.",
    "start": "492340",
    "end": "493930"
  },
  {
    "text": "We also like to see\nthe test accuracy.",
    "start": "493930",
    "end": "496380"
  },
  {
    "text": "So I basically run\nthe program again,",
    "start": "496380",
    "end": "499560"
  },
  {
    "text": "but this time on using\nthe test data and not",
    "start": "499560",
    "end": "502770"
  },
  {
    "text": "the validation data.",
    "start": "502770",
    "end": "504870"
  },
  {
    "text": "I won't show that now.",
    "start": "504870",
    "end": "507350"
  },
  {
    "start": "507350",
    "end": "508000"
  }
]
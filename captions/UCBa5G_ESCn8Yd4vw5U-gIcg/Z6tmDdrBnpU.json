[
  {
    "text": "hi I'm Luna from Google and uh so yes today we will talk about uh knowledge",
    "start": "11559",
    "end": "17560"
  },
  {
    "text": "Fusion and the knowledge based trust uh the title and the content is a little",
    "start": "17560",
    "end": "23160"
  },
  {
    "text": "different from the title and Abstract in the course announcement but uh the",
    "start": "23160",
    "end": "29119"
  },
  {
    "text": "overlap is big so this is collaboration with my colleagues at Google including van of",
    "start": "29119",
    "end": "35559"
  },
  {
    "text": "guine wio Camilo Kevin shiaa and way so I started uh uh working on the quality",
    "start": "35559",
    "end": "44840"
  },
  {
    "text": "of data especially quality of uh integrated data since 2007 and the major",
    "start": "44840",
    "end": "52920"
  },
  {
    "text": "work is to figure out whether something is correct and um whether the source is",
    "start": "52920",
    "end": "58600"
  },
  {
    "text": "of good quality and whether some Source copies data from some other sources and so on so since then I was collecting",
    "start": "58600",
    "end": "67080"
  },
  {
    "text": "various examples from the web so to give my talks and um I have a whole lot of",
    "start": "67080",
    "end": "74080"
  },
  {
    "text": "examples about incorrect data imprecise data about out ofd data about um ahead",
    "start": "74080",
    "end": "81520"
  },
  {
    "text": "of dat data so this is kind of a op before it really happens and about how",
    "start": "81520",
    "end": "87520"
  },
  {
    "text": "rumors res out from Wikipedia from uh tweets from blogs and so on so I won't",
    "start": "87520",
    "end": "93560"
  },
  {
    "text": "go to the details of any of this example but today I'm going to give uh give you",
    "start": "93560",
    "end": "98960"
  },
  {
    "text": "my own example so it started in February this",
    "start": "98960",
    "end": "104240"
  },
  {
    "text": "year I uploaded uh uh a paper which I",
    "start": "104240",
    "end": "109560"
  },
  {
    "text": "was submitting to vldb uh I uploaded it to Archive and uh the title is knowledge",
    "start": "109560",
    "end": "115920"
  },
  {
    "text": "based trust estimating the trustworthiness of web sources and that's kind of the major thing I will",
    "start": "115920",
    "end": "121799"
  },
  {
    "text": "talk about in this uh talk and then on February 28th there was an article from",
    "start": "121799",
    "end": "129520"
  },
  {
    "text": "New Scientist about our tic uh our paper and most of the stuff in the article is",
    "start": "129520",
    "end": "136480"
  },
  {
    "text": "correct so for example the first sentence says the trustworthiness of a web page might help it rise up Google's",
    "start": "136480",
    "end": "144360"
  },
  {
    "text": "ranking if the search giant starts to measure quality by facts not just the links",
    "start": "144360",
    "end": "150959"
  },
  {
    "text": "however the headline of the news is very misleading it is saying Google wants to rank websites based on facts not links",
    "start": "150959",
    "end": "159480"
  },
  {
    "text": "and right after that there have been a lot of news articles from uh at least",
    "start": "159480",
    "end": "165599"
  },
  {
    "text": "200 newspapers or some of them being possibly blogs and I'm sort of uh",
    "start": "165599",
    "end": "172200"
  },
  {
    "text": "plotting the distribution of the Articles over time you can see that the peak is in the first week and then there",
    "start": "172200",
    "end": "179879"
  },
  {
    "text": "are news even until like when I checked it last weekend and there are basically",
    "start": "179879",
    "end": "185760"
  },
  {
    "text": "two voices one voice is ah there is a lot of misinformation on the web and I",
    "start": "185760",
    "end": "190920"
  },
  {
    "text": "really hope somebody would tell me what is true what is false and another kind",
    "start": "190920",
    "end": "196920"
  },
  {
    "text": "of voice is no no no no no no I cannot trust this knowledge based trust how can",
    "start": "196920",
    "end": "202760"
  },
  {
    "text": "the machine tell me what is true and what is the false and what is the role of Google on this and um this will",
    "start": "202760",
    "end": "210799"
  },
  {
    "text": "definitely slow down the development of science so on and so forth and",
    "start": "210799",
    "end": "216720"
  },
  {
    "text": "so the best way to tell you what's happening is to read some quotes from",
    "start": "216720",
    "end": "222519"
  },
  {
    "text": "three Washington Post articles and the first one is on March 2nd uh with the",
    "start": "222519",
    "end": "229040"
  },
  {
    "text": "title Google has developed a technology to tell where the facts on the internet are true and uh it basically said uh",
    "start": "229040",
    "end": "236840"
  },
  {
    "text": "concluded that uh it's unclear exactly what Google plans to do with this new technology if anything at all still even",
    "start": "236840",
    "end": "244680"
  },
  {
    "text": "the possibility of a search engine that evaluates truth is a pretty incredible",
    "start": "244680",
    "end": "250760"
  },
  {
    "text": "breakthrough and it definitely gives new meaning to the phrase let me Google that for you so this is very positive at this",
    "start": "250760",
    "end": "259000"
  },
  {
    "text": "point and then one week later so on March 11th there was a second article by",
    "start": "259000",
    "end": "265800"
  },
  {
    "text": "another journalist titled uh the huge impl uh implications of Google's idea to",
    "start": "265800",
    "end": "272479"
  },
  {
    "text": "rank sitze based on their accuracy and at this point he was describing what has happened in the previous week and he",
    "start": "272479",
    "end": "279680"
  },
  {
    "text": "said um Google's new research didn't explicitly mention how this approach",
    "start": "279680",
    "end": "285160"
  },
  {
    "text": "might rank science contrarian websites but media have been reporting this week",
    "start": "285160",
    "end": "291240"
  },
  {
    "text": "that climate change Skeptics seem unnerved by the direction that Google appears to be heading if this ever moves",
    "start": "291240",
    "end": "298840"
  },
  {
    "text": "closer to a reality than they should be and after that one day later the same",
    "start": "298840",
    "end": "304759"
  },
  {
    "text": "journalist write wrote another article saying why some people are so terrified by the idea of a Google truth machine",
    "start": "304759",
    "end": "312680"
  },
  {
    "text": "and uh he started with uh there seems to be a fair amount of confusion and some critical points that I think people are",
    "start": "312680",
    "end": "319919"
  },
  {
    "text": "missing in a sense Google is both closer to and farther from doing this than",
    "start": "319919",
    "end": "325720"
  },
  {
    "text": "people seem to realize later on he gave a lot of like a good analysis good uh discussions and uh finally he said it's",
    "start": "325720",
    "end": "332800"
  },
  {
    "text": "a really exciting and A Brave New World where big data and smart Engineers can indeed in theory build tools and apps to",
    "start": "332800",
    "end": "340680"
  },
  {
    "text": "help protect us from misinformation what remains up in the air right now is precisely how and if these will be",
    "start": "340680",
    "end": "349120"
  },
  {
    "text": "implemented which is something I will describe in this talk but back to my example why do I say this is a data",
    "start": "349120",
    "end": "356039"
  },
  {
    "text": "quality example and um so we you see that I'm using a wide Arrow from this",
    "start": "356039",
    "end": "363000"
  },
  {
    "text": "first article to the rest of Articles and the thingin arrow from the paper to the Articles and uh although there are",
    "start": "363000",
    "end": "370680"
  },
  {
    "text": "some articles very seriously like a quoting our sentences in the paper",
    "start": "370680",
    "end": "375759"
  },
  {
    "text": "showing our experimental results but there are a lot of Articles basically repeating what the first uh article says",
    "start": "375759",
    "end": "383000"
  },
  {
    "text": "is best especially repeating what the headline says and there are a lot of",
    "start": "383000",
    "end": "388479"
  },
  {
    "text": "information that surprised me for example One news article said U well they are going to use uh New York Times",
    "start": "388479",
    "end": "395800"
  },
  {
    "text": "and um uh Wall Street Journal as their go standard and I mean obviously this is",
    "start": "395800",
    "end": "401680"
  },
  {
    "text": "worrisome and I couldn't remember where I mentioned at all these two like a",
    "start": "401680",
    "end": "408000"
  },
  {
    "text": "newspapers okay so now coming back to this knowledge based the trust and the",
    "start": "408360",
    "end": "414360"
  },
  {
    "text": "motivation is that we want to provide A New Perspective to evaluate at web",
    "start": "414360",
    "end": "419919"
  },
  {
    "text": "Source quality and uh currently we evaluate the quality of the web pages",
    "start": "419919",
    "end": "428120"
  },
  {
    "text": "web sources using link based signals such as page rank I'm sure everybody",
    "start": "428120",
    "end": "433400"
  },
  {
    "text": "knows using uh search log and click through rate and also through some like",
    "start": "433400",
    "end": "438960"
  },
  {
    "text": "web spam detection all of these are exogenous signals but uh what we want to do is we",
    "start": "438960",
    "end": "447759"
  },
  {
    "text": "want to evaluate TR of sources by the correctness of its factual information",
    "start": "447759",
    "end": "454400"
  },
  {
    "text": "in other words we want to use some endogenous signals so what do I mean by the",
    "start": "454400",
    "end": "461039"
  },
  {
    "text": "correctness of the factual information so if we have a web page and uh we find",
    "start": "461039",
    "end": "466960"
  },
  {
    "text": "out it claims 10 facts and out of it seven are correct and um three are wrong",
    "start": "466960",
    "end": "474879"
  },
  {
    "text": "then we compute the accuracy as the number of correct facts out out of the number of all facts and in this example",
    "start": "474879",
    "end": "482840"
  },
  {
    "text": "it is seven out of 10 is 7 right wrong means whether it is consistent with the",
    "start": "482840",
    "end": "488720"
  },
  {
    "text": "real world so before I even talk about how to do this let's see why we care about",
    "start": "488720",
    "end": "497159"
  },
  {
    "text": "this so here uh the one of the motivation is that um the tail sources",
    "start": "497159",
    "end": "503280"
  },
  {
    "text": "on the web typically they are not well linked and they may not be uh viewed a",
    "start": "503280",
    "end": "508319"
  },
  {
    "text": "lot but they can be useful let me use Google web answers as an example so web",
    "start": "508319",
    "end": "514240"
  },
  {
    "text": "answers basically they look at the top uh return answers for a question and",
    "start": "514240",
    "end": "520399"
  },
  {
    "text": "then they extract the answer from those uh Snippets and here if you ask who",
    "start": "520399",
    "end": "527120"
  },
  {
    "text": "played the stum ball uh the stum ball is a awardwinning guitar music and then it",
    "start": "527120",
    "end": "533080"
  },
  {
    "text": "will show you somebody teach H shows how to play the dumble stops in Freddy CHS",
    "start": "533080",
    "end": "539720"
  },
  {
    "text": "the stum ball so it gives you the answer this works well however if you ask about",
    "start": "539720",
    "end": "547240"
  },
  {
    "text": "a not so popular song like uh who play guitar going home you didn't get the",
    "start": "547240",
    "end": "552640"
  },
  {
    "text": "answer it's not that this piece of information is not uh on the web it is just not in the top returned results top",
    "start": "552640",
    "end": "561240"
  },
  {
    "text": "returned pages so for example this website called backing track guitar.com",
    "start": "561240",
    "end": "567839"
  },
  {
    "text": "it gives V very precise information about guitar players and so on but it",
    "start": "567839",
    "end": "574519"
  },
  {
    "text": "page rank is quite low because it's one of the tail",
    "start": "574519",
    "end": "579760"
  },
  {
    "text": "sources and uh on the other hand we found that that a lot of popular websites they may not really be",
    "start": "579760",
    "end": "587000"
  },
  {
    "text": "trustworthy and here I'm showing 15 gossip websites led by this URL we found",
    "start": "587000",
    "end": "594519"
  },
  {
    "text": "that 14 out of these 15 have a page rank among the top 15% of the websites so why",
    "start": "594519",
    "end": "602360"
  },
  {
    "text": "because we all love gossip and uh can the trust worthiness",
    "start": "602360",
    "end": "608800"
  },
  {
    "text": "of the sources help here so in our system we compute this",
    "start": "608800",
    "end": "614160"
  },
  {
    "text": "knowledge based the trust abbreviated as KBT and it the value is uh between zero",
    "start": "614160",
    "end": "621040"
  },
  {
    "text": "and one as I mentioned it's the percentage of correct facts out of all facts and we can compute it for 5.6",
    "start": "621040",
    "end": "628640"
  },
  {
    "text": "million of websites and about 120 millions of web pages here I'm showing",
    "start": "628640",
    "end": "635680"
  },
  {
    "text": "the distribution of KBT for websites where we believe we have at least 100",
    "start": "635680",
    "end": "642760"
  },
  {
    "text": "facts and we see that the peak is 08 and 085 and uh more than half of the soures",
    "start": "642760",
    "end": "650639"
  },
  {
    "text": "have a score over 08 however there are also sources with low scores this",
    "start": "650639",
    "end": "657959"
  },
  {
    "text": "distribution set kind of um make sense because a lot of the websites gives decent content",
    "start": "657959",
    "end": "666360"
  },
  {
    "text": "factual content so how does that compare with a page Rank and uh these plotting where",
    "start": "666360",
    "end": "675920"
  },
  {
    "text": "the x axis is uh KBT and the Y AIS is the page rank show that they are pretty",
    "start": "675920",
    "end": "682279"
  },
  {
    "text": "much orthogonal and there are a lot of uh some data sources between these two",
    "start": "682279",
    "end": "688320"
  },
  {
    "text": "lines they got the correlated scores but on the other hand there are a lot of sources where the KBT is fairly high but",
    "start": "688320",
    "end": "697600"
  },
  {
    "text": "the page rank is low especially in this area so these are often the tail sources",
    "start": "697600",
    "end": "703680"
  },
  {
    "text": "with high trust worthy contents and um I'm showing four examples here uh this",
    "start": "703680",
    "end": "710959"
  },
  {
    "text": "salary.com gives very good information about companies and colleges this",
    "start": "710959",
    "end": "716600"
  },
  {
    "text": "website gives very good information about UK livestock this is what we just",
    "start": "716600",
    "end": "721839"
  },
  {
    "text": "saw the backing track guitar and this gives very good information about Korean",
    "start": "721839",
    "end": "727519"
  },
  {
    "text": "drama it's not that nobody I mean it's not that many people care about Korean",
    "start": "727519",
    "end": "732680"
  },
  {
    "text": "drama but still a lot of people like my mom cares about it and they can benefit from such websites if she can read",
    "start": "732680",
    "end": "740920"
  },
  {
    "text": "English and we sampled 100 websites uh where the kbd is above point9 and we",
    "start": "740920",
    "end": "747279"
  },
  {
    "text": "found we are very confident that 85 of them are indeed trustworthy for the rest",
    "start": "747279",
    "end": "753560"
  },
  {
    "text": "of the 15 I will mention them later on so on the other side we also have",
    "start": "753560",
    "end": "760720"
  },
  {
    "text": "sources where the page rank is high but uh KBT is fairly low and now let's come",
    "start": "760720",
    "end": "767279"
  },
  {
    "text": "back to the gossip websites we found that all of them have a knowledge based",
    "start": "767279",
    "end": "772480"
  },
  {
    "text": "trust in bottom 50% meaning we believe at least half of the websites have a",
    "start": "772480",
    "end": "777600"
  },
  {
    "text": "higher score than the and uh we also find out that some Forum",
    "start": "777600",
    "end": "783720"
  },
  {
    "text": "websites have lower score so for example like this web page from Yahoo answers I",
    "start": "783720",
    "end": "789959"
  },
  {
    "text": "mean I cannot tell if this is correct however they mentioned Catherine Zeta is",
    "start": "789959",
    "end": "796120"
  },
  {
    "text": "from New Zealand and from uh Wikipedia and some other data sources we know that",
    "start": "796120",
    "end": "802000"
  },
  {
    "text": "she's from Wales and the third usage of this is",
    "start": "802000",
    "end": "809519"
  },
  {
    "text": "that uh we can recommend websites by verticals by domains and this is because",
    "start": "809519",
    "end": "815399"
  },
  {
    "text": "we can compute the trustworthiness at different granularities at the web",
    "start": "815399",
    "end": "820800"
  },
  {
    "text": "granularity or at the web page granularity or at web sour granularity",
    "start": "820800",
    "end": "827160"
  },
  {
    "text": "for every uh domain for every vertical so for example if I search for food",
    "start": "827160",
    "end": "833680"
  },
  {
    "text": "cheese then it returns me something like Wikipedia.org cheese week key uh",
    "start": "833680",
    "end": "841040"
  },
  {
    "text": "ranker uh this is cheese plates the cheese sck Etc and it tells me about uh",
    "start": "841040",
    "end": "848279"
  },
  {
    "text": "the accuracy of the information the um kind of the coverage of the information",
    "start": "848279",
    "end": "853959"
  },
  {
    "text": "Etc and instead if I search computer it will return me Wikipedia in different",
    "start": "853959",
    "end": "860399"
  },
  {
    "text": "languages it will return me open sour software directory um uh this is free code",
    "start": "860399",
    "end": "869320"
  },
  {
    "text": "uh something like um uh Linux links so on and so",
    "start": "869320",
    "end": "875720"
  },
  {
    "text": "forth okay so at this point any",
    "start": "876399",
    "end": "880959"
  },
  {
    "text": "question [Applause]",
    "start": "881839",
    "end": "886920"
  },
  {
    "text": "okay I hope now you are already curious about how we compute this knowledge",
    "start": "886920",
    "end": "892720"
  },
  {
    "text": "based the trust and recall that I said uh we want to find out the facts claimed by each",
    "start": "892720",
    "end": "900079"
  },
  {
    "text": "web page and the correctness of each fact and both of these tasks are very",
    "start": "900079",
    "end": "907920"
  },
  {
    "text": "hard however we have a project called knowledge Vault where we try to build a",
    "start": "907920",
    "end": "913920"
  },
  {
    "text": "probabilistic knowledge base we used the 16 extractors extracting knowledge",
    "start": "913920",
    "end": "921519"
  },
  {
    "text": "triport subject predicate object triples from the whole web including 2.5",
    "start": "921519",
    "end": "927880"
  },
  {
    "text": "billions of Eur LS and 28 millions of websites and uh we extract from free",
    "start": "927880",
    "end": "934079"
  },
  {
    "text": "text from Dom trees from web tables and from uh uh annotations according to for",
    "start": "934079",
    "end": "940440"
  },
  {
    "text": "example schema.org after that we put all of the extractions",
    "start": "940440",
    "end": "946360"
  },
  {
    "text": "together and try to decide what is correct and what is not and we generate",
    "start": "946360",
    "end": "951639"
  },
  {
    "text": "a probability for each triple indicating its probability of being true and then",
    "start": "951639",
    "end": "958720"
  },
  {
    "text": "we build a probabilistic knowledge base so coming back to our plan now instead",
    "start": "958720",
    "end": "964600"
  },
  {
    "text": "of looking at the facts we want to look at all of the extracted triples and",
    "start": "964600",
    "end": "970399"
  },
  {
    "text": "instead of looking at true or false we want to look at the predicted",
    "start": "970399",
    "end": "975600"
  },
  {
    "text": "probabilities and then we compute an average of the probabilities as the",
    "start": "975600",
    "end": "980839"
  },
  {
    "text": "accuracy of the web source so seems life is good for now but",
    "start": "980839",
    "end": "987480"
  },
  {
    "text": "there is one for in a thing that is missing here so does anybody find out",
    "start": "987480",
    "end": "994600"
  },
  {
    "text": "something missing relevance uh that's a good point",
    "start": "994600",
    "end": "1000360"
  },
  {
    "text": "not the major thing well is that accuracy that the extracted triple is actually an assertion of a fact or that",
    "start": "1000360",
    "end": "1007319"
  },
  {
    "text": "it's a true fact because those are sort of distinct things uh I think you are getting there",
    "start": "1007319",
    "end": "1014120"
  },
  {
    "text": "so so these are all of the extracted triples and the probab abilities are",
    "start": "1014120",
    "end": "1019240"
  },
  {
    "text": "talking about the probability for the Triple to be true to be consistent with",
    "start": "1019240",
    "end": "1025079"
  },
  {
    "text": "the real world yeah how uhhuh I'm finding out that consistent",
    "start": "1025079",
    "end": "1032240"
  },
  {
    "text": "with the real world is often not true yeah everybody",
    "start": "1032240",
    "end": "1037480"
  },
  {
    "text": "lies so that for that part we are hoping we have some magic way to find it out",
    "start": "1037480",
    "end": "1043558"
  },
  {
    "text": "but uh before even talking about that we actually find out a lot of the triples",
    "start": "1043559",
    "end": "1049200"
  },
  {
    "text": "are wrong because of some extraction errors and uh so there might be Tripes",
    "start": "1049200",
    "end": "1057760"
  },
  {
    "text": "wrongly extracted not really claimed by the website and this happens not only",
    "start": "1057760",
    "end": "1064200"
  },
  {
    "text": "not only happens but happens a lot so for example here we extract the triple",
    "start": "1064200",
    "end": "1070880"
  },
  {
    "text": "Obama nationality Kenya from 2,000 web pages and uh some of of them",
    "start": "1070880",
    "end": "1078679"
  },
  {
    "text": "are correctly extracted for example this one says Michelle Obama declares Obama",
    "start": "1078679",
    "end": "1083880"
  },
  {
    "text": "is Kenyon and the America is mean and some of them however are",
    "start": "1083880",
    "end": "1089600"
  },
  {
    "text": "wrongly extracted like this news headline says us will respect winner of Kenyan election Obama says it actually",
    "start": "1089600",
    "end": "1096960"
  },
  {
    "text": "says the opposite Obama is not a Kenyan",
    "start": "1096960",
    "end": "1102120"
  },
  {
    "text": "Citizen and even for some correct presumably correct triples like",
    "start": "1102120",
    "end": "1108720"
  },
  {
    "text": "Obama nationality USA we extracted 2,500",
    "start": "1108720",
    "end": "1113919"
  },
  {
    "text": "times and uh a lot of them are correctly extracted but still some of them are",
    "start": "1113919",
    "end": "1119600"
  },
  {
    "text": "wrongly extracted so if you look at this screenshot it is a Blog by team Stanley",
    "start": "1119600",
    "end": "1126760"
  },
  {
    "text": "uh who is a historian of the United States and the blog is talking about",
    "start": "1126760",
    "end": "1132600"
  },
  {
    "text": "Barack Obama's life story contains myth not truth blah blah blah but it doesn't",
    "start": "1132600",
    "end": "1137880"
  },
  {
    "text": "say anything regarding his nationality or place of birth Etc and this United",
    "start": "1137880",
    "end": "1144120"
  },
  {
    "text": "States is about Tim Stanley rather than about Barack Obama so this is wrongly",
    "start": "1144120",
    "end": "1152240"
  },
  {
    "text": "extracted so we randomly sampled uh 25 false triples and we found that uh 11 of",
    "start": "1152240",
    "end": "1159720"
  },
  {
    "text": "them have some triple identification errors for example they take part of the album name as the album artist and uh 11",
    "start": "1159720",
    "end": "1168600"
  },
  {
    "text": "of them have some uh anti linkage arrows for example they take Obama's father as",
    "start": "1168600",
    "end": "1175159"
  },
  {
    "text": "Barack Obama and um four five of them have some predicate linkage arrows such",
    "start": "1175159",
    "end": "1180520"
  },
  {
    "text": "as date of birth and uh place of birth are wrongly matched and only one of them",
    "start": "1180520",
    "end": "1186159"
  },
  {
    "text": "have some Source data aror in other words the extraction errors actually",
    "start": "1186159",
    "end": "1191600"
  },
  {
    "text": "Dominate and so we do not want to blame our source for those wrong extractions",
    "start": "1191600",
    "end": "1198679"
  },
  {
    "text": "so we want to identify the extraction arrows so there are some other",
    "start": "1198679",
    "end": "1205080"
  },
  {
    "text": "challenges the Second Challenge is that since we are going to compute the average of the probability the",
    "start": "1205080",
    "end": "1211960"
  },
  {
    "text": "probability is better to be well calibrated so what do I mean by well",
    "start": "1211960",
    "end": "1217120"
  },
  {
    "text": "calibrated if for a triple I predict its probability of being true is 7 then we",
    "start": "1217120",
    "end": "1224440"
  },
  {
    "text": "hope its real probability of being true is also 7 in other words if I plot the",
    "start": "1224440",
    "end": "1231280"
  },
  {
    "text": "predicted probability and the real probability it should be a diagonal line",
    "start": "1231280",
    "end": "1236840"
  },
  {
    "text": "from 0 0 to 1 one and what do I mean by real probability for one fact so actually",
    "start": "1236840",
    "end": "1244480"
  },
  {
    "text": "what we do is uh we look at all of the facts in the bucket with probability 7",
    "start": "1244480",
    "end": "1251240"
  },
  {
    "text": "and uh we look at their accuracy the accuracy can be considered as the real",
    "start": "1251240",
    "end": "1257120"
  },
  {
    "text": "probability and if for the buckets of triples where we predict a probability",
    "start": "1257120",
    "end": "1262520"
  },
  {
    "text": "of 7 70% of them are correct then the real probability for those triples to be",
    "start": "1262520",
    "end": "1269000"
  },
  {
    "text": "true is indeed 70% make sense",
    "start": "1269000",
    "end": "1274520"
  },
  {
    "text": "yes is this an external structure database or is this manual anything I tell you soon that's a good question and",
    "start": "1274520",
    "end": "1282559"
  },
  {
    "text": "uh the third challenge is basically uh how to handle two large sources or two",
    "start": "1282559",
    "end": "1287799"
  },
  {
    "text": "small small sources and uh on the web the data sources are very different and this is the distribution of the number",
    "start": "1287799",
    "end": "1294200"
  },
  {
    "text": "of triples extracted from each URL we see that for 74% of the URLs there are",
    "start": "1294200",
    "end": "1300919"
  },
  {
    "text": "at most of five extracted triples and we don't have enough triples for",
    "start": "1300919",
    "end": "1306440"
  },
  {
    "text": "trustworthiness evaluation we don't have the statistical power and on the other",
    "start": "1306440",
    "end": "1311640"
  },
  {
    "text": "hand there are some large URS where we have um more than 50k triples a lot of",
    "start": "1311640",
    "end": "1317600"
  },
  {
    "text": "them actually wrongly extracted and they become the bottom neck in the parallelization in",
    "start": "1317600",
    "end": "1325799"
  },
  {
    "text": "computation so our solution is to use a graphical model such that we can predict",
    "start": "1326880",
    "end": "1333720"
  },
  {
    "text": "at the same time what is the extraction correctness what's the triple correctness what is the accuracy of the",
    "start": "1333720",
    "end": "1340960"
  },
  {
    "text": "web source and what is the Precision recall of the extractor and um here we use",
    "start": "1340960",
    "end": "1348880"
  },
  {
    "text": "unsupervised learning or semi-supervised learning when we predict the correctness",
    "start": "1348880",
    "end": "1354919"
  },
  {
    "text": "so when we try to decide whether a fact or extracted triple is correct we will",
    "start": "1354919",
    "end": "1361760"
  },
  {
    "text": "leverage agreement from different sources and we will give more trust to",
    "start": "1361760",
    "end": "1368679"
  },
  {
    "text": "sources with a higher trustworthy or higher accuracy and on the other hand",
    "start": "1368679",
    "end": "1374440"
  },
  {
    "text": "when we try to decide if an extraction is correct we we will leverage the agreement between the extractors and we",
    "start": "1374440",
    "end": "1382360"
  },
  {
    "text": "will give higher trust to the extractors with higher",
    "start": "1382360",
    "end": "1387679"
  },
  {
    "text": "quality and um uh another thing is uh since we have a super big and a super",
    "start": "1387679",
    "end": "1393400"
  },
  {
    "text": "small sources and extractors we break down the large sources so they wouldn't",
    "start": "1393400",
    "end": "1398440"
  },
  {
    "text": "be the computation bottleneck and uh we merge the small sources such that they",
    "start": "1398440",
    "end": "1403679"
  },
  {
    "text": "could borrow some statistical power from their neighbors",
    "start": "1403679",
    "end": "1408960"
  },
  {
    "text": "now let's see some uh high level uh intuition through some",
    "start": "1408960",
    "end": "1414559"
  },
  {
    "text": "examples oops so let's see we have a three data sources providing the",
    "start": "1414559",
    "end": "1421679"
  },
  {
    "text": "affiliation information for five database researchers and uh let's say uh S one",
    "start": "1421679",
    "end": "1428840"
  },
  {
    "text": "provides all of the correct affiliations and a series 2 and a series three make",
    "start": "1428840",
    "end": "1434880"
  },
  {
    "text": "some mistakes here and there so if we do a voting where we trust the majority we",
    "start": "1434880",
    "end": "1442279"
  },
  {
    "text": "can actually do pretty well for four out of five researchers we get the correct",
    "start": "1442279",
    "end": "1449640"
  },
  {
    "text": "value the red and for my cray we have three sources giving three different",
    "start": "1449640",
    "end": "1456880"
  },
  {
    "text": "affiliations so there is a tie and we don't know which one is correct now if we look at the red marks",
    "start": "1456880",
    "end": "1465000"
  },
  {
    "text": "it seems Source One is more accurate more trustworthy than Source two and",
    "start": "1465000",
    "end": "1471600"
  },
  {
    "text": "Source three so we want to give it a higher trust a higher vote let's say and",
    "start": "1471600",
    "end": "1479240"
  },
  {
    "text": "then we can correctly decide that UCI is the correct affiliation for",
    "start": "1479240",
    "end": "1484960"
  },
  {
    "text": "Micra so we see that um uh there is kind of a chicken and EG problem higher",
    "start": "1484960",
    "end": "1491799"
  },
  {
    "text": "trustworthiness Mak us believe that what it provides is more likely to be true",
    "start": "1491799",
    "end": "1497399"
  },
  {
    "text": "and uh more truthful facts make us believe that uh this is more",
    "start": "1497399",
    "end": "1505039"
  },
  {
    "text": "trustworthy so now let's come to extractions and let's see we have uh",
    "start": "1505039",
    "end": "1510120"
  },
  {
    "text": "three extractors extracting Harry Potter uh play uh actor actress from one web",
    "start": "1510120",
    "end": "1519440"
  },
  {
    "text": "page and uh extractor one extracts four of them extractor two extracts two of",
    "start": "1519440",
    "end": "1525520"
  },
  {
    "text": "them and extractor three extracts this three and yes question question so uh",
    "start": "1525520",
    "end": "1533399"
  },
  {
    "text": "the instructors today follow pretty much the same algorithms about perhaps with different parameters or do you have",
    "start": "1533399",
    "end": "1539520"
  },
  {
    "text": "different um uh approaches for each so they could use very different um",
    "start": "1539520",
    "end": "1545919"
  },
  {
    "text": "algorithms they could learn different patterns they could apply different models and so on so we do not assume any",
    "start": "1545919",
    "end": "1553360"
  },
  {
    "text": "detail yeah okay so now again let's do a voting and then it",
    "start": "1553360",
    "end": "1559320"
  },
  {
    "text": "seems these three are more likely to be correct and these two are more likely to be wrong and according to this it seems",
    "start": "1559320",
    "end": "1567600"
  },
  {
    "text": "extractor one uh extracts all of the correct uh things so has a higher recall",
    "start": "1567600",
    "end": "1574360"
  },
  {
    "text": "extractor two all of its extractions are correct so it has a higher precision and",
    "start": "1574360",
    "end": "1580480"
  },
  {
    "text": "the extractor three has medium precedent recall and now if we look at uh the",
    "start": "1580480",
    "end": "1587760"
  },
  {
    "text": "extractions again Daniel and Rupert are extracted by high Precision extractor so",
    "start": "1587760",
    "end": "1593679"
  },
  {
    "text": "it is more likely to be true and on the other hand Eric is missed from by a high",
    "start": "1593679",
    "end": "1599960"
  },
  {
    "text": "recall extractor so it is more likely to be wrong make sense",
    "start": "1599960",
    "end": "1607360"
  },
  {
    "text": "good so this is what our graphical model looks like we have four boxes the w box",
    "start": "1607360",
    "end": "1615320"
  },
  {
    "text": "represents a web source the E box represents an",
    "start": "1615320",
    "end": "1621760"
  },
  {
    "text": "extractor the dbox extra uh present uh data item the attribute of some",
    "start": "1621760",
    "end": "1629840"
  },
  {
    "text": "particular entity or subject predicate pair and then the",
    "start": "1629840",
    "end": "1636120"
  },
  {
    "text": "vbx represents a value for a data item so in other words the object in a",
    "start": "1636120",
    "end": "1642679"
  },
  {
    "text": "triple and uh these are our variables X",
    "start": "1642679",
    "end": "1648440"
  },
  {
    "text": "is our observation x e wdv means that extractor e extracts from Source",
    "start": "1648440",
    "end": "1657080"
  },
  {
    "text": "W uh the data item D value V",
    "start": "1657080",
    "end": "1662919"
  },
  {
    "text": "pair and uh c wdv means that web series",
    "start": "1662919",
    "end": "1668760"
  },
  {
    "text": "W indeed provides the DV pair and this",
    "start": "1668760",
    "end": "1674640"
  },
  {
    "text": "is a latent variable and uh VD shows that uh what is the",
    "start": "1674640",
    "end": "1681919"
  },
  {
    "text": "correct value for this data item this is again a latent V uh variable aw is the",
    "start": "1681919",
    "end": "1690279"
  },
  {
    "text": "accuracy of the web Source it's a parameter and P re are the precedent",
    "start": "1690279",
    "end": "1695640"
  },
  {
    "text": "recall of an extractor so note that this is basically",
    "start": "1695640",
    "end": "1701559"
  },
  {
    "text": "the knowledge based trust and what we do is recall that this",
    "start": "1701559",
    "end": "1706880"
  },
  {
    "text": "is chicken and act problem and uh certainly we want to do it in EM fashion",
    "start": "1706880",
    "end": "1713080"
  },
  {
    "text": "and uh we first compute the probability of a web Source provides a particular",
    "start": "1713080",
    "end": "1719120"
  },
  {
    "text": "triple conditioned on the extractor quality this is more of predicting the",
    "start": "1719120",
    "end": "1724440"
  },
  {
    "text": "extraction correctness after that we compute the probability of a triple condition down",
    "start": "1724440",
    "end": "1730559"
  },
  {
    "text": "SCE quality and this is more of a prediction on the triple",
    "start": "1730559",
    "end": "1736000"
  },
  {
    "text": "correctness and then we compute the source accuracy and we compute the",
    "start": "1736000",
    "end": "1741399"
  },
  {
    "text": "extractor precision and recall so these are by Bas analysis they can be",
    "start": "1741399",
    "end": "1746600"
  },
  {
    "text": "considered as the Eep and this two can be considered as mstep however to simplify it and uh make",
    "start": "1746600",
    "end": "1754240"
  },
  {
    "text": "it scalable to the web data we I mean we simplified it a lot and one way to",
    "start": "1754240",
    "end": "1761120"
  },
  {
    "text": "consider this is um for web soures we basically add some weight using the",
    "start": "1761120",
    "end": "1767960"
  },
  {
    "text": "extraction correctness and instead of computing the act the average of the",
    "start": "1767960",
    "end": "1773679"
  },
  {
    "text": "triple correctness we compute the average weighted by the extraction",
    "start": "1773679",
    "end": "1781720"
  },
  {
    "text": "correctness so far so good okay so coming back to our examples",
    "start": "1782360",
    "end": "1790000"
  },
  {
    "text": "we see that for this triple uh we compute for this particular correct",
    "start": "1790000",
    "end": "1795519"
  },
  {
    "text": "extraction we compute a probability of nearly 8 and for this for this wrong",
    "start": "1795519",
    "end": "1801279"
  },
  {
    "text": "extraction we compute the probability of .13 regarding the extraction",
    "start": "1801279",
    "end": "1806799"
  },
  {
    "text": "correctness for the whole triple we decide that the probability for the Triple to be correct is zero because it",
    "start": "1806799",
    "end": "1814480"
  },
  {
    "text": "does not have enough support and uh if we go to this presumably correct triple uh then uh for",
    "start": "1814480",
    "end": "1823399"
  },
  {
    "text": "the correct extraction again we compute very high EXT uh extraction correctness",
    "start": "1823399",
    "end": "1829679"
  },
  {
    "text": "and uh for um wrong extraction we compute a low",
    "start": "1829679",
    "end": "1835240"
  },
  {
    "text": "probability and for the Triple itself we compute a probability of one and this is",
    "start": "1835240",
    "end": "1841360"
  },
  {
    "text": "mainly because of the high contrast between the two triple triples and if we",
    "start": "1841360",
    "end": "1848039"
  },
  {
    "text": "look at the distribution we see that for those of the extractions where we",
    "start": "1848039",
    "end": "1855440"
  },
  {
    "text": "compute a Hy probability for the extraction to be correct the number of",
    "start": "1855440",
    "end": "1862240"
  },
  {
    "text": "web sources providing USA is almost a half more than the number of web pages",
    "start": "1862240",
    "end": "1870039"
  },
  {
    "text": "that claim Kenya so recall that we want our",
    "start": "1870039",
    "end": "1877519"
  },
  {
    "text": "computed triple probability to be well calibrated and uh this is our",
    "start": "1877519",
    "end": "1883000"
  },
  {
    "text": "calibration curve and we see that although this is kind of a semi uh",
    "start": "1883000",
    "end": "1888880"
  },
  {
    "text": "supervised learning but still here it is CL uh aligned very well with this",
    "start": "1888880",
    "end": "1895200"
  },
  {
    "text": "diagonal line also on these two sides it is very well aligned and actually the",
    "start": "1895200",
    "end": "1900679"
  },
  {
    "text": "majority of the triples fall in these two areas here it is not very well but",
    "start": "1900679",
    "end": "1906679"
  },
  {
    "text": "on the other hand it does not contain that many triples and uh this is about triple",
    "start": "1906679",
    "end": "1914399"
  },
  {
    "text": "correctness and this shows the extraction correctness so for some of",
    "start": "1914399",
    "end": "1919840"
  },
  {
    "text": "the tripos we identify that it has some uh type problem for example claiming",
    "start": "1919840",
    "end": "1926200"
  },
  {
    "text": "somebody's uh place of birth being uh let's say a company which is obviously",
    "start": "1926200",
    "end": "1931799"
  },
  {
    "text": "wrong and for those things the they are definitely wrong extractions and",
    "start": "1931799",
    "end": "1937360"
  },
  {
    "text": "presumably ideally we should compute a very low probability for the extraction to be correct and that is this red line",
    "start": "1937360",
    "end": "1945399"
  },
  {
    "text": "so for 85% s of the triples we compute the probability of zero for the",
    "start": "1945399",
    "end": "1951639"
  },
  {
    "text": "extraction to be correct on the other hand for for the triples in free base",
    "start": "1951639",
    "end": "1959279"
  },
  {
    "text": "which presumably are correct we found that for half of them we compute a",
    "start": "1959279",
    "end": "1967000"
  },
  {
    "text": "probability of over7 for the extraction correctness note that even correct triples can be",
    "start": "1967000",
    "end": "1974399"
  },
  {
    "text": "wrongly extracted so some of for for some others we compute low",
    "start": "1974399",
    "end": "1980960"
  },
  {
    "text": "probabilities and finally this is the pr curve and the r curve of uh our",
    "start": "1980960",
    "end": "1988240"
  },
  {
    "text": "predictions on the triple correctness again they are in kind of a good",
    "start": "1988240",
    "end": "1995278"
  },
  {
    "text": "shape okay any questions so far yes models where the trust that variable a",
    "start": "1997200",
    "end": "2003600"
  },
  {
    "text": "is a distribution over topic so that you know a website could be more trustworthy on",
    "start": "2003600",
    "end": "2009360"
  },
  {
    "text": "certain yes yeah so that's a very good question and actually instead of looking at the whole website we do look uh at",
    "start": "2009360",
    "end": "2018679"
  },
  {
    "text": "website uh predicate pair unless if there are only a few triples for a",
    "start": "2018679",
    "end": "2025559"
  },
  {
    "text": "particular predicate then we merge all such small predicates",
    "start": "2025559",
    "end": "2032080"
  },
  {
    "text": "together yes so where did you get the model that has the constraints like somebody has to be born in a country not",
    "start": "2032399",
    "end": "2038480"
  },
  {
    "text": "a compan so we uh we basically have some um for in in the schema in the knowledge",
    "start": "2038480",
    "end": "2045279"
  },
  {
    "text": "based schema uh we have uh some constraints about like uh if the",
    "start": "2045279",
    "end": "2050638"
  },
  {
    "text": "predicate is place of birth then the object should be",
    "start": "2050639",
    "end": "2055760"
  },
  {
    "text": "location yeah any other",
    "start": "2055760",
    "end": "2061000"
  },
  {
    "text": "question okay so the last question I would like to discuss about in this talk",
    "start": "2061000",
    "end": "2066638"
  },
  {
    "text": "is whether we are really ready to use knowledge-based trust and from the",
    "start": "2066639",
    "end": "2073200"
  },
  {
    "text": "question you possibly sensed that uh the answer is not uh that positive and um uh",
    "start": "2073200",
    "end": "2080638"
  },
  {
    "text": "this might be a little bit disappointing if you believe our you feel the results are interesting and the techniques are",
    "start": "2080639",
    "end": "2087280"
  },
  {
    "text": "interesting however uh this actually shows a lot of good research opportunities so let's start uh talk",
    "start": "2087280",
    "end": "2095560"
  },
  {
    "text": "about it in three aspect aspects input Readiness um the Readiness of technology",
    "start": "2095560",
    "end": "2101760"
  },
  {
    "text": "and the Readiness of output application so let's start with input so",
    "start": "2101760",
    "end": "2108160"
  },
  {
    "text": "we recall that we used 16 extractors to extract uh knowledge triples and uh even",
    "start": "2108160",
    "end": "2116320"
  },
  {
    "text": "so the extraction is uh very low quality so on the one hand the extraction is",
    "start": "2116320",
    "end": "2123560"
  },
  {
    "text": "very sparse for 74% of the knowledge B and of the URLs we have at most five",
    "start": "2123560",
    "end": "2133240"
  },
  {
    "text": "triples and so we don't have enough information to say this is trustworthy",
    "start": "2133240",
    "end": "2138520"
  },
  {
    "text": "or not and in fact we compute reliable KBT only for less than 20% of the",
    "start": "2138520",
    "end": "2147160"
  },
  {
    "text": "websites and for far less than 5% of the web",
    "start": "2147160",
    "end": "2153359"
  },
  {
    "text": "pages and on the other hand the extraction is not not only sparse but of",
    "start": "2153359",
    "end": "2158400"
  },
  {
    "text": "very low quality I really hate to say what is the accuracy of the extraction",
    "start": "2158400",
    "end": "2164319"
  },
  {
    "text": "but it already shows up here it is as low as 11.5% meaning if I extracted 10 triples",
    "start": "2164319",
    "end": "2172000"
  },
  {
    "text": "then n of them are wrong so I mean so so the expectation is likely to be like a",
    "start": "2172000",
    "end": "2178240"
  },
  {
    "text": "garbage in garbage out although we work very very hard but still uh we might",
    "start": "2178240",
    "end": "2184800"
  },
  {
    "text": "miss some wrongly extracted triples still predict them as correct as a",
    "start": "2184800",
    "end": "2190920"
  },
  {
    "text": "result for those web sources we will compute a relatively lower accuracy",
    "start": "2190920",
    "end": "2197920"
  },
  {
    "text": "trustworthiness for them and another problem is that we have an imbalance",
    "start": "2197920",
    "end": "2204880"
  },
  {
    "text": "between the extraction extraction on free Tex and extraction on d trees d",
    "start": "2204880",
    "end": "2212720"
  },
  {
    "text": "trees have some structure can be considered as semi-structure data and there we have a better extraction",
    "start": "2212720",
    "end": "2220240"
  },
  {
    "text": "quality and for free tax we have lower quality and among the 100 sample",
    "start": "2220240",
    "end": "2226960"
  },
  {
    "text": "sources with uh KBT over 0.9 uh 95% of them are mainly",
    "start": "2226960",
    "end": "2233960"
  },
  {
    "text": "semi-structured data",
    "start": "2233960",
    "end": "2240040"
  },
  {
    "text": "H extract what the web page said correctly or that the web",
    "start": "2240040",
    "end": "2245599"
  },
  {
    "text": "page and you extracted the the correct line",
    "start": "2245599",
    "end": "2251480"
  },
  {
    "text": "uhuh that's a good question and here actually when I say the accuracy is",
    "start": "2251480",
    "end": "2256680"
  },
  {
    "text": "11.5% it means among all of the extractions among all of the extracted",
    "start": "2256680",
    "end": "2262680"
  },
  {
    "text": "triples 11.5% of the triples are considered to are really true consistent",
    "start": "2262680",
    "end": "2268880"
  },
  {
    "text": "with the real world and for the wrong triples yes some of them are indeed provided by some bad sources however",
    "start": "2268880",
    "end": "2276839"
  },
  {
    "text": "recall that I said we did our sampling on 25 uh uh wrong triples and the 24 of",
    "start": "2276839",
    "end": "2283200"
  },
  {
    "text": "them are because of extraction errors yes um how do you validate",
    "start": "2283200",
    "end": "2290720"
  },
  {
    "text": "accuracy do you do that uh like manity of use another yeah that's a good",
    "start": "2290720",
    "end": "2297240"
  },
  {
    "text": "question so it's about how we uh evaluate the accuracy we take the uh we",
    "start": "2297240",
    "end": "2303640"
  },
  {
    "text": "take the free base as our goal standard however free base only tells us what is",
    "start": "2303640",
    "end": "2309760"
  },
  {
    "text": "true it doesn't tell us what is wrong and uh we apply a local closed word",
    "start": "2309760",
    "end": "2316599"
  },
  {
    "text": "assumption meaning if uh free Bas have some information about Barack Obama's",
    "start": "2316599",
    "end": "2324079"
  },
  {
    "text": "children and then for whatever not in free base we will consider them as wrong",
    "start": "2324079",
    "end": "2330960"
  },
  {
    "text": "in our go standard because we assume once it has some information about",
    "start": "2330960",
    "end": "2337200"
  },
  {
    "text": "uh uh a state item about entity attribute it has complete information so",
    "start": "2337200",
    "end": "2344680"
  },
  {
    "text": "that's local closed word however if uh free base doesn't say anything about uh",
    "start": "2344680",
    "end": "2351480"
  },
  {
    "text": "Obama's children then whatever we see we say a no we don't know if that's correct",
    "start": "2351480",
    "end": "2357440"
  },
  {
    "text": "or not yes I'm still slightly confused on the difference you're describing to",
    "start": "2357440",
    "end": "2364359"
  },
  {
    "text": "Truth versus accuracy [Music] so truth is basically saying whether",
    "start": "2364359",
    "end": "2371440"
  },
  {
    "text": "given a triple subject predicate object whether it is correct or not correct",
    "start": "2371440",
    "end": "2378079"
  },
  {
    "text": "uhuh that's my problem uhuh truth to mean to me means it's uh makes absolute",
    "start": "2378079",
    "end": "2385240"
  },
  {
    "text": "sense in the physical world and accuracy is your triples",
    "start": "2385240",
    "end": "2390480"
  },
  {
    "text": "reflecting what you want them to reflect want them to reflect so you're",
    "start": "2390480",
    "end": "2398720"
  },
  {
    "text": "saying that right triple your algorithm is working that that's a Precision thing",
    "start": "2398720",
    "end": "2404640"
  },
  {
    "text": "that's an accuracy thing truth means that it's true in the world",
    "start": "2404640",
    "end": "2409839"
  },
  {
    "text": "physically so like you can get lots of accurate triples with creationism or",
    "start": "2409839",
    "end": "2415720"
  },
  {
    "text": "global warming yes you know that's going to be they fit your algorithm just fine",
    "start": "2415720",
    "end": "2421079"
  },
  {
    "text": "none of that's true you know it has to be true to be",
    "start": "2421079",
    "end": "2427040"
  },
  {
    "text": "uh consistent yeah so um I guess there are two parts of it and one part of it",
    "start": "2427040",
    "end": "2435520"
  },
  {
    "text": "is um whether this is already kind of decided to be true true or false and uh",
    "start": "2435520",
    "end": "2443599"
  },
  {
    "text": "whether we have I mean in the physical world we already know it is true or false not that everything is at simple",
    "start": "2443599",
    "end": "2450680"
  },
  {
    "text": "as saying somebody's nationality being something and uh in that case like the global warm in thing I mean it is fuzzy",
    "start": "2450680",
    "end": "2460200"
  },
  {
    "text": "and um we basically sort of uh leverage the agreement between the sources and",
    "start": "2460200",
    "end": "2466280"
  },
  {
    "text": "leverage and we trust the authoritative sources more than other sources so we",
    "start": "2466280",
    "end": "2473160"
  },
  {
    "text": "make our decisions on both of them on the other hand we also have this kind of",
    "start": "2473160",
    "end": "2479200"
  },
  {
    "text": "a simple fact and uh sophisticated facts and for example coming back to the to",
    "start": "2479200",
    "end": "2486040"
  },
  {
    "text": "the to the news headline when I say um when it says Google is going to use",
    "start": "2486040",
    "end": "2493280"
  },
  {
    "text": "facts not links to rank the websites it is false but if it doesn't say Not facts",
    "start": "2493280",
    "end": "2501760"
  },
  {
    "text": "then I mean whether it is true or false it is not clear so for those sophisticated facts we even do not have",
    "start": "2501760",
    "end": "2508839"
  },
  {
    "text": "a way to sort of uh represented using the knowledge triples and finally",
    "start": "2508839",
    "end": "2516280"
  },
  {
    "text": "basically here I'm saying factual information I'm not saying anything about predictions or anything about the",
    "start": "2516280",
    "end": "2523240"
  },
  {
    "text": "opinions and so on does that answer your",
    "start": "2523240",
    "end": "2528160"
  },
  {
    "text": "question okay uh any other question yes this all about maybe narrowing down the",
    "start": "2530880",
    "end": "2537960"
  },
  {
    "text": "domain a little bit so that you can increase the accuracy um in terms of the",
    "start": "2537960",
    "end": "2546839"
  },
  {
    "text": "if our goal is to extract correct triples then it would be good to narrow",
    "start": "2546839",
    "end": "2553520"
  },
  {
    "text": "down the domains however if our goal is to uh",
    "start": "2553520",
    "end": "2559720"
  },
  {
    "text": "evaluate the quality of a web Source we should look at whatever facts it the web",
    "start": "2559720",
    "end": "2567440"
  },
  {
    "text": "Source claims yes but what what I'm thinking is",
    "start": "2567440",
    "end": "2573920"
  },
  {
    "text": "that um so so Al in reality a statement could be two under different models",
    "start": "2573920",
    "end": "2579520"
  },
  {
    "text": "assumptions for example if you have certain things that assume that human beings are Ral then you have theorems",
    "start": "2579520",
    "end": "2585559"
  },
  {
    "text": "that what be true under those assumptions and then you will have you follow model like Behavior",
    "start": "2585559",
    "end": "2592119"
  },
  {
    "text": "economics and you find people do a lot irrational things they both could be",
    "start": "2592119",
    "end": "2597160"
  },
  {
    "text": "true under the in in duplication and then there are things that that change according to",
    "start": "2597160",
    "end": "2603319"
  },
  {
    "text": "context for example it's R now this could be true at one place but false in a different place it could the truth",
    "start": "2603319",
    "end": "2609920"
  },
  {
    "text": "value could vary from time to time and that things about taste and so all so all those it seems that if you narrow it",
    "start": "2609920",
    "end": "2616720"
  },
  {
    "text": "down to a particular context or domain then you could have more precise meaning of whether it's accurate or not",
    "start": "2616720",
    "end": "2622880"
  },
  {
    "text": "otherwise both them could be true but you know was patient M so very good",
    "start": "2622880",
    "end": "2628520"
  },
  {
    "text": "question so there are basically two parts let me first say about the second part an example is H it is raining now",
    "start": "2628520",
    "end": "2635920"
  },
  {
    "text": "it is not true in general for the whole world but if we say it is raining now in",
    "start": "2635920",
    "end": "2641839"
  },
  {
    "text": "palado uh at the Stanford area then it is possibly true or false and in that",
    "start": "2641839",
    "end": "2647599"
  },
  {
    "text": "case we actually make sure that uh in our knowledge triple it is very specific",
    "start": "2647599",
    "end": "2653359"
  },
  {
    "text": "so for example when we say uh this is the height of somebody we wouldn't say",
    "start": "2653359",
    "end": "2658520"
  },
  {
    "text": "just 163 we will say uh 163 cm or some",
    "start": "2658520",
    "end": "2664720"
  },
  {
    "text": "uh 55 ft Etc and uh for your first uh statement",
    "start": "2664720",
    "end": "2670520"
  },
  {
    "text": "like uh some of the uh statements is based on some assumptions with this",
    "start": "2670520",
    "end": "2677119"
  },
  {
    "text": "assumptions this is correct but with some other assumptions this is incorrect this is very interesting research topic",
    "start": "2677119",
    "end": "2684760"
  },
  {
    "text": "and uh we currently work on finding out different perspectives because the",
    "start": "2684760",
    "end": "2689839"
  },
  {
    "text": "perspectives basically are based on some assumptions for example if you consider",
    "start": "2689839",
    "end": "2695079"
  },
  {
    "text": "the uh liberal View and uh conservative view in po politics Ian it also has some",
    "start": "2695079",
    "end": "2701599"
  },
  {
    "text": "assumptions associated with it it's hard to say if it is true or false but associated with some assumption then we",
    "start": "2701599",
    "end": "2708640"
  },
  {
    "text": "can roughly say yeah it possibly is true or false with this",
    "start": "2708640",
    "end": "2715440"
  },
  {
    "text": "assumption yes how do you deal with Providence where one site is really",
    "start": "2715440",
    "end": "2720480"
  },
  {
    "text": "derived from another site for example there are many sites which scrape the Wall Street Journal or Wikipedia how do",
    "start": "2720480",
    "end": "2726280"
  },
  {
    "text": "you keep from that both of them look equally correct but but you would register those as two confirming sources",
    "start": "2726280",
    "end": "2733839"
  },
  {
    "text": "when they really aren't this is an excellent question basically what if the",
    "start": "2733839",
    "end": "2738960"
  },
  {
    "text": "data one data source CP data from another source or copy data from another source or whatever and I like this",
    "start": "2738960",
    "end": "2745240"
  },
  {
    "text": "question so much that I spent five years doing research on it detecting the copying relationships between the",
    "start": "2745240",
    "end": "2752000"
  },
  {
    "text": "structured data and uh our basic idea since I think think we have time uh so",
    "start": "2752000",
    "end": "2757559"
  },
  {
    "text": "our basic idea is like this if you have some multi-choice uh answer uh questions for",
    "start": "2757559",
    "end": "2765000"
  },
  {
    "text": "uh for the students and now you get two answer sheets and they are exactly the same and both of them have full score",
    "start": "2765000",
    "end": "2772359"
  },
  {
    "text": "will you say what must copy the other without any prior knowledge about whether they are good students or bad",
    "start": "2772359",
    "end": "2779240"
  },
  {
    "text": "that's so good students you possibly wouldn't say one H has to copy from the",
    "start": "2779240",
    "end": "2784440"
  },
  {
    "text": "other because they can both be excellent students and give perfect answers",
    "start": "2784440",
    "end": "2790119"
  },
  {
    "text": "however if you see two answer sheets exactly the same and they make a lot of common mistakes at this point you would",
    "start": "2790119",
    "end": "2797480"
  },
  {
    "text": "say okay why do you make so many common mistakes so that's the intuition and we",
    "start": "2797480",
    "end": "2804079"
  },
  {
    "text": "use the intuition to find out copying relationship and we will lower the B for",
    "start": "2804079",
    "end": "2811200"
  },
  {
    "text": "the copers yeah so however for this actually",
    "start": "2811200",
    "end": "2816839"
  },
  {
    "text": "comes to this um uh page uh this slide so for this copy detection although we",
    "start": "2816839",
    "end": "2824000"
  },
  {
    "text": "did so much work and we found that it works perfectly for not perfectly works very well for like thousands of data",
    "start": "2824000",
    "end": "2830760"
  },
  {
    "text": "sources we just cannot get it scale to billions of data sources it's just too",
    "start": "2830760",
    "end": "2836640"
  },
  {
    "text": "many data sources when we need to have a complexity of o n Square so that part is",
    "start": "2836640",
    "end": "2842800"
  },
  {
    "text": "still left out for this work but it is important so I see you also have",
    "start": "2842800",
    "end": "2850160"
  },
  {
    "text": "question um so I mean one you haven't said much about how you're extracting",
    "start": "2850160",
    "end": "2856240"
  },
  {
    "text": "facts from from natural language which is hard enough and you know presumably that's why most of your accurate facts",
    "start": "2856240",
    "end": "2862200"
  },
  {
    "text": "come from the semi structure stuff but but you know I guess you know how could",
    "start": "2862200",
    "end": "2867640"
  },
  {
    "text": "could that be improved with better with better te Tex parsing or so let me try to be really I think of",
    "start": "2867640",
    "end": "2876640"
  },
  {
    "text": "funding here are there any people here doing natural language processing a lot",
    "start": "2876640",
    "end": "2882040"
  },
  {
    "text": "right and do you think we are fully ready for extracting Knowledge from the web arbitrary web",
    "start": "2882040",
    "end": "2890960"
  },
  {
    "text": "pages well I guess I work on uh Deep dive which is a yes how you work on Deep",
    "start": "2893440",
    "end": "2899319"
  },
  {
    "text": "dive so that's somewhere in between thinking NLP is very necessary or just a",
    "start": "2899319",
    "end": "2904839"
  },
  {
    "text": "supporting tool so somewhere in the middle for deep dive the interesting thing is to my understanding it is about",
    "start": "2904839",
    "end": "2912640"
  },
  {
    "text": "the a gan science domain not the full web",
    "start": "2912640",
    "end": "2917720"
  },
  {
    "text": "right I think general liability I work on a genan stuff but uh",
    "start": "2917720",
    "end": "2923040"
  },
  {
    "text": "yeah um I mean like at free based level",
    "start": "2923040",
    "end": "2929319"
  },
  {
    "text": "comparing against Freebase lot of those things are are I think where we we have",
    "start": "2929319",
    "end": "2934960"
  },
  {
    "text": "decent extraction capabilities M that's very nice yeah so typically like as I",
    "start": "2934960",
    "end": "2940799"
  },
  {
    "text": "said from our extractions for the even from the same project we found that extractions on",
    "start": "2940799",
    "end": "2948119"
  },
  {
    "text": "free text is the quality is much lower than than the extraction on uh",
    "start": "2948119",
    "end": "2953880"
  },
  {
    "text": "semi-structure data and uh we do have uh some LP tools to do The annotation for",
    "start": "2953880",
    "end": "2960680"
  },
  {
    "text": "web contents and then we apply like this supervision ET such to learn the",
    "start": "2960680",
    "end": "2967680"
  },
  {
    "text": "patterns but uh it is still aror PR and one of the reasons of uh these arrows is",
    "start": "2967680",
    "end": "2973760"
  },
  {
    "text": "because we don't have enough negative examples kind of a side question on this",
    "start": "2973760",
    "end": "2981160"
  },
  {
    "text": "whole thing but I noticed that if I plug in three keywords or four keywords on my computer I get certain results if I plug",
    "start": "2981160",
    "end": "2988559"
  },
  {
    "text": "in the same exact keywords into somebody else's computer I'll get different",
    "start": "2988559",
    "end": "2993920"
  },
  {
    "text": "results is that because of previous history on the computer so it is more of the personal search so uh I assume you",
    "start": "2993920",
    "end": "3003280"
  },
  {
    "text": "are talking about Google I don't know if other if like Bing is doing similar",
    "start": "3003280",
    "end": "3008960"
  },
  {
    "text": "things but uh Google has this personal search and it will look at your search uh history look at your clickthrough",
    "start": "3008960",
    "end": "3016240"
  },
  {
    "text": "history and then it will decide okay when you talk about Apple you mean the",
    "start": "3016240",
    "end": "3021400"
  },
  {
    "text": "the iPhone company you are not talking about what to eat",
    "start": "3021400",
    "end": "3026440"
  },
  {
    "text": "yeah and maybe for uh like for people who plant apples it is",
    "start": "3026440",
    "end": "3032880"
  },
  {
    "text": "different so clearing my history all the time religiously probably affects what I",
    "start": "3032880",
    "end": "3039280"
  },
  {
    "text": "search yeah the history stored on their end instead of your",
    "start": "3039280",
    "end": "3044839"
  },
  {
    "text": "end yeah next don't don't destroy",
    "start": "3044839",
    "end": "3050680"
  },
  {
    "text": "youy you okay so move ahead",
    "start": "3050680",
    "end": "3056480"
  },
  {
    "text": "yes if you have multiple user logins on a Mac or a PC is this um past history",
    "start": "3056480",
    "end": "3067480"
  },
  {
    "text": "kept in the per user database or is it more Global uh it is per user and very",
    "start": "3067480",
    "end": "3074720"
  },
  {
    "text": "likely per machine well so let me put it in this way if you if uh so if you lo lo uh if",
    "start": "3074720",
    "end": "3082079"
  },
  {
    "text": "you use the same let's say uh Gmail uh account then it is per user if you do",
    "start": "3082079",
    "end": "3089839"
  },
  {
    "text": "not log in it is more of per machine and if somebody else logs in",
    "start": "3089839",
    "end": "3095920"
  },
  {
    "text": "yeah that's true it will basically attribute it to different uh",
    "start": "3095920",
    "end": "3102200"
  },
  {
    "text": "accounts okay so let's come back to trust worthiness instead of uh personal",
    "start": "3103440",
    "end": "3108799"
  },
  {
    "text": "search uh so we talked about the input Readiness and um it's not that ready yet",
    "start": "3108799",
    "end": "3115880"
  },
  {
    "text": "and for the techniques we already mentioned some of them like the simple versus sophisticated facts about",
    "start": "3115880",
    "end": "3123040"
  },
  {
    "text": "different perspectives about the copy detection and one thing I didn't mention",
    "start": "3123040",
    "end": "3128319"
  },
  {
    "text": "that much in my uh graphical model is that we assume for each subject",
    "start": "3128319",
    "end": "3134200"
  },
  {
    "text": "predicate pair there is a single Choice which is obvious obviously not true so",
    "start": "3134200",
    "end": "3139480"
  },
  {
    "text": "like uh a person could author multiple uh uh books and uh a movie star could",
    "start": "3139480",
    "end": "3146520"
  },
  {
    "text": "play in multiple movies and um why do we use this single Choice model we do have",
    "start": "3146520",
    "end": "3152599"
  },
  {
    "text": "a multi choose model but if we compare the results the single choose model is so much better and when we use multi-",
    "start": "3152599",
    "end": "3159160"
  },
  {
    "text": "choose model the Precision dropped significantly and this is also associated with the fact that uh we have",
    "start": "3159160",
    "end": "3166760"
  },
  {
    "text": "a very bad extraction so if we use the single choose model Yes we made some of",
    "start": "3166760",
    "end": "3172880"
  },
  {
    "text": "the correct facts but on the other hand we filter the huge amount of",
    "start": "3172880",
    "end": "3179079"
  },
  {
    "text": "noise and uh another thing we don't capture is the value similarity so for",
    "start": "3179079",
    "end": "3184839"
  },
  {
    "text": "example we have some ex uh like we have some like gold standard or what we",
    "start": "3184839",
    "end": "3191799"
  },
  {
    "text": "decided to be correct saying that somebody was born in Oakland but on the other hand we see a source saying",
    "start": "3191799",
    "end": "3198480"
  },
  {
    "text": "somebody was born in San Francisco and then we say this is incorrect however",
    "start": "3198480",
    "end": "3204359"
  },
  {
    "text": "what this San Fran Isco might be just referring to the big large San Francisco",
    "start": "3204359",
    "end": "3211119"
  },
  {
    "text": "area and um another thing is uh I think one of the questions mentioned about",
    "start": "3211119",
    "end": "3217599"
  },
  {
    "text": "this is kind of a triple filtering we found we cannot evaluate based on all of",
    "start": "3217599",
    "end": "3223760"
  },
  {
    "text": "the extracted triples recall that I said we sampled 100 websites for 15 of them",
    "start": "3223760",
    "end": "3231160"
  },
  {
    "text": "we are not confident that they are trustworthy and actually two of them uh",
    "start": "3231160",
    "end": "3238000"
  },
  {
    "text": "we extracted triples irrelevant to the topic of the source for example for one",
    "start": "3238000",
    "end": "3243880"
  },
  {
    "text": "of the web series it gives the business listings in Brazil but all of our",
    "start": "3243880",
    "end": "3249559"
  },
  {
    "text": "extracted triple says this city belongs to this state uh this city has this sip",
    "start": "3249559",
    "end": "3255000"
  },
  {
    "text": "code this state belongs to Brazil and so on so it doesn't have anything regarding the business listing and then just to",
    "start": "3255000",
    "end": "3262280"
  },
  {
    "text": "say this is a trustworthy sources because of the geography information correctness this is not fair and we have",
    "start": "3262280",
    "end": "3271119"
  },
  {
    "text": "12 sources where we basically evaluate on the trivial triples and trivial",
    "start": "3271119",
    "end": "3278839"
  },
  {
    "text": "basically means something that is obviously true and as an example we have",
    "start": "3278839",
    "end": "3283880"
  },
  {
    "text": "a source that provides hotel listings and most of our extracted triple says",
    "start": "3283880",
    "end": "3289520"
  },
  {
    "text": "what is the accommodation type of this hotel and 95% of the uh types are hotel",
    "start": "3289520",
    "end": "3296880"
  },
  {
    "text": "and uh if you see this is a hotel website where all we know is those hotels have accommodation type Hotel you",
    "start": "3296880",
    "end": "3304680"
  },
  {
    "text": "really can't say this is a trustworthy source so we need to do all of the things to filter the triples that are",
    "start": "3304680",
    "end": "3312200"
  },
  {
    "text": "irrelevant give lower weight to the trival triples",
    "start": "3312200",
    "end": "3317558"
  },
  {
    "text": "Etc and uh finally let's look at the output application Readiness the",
    "start": "3317799",
    "end": "3323799"
  },
  {
    "text": "customer Readiness there are basically two usages of the trust worthiness score",
    "start": "3323799",
    "end": "3329119"
  },
  {
    "text": "the first one is to predict the quality for websites and web pages and uh to use",
    "start": "3329119",
    "end": "3335200"
  },
  {
    "text": "this we have to combine this with some other signals like like the page Rank and the clickthrough rate and currently",
    "start": "3335200",
    "end": "3342319"
  },
  {
    "text": "it is not super clear how to do the combination and uh a second uh",
    "start": "3342319",
    "end": "3348280"
  },
  {
    "text": "application is to recommend sources if I want to collect knowledge about this vertical regarding uh food the cheese",
    "start": "3348280",
    "end": "3355559"
  },
  {
    "text": "variety what are the data sources where I can get uh uh a lot of uh good high",
    "start": "3355559",
    "end": "3362119"
  },
  {
    "text": "accurate information and um here the interesting thing is uh we can consider",
    "start": "3362119",
    "end": "3368000"
  },
  {
    "text": "those verticals or domains as head verticals and tail verticals for head verticals like movie like song we know",
    "start": "3368000",
    "end": "3376200"
  },
  {
    "text": "what are the good data sources and for movie let's say I mean you know you want to go to MDB and uh you don't need any",
    "start": "3376200",
    "end": "3383240"
  },
  {
    "text": "recommendation for it but for for the long tals uh we have some uh recommendations",
    "start": "3383240",
    "end": "3392000"
  },
  {
    "text": "but because of the sparsity of the extractions uh we might miss some good",
    "start": "3392000",
    "end": "3400079"
  },
  {
    "text": "sources and here it actually comes to my sort of uh um suggestion to the research",
    "start": "3400240",
    "end": "3407559"
  },
  {
    "text": "community and I think now if you look at the like a knowledge uh uh curation",
    "start": "3407559",
    "end": "3413839"
  },
  {
    "text": "knowledge extraction knowledge man Management Systems uh there are they",
    "start": "3413839",
    "end": "3419440"
  },
  {
    "text": "they they have done very good job but uh it's more about the head entities and",
    "start": "3419440",
    "end": "3426039"
  },
  {
    "text": "the head verticals and um however if I have ACC company and I want to extract knowledge",
    "start": "3426039",
    "end": "3433640"
  },
  {
    "text": "for uh a particular head vertical what I might what will I do I will buy data",
    "start": "3433640",
    "end": "3440119"
  },
  {
    "text": "from some authoritative sources W which everybody knows and then I will hire 50",
    "start": "3440119",
    "end": "3446039"
  },
  {
    "text": "Engineers to script the data for it and then I have high quality data and I can",
    "start": "3446039",
    "end": "3451359"
  },
  {
    "text": "refresh the data from time to time and I don't need to worry about the quality issue but for the kind of the uh",
    "start": "3451359",
    "end": "3458400"
  },
  {
    "text": "arbitrary extractions as I mentioned the quality can be quite low on the other",
    "start": "3458400",
    "end": "3463599"
  },
  {
    "text": "hand this engineering approach it does not scale to the tail entities to the",
    "start": "3463599",
    "end": "3468920"
  },
  {
    "text": "tail verticals where we might have like millions of tail verticals but we don't",
    "start": "3468920",
    "end": "3474000"
  },
  {
    "text": "know what are the good good sources and we don't know where to get the good data and so I'm hoping um the research could",
    "start": "3474000",
    "end": "3483000"
  },
  {
    "text": "really help for those body to tail data for those long tails and so here the",
    "start": "3483000",
    "end": "3489200"
  },
  {
    "text": "call to arm thing is we want to leave no valuable data behind including tail",
    "start": "3489200",
    "end": "3495079"
  },
  {
    "text": "verticals tail sources tail entities tail attributes and also data from let's",
    "start": "3495079",
    "end": "3500760"
  },
  {
    "text": "say a long time ago uh kind of um maybe out date but it would be valuable",
    "start": "3500760",
    "end": "3506720"
  },
  {
    "text": "history data so typically I would end my talk with some go links and here I will end",
    "start": "3506720",
    "end": "3513760"
  },
  {
    "text": "my talk with some notgo links and for knowledge based trust.org and",
    "start": "3513760",
    "end": "3519280"
  },
  {
    "text": "knowledgebase trust.com uh these are registered during the news busz week and",
    "start": "3519280",
    "end": "3525480"
  },
  {
    "text": "we have no control of it and we wouldn't be responsible for lack of information there and uh with this I will end my",
    "start": "3525480",
    "end": "3532480"
  },
  {
    "text": "talk thank you",
    "start": "3532480",
    "end": "3536720"
  },
  {
    "text": "so any question yes so did you just open a new field for search Eng optimization",
    "start": "3538119",
    "end": "3543359"
  },
  {
    "text": "and spam creation uh so yes I think this can be",
    "start": "3543359",
    "end": "3549119"
  },
  {
    "text": "considered as a new field to decide the trustworthiness to decide the",
    "start": "3549119",
    "end": "3554680"
  },
  {
    "text": "truthfulness we don't you don't hire a certain doation company because you want to be more truthful you want more",
    "start": "3554680",
    "end": "3562319"
  },
  {
    "text": "traffic uh how ever I mean if uh you get",
    "start": "3562319",
    "end": "3568000"
  },
  {
    "text": "boosted with more trustworthy data then I mean you will have more",
    "start": "3568000",
    "end": "3574799"
  },
  {
    "text": "traffic yeah but just because you added more trustworthy data doesn't make",
    "start": "3574799",
    "end": "3581760"
  },
  {
    "text": "you why I answered 5,000 great facts just",
    "start": "3581760",
    "end": "3587680"
  },
  {
    "text": "to slip the one untruth that I want you to have so that is a very good point and",
    "start": "3587680",
    "end": "3593760"
  },
  {
    "text": "this is actually one of the challenges I mentioned we need to figure out so first",
    "start": "3593760",
    "end": "3599440"
  },
  {
    "text": "we need to figure out what is the tribess of those information if a lot of",
    "start": "3599440",
    "end": "3606079"
  },
  {
    "text": "the information is basically saying the sky is blue birds could fly Etc and that",
    "start": "3606079",
    "end": "3612119"
  },
  {
    "text": "could shouldn't be given a lot of weight and the second I mean smart people they can put a lot of uh non-trivial correct",
    "start": "3612119",
    "end": "3620799"
  },
  {
    "text": "information and then say hey this uh this uh singer sings this song and this",
    "start": "3620799",
    "end": "3627359"
  },
  {
    "text": "uh uh politician is from this country blah blah blah blah and then finally he says oh by the way Obama is really from",
    "start": "3627359",
    "end": "3634559"
  },
  {
    "text": "Kenya and then we would be biased by the many like a correct facts so that's",
    "start": "3634559",
    "end": "3640079"
  },
  {
    "text": "something very interesting and we are still considering how to solve that",
    "start": "3640079",
    "end": "3646520"
  },
  {
    "text": "problem how do you handle conflict between authorities uh the case in mind",
    "start": "3647480",
    "end": "3655200"
  },
  {
    "text": "uh the discovery of of misfolded proteins which was denigrated for a",
    "start": "3655200",
    "end": "3661039"
  },
  {
    "text": "number of years until uh St prisoner was able to prove it got the noble price for",
    "start": "3661039",
    "end": "3667160"
  },
  {
    "text": "it but that sort of uh knowledge coming out and being",
    "start": "3667160",
    "end": "3675039"
  },
  {
    "text": "denied so uh this actually is related to one of the uh research ideas which we",
    "start": "3675039",
    "end": "3682280"
  },
  {
    "text": "call a time machine and uh for time machine there are basically two things",
    "start": "3682280",
    "end": "3687799"
  },
  {
    "text": "we want to discover one is the evolving truth and uh something is correct at",
    "start": "3687799",
    "end": "3693720"
  },
  {
    "text": "some point for example using the simplest example uh I'm working for Google Now and 5 years ago I'm working",
    "start": "3693720",
    "end": "3701559"
  },
  {
    "text": "for another company and 10 years ago I'm a graduate student from udub something",
    "start": "3701559",
    "end": "3706920"
  },
  {
    "text": "like this so the choose is evolving over time and the second thing is uh the s of",
    "start": "3706920",
    "end": "3715039"
  },
  {
    "text": "uh the belief of Truth so for example at some point people believe uh the the the",
    "start": "3715039",
    "end": "3722839"
  },
  {
    "text": "the sun is rotating around the earth and it is certainly not true but at some",
    "start": "3722839",
    "end": "3728359"
  },
  {
    "text": "point it is believed to be true and uh I believe there should be a",
    "start": "3728359",
    "end": "3734240"
  },
  {
    "text": "lot of like uh research can can be done on this yes what is the best way to",
    "start": "3734240",
    "end": "3742359"
  },
  {
    "text": "validate authoritative sources so this is actually a very interesting",
    "start": "3742359",
    "end": "3749559"
  },
  {
    "text": "question what is the best way to validate the authoritative sources and",
    "start": "3749559",
    "end": "3755520"
  },
  {
    "text": "uh we found that uh because the majority of the data sources they do not",
    "start": "3755520",
    "end": "3761039"
  },
  {
    "text": "intention intentionally give bad information and typically if something",
    "start": "3761039",
    "end": "3767359"
  },
  {
    "text": "is correct then there will be more sources claiming it or more authorita",
    "start": "3767359",
    "end": "3774440"
  },
  {
    "text": "ative source is claiming it if a authoritative source is claiming something opposite to most of the other",
    "start": "3774440",
    "end": "3782400"
  },
  {
    "text": "sources then it is really a question mark of whether it is true or false it",
    "start": "3782400",
    "end": "3788119"
  },
  {
    "text": "we might compute probability not really zero but like 04.5 but it's a question mark it",
    "start": "3788119",
    "end": "3795160"
  },
  {
    "text": "basically says we are not sure if this correct or not",
    "start": "3795160",
    "end": "3802520"
  },
  {
    "text": "yeah I look at different Leading Edge science and different Leading Edge science is usually one qualitative",
    "start": "3803279",
    "end": "3810039"
  },
  {
    "text": "source and everybody else is wrong so you can't do it by quantity I",
    "start": "3810039",
    "end": "3816119"
  },
  {
    "text": "agree I agree and that's why so let's say if you are a good source and I'm a",
    "start": "3816119",
    "end": "3822079"
  },
  {
    "text": "bad source and uh let's say we are all about scientific things and at some",
    "start": "3822079",
    "end": "3827400"
  },
  {
    "text": "point I come up with a new discovery which unfortunately is wrong but because",
    "start": "3827400",
    "end": "3834279"
  },
  {
    "text": "because I'm a bad source and for that Discovery it will be given a low",
    "start": "3834279",
    "end": "3839920"
  },
  {
    "text": "probability and because you are a good source and if you come up with some Discovery you will get much higher",
    "start": "3839920",
    "end": "3847480"
  },
  {
    "text": "probability although you conflict with the rest of the world and you will have",
    "start": "3847480",
    "end": "3852680"
  },
  {
    "text": "a higher probability to start with and hopefully with more and more people like agreeing with you the probability will",
    "start": "3852680",
    "end": "3859359"
  },
  {
    "text": "go upar I don't know how you algorithmically make a decision",
    "start": "3859359",
    "end": "3865480"
  },
  {
    "text": "how did you a good guy how do you know that was a good guy or a bad guy oh that's a very good question so we the",
    "start": "3865480",
    "end": "3871839"
  },
  {
    "text": "good guys bad guys have just flipped right yes we so we have two ways the",
    "start": "3871839",
    "end": "3877559"
  },
  {
    "text": "first way is we start with the assuming all of the sources have the same quality",
    "start": "3877559",
    "end": "3884520"
  },
  {
    "text": "and uh then recall that uh we iteratively compute these probabilities",
    "start": "3884520",
    "end": "3890880"
  },
  {
    "text": "and quality until it converges or until a certain number of rounds so this is a",
    "start": "3890880",
    "end": "3897119"
  },
  {
    "text": "purely unsupervised way and a second way is that uh we boot strap the quality of",
    "start": "3897119",
    "end": "3903760"
  },
  {
    "text": "a data source using some goal standard for example using the free base with the local closed word",
    "start": "3903760",
    "end": "3911400"
  },
  {
    "text": "assumption question well no I understand a little bit of how I'm just not sure",
    "start": "3914520",
    "end": "3920880"
  },
  {
    "text": "it's 100% correct you know maybe 99% 98%",
    "start": "3920880",
    "end": "3926520"
  },
  {
    "text": "maybe that's good yeah I mean I I the the the only thing I could say is uh I mean there are",
    "start": "3926520",
    "end": "3933279"
  },
  {
    "text": "definitely problems and there are definitely wrong decisions but according to the results this is what we",
    "start": "3933279",
    "end": "3941920"
  },
  {
    "text": "get if you've done any work in like trying to characterize what of the sources of inaccurate information like",
    "start": "3941960",
    "end": "3948240"
  },
  {
    "text": "you know that that Obama was born in Kenya clearly that's from you know politically motivated SES but you know",
    "start": "3948240",
    "end": "3954359"
  },
  {
    "text": "you mentioned gossip sites I wonder are there other broad broad categories or",
    "start": "3954359",
    "end": "3959559"
  },
  {
    "text": "sources of inaccurate information you youve discovered we haven't done so it would be very interesting research did",
    "start": "3959559",
    "end": "3965799"
  },
  {
    "text": "you see the one recently where somebody it was a school in India that was a sham",
    "start": "3965799",
    "end": "3972039"
  },
  {
    "text": "but they managed to infiltrate Wikipedia no I get",
    "start": "3972039",
    "end": "3978760"
  },
  {
    "text": "the I'm I'm in the in the belg royal family okay so",
    "start": "3978760",
    "end": "3984720"
  },
  {
    "text": "uh how sensitive is it to your ranking function what if you use say harmonic mean instead of arithmetic",
    "start": "3984720",
    "end": "3991760"
  },
  {
    "text": "mean maximum likel or yeah there's a bunch of different so so we we actually",
    "start": "3991760",
    "end": "3998559"
  },
  {
    "text": "started with thinking about we use the maximum likelihood and that's basically",
    "start": "3998559",
    "end": "4003960"
  },
  {
    "text": "the M step that's a true M step but then it turns out to be very complex and uh",
    "start": "4003960",
    "end": "4011319"
  },
  {
    "text": "there are some paper I couldn't remember so I remember the complexity is n to the",
    "start": "4011319",
    "end": "4016599"
  },
  {
    "text": "power of three and then it it wouldn't scale for the web scalability and so",
    "start": "4016599",
    "end": "4023160"
  },
  {
    "text": "that's why we too expensive for",
    "start": "4023160",
    "end": "4028319"
  },
  {
    "text": "Google too expensive even for Google harmonic meion scale though just as well",
    "start": "4028319",
    "end": "4033880"
  },
  {
    "text": "as arithmetic uh that's a good question we haven't tried a mean for everybody",
    "start": "4033880",
    "end": "4042798"
  },
  {
    "text": "so maybe there's a right mean that makes everything",
    "start": "4042920",
    "end": "4048760"
  },
  {
    "text": "better yes what are your expectations to where this is all headed to what extent",
    "start": "4048760",
    "end": "4055920"
  },
  {
    "text": "will this become anything near deterministic in what kind of time frame",
    "start": "4055920",
    "end": "4061760"
  },
  {
    "text": "uh my impression is it's very interesting but more as a philosophical",
    "start": "4061760",
    "end": "4066880"
  },
  {
    "text": "discussion of what constitutes truth and how do you define a fact and how do you",
    "start": "4066880",
    "end": "4072160"
  },
  {
    "text": "identify the way of deter if something is accurate or not as opposed to a",
    "start": "4072160",
    "end": "4077200"
  },
  {
    "text": "science or an engineering discipline where you write the code and you come up with an answer at the back end where do",
    "start": "4077200",
    "end": "4082440"
  },
  {
    "text": "you think this is heading and how quickly will you be getting to something that's",
    "start": "4082440",
    "end": "4087680"
  },
  {
    "text": "solid uh so uh first let's talk about um",
    "start": "4087680",
    "end": "4093799"
  },
  {
    "text": "uh regarding solid or regarding I mean one this iteration would uh stop so what",
    "start": "4093799",
    "end": "4101000"
  },
  {
    "text": "we found is that um uh because because of the simplification in the M step so",
    "start": "4101000",
    "end": "4107400"
  },
  {
    "text": "we found that if we consider only the SE accuracy then it does not necessarily",
    "start": "4107400",
    "end": "4113880"
  },
  {
    "text": "converge and um however if the number of uh uh triples is far more than the",
    "start": "4113880",
    "end": "4122400"
  },
  {
    "text": "number of sources then our observation is that it typically",
    "start": "4122400",
    "end": "4128199"
  },
  {
    "text": "converges uh but uh for this particular uh like uh experiment we didn't really",
    "start": "4128199",
    "end": "4137080"
  },
  {
    "text": "go until it converges because that's just too expensive and uh we stopped",
    "start": "4137080",
    "end": "4144960"
  },
  {
    "text": "after five rounds and we found that after five rounds the results are pretty",
    "start": "4144960",
    "end": "4150120"
  },
  {
    "text": "much stable and actually after starting from the third round the results are pretty much stable and uh then for a",
    "start": "4150120",
    "end": "4158238"
  },
  {
    "text": "question about where it leads to do you basically mean what I just the set or do",
    "start": "4158239",
    "end": "4164560"
  },
  {
    "text": "you mean where the research results will lead to I mean um it's currently in a",
    "start": "4164560",
    "end": "4169758"
  },
  {
    "text": "research phase and you're learning as you go at some point this might actually roll out and become part of a standard",
    "start": "4169759",
    "end": "4176600"
  },
  {
    "text": "product and a main part of the Google replacement for page ranking or a strong supplement what kind of time frame",
    "start": "4176600",
    "end": "4183238"
  },
  {
    "text": "before you think it gets to that level of reliability so this is something I could answer but there are indeed I mean",
    "start": "4183239",
    "end": "4190960"
  },
  {
    "text": "many like collaborations Where We Are trying to use this to decide whether extractions are correct uh we are trying",
    "start": "4190960",
    "end": "4198679"
  },
  {
    "text": "to recommend uh web sources for verticals we are even trying to find out",
    "start": "4198679",
    "end": "4205159"
  },
  {
    "text": "uh what is the quality of a website Etc",
    "start": "4205159",
    "end": "4210920"
  },
  {
    "text": "yeah yes when do you think I can type in 27 symptoms and get a better diagnosis than a",
    "start": "4210920",
    "end": "4217040"
  },
  {
    "text": "doctor so Google Now launched some like a medical knowledge panel and basically",
    "start": "4217040",
    "end": "4223120"
  },
  {
    "text": "it will say uh for some disease what are the symptoms and you can you can basically search Disease by symptom or",
    "start": "4223120",
    "end": "4229360"
  },
  {
    "text": "symptom by disease I don't know how mature it is and what is the coverage by uh for this what I heard is uh this is",
    "start": "4229360",
    "end": "4237080"
  },
  {
    "text": "definitely not something that they get from sources they hire doctors to come",
    "start": "4237080",
    "end": "4243560"
  },
  {
    "text": "up with this",
    "start": "4243560",
    "end": "4247480"
  },
  {
    "text": "doctors it's supposed to hire a lot of the top doctors and a lot",
    "start": "4248640",
    "end": "4254320"
  },
  {
    "text": "yeah just a quick comment on Maxim likely typically converges in",
    "start": "4254320",
    "end": "4260239"
  },
  {
    "text": "distribution doesn't work doesn't converge onto number if it goes through the loop you don't Converge on numbers",
    "start": "4260239",
    "end": "4266360"
  },
  {
    "text": "you get distributions that's so point is you may have to report the",
    "start": "4266360",
    "end": "4272159"
  },
  {
    "text": "distribution and I think that would be more interesting say these sources say that yes they say",
    "start": "4272159",
    "end": "4279000"
  },
  {
    "text": "no let me report the distribution like you do some of the other Real Time news",
    "start": "4279000",
    "end": "4284960"
  },
  {
    "text": "whatever how many papers blah blah blah the science can tell you often",
    "start": "4284960",
    "end": "4292199"
  },
  {
    "text": "things converge in distribution but not single",
    "start": "4292199",
    "end": "4296880"
  },
  {
    "text": "numbers Politics the other way around smoking",
    "start": "4297520",
    "end": "4302679"
  },
  {
    "text": "and yeah if you consider those because especially because we sort of make this",
    "start": "4302679",
    "end": "4307760"
  },
  {
    "text": "simple uh single truth assumption for every date item subject predicate pair",
    "start": "4307760",
    "end": "4312880"
  },
  {
    "text": "and for the op objects I mean the for each object we compute some probability",
    "start": "4312880",
    "end": "4320159"
  },
  {
    "text": "and that's kind of a distribution for the probabilities of the candidate objects certainly it is not true that",
    "start": "4320159",
    "end": "4327600"
  },
  {
    "text": "distribution for each object for each triple",
    "start": "4327600",
    "end": "4334199"
  },
  {
    "text": "that's",
    "start": "4342480",
    "end": "4345480"
  }
]
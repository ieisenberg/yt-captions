[
  {
    "start": "0",
    "end": "5730"
  },
  {
    "text": "All right. Let's get started. OK. ",
    "start": "5730",
    "end": "11060"
  },
  {
    "text": "So part 2 of our discussion. So now we're going to focus on\npost hoc explanation methods.",
    "start": "11060",
    "end": "17090"
  },
  {
    "text": "Right. So let's think\nabout explanations",
    "start": "17090",
    "end": "22210"
  },
  {
    "text": "a bit more because unlike what\nwe have been talking about so far, there is no\nlonger a model that",
    "start": "22210",
    "end": "28900"
  },
  {
    "text": "is trying to be inherently\ninterpretable here or produce things that can be\ninterpreted, right?",
    "start": "28900",
    "end": "34960"
  },
  {
    "text": "Now we are in a situation\nwhere we essentially have this kind of a\ncomplex classifier.",
    "start": "34960",
    "end": "41140"
  },
  {
    "text": "We can't touch the classifier\nor that's the setting that we are working with. We don't want to change\nanything about this classifier.",
    "start": "41140",
    "end": "47800"
  },
  {
    "text": "But there is an end\nuser and we need to sort of provide some\ninterpretable description",
    "start": "47800",
    "end": "53769"
  },
  {
    "text": "of this model's behavior\nto the end user, right? So the explanation\nwill be an interface",
    "start": "53770",
    "end": "59920"
  },
  {
    "text": "between this complex\nmodel and the end user. So it has to almost\nhave two key properties.",
    "start": "59920",
    "end": "65810"
  },
  {
    "text": "So the first thing\nis the explanation should faithfully describe the\nbehavior of this classifier,",
    "start": "65810",
    "end": "72505"
  },
  {
    "text": "right? So if the explanation\nis not correctly describing model behavior,\nthen essentially it's",
    "start": "72505",
    "end": "78820"
  },
  {
    "text": "not useful even if it is\ninterpretable to the user, right? That's one piece of it.",
    "start": "78820",
    "end": "84640"
  },
  {
    "text": "And the other side\nof it is whatever we are producing should be\ninterpretable to the end user,",
    "start": "84640",
    "end": "91952"
  },
  {
    "text": "right? So those are the two pieces. And then the sort of complexity\nin this entire scenario",
    "start": "91952",
    "end": "99280"
  },
  {
    "text": "comes from what\nexactly do we mean by understandable\nto the end user.",
    "start": "99280",
    "end": "104560"
  },
  {
    "text": "And that depends quite a\nbit on the nature of the end user themselves, right? So whether they are\nmachine learning experts,",
    "start": "104560",
    "end": "111430"
  },
  {
    "text": "whether they're domain\nexperts, all of those aspects, and that's something that we are\ngoing to also talk about a bit",
    "start": "111430",
    "end": "117580"
  },
  {
    "text": "more later, all right? So for example,\nwhen we think of oh, we just need to provide an\ninterpretable description",
    "start": "117580",
    "end": "124090"
  },
  {
    "text": "of the model behavior. That could look like\nany of the following. For example, you could just send\nall the model parameters theta,",
    "start": "124090",
    "end": "131890"
  },
  {
    "text": "and if this is somebody who\nis building a model themselves or is a scientist researcher\nengineer who understands",
    "start": "131890",
    "end": "139990"
  },
  {
    "text": "machine learning, they may be\nable to make some sense of it, right? So that's some form of providing\nthat person more information.",
    "start": "139990",
    "end": "148090"
  },
  {
    "text": "Or you could basically send\nmany example predictions and say that for\nthis example, this",
    "start": "148090",
    "end": "153885"
  },
  {
    "text": "is the output I get,\nfor such examples, this is the output\nI get and so on. Or you could summarize with\na program or rule or a tree,",
    "start": "153885",
    "end": "163480"
  },
  {
    "text": "all these kinds of constructs\nthat we talked about earlier, or you could sort of select most\nimportant features or points",
    "start": "163480",
    "end": "171340"
  },
  {
    "text": "that are influencing\nthe prediction, or you could sort of describe\nhow to flip a given model's",
    "start": "171340",
    "end": "177580"
  },
  {
    "text": "prediction. So all of these are possible\nexplanations of a complex model",
    "start": "177580",
    "end": "183940"
  },
  {
    "text": "to an end user, right? Now which one is\nmore apt depends on exactly what your\napplication is and also",
    "start": "183940",
    "end": "191200"
  },
  {
    "text": "who your end user is, right? So for example, I can't send\nall the model parameters theta to a doctor and assume that\nthey would make any sense of it,",
    "start": "191200",
    "end": "199280"
  },
  {
    "text": "right? But whereas if I\ntell them things like most important\nfeatures, they might be able to use\nthat information, right?",
    "start": "199280",
    "end": "205480"
  },
  {
    "text": "OK.  At a very high\nlevel the literature",
    "start": "205480",
    "end": "211489"
  },
  {
    "text": "on post hoc\nexplanation methods can be divided into two\nclasses of explanations.",
    "start": "211490",
    "end": "217010"
  },
  {
    "text": "So one is local\nexplanations and the other is global explanations. I think the names are\npretty descriptive,",
    "start": "217010",
    "end": "223640"
  },
  {
    "text": "but let's just walk\nover what this means. So local explanations, the\ngoal of these explanations",
    "start": "223640",
    "end": "230540"
  },
  {
    "text": "or these methods is to\nexplain individual predictions of the model, right?",
    "start": "230540",
    "end": "235700"
  },
  {
    "text": "So if we have one prediction,\nhow is that prediction coming about or what\nare the factors that",
    "start": "235700",
    "end": "240950"
  },
  {
    "text": "are impacting that prediction? Now global explanations\non the other hand, they try to describe\nto the most part",
    "start": "240950",
    "end": "248840"
  },
  {
    "text": "complete behavior of the models. So they try to give\na global picture of the model's behavior, OK?",
    "start": "248840",
    "end": "255120"
  },
  {
    "text": "So their goals are also\nslightly different, again, because of the way\nthey are thought about.",
    "start": "255120",
    "end": "261919"
  },
  {
    "text": "Local explanations\ntypically help us unearth any kinds of\nbiases or models reliance",
    "start": "261920",
    "end": "268250"
  },
  {
    "text": "on spurious features, et cetera\nin a given local neighborhood of an instance whereas global\nexplanations help shed light",
    "start": "268250",
    "end": "275930"
  },
  {
    "text": "on big picture issues\nor big picture biases affecting larger subgroups\nin the population.",
    "start": "275930",
    "end": "281360"
  },
  {
    "text": "Right? And again, I guess\nit kind of follows",
    "start": "281360",
    "end": "286370"
  },
  {
    "text": "from what we are\ndiscussing earlier, so while local\nexplanations help vet if individual\npredictions are being",
    "start": "286370",
    "end": "292460"
  },
  {
    "text": "made for the right reasons,\nglobal explanations help vet if a model\nat a high level",
    "start": "292460",
    "end": "297980"
  },
  {
    "text": "is suitable for\ndeployment, right? So these might seem like\nsomewhat trivial issues. But in practice these\nthings are important,",
    "start": "297980",
    "end": "305330"
  },
  {
    "text": "because, for example, before\nwe even deploy a model, so there needs to be\nlet's say in a hospital",
    "start": "305330",
    "end": "312050"
  },
  {
    "text": "or in a court system and so\non, there needs to be approvals or high level authorities\nneed to approve",
    "start": "312050",
    "end": "319190"
  },
  {
    "text": "that OK, these models are fine\nenough to be deployed, right?",
    "start": "319190",
    "end": "324290"
  },
  {
    "text": "In that case, we can't\ngive them a bunch of local predictions\nof 1 million points",
    "start": "324290",
    "end": "330020"
  },
  {
    "text": "and say now use this\nto vet your model. So for them, the\nglobal description is very important so that\nthey can see a big picture",
    "start": "330020",
    "end": "337430"
  },
  {
    "text": "view of what's going on right. So in practice,\nthese differences play a very significant role in\nenabling certain applications",
    "start": "337430",
    "end": "344930"
  },
  {
    "text": "and practices versus the others. OK? All right. So this is broadly\nthe different set",
    "start": "344930",
    "end": "351800"
  },
  {
    "text": "of post hoc explanation methods\nwe are going to look at. So first, we are going to focus\non local explanation methods.",
    "start": "351800",
    "end": "359270"
  },
  {
    "text": "Under that, the thing about\nsort of what we discussed so far and how it ties to\nthis is you might",
    "start": "359270",
    "end": "365960"
  },
  {
    "text": "see some familiar\nconstructs here that we already talked about\nin the context of inherently interpretable models, right?",
    "start": "365960",
    "end": "372620"
  },
  {
    "text": "Whether it is the rules, whether\nit is the feature importance, whether it is prototypes,\nthese constructs",
    "start": "372620",
    "end": "378770"
  },
  {
    "text": "will repeatedly occur through\nthis entire literature whether you're talking about\ninherently interpretable models",
    "start": "378770",
    "end": "384949"
  },
  {
    "text": "or post hoc explanations. OK? But these bring a whole new\nset of challenges with them",
    "start": "384950",
    "end": "390410"
  },
  {
    "text": "because we are considering\napproximations of another model here. All right? OK.",
    "start": "390410",
    "end": "395630"
  },
  {
    "text": "So let's jump into the first\nand a very popular class of local explanations, which\nis feature importances, right?",
    "start": "395630",
    "end": "403640"
  },
  {
    "text": "So I'm sure some\nof you have heard of this method called\nLIME or SHAP because these",
    "start": "403640",
    "end": "409190"
  },
  {
    "text": "are pretty popular. And if you are looking for I\nwant an explanation method, you might run into\nrepositories and packages",
    "start": "409190",
    "end": "416300"
  },
  {
    "text": "which have implementations\nfor these, right? So this was, I think, one\nof the initial methods",
    "start": "416300",
    "end": "421880"
  },
  {
    "text": "that came up within this area\nof post hoc explanation methods. And the algorithm\nor the actual method",
    "start": "421880",
    "end": "428180"
  },
  {
    "text": "is actually very simple\nand intuitive, right? So what this is trying to do\nagain, remember that there's",
    "start": "428180",
    "end": "433970"
  },
  {
    "text": "a local explanation which\nmeans we are trying to explain individual predictions of\nmodel, just one prediction",
    "start": "433970",
    "end": "439910"
  },
  {
    "text": "at a time, all right? And the way this method\nworks is let's say, our goal is to sort of\nexplain the prediction",
    "start": "439910",
    "end": "446810"
  },
  {
    "text": "of the model on that instance\nthat you see on the screen and the underlying\nmodel's decision",
    "start": "446810",
    "end": "453140"
  },
  {
    "text": "surfaces this kind of\ncomplex nonlinear surface that you see sort of\nbelow the plus mark.",
    "start": "453140",
    "end": "460340"
  },
  {
    "text": "And the way you proceed\nwith this algorithm is that you take that\npoint, let's call it xi,",
    "start": "460340",
    "end": "466970"
  },
  {
    "text": "and then you perturb\nthat point several times and you basically generate\ninstances around xi, right?",
    "start": "466970",
    "end": "475370"
  },
  {
    "text": "So you add some\nrandom Gaussian noise to x and then you generate\na bunch of instances",
    "start": "475370",
    "end": "481068"
  },
  {
    "text": "in the local\nneighborhood of x or xi. All right. So now use the underlying\nmodel to predict the labels",
    "start": "481068",
    "end": "488960"
  },
  {
    "text": "for each of these perturbations\nthat you generated, right? So now take the underlying model\nand determine the predictions",
    "start": "488960",
    "end": "495560"
  },
  {
    "text": "of each of those points. And then weigh these\nsamples according",
    "start": "495560",
    "end": "502449"
  },
  {
    "text": "to the distance to xi, right? So points that are closer to\nxi will get higher weightage",
    "start": "502450",
    "end": "508330"
  },
  {
    "text": "and points that are\nfarther away from xi will get lower weightage. And essentially you\ndo that weighting",
    "start": "508330",
    "end": "515349"
  },
  {
    "text": "and then you basically\nfit a simple linear model like a linear regression\nor a logistic regression",
    "start": "515350",
    "end": "522070"
  },
  {
    "text": "on these weighted samples. OK? So that's pretty\nmuch what this does.",
    "start": "522070",
    "end": "528140"
  },
  {
    "text": "And now your simple\nlinear model, it gives you a bunch of\ncoefficients or weights",
    "start": "528140",
    "end": "533660"
  },
  {
    "text": "associated with\ndifferent features, and that becomes\nyour explanation because that provides\nfeature importances, OK?",
    "start": "533660",
    "end": "541140"
  },
  {
    "text": "So the algorithm is super\nsimple as you can see. So you literally take a point,\nperturb it a bunch of times,",
    "start": "541140",
    "end": "548600"
  },
  {
    "text": "generate a local neighborhood,\nand get the model's predictions on that local neighborhood\nand then fit a linear model",
    "start": "548600",
    "end": "555560"
  },
  {
    "text": "on those instances\nand their predictions. Right? So that's it. OK? All right. ",
    "start": "555560",
    "end": "563030"
  },
  {
    "text": "So this paper also\nkind of gives some interesting examples\nwhich have become",
    "start": "563030",
    "end": "568459"
  },
  {
    "text": "like classic examples of\nthinking about explanations and their necessity,\nand we have already seen some of this\nin our motivation.",
    "start": "568460",
    "end": "575389"
  },
  {
    "text": "For example, if we just\nlook at the predictions made by let's say some\nmodels, we might see that there is\nonly one mistake,",
    "start": "575390",
    "end": "582269"
  },
  {
    "text": "so maybe the model is actually\ndoing extremely well, right? So it's predicting\neverything correctly. There is only one image\nwhere it's making a mistake.",
    "start": "582270",
    "end": "589730"
  },
  {
    "text": "But on the other hand, once\nyou see the explanations output by this method, what you realize\nis what we have essentially",
    "start": "589730",
    "end": "596240"
  },
  {
    "text": "built is a snow detector, right? So this kind of insight can only\nbe obtained from explanations.",
    "start": "596240",
    "end": "603970"
  },
  {
    "text": "OK? ",
    "start": "603970",
    "end": "609730"
  },
  {
    "text": "Alongside LIME\nanother popular method that often comes up\nwhen you think of or when you actually even\nsearch for post hoc explanation",
    "start": "609730",
    "end": "617410"
  },
  {
    "text": "methods is called SHAP. So SHAP is also\ntrying to play along the similar intuitions\nas that of LIME,",
    "start": "617410",
    "end": "624670"
  },
  {
    "text": "and it has a lot of\nconnections with LIME. But at a very high level,\nwhat SHAP is trying to do",
    "start": "624670",
    "end": "631360"
  },
  {
    "text": "is estimate marginal\ncontribution of each feature\ntowards the prediction",
    "start": "631360",
    "end": "637430"
  },
  {
    "text": "and you average\nthis contribution across all possible\npermutations.",
    "start": "637430",
    "end": "642710"
  },
  {
    "text": "So what I mean by that\nis, let's take an example where we have three features--\nso x1, x2, and x3, OK,",
    "start": "642710",
    "end": "653889"
  },
  {
    "text": "and now we want to come up\nwith this feature importance according to Shapley\nvalues for x1.",
    "start": "653890",
    "end": "660940"
  },
  {
    "text": "So we want to determine what\nis the contribution of x1. So the way SHAP operates\nis actually very simple,",
    "start": "660940",
    "end": "667270"
  },
  {
    "text": "but scalability\nissues arise which needs a lot more\ntricks to happen in the background\nfor that to work out.",
    "start": "667270",
    "end": "673910"
  },
  {
    "text": "But essentially the\nidea is you compute how much does the prediction\nchange, prediction",
    "start": "673910",
    "end": "681010"
  },
  {
    "text": "of the underlying model\nchange with or without x1 for different permutations\nof the features, right?",
    "start": "681010",
    "end": "688210"
  },
  {
    "text": "So first, you see, OK,\nso with no features what will be the prediction,\nif you add x1 what",
    "start": "688210",
    "end": "694660"
  },
  {
    "text": "will be the prediction, OK? Then with x2 alone what\nwill be the prediction,",
    "start": "694660",
    "end": "699790"
  },
  {
    "text": "if you add x1 what\nwill be the prediction or what's the difference? And again, the marginal\ncontribution of adding",
    "start": "699790",
    "end": "706209"
  },
  {
    "text": "x1 to x3, right? So essentially for\neach such combination, you are computing what is the\nresult of, for example, adding",
    "start": "706210",
    "end": "715870"
  },
  {
    "text": "x1 to the mix minus what\nis the result of not",
    "start": "715870",
    "end": "721330"
  },
  {
    "text": "having x1 in the mix, right? So you do this for every\npossible future permutation",
    "start": "721330",
    "end": "727900"
  },
  {
    "text": "and then you sum\nup and average all those marginal contributions. So that's what will\nconstitute the Shapley value",
    "start": "727900",
    "end": "735279"
  },
  {
    "text": "or the contribution or\nimportance of each feature, and this is how\nyou can compute it.",
    "start": "735280",
    "end": "741200"
  },
  {
    "text": "But as you can see, once you\nget into permutations a lot, this will become a\nvery hard problem",
    "start": "741200",
    "end": "747190"
  },
  {
    "text": "to solve computationally. And there are tricks for\napproximating these and so on, but that we are not\ngoing to get into.",
    "start": "747190",
    "end": "753665"
  },
  {
    "text": "But here is the high\nlevel intuition. OK? All right. ",
    "start": "753665",
    "end": "758680"
  },
  {
    "text": "Now in this class also, there\nare some rule-based methods, which are pretty popular.",
    "start": "758680",
    "end": "764990"
  },
  {
    "text": "So one of them is\nanchors, which can be thought of as a\nrule-based variant of LIME",
    "start": "764990",
    "end": "770920"
  },
  {
    "text": "we talked about, right? And anchors essentially\nrelies on the same tactics",
    "start": "770920",
    "end": "776200"
  },
  {
    "text": "as that of LIME. So what we do is if you\nwant to sort of think about the explanation\nof an instance x,",
    "start": "776200",
    "end": "783550"
  },
  {
    "text": "you perturb that instance x to\ngenerate the local neighborhood just like you read for\nLIME, and then what you do",
    "start": "783550",
    "end": "790390"
  },
  {
    "text": "is you try to find a rule\nthat sort of correctly covers that local\nneighborhood, right?",
    "start": "790390",
    "end": "796810"
  },
  {
    "text": "So again if you recap and\nthink back to this decision sets or rule sets that\nwe were talking about,",
    "start": "796810",
    "end": "802900"
  },
  {
    "text": "there also the goal was to\nfind some rules which nicely and correctly cover a\ncertain space or the data set",
    "start": "802900",
    "end": "809259"
  },
  {
    "text": "in that case, here\nwe are just trying to find the rules that correctly\ncover the local neighborhood.",
    "start": "809260",
    "end": "815140"
  },
  {
    "text": "So the intuitions are the same. We're not going to go over\nthe details of the algorithm.",
    "start": "815140",
    "end": "820149"
  },
  {
    "text": "But roughly, you\nare trying to find rules that cover the local\nneighborhood correctly. So for example, let's\nsay here is a data point",
    "start": "820150",
    "end": "829930"
  },
  {
    "text": "and this is the prediction\nof that data point. So lines explanation\nwill basically",
    "start": "829930",
    "end": "835990"
  },
  {
    "text": "tell you the importance\nand the direction of the importance positive\nor negative for each feature",
    "start": "835990",
    "end": "842410"
  },
  {
    "text": "whereas anchor\nexplanation is basically that rule that is\nsort of covering the local neighborhood, OK?",
    "start": "842410",
    "end": "848340"
  },
  {
    "text": "All right. OK. ",
    "start": "848340",
    "end": "855430"
  },
  {
    "text": "So the next class of\nlocal exploration methods that's very popular, especially\nin images and computer vision",
    "start": "855430",
    "end": "863170"
  },
  {
    "text": "is saliency maps. And saliency maps,\nagain, these are also",
    "start": "863170",
    "end": "868240"
  },
  {
    "text": "going to output some kind\nof feature importance. But they sort of do it\nin a very different way than LIME and SHAP.",
    "start": "868240",
    "end": "874780"
  },
  {
    "text": "Let's take a look at those, OK? So with saliency\nmaps, the idea is that let's say you\nhave this complex model",
    "start": "874780",
    "end": "882190"
  },
  {
    "text": "and you can input\nimages to that model and then it basically\nmakes predictions.",
    "start": "882190",
    "end": "887680"
  },
  {
    "text": "In this case, the model\nis saying the images that of a junco bird. The question that you're asking\nis, what parts of this image",
    "start": "887680",
    "end": "895329"
  },
  {
    "text": "are most relevant for the\nprediction junco bird, right? So that's the question\nthat you're asking.",
    "start": "895330",
    "end": "901769"
  },
  {
    "text": "And you're hoping to get\nan output like this, which basically highlights\nthe important pieces",
    "start": "901770",
    "end": "908250"
  },
  {
    "text": "within the image\nthat the model is relying on when making that\nprediction, junco bird, OK? All right. OK.",
    "start": "908250",
    "end": "913490"
  },
  {
    "text": " So just for the sake\nof I think thinking",
    "start": "913490",
    "end": "921050"
  },
  {
    "text": "about different classes\nin the settings, So either you could\nthink of a binary class model or a binary classifier\nwhere there is a function f",
    "start": "921050",
    "end": "929270"
  },
  {
    "text": "mapping to class 1. Or if you have\nmultiple classes, you can think of a class\nspecific logit, right?",
    "start": "929270",
    "end": "936470"
  },
  {
    "text": "And Fi is a class specific\nlogit for class i. ",
    "start": "936470",
    "end": "941887"
  },
  {
    "text": "OK. All right. So there are several\nmethods in order to generate these\nsaliency maps that we just",
    "start": "941887",
    "end": "947750"
  },
  {
    "text": "saw, and a lot of\nthese basically play on gradients or derivatives,\nto put it more simply.",
    "start": "947750",
    "end": "955160"
  },
  {
    "text": "So for example,\nthe first method, which actually was popular\nfor a while before, of course,",
    "start": "955160",
    "end": "962000"
  },
  {
    "text": "then people started\ndetecting issues with it and so on is this\ninput gradient where",
    "start": "962000",
    "end": "967940"
  },
  {
    "text": "what you're trying to\ncompute is basically the gradient of that\nclass-specific logit, right,",
    "start": "967940",
    "end": "974300"
  },
  {
    "text": "so gradient of that function\nor the underlying model f of x with respect\nto the instance",
    "start": "974300",
    "end": "980600"
  },
  {
    "text": "x whose prediction\nyou want to explain. So what is the reason\nbehind doing this? It's a very simple\nintuition, right?",
    "start": "980600",
    "end": "987320"
  },
  {
    "text": "So you want to see how\nmuch does the output change or how much does the underlying\nfunction change when you make",
    "start": "987320",
    "end": "995510"
  },
  {
    "text": "a small change to the given\ninput data point, right, or each of the features of that\ninput data point essentially,",
    "start": "995510",
    "end": "1003020"
  },
  {
    "text": "right? If y changes a lot as\na result of changing",
    "start": "1003020",
    "end": "1008050"
  },
  {
    "text": "one particular\nfeature in your input points vector, then\nessentially that feature",
    "start": "1008050",
    "end": "1014290"
  },
  {
    "text": "is very important for y, right? So that's it. Rate of change of\ny given x, that's",
    "start": "1014290",
    "end": "1019600"
  },
  {
    "text": "essentially the\nprinciple you are using and you're computing this. And things that have\nhigher gradient values",
    "start": "1019600",
    "end": "1026560"
  },
  {
    "text": "here will basically\nmean that the features are more important. OK? All right. ",
    "start": "1026560",
    "end": "1033349"
  },
  {
    "text": "So if we sort of\ntake this example and visualize the heat\nmap where red indicates",
    "start": "1033349",
    "end": "1040550"
  },
  {
    "text": "the regions of higher\nimportance and white is regions of less\nimportance, here",
    "start": "1040550",
    "end": "1045709"
  },
  {
    "text": "is the kind of outputs that\nwere produced by these input gradient methods, right? And several challenges exist\nwith something like this.",
    "start": "1045710",
    "end": "1054540"
  },
  {
    "text": "First of all, this is visually\nnoisy and somewhat difficult to interpret. And there are also other issues\nsuch as gradient saturation",
    "start": "1054540",
    "end": "1062360"
  },
  {
    "text": "that have been documented. But mainly if you\nlook at this image, we can see that\nit's somewhat noisy.",
    "start": "1062360",
    "end": "1069440"
  },
  {
    "text": "We are not sure\nwhat to make of it, what is the model\nlooking at, is that what the model looking at, and so on.",
    "start": "1069440",
    "end": "1075270"
  },
  {
    "text": "So in order to fix some of\nthe issues with these methods, there was a variant\nproposed called SmoothGrad.",
    "start": "1075270",
    "end": "1081860"
  },
  {
    "text": "And what SmoothGrad\ndoes is essentially it averages the\ngradients of noisy input.",
    "start": "1081860",
    "end": "1088700"
  },
  {
    "text": "It does not just\ntake x and compute the gradient of the\nfunction with respect to x.",
    "start": "1088700",
    "end": "1093980"
  },
  {
    "text": "It basically takes x,\nperturbs it n times and then computes the gradient of the\noutput function with respect",
    "start": "1093980",
    "end": "1102710"
  },
  {
    "text": "to each of these perturbations\nand then you average all that. So you are essentially creating\na smoothing effect in this case",
    "start": "1102710",
    "end": "1110300"
  },
  {
    "text": "when computing the\ngradient, right? So this is the output for the\nsame image with SmoothGrad.",
    "start": "1110300",
    "end": "1117650"
  },
  {
    "text": "As you can see you can\nmake a bit more sort of sense out of this. It is not as noisy\nas what we were",
    "start": "1117650",
    "end": "1124159"
  },
  {
    "text": "seeing with gradients, right? OK. ",
    "start": "1124160",
    "end": "1129529"
  },
  {
    "text": "So the next approach\nthat was proposed again along these lines was that\nof integrated gradients.",
    "start": "1129530",
    "end": "1135830"
  },
  {
    "text": "And the idea here\nis, again, you're trying to sort of do some\nsmoothing of the gradients",
    "start": "1135830",
    "end": "1142310"
  },
  {
    "text": "here, but a slightly\ndifferent kind of smoothing than averaging the gradients. So the idea that's\nbeing used here",
    "start": "1142310",
    "end": "1149060"
  },
  {
    "text": "is do a path integral,\nwhich is basically compute a sum of the\ninterpolated gradients.",
    "start": "1149060",
    "end": "1155000"
  },
  {
    "text": "So you'll think of this as there\nis some baseline input x tilde. You can think of that as\nlike just a black image,",
    "start": "1155000",
    "end": "1162410"
  },
  {
    "text": "right, with nothing on it. So there is some baseline input. And the way you're\nthinking about gradients",
    "start": "1162410",
    "end": "1168890"
  },
  {
    "text": "here is you are\ninterpolating gradients between the baseline\ninput and the point.",
    "start": "1168890",
    "end": "1174830"
  },
  {
    "text": "So you're basically going\nthrough all the gradients in between and trying\nto compute the integral",
    "start": "1174830",
    "end": "1180470"
  },
  {
    "text": "of all those gradients\non that interpolation. OK? And again, the outputs started\nbecoming more and more clearer",
    "start": "1180470",
    "end": "1189800"
  },
  {
    "text": "as people improved these\nmethods one on top of the other. And there are also a few\nother methods, for example.",
    "start": "1189800",
    "end": "1196910"
  },
  {
    "text": "There is gradient\ntimes input, which is you don't just\ncompute the gradient, you also do a dot product\nwith the point x itself.",
    "start": "1196910",
    "end": "1205290"
  },
  {
    "text": "So that's the element-wise\nproduct of gradients and the input points.",
    "start": "1205290",
    "end": "1210890"
  },
  {
    "text": "That is what produces\nimages like these. And there are more variants.",
    "start": "1210890",
    "end": "1216200"
  },
  {
    "text": "For example, there is\nLRP, Layer-wise Relevance Propagation, Grad-CAM and so on.",
    "start": "1216200",
    "end": "1221820"
  },
  {
    "text": "But the point of\nthese kinds of methods is they use gradients\nin some way or the other and create different versions\nof smoothing of these gradients",
    "start": "1221820",
    "end": "1230960"
  },
  {
    "text": "to come up with the saliency\nmap or the explanation. And this is a pretty popular\nclass of post hoc explanation",
    "start": "1230960",
    "end": "1238430"
  },
  {
    "text": "methods that are\ncommonly being used in a variety of\napplications including health care, for example,\nusing chest X-rays to sort",
    "start": "1238430",
    "end": "1247270"
  },
  {
    "text": "of detect tumors and so on. People are also using\nthese kinds of methods for generating\nexplanations there.",
    "start": "1247270",
    "end": "1255955"
  },
  {
    "text": "OK. So the next class is\nprototypes and example based post hoc explanations.",
    "start": "1255955",
    "end": "1262120"
  },
  {
    "text": "So under this broad area, again\nthere are several approaches. There's just probably a\nrunning note for everything.",
    "start": "1262120",
    "end": "1268690"
  },
  {
    "text": "So I think we are touching\nsome representative approaches in each class or each category.",
    "start": "1268690",
    "end": "1274090"
  },
  {
    "text": "There are several\nother approaches that due to time constraints\nwe are able to get into. But the goal is to give\nyou a high-level idea",
    "start": "1274090",
    "end": "1281220"
  },
  {
    "text": "about each class, right? OK. So with the prototypes or\nexample-based explanations,",
    "start": "1281220",
    "end": "1287200"
  },
  {
    "text": "there are two key\nmethods that have been proposed under this category. At a high level,\nthese class of methods",
    "start": "1287200",
    "end": "1293500"
  },
  {
    "text": "use examples, whether\nthey're synthetic examples or natural examples, to explain\nindividual predictions, right?",
    "start": "1293500",
    "end": "1301659"
  },
  {
    "text": "So the first work is by Percy\nLiang and his student Pang Wei, which is on\ninfluence functions.",
    "start": "1301660",
    "end": "1307690"
  },
  {
    "text": "The goal here is to\nbasically identify instances in the training set that are\nresponsible for the prediction",
    "start": "1307690",
    "end": "1315190"
  },
  {
    "text": "of a given test instance, right? So if you have a test instance,\nwhich of the k training",
    "start": "1315190",
    "end": "1320530"
  },
  {
    "text": "instances were responsible\nfor this prediction? That's what you\nwant to identify. And the second is called\nactivation maximization",
    "start": "1320530",
    "end": "1328690"
  },
  {
    "text": "where the goal is\nto identify, again, examples whether\nsynthetic or natural that strongly activate a\nspecific function of interest",
    "start": "1328690",
    "end": "1336340"
  },
  {
    "text": "or a neuron of interest, OK? So let's talk about the\nfirst approach a little bit and then go to the second one.",
    "start": "1336340",
    "end": "1343820"
  },
  {
    "text": "So here, as I was\njust explaining is the first\napproach, what we want to ask here is not just look\nat what pieces of the image",
    "start": "1343820",
    "end": "1352067"
  },
  {
    "text": "are influential\nto the prediction, but ask the question of which\ntraining points have the most",
    "start": "1352067",
    "end": "1357970"
  },
  {
    "text": "influence on the test loss\nfor this particular point and the prediction.",
    "start": "1357970",
    "end": "1364420"
  },
  {
    "text": "So for example, in\nthis case, the answer might be some other\nimages in the data set",
    "start": "1364420",
    "end": "1369610"
  },
  {
    "text": "that are of a junco bird, right? And the approach\nor the technique that was used in\nthis work is actually",
    "start": "1369610",
    "end": "1377650"
  },
  {
    "text": "borrowed from a very\nclassic technique in robust statistics, which\nis titled influence functions.",
    "start": "1377650",
    "end": "1383860"
  },
  {
    "text": "And the goal of style while\nin the classic statistics literature this\nwas obviously not",
    "start": "1383860",
    "end": "1389590"
  },
  {
    "text": "used for quote,\nunquote explanations, there is something\ncalled as Cook's distance",
    "start": "1389590",
    "end": "1395200"
  },
  {
    "text": "in classic robust\nstatistics literature. The goal here is we\nare trying to estimate",
    "start": "1395200",
    "end": "1401440"
  },
  {
    "text": "the influence of\neach of the points in the training data set on\nthe model parameters, right?",
    "start": "1401440",
    "end": "1408250"
  },
  {
    "text": "So in order to do\nthat, for example, if I want to estimate the influence\nof this point on the model",
    "start": "1408250",
    "end": "1413770"
  },
  {
    "text": "parameters, one way\nis, I remove the point, I'll train the model again, see\nhow the model changes, right?",
    "start": "1413770",
    "end": "1420640"
  },
  {
    "text": "But that quickly\nbecomes complicated if I have to do it for every point. So there is a very\npopular measure",
    "start": "1420640",
    "end": "1427630"
  },
  {
    "text": "called as Cook's\ndistance, which actually gives an analytical\nexpression for computing",
    "start": "1427630",
    "end": "1433180"
  },
  {
    "text": "the change in the model\nparameters when you remove a point from the data. So essentially you're computing\nthe influence of that point,",
    "start": "1433180",
    "end": "1440515"
  },
  {
    "text": "right? So what this paper does\nis essentially take that basic idea\nof Cook's distance",
    "start": "1440515",
    "end": "1447250"
  },
  {
    "text": "and apply it to a modern machine\nlearning setting of thinking about explanations and\ninfluence of training points",
    "start": "1447250",
    "end": "1454450"
  },
  {
    "text": "on test points and so on, right? So for example, let's say xj\nis basically a training sample",
    "start": "1454450",
    "end": "1463687"
  },
  {
    "text": "point, sorry, zj is a\ntraining sample point, zi is basically indicating\nany point i in the data set",
    "start": "1463687",
    "end": "1469330"
  },
  {
    "text": "and there's also some\ntest point z test, OK? So for those of you who are\nfamiliar with machine learning,",
    "start": "1469330",
    "end": "1475929"
  },
  {
    "text": "this is like a classic\nempirical risk minimization sort of objective\nfunction, and this",
    "start": "1475930",
    "end": "1482200"
  },
  {
    "text": "is what we used to learn\nmodel parameters, right? So these approaches, they\nthink about this sort",
    "start": "1482200",
    "end": "1488070"
  },
  {
    "text": "of slightly differently in\nthe form of an upweighted ERM solution. So let's say, our goal is\nto estimate the influence",
    "start": "1488070",
    "end": "1495430"
  },
  {
    "text": "of the point zj on the model. Then you can think about that\nkind of an upweighted solution.",
    "start": "1495430",
    "end": "1504050"
  },
  {
    "text": "And if you set epsilon\nto minus 1 by n, that is effectively sort\nof removing the point",
    "start": "1504050",
    "end": "1512290"
  },
  {
    "text": "zj from the data set. OK? So this is a slightly\ngeneralized formulation",
    "start": "1512290",
    "end": "1517780"
  },
  {
    "text": "so that you can think about\nthe influence of the point zj on model parameters.",
    "start": "1517780",
    "end": "1523130"
  },
  {
    "text": "So basically, they use\nthat to sort of compute this kind of influence\nof the training points",
    "start": "1523130",
    "end": "1529990"
  },
  {
    "text": "on the model parameters, right? That's the main goal. So ultimately you\nwant to get to this",
    "start": "1529990",
    "end": "1535029"
  },
  {
    "text": "where you want to compute the\ninfluence of a training point zj on the model parameters.",
    "start": "1535030",
    "end": "1540700"
  },
  {
    "text": "And as you can see, that\ninvolves computing the Hessian. And once you have that, then you\ncan estimate the impact of zj",
    "start": "1540700",
    "end": "1549820"
  },
  {
    "text": "on the loss of z test, which\nis a test data point by using that expression, OK?",
    "start": "1549820",
    "end": "1557120"
  },
  {
    "text": "And this paper also talked about\na bunch of explanations here. One is you can sort of\ncompute self-influence",
    "start": "1557120",
    "end": "1565060"
  },
  {
    "text": "of mislabelled\nexamples to understand what is happening, right? So if a point is misclassified,\nif we compute the influence",
    "start": "1565060",
    "end": "1572740"
  },
  {
    "text": "of that point on the\npredictor, then we can see or\npotentially understand why that misclassification\nis happening,",
    "start": "1572740",
    "end": "1579710"
  },
  {
    "text": "or we could potentially diagnose\na possible domain mismatch where a point is\nout of distribution",
    "start": "1579710",
    "end": "1586000"
  },
  {
    "text": "and we can sort of see that\nby looking at the training examples that are influencing\nthe prediction of this point.",
    "start": "1586000",
    "end": "1593529"
  },
  {
    "text": "And also because this is helping\nus identify influential points in the data, potentially\nif adversaries",
    "start": "1593530",
    "end": "1601960"
  },
  {
    "text": "poison those points,\nthen they may be able to change the\npredictor maximally, right?",
    "start": "1601960",
    "end": "1606970"
  },
  {
    "text": "So there are several sort of\nother applications boiling down into adversarial examples\nand other kinds of literature",
    "start": "1606970",
    "end": "1614260"
  },
  {
    "text": "of this approach. So there are a couple of\nchallenges with this kind of approach though.",
    "start": "1614260",
    "end": "1619389"
  },
  {
    "text": "So one is scalability, because\nit involves computing a Hessian as we just saw, right? So that can be hard in practice.",
    "start": "1619390",
    "end": "1626740"
  },
  {
    "text": "And the non-convexity of the\nobjective we are looking at, that also turns out to be\nchallenging in practice,",
    "start": "1626740",
    "end": "1632800"
  },
  {
    "text": "and there are some\nother papers that try to fix some of these issues. OK? The other approach that we\nconsider under the setting",
    "start": "1632800",
    "end": "1640510"
  },
  {
    "text": "is activation maximization. So this approach,\nagain, the goal is to identify examples that\nactivate a neuron of interest,",
    "start": "1640510",
    "end": "1648617"
  },
  {
    "text": "right? And then the different\nimplementation flavors here are one is\nsearch for natural examples",
    "start": "1648617",
    "end": "1657310"
  },
  {
    "text": "within a specified\ndata set, a train data or so that strongly activate\na neuron of interest,",
    "start": "1657310",
    "end": "1663940"
  },
  {
    "text": "or synthesize examples\nthat may not necessarily exist in the original training\ndata typically via optimization",
    "start": "1663940",
    "end": "1672460"
  },
  {
    "text": "procedures like gradient\ndescent that strongly activate a neuron of interest, right? So either use optimization\nto find synthetic examples",
    "start": "1672460",
    "end": "1680470"
  },
  {
    "text": "or search in your data\nset to find the example. So here are some examples\nthat were sort of like output",
    "start": "1680470",
    "end": "1687490"
  },
  {
    "text": "by using each of\nthese approaches. The top row is\nbasically examples",
    "start": "1687490",
    "end": "1693340"
  },
  {
    "text": "chosen from the data\nset itselt, right, so which were activating\ncertain neurons",
    "start": "1693340",
    "end": "1698980"
  },
  {
    "text": "in a particular\nintermediate layer strongly. And the bottom is if we\nuse optimization to find",
    "start": "1698980",
    "end": "1704650"
  },
  {
    "text": "such examples what\nthey look like. So clearly there\nis a big difference between the kinds of examples\nyou see in both cases.",
    "start": "1704650",
    "end": "1712540"
  },
  {
    "text": "So in some sense,\nthe top you can see it's showing some\nbaseball images or stripes,",
    "start": "1712540",
    "end": "1719950"
  },
  {
    "text": "and then the bottom is like it's\na clear sort of ambiguity there that whether it's a baseball\nor stripes is unclear.",
    "start": "1719950",
    "end": "1726950"
  },
  {
    "text": "So they may just\nthat you would get when you think about natural\nexamples versus synthetic can look quite different.",
    "start": "1726950",
    "end": "1732775"
  },
  {
    "text": "OK? All right.  OK. So now the last class of\nlocal explanation approaches",
    "start": "1732775",
    "end": "1739930"
  },
  {
    "text": "is counterfactuals,\nwhich actually has been popular because of\nother kinds of applications",
    "start": "1739930",
    "end": "1745630"
  },
  {
    "text": "than the ones that we have\nbeen talking about, right? So at a very bare\nminimum level, what",
    "start": "1745630",
    "end": "1750700"
  },
  {
    "text": "is a counterfactual explanation? Counterfactual\nexplanations tell us what features need to be\nchanged and by how much to flip",
    "start": "1750700",
    "end": "1758890"
  },
  {
    "text": "a model's prediction, right? So for example,\nin this case, what features in this image\nof a crested auklet",
    "start": "1758890",
    "end": "1765340"
  },
  {
    "text": "need to be changed and to\nwhat in order to get a red faced cormorant.",
    "start": "1765340",
    "end": "1771940"
  },
  {
    "text": "So why is this important or\nlike where is this useful? This is an interesting\nquestion because a lot",
    "start": "1771940",
    "end": "1778120"
  },
  {
    "text": "of this area of research is\nthinking about applications in banking and\nfinancing, because as I",
    "start": "1778120",
    "end": "1785170"
  },
  {
    "text": "was saying earlier,\nregulations like GDPR are sort of focusing\non those areas",
    "start": "1785170",
    "end": "1790570"
  },
  {
    "text": "as their preliminary\nareas of enforcement. So these explanations\nhave become popular",
    "start": "1790570",
    "end": "1795910"
  },
  {
    "text": "because of those areas. So just to understand\na scenario here, let's take a look at\nthis example where",
    "start": "1795910",
    "end": "1802180"
  },
  {
    "text": "there is a loan applicant\nwho has submitted their loan application to a bank which\nhas a predictive model which",
    "start": "1802180",
    "end": "1809110"
  },
  {
    "text": "determines if that person\nshould get a loan or not, right? So in this case, if the person\nis denied a loan, instead",
    "start": "1809110",
    "end": "1815440"
  },
  {
    "text": "of just saying that, the\nperson might actually benefit if we tell\nthem what they",
    "start": "1815440",
    "end": "1821470"
  },
  {
    "text": "need to do in order to\nchange their profile and reapply for a\nloan so that they",
    "start": "1821470",
    "end": "1826899"
  },
  {
    "text": "have more success next time\nthey reapply for a loan, right? So now how do we generate\nsuch explanations is basically",
    "start": "1826900",
    "end": "1834789"
  },
  {
    "text": "this area of counterfactual\nexplanations, also referred to as algorithmic recourse.",
    "start": "1834790",
    "end": "1840070"
  },
  {
    "text": "So these terms are often\nused pretty interchangeably in the literature today. So whenever you hear one or\nthe other, you're basically",
    "start": "1840070",
    "end": "1846789"
  },
  {
    "text": "referring to the\nsame thing, right? And the recourse or the\ncounterfactual explanation takes a form of\nsomething like this--",
    "start": "1846790",
    "end": "1853870"
  },
  {
    "text": "feature and then the\nchange to the feature. For example, salary,\nincrease salary by 5k,",
    "start": "1853870",
    "end": "1860860"
  },
  {
    "text": "pay credit card bills on\ntime for next three months. So that's the kind of\nchanges that are recommended",
    "start": "1860860",
    "end": "1866350"
  },
  {
    "text": "using these algorithms. So the strategies for generating\nthese kinds of explanations",
    "start": "1866350",
    "end": "1874510"
  },
  {
    "text": "are many but they have some\ncommon underlying principles. So I'm going to touch\nupon those first",
    "start": "1874510",
    "end": "1880240"
  },
  {
    "text": "before I get into\nother details, OK? So generating\ncounterfactual explanations",
    "start": "1880240",
    "end": "1886210"
  },
  {
    "text": "at an intuitive level,\nyou can think of it in a very simple way, right? So your goal is\nthere is some point",
    "start": "1886210",
    "end": "1893050"
  },
  {
    "text": "x on this negative labeled area\nof the model decision boundary",
    "start": "1893050",
    "end": "1898370"
  },
  {
    "text": "and you want to find another\npoint in the positively labeled area of the decision boundary\nthat x can morph into, right?",
    "start": "1898370",
    "end": "1907600"
  },
  {
    "text": "So that's the problem. So intuitively, you can think of\nit as, so now take the point x",
    "start": "1907600",
    "end": "1913420"
  },
  {
    "text": "and keep perturbing\nit and pushing it towards the decision boundary. And once it crosses\nthe decision boundary,",
    "start": "1913420",
    "end": "1920350"
  },
  {
    "text": "stop, and say x should\nbecome that point in order to get a loan, right?",
    "start": "1920350",
    "end": "1925750"
  },
  {
    "text": "Now the question\nhere though is if I take x and start perturbing it\ntowards a decision boundary,",
    "start": "1925750",
    "end": "1932620"
  },
  {
    "text": "it can either go this way\nand become this point CF2 or it can go this way and\nbecome this point CF1.",
    "start": "1932620",
    "end": "1939850"
  },
  {
    "text": "Which should it become? So that is basically where\ndifferent approaches differ on.",
    "start": "1939850",
    "end": "1945679"
  },
  {
    "text": "So in some sense, the\nproposed algorithms for solving this\nproblem differ on how",
    "start": "1945680",
    "end": "1951070"
  },
  {
    "text": "to choose among these\ncandidate counterfactuals, and the second thing\nis how much access",
    "start": "1951070",
    "end": "1956950"
  },
  {
    "text": "is needed to the underlying\npredictive model, whether they can\nwork with a black box",
    "start": "1956950",
    "end": "1962590"
  },
  {
    "text": "or whether they need\naccess to the gradients of the underlying\nmodel, all right? OK. ",
    "start": "1962590",
    "end": "1968990"
  },
  {
    "text": "So we'll get into some of the\ndetails of these approaches now and just go in sequence\nto see how they sort of go",
    "start": "1968990",
    "end": "1975380"
  },
  {
    "text": "from one to the other. Actually, let me\npause here and see if there are any\nquestions before I do that",
    "start": "1975380",
    "end": "1981650"
  },
  {
    "text": "and go into more details.  There is one question\nfrom the chat here",
    "start": "1981650",
    "end": "1991159"
  },
  {
    "text": "that might be relevant to what\nwe were talking about just previously. And the question\nis generally, what",
    "start": "1991160",
    "end": "1998060"
  },
  {
    "text": "do you think of Anthropic's\nrecent softmax linear units paper? Does it give more hope for\nbuilding more interpretable",
    "start": "1998060",
    "end": "2004930"
  },
  {
    "text": "model architectures or should\nwe be focusing on these post hoc explanations that\nyou've been talking about?",
    "start": "2004930",
    "end": "2011360"
  },
  {
    "text": "Yeah, I mean, I would say all\nthe efforts whether you're",
    "start": "2011360",
    "end": "2019450"
  },
  {
    "text": "trying to sort of do it\nat the level of the model, whether you're making\nmodels more smoother, right,",
    "start": "2019450",
    "end": "2025540"
  },
  {
    "text": "or whether you're using\npost hoc explanations, these are all efforts\nin the direction",
    "start": "2025540",
    "end": "2031840"
  },
  {
    "text": "of making something more\nunderstandable in some way or the other, right? So at least in my\npersonal opinion,",
    "start": "2031840",
    "end": "2038210"
  },
  {
    "text": "the answer is probably\nnot one versus the other. But I think sort of having a\nmore clearer characterization",
    "start": "2038210",
    "end": "2046270"
  },
  {
    "text": "of when to go to that\nand when would that fail, and in that case would\nsomething else help?",
    "start": "2046270",
    "end": "2054339"
  },
  {
    "text": "So currently, and\nwe'll talk about this a bit more as we go\ntowards the end of this, I think all these\napproaches are useful.",
    "start": "2054340",
    "end": "2062060"
  },
  {
    "text": "It's just that I\nfeel what is needed is a clearer understanding. Instead of saying it's\nthis versus that battle,",
    "start": "2062060",
    "end": "2070239"
  },
  {
    "text": "a clearer understanding\nof here is when this would be\nmore useful and here is when something else might\nbe more useful, I think",
    "start": "2070239",
    "end": "2078219"
  },
  {
    "text": "that's where we\nshould be headed, because this is\nsomething that I get asked a lot in different\nforums, as to oh,",
    "start": "2078219",
    "end": "2084864"
  },
  {
    "text": "so like maybe we should\nnever use post hoc explanations because there are\nsome disadvantages, which we'll",
    "start": "2084864",
    "end": "2090158"
  },
  {
    "text": "talk about at length in\nthe afternoon session. But I think the answer is\nprobably not to pick a side,",
    "start": "2090159",
    "end": "2096760"
  },
  {
    "text": "but like to see when each\napproach would be useful. OK. All right? ",
    "start": "2096760",
    "end": "2103849"
  },
  {
    "text": "So let's move forward\nand try to look at each of the individual\napproaches in this area.",
    "start": "2103850",
    "end": "2109260"
  },
  {
    "text": "So here is basically\nthe core objective of a lot of approaches\nthat try to generate",
    "start": "2109260",
    "end": "2114890"
  },
  {
    "text": "counterfactual explanations. So the idea is,\ngiven a point x, we",
    "start": "2114890",
    "end": "2121099"
  },
  {
    "text": "want to find a\npoint x prime such that the distance between x and\nx prime is as small as possible",
    "start": "2121100",
    "end": "2129060"
  },
  {
    "text": "and the model's output on x\nprime is a positive label.",
    "start": "2129060",
    "end": "2134082"
  },
  {
    "text": "Right? So you want to find\nthe closest instance to the original instance\nyou started with such",
    "start": "2134082",
    "end": "2141180"
  },
  {
    "text": "that these two are\npretty close, but also the label of this new\ninstance that you're finding",
    "start": "2141180",
    "end": "2146970"
  },
  {
    "text": "is a positive label, right? And then you ask x to change\ninto x prime basically. That's the idea.",
    "start": "2146970",
    "end": "2152265"
  },
  {
    "text": "OK? So x prime is called\nyour counterfactual and x is your original instance\nand d can be some distance",
    "start": "2152265",
    "end": "2160440"
  },
  {
    "text": "metric whether it's L2\ndistance or some other kinds of distance, Manhattan\ndistance and so on.",
    "start": "2160440",
    "end": "2165945"
  },
  {
    "text": "OK? So the choice of distance\nmetric is also important",
    "start": "2165945",
    "end": "2171300"
  },
  {
    "text": "because if you're thinking\nabout a practical application, this can dictate what\nkinds of counterfactuals",
    "start": "2171300",
    "end": "2176700"
  },
  {
    "text": "are chosen, right? Of course, in terms of your\noptimization methods and stuff, it might make some\ndifference but I",
    "start": "2176700",
    "end": "2183202"
  },
  {
    "text": "think there's more of\nsomething that would make a big difference in practice. OK. So the first paper that\nactually touches upon this area",
    "start": "2183202",
    "end": "2191610"
  },
  {
    "text": "is presented by Sandra\nWachter and her colleagues, and they use normalized\nManhattan distance here.",
    "start": "2191610",
    "end": "2197559"
  },
  {
    "text": "But other papers,\nwhich build on it have started using L2 as\na classic distance metric because it improves the\noptimization pieces.",
    "start": "2197560",
    "end": "2204506"
  },
  {
    "text": "Right? OK. So that's basically your minimum\ndistance counterfactuals,",
    "start": "2204506",
    "end": "2211920"
  },
  {
    "text": "right? So this is the objective. Typically when solving\nthis objective, Wachter and even other\nmethods in this area",
    "start": "2211920",
    "end": "2219150"
  },
  {
    "text": "essentially try to make\nthis constraint optimization problem as an unconstrained\none by bringing up",
    "start": "2219150",
    "end": "2225090"
  },
  {
    "text": "these constraints into\nthe objective itself and then they basically\nsolve this differentiable and",
    "start": "2225090",
    "end": "2231510"
  },
  {
    "text": "constrained version using\noptimization algorithms like ADAM with random\nrestarts, right?",
    "start": "2231510",
    "end": "2237809"
  },
  {
    "text": "So as you can see, this is\nalready a non-convex problem, so you would need\nrandom restarts in order to have a chance at\ngetting to the global minimum.",
    "start": "2237810",
    "end": "2246000"
  },
  {
    "text": "All right. So this particular\nmethod actually requires access to gradients\nof the underlying predictive",
    "start": "2246000",
    "end": "2253140"
  },
  {
    "text": "model. So the predictive model\ncan be a total black box where you're just seeing the\npredictions of the model.",
    "start": "2253140",
    "end": "2258750"
  },
  {
    "text": "You need to be able to compute\nthe gradients of the model, right? So here are some examples\nthat this method produces.",
    "start": "2258750",
    "end": "2266400"
  },
  {
    "text": "So for example, it says\nif your LSAT score was 34, you would have some\npredicted score of 0,",
    "start": "2266400",
    "end": "2273030"
  },
  {
    "text": "and if you change your\nLSAT score to some value, then this is what would\nbe your predicted score.",
    "start": "2273030",
    "end": "2280380"
  },
  {
    "text": "So the interesting\nthing is just the way this method is implemented,\nit's suggesting people",
    "start": "2280380",
    "end": "2287070"
  },
  {
    "text": "to change their race in order\nto get a desired outcome, right?",
    "start": "2287070",
    "end": "2292680"
  },
  {
    "text": "So obviously,\nsomething like this is not feasible to\nact upon in practice, but also it is highly\nunethical to sort of do",
    "start": "2292680",
    "end": "2301289"
  },
  {
    "text": "these kinds of things, right? So that's why there are further\napproaches which sort of build upon this approach and that's\nthe work by Ustun et al.",
    "start": "2301290",
    "end": "2309960"
  },
  {
    "text": "where they change this\nobjective to now enforce that x prime, which is the\ncounterfactual that we are",
    "start": "2309960",
    "end": "2317430"
  },
  {
    "text": "picking should belong to\na particular set A, which can be thought of as a set of\nvalid counterfactuals, right?",
    "start": "2317430",
    "end": "2325140"
  },
  {
    "text": "So in that set A\nfor example, you will not allow changes\nto race or gender",
    "start": "2325140",
    "end": "2330569"
  },
  {
    "text": "or any other sensitive\nattributes that are unethical to use, OK? Yeah. All right.",
    "start": "2330570",
    "end": "2335870"
  },
  {
    "start": "2335870",
    "end": "2342590"
  },
  {
    "text": "So here, as I was just\ntalking about, this a set of feasible counterfactuals\nthat is often",
    "start": "2342590",
    "end": "2348109"
  },
  {
    "text": "given by the end user and\nchanges to race and gender and these kinds of things\nare not feasible, right?",
    "start": "2348110",
    "end": "2353630"
  },
  {
    "text": "And there is also\nan additional thing that you see there\nthat has changed from our first objective\nthat we considered,",
    "start": "2353630",
    "end": "2360210"
  },
  {
    "text": "which is instead of\ndistance, this approach is now considering cost. So in some sense,\ninstead of just saying",
    "start": "2360210",
    "end": "2366560"
  },
  {
    "text": "I'll compute an L2 distance\nin this sort of data space, it's saying some\nfeatures might be harder",
    "start": "2366560",
    "end": "2373310"
  },
  {
    "text": "to change for a person in\npractice than others, right? So let's try and\naccount for them.",
    "start": "2373310",
    "end": "2378710"
  },
  {
    "text": "Maybe for somebody who is\nliving in a particular place it is easy to increase\nthe size of their house",
    "start": "2378710",
    "end": "2384410"
  },
  {
    "text": "or the square footage of their\nhouse, but not their salary. And for somebody\nin another place, the vice versa\ncould be true, how",
    "start": "2384410",
    "end": "2391400"
  },
  {
    "text": "can we incorporate\nthose better when recommending these changes? So let's not just look at the\ndistance in the input space,",
    "start": "2391400",
    "end": "2398450"
  },
  {
    "text": "but look at the cost\nassociated with changing certain features\nwhen prescribing",
    "start": "2398450",
    "end": "2403940"
  },
  {
    "text": "this kind of recourse, right? And as a first solution to this,\nthis particular approach sort",
    "start": "2403940",
    "end": "2411520"
  },
  {
    "text": "of models cost as a\nlog percentile shift, which basically models this\naspect that changes become",
    "start": "2411520",
    "end": "2418310"
  },
  {
    "text": "harder when you are trying\nto make changes at a higher percentile shift, right? So changing from\n90 to 95 might be",
    "start": "2418310",
    "end": "2425359"
  },
  {
    "text": "much harder than going from 50\nto 55 percentile, for example, OK? So this, of course, what this\napproach, does, several follow",
    "start": "2425360",
    "end": "2432740"
  },
  {
    "text": "up works, including some\nof ours actually try to learn these costs by asking\nusers about their preferences.",
    "start": "2432740",
    "end": "2440370"
  },
  {
    "text": "So for example, we did some work\nwhere we basically go and ask users, people are bad at\nassigning this cost rate up",
    "start": "2440370",
    "end": "2447470"
  },
  {
    "text": "to a feature. But if I tell them\nwould it be easier for you to change\nyour salary versus",
    "start": "2447470",
    "end": "2453380"
  },
  {
    "text": "the square footage\nof your house, they can give a yes or no answer\nand do pairwise comparisons, well, right?",
    "start": "2453380",
    "end": "2459350"
  },
  {
    "text": "So how to go from there to\ninferring such costs is, of course, some\nfollow-up work to this",
    "start": "2459350",
    "end": "2464930"
  },
  {
    "text": "that we and other\nresearchers have done. All right. Yeah, OK. ",
    "start": "2464930",
    "end": "2477820"
  },
  {
    "text": "So basically this\napproach or this paper only considers the\ncase where the model",
    "start": "2477820",
    "end": "2484060"
  },
  {
    "text": "is a linear classifier. So they also have\ntheories surrounding this in order to say that whatever\nyou are getting out of this",
    "start": "2484060",
    "end": "2491830"
  },
  {
    "text": "is a good solution for\na linear classifier. So the way, they\nsolved this problem is they formulated\nas an integer program",
    "start": "2491830",
    "end": "2498579"
  },
  {
    "text": "and optimized it using simplex. So this approach actually\nrequires complete access",
    "start": "2498580",
    "end": "2504220"
  },
  {
    "text": "to the linear classifier. They need the weight\nvector in order to compute this\nkind of recourse or",
    "start": "2504220",
    "end": "2509680"
  },
  {
    "text": "a counterfactual explanation,\nwhich may or may not be available depending on the\nsetting you're working with.",
    "start": "2509680",
    "end": "2515155"
  },
  {
    "text": "OK? All right. ",
    "start": "2515155",
    "end": "2522020"
  },
  {
    "text": "So now the question\nis, what if we have a black Box or a\nnonlinear classifier instead",
    "start": "2522020",
    "end": "2528200"
  },
  {
    "text": "of a linear classifier? Now one potential solution\ncould be something",
    "start": "2528200",
    "end": "2533240"
  },
  {
    "text": "generate a local linear model\napproximation, for example, using an approach like LIME\nthat we talked about earlier.",
    "start": "2533240",
    "end": "2541110"
  },
  {
    "text": "And then once you get\nsuch a local linear model, then apply this framework in\norder to get the recourse.",
    "start": "2541110",
    "end": "2547940"
  },
  {
    "text": "That's one approach. It of course, has its\nflaws and depends heavily on the quality of that\nlocal linear model",
    "start": "2547940",
    "end": "2553610"
  },
  {
    "text": "approximation itself. But that's the sort\nof potential way to use this approach with a\nnonlinear classifier, right?",
    "start": "2553610",
    "end": "2562010"
  },
  {
    "text": "All this is an example\nof how the output from this particular\napproach looks like. So basically, it has\nsome features to change",
    "start": "2562010",
    "end": "2568760"
  },
  {
    "text": "and what's the current value and\nwhat are the required values? So essentially that's\nthe kind of output",
    "start": "2568760",
    "end": "2574730"
  },
  {
    "text": "that these approaches\nget, right? So now here let's say\nthere is this value called",
    "start": "2574730",
    "end": "2580250"
  },
  {
    "text": "this current depth and\nyou want to decrease that, but one more\npiece to notice is that in reality, in\npractice, changing one feature",
    "start": "2580250",
    "end": "2589250"
  },
  {
    "text": "without affecting the\nother might not always be possible, right? So what do I mean by that? For example, we just\ntold this applicant",
    "start": "2589250",
    "end": "2596480"
  },
  {
    "text": "reduce your current debt\nfrom 3,250 to 1,000, and let's say after one year\nthis applicant comes back",
    "start": "2596480",
    "end": "2603170"
  },
  {
    "text": "and say, oh, my current\ndebt has reduced to 1,000, now give me a loan, and\nthen the model might say,",
    "start": "2603170",
    "end": "2608609"
  },
  {
    "text": "oh, but your age\nalso increased by 1 and this recourse is no\nlonger valid for people",
    "start": "2608610",
    "end": "2613910"
  },
  {
    "text": "whose age has increased\nby 1 along with your debt reducing, right?",
    "start": "2613910",
    "end": "2618950"
  },
  {
    "text": "Now it's very important to\naccount for these feature interactions when\ngenerating counterfactuals.",
    "start": "2618950",
    "end": "2624830"
  },
  {
    "text": "But how do we do it is basically\nthe next practical problem, which was addressed\nby some works, right?",
    "start": "2624830",
    "end": "2630470"
  },
  {
    "text": "And the solution\nis what you might be expecting by now, which is\nyou play with the set A, which",
    "start": "2630470",
    "end": "2637160"
  },
  {
    "text": "is basically the set of\nfeasible counterfactuals that you allow\nwhen trying to pick",
    "start": "2637160",
    "end": "2643160"
  },
  {
    "text": "a particular counterfactual\nfor a person, right? And in this case,\nyou will now resort",
    "start": "2643160",
    "end": "2649640"
  },
  {
    "text": "to using structural\ncausal models. So for example,\nlet's say you have access to the causal process\nthat is generating the data",
    "start": "2649640",
    "end": "2658430"
  },
  {
    "text": "which captures all\nthe interactions between different variables in\nthe data and how they interact.",
    "start": "2658430",
    "end": "2664160"
  },
  {
    "text": "You can use that model and\nallow only those changes which are permitted according\nto that causal model, right?",
    "start": "2664160",
    "end": "2671450"
  },
  {
    "text": "So that's one approach which\nwas suggested in literature. But the big question is, what\nif we just don't have access",
    "start": "2671450",
    "end": "2678440"
  },
  {
    "text": "to this structural causal model,\nwhich is often the case because with any real world data\nset you rarely get access",
    "start": "2678440",
    "end": "2685339"
  },
  {
    "text": "to a full fledged causal model\nof the underlying generation process.",
    "start": "2685340",
    "end": "2690410"
  },
  {
    "text": "There are also other\nworks which try to work around this problem. One approach\nbasically tries to say",
    "start": "2690410",
    "end": "2697160"
  },
  {
    "text": "if you have imperfect\ncausal knowledge, like you kind of know some\nrelationships, you will try to infer the others\nand then leverage that,",
    "start": "2697160",
    "end": "2704930"
  },
  {
    "text": "or the more recent approaches\nthat have become popular are based on variational\nautoencoders.",
    "start": "2704930",
    "end": "2710630"
  },
  {
    "text": "So the idea is\nultimately you want a realistic enough\ncounterfactual, right?",
    "start": "2710630",
    "end": "2715640"
  },
  {
    "text": "So that's your goal. With all this, even when you\nlook at structural constraints and so on, you're saying my\ncounterfactual should not",
    "start": "2715640",
    "end": "2722570"
  },
  {
    "text": "look unrealistic. So how do I generate more\nrealistic counterfactuals whether it is using\nthe causal graphs",
    "start": "2722570",
    "end": "2728990"
  },
  {
    "text": "or whether it is using\nsome other approach, right? And the other strategy or\nan alternative strategy",
    "start": "2728990",
    "end": "2734570"
  },
  {
    "text": "that was sort of considered\nor is becoming more popular these days is, so the goal is\nthe generated counterfactuals",
    "start": "2734570",
    "end": "2741800"
  },
  {
    "text": "should lie on the data manifold\nso the approach taken is construct variational\nautoencoders to map input",
    "start": "2741800",
    "end": "2749390"
  },
  {
    "text": "instances to a\nlatent space, right? And then you search\nfor counterfactuals",
    "start": "2749390",
    "end": "2754760"
  },
  {
    "text": "in that latent space. And once a\ncounterfactual is found, map it back to the input\nspace using a decoder.",
    "start": "2754760",
    "end": "2761750"
  },
  {
    "text": "OK? So this basically helps\nwith a bunch of things,",
    "start": "2761750",
    "end": "2767160"
  },
  {
    "text": "including the fact that your\ninput feature space may not always be smooth or\ncontinuous whereas the chance",
    "start": "2767160",
    "end": "2773720"
  },
  {
    "text": "of your latent space\nbeing that is higher. So you are likely to\nuse a gradient descent and get to a point that you\nwant to give as a counterfactual",
    "start": "2773720",
    "end": "2784040"
  },
  {
    "text": "more nicely in your latent space\nthan you might be able to do so in your input space, partly\nbecause input space could also",
    "start": "2784040",
    "end": "2791000"
  },
  {
    "text": "be discrete and you could\nhave features that are just binary valued or rank\nordered and so on, right?",
    "start": "2791000",
    "end": "2797210"
  },
  {
    "text": "So that's what this approach\nis trying to tackle. So with that we are\npretty much at the end",
    "start": "2797210",
    "end": "2803660"
  },
  {
    "text": "of our local explanation\napproaches module. And again, between\nthese two approaches,",
    "start": "2803660",
    "end": "2810450"
  },
  {
    "text": "local explanation approaches\nhave gained a lot of popularity compared to even global\nexplanations in the literature",
    "start": "2810450",
    "end": "2816650"
  },
  {
    "text": "and also in terms of adoption. OK? So before I get into\nglobal explanations",
    "start": "2816650",
    "end": "2821760"
  },
  {
    "text": "and go over some of\nthe approaches there, I'll pause here\nbriefly to see if there are any further questions about\nlocal post hoc explanations.",
    "start": "2821760",
    "end": "2829789"
  },
  {
    "text": "Yep? So regardless of\n[INAUDIBLE] just explain when you go to the\nwhole dimensional space. How do you know\nwhen you go back,",
    "start": "2829790",
    "end": "2835585"
  },
  {
    "text": "you will get the\nvalid [INAUDIBLE]?? Yeah, so you go back by\nbasically using the decoder.",
    "start": "2835585",
    "end": "2844410"
  },
  {
    "text": "So when you develop the\nencoder and decoder, so the decoder will map this\npoint back to the input space,",
    "start": "2844410",
    "end": "2851310"
  },
  {
    "text": "and that will help you generate\nrealistic enough points in the input space.",
    "start": "2851310",
    "end": "2856410"
  },
  {
    "text": "But you might have some\ncorrelation with the features, and when you go to the decoder\nversus correlation, maybe-- I don't know.",
    "start": "2856410",
    "end": "2861930"
  },
  {
    "text": "Let's say, male pregnant. You might get this\ntype of strange.",
    "start": "2861930",
    "end": "2866970"
  },
  {
    "text": "Right, so the hope\nis that, I think, because this approach\ndoes not add anything",
    "start": "2866970",
    "end": "2871980"
  },
  {
    "text": "more on top of the decoder to\nensure some of these things. I think the hope is that when\nyou do this encoding decoding",
    "start": "2871980",
    "end": "2879839"
  },
  {
    "text": "process, or especially\nthe encoding process, you're preserving some of\nthese kinds of relationships",
    "start": "2879840",
    "end": "2885540"
  },
  {
    "text": "in the data because they\nmay appear prominently. But as of now, this approach\ndoes not add anything else",
    "start": "2885540",
    "end": "2891120"
  },
  {
    "text": "to the decoder. So if something\ngets missed in terms of how the encoder is\ncapturing these relationships,",
    "start": "2891120",
    "end": "2897300"
  },
  {
    "text": "you might still run\ninto those problems. But the hope is that will be\ntaken care of by the encoding. Yeah, OK. ",
    "start": "2897300",
    "end": "2907010"
  },
  {
    "text": "All right, OK, so let's\ngo to global explanations, and the goal here,\nkind of contrasting",
    "start": "2907010",
    "end": "2913369"
  },
  {
    "text": "from what we were\nseeing so far, is to explain the complete\nbehavior of a given",
    "start": "2913370",
    "end": "2919160"
  },
  {
    "text": "black-box model, right? So in some sense, we want\nto provide a bird's eye view of the model\nbehavior, and why do we",
    "start": "2919160",
    "end": "2926990"
  },
  {
    "text": "need this is it\ncan help us detect the big-picture biases\npersistent across larger subgroups.",
    "start": "2926990",
    "end": "2932330"
  },
  {
    "text": "For example, the biases\npersistent against, let's say, a minority group or\na particular gender or race.",
    "start": "2932330",
    "end": "2938780"
  },
  {
    "text": "You can sort of see those better\nwith this kind of a bird's eye view, right? That's the goal.",
    "start": "2938780",
    "end": "2944390"
  },
  {
    "text": "And, well, one\nmight think, well, I have local explanations. I know how to compute them.",
    "start": "2944390",
    "end": "2949970"
  },
  {
    "text": "Why can't we just inspect\nthese local explanations and then learn about the\nbig-picture behavior,",
    "start": "2949970",
    "end": "2955609"
  },
  {
    "text": "as we can already see\nintuitively that's very hard to do in practice. Because if you\nhave 10,000 points,",
    "start": "2955610",
    "end": "2961940"
  },
  {
    "text": "manually inspecting all\nthese local explanations and trying to make\nsense of them is going to be\nextremely challenging",
    "start": "2961940",
    "end": "2968780"
  },
  {
    "text": "from a cognitive overload\nperspective for people. So that's why we\nwant a better summary of the local\nexplanations, and that's",
    "start": "2968780",
    "end": "2975710"
  },
  {
    "text": "what global explanations\nare trying to do, okay? So in some sense,\nglobal explanations are complementary to\nlocal explanations",
    "start": "2975710",
    "end": "2982789"
  },
  {
    "text": "in terms of the view they\ntake on the model behavior. ",
    "start": "2982790",
    "end": "2988380"
  },
  {
    "text": "OK. So we already talked a little\nbit about some of this. So I'm not going to\ngo over that again.",
    "start": "2988380",
    "end": "2993500"
  },
  {
    "text": "Instead, let's look at\nsome of the categories of global explanations. So people have, again, thought\nabout different approaches",
    "start": "2993500",
    "end": "3001720"
  },
  {
    "text": "to sort of generating\nglobal explanations. So one is think of\nthem as a collection of representative\nlocal explanations.",
    "start": "3001720",
    "end": "3009370"
  },
  {
    "text": "So we'll discuss how to do that. The other is\nrepresentation-based explanations, which is a\nslightly different category",
    "start": "3009370",
    "end": "3016390"
  },
  {
    "text": "than all the sets of things\nthat we have seen so far. And then there is\nmodel distillation,",
    "start": "3016390",
    "end": "3021820"
  },
  {
    "text": "which means you are just\ntrying to sort of use a simpler model to approximate this\nexisting complex model",
    "start": "3021820",
    "end": "3028090"
  },
  {
    "text": "as accurately as you can\ngiven the constraints of the expressiveness\nof the simpler model.",
    "start": "3028090",
    "end": "3033100"
  },
  {
    "text": "And then with respect\nto counterfactuals, what can we do with\nglobal explanations?",
    "start": "3033100",
    "end": "3038620"
  },
  {
    "text": "So those are the\ndifferent approaches that we'll touch upon, OK? All right.",
    "start": "3038620",
    "end": "3043660"
  },
  {
    "text": "So let's think about the\nfirst approach, which is global explanation\nas a collection of local explanations, right?",
    "start": "3043660",
    "end": "3049900"
  },
  {
    "text": "So how to generate\na global explanation of a black-box model. So the high-level idea is\ngenerate a local explanation",
    "start": "3049900",
    "end": "3057700"
  },
  {
    "text": "for every instance in the data\nusing one of the approaches that we have discussed\nearlier and pick",
    "start": "3057700",
    "end": "3064299"
  },
  {
    "text": "a subset of k local\nexplanations and then return that as a global explanation.",
    "start": "3064300",
    "end": "3070030"
  },
  {
    "text": "By saying, instances\nwhich look like this, have this kind of explanation.",
    "start": "3070030",
    "end": "3075070"
  },
  {
    "text": "That's how you're thinking\nabout a global explanation, but I guess the key\nquestion in terms of the exact algorithms\nyou use are, well,",
    "start": "3075070",
    "end": "3082240"
  },
  {
    "text": "what local explanation\ntechnique to use, and how to choose this subset\nof k local explanations.",
    "start": "3082240",
    "end": "3088869"
  },
  {
    "text": "So to this end, different\napproaches were proposed, and again, let's talk about this\nfirst in the context of line",
    "start": "3088870",
    "end": "3095650"
  },
  {
    "text": "so that we can\nunderstand how to pick a subset of k\nlocal explanations.",
    "start": "3095650",
    "end": "3100690"
  },
  {
    "text": "Recall that line is used to\nexplain a single prediction. So essentially, if we are\nlooking at that point that",
    "start": "3100690",
    "end": "3108190"
  },
  {
    "text": "is labeled in the\nblack color, it can provide you a\nlinear model that approximates the behavior\nof the underlying",
    "start": "3108190",
    "end": "3115000"
  },
  {
    "text": "model in the locality\nof that point, right? Again, we have been discussing\nabout this challenge of it's",
    "start": "3115000",
    "end": "3121300"
  },
  {
    "text": "hard to examine all\nthe explanations. So how do I pick k? So that's the question.",
    "start": "3121300",
    "end": "3126550"
  },
  {
    "text": "So these k explanations are\na subset of k explanations that we pick, should\nhave two characteristics.",
    "start": "3126550",
    "end": "3133250"
  },
  {
    "text": "So one is they should\nbe representative. In some sense, they\nshould summarize",
    "start": "3133250",
    "end": "3138369"
  },
  {
    "text": "the model's global\nbehavior, and the other is they should be diverse. They should not be redundant\ndescriptions, right?",
    "start": "3138370",
    "end": "3144700"
  },
  {
    "text": "So for example, let's say if I\nhave picked the point already that is labeled in black\ncolor, and its associated",
    "start": "3144700",
    "end": "3152260"
  },
  {
    "text": "explanation in my\nglobal explanation, I would rather pick the blue\npoint, and its explanation next",
    "start": "3152260",
    "end": "3158860"
  },
  {
    "text": "instead of the red. Because the red is essentially\nthe same linear model, right?",
    "start": "3158860",
    "end": "3164200"
  },
  {
    "text": "Given that you are\ntrying to only pick k points and their explanation\nto give a global summary",
    "start": "3164200",
    "end": "3169779"
  },
  {
    "text": "you don't want to pick\nredundant explanations, right? So now, how do we do this?",
    "start": "3169780",
    "end": "3175120"
  },
  {
    "text": "Essentially, this\ncan be formulated as a sub-modular\noptimization problem, and a greedy approach can\nbe employed in order to pick",
    "start": "3175120",
    "end": "3182829"
  },
  {
    "text": "such explanations, right? So you basically start at some\npoint, pick an explanation,",
    "start": "3182830",
    "end": "3188770"
  },
  {
    "text": "and then maximally try\nto pick explanations that differ maximally\nfrom this explanation",
    "start": "3188770",
    "end": "3195340"
  },
  {
    "text": "that you have already\npicked, right? So that's the way in\nwhich you can intuitively think about this process,\nand this approach is",
    "start": "3195340",
    "end": "3202480"
  },
  {
    "text": "model agnostic, which means you\ndon't need access to gradients of the model, functional\nforms of the model,",
    "start": "3202480",
    "end": "3208810"
  },
  {
    "text": "architecture of the model. All you need is you should\nbe able to throw a data point at the model, query the\nlabel of the point, and get it,",
    "start": "3208810",
    "end": "3215860"
  },
  {
    "text": "right? So that's true even of\nLIME and SHAP and some of these other\napproaches, by the way.",
    "start": "3215860",
    "end": "3221050"
  },
  {
    "text": "That distinction often\nof how much access you need to the model becomes\nimportant again in practice",
    "start": "3221050",
    "end": "3227590"
  },
  {
    "text": "because in certain settings\nyou may not have access to, say, model gradients\nor model architectures",
    "start": "3227590",
    "end": "3232900"
  },
  {
    "text": "or their functional forms. All right, so similarly,\nthere is another approach",
    "start": "3232900",
    "end": "3238119"
  },
  {
    "text": "called SP-Anchor,\nwhich is essentially what we thought about for LIME. It's an analogous extension,\nbut for Anchor algorithm,",
    "start": "3238120",
    "end": "3246430"
  },
  {
    "text": "and it produces rules. So use the Anchor's algorithm\nto obtain these local rules set",
    "start": "3246430",
    "end": "3252040"
  },
  {
    "text": "for every instance and\nthen use the same procedure to greedily select a subset\nof k local explanations",
    "start": "3252040",
    "end": "3258730"
  },
  {
    "text": "and then return them as\na global explanation, OK? All right, so let's\ntalk a little bit",
    "start": "3258730",
    "end": "3263830"
  },
  {
    "text": "about representation-based\napproaches because these have gained a lot\nof popularity in recent times",
    "start": "3263830",
    "end": "3269980"
  },
  {
    "text": "but have also encountered\na lot of pushback, OK, and you'll see\nwhy in just a bit.",
    "start": "3269980",
    "end": "3275000"
  },
  {
    "text": "So the goal of\nrepresentation-based approaches is that you're trying to\nderive model understanding",
    "start": "3275000",
    "end": "3281529"
  },
  {
    "text": "by analyzing intermediate\nrepresentations of a deep neural network, right?",
    "start": "3281530",
    "end": "3286870"
  },
  {
    "text": "So in some sense, your\nmain goal in doing so is to see how much\ndo models rely",
    "start": "3286870",
    "end": "3293650"
  },
  {
    "text": "on concepts that\nare semantically meaningful to humans. So what we want to go from--",
    "start": "3293650",
    "end": "3299920"
  },
  {
    "text": "where we want to go to\nis, so far, we are saying, OK, you give me a bunch\nof input features,",
    "start": "3299920",
    "end": "3305170"
  },
  {
    "text": "and I'll tell you the importance\nof each of these input features on the prediction, right? But what we are saying\nis, what if I as a human",
    "start": "3305170",
    "end": "3313210"
  },
  {
    "text": "will tell you a concept that's\nnot a feature in the data? For example, let's look\nat this scenario, right?",
    "start": "3313210",
    "end": "3319599"
  },
  {
    "text": "So let's say we are looking\nat this particular prediction where you have the\nimage of the zebra,",
    "start": "3319600",
    "end": "3325000"
  },
  {
    "text": "and there's a model\nthat takes this image and predicts the label\ncorrectly, right? Now, if I want to ask the\nquestion, how important is",
    "start": "3325000",
    "end": "3333549"
  },
  {
    "text": "the concept of stripes\nto this prediction, where stripes is not an encoded\nfeature in the feature space.",
    "start": "3333550",
    "end": "3342010"
  },
  {
    "text": "I know what stripes is. As humans, we know what\nthat concept means, right,",
    "start": "3342010",
    "end": "3348880"
  },
  {
    "text": "but for the model,\nit's all pixels, right? So it can only\ncompute importance on the pixels in the\nimage, but now you're",
    "start": "3348880",
    "end": "3355480"
  },
  {
    "text": "saying I have a\nconcept in my mind. How important is that\nconcept to this prediction?",
    "start": "3355480",
    "end": "3361490"
  },
  {
    "text": "So how to do that is\nbasically this idea of representation-based\nexplanations. OK?",
    "start": "3361490",
    "end": "3367569"
  },
  {
    "text": "So one of the approaches\nthat's popular in this area is called TCAV, and the way\nthis approach approaches",
    "start": "3367570",
    "end": "3374440"
  },
  {
    "text": "this problem is\nas follows, right? So let's say now our goal is\nto estimate the importance of",
    "start": "3374440",
    "end": "3380110"
  },
  {
    "text": "or influence of the\nconcept called stripes on the predictions of a model. OK? So for this, first of all,\nI need to tell the model",
    "start": "3380110",
    "end": "3388210"
  },
  {
    "text": "or tell your algorithm what\nstripes even mean, right? So to this end, I'll give\nmy model two sets of images.",
    "start": "3388210",
    "end": "3397059"
  },
  {
    "text": "The top set of\nimages that you see is all capturing the concept\nof stripes in different ways,",
    "start": "3397060",
    "end": "3404020"
  },
  {
    "text": "and the bottom set\nof images are just random examples, which have\nnothing to do with stripes.",
    "start": "3404020",
    "end": "3409630"
  },
  {
    "text": "So I'm giving two\nsets of images. One from the stripes\nclass, and the other",
    "start": "3409630",
    "end": "3415330"
  },
  {
    "text": "from a class that\nis not stripes, like a random set\nof image, right? Now, I pass these\ntwo sets of images",
    "start": "3415330",
    "end": "3423160"
  },
  {
    "text": "through the model\nwhose predictions I'm trying to explain, and\nlet's pick a particular layer.",
    "start": "3423160",
    "end": "3430030"
  },
  {
    "text": "Let's say the l-th\nlayer, which generates a bunch of representations.",
    "start": "3430030",
    "end": "3435349"
  },
  {
    "text": "So let's say, our goal is\nto basically determine how does the concept of\nstripiness in some sense",
    "start": "3435350",
    "end": "3442090"
  },
  {
    "text": "influence the representations in\nthe l-th later of this network, OK? So let's say that\nthat's the goal,",
    "start": "3442090",
    "end": "3448570"
  },
  {
    "text": "or in fact, there\nis more we want to say about the prediction,\nbut we can literally do that approach that I'm\ngoing to discuss at each layer",
    "start": "3448570",
    "end": "3456130"
  },
  {
    "text": "and then sort of compute the\naggregates over all the layers to determine what\nis the influence",
    "start": "3456130",
    "end": "3461860"
  },
  {
    "text": "of the stripiness\nconcept on the output. OK? But let's just pick the\nl-th layer at this point,",
    "start": "3461860",
    "end": "3468430"
  },
  {
    "text": "and let's take the\nrepresentations generated by that layer by the model\nfor each of these images.",
    "start": "3468430",
    "end": "3476230"
  },
  {
    "text": "Both the stripe images as well\nas the random images, right, and let's say that that's\nwhat we are basically",
    "start": "3476230",
    "end": "3483099"
  },
  {
    "text": "getting at the l-th layer\nfor each of these images. Now, we build a\nlinear classifier,",
    "start": "3483100",
    "end": "3489490"
  },
  {
    "text": "which basically separates\nthese two classes of vectors. So all this linear\nclassifier does",
    "start": "3489490",
    "end": "3496780"
  },
  {
    "text": "is essentially say, for\nthis particular image, so here is the vector\nset or here is the vector",
    "start": "3496780",
    "end": "3504070"
  },
  {
    "text": "that this would be, or it\nis just basically trying to separate the class. Is this vector belonging\nto the stripes class,",
    "start": "3504070",
    "end": "3511960"
  },
  {
    "text": "or is this vector belonging\nto the random class, right? So that's what it is doing.",
    "start": "3511960",
    "end": "3517180"
  },
  {
    "text": "And then, now, using this\nlinear classifier that we fit, we can actually\ncompute a vector that",
    "start": "3517180",
    "end": "3526329"
  },
  {
    "text": "is orthogonal to the\ndecision boundary and moves in the direction of the\nconcept of stripes, right?",
    "start": "3526330",
    "end": "3533050"
  },
  {
    "text": "So if you see this\nvector, we see l. It's orthogonal to\nthe decision boundary. It is pointing in the\ndirection of the stripes class",
    "start": "3533050",
    "end": "3540340"
  },
  {
    "text": "and away from the\nrandom class, right? So why are we doing\nall this exercise?",
    "start": "3540340",
    "end": "3545350"
  },
  {
    "text": "Our goal is to basically\nget a vector representation",
    "start": "3545350",
    "end": "3550420"
  },
  {
    "text": "of the concept stripes, right? So if I train\nstripes to the model, like stripes is a concept\nthat makes sense to me",
    "start": "3550420",
    "end": "3558460"
  },
  {
    "text": "but not the model. Now, by doing all this,\nI generated a vector representation in the space\nof the representations",
    "start": "3558460",
    "end": "3566560"
  },
  {
    "text": "in the l-th layer. That corresponds to the notion\nor the concept of stripes. OK?",
    "start": "3566560",
    "end": "3572710"
  },
  {
    "text": "So once we have such\na vector, then we can leverage this and\ncompute gradients,",
    "start": "3572710",
    "end": "3578380"
  },
  {
    "text": "do all other things\nin order to get the importance of this\nvector on the outcome, right?",
    "start": "3578380",
    "end": "3585920"
  },
  {
    "text": "So that's basically the logic\nthat's being implied here. So just to recap\nthis whole process,",
    "start": "3585920",
    "end": "3591619"
  },
  {
    "text": "the goal is you will start\nwith two sets of images. One set of images represents\nthe notion of stripes.",
    "start": "3591620",
    "end": "3597859"
  },
  {
    "text": "The other set of images\nrepresents random examples, and then you get the vectors\nfor all of those images",
    "start": "3597860",
    "end": "3604369"
  },
  {
    "text": "from the model, from each\nof the layers actually. And then you try to build\nlinear classifiers that",
    "start": "3604370",
    "end": "3611000"
  },
  {
    "text": "separate the two classes\nof vector activations, and you take the vector that\nis orthogonal to the decision",
    "start": "3611000",
    "end": "3618680"
  },
  {
    "text": "boundary pointing\nin the direction of the concept of interest. And then you compute derivatives\nby leveraging this vector",
    "start": "3618680",
    "end": "3626329"
  },
  {
    "text": "to determine the importance\nof the notion of stripes on a given prediction, right?",
    "start": "3626330",
    "end": "3631380"
  },
  {
    "text": "So the key thing here\nis we went from having the concept of stripes in our\nmind to getting a vector which",
    "start": "3631380",
    "end": "3638090"
  },
  {
    "text": "quantifies what is the notion\nof stripes to the model, right?",
    "start": "3638090",
    "end": "3643110"
  },
  {
    "text": "OK, great. So let's move to the next\nclass of global exploration",
    "start": "3643110",
    "end": "3648900"
  },
  {
    "text": "approaches. This is called\nmodern distillation and has actually been\nthere for quite a long time",
    "start": "3648900",
    "end": "3654870"
  },
  {
    "text": "and also is popular among\nespecially these tabular sort of data environments.",
    "start": "3654870",
    "end": "3662830"
  },
  {
    "text": "So the goal here is that you\nhave this predictive model again, f of x, that you\nwant to explain or provide",
    "start": "3662830",
    "end": "3669000"
  },
  {
    "text": "a global explanation for. So let's say you have\na bunch of data points here that you can\nthrow at this model.",
    "start": "3669000",
    "end": "3675120"
  },
  {
    "text": "You can get the\npredictions of this model on each of those data points.",
    "start": "3675120",
    "end": "3680490"
  },
  {
    "text": "You have query access to\nthis predictive model, and you have access to the data\nset and the corresponding model",
    "start": "3680490",
    "end": "3686280"
  },
  {
    "text": "predictions. Now, you take all this, pass it\nthrough an explainer algorithm,",
    "start": "3686280",
    "end": "3691589"
  },
  {
    "text": "and then sort of approximate\nthese predictions or either try to mimic these\npredictions using a simpler",
    "start": "3691590",
    "end": "3699870"
  },
  {
    "text": "interpretable model, which\nis sort of a lot more easier to understand.",
    "start": "3699870",
    "end": "3705360"
  },
  {
    "text": "So, essentially, take these\nmodels predictions and input instances and try to\napproximate or mimic",
    "start": "3705360",
    "end": "3711839"
  },
  {
    "text": "the predictions of this\nmodel but now using a simpler model, right? And, if you recall, we talked\nabout GAMs a bit earlier",
    "start": "3711840",
    "end": "3720390"
  },
  {
    "text": "when we were discussing\ninherently interpretable models. So GAMs have actually\nbeen proposed",
    "start": "3720390",
    "end": "3726869"
  },
  {
    "text": "as a global explanation\nsolution for a lot of these black-box models. So the idea is that,\nagain, take the points,",
    "start": "3726870",
    "end": "3734160"
  },
  {
    "text": "take the predictions, try to\nfit a GAM on these predictions. Of course, how accurate\nwould these fitting GAMs",
    "start": "3734160",
    "end": "3742950"
  },
  {
    "text": "to these kinds of the setting\nwould depend on, again, how complex are the predictions\nto capture using the functional",
    "start": "3742950",
    "end": "3751800"
  },
  {
    "text": "forms of GAM, right? Sometimes, you\ncan be successful. Sometimes, it might be hard. So that depends on the\nnature of the data,",
    "start": "3751800",
    "end": "3759060"
  },
  {
    "text": "and the complexity of the\nboundaries in the data. ",
    "start": "3759060",
    "end": "3764180"
  },
  {
    "text": "So we have discussed at length\nabout this kind of outcome variable and how the\noutcome variable is",
    "start": "3764180",
    "end": "3770390"
  },
  {
    "text": "affected by the different\nvalues of the input variable and so on. So I'm not going\nto touch upon this,",
    "start": "3770390",
    "end": "3776509"
  },
  {
    "text": "but essentially, here is\nwhat you will try to fit. So what you do is you\nhave input points. You have the corresponding\nmodel predictions.",
    "start": "3776510",
    "end": "3783200"
  },
  {
    "text": "You try to fit a GAM on it. That's essentially what\nis happening here, OK? All right. ",
    "start": "3783200",
    "end": "3789780"
  },
  {
    "text": "And as you can imagine,\nnow decision trees have also been considered\nas this kind of fitting",
    "start": "3789780",
    "end": "3796319"
  },
  {
    "text": "the simpler models to try and\napproximate the predictions of the complex models. So that was also something\nthat has been explored by some",
    "start": "3796320",
    "end": "3804060"
  },
  {
    "text": "of the prior approaches. And once you have some class\nof rule-based approaches,",
    "start": "3804060",
    "end": "3809250"
  },
  {
    "text": "you can imagine people would\nthink of other classes, like rule sets and so on. So those are also used in order\nto approximate these kinds",
    "start": "3809250",
    "end": "3818910"
  },
  {
    "text": "of mimic the predictions\nof the complex models. So in some sense,\nI'll just give you",
    "start": "3818910",
    "end": "3824700"
  },
  {
    "text": "one example of a stylized\nversion of decision sets that at some point\nwe used to work on.",
    "start": "3824700",
    "end": "3831610"
  },
  {
    "text": "So here, as you\ncan see, so this is the summary of what a\ncomplex neural net is doing.",
    "start": "3831610",
    "end": "3837990"
  },
  {
    "text": "This is actually quite\naccurate, particularly in this particular data set\nand this particular setting.",
    "start": "3837990",
    "end": "3844410"
  },
  {
    "text": "But these decision\nsets are also, I'm calling them stylized. Because instead of\njust having some rules,",
    "start": "3844410",
    "end": "3849690"
  },
  {
    "text": "this is ordered in like\na two-level hierarchy, where the upper layer\nrepresents subgroup description.",
    "start": "3849690",
    "end": "3856810"
  },
  {
    "text": "So that's basically\nthe description of the properties of\ncertain groups in the data,",
    "start": "3856810",
    "end": "3863790"
  },
  {
    "text": "and then the inner\nrules basically represent what the model is\ndoing on those subgroups, right? So there is a very\nclean separation",
    "start": "3863790",
    "end": "3870960"
  },
  {
    "text": "between what is a\nsubgroup and then what is model logic in some sense. And that is very\nhelpful in seeing",
    "start": "3870960",
    "end": "3878940"
  },
  {
    "text": "at a high level\nwhat the model is doing for different\nsubgroups in the data. And all of these,\nincluding segmenting",
    "start": "3878940",
    "end": "3886349"
  },
  {
    "text": "the data into subgroups\nand finding rules that explain model logic in\nthat subgroup, all of these",
    "start": "3886350",
    "end": "3892980"
  },
  {
    "text": "are automatically generated,\nand there is the ability to customize these, OK?",
    "start": "3892980",
    "end": "3899200"
  },
  {
    "text": "So for example, an end user\ncan say something like, explain how this model\nbehaves across patient groups",
    "start": "3899200",
    "end": "3908010"
  },
  {
    "text": "with different values\nof smoking and exercise. So you know that\nsmoking and exercise are like the features of interest.",
    "start": "3908010",
    "end": "3914500"
  },
  {
    "text": "So you can customize\nthat set of rules that you saw using these\ntwo features of interest.",
    "start": "3914500",
    "end": "3920819"
  },
  {
    "text": "That's exercise and smoking. And now, the rules are split\naccording to different values",
    "start": "3920820",
    "end": "3926490"
  },
  {
    "text": "of exercise and smoking. As you can see, not all values. Some because you also want\nthe rules to be compact.",
    "start": "3926490",
    "end": "3932640"
  },
  {
    "text": "So it's deciding\nhow to divide the-- partition the space\nor divide the space",
    "start": "3932640",
    "end": "3937680"
  },
  {
    "text": "based on features of interest. And how to go about these\nthings or generate these things.",
    "start": "3937680",
    "end": "3945930"
  },
  {
    "text": "A lot of this can\nactually be inspired by, and that's the running theme. We talked about some of\nthe objective functions",
    "start": "3945930",
    "end": "3953340"
  },
  {
    "text": "with the decision sets. So we could employ\nsome of the pieces that are similar to that.",
    "start": "3953340",
    "end": "3959040"
  },
  {
    "text": "Others are a bit\ndifferent from that. For example, you\nwill try to minimize the number of instances for\nwhich the explanations label is",
    "start": "3959040",
    "end": "3967770"
  },
  {
    "text": "not equal to the model\nprediction, right? So the sets are\nproducing labels. You want those labels to\nmatch the model predictions,",
    "start": "3967770",
    "end": "3975970"
  },
  {
    "text": "and then you will also minimize\nthe number of duplicate rules applicable to each\ninstance so that there",
    "start": "3975970",
    "end": "3981510"
  },
  {
    "text": "is no confusion in terms of the\nexplanation for each instance. And then you, of course,\nminimize the number",
    "start": "3981510",
    "end": "3987300"
  },
  {
    "text": "of conditions in the rules. You also put constraints\non the number of rules and the subgroups,\nwhich is the outer rule.",
    "start": "3987300",
    "end": "3994619"
  },
  {
    "text": "And you can also allow\nfor customizability by saying outer\nrules should only comprise of features\nof interest,",
    "start": "3994620",
    "end": "4001740"
  },
  {
    "text": "which are given by the user. So these are some of the\ntricks, and this turns out to,",
    "start": "4001740",
    "end": "4007710"
  },
  {
    "text": "again, be a similar problem. But this time, with\nmatroid constraints. So you can use like a\nsmoothened-out version",
    "start": "4007710",
    "end": "4014150"
  },
  {
    "text": "of some local search algorithms\nthat we talked about previously in order to solve these kinds\nof optimization problems.",
    "start": "4014150",
    "end": "4022760"
  },
  {
    "text": "And along similar\nways, actually, you can think of summaries\nof counterfactuals.",
    "start": "4022760",
    "end": "4029160"
  },
  {
    "text": "So for example, we\ntalked about this a bit earlier as how to generate\ncounterfactual explanations",
    "start": "4029160",
    "end": "4035450"
  },
  {
    "text": "for individual users\nor individual instances in the data. Now, you get a bunch of such\ncounterfactuals or recourses.",
    "start": "4035450",
    "end": "4043940"
  },
  {
    "text": "Now, the question is\nthere is a decision maker or a regulatory\nauthority who",
    "start": "4043940",
    "end": "4049040"
  },
  {
    "text": "is trying to figure out\nif this particular model and the associated\nrecourses are reasonable,",
    "start": "4049040",
    "end": "4055730"
  },
  {
    "text": "or if they have some bizarre\nbiases that are going on that we can't figure out. So how to help them.",
    "start": "4055730",
    "end": "4061760"
  },
  {
    "text": "So in some sense,\nhow do recourses permitted by the model vary\nacross various racial and",
    "start": "4061760",
    "end": "4068090"
  },
  {
    "text": "gender subgroups? Are there any biases against\ncertain demographics, and the biases in\nthis context could",
    "start": "4068090",
    "end": "4074720"
  },
  {
    "text": "look like you're asking\nsome people to change a lot of features,\nwhereas you're asking some other people to\njust change very little, right?",
    "start": "4074720",
    "end": "4082850"
  },
  {
    "text": "And you're doing-- or\nthat decision is somehow getting hinged on or based\non what racial subgroup",
    "start": "4082850",
    "end": "4089150"
  },
  {
    "text": "they belong to or what gender\nsubgroup they belong to, then it's a problem, right? So let's just maybe\nsee this example.",
    "start": "4089150",
    "end": "4096600"
  },
  {
    "text": "So for instance,\nyou are trying to-- so here is, basically, sort\nof this kind of a summaries",
    "start": "4096600",
    "end": "4105620"
  },
  {
    "text": "of counterfactuals. What this is saying is\nfor different subgroups, again, the subgroups are\ncaptured by the outer rules.",
    "start": "4105620",
    "end": "4113660"
  },
  {
    "text": "And for each subgroup,\nyou are seeing what needs to be\nchanged for that person to sort of get alone, right?",
    "start": "4113660",
    "end": "4120139"
  },
  {
    "text": "So for example, if race is\nCaucasian, gender is male, so you're asking that person\nto change has job from no",
    "start": "4120140",
    "end": "4128449"
  },
  {
    "text": "to yes, right? The rest is fine. And similarly, drugs\nfrom yes to no, right?",
    "start": "4128450",
    "end": "4134810"
  },
  {
    "text": "On the other hand,\nfor Caucasian females, you're asking them to change\ntwo features in the second rule",
    "start": "4134810",
    "end": "4140899"
  },
  {
    "text": "instead of one for the\ncorresponding Caucasian male, right? So similarly, if the\nrace is different,",
    "start": "4140899",
    "end": "4146990"
  },
  {
    "text": "you're actually asking people\nto change a lot more features. Now, this kind of\nbias is a problem",
    "start": "4146990",
    "end": "4153679"
  },
  {
    "text": "because you're making one\nsubgroup do a lot more work or put more effort when\ngetting a recourse.",
    "start": "4153680",
    "end": "4159859"
  },
  {
    "text": "But this, you can\nonly know when you have a summary of all\nthe counterfactuals or the recourses that the\nalgorithm is generating",
    "start": "4159859",
    "end": "4168049"
  },
  {
    "text": "for a given model, right? So that's why these\nsummaries can be useful. All right. ",
    "start": "4168050",
    "end": "4175409"
  },
  {
    "text": "So, again, the\nouter rules that you see, just similar to some\nof these other summaries that we have looked at earlier\nare the subgroup descriptors.",
    "start": "4175410",
    "end": "4183989"
  },
  {
    "text": "And then the inner\nrules that you see are the recourse\nrules, which tell a person or which tell us what\nfeatures need to be changed",
    "start": "4183990",
    "end": "4192839"
  },
  {
    "text": "and from what to what, right? So now, if the\nregulator sees that this",
    "start": "4192840",
    "end": "4200340"
  },
  {
    "text": "is in fact what is happening\nwith respect to the recourses, they can actually realize\nthat, OK, this is biased.",
    "start": "4200340",
    "end": "4206790"
  },
  {
    "text": "It's requiring\ncertain demographics to act upon a lot more features\nthan the others, right?",
    "start": "4206790",
    "end": "4211980"
  },
  {
    "text": "And the desiderata\nin this case will be that we want\nthe recourses that",
    "start": "4211980",
    "end": "4217440"
  },
  {
    "text": "are coming out in these\nsummaries to be correct. So in some sense,\nwe want to minimize the number of\napplicants for whom",
    "start": "4217440",
    "end": "4224100"
  },
  {
    "text": "prescribed recourse does not\nlead to a desired outcome, right? So you don't want to capture\nthose things in the summary",
    "start": "4224100",
    "end": "4230760"
  },
  {
    "text": "because that's an\nincorrect summary. And then the other thing is you\nwant recourse coverage, where",
    "start": "4230760",
    "end": "4236820"
  },
  {
    "text": "you're trying to minimize the\nnumber of applicants for whom recourse does not exist. So in this set of rules,\nyou don't see a recourse",
    "start": "4236820",
    "end": "4244260"
  },
  {
    "text": "for certain applicants. We want to minimize that\nset of people, okay? And then we want to minimize\nthe total feature costs, as well",
    "start": "4244260",
    "end": "4252540"
  },
  {
    "text": "as magnitude of changes in\nthe feature values, right? So that's basically\nthe generic way",
    "start": "4252540",
    "end": "4258502"
  },
  {
    "text": "of-- by the way, the summaries\nof recourses that we saw, the counterfactuals that\nwe saw, that summary itself",
    "start": "4258502",
    "end": "4265170"
  },
  {
    "text": "can be used to prescribe\nrecourses to individuals too, right? So it can have a dual purpose.",
    "start": "4265170",
    "end": "4270850"
  },
  {
    "text": "It can serve as a summary\nto tell a regulator what is happening, and you can\nalso use the exact same thing",
    "start": "4270850",
    "end": "4277199"
  },
  {
    "text": "to prescribe recourses\nto individuals. So it's a dual approach, right?",
    "start": "4277200",
    "end": "4282360"
  },
  {
    "text": "Given that it's a\ndual approach, we are also trying to\nfocus on minimizing the total cost required to\nimplement the recourses that",
    "start": "4282360",
    "end": "4290760"
  },
  {
    "text": "are being prescribed\nfor each group, as well as the\nmagnitude of the changes that are required, right?",
    "start": "4290760",
    "end": "4296460"
  },
  {
    "text": "And of course, we need these\nsummaries to be interpretable, which means we can't let this\nsort of summary rule set bloat",
    "start": "4296460",
    "end": "4304780"
  },
  {
    "text": "up. So we want some constraints\non the number of rules, number of conditions in the\nrules, number of subgroups,",
    "start": "4304780",
    "end": "4311130"
  },
  {
    "text": "and we can also\nprovide customizability by ensuring that\nouter rules only",
    "start": "4311130",
    "end": "4316739"
  },
  {
    "text": "comprise of these features of\ninterest to the stakeholders. And those features don't\nshow up in the inner rules,",
    "start": "4316740",
    "end": "4323070"
  },
  {
    "text": "for example, right? OK.  So again, it's a similar\nkind of problem as the one",
    "start": "4323070",
    "end": "4329159"
  },
  {
    "text": "that we just talked about with\nthe two-level decision sets without the recourse or\nwithout the counterfactuals.",
    "start": "4329160",
    "end": "4335560"
  },
  {
    "text": "So that's what it turns\nout to be, ultimately. So I think, with\nthis, we are almost",
    "start": "4335560",
    "end": "4342030"
  },
  {
    "text": "at the end of this module. So what I can do is take a\nfew minutes of questions, and then maybe we'll pause here\nand then reconvene back right",
    "start": "4342030",
    "end": "4350429"
  },
  {
    "text": "after lunch. ",
    "start": "4350430",
    "end": "4357000"
  }
]
[
  {
    "start": "0",
    "end": "16000"
  },
  {
    "start": "0",
    "end": "4468"
  },
  {
    "text": "CHRISTOPHER POTTS:\nWelcome, everyone.",
    "start": "4468",
    "end": "6010"
  },
  {
    "text": "This is the first\nscreencast in our series",
    "start": "6010",
    "end": "7760"
  },
  {
    "text": "on Analysis Methods in NLP.",
    "start": "7760",
    "end": "8973"
  },
  {
    "text": "This is one of my favorite\nunits in the course",
    "start": "8973",
    "end": "10889"
  },
  {
    "text": "because it's directly\noriented toward helping you",
    "start": "10890",
    "end": "13110"
  },
  {
    "text": "do even better final projects.",
    "start": "13110",
    "end": "15719"
  },
  {
    "text": "Now there's a lot we could\ndiscuss under the rubric",
    "start": "15720",
    "end": "17880"
  },
  {
    "start": "16000",
    "end": "74000"
  },
  {
    "text": "of analysis methods in NLP.",
    "start": "17880",
    "end": "19500"
  },
  {
    "text": "I've chosen four things.",
    "start": "19500",
    "end": "21228"
  },
  {
    "text": "The first two, fall\nunder the heading",
    "start": "21228",
    "end": "22770"
  },
  {
    "text": "of behavioral evaluations.",
    "start": "22770",
    "end": "24390"
  },
  {
    "text": "We'll talk about\nadversarial testing, which",
    "start": "24390",
    "end": "26279"
  },
  {
    "text": "is a very flexible\nway for you to expose",
    "start": "26280",
    "end": "28500"
  },
  {
    "text": "that your system might\nhave some weaknesses",
    "start": "28500",
    "end": "30960"
  },
  {
    "text": "or fail to capture some\nlinguistic phenomenon in a very",
    "start": "30960",
    "end": "34230"
  },
  {
    "text": "systematic way.",
    "start": "34230",
    "end": "36100"
  },
  {
    "text": "And then at this point, we\nalso have the opportunity",
    "start": "36100",
    "end": "38489"
  },
  {
    "text": "for a number of tasks to\ndo adversarial training",
    "start": "38490",
    "end": "41070"
  },
  {
    "text": "and testing, and these\nwould be large dataset that",
    "start": "41070",
    "end": "43800"
  },
  {
    "text": "are full of examples\nthat we know",
    "start": "43800",
    "end": "45989"
  },
  {
    "text": "are difficult for present\nday architectures.",
    "start": "45990",
    "end": "48290"
  },
  {
    "text": "So for every architecture\nyou're exploring,",
    "start": "48290",
    "end": "50820"
  },
  {
    "text": "this would be a chance to really\nstress test that architecture.",
    "start": "50820",
    "end": "54630"
  },
  {
    "text": "And then we're going to move\nbeyond behavioral evaluations",
    "start": "54630",
    "end": "57090"
  },
  {
    "text": "to talk about what I've called\nstructural evaluation methods.",
    "start": "57090",
    "end": "59820"
  },
  {
    "text": "And these include probing\nand feature attribution.",
    "start": "59820",
    "end": "62435"
  },
  {
    "text": "And these are\ntechniques that you",
    "start": "62435",
    "end": "63810"
  },
  {
    "text": "could use to peer\ninside your system",
    "start": "63810",
    "end": "65640"
  },
  {
    "text": "and gain an understanding of\nwhat its hidden representations",
    "start": "65640",
    "end": "68760"
  },
  {
    "text": "are like, and how those\nrepresentations are impacting",
    "start": "68760",
    "end": "71670"
  },
  {
    "text": "the model's predictions.",
    "start": "71670",
    "end": "74700"
  },
  {
    "start": "74000",
    "end": "144000"
  },
  {
    "text": "The motivations\nfor this are many.",
    "start": "74700",
    "end": "76619"
  },
  {
    "text": "Here are just a\nfew high-level ones",
    "start": "76620",
    "end": "78210"
  },
  {
    "text": "that are kind of\noriented toward projects.",
    "start": "78210",
    "end": "80140"
  },
  {
    "text": "The first, is just\nthat we might want",
    "start": "80140",
    "end": "81682"
  },
  {
    "text": "to find the limits of the\nsystem that you're developing.",
    "start": "81682",
    "end": "84210"
  },
  {
    "text": "All our systems have\nlimitations and finding",
    "start": "84210",
    "end": "86790"
  },
  {
    "text": "them is always\nscientifically useful.",
    "start": "86790",
    "end": "89730"
  },
  {
    "text": "We might just also\nwant to understand",
    "start": "89730",
    "end": "91620"
  },
  {
    "text": "your system's behavior better.",
    "start": "91620",
    "end": "93000"
  },
  {
    "text": "What are its internal\nrepresentations like,",
    "start": "93000",
    "end": "95160"
  },
  {
    "text": "and how are they feeding\ninto its final predictions",
    "start": "95160",
    "end": "97500"
  },
  {
    "text": "and its overall behaviors?",
    "start": "97500",
    "end": "98730"
  },
  {
    "text": "That's also just\nincredibly rewarding.",
    "start": "98730",
    "end": "101040"
  },
  {
    "text": "And both of these things\nmight feed into just",
    "start": "101040",
    "end": "102990"
  },
  {
    "text": "achieving more robust systems.",
    "start": "102990",
    "end": "104670"
  },
  {
    "text": "To the extent that we can\nfind weaknesses and understand",
    "start": "104670",
    "end": "107939"
  },
  {
    "text": "behaviors, we can\npossibly take steps",
    "start": "107940",
    "end": "110280"
  },
  {
    "text": "toward building even\nmore robust systems.",
    "start": "110280",
    "end": "113570"
  },
  {
    "text": "And as I said, all\nof this is oriented",
    "start": "113570",
    "end": "115325"
  },
  {
    "text": "toward your final projects.",
    "start": "115325",
    "end": "116450"
  },
  {
    "text": "The techniques that\nwe're discussing",
    "start": "116450",
    "end": "118159"
  },
  {
    "text": "are powerful and easy ways\nto improve the analysis",
    "start": "118160",
    "end": "121070"
  },
  {
    "text": "section of a paper.",
    "start": "121070",
    "end": "122430"
  },
  {
    "text": "Analysis sections\nare important, but it",
    "start": "122430",
    "end": "124310"
  },
  {
    "text": "can be difficult to write them.",
    "start": "124310",
    "end": "125720"
  },
  {
    "text": "It feels very open ended\nand often very unstructured.",
    "start": "125720",
    "end": "128449"
  },
  {
    "text": "People talk in general\nways about doing",
    "start": "128449",
    "end": "130729"
  },
  {
    "text": "error analysis and\nso forth, but it",
    "start": "130729",
    "end": "132440"
  },
  {
    "text": "can be hard to pinpoint exactly\nwhat would be productive.",
    "start": "132440",
    "end": "135470"
  },
  {
    "text": "I think the methods that\nwe're talking about here",
    "start": "135470",
    "end": "137960"
  },
  {
    "text": "are very generally\napplicable and can",
    "start": "137960",
    "end": "140750"
  },
  {
    "text": "lead to really productive\nand rich analysis sections.",
    "start": "140750",
    "end": "144110"
  },
  {
    "start": "144000",
    "end": "323000"
  },
  {
    "text": "Let's begin with\nadversarial testing,",
    "start": "144110",
    "end": "145733"
  },
  {
    "text": "this is a mode that we've\ntalked about before.",
    "start": "145733",
    "end": "147650"
  },
  {
    "text": "The examples on this slide are\nfrom this now classic paper",
    "start": "147650",
    "end": "150349"
  },
  {
    "text": "Glockner et al., 2018,\ncalled \"Breaking NLI.\"",
    "start": "150350",
    "end": "153770"
  },
  {
    "text": "And what they did is only\nreally mildly adversarial.",
    "start": "153770",
    "end": "156270"
  },
  {
    "text": "It's just kind of a challenge.",
    "start": "156270",
    "end": "157520"
  },
  {
    "text": "And it exposes some lack of\nsystematicity in certain NLI",
    "start": "157520",
    "end": "161090"
  },
  {
    "text": "models.",
    "start": "161090",
    "end": "161819"
  },
  {
    "text": "So here's what they did.",
    "start": "161820",
    "end": "163020"
  },
  {
    "text": "They began from SNLI\nexamples like, \"a little girl",
    "start": "163020",
    "end": "165680"
  },
  {
    "text": "is kneeling in the\ndirt crying\" entails",
    "start": "165680",
    "end": "168079"
  },
  {
    "text": "\"a little girl is very sad.\"",
    "start": "168080",
    "end": "169850"
  },
  {
    "text": "And they simply use\nlexical resources",
    "start": "169850",
    "end": "171920"
  },
  {
    "text": "to change the\nhypothesis by one word.",
    "start": "171920",
    "end": "173990"
  },
  {
    "text": "So that it now reads, \"a\nlittle girl is very unhappy.\"",
    "start": "173990",
    "end": "177350"
  },
  {
    "text": "We would expect a system\nthat truly understood",
    "start": "177350",
    "end": "180260"
  },
  {
    "text": "the reasoning involved\nin these examples",
    "start": "180260",
    "end": "182330"
  },
  {
    "text": "to continue to predict\nentail in the second case",
    "start": "182330",
    "end": "185180"
  },
  {
    "text": "because these examples\nare roughly synonymous.",
    "start": "185180",
    "end": "187579"
  },
  {
    "text": "But what they found, is that\nsystems would often start",
    "start": "187580",
    "end": "189860"
  },
  {
    "text": "to predict\ncontradiction, possibly",
    "start": "189860",
    "end": "191540"
  },
  {
    "text": "because of the negation\nthat occurs here.",
    "start": "191540",
    "end": "194120"
  },
  {
    "text": "The second example is similar.",
    "start": "194120",
    "end": "195799"
  },
  {
    "text": "We begin from the SNLI\nexample, \"an elderly couple",
    "start": "195800",
    "end": "198650"
  },
  {
    "text": "are sitting outside a\nrestaurant enjoying wine\"",
    "start": "198650",
    "end": "201200"
  },
  {
    "text": "entails \"a couple\ndrinking wine.\"",
    "start": "201200",
    "end": "203300"
  },
  {
    "text": "And here they just\nchanged wine to champagne.",
    "start": "203300",
    "end": "206090"
  },
  {
    "text": "What we would expect\nis that a system that",
    "start": "206090",
    "end": "207890"
  },
  {
    "text": "knew about these lexical\nitems and their relations,",
    "start": "207890",
    "end": "210440"
  },
  {
    "text": "would flip to predicting\nneutral in this case.",
    "start": "210440",
    "end": "213450"
  },
  {
    "text": "But as you might\nimagine, systems",
    "start": "213450",
    "end": "215270"
  },
  {
    "text": "continue to predict\nentails because they",
    "start": "215270",
    "end": "217370"
  },
  {
    "text": "have only a very fuzzy\nunderstanding of how",
    "start": "217370",
    "end": "220159"
  },
  {
    "text": "wine and champagne are\nrelated to each other.",
    "start": "220160",
    "end": "224590"
  },
  {
    "text": "Here is the results table, and\nrecall this is a 2018 paper.",
    "start": "224590",
    "end": "227760"
  },
  {
    "text": "And what they're\nmainly testing here,",
    "start": "227760",
    "end": "229500"
  },
  {
    "text": "are models that we might\nregard as precursors",
    "start": "229500",
    "end": "231960"
  },
  {
    "text": "to the transformers that\nwe've been so focused on.",
    "start": "231960",
    "end": "234720"
  },
  {
    "text": "And the picture is very clear.",
    "start": "234720",
    "end": "236110"
  },
  {
    "text": "These models do well on the\nSNLI test set, mid-to-high 80s,",
    "start": "236110",
    "end": "240000"
  },
  {
    "text": "but their performance plummets\non this new adversarial test",
    "start": "240000",
    "end": "243030"
  },
  {
    "text": "set.",
    "start": "243030",
    "end": "243959"
  },
  {
    "text": "There are two exceptions down\nhere, this WordNet baseline",
    "start": "243960",
    "end": "246810"
  },
  {
    "text": "and the KIM architecture.",
    "start": "246810",
    "end": "248010"
  },
  {
    "text": "But it's important to note\nthat these models effectively",
    "start": "248010",
    "end": "250980"
  },
  {
    "text": "had access directly\nin the case of WordNet",
    "start": "250980",
    "end": "253390"
  },
  {
    "text": "and indirectly in\nthe case of KIM,",
    "start": "253390",
    "end": "255240"
  },
  {
    "text": "to a lexical resource\nthat was used",
    "start": "255240",
    "end": "257250"
  },
  {
    "text": "to create the adversarial test.",
    "start": "257250",
    "end": "259480"
  },
  {
    "text": "And so they don't see such a\nlarge performance drop here.",
    "start": "259480",
    "end": "262240"
  },
  {
    "text": "But even still, all\nof these numbers",
    "start": "262240",
    "end": "264449"
  },
  {
    "text": "are kind of modest\nat this point.",
    "start": "264450",
    "end": "266800"
  },
  {
    "text": "And I told you that this\nwas an interesting story.",
    "start": "266800",
    "end": "269181"
  },
  {
    "text": "Here's the interesting twist.",
    "start": "269182",
    "end": "270390"
  },
  {
    "text": "At this point in 2021, you can\nsimply download RoBERTA-MNLI--",
    "start": "270390",
    "end": "275100"
  },
  {
    "text": "that's the RoBERTA parameters\nfine-tuned on the MultiNLI data",
    "start": "275100",
    "end": "278670"
  },
  {
    "text": "set--",
    "start": "278670",
    "end": "279660"
  },
  {
    "text": "and run this adversarial test.",
    "start": "279660",
    "end": "281400"
  },
  {
    "text": "And what you find is that\nmodel does astoundingly well",
    "start": "281400",
    "end": "284610"
  },
  {
    "text": "on the Breaking NLI data set.",
    "start": "284610",
    "end": "286389"
  },
  {
    "text": "I would focus on\nthese two f1-scores",
    "start": "286390",
    "end": "288270"
  },
  {
    "text": "here for the two classes where\nwe have a lot of support,",
    "start": "288270",
    "end": "290970"
  },
  {
    "text": "contradiction and entailment.",
    "start": "290970",
    "end": "292500"
  },
  {
    "text": "The numbers are above 90\nas is the accuracy here,",
    "start": "292500",
    "end": "295360"
  },
  {
    "text": "which is directly\ncomparable to the numbers",
    "start": "295360",
    "end": "297599"
  },
  {
    "text": "that Glockner et al. reported.",
    "start": "297600",
    "end": "299430"
  },
  {
    "text": "An amazing\naccomplishment-- recall",
    "start": "299430",
    "end": "301169"
  },
  {
    "text": "that the original examples\nfrom the adversarial test",
    "start": "301170",
    "end": "304350"
  },
  {
    "text": "are from SNLI,\nthis is multi-NLI.",
    "start": "304350",
    "end": "306810"
  },
  {
    "text": "It was not developed\nspecifically",
    "start": "306810",
    "end": "308580"
  },
  {
    "text": "to solve this adversarial test.",
    "start": "308580",
    "end": "310199"
  },
  {
    "text": "And nonetheless, it\nlooks like RoBERTA",
    "start": "310200",
    "end": "312360"
  },
  {
    "text": "has systematic knowledge of\nthe lexical relations involved",
    "start": "312360",
    "end": "316469"
  },
  {
    "text": "and required to solve\nthis adversarial test--",
    "start": "316470",
    "end": "319710"
  },
  {
    "text": "so possibly a mark\nof real progress.",
    "start": "319710",
    "end": "323330"
  },
  {
    "start": "323000",
    "end": "357000"
  },
  {
    "text": "As I said, you can also,\nfor selective tests,",
    "start": "323330",
    "end": "325669"
  },
  {
    "text": "move into the mode of\ndoing adversarial training",
    "start": "325670",
    "end": "327860"
  },
  {
    "text": "and testing.",
    "start": "327860",
    "end": "329270"
  },
  {
    "text": "Here are the cases I know where\nthe dataset is large enough",
    "start": "329270",
    "end": "331729"
  },
  {
    "text": "to support training\nand testing on examples",
    "start": "331730",
    "end": "334820"
  },
  {
    "text": "that were created via\nsome adversarial dynamic--",
    "start": "334820",
    "end": "337730"
  },
  {
    "text": "common sense reasoning,\nnatural language inference,",
    "start": "337730",
    "end": "340310"
  },
  {
    "text": "question answering,\nsentiment and hate speech.",
    "start": "340310",
    "end": "342860"
  },
  {
    "text": "And as I said, this is a\nreally exciting opportunity",
    "start": "342860",
    "end": "345650"
  },
  {
    "text": "to see just how\nrobust your system is",
    "start": "345650",
    "end": "348050"
  },
  {
    "text": "when exposed to\nexamples that we know",
    "start": "348050",
    "end": "350090"
  },
  {
    "text": "are difficult for\nmodern architectures,",
    "start": "350090",
    "end": "352040"
  },
  {
    "text": "because that's how these\ndatasets were designed.",
    "start": "352040",
    "end": "356090"
  },
  {
    "text": "Now let's move into the\nmore behavioral mode.",
    "start": "356090",
    "end": "358010"
  },
  {
    "start": "357000",
    "end": "415000"
  },
  {
    "text": "We'll start with probing of\ninternal representations.",
    "start": "358010",
    "end": "360620"
  },
  {
    "text": "Probes are little\nsupervised models typically,",
    "start": "360620",
    "end": "362840"
  },
  {
    "text": "that you fit on the\ninternal representations",
    "start": "362840",
    "end": "365480"
  },
  {
    "text": "of your model of\ninterest to expose",
    "start": "365480",
    "end": "368690"
  },
  {
    "text": "what those hidden\nrepresentations latently",
    "start": "368690",
    "end": "370640"
  },
  {
    "text": "encode.",
    "start": "370640",
    "end": "371540"
  },
  {
    "text": "This is from a classic paper\nby Ian Tenney et al., 2019.",
    "start": "371540",
    "end": "375200"
  },
  {
    "text": "And what we have\nalong the x-axis",
    "start": "375200",
    "end": "377390"
  },
  {
    "text": "is the BERT layers, starting\nfrom the embedding layer",
    "start": "377390",
    "end": "379610"
  },
  {
    "text": "and going to 24.",
    "start": "379610",
    "end": "380969"
  },
  {
    "text": "This is BERT large, so\nthere are 24 layers.",
    "start": "380970",
    "end": "383510"
  },
  {
    "text": "And the picture\nis quite striking.",
    "start": "383510",
    "end": "385010"
  },
  {
    "text": "As you start from the\ntop here and move down,",
    "start": "385010",
    "end": "387240"
  },
  {
    "text": "you can see that as we move\nfrom more syntactic things, up",
    "start": "387240",
    "end": "390110"
  },
  {
    "text": "into more discourse-y\nsemantic content,",
    "start": "390110",
    "end": "392509"
  },
  {
    "text": "like co-ref and\nrelation extraction,",
    "start": "392510",
    "end": "396080"
  },
  {
    "text": "you find that the higher\nlayers of the BERT model",
    "start": "396080",
    "end": "399050"
  },
  {
    "text": "are encoding that\ninformation latently.",
    "start": "399050",
    "end": "401090"
  },
  {
    "text": "That's what these probing\nresults reveal in this picture.",
    "start": "401090",
    "end": "404360"
  },
  {
    "text": "Quite striking look at what\nthe pretraining process",
    "start": "404360",
    "end": "408169"
  },
  {
    "text": "in this case, of BERT,\nis learning latently",
    "start": "408170",
    "end": "411290"
  },
  {
    "text": "about the structures\nof language.",
    "start": "411290",
    "end": "415210"
  },
  {
    "start": "415000",
    "end": "507000"
  },
  {
    "text": "And then we'll finally talk\nabout feature attribution,",
    "start": "415210",
    "end": "417590"
  },
  {
    "text": "which is one step further in\nthis more introspective mode,",
    "start": "417590",
    "end": "420400"
  },
  {
    "text": "because here as\nyou'll see, I think",
    "start": "420400",
    "end": "422350"
  },
  {
    "text": "we can get a really deep picture\nat how individual features",
    "start": "422350",
    "end": "426430"
  },
  {
    "text": "and representations\nare directly related",
    "start": "426430",
    "end": "429430"
  },
  {
    "text": "to the model's predictions.",
    "start": "429430",
    "end": "430996"
  },
  {
    "text": "And what I've done here, is\nuse the Integrated Gradients",
    "start": "430997",
    "end": "433330"
  },
  {
    "text": "model, which is the model\nthat we'll focus on.",
    "start": "433330",
    "end": "435610"
  },
  {
    "text": "I ran it on a sentiment model.",
    "start": "435610",
    "end": "437479"
  },
  {
    "text": "And you can see here,\nwe have the true label,",
    "start": "437480",
    "end": "439480"
  },
  {
    "text": "the predicted model\nwith the probability,",
    "start": "439480",
    "end": "441550"
  },
  {
    "text": "and then we have word\nlevel importances,",
    "start": "441550",
    "end": "443620"
  },
  {
    "text": "as measured by Integrated\nGradients, where blue means",
    "start": "443620",
    "end": "446410"
  },
  {
    "text": "it's a bias toward\npositive predictions,",
    "start": "446410",
    "end": "448960"
  },
  {
    "text": "and red means it's a bias\ntoward negative predictions.",
    "start": "448960",
    "end": "452470"
  },
  {
    "text": "And I've picked an example\nthat I think kind of stress",
    "start": "452470",
    "end": "454720"
  },
  {
    "text": "tests the model.",
    "start": "454720",
    "end": "455600"
  },
  {
    "text": "It's a little bit adversarial\nbecause it's-- all these",
    "start": "455600",
    "end": "458020"
  },
  {
    "text": "examples involve mean\nin the sense of good,",
    "start": "458020",
    "end": "461710"
  },
  {
    "text": "as in a mean apple pie, meaning\na delicious or a good one.",
    "start": "461710",
    "end": "465250"
  },
  {
    "text": "And you can see that by and\nlarge, this model's predictions",
    "start": "465250",
    "end": "467740"
  },
  {
    "text": "are pretty systematic.",
    "start": "467740",
    "end": "468819"
  },
  {
    "text": "It's mostly predicting positive\nfor variants, like \"they sell,\"",
    "start": "468820",
    "end": "472360"
  },
  {
    "text": "\"they make,\" \"he makes,\"\nalthough this last one,",
    "start": "472360",
    "end": "475180"
  },
  {
    "text": "\"he sells,\" might worry\nus a little bit because it",
    "start": "475180",
    "end": "477280"
  },
  {
    "text": "has flipped to negative, despite\nthe changes to the example",
    "start": "477280",
    "end": "480370"
  },
  {
    "text": "being truly incidental.",
    "start": "480370",
    "end": "482949"
  },
  {
    "text": "And this might point to a way in\nwhich the model does or doesn't",
    "start": "482950",
    "end": "485950"
  },
  {
    "text": "have knowledge of how\nthe individual components",
    "start": "485950",
    "end": "488530"
  },
  {
    "text": "of these examples should\nbe predict-- should",
    "start": "488530",
    "end": "491050"
  },
  {
    "text": "be feeding into the\nfinal predictions",
    "start": "491050",
    "end": "492789"
  },
  {
    "text": "that the model makes.",
    "start": "492790",
    "end": "493817"
  },
  {
    "text": "I think that's a\nwonderful opportunity",
    "start": "493817",
    "end": "495400"
  },
  {
    "text": "to get a sense for how\nrobust the model is actually",
    "start": "495400",
    "end": "497800"
  },
  {
    "text": "going to be to variations,\nlike the one that you see here.",
    "start": "497800",
    "end": "501900"
  },
  {
    "start": "501900",
    "end": "506000"
  }
]
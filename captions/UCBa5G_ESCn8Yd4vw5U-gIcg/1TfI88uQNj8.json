[
  {
    "text": "thank you so so as well as the",
    "start": "12750",
    "end": "18400"
  },
  {
    "text": "University of San Francisco I'm also the co-founder of a self-funded lab cord",
    "start": "18400",
    "end": "23560"
  },
  {
    "text": "fast AI fast at AI actually is very related to this quote from this obscure",
    "start": "23560",
    "end": "30460"
  },
  {
    "text": "person guy called Dennis Allison and 1972 created something called the people's computer company where he said",
    "start": "30460",
    "end": "36910"
  },
  {
    "text": "computers are mostly used against people instead of for people used to control people instead of to free them time to",
    "start": "36910",
    "end": "43900"
  },
  {
    "text": "change all that it was interesting to me reading this quote because we saw something similar",
    "start": "43900",
    "end": "54820"
  },
  {
    "text": "similar happening with with AI which is that AI is this super powerful set of",
    "start": "54820",
    "end": "61060"
  },
  {
    "text": "technologies that we saw were in the hands of a kind of an elite few that",
    "start": "61060",
    "end": "66729"
  },
  {
    "text": "that elite few was pretty homogeneous and we're not necessarily people who",
    "start": "66729",
    "end": "75330"
  },
  {
    "text": "deeply understood what the most pressing societal problems in the world really are or had the you know data to fix them",
    "start": "75330",
    "end": "82810"
  },
  {
    "text": "or understood the operational constraints necessary to do something about them and so when we started",
    "start": "82810",
    "end": "88780"
  },
  {
    "text": "looking into the question of like well what would it take to make AI more",
    "start": "88780",
    "end": "94090"
  },
  {
    "text": "accessible so it's not in the pay in the hands of this elite few we've we found",
    "start": "94090",
    "end": "99130"
  },
  {
    "text": "that the answer was quite difficult actually so for example my my co-founder",
    "start": "99130",
    "end": "106540"
  },
  {
    "text": "Rachel Thomas asked one of the top researchers in in 2013 I think it was at",
    "start": "106540",
    "end": "114130"
  },
  {
    "text": "a meet-up how do you actually initialize your your models in a way that they",
    "start": "114130",
    "end": "119979"
  },
  {
    "text": "trained from a good starting point and he said his response was well that's part of a bag of tricks that nobody",
    "start": "119979",
    "end": "127780"
  },
  {
    "text": "publishes so it's like you couldn't even start training because you didn't even",
    "start": "127780",
    "end": "133510"
  },
  {
    "text": "know how to start with your weights so we kind of set out to change that we started this self-funded lab cord fast",
    "start": "133510",
    "end": "140230"
  },
  {
    "text": "AI where we basically tried to figure out can we get deep learning specifically into the",
    "start": "140230",
    "end": "146300"
  },
  {
    "text": "hands of domain experts by which I mean like radiologists or journalists or",
    "start": "146300",
    "end": "154780"
  },
  {
    "text": "lawyers or whatever so so first today I",
    "start": "154780",
    "end": "162410"
  },
  {
    "text": "does a number of things to try and do this this mission of making deep learning accessible the main thing I'm",
    "start": "162410",
    "end": "170060"
  },
  {
    "text": "going to focus on today is that we write software the software we write is basically to try and make it so that",
    "start": "170060",
    "end": "176180"
  },
  {
    "text": "it's it's easier to get really good results with deep learning we also teach which is a lot about",
    "start": "176180",
    "end": "183230"
  },
  {
    "text": "basically teaching how do you get really good results with deep learning and a lot of time part of the answer is use",
    "start": "183230",
    "end": "189350"
  },
  {
    "text": "the software we've written some of the time it's not we do a lot of you know",
    "start": "189350",
    "end": "194690"
  },
  {
    "text": "traditional or semi traditional academic research any time we come across something where we think oh this is like",
    "start": "194690",
    "end": "201230"
  },
  {
    "text": "something that deep learning can or should be able to do really well but currently it doesn't do well or it's expensive or it requires the math PhD or",
    "start": "201230",
    "end": "209150"
  },
  {
    "text": "whatever we do the research to figure out how to make it easier and cheaper and not not much data and then there's",
    "start": "209150",
    "end": "216230"
  },
  {
    "text": "kind of no point making something accessible if if each person who comes",
    "start": "216230",
    "end": "221870"
  },
  {
    "text": "into your field is now an island you know with with no community to reach out",
    "start": "221870",
    "end": "227330"
  },
  {
    "text": "to and share their work and get support from and so forth so we also have developed the world's largest deep",
    "start": "227330",
    "end": "233120"
  },
  {
    "text": "learning community which is just this super friendly engaging and also a",
    "start": "233120",
    "end": "239600"
  },
  {
    "text": "highly competent online place before I",
    "start": "239600",
    "end": "245209"
  },
  {
    "text": "tell you about our software I'll give you a quick sense of some of the stuff that kind of goes into it around the",
    "start": "245209",
    "end": "251330"
  },
  {
    "text": "research and training that we do our online course so you know we're we don't",
    "start": "251330",
    "end": "257630"
  },
  {
    "text": "have any revenues or profits or anything like I said we're a self-funded lab so everything we do is free and open source",
    "start": "257630",
    "end": "264260"
  },
  {
    "text": "and there's no ads or anything like that so we have this course online practical",
    "start": "264260",
    "end": "269780"
  },
  {
    "text": "tech learning for coders which I don't know for sure but I think it might be the most popular tech learning course in",
    "start": "269780",
    "end": "275330"
  },
  {
    "text": "the world there are 14 lessons about 28 hours of material each lessons you expect her to",
    "start": "275330",
    "end": "282150"
  },
  {
    "text": "do about 10 hours of work so you know your energy up doing well over 100 hours of pretty intense work currently it",
    "start": "282150",
    "end": "288840"
  },
  {
    "text": "assumes that you've had at least a year of solid coding experience which is a prerequisite we would love to get rid of",
    "start": "288840",
    "end": "297020"
  },
  {
    "text": "one of the interesting things was were after a course a couple of years ago I",
    "start": "297170",
    "end": "302210"
  },
  {
    "text": "put up a post on our community forums saying after the first class saying like",
    "start": "302210",
    "end": "307650"
  },
  {
    "text": "hey did anybody build anything cool after today's class and this was a while",
    "start": "307650",
    "end": "314160"
  },
  {
    "text": "ago there's now more than well more than a thousand people who answered that by saying yes which was super cool and so",
    "start": "314160",
    "end": "320630"
  },
  {
    "text": "people who as I said come into this with a year of coding experience but no other",
    "start": "320630",
    "end": "327300"
  },
  {
    "text": "prerequisites so from all around the world so no math prerequisites other than high school math so one person said",
    "start": "327300",
    "end": "335100"
  },
  {
    "text": "oh I'm from Trinidad and Tobago and we have certain kinds of Islanders and I built a classifier to figure out what",
    "start": "335100",
    "end": "340980"
  },
  {
    "text": "kind of Island or a picture is of somebody else did Sookie knees versus cucumbers somebody else picked aerial",
    "start": "340980",
    "end": "348600"
  },
  {
    "text": "photos of the earth and built something that with 85% accuracy you could figure",
    "start": "348600",
    "end": "353610"
  },
  {
    "text": "out what city a picture was of somebody else classified types of Panamanian bus",
    "start": "353610",
    "end": "360170"
  },
  {
    "text": "the interesting thing about these is better cloth they're generally with",
    "start": "360170",
    "end": "367190"
  },
  {
    "text": "here's one 300 pictures across 50 types so like it was quite it's quite common",
    "start": "367190",
    "end": "373230"
  },
  {
    "text": "to have like less than 10 miniatures per class a lot of people getting good results with less than 50 images overall",
    "start": "373230",
    "end": "380510"
  },
  {
    "text": "so like definitely kind of showing you don't need this is after one lesson so",
    "start": "380510",
    "end": "385680"
  },
  {
    "text": "you don't need a PhD and a data center and a million images and so forth so",
    "start": "385680",
    "end": "392280"
  },
  {
    "text": "we're kind of trying to show that the the the baseline required to get good",
    "start": "392280",
    "end": "399000"
  },
  {
    "text": "results in this technology it may be not as high as people assume as an example of figuring out different types of",
    "start": "399000",
    "end": "408330"
  },
  {
    "text": "addition of buildings in Tanzania this kind of stuff super important for like earthquake resilience and other disaster",
    "start": "408330",
    "end": "414270"
  },
  {
    "text": "resilience there are people working on this field very actively to help get teams to the places that really need the",
    "start": "414270",
    "end": "420030"
  },
  {
    "text": "help after a natural disaster now the student got got straightaway a state-of-the-art Resort better than any",
    "start": "420030",
    "end": "426060"
  },
  {
    "text": "academic paper for Devin Geary classification one of the interesting things that happens when you bring people in from all around the world",
    "start": "426060",
    "end": "432419"
  },
  {
    "text": "who you know they often tackle problems that just haven't been tackled before whether it be you know Trinidad and",
    "start": "432419",
    "end": "438810"
  },
  {
    "text": "Tobago person recognition or Devon Gary character recognition often it turns out",
    "start": "438810",
    "end": "445409"
  },
  {
    "text": "that to kind of create the best ever result it doesn't actually require that much because there just hasn't been that",
    "start": "445409",
    "end": "451919"
  },
  {
    "text": "much resources thrown at it before so that's been cool what are the",
    "start": "451919",
    "end": "457050"
  },
  {
    "text": "interesting things is to see how people kind of take the tools and adjust them",
    "start": "457050",
    "end": "462750"
  },
  {
    "text": "to work in their domain so somebody was looking at after getting after lesson one was looking at an environmental",
    "start": "462750",
    "end": "467909"
  },
  {
    "text": "sound classification and at this after Lesson one you only know computer vision",
    "start": "467909",
    "end": "473039"
  },
  {
    "text": "right so they basically talk sounds and turn them into pictures by doing spectrograms of them and throw it",
    "start": "473039",
    "end": "480930"
  },
  {
    "text": "through the models that we taught in Lesson one and again they got that turned out they got the state of beat",
    "start": "480930",
    "end": "486120"
  },
  {
    "text": "easily the state of the art result from the academic literature for environmental sound classification",
    "start": "486120",
    "end": "492379"
  },
  {
    "text": "Elena Haile is amazing she's from human long activity international she's now created a whole bunch of projects",
    "start": "492960",
    "end": "499460"
  },
  {
    "text": "showing significant advances in in genomics again she doesn't have a background in in AI but has a very",
    "start": "499460",
    "end": "507810"
  },
  {
    "text": "strong background in genomics I'm working with a Craig Venters lab and",
    "start": "507810",
    "end": "514649"
  },
  {
    "text": "then there are some folks who go kind of above and beyond so one of the things we",
    "start": "514649",
    "end": "520440"
  },
  {
    "text": "did in lesson 7 was we showed people how you can take you can do generative image",
    "start": "520440",
    "end": "526110"
  },
  {
    "text": "models which is where you take a deep learning network where the outputs not a classification but it's another image and one of the folks in the course Jason",
    "start": "526110",
    "end": "534240"
  },
  {
    "text": "antic thought oh I wonder if that could add color to black more images and he tried it out and it turns out the answer",
    "start": "534240",
    "end": "540899"
  },
  {
    "text": "was you you can and he's now spent over a year working on this and this is an example of his model that color roses this black",
    "start": "540899",
    "end": "548740"
  },
  {
    "text": "and white image as you can see it does a beautiful job and actually this technology has just been acquired by",
    "start": "548740",
    "end": "554040"
  },
  {
    "text": "it's got my heritage which is like the biggest kind of family tree thing in the",
    "start": "554040",
    "end": "559840"
  },
  {
    "text": "world and they now I think of the first week something like a million images term customers got colorized so this is",
    "start": "559840",
    "end": "567730"
  },
  {
    "text": "something that kind of started as a first AI student project this guy was working at an insurance company and",
    "start": "567730",
    "end": "573220"
  },
  {
    "text": "turned into this passion project and is now a commercial thing that you can that",
    "start": "573220",
    "end": "578260"
  },
  {
    "text": "you can go and use one of the nice things has been to see how groups of",
    "start": "578260",
    "end": "584560"
  },
  {
    "text": "domain experts kind of get together and and build cool stuff so a lot of radiologists have gone through the",
    "start": "584560",
    "end": "590530"
  },
  {
    "text": "course and this is kind of really strong alumni network of fast AI radiology kind",
    "start": "590530",
    "end": "598090"
  },
  {
    "text": "of practitioners so Alexander is one of those he's now published a paper he's",
    "start": "598090",
    "end": "604960"
  },
  {
    "text": "won a capital competition I don't know how these people who are working doctors",
    "start": "604960",
    "end": "611680"
  },
  {
    "text": "hours or every to this but there are people who it's really cool there there are now you know young",
    "start": "611680",
    "end": "617380"
  },
  {
    "text": "doctors and residents who are also world-class D cloning practitioners and",
    "start": "617380",
    "end": "623440"
  },
  {
    "text": "that's been great to see oh this is a cool example so one of our alumni",
    "start": "623440",
    "end": "629590"
  },
  {
    "text": "Christine Payne who seems everything she does in the world she does incredibly well she actually went to open AI",
    "start": "629590",
    "end": "638250"
  },
  {
    "text": "shortly after finishing her first AI course and working super hard in lots of",
    "start": "638250",
    "end": "643510"
  },
  {
    "text": "other areas she built a neural network music generator which was such a big",
    "start": "643510",
    "end": "651760"
  },
  {
    "text": "thing that the BBC Philharmonic Orchestra commissioned to actually play some of the music that this thing built",
    "start": "651760",
    "end": "658600"
  },
  {
    "text": "so she's now at open AI which is a pretty cool research lab focusing on",
    "start": "658600",
    "end": "666130"
  },
  {
    "text": "deep learning and one of the interesting things about Christine is that before that she was a pianist so like this is a",
    "start": "666130",
    "end": "674350"
  },
  {
    "text": "good example of a domain expert and giving them at all",
    "start": "674350",
    "end": "680200"
  },
  {
    "text": "and seeing what they what they kind of build with it not just a pnsu stone a",
    "start": "680200",
    "end": "685450"
  },
  {
    "text": "thousand different things but that was one of them as well as a course as I mentioned we do research one of the",
    "start": "685450",
    "end": "691990"
  },
  {
    "text": "things I noticed early on in this research was that people in the deep learning community didn't seem to talk",
    "start": "691990",
    "end": "697960"
  },
  {
    "text": "to each other as much as they chords so for example there was the NLP people and there was a computer vision people and",
    "start": "697960",
    "end": "704010"
  },
  {
    "text": "when he built software and create courses you kind of have to be cross-disciplinary within the groups and",
    "start": "704010",
    "end": "710140"
  },
  {
    "text": "I noticed all the cool stuff in computer vision wasn't being used in natural language processing which I thought was",
    "start": "710140",
    "end": "716530"
  },
  {
    "text": "weird so I started asking um yeah so",
    "start": "716530",
    "end": "721630"
  },
  {
    "text": "that's yeah that's normal so I you know I asked my friends in NLP how come you're not using the computer vision",
    "start": "721630",
    "end": "727870"
  },
  {
    "text": "stuff and the answer was always that's be a waste of time and it'll pay special its unique you know but I did it anyway",
    "start": "727870",
    "end": "734950"
  },
  {
    "text": "and literally within like four hours of trying a basic computer vision transfer",
    "start": "734950",
    "end": "740800"
  },
  {
    "text": "learning techniques I had broken the state of the art for one of the most important classification datasets in NLP the IMDB data set so that got turned",
    "start": "740800",
    "end": "750100"
  },
  {
    "text": "into a course sebastian ruder who was then doing his PhD saw that and said",
    "start": "750100",
    "end": "756280"
  },
  {
    "text": "that's amazing you should turn it into a paper so Sebastian and I wrote a paper together and that became um fit which",
    "start": "756280",
    "end": "763270"
  },
  {
    "text": "became pretty much the first really strong example of of general transfer",
    "start": "763270",
    "end": "768910"
  },
  {
    "text": "learning and NLP Alec had fitted open Lu I then took that and turned it into GPT",
    "start": "768910",
    "end": "774400"
  },
  {
    "text": "which became GPT too and Google took that and they turned that into Bert and now we've got this flowering of transfer",
    "start": "774400",
    "end": "779980"
  },
  {
    "text": "learning in NLP so often it just requires this you know small little observation not a whole lot of time not",
    "start": "779980",
    "end": "786550"
  },
  {
    "text": "a whole lot of effort to say okay maybe these approaches would work well and",
    "start": "786550",
    "end": "793020"
  },
  {
    "text": "yeah so Sebastian's now at deep mind and a lot of people now talking a lot about",
    "start": "793020",
    "end": "800560"
  },
  {
    "text": "the power of find treating and transfer learning and natural language processing one of the",
    "start": "800560",
    "end": "807520"
  },
  {
    "text": "challenges in in the field of deep learning has been all the kind of hyper",
    "start": "807520",
    "end": "815050"
  },
  {
    "text": "hyper parameters or the settings you have to tune to get something to train properly so one of the things we've",
    "start": "815050",
    "end": "821110"
  },
  {
    "text": "tried a lot with our research is to figure out how to make it so you don't have to sew like we did something pretty",
    "start": "821110",
    "end": "826630"
  },
  {
    "text": "obvious which was to look at a whole bunch of hyper parameters and then we worked with a group called fellowship AI",
    "start": "826630",
    "end": "834300"
  },
  {
    "text": "who are basically a bunch of mainly PhD",
    "start": "834300",
    "end": "839310"
  },
  {
    "text": "graduates from non math and machine learning fields so kind of economics and",
    "start": "839310",
    "end": "844560"
  },
  {
    "text": "political science and whatever who were interested in getting into AI and they",
    "start": "844560",
    "end": "850090"
  },
  {
    "text": "helped run these experiments where across lots of different kinds of datasets and lots of different kinds of hyper parameters we basically found a",
    "start": "850090",
    "end": "857470"
  },
  {
    "text": "set of hyper parameters so you know yellow means it's kind of the midpoint",
    "start": "857470",
    "end": "863380"
  },
  {
    "text": "set of curated hyper parameters found a set of hyper parameters where basically there was no data set and no set of",
    "start": "863380",
    "end": "870310"
  },
  {
    "text": "other hyper parameters that was very significantly better so they you can see how this goes into the software that",
    "start": "870310",
    "end": "876460"
  },
  {
    "text": "kind of becomes then the defaults in the software and then when we find places where it's like okay this hyper",
    "start": "876460",
    "end": "883150"
  },
  {
    "text": "parameter does matter and it depends on this feature of the data set or this features the loss function we can put",
    "start": "883150",
    "end": "890020"
  },
  {
    "text": "those rules as just you know simple heuristics into the software so we kind",
    "start": "890020",
    "end": "895510"
  },
  {
    "text": "of try to replace like Google has this auto ml thing where they run thousands",
    "start": "895510",
    "end": "901240"
  },
  {
    "text": "of models and it costs a fortune of you know to figure out what the best optimal set of high parameters are and we kind",
    "start": "901240",
    "end": "908560"
  },
  {
    "text": "of try to say okay we don't want people to have to pay Google thousands of dollars to run every possibility let's",
    "start": "908560",
    "end": "914830"
  },
  {
    "text": "just give you a set that's going to work first time so this is kind of our approach to you know one of our",
    "start": "914830",
    "end": "920830"
  },
  {
    "text": "approaches to making things more accessible one of the things we really",
    "start": "920830",
    "end": "928420"
  },
  {
    "text": "struggle with is people using lots of money and lots of computers to do cool things is super popular in the",
    "start": "928420",
    "end": "934990"
  },
  {
    "text": "mainstream so and and companies like Google and open a I want to tell this story about",
    "start": "934990",
    "end": "942490"
  },
  {
    "text": "how they have more resources and everybody else and they they use those resources to get great results and the",
    "start": "942490",
    "end": "950380"
  },
  {
    "text": "problem for for us is we keep meeting people who I say hey if you ever thought",
    "start": "950380",
    "end": "955810"
  },
  {
    "text": "about applying deep learning to your problem or seeing if deep learning might be useful in your field I keep hearing the answer I'm not going to try because",
    "start": "955810",
    "end": "963280"
  },
  {
    "text": "I don't have Google's computers I don't have their amount of data I you know I can't usefully contribute to this field",
    "start": "963280",
    "end": "970630"
  },
  {
    "text": "so we hear that all the time so from time to time we try to make our own",
    "start": "970630",
    "end": "975880"
  },
  {
    "text": "little stamp to say you know even a little to person self funded research",
    "start": "975880",
    "end": "982780"
  },
  {
    "text": "lab you know with a bunch of new students can do you know this kind of work so the the main one we did",
    "start": "982780",
    "end": "990520"
  },
  {
    "text": "particularly was dawn bench which was actually a competition run out of Stanford very cool competition where",
    "start": "990520",
    "end": "998170"
  },
  {
    "text": "they said okay rather than seeing who can be the most accurate on imagenet",
    "start": "998170",
    "end": "1003270"
  },
  {
    "text": "which is a very popular computer vision data set who can train at the fastest to you know a approximately",
    "start": "1003270",
    "end": "1009900"
  },
  {
    "text": "state-of-the-art level so kind of the first to dive in was Intel and they",
    "start": "1009900",
    "end": "1016890"
  },
  {
    "text": "published a result on the leaderboard using a thousand computers networked together and they got I don't know what",
    "start": "1016890",
    "end": "1022740"
  },
  {
    "text": "it was like nine hours or something and then Google had a big team from Google",
    "start": "1022740",
    "end": "1027810"
  },
  {
    "text": "brain working on it and they published something that was like I can't remember maybe it's like four hours using a whole",
    "start": "1027810",
    "end": "1033630"
  },
  {
    "text": "pot of TP use working in parallel and then one of my students came to me and",
    "start": "1033630",
    "end": "1040050"
  },
  {
    "text": "told me about this there's the one bench thing and said you know maybe we could",
    "start": "1040050",
    "end": "1046350"
  },
  {
    "text": "try to give it a go and see if we can not come last which is always a good goal so we thought we'd see if we could",
    "start": "1046350",
    "end": "1051870"
  },
  {
    "text": "not come last and we won and we won",
    "start": "1051870",
    "end": "1057600"
  },
  {
    "text": "using one computer and the key thing we",
    "start": "1057600",
    "end": "1062970"
  },
  {
    "text": "we did was just the stupid stuff that nobody else had bothered a try most",
    "start": "1062970",
    "end": "1069460"
  },
  {
    "text": "but most importantly rather than training on the large image net images",
    "start": "1069460",
    "end": "1076149"
  },
  {
    "text": "let's make them small and train on the small ones all right so 64 by 64 image compared to",
    "start": "1076149",
    "end": "1082510"
  },
  {
    "text": "a 300 by 300 image you're going to do it 10 times faster even if you only have",
    "start": "1082510",
    "end": "1088360"
  },
  {
    "text": "one computer but it's a picture of the same thing it looks the same it's just a",
    "start": "1088360",
    "end": "1093580"
  },
  {
    "text": "bit pixelated and it's that kind of common-sense thing where you're like okay if a human can see that a 64 by 64",
    "start": "1093580",
    "end": "1099399"
  },
  {
    "text": "image and a 300 by 300 image look the same the computers you know take learning algorithm it's going to see",
    "start": "1099399",
    "end": "1105190"
  },
  {
    "text": "they look the same too so we trained 95% of the epochs on these small images and",
    "start": "1105190",
    "end": "1111100"
  },
  {
    "text": "then at the end we gradually scaled the month and the cool thing is that not only is it way faster because you're",
    "start": "1111100",
    "end": "1116799"
  },
  {
    "text": "just doing less compute you also get a very nice natural data augmentation which is you're actually giving the",
    "start": "1116799",
    "end": "1122169"
  },
  {
    "text": "computer different resolution images during training so it actually tends to overfit less so you can do less epochs",
    "start": "1122169",
    "end": "1128909"
  },
  {
    "text": "and then we did other things like we kind of try to find the research papers",
    "start": "1128909",
    "end": "1134919"
  },
  {
    "text": "that don't get noticed because they don't come out of fancy universities",
    "start": "1134919",
    "end": "1139960"
  },
  {
    "text": "like Stanford so for example there's a guy called Leslie Smith at the Naval Research Lab which he's basically the",
    "start": "1139960",
    "end": "1147279"
  },
  {
    "text": "only guy working there on deep learning stuff nobody's heard of that lab really at least fatigue learning but it turns",
    "start": "1147279",
    "end": "1153039"
  },
  {
    "text": "out that he's he published some amazing insights one of which he discovered that",
    "start": "1153039",
    "end": "1158470"
  },
  {
    "text": "there were certain sets of parameters in certain situations where we could use a 10 times higher learning rate than",
    "start": "1158470",
    "end": "1165429"
  },
  {
    "text": "previously known approaches and train things 10 times faster and he called this thing super convergence academia",
    "start": "1165429",
    "end": "1172659"
  },
  {
    "text": "being what it is he got rejected from every conference it never got published but thanks to the modern world",
    "start": "1172659",
    "end": "1178000"
  },
  {
    "text": "there's a preprint on archive and we could read it and it was clear that like something weirds going on so so yeah",
    "start": "1178000",
    "end": "1187539"
  },
  {
    "text": "Leslie and I in first AI have kind of collaborated informally and figured out",
    "start": "1187539",
    "end": "1193260"
  },
  {
    "text": "with the help of lots of other people around the community how to train neural",
    "start": "1193260",
    "end": "1199029"
  },
  {
    "text": "nets super super fast and one of the nice things is is a great link to the course which is",
    "start": "1199029",
    "end": "1206289"
  },
  {
    "text": "that we tend to say like hey here's this paper we found by this guy quick Leslie Smith here's why it's interesting",
    "start": "1206289",
    "end": "1211539"
  },
  {
    "text": "and then suddenly we've got tens of thousands of people who will who are also enthused and so it tends to kind of",
    "start": "1211539",
    "end": "1218049"
  },
  {
    "text": "percolate up so there's this nice yeah kind of mesh of things going on so",
    "start": "1218049",
    "end": "1224889"
  },
  {
    "text": "that's kind of how that's the feed in to the software and I'd say honestly that",
    "start": "1224889",
    "end": "1233559"
  },
  {
    "text": "you know the focus for us is very much moving from from education to software",
    "start": "1233559",
    "end": "1239409"
  },
  {
    "text": "development because when we started there was like okay let's teach what's already there and then once we felt we",
    "start": "1239409",
    "end": "1247029"
  },
  {
    "text": "were doing the best we can of that then it's like okay well let's try and make it so there are better things to teach",
    "start": "1247029",
    "end": "1252190"
  },
  {
    "text": "and so ideally it would be nice to get to a point where deep learning was as",
    "start": "1252190",
    "end": "1259690"
  },
  {
    "text": "easy to use as the internet is on an iPhone you know we're a long way away",
    "start": "1259690",
    "end": "1266169"
  },
  {
    "text": "from that yet but the only way to get there is not by improving the training but by improving the software people are",
    "start": "1266169",
    "end": "1272139"
  },
  {
    "text": "using so you know we have many steps to get there but as Dennis said in the",
    "start": "1272139",
    "end": "1278049"
  },
  {
    "text": "introduction we're kind of at step two of the software which is we've just spent the last 18 months trying to",
    "start": "1278049",
    "end": "1285730"
  },
  {
    "text": "create the very best library for deep learning that we can one of the I think",
    "start": "1285730",
    "end": "1293889"
  },
  {
    "text": "perhaps the most interesting insight about this development process for me is I have far more experience as a software",
    "start": "1293889",
    "end": "1301749"
  },
  {
    "text": "engineer and coda then as a deep learning person you have been coding for",
    "start": "1301749",
    "end": "1308529"
  },
  {
    "text": "many decades and I love refactoring I think refactorings super cool there are",
    "start": "1308529",
    "end": "1317409"
  },
  {
    "text": "very few people with really deep software engineering backgrounds in the deep learning world and so re things",
    "start": "1317409",
    "end": "1322749"
  },
  {
    "text": "like refactoring don't happen very much faster I - is what happens when you",
    "start": "1322749",
    "end": "1330629"
  },
  {
    "text": "bring refactoring to deep learning and it's actually quite amazing what what",
    "start": "1330629",
    "end": "1336129"
  },
  {
    "text": "happens so the first thing I point out is what we see here which is that you end up with with a layered decoupled API so",
    "start": "1336129",
    "end": "1344930"
  },
  {
    "text": "people often ask us is faster I designed like for beginners and end-users to be",
    "start": "1344930",
    "end": "1350840"
  },
  {
    "text": "like a quick out-of-the-box thing or is it designed for researchers or or what",
    "start": "1350840",
    "end": "1357080"
  },
  {
    "text": "and that the nice thing is with a layered API the answer is yes it's it's all of those things which like to a",
    "start": "1357080",
    "end": "1364010"
  },
  {
    "text": "software engineer does not sound weird back to a machine learning person that's that's mind blowing so we have this",
    "start": "1364010",
    "end": "1372590"
  },
  {
    "text": "applications layer where these four applications are basically things where deep learning is pretty mature pretty",
    "start": "1372590",
    "end": "1380179"
  },
  {
    "text": "effective being used in industry and commercially right now we've done enough",
    "start": "1380179",
    "end": "1386780"
  },
  {
    "text": "research to figure out kind of had a package in it away it's going to it's going to work for you with no more than",
    "start": "1386780",
    "end": "1392330"
  },
  {
    "text": "a couple of hours of training so you know those that's the application layer the mid layer is what all the",
    "start": "1392330",
    "end": "1398809"
  },
  {
    "text": "applications are built on which I'll describe shortly but they're the things",
    "start": "1398809",
    "end": "1403970"
  },
  {
    "text": "which kind of researchers and people building new applications would build on and then the mid layer is built on this",
    "start": "1403970",
    "end": "1409700"
  },
  {
    "text": "foundation layer which has some things",
    "start": "1409700",
    "end": "1414800"
  },
  {
    "text": "that are not at all new but they're new to this world so to give you an example",
    "start": "1414800",
    "end": "1419980"
  },
  {
    "text": "object-oriented tensors so a tensor is kind of the basic building block of deep",
    "start": "1419980",
    "end": "1425420"
  },
  {
    "text": "learning it's it's just a it's just a an N dimensional array not a jagged array",
    "start": "1425420",
    "end": "1432920"
  },
  {
    "text": "so that's the thing that kind of makes it a tensor for computer scientists so tensor for physicists is a bit different",
    "start": "1432920",
    "end": "1439960"
  },
  {
    "text": "in tensor flow and pi torch and you know the libraries people use day to day the",
    "start": "1439960",
    "end": "1446660"
  },
  {
    "text": "types of cancer float tensor byte tensor that's kind of",
    "start": "1446660",
    "end": "1453740"
  },
  {
    "text": "what we mean by type right so when you have a tensor there's not much you can",
    "start": "1453740",
    "end": "1458750"
  },
  {
    "text": "do with it you can't display it or pass",
    "start": "1458750",
    "end": "1464330"
  },
  {
    "text": "it to you know prettier or flip it or translate it or",
    "start": "1464330",
    "end": "1469520"
  },
  {
    "text": "whatever and the rest of the world software engineers use types to describe",
    "start": "1469520",
    "end": "1476450"
  },
  {
    "text": "the semantics of what their thing is no tensor always has semantics you know a tensor represents a three-channel",
    "start": "1476450",
    "end": "1484840"
  },
  {
    "text": "normalized mini batch of images in channel first access order for example",
    "start": "1484840",
    "end": "1491390"
  },
  {
    "text": "so create a type system that can understand those kind of concepts so",
    "start": "1491390",
    "end": "1497660"
  },
  {
    "text": "that's what we did right as it's it's not remotely innovative but it hasn't",
    "start": "1497660",
    "end": "1504620"
  },
  {
    "text": "been done in this field before so we now have a library where you can dot show a",
    "start": "1504620",
    "end": "1510950"
  },
  {
    "text": "tensor and it works or you can not predict on it and it was so that's kind",
    "start": "1510950",
    "end": "1517640"
  },
  {
    "text": "of some of the foundational stuff so the applications well so this faster your",
    "start": "1517640",
    "end": "1524120"
  },
  {
    "text": "library as Dennis mentioned there's a book coming out about it which we just have to finish writing and there's a",
    "start": "1524120",
    "end": "1532880"
  },
  {
    "text": "paper which just came out about it as well yeah we have enough pressure in the",
    "start": "1532880",
    "end": "1545930"
  },
  {
    "text": "applications layer there's kind of some stuff that's across all the applications like transfer learning for example is",
    "start": "1545930",
    "end": "1552860"
  },
  {
    "text": "fundamental to fast AI transfer learning is a thing where you don't have to start with a neural net that can't do anything",
    "start": "1552860",
    "end": "1560270"
  },
  {
    "text": "at all you start with somebody else's neural net that does something a bit like what you want and then you",
    "start": "1560270",
    "end": "1565580"
  },
  {
    "text": "fine-tune it that's what transfer learning is it turns out that how you transfer learn matters a lot",
    "start": "1565580",
    "end": "1572450"
  },
  {
    "text": "very few academics have spent any time focusing on this question it's not a popular research question but it's like",
    "start": "1572450",
    "end": "1578780"
  },
  {
    "text": "just about the most popular most important practical question so we spent a lot of time figuring out how to do",
    "start": "1578780",
    "end": "1583970"
  },
  {
    "text": "this well and it's all built into the first day a library so for every application you can literally call a",
    "start": "1583970",
    "end": "1590540"
  },
  {
    "text": "fine-tuned method and it does all the transfer learning best practices we also",
    "start": "1590540",
    "end": "1597290"
  },
  {
    "text": "try to make it easy to figure out what's going on and specifically if something's not going well why isn't it going well",
    "start": "1597290",
    "end": "1603049"
  },
  {
    "text": "so we provide these kind of graphs that show what's happening each line is a",
    "start": "1603049",
    "end": "1608450"
  },
  {
    "text": "different layer of the model and of the x-axis is different mini-batches being passed through and we look at the means",
    "start": "1608450",
    "end": "1615139"
  },
  {
    "text": "and standard deviations of the layers in various different ways one of the really interesting ones is this thing which we",
    "start": "1615139",
    "end": "1621619"
  },
  {
    "text": "call the colorful dimension which these four pictures are four layers of a",
    "start": "1621619",
    "end": "1627860"
  },
  {
    "text": "neural network that's training the again the x axis is batch is mini-batches so",
    "start": "1627860",
    "end": "1634100"
  },
  {
    "text": "it's kind of time and if you like and each set of pixels represents a log",
    "start": "1634100",
    "end": "1641690"
  },
  {
    "text": "normalized histogram of all of the activations in that layer so when you",
    "start": "1641690",
    "end": "1647239"
  },
  {
    "text": "see kind of all the color down here it indicates that nearly all of the activations are close to zero and when",
    "start": "1647239",
    "end": "1654470"
  },
  {
    "text": "you see it spread out like this it means that there's activations throughout the neural net and generally speaking this",
    "start": "1654470",
    "end": "1661519"
  },
  {
    "text": "is bad because it means that you've got like a very sparse set of activations so",
    "start": "1661519",
    "end": "1667489"
  },
  {
    "text": "it's not doing much computation you've got tens of millions of activations but most of them aren't doing anything at",
    "start": "1667489",
    "end": "1673850"
  },
  {
    "text": "all and so this is fascinating thing when you create this picture you discover that for many neuron it's when",
    "start": "1673850",
    "end": "1681980"
  },
  {
    "text": "you start training the the kind of spread of activations goes up nicely and",
    "start": "1681980",
    "end": "1687320"
  },
  {
    "text": "then it crashes and then goes up but it kinda goes up exponentially and crashes and because that text in your question so we had never seen this picture drawn",
    "start": "1687320",
    "end": "1694129"
  },
  {
    "text": "before we before we created this and it's a sudden like a-ha moment where",
    "start": "1694129",
    "end": "1700759"
  },
  {
    "text": "you're like this has got to be bad right because every time it comes up and crashes it's got a whole lot of work to",
    "start": "1700759",
    "end": "1707960"
  },
  {
    "text": "do to make these activations anything other than zero and you can see that by the time you get to the fourth layer",
    "start": "1707960",
    "end": "1714019"
  },
  {
    "text": "it's it's very very clear so one of our students actually Stephan all spent a",
    "start": "1714019",
    "end": "1720799"
  },
  {
    "text": "lot of time during a course on like drawing up different ways that we could represent this and helped us create these beautiful pictures but it actually",
    "start": "1720799",
    "end": "1728600"
  },
  {
    "text": "turns out after all that one line is really what you want and that line is at each mini-batch what percentage of the",
    "start": "1728600",
    "end": "1736400"
  },
  {
    "text": "activations for a laya r0 and so for this training in layer four you can see",
    "start": "1736400",
    "end": "1743960"
  },
  {
    "text": "that basically you get to nearly all of them a zero and so you would never know",
    "start": "1743960",
    "end": "1750620"
  },
  {
    "text": "this without these pictures you would just be like oh my models 90% accurate it's a bit disappointing but so be it",
    "start": "1750620",
    "end": "1756920"
  },
  {
    "text": "but actually if you look inside you realize my models not working well at",
    "start": "1756920",
    "end": "1762110"
  },
  {
    "text": "all so in this case we realized that there was a key issue that the the main",
    "start": "1762110",
    "end": "1768500"
  },
  {
    "text": "activation function called the rectified linear unit actually doesn't have a mean of zero value basically removes all",
    "start": "1768500",
    "end": "1776900"
  },
  {
    "text": "negatives and replaces them with zeros which by definition has a positive mean so we just subtracted 0.4 from riolu and",
    "start": "1776900",
    "end": "1784220"
  },
  {
    "text": "reran the exact same model and this is the pictures we got and you can see it the entire that problem is totally gone",
    "start": "1784220",
    "end": "1790220"
  },
  {
    "text": "away and the percent of zeros is great and we ended up with a more accurate",
    "start": "1790220",
    "end": "1795530"
  },
  {
    "text": "model which trained more quickly so there's kind of these you know these defaults and these insights and kind of",
    "start": "1795530",
    "end": "1802790"
  },
  {
    "text": "this focus where we just try to make things work well in practice so we end up with this nice situation where for",
    "start": "1802790",
    "end": "1809450"
  },
  {
    "text": "example there's a computer vision library where we just say import the",
    "start": "1809450",
    "end": "1814640"
  },
  {
    "text": "vision library and then there's kind of one two three one two three four lines",
    "start": "1814640",
    "end": "1821240"
  },
  {
    "text": "of code and it gives you so in this case we're getting a nine percent error rate",
    "start": "1821240",
    "end": "1827060"
  },
  {
    "text": "after 35 seconds for recognizing which one of 37 pet breeds there's an image",
    "start": "1827060",
    "end": "1834250"
  },
  {
    "text": "that's basically the same one two three four lines of code will also fit this",
    "start": "1834250",
    "end": "1839930"
  },
  {
    "text": "data set which will mark every pixel in an image with what kind of object that",
    "start": "1839930",
    "end": "1846260"
  },
  {
    "text": "pixel represents and you can see where the object-oriented stuff comes in I can",
    "start": "1846260",
    "end": "1851600"
  },
  {
    "text": "say show batch and because fast AI knows that the input type is an image in the",
    "start": "1851600",
    "end": "1859880"
  },
  {
    "text": "output type is a mask it knows that the correct way to display it is to provide a color coded mask with an alpha",
    "start": "1859880",
    "end": "1866530"
  },
  {
    "text": "overlaid on top of the image and it's the same thing with the model you could say show results and it'll",
    "start": "1866530",
    "end": "1872270"
  },
  {
    "text": "show you the results with the same way so without the kind of the typed foundation you would you don't need a",
    "start": "1872270",
    "end": "1879980"
  },
  {
    "text": "different function for every combination it will get pretty unwieldy so text classification the same lines of code to",
    "start": "1879980",
    "end": "1888110"
  },
  {
    "text": "a text classification and also again show batch is now going to show you your",
    "start": "1888110",
    "end": "1893710"
  },
  {
    "text": "your texts tabular analysis the same basic lines of code will analyze tables",
    "start": "1893710",
    "end": "1901010"
  },
  {
    "text": "of data collaborative filtering the same basic lines of code will do a collaborative filtering and so this",
    "start": "1901010",
    "end": "1908960"
  },
  {
    "text": "stuff turns out to work super well so people sometimes jump now for him and so this person said oh I just started and I",
    "start": "1908960",
    "end": "1916280"
  },
  {
    "text": "just comparing it to my chance of flow to models and I can't understand why everything's so much better I'm trying",
    "start": "1916280",
    "end": "1921800"
  },
  {
    "text": "to make it as less good as I can and it still much better so like what he kind of build in the best practices into the",
    "start": "1921800",
    "end": "1928220"
  },
  {
    "text": "library so then somebody replied to that 400 some company he said yep we were using transfer flow before spent months",
    "start": "1928220",
    "end": "1935390"
  },
  {
    "text": "tweaking first ai2 days we were getting better results it's important to support",
    "start": "1935390",
    "end": "1943250"
  },
  {
    "text": "kind of incrementally moving across so fast AI lives on top of pi torch it absolutely wouldn't be possible without",
    "start": "1943250",
    "end": "1948860"
  },
  {
    "text": "pi torch which is just a fantastic piece of software and so one of the things we do is you know you can take the official",
    "start": "1948860",
    "end": "1955730"
  },
  {
    "text": "pi torch repository example code delete 30 the 30 lines in the training loop and",
    "start": "1955730",
    "end": "1961430"
  },
  {
    "text": "replace it with these three lines and you get all of the benefits of fasting i training with you know existing with",
    "start": "1961430",
    "end": "1970040"
  },
  {
    "text": "existing code you don't get all the benefits of the libraries or things like show batch won't work because pi torch",
    "start": "1970040",
    "end": "1976340"
  },
  {
    "text": "native doesn't have the same concept of like type sensors and things but gets you some of the way there so as i",
    "start": "1976340",
    "end": "1984020"
  },
  {
    "text": "mentioned and this is the thing I'm most interested in excited about I think for first di2 is this mid layer API because",
    "start": "1984020",
    "end": "1990890"
  },
  {
    "text": "this is something that it's not and at all uncommon in software engineering but it hasn't existed before",
    "start": "1990890",
    "end": "1996860"
  },
  {
    "text": "in the deep learning world and it's a it's basically a refactoring of the",
    "start": "1996860",
    "end": "2006440"
  },
  {
    "text": "pieces that make up those applications so silver who's the person who I wrote",
    "start": "2006440",
    "end": "2012890"
  },
  {
    "text": "this Wiz created this bit about one of the pieces of this mid layer which is",
    "start": "2012890",
    "end": "2019550"
  },
  {
    "text": "the training loop this is what a training loop looks like in PI torch",
    "start": "2019550",
    "end": "2025070"
  },
  {
    "text": "you basically loop through epochs you look through MIDI batches you get your predictions you call your loss function",
    "start": "2025070",
    "end": "2030140"
  },
  {
    "text": "and you do the backward pass to get the gradients and you step your optimizer so you basically do these things right now",
    "start": "2030140",
    "end": "2036920"
  },
  {
    "text": "the problem is that there's lots of tweaks you keep track of metrics you",
    "start": "2036920",
    "end": "2042350"
  },
  {
    "text": "have hyper parameter schedulers there's all kinds of regularization techniques you might want to handle 1/2 precision",
    "start": "2042350",
    "end": "2049429"
  },
  {
    "text": "floating point training you might want to do complex training like generative adversarial networks so either you do",
    "start": "2049430",
    "end": "2056179"
  },
  {
    "text": "what everybody else does which is to write a new training loop from scratch every time or you try and do what I try",
    "start": "2056180",
    "end": "2062720"
  },
  {
    "text": "to do in fast AI 0.7 which is to create one training loop that has everything and that led to my early insanity or you",
    "start": "2062720",
    "end": "2071210"
  },
  {
    "text": "do what we do now which is to add what we call two-way callbacks at every point during training a two-way callback is",
    "start": "2071210",
    "end": "2079010"
  },
  {
    "text": "something where a callback can read everything every bit of state every bit",
    "start": "2079010",
    "end": "2084710"
  },
  {
    "text": "of data every gradient every hyper parameter and can write them all back and can change the control flow so you",
    "start": "2084710",
    "end": "2092419"
  },
  {
    "text": "can you know inject functionality that has access to the world and can change",
    "start": "2092420",
    "end": "2097700"
  },
  {
    "text": "the world so basically you start with a loop that looks like that and you end up with one",
    "start": "2097700",
    "end": "2104480"
  },
  {
    "text": "with the same steps that a whole bunch of call backs and so callbacks end up",
    "start": "2104480",
    "end": "2109490"
  },
  {
    "text": "being these like tiny little pieces of code that do a whole lot of stuff so for example an early stopping callback would",
    "start": "2109490",
    "end": "2117290"
  },
  {
    "text": "define and after a park which would check for some function of the recorded",
    "start": "2117290",
    "end": "2122330"
  },
  {
    "text": "values and it wants to stop we use exceptions or control flow you can raise a canceled fit exception there's also",
    "start": "2122330",
    "end": "2129380"
  },
  {
    "text": "canceled batch canceled validation and so forth",
    "start": "2129380",
    "end": "2134750"
  },
  {
    "text": "or gradient flipping so if you want to avoid activations which are going off to",
    "start": "2134750",
    "end": "2141020"
  },
  {
    "text": "infinity there can be an after backward step which actually modifies the parameters",
    "start": "2141020",
    "end": "2147440"
  },
  {
    "text": "of the model and changes their gradients for instance so it's been amazingly",
    "start": "2147440",
    "end": "2153620"
  },
  {
    "text": "successful basically everything we've tried to add every paper we've implemented every experiment we've done",
    "start": "2153620",
    "end": "2159560"
  },
  {
    "text": "we've been able to do without changing the training loop just by changing callbacks yeah yeah so can you reason",
    "start": "2159560",
    "end": "2181610"
  },
  {
    "text": "about the callback so if you didn't write them yes absolutely the the nice thing is that well for one thing there's",
    "start": "2181610",
    "end": "2188300"
  },
  {
    "text": "great documentation and the the callbacks are they're very they're very",
    "start": "2188300",
    "end": "2197330"
  },
  {
    "text": "easy to reason but reason about because they have very consistent names you know so before that shore after that shore",
    "start": "2197330",
    "end": "2203360"
  },
  {
    "text": "before loss or after loss and the other thing is we we try to write our code in",
    "start": "2203360",
    "end": "2209210"
  },
  {
    "text": "a way that is just super easy to understand what's going on so one of the",
    "start": "2209210",
    "end": "2216470"
  },
  {
    "text": "things is actually that's interesting is all of the entire library is written interpreter notebooks and so we've built",
    "start": "2216470",
    "end": "2222260"
  },
  {
    "text": "this new system called env dev which allows you to kind of do true literate",
    "start": "2222260",
    "end": "2227450"
  },
  {
    "text": "programming so if you if you look at the code in the notebooks it takes you",
    "start": "2227450",
    "end": "2234350"
  },
  {
    "text": "through every step of like what are we doing and here's a link to the paper and here's a picture of it and here's a",
    "start": "2234350",
    "end": "2239450"
  },
  {
    "text": "graph and so forth and then it exports it into standard Python modules which",
    "start": "2239450",
    "end": "2246800"
  },
  {
    "text": "you can then look through in your editor and if you prefer you can edit them in an editor and then synchronize them back",
    "start": "2246800",
    "end": "2252860"
  },
  {
    "text": "to the notebooks so the if you want to know what's going on in the training",
    "start": "2252860",
    "end": "2259910"
  },
  {
    "text": "loop then you know ideally you just use the documentation but if you want to",
    "start": "2259910",
    "end": "2265040"
  },
  {
    "text": "really know what's going on you can actually say okay here is here",
    "start": "2265040",
    "end": "2270510"
  },
  {
    "text": "is the piece that does one batch right and we really try to lay things out so",
    "start": "2270510",
    "end": "2276240"
  },
  {
    "text": "you can see what's going on so you can see here like no Auto code formatting for us right like lay it out in the grid",
    "start": "2276240",
    "end": "2282480"
  },
  {
    "text": "here is the list of each callback that happens in one batch here is a list of",
    "start": "2282480",
    "end": "2287940"
  },
  {
    "text": "each piece of code that happens in one batch book across here is the connection between HP to code and H callback right",
    "start": "2287940",
    "end": "2294960"
  },
  {
    "text": "so you know we try to make it so that you can see what's going on as well and",
    "start": "2294960",
    "end": "2301470"
  },
  {
    "text": "then you can jump into the notebook and see the experiments and the tests and and so forth so yeah we try to make it",
    "start": "2301470",
    "end": "2307560"
  },
  {
    "text": "so that it's everybody can contribute and do their own stuff and of course we",
    "start": "2307560",
    "end": "2313200"
  },
  {
    "text": "have this great community as well where we help and they help each other which works great too so for example here's a",
    "start": "2313200",
    "end": "2321900"
  },
  {
    "text": "really really important regularizer cord mix up mix up is a fantastic data",
    "start": "2321900",
    "end": "2327090"
  },
  {
    "text": "augmentation procedure which takes two images or whatever and basically takes a",
    "start": "2327090",
    "end": "2333450"
  },
  {
    "text": "weighted average of the two images and then takes a weighted average of the two sets of labels and that becomes the data",
    "start": "2333450",
    "end": "2341280"
  },
  {
    "text": "for a model it turns out that with mix up you can use far less data and get far",
    "start": "2341280",
    "end": "2346680"
  },
  {
    "text": "better results and so here's here's the size have mix up a GPU accelerated",
    "start": "2346680",
    "end": "2352530"
  },
  {
    "text": "version of mix up I might add in as a first day a callback and here's the version in the from the research paper",
    "start": "2352530",
    "end": "2359610"
  },
  {
    "text": "right so a few things to note here the first is you know the first day I call",
    "start": "2359610",
    "end": "2365340"
  },
  {
    "text": "back is much shorter and shorter is not just good because it's short but it's good because each line of code that's",
    "start": "2365340",
    "end": "2372240"
  },
  {
    "text": "pretty directly to a line in the paper of the algorithm there's not the",
    "start": "2372240",
    "end": "2377760"
  },
  {
    "text": "boilerplate more importantly the research code only works with one data",
    "start": "2377760",
    "end": "2382980"
  },
  {
    "text": "set so far 10 it only works with one metric it doesn't work with any other",
    "start": "2382980",
    "end": "2390110"
  },
  {
    "text": "regular Iser with any other training tweak and so forth right with callbacks",
    "start": "2390110",
    "end": "2397070"
  },
  {
    "text": "you know you get the nice software engineering principle of like decoupled pieces that can work together another",
    "start": "2397070",
    "end": "2405420"
  },
  {
    "text": "example of this sort of refactoring is optimizers there's been a lot of",
    "start": "2405420",
    "end": "2410660"
  },
  {
    "text": "developments in optimizers in the last 12 to 18 months including people kind of",
    "start": "2410660",
    "end": "2418590"
  },
  {
    "text": "combining optimizers together in interesting ways now the four first day I came along",
    "start": "2418590",
    "end": "2424890"
  },
  {
    "text": "these different optimizers lived in their own worlds there wasn't really this ability to combine them so for",
    "start": "2424890",
    "end": "2432090"
  },
  {
    "text": "example there was a really important paper called decoupled wait okay which developed something called atom W which",
    "start": "2432090",
    "end": "2438360"
  },
  {
    "text": "showed that the way people have been doing probably just about the most popular optimizer chord atom was all",
    "start": "2438360",
    "end": "2444570"
  },
  {
    "text": "wrong though there was you know a pretty minor tweak to the equation it turned",
    "start": "2444570",
    "end": "2450300"
  },
  {
    "text": "out that made it work much better and was like much more mathematically sound in play torch it took a couple of years",
    "start": "2450300",
    "end": "2457080"
  },
  {
    "text": "for atom W to get implemented and this is the basic code and they basically",
    "start": "2457080",
    "end": "2462860"
  },
  {
    "text": "rewrote all of atom plus the one tweak",
    "start": "2462860",
    "end": "2468770"
  },
  {
    "text": "first day I implemented atom W like the day after we noticed the paper and in",
    "start": "2468770",
    "end": "2475650"
  },
  {
    "text": "our case we had to add these four lines of code and this section in gray because",
    "start": "2475650",
    "end": "2482330"
  },
  {
    "text": "we had refactored optimizers so we looked at lots of optimizers and just",
    "start": "2482330",
    "end": "2489530"
  },
  {
    "text": "factored out the the common pieces of code and and ideas and so it turns out",
    "start": "2489530",
    "end": "2495720"
  },
  {
    "text": "that there's two main ideas in an optimizer one is keep track of stuff so",
    "start": "2495720",
    "end": "2501470"
  },
  {
    "text": "the moving average gradients or the moving average gradient squared or the most recent gradients or whatever and",
    "start": "2501470",
    "end": "2508410"
  },
  {
    "text": "then update things in some way so for example add the learning rates times the",
    "start": "2508410",
    "end": "2517680"
  },
  {
    "text": "gradients to the weights that's the most basic SGD update step so we basically",
    "start": "2517680",
    "end": "2523170"
  },
  {
    "text": "provide optimizer callbacks to let you do those two things yourself and to mix and match the",
    "start": "2523170",
    "end": "2530880"
  },
  {
    "text": "existing ones and that's why our students are able to write things like this where they say oh we've taken these",
    "start": "2530880",
    "end": "2537599"
  },
  {
    "text": "things in this paper and these things from this paper and it turns out we end up with something that's better than any",
    "start": "2537599",
    "end": "2542609"
  },
  {
    "text": "paper so it's really cool for kind of identifying interesting research directions and trying things out so like",
    "start": "2542609",
    "end": "2551609"
  },
  {
    "text": "this paper on reducing Burt pre-training time came up with a really nifty",
    "start": "2551609",
    "end": "2556680"
  },
  {
    "text": "optimizer called the lam optimizer this is our implementation of the lam optimizer that we had wrote the day",
    "start": "2556680",
    "end": "2563010"
  },
  {
    "text": "after the paper came out and one of the nice things is that you can compare it directly to the math and it's pretty",
    "start": "2563010",
    "end": "2568980"
  },
  {
    "text": "much line for line the same except the math actually hides some things that",
    "start": "2568980",
    "end": "2574650"
  },
  {
    "text": "aren't in the paper so it actually also makes it more explicit as to what's going on as everybody knows one of the",
    "start": "2574650",
    "end": "2585750"
  },
  {
    "text": "hard parts about any kind of machine learning is getting the data in order and so I used to drive myself a bit",
    "start": "2585750",
    "end": "2594960"
  },
  {
    "text": "crazy with this because I would try to make it easy to get your data in order",
    "start": "2594960",
    "end": "2600119"
  },
  {
    "text": "and so I so Sylvia and I had in first day one dozens of classes for what if",
    "start": "2600119",
    "end": "2608250"
  },
  {
    "text": "your input is images and your output is a single label classification what if it's an import in the multi-label",
    "start": "2608250",
    "end": "2613829"
  },
  {
    "text": "classification what if it's a black-and-white import in a single label classification you know what if you're doing the validation set is just fine",
    "start": "2613829",
    "end": "2621540"
  },
  {
    "text": "based on what folder it's the inverses you want to do a random split and we just ended up with all this code and all",
    "start": "2621540",
    "end": "2627839"
  },
  {
    "text": "this complexity and it was too hard for us and it was too hard for our users and",
    "start": "2627839",
    "end": "2634050"
  },
  {
    "text": "so we kind of stepped back and we thought oh let's refactor all those",
    "start": "2634050",
    "end": "2639480"
  },
  {
    "text": "classes so we realized there was basically a small number of things that",
    "start": "2639480",
    "end": "2645960"
  },
  {
    "text": "you need to tell the the algorithm how to do it and so basically you have to",
    "start": "2645960",
    "end": "2653700"
  },
  {
    "text": "say what are the types of my inputs what are the types of my outputs and one of",
    "start": "2653700",
    "end": "2658829"
  },
  {
    "text": "the nice things is when you refactor it this way you do more interesting things like Siamese networks where there are actually two",
    "start": "2658829",
    "end": "2665099"
  },
  {
    "text": "input images in a boolean output for instance so you don't have to always have one on one or unpaired image",
    "start": "2665099",
    "end": "2674220"
  },
  {
    "text": "translation like cycle gains where there's like two inputs or no output so and again this is where the types come",
    "start": "2674220",
    "end": "2681450"
  },
  {
    "text": "in so we have proper types so we can define what the types are and then you",
    "start": "2681450",
    "end": "2688170"
  },
  {
    "text": "say okay how do you take for example a list of file names and convert them into",
    "start": "2688170",
    "end": "2693599"
  },
  {
    "text": "those types and so there are certain defaults like if the type is an image and it's a file name by default it",
    "start": "2693599",
    "end": "2700710"
  },
  {
    "text": "assumes it would image don't open that file name but you can override those things in any way you like particularly",
    "start": "2700710",
    "end": "2707190"
  },
  {
    "text": "important for labeling right there's a thousand different ways to label things and so you couldn't you know there are",
    "start": "2707190",
    "end": "2713759"
  },
  {
    "text": "regex labelers or there are the parent folder name could be a label ER so we",
    "start": "2713759",
    "end": "2719940"
  },
  {
    "text": "kind of extracted out all the common labelers and also provided some building blocks for doing your own and then okay",
    "start": "2719940",
    "end": "2726450"
  },
  {
    "text": "how do you create your validation set is it random is that the last thousand records is it based on the grandparent",
    "start": "2726450",
    "end": "2733469"
  },
  {
    "text": "folder name again we given some kind of classes that do some of the standard",
    "start": "2733469",
    "end": "2739200"
  },
  {
    "text": "things and let you build your own and then once you've got all these things you then callate the data into mini-batches and",
    "start": "2739200",
    "end": "2746670"
  },
  {
    "text": "there are some certain choices you make like a batch size and stuff like that so we end up with this thing called data",
    "start": "2746670",
    "end": "2752009"
  },
  {
    "text": "block where you say these are my types this is the function that finds the in this case the file names this is the",
    "start": "2752009",
    "end": "2758609"
  },
  {
    "text": "class which splits based in this case based on the grandparent folder name this is my labeling function which is",
    "start": "2758609",
    "end": "2765930"
  },
  {
    "text": "going to do the parent folder name and so this will do the m-most data set",
    "start": "2765930",
    "end": "2771440"
  },
  {
    "text": "there's you know same basic idea with very few changes will do you know here's",
    "start": "2771440",
    "end": "2776670"
  },
  {
    "text": "a regex label for doing pets here's one for doing multi-label classification so",
    "start": "2776670",
    "end": "2783119"
  },
  {
    "text": "we've got an image and a multi category dependent variable we've already seen",
    "start": "2783119",
    "end": "2788430"
  },
  {
    "text": "segmentation so an image input and a mask out port",
    "start": "2788430",
    "end": "2793849"
  },
  {
    "text": "key points you know so now a tensor point is the output object detection so",
    "start": "2794000",
    "end": "2801740"
  },
  {
    "text": "bounding box is the output and so forth so yeah that's the bit which I'm kind of",
    "start": "2801740",
    "end": "2811180"
  },
  {
    "text": "most excited about because it means that researchers you know can or people",
    "start": "2811180",
    "end": "2819470"
  },
  {
    "text": "trying to get more performance or customized things for their organization or whatever can get underneath the",
    "start": "2819470",
    "end": "2825230"
  },
  {
    "text": "surface they don't have to write stuff from scratch but they also have a lot of",
    "start": "2825230",
    "end": "2831500"
  },
  {
    "text": "flexibility so then finally that is",
    "start": "2831500",
    "end": "2837290"
  },
  {
    "text": "built on these kind of foundation layer we've already mentioned object oriented",
    "start": "2837290",
    "end": "2844400"
  },
  {
    "text": "tenses so you can go image dot flip and",
    "start": "2844400",
    "end": "2849890"
  },
  {
    "text": "it flips it regardless of whether it's a pillow image or a tensor image or even",
    "start": "2849890",
    "end": "2855380"
  },
  {
    "text": "it could be a bounding box or it could be a point cloud you know all of these things have a concept of a flip we we",
    "start": "2855380",
    "end": "2864530"
  },
  {
    "text": "try to really take advantage of the fact that python is a dynamic language there's a lot of downsides to Python but",
    "start": "2864530",
    "end": "2871010"
  },
  {
    "text": "python is kind of what we're stuck with for now that's that's where the world of deep learning is so if we're stuck with",
    "start": "2871010",
    "end": "2877340"
  },
  {
    "text": "that we most will make the most of it so a dynamic language like Python lets you",
    "start": "2877340",
    "end": "2882980"
  },
  {
    "text": "define decorators which add functionality to existing classes for example so we've created this patch",
    "start": "2882980",
    "end": "2888620"
  },
  {
    "text": "decorator which will add flip left-right to each of these types so people who",
    "start": "2888620",
    "end": "2895820"
  },
  {
    "text": "have not really used types even though there are type annotations in Python",
    "start": "2895820",
    "end": "2901100"
  },
  {
    "text": "people who haven't really used them that much on the whole so we use them a lot you wish yeah and they're mainly",
    "start": "2901100",
    "end": "2908420"
  },
  {
    "text": "designed for static analysis but actually you know that as you can see here the the basic mechanics are all",
    "start": "2908420",
    "end": "2915950"
  },
  {
    "text": "there that we can use them at runtime in this way and the patch decorator itself",
    "start": "2915950",
    "end": "2922430"
  },
  {
    "text": "is like two lines of code so yeah with that we can kind of have",
    "start": "2922430",
    "end": "2929650"
  },
  {
    "text": "show batch two different things and actually and also this is kind of nice",
    "start": "2929650",
    "end": "2935230"
  },
  {
    "text": "like show results so for example show results we can do things like automatically color code things where",
    "start": "2935230",
    "end": "2941859"
  },
  {
    "text": "the classification is is wrong for instance so one of the things we did to",
    "start": "2941859",
    "end": "2948730"
  },
  {
    "text": "make stuff like this work is we created a new type dispatch system and again",
    "start": "2948730",
    "end": "2954160"
  },
  {
    "text": "Python is this you know wonderfully dynamic language it's got a super great metaclass system which is really",
    "start": "2954160",
    "end": "2960430"
  },
  {
    "text": "underutilized and so we use the metal class system to create the new type dispatch system which allows us to",
    "start": "2960430",
    "end": "2967510"
  },
  {
    "text": "annotate like so and end up with something that kind of feels more like",
    "start": "2967510",
    "end": "2972520"
  },
  {
    "text": "Julia than traditional Python and this is working great for us because it's",
    "start": "2972520",
    "end": "2978940"
  },
  {
    "text": "actually allowed us to do things like this this dispatch system does the kinds",
    "start": "2978940",
    "end": "2984280"
  },
  {
    "text": "of things that machine learning people need so for example we tend to have mini",
    "start": "2984280",
    "end": "2989559"
  },
  {
    "text": "batches with an independent variable independent variable and in hi torch these are represented as triples this",
    "start": "2989559",
    "end": "2996490"
  },
  {
    "text": "type dispatch system when it gets a tuple by default it doesn't look for a",
    "start": "2996490",
    "end": "3003329"
  },
  {
    "text": "tuple type annotation it pulls the triple apart and looks at each component",
    "start": "3003329",
    "end": "3008700"
  },
  {
    "text": "of that tuple that's tight and puts each one a part of the tuple out to separate functions based on the type of spatch",
    "start": "3008700",
    "end": "3015089"
  },
  {
    "text": "system and then pulls them back together again so that means people can create pipelines which we'll see in a moment",
    "start": "3015089",
    "end": "3021089"
  },
  {
    "text": "where those pipelines basically say for example flip and if that's a mini batch",
    "start": "3021089",
    "end": "3027869"
  },
  {
    "text": "containing a point cloud dependent variable and a color image independent",
    "start": "3027869",
    "end": "3034170"
  },
  {
    "text": "variable both of those will be flipped automatically by the type dispatch",
    "start": "3034170",
    "end": "3039240"
  },
  {
    "text": "system so it makes a lot of the code just much simpler much shorter and so",
    "start": "3039240",
    "end": "3047069"
  },
  {
    "text": "this this ends up in this transform pipeline system the idea of pipelines in",
    "start": "3047069",
    "end": "3052770"
  },
  {
    "text": "machine learning data processing goes back a long time a pipeline is just a compact just it's just function",
    "start": "3052770",
    "end": "3060150"
  },
  {
    "text": "composition basically but one of the things that we wanted to do with",
    "start": "3060150",
    "end": "3066470"
  },
  {
    "text": "pipelines so they're really impact lines function composition is very important for data processing because generally to",
    "start": "3066470",
    "end": "3073170"
  },
  {
    "text": "get from like a file name to a normalized image batch of tenses in the",
    "start": "3073170",
    "end": "3078690"
  },
  {
    "text": "right access order there's just steps you take in each one's just a function applied to the",
    "start": "3078690",
    "end": "3083910"
  },
  {
    "text": "previous result the thing is that we wanted to be able to go the other way as well which is to start with so you call a",
    "start": "3083910",
    "end": "3093120"
  },
  {
    "text": "prediction on a model you get back some tensor which represents basically the endpoint of that processing I need to go",
    "start": "3093120",
    "end": "3100380"
  },
  {
    "text": "reverse back through the pipeline to get back you know the image in a form I can see it or the class as a string with the",
    "start": "3100380",
    "end": "3108780"
  },
  {
    "text": "correct name so these pipelines these transforms actually are reversible it's",
    "start": "3108780",
    "end": "3114330"
  },
  {
    "text": "not automatic there's no concept of an inverse function in Python you just write the inverse function each time you",
    "start": "3114330",
    "end": "3121380"
  },
  {
    "text": "want to create an invertible function and then the pipeline will automatically do the composition in in reverse order",
    "start": "3121380",
    "end": "3130700"
  },
  {
    "text": "great so I think five thirty at a time work like okay great oh yes I mean",
    "start": "3130700",
    "end": "3138360"
  },
  {
    "text": "anytime also so sure I'm nearly out of I'm really out of slides anyway but so",
    "start": "3138360",
    "end": "3146930"
  },
  {
    "text": "here's a really great example for us especially for me right I I tried to",
    "start": "3146930",
    "end": "3154260"
  },
  {
    "text": "create a data loader with silver a couple of years ago for fast AI v1 for",
    "start": "3154260",
    "end": "3160860"
  },
  {
    "text": "language modeling language modeling is a really important technique in modern NLP",
    "start": "3160860",
    "end": "3165930"
  },
  {
    "text": "and it's kind of the basis of our LM fit algorithm I described simple idea predict the next word in in a sequence",
    "start": "3165930",
    "end": "3173970"
  },
  {
    "text": "of words and it turns out that if you can predict the next word in a sequence of words that that kind of model learns",
    "start": "3173970",
    "end": "3180510"
  },
  {
    "text": "a lot about not just language but about the world so for example if the sentence is you know some quote you know as said",
    "start": "3180510",
    "end": "3189630"
  },
  {
    "text": "by the forty-fifth the united states president la to finish that you need to not only know about",
    "start": "3189630",
    "end": "3195719"
  },
  {
    "text": "english but about the concept of a president and which country it probably was and who was the president knew the",
    "start": "3195719",
    "end": "3202109"
  },
  {
    "text": "45th president so language models are super important and the creating a data",
    "start": "3202109",
    "end": "3209190"
  },
  {
    "text": "set which kind of has a corpus of text and there's then the same corpus of text",
    "start": "3209190",
    "end": "3214979"
  },
  {
    "text": "offset by one is surprisingly fiddly because you actually have to kind of batch that up and feed it to a GPU a",
    "start": "3214979",
    "end": "3221969"
  },
  {
    "text": "batch at a time in a way that all the batches line up with each other and it doesn't get to cheat by kind of seeing",
    "start": "3221969",
    "end": "3227190"
  },
  {
    "text": "what the next token was and Papapa so in first AI vision one we just had page",
    "start": "3227190",
    "end": "3233130"
  },
  {
    "text": "after page of code which we just couldn't understand or maintain even though we wrote it you know how it is",
    "start": "3233130",
    "end": "3238819"
  },
  {
    "text": "and then fourth version too we were able to throw it all away and just use these",
    "start": "3238819",
    "end": "3245869"
  },
  {
    "text": "these these this pipeline approach these transformations and also again callbacks",
    "start": "3245869",
    "end": "3251940"
  },
  {
    "text": "so our data loader is almost entirely",
    "start": "3251940",
    "end": "3257130"
  },
  {
    "text": "api compatible with the pi torch data loader but it has i think 16 callback",
    "start": "3257130",
    "end": "3263069"
  },
  {
    "text": "points you can hook into where else the pi torch one has you know a small",
    "start": "3263069",
    "end": "3268170"
  },
  {
    "text": "handful and so it just made this code so much simpler easier to read easier to",
    "start": "3268170",
    "end": "3273209"
  },
  {
    "text": "write which is great none of this is really much use unless",
    "start": "3273209",
    "end": "3280739"
  },
  {
    "text": "it's fast there's no point giving people stuff that's that's pretty and concise if it",
    "start": "3280739",
    "end": "3286199"
  },
  {
    "text": "isn't performant enough to be useful so we wrote you know as optimized a",
    "start": "3286199",
    "end": "3291420"
  },
  {
    "text": "foundation for everything as we could so some you know really easy to use parallelization constructs in python and",
    "start": "3291420",
    "end": "3300479"
  },
  {
    "text": "then use those in for example tokenization so tokenizing has traditionally been this really slow",
    "start": "3300479",
    "end": "3306989"
  },
  {
    "text": "thing we can't particularly make it faster but we can make it so that it will automatically paralyze tokenization",
    "start": "3306989",
    "end": "3313709"
  },
  {
    "text": "and you can pick any tokenizer you want so to do this we tend to take a lot of",
    "start": "3313709",
    "end": "3320130"
  },
  {
    "text": "advantage of the lazy generator functionality in Python which makes a lot of this stuff kind of",
    "start": "3320130",
    "end": "3325570"
  },
  {
    "text": "trivially easy unfortunately the the Python has a global interpreter lock",
    "start": "3325570",
    "end": "3331960"
  },
  {
    "text": "which can get in the way but most of the things that we're calling written in C",
    "start": "3331960",
    "end": "3337210"
  },
  {
    "text": "so that doesn't impact things as much as you might expect we've written a new",
    "start": "3337210",
    "end": "3343450"
  },
  {
    "text": "computer vision library which actually runs on the GPU using PI torch and it's",
    "start": "3343450",
    "end": "3351190"
  },
  {
    "text": "really interesting there's a really small number of basic foundational piece pieces that you need in a tensor library",
    "start": "3351190",
    "end": "3357880"
  },
  {
    "text": "to be able to do pretty much anything you want in computer vision so we have this affine coordinate transform which",
    "start": "3357880",
    "end": "3365920"
  },
  {
    "text": "basically takes something called a flow field which is basically says whereabouts should each pixel be moved",
    "start": "3365920",
    "end": "3371410"
  },
  {
    "text": "to and with a flow field you can zoom you can warp you can rotate we use lazy operations so that all of the cordon",
    "start": "3371410",
    "end": "3378490"
  },
  {
    "text": "operations and f-fine transforms operate on the flow field and then there's this really cool thing in patriach called",
    "start": "3378490",
    "end": "3384820"
  },
  {
    "text": "grid sample which takes a flow field and an image and moves the pixels and does",
    "start": "3384820",
    "end": "3391720"
  },
  {
    "text": "the interpolation and padding and so forth so that's been super fun to kind of create this thing entirely in Python",
    "start": "3391720",
    "end": "3399190"
  },
  {
    "text": "where people can write new GPU accelerated computer vision stuff",
    "start": "3399190",
    "end": "3404560"
  },
  {
    "text": "entirely in Python and see exactly what's going on yeah so I think that's",
    "start": "3404560",
    "end": "3410770"
  },
  {
    "text": "that's everything questions please yes so I should mention",
    "start": "3410770",
    "end": "3420400"
  },
  {
    "text": "like we almost entirely only write Python Silva has written a little bit of",
    "start": "3420400",
    "end": "3425770"
  },
  {
    "text": "courtesy plus plus stuff for one particular thing we needed but it's basically all Python as it stands to get",
    "start": "3425770",
    "end": "3434970"
  },
  {
    "text": "decent performance reasonably reliably without too much fuss you pretty much have to use NVIDIA GPUs so so as I say",
    "start": "3434970",
    "end": "3444490"
  },
  {
    "text": "we sit on top of pi torch we desperately hope that other GPU manufacturers will",
    "start": "3444490",
    "end": "3451060"
  },
  {
    "text": "start delivering decent libraries so that that will change but it's happening",
    "start": "3451060",
    "end": "3456640"
  },
  {
    "text": "very slowly",
    "start": "3456640",
    "end": "3458910"
  },
  {
    "text": "yep yep okay so what prompted is to",
    "start": "3462360",
    "end": "3479320"
  },
  {
    "text": "create vision to what would prompt us to create version three is actually a really good question",
    "start": "3479320",
    "end": "3484560"
  },
  {
    "text": "version two is a rewrite from scratch and it was clearly needed because until",
    "start": "3484560",
    "end": "3491830"
  },
  {
    "text": "version two we've always operated under significant time constraints so you know",
    "start": "3491830",
    "end": "3497170"
  },
  {
    "text": "self created time constraints which is generally like we want to have something ready for a course so we never actually",
    "start": "3497170",
    "end": "3505720"
  },
  {
    "text": "shipped a library I would say we were proud of I would say we thought it was better than anybody else's library doing",
    "start": "3505720",
    "end": "3512020"
  },
  {
    "text": "similar stuff but it was nowhere near as good as we thought it should be so we",
    "start": "3512020",
    "end": "3517260"
  },
  {
    "text": "made a conscious decision to to take 18 months off and have no deadlines and",
    "start": "3517260",
    "end": "3525420"
  },
  {
    "text": "start from scratch and build the best of everything we could so that's why we have a new type you know what the new",
    "start": "3525420",
    "end": "3531430"
  },
  {
    "text": "type is batch system and a new transformation pipeline and all this stuff and a new computer vision library",
    "start": "3531430",
    "end": "3536850"
  },
  {
    "text": "because every time we got to a point where we thought like oh this this is",
    "start": "3536850",
    "end": "3542410"
  },
  {
    "text": "not as good as it could be whether we had written it or somebody else we decided to fix it so it's kind of like a",
    "start": "3542410",
    "end": "3548560"
  },
  {
    "text": "pretty key moment for us because we now do feel like this is the best we can",
    "start": "3548560",
    "end": "3555640"
  },
  {
    "text": "create not just in the time but just the best we can create today . and so we've",
    "start": "3555640",
    "end": "3562000"
  },
  {
    "text": "decided to also step back and like write a book about it let me try to write the best book we can",
    "start": "3562000",
    "end": "3567720"
  },
  {
    "text": "and to create now the best course we can so like what would lead to version 3 is",
    "start": "3567720",
    "end": "3574510"
  },
  {
    "text": "a is a great question my hope is that version 3 will be where",
    "start": "3574510",
    "end": "3581590"
  },
  {
    "text": "we really want to get to which is like something that requires little or no code version 3 maybe won't be a library",
    "start": "3581590",
    "end": "3588400"
  },
  {
    "text": "maybe it'll be a GUI application or GUI application with a thin library underneath or something because",
    "start": "3588400",
    "end": "3594310"
  },
  {
    "text": "hopefully we've built this foundation feels like it's kind of should be solid",
    "start": "3594310",
    "end": "3600520"
  },
  {
    "text": "enough that we don't need to pull it apart and start again you know this is so many injection points or callbacks or",
    "start": "3600520",
    "end": "3606910"
  },
  {
    "text": "whatever it feels like it should be extensible it doesn't feel particularly tied to how deep learning is done today",
    "start": "3606910",
    "end": "3612640"
  },
  {
    "text": "but kind of fundamentally to he'll kind of data processing pipelines and modeling has to work sure how is",
    "start": "3612640",
    "end": "3634210"
  },
  {
    "text": "generalized how is generalized really different to changing the bias so the the key reason is batch norm so batch",
    "start": "3634210",
    "end": "3644380"
  },
  {
    "text": "norm will we'll move it to where it",
    "start": "3644380",
    "end": "3651640"
  },
  {
    "text": "wants to and so then the rel you will kick in and then the output of that will",
    "start": "3651640",
    "end": "3657190"
  },
  {
    "text": "have the you know an average you don't want so you you still end up with a",
    "start": "3657190",
    "end": "3667240"
  },
  {
    "text": "nonzero main at the end of each kind of super layer if you like so",
    "start": "3667240",
    "end": "3673660"
  },
  {
    "text": "we saw that in practice having a non zero mean makes it very hard to maintain",
    "start": "3673660",
    "end": "3683050"
  },
  {
    "text": "a unit variance and that's actually the thing you really care about so and I",
    "start": "3683050",
    "end": "3691780"
  },
  {
    "text": "will say it turns out this observation we were not the only ones to make it",
    "start": "3691780",
    "end": "3696790"
  },
  {
    "text": "this idea of centralized values has as",
    "start": "3696790",
    "end": "3702040"
  },
  {
    "text": "appeared elsewhere there's a thing called cell you see elu which is a centralized exponential unit and yeah",
    "start": "3702040",
    "end": "3712840"
  },
  {
    "text": "how much it matters depends a lot like if if you can have batch norm everywhere it's much less of an issue but",
    "start": "3712840",
    "end": "3719440"
  },
  {
    "text": "particularly for something like Aaron n we're batch norms not really not",
    "start": "3719440",
    "end": "3725340"
  },
  {
    "text": "you know or things where you have to have very very small batches so batch",
    "start": "3725340",
    "end": "3732760"
  },
  {
    "text": "nom doesn't really work this kind of really good initialization matters that",
    "start": "3732760",
    "end": "3737860"
  },
  {
    "text": "it's very hard it's not really possible to get really good initialization without a centralized activation",
    "start": "3737860",
    "end": "3744730"
  },
  {
    "text": "function and some of our students have actually found now I don't think any of its published yet but there are combinations of specific units and",
    "start": "3744730",
    "end": "3751620"
  },
  {
    "text": "centralized activation functions that'll that's one of our students trained thousand layer deep networks without",
    "start": "3751620",
    "end": "3757060"
  },
  {
    "text": "batch norm which is pretty cool so we",
    "start": "3757060",
    "end": "3803290"
  },
  {
    "text": "have a peer-reviewed paper in information which you know honestly I",
    "start": "3803290",
    "end": "3811270"
  },
  {
    "text": "mean the reviewers were super helpful but the the help was around wording",
    "start": "3811270",
    "end": "3816280"
  },
  {
    "text": "tweaks little missing citations there was nothing surprising because of the",
    "start": "3816280",
    "end": "3823030"
  },
  {
    "text": "the wider community who's already been pounding on this for a while so we do all of our work entirely in the open and",
    "start": "3823030",
    "end": "3830830"
  },
  {
    "text": "every time we push something significant we tell people about it on the forum no",
    "start": "3830830",
    "end": "3841600"
  },
  {
    "text": "no I know I'm getting there yeah so so as a result of that there is a hardcore",
    "start": "3841600",
    "end": "3849130"
  },
  {
    "text": "group that keep up and I try to help them keep up so for example when fast AI to first kind of got to a point where it",
    "start": "3849130",
    "end": "3855460"
  },
  {
    "text": "could do things I did you know it's 12 hours of video code",
    "start": "3855460",
    "end": "3860589"
  },
  {
    "text": "walkthroughs with a group of people online with me asking me questions and",
    "start": "3860589",
    "end": "3866430"
  },
  {
    "text": "what we found is a lot of people are really interested in AI and a lot of",
    "start": "3866430",
    "end": "3874930"
  },
  {
    "text": "people interested enough that they give up their jobs and spend a year studying it and a lot of those people will turn",
    "start": "3874930",
    "end": "3881109"
  },
  {
    "text": "out to be like super high achieving kinds of people you know people a lot of",
    "start": "3881109",
    "end": "3886509"
  },
  {
    "text": "people who can do that do that because they just sold their company or whatever so we kind of have this really nice",
    "start": "3886509",
    "end": "3891869"
  },
  {
    "text": "hardcore community of people who are you",
    "start": "3891869",
    "end": "3896950"
  },
  {
    "text": "know absolutely trying out every new line of code as we add it telling us",
    "start": "3896950",
    "end": "3902289"
  },
  {
    "text": "about things that don't work building new things so there's a you know and",
    "start": "3902289",
    "end": "3908200"
  },
  {
    "text": "then they form on the community they form these kind of no study groups so there's an audio study group so there's no fast AI audio yet but there is a fast",
    "start": "3908200",
    "end": "3916690"
  },
  {
    "text": "AI dot audio library built by this community of people who know a lot more about audio than I do",
    "start": "3916690",
    "end": "3923140"
  },
  {
    "text": "same with time series there's a nice time series study group who you know who have been creating state-of-the-art",
    "start": "3923140",
    "end": "3929529"
  },
  {
    "text": "results with fast AI with time-series building time series applications it's",
    "start": "3929529",
    "end": "3934839"
  },
  {
    "text": "not you know it's it's a minority of the",
    "start": "3934839",
    "end": "3940299"
  },
  {
    "text": "community which as it should be most of the community are just using it to do stuff I will say this though pi torch is",
    "start": "3940299",
    "end": "3947589"
  },
  {
    "text": "by far by far the most popular library used for research so like it at at just",
    "start": "3947589",
    "end": "3954940"
  },
  {
    "text": "within the last 12 months Europe's it went from tensorflow being like 75% of the publications to pi torch",
    "start": "3954940",
    "end": "3960700"
  },
  {
    "text": "being like 75% of the publications and increasingly you know as fast I to mature was more",
    "start": "3960700",
    "end": "3966759"
  },
  {
    "text": "and more of those researchers are looking to do stuff with the first AI as well and then naturally have a tendency",
    "start": "3966759",
    "end": "3972759"
  },
  {
    "text": "to push deep into the code because they need to try things that haven't been tried before",
    "start": "3972759",
    "end": "3979140"
  },
  {
    "text": "how many people it could be hundreds but but I also know",
    "start": "3980130",
    "end": "3988300"
  },
  {
    "text": "there's a lot more than I know about like sometimes things pop up so like a couple of weeks ago this paper appeared",
    "start": "3988300",
    "end": "3994140"
  },
  {
    "text": "from de Shore research Saudi sure David Shores was one of the top you know",
    "start": "3994140",
    "end": "4000210"
  },
  {
    "text": "billionaire hedge fund guys who founded a research group a few years ago cool",
    "start": "4000210",
    "end": "4005280"
  },
  {
    "text": "okay so so he's now spending his time doing biotech research and I was",
    "start": "4005280",
    "end": "4010800"
  },
  {
    "text": "delighted to find this paper up here where they're using fast AI to to create",
    "start": "4010800",
    "end": "4016740"
  },
  {
    "text": "a state-of-the-art protein analysis system and I only found out about it because one of those people came back to",
    "start": "4016740",
    "end": "4023970"
  },
  {
    "text": "take our most recent course and introduce themselves in the forum and said oh by the way you should check out on your paper you know so I know there's",
    "start": "4023970",
    "end": "4030510"
  },
  {
    "text": "a bigger group another example I know like somebody from not somebody the VP of AI and ml Glasgow SmithKline",
    "start": "4030510",
    "end": "4037290"
  },
  {
    "text": "contacted me last week and said hey everybody who comes to GSK it takes your",
    "start": "4037290",
    "end": "4042540"
  },
  {
    "text": "course your library is integrated into our HPC clusters that's like I had no",
    "start": "4042540",
    "end": "4047790"
  },
  {
    "text": "idea so it's very hard to judge",
    "start": "4047790",
    "end": "4051800"
  },
  {
    "text": "[Applause]",
    "start": "4056920",
    "end": "4060499"
  }
]
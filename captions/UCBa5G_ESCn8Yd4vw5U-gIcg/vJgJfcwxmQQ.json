[
  {
    "text": "foreign thank you very much Allison it's a pleasure to be here yes I've looked up uh to Allison for",
    "start": "10740",
    "end": "18539"
  },
  {
    "text": "um basically my entire adult life and so it's absolutely a dream come true to come here and share my research with all",
    "start": "18539",
    "end": "25080"
  },
  {
    "text": "of you I am the pi and director of the",
    "start": "25080",
    "end": "31679"
  },
  {
    "text": "cognitive optimization relational robotics laboratory at Georgia Tech where we are trying to enable robots to",
    "start": "31679",
    "end": "38820"
  },
  {
    "text": "work in the hands of everyday end users relaxing a lot of the assumptions we",
    "start": "38820",
    "end": "44219"
  },
  {
    "text": "make about those interactions so we can really automate the job of the",
    "start": "44219",
    "end": "49680"
  },
  {
    "text": "roboticists so to get myself out of the end user robot Loop",
    "start": "49680",
    "end": "55739"
  },
  {
    "text": "why might we want to do that here's a graphic we're on the horizontal",
    "start": "55739",
    "end": "61320"
  },
  {
    "text": "axis you're going to see years where we're actually very much towards the far right of this graph",
    "start": "61320",
    "end": "67619"
  },
  {
    "text": "and the vertical axis on the left you're going to see the number of full-time equivalents of registered nurses",
    "start": "67619",
    "end": "74820"
  },
  {
    "text": "and on the right the average age of the population in the United States",
    "start": "74820",
    "end": "80280"
  },
  {
    "text": "unfortunately what we find is that the minimum standards for a government agency hsri Supply requirements for",
    "start": "80280",
    "end": "88140"
  },
  {
    "text": "nursing is outstripping the availability of nurses",
    "start": "88140",
    "end": "93479"
  },
  {
    "text": "that's the minimum standards that's not actually what we really need to take care of everyone if you look at this",
    "start": "93479",
    "end": "99659"
  },
  {
    "text": "graphic for example out of North Carolina we are already approaching this linear",
    "start": "99659",
    "end": "106079"
  },
  {
    "text": "decline that's going to go on in perpetuity unless something changes so",
    "start": "106079",
    "end": "111600"
  },
  {
    "text": "we're going to have a drastically insufficient number of healthcare professionals to take care of our aging",
    "start": "111600",
    "end": "117180"
  },
  {
    "text": "population not only are older people requiring more care intervention",
    "start": "117180",
    "end": "123600"
  },
  {
    "text": "but also that means that there are fewer young people who can also be in the population to take care of them",
    "start": "123600",
    "end": "131459"
  },
  {
    "text": "we are working as a part of the AI caring Institute NSF funded at Georges HACC the program director was is Sonia",
    "start": "131459",
    "end": "138660"
  },
  {
    "text": "chernova and we're working with the cognitive empowerment program at Emory University",
    "start": "138660",
    "end": "144840"
  },
  {
    "text": "to look at how we might be able to use technology deploy robots or smart smart",
    "start": "144840",
    "end": "150360"
  },
  {
    "text": "home technology to enable the individuals with mild cognitive",
    "start": "150360",
    "end": "156780"
  },
  {
    "text": "impairment who ultimately might have dementia to stay in their home as long as",
    "start": "156780",
    "end": "161940"
  },
  {
    "text": "possible to have some autonomy some dignity before they might have to go to an acute",
    "start": "161940",
    "end": "170459"
  },
  {
    "text": "care facility these individuals slowly lose their capabilities and Retreat from society in",
    "start": "170459",
    "end": "177239"
  },
  {
    "text": "a very sad way and we just don't have the resources to take care of them and so our long-term goal is to actually",
    "start": "177239",
    "end": "184440"
  },
  {
    "text": "have these robots be able to be deployed by Care Partners adult children or",
    "start": "184440",
    "end": "190019"
  },
  {
    "text": "spouses who are still fully cognitively intact who could help program these robots to perform everything from taking",
    "start": "190019",
    "end": "195900"
  },
  {
    "text": "out the trash to delivering proper medicine to actually developing models of your behavior so that they could",
    "start": "195900",
    "end": "202440"
  },
  {
    "text": "identify if you might have had a stroke or have some other decline that might",
    "start": "202440",
    "end": "207599"
  },
  {
    "text": "warrant and benefit from medical intervention",
    "start": "207599",
    "end": "211819"
  },
  {
    "text": "the challenges are also in manufacturing with our aging population unfortunately",
    "start": "213959",
    "end": "219180"
  },
  {
    "text": "the US is slipping and our manufacturing output and that our population and the",
    "start": "219180",
    "end": "224519"
  },
  {
    "text": "skill set that we have is not keeping up and we need robotic systems that are",
    "start": "224519",
    "end": "229980"
  },
  {
    "text": "going to enable our work in cyber manufacturing which I recently have a grant on with some of my colleagues at",
    "start": "229980",
    "end": "236220"
  },
  {
    "text": "Georgia Tech and kind of focusing American manufacturing on made to order",
    "start": "236220",
    "end": "241260"
  },
  {
    "text": "custom parts that can be efficiently cheaply made for you unfortunately most",
    "start": "241260",
    "end": "246480"
  },
  {
    "text": "of that work has to be done manually now because it's one-offs but if we can actually have general purpose robotic",
    "start": "246480",
    "end": "252060"
  },
  {
    "text": "systems that can learn and adapt on the fly without needing somebody in C plus plus to come",
    "start": "252060",
    "end": "257519"
  },
  {
    "text": "and rewrite the robot software every time a part changes then maybe we would able to be to realize this kind of",
    "start": "257519",
    "end": "264680"
  },
  {
    "text": "made-to-order cyber manufacturing future so how are we going to do this how are",
    "start": "264680",
    "end": "270060"
  },
  {
    "text": "we going to have robots actually deployed in Mass around the world um are we going to have hand-derived",
    "start": "270060",
    "end": "275520"
  },
  {
    "text": "controllers as one of my colleagues Professor Seth Hutchinson likes to say why don't I just pay one of my grad",
    "start": "275520",
    "end": "281880"
  },
  {
    "text": "students to do it why do you actually need your reinforcement learning algorithms",
    "start": "281880",
    "end": "287340"
  },
  {
    "text": "um well I don't think there's enough grad students to go around solving every problem that robots are going to have in the future",
    "start": "287340",
    "end": "293340"
  },
  {
    "text": "it's also very challenging we've evolved over tens of thousands of years to be",
    "start": "293340",
    "end": "298380"
  },
  {
    "text": "very amazing at performing a great variety of tasks to close a loop between perception decision making and action",
    "start": "298380",
    "end": "304680"
  },
  {
    "text": "and we often find it difficult to articulate that into a program that would enable a robot to work that's why",
    "start": "304680",
    "end": "310800"
  },
  {
    "text": "for example we use deep neural networks for computer vision rather than a decision tree",
    "start": "310800",
    "end": "317180"
  },
  {
    "text": "we could also just think about pure reinforcement learning we have tried that we've tried arm farms",
    "start": "318540",
    "end": "324360"
  },
  {
    "text": "and they have had some impressive successes But ultimately the amount of resources",
    "start": "324360",
    "end": "331380"
  },
  {
    "text": "that you need to invest into reinforcement learning because it's a lack of sample efficiency how long it",
    "start": "331380",
    "end": "337320"
  },
  {
    "text": "takes to learn it and just for a very single task with a very clearly defined and perhaps shaped reward function",
    "start": "337320",
    "end": "343620"
  },
  {
    "text": "that's also not really a scalable approach so I argue we need to bring and",
    "start": "343620",
    "end": "348840"
  },
  {
    "text": "leverage bring the human into Loop Leverage What humans are good at being able to quickly learn adapt create teach",
    "start": "348840",
    "end": "355199"
  },
  {
    "text": "disseminate knowledge and enable the right robot techniques the right formulations of artificial",
    "start": "355199",
    "end": "361500"
  },
  {
    "text": "intelligence and machine learning and explainable AI so that these systems can collaborate with you and you can",
    "start": "361500",
    "end": "367020"
  },
  {
    "text": "customize their behavior for whatever application you need what am I specifically saying when I",
    "start": "367020",
    "end": "373680"
  },
  {
    "text": "talk about learning from humans let's say learning from demonstration lfd is going to take his input a markup",
    "start": "373680",
    "end": "380100"
  },
  {
    "text": "decision process without a known reward function we're going to have a set of states of the world say in a healthcare",
    "start": "380100",
    "end": "387600"
  },
  {
    "text": "environment we can describe the state of the world as where all the patients are and obsectious and Gynecology we can",
    "start": "387600",
    "end": "393120"
  },
  {
    "text": "describe their gestational age how many children they've delivered before if",
    "start": "393120",
    "end": "399360"
  },
  {
    "text": "they've had any kind of anesthetic applied or other medications or comorbidities it's really kind of a pomdy p but we're",
    "start": "399360",
    "end": "407039"
  },
  {
    "text": "going to ignore that for a moment we can have actions if you're a charge nurse and this is at the Brigham and",
    "start": "407039",
    "end": "414360"
  },
  {
    "text": "Women's Hospital in Boston Massachusetts this single charge nurse has to basically be an air traffic controller deciding which of something the order of",
    "start": "414360",
    "end": "421860"
  },
  {
    "text": "30 nurses in scrub techs are going to have to take care of which patients when where and Route everyone through so that",
    "start": "421860",
    "end": "428759"
  },
  {
    "text": "everyone in all the mothers delivering have the right resources at the right time so that nothing goes wrong and she",
    "start": "428759",
    "end": "434759"
  },
  {
    "text": "currently doesn't have any decision support and they're literally using a whiteboard with rows and columns where",
    "start": "434759",
    "end": "439979"
  },
  {
    "text": "people write in the information and update it as you go",
    "start": "439979",
    "end": "445520"
  },
  {
    "text": "so she can make those decisions about uh Resource Management who should take care of what when where and how",
    "start": "446160",
    "end": "453479"
  },
  {
    "text": "and we want to learn from her her policy Pi star that's going to map",
    "start": "453479",
    "end": "459300"
  },
  {
    "text": "the state of the world to the action that she would take for managing these resources in labor delivery and minimize",
    "start": "459300",
    "end": "465060"
  },
  {
    "text": "a measure of Divergence or difference between what the robot would guess the human would do PI of s and then what the",
    "start": "465060",
    "end": "472139"
  },
  {
    "text": "human Pi star of s would do and then whether we take the expectation over the",
    "start": "472139",
    "end": "478680"
  },
  {
    "text": "distribution of States induced by the teacher versus the learner gets us whether we're talking about Behavior",
    "start": "478680",
    "end": "484560"
  },
  {
    "text": "cloning or imitation learning if you're familiar with those Concepts and so and so in my prior work we actually did this",
    "start": "484560",
    "end": "490199"
  },
  {
    "text": "to provide decision support for nurses now why would I want decision support",
    "start": "490199",
    "end": "495660"
  },
  {
    "text": "for nurses well it's an incredibly stressful job and as I'll show you later their decision making is actually",
    "start": "495660",
    "end": "501680"
  },
  {
    "text": "impacted by a workload their decision making might deteriorate and high workload high stress situations",
    "start": "501680",
    "end": "508620"
  },
  {
    "text": "so if you can actually learn from experts in nominal conditions perhaps you could provide decision support for",
    "start": "508620",
    "end": "514440"
  },
  {
    "text": "them or play Devil's Advocate role when things get more stressful there's also a lot of work by Maya matarich that I",
    "start": "514440",
    "end": "520500"
  },
  {
    "text": "would point you to for why we want something embodied ultimately I want this robot to be physically useful as well but in the meantime there's",
    "start": "520500",
    "end": "526860"
  },
  {
    "text": "actually a lot of cognitive benefits and the psychosocial aspects of trust Reliance and compliance on this",
    "start": "526860",
    "end": "532980"
  },
  {
    "text": "technology that can be that we can modulate through an actual embodied an anthropomorphic form",
    "start": "532980",
    "end": "540000"
  },
  {
    "text": "so why should all researchers care about learning from demonstration let's just do it RL",
    "start": "540000",
    "end": "546060"
  },
  {
    "text": "well first many great feats of reinforcement learning are precipitated because of learning from humans the",
    "start": "546060",
    "end": "551100"
  },
  {
    "text": "original alphago relied on a backbone of supervised learning to get it to work and there's actually one sentence in",
    "start": "551100",
    "end": "556980"
  },
  {
    "text": "that paper if you go and read it that says why this might be the case that human we needed to use a human",
    "start": "556980",
    "end": "562019"
  },
  {
    "text": "supervised learning model as the backbone instead of our early said maybe something about humans can explore the",
    "start": "562019",
    "end": "567120"
  },
  {
    "text": "space better it's just like one sentence on it um of course they had RL built on top of",
    "start": "567120",
    "end": "572940"
  },
  {
    "text": "it and then ultimately they solved it without the need of humans um recently there's gato that came out",
    "start": "572940",
    "end": "578940"
  },
  {
    "text": "as pure supervised learning maybe in a few years once we've now kind of figured out how to do this with imitation",
    "start": "578940",
    "end": "584220"
  },
  {
    "text": "learning maybe one day we'll figure out how to do it with RL from scratch",
    "start": "584220",
    "end": "589260"
  },
  {
    "text": "second lfd can be used to distill engineering controllers for bootstrapping RL so Byron boots panels",
    "start": "589260",
    "end": "595320"
  },
  {
    "text": "Co trust and evangelist theodoro have been doing a lot of work where you can actually design NPC controllers or other",
    "start": "595320",
    "end": "603180"
  },
  {
    "text": "mechanisms from from control theory and actually have a neural network imitate the controller and then do RL on top of",
    "start": "603180",
    "end": "610740"
  },
  {
    "text": "that to exceed the ability of the engineer to hand specify a controller it's pretty cool idea",
    "start": "610740",
    "end": "616800"
  },
  {
    "text": "and then thirdly work um with Peter Beale on contragon has",
    "start": "616800",
    "end": "622680"
  },
  {
    "text": "looked at say digital cooking environments in",
    "start": "622680",
    "end": "628019"
  },
  {
    "text": "which a human and an AI would work together to coordinate activities to bake items",
    "start": "628019",
    "end": "633959"
  },
  {
    "text": "and you can actually think about the challenge that would be to train an RL agent from scratch with a human I don't",
    "start": "633959",
    "end": "641339"
  },
  {
    "text": "know if anyone in this room would live long enough to provide all the samples needed for an RL agent to learn",
    "start": "641339",
    "end": "646740"
  },
  {
    "text": "something complicated but what if you could have two people playing together and you could learn with imitation",
    "start": "646740",
    "end": "652740"
  },
  {
    "text": "learning a model of that human and used in basically in a dream state offline of",
    "start": "652740",
    "end": "658440"
  },
  {
    "text": "an RL agent work an infinite amount of time with that model of a human and then",
    "start": "658440",
    "end": "663720"
  },
  {
    "text": "be able to deploy that RL agents in the real world they've shown some promise for that",
    "start": "663720",
    "end": "670019"
  },
  {
    "text": "and why not because humans are amazing we should want to learn from them we can jump from space we can separate",
    "start": "670019",
    "end": "676019"
  },
  {
    "text": "conjoined twins without ever having done that before that specific case of",
    "start": "676019",
    "end": "681300"
  },
  {
    "text": "conjoined twins and we can fly like Iron Man almost but humans also have failings we have",
    "start": "681300",
    "end": "688620"
  },
  {
    "text": "biases so this video is not fake but you've probably never seen it before",
    "start": "688620",
    "end": "695779"
  },
  {
    "text": "and this is not just people trying to make fun of astronauts or create a hoax for the moon landing the moon landing",
    "start": "695779",
    "end": "701820"
  },
  {
    "text": "really did happen I was there um so you have a Gravity Sensor in your",
    "start": "701820",
    "end": "708180"
  },
  {
    "text": "head the otolith organs will tell you where down is it can actually get messed up when you are in high G situations it",
    "start": "708180",
    "end": "715200"
  },
  {
    "text": "used to be that Pilots launching off of aircraft carriers would when they're",
    "start": "715200",
    "end": "720779"
  },
  {
    "text": "thrown back from the g-forces their otolith organ would slide to the back of their head and they would think that",
    "start": "720779",
    "end": "725820"
  },
  {
    "text": "they're looking up and the right off they go to the carrier they pitch the nose down and fly right into the ocean",
    "start": "725820",
    "end": "731760"
  },
  {
    "text": "so they had to change the rules and you'll see videos of the Pilots Holding On To A handlebar up in their cockpit",
    "start": "731760",
    "end": "738240"
  },
  {
    "text": "they're not allowed to touch their joystick until they actually get airborne because of that and when you're",
    "start": "738240",
    "end": "743459"
  },
  {
    "text": "on the moon the gravity is so small your otolith organ doesn't work right so you're only working on your visual",
    "start": "743459",
    "end": "749339"
  },
  {
    "text": "system and if you're walking on the side of a hill your eyes tell your brain that",
    "start": "749339",
    "end": "755459"
  },
  {
    "text": "you are sideways and you need to orient yourself perpendicular to the surface of the hill and then there's just enough",
    "start": "755459",
    "end": "761040"
  },
  {
    "text": "gravity that you will fall over and your brain can't figure it out so it's pretty funny but we still went to",
    "start": "761040",
    "end": "767339"
  },
  {
    "text": "the moon and the astronauts still figured out how to get around enough I think they even maybe hit a golf ball",
    "start": "767339",
    "end": "773040"
  },
  {
    "text": "so there are these limitations physically there's also cognitive biases that we",
    "start": "773040",
    "end": "779940"
  },
  {
    "text": "have um many of us have probably experienced that algorithm or that paper we just",
    "start": "779940",
    "end": "785160"
  },
  {
    "text": "can't figure out and it's a sunken cost fallacy but we just we have to get it to work there's no way I spent this much",
    "start": "785160",
    "end": "791399"
  },
  {
    "text": "time on this paper to fail there's confirmation bias that we often",
    "start": "791399",
    "end": "797459"
  },
  {
    "text": "experience when we want to try to see if we're right or wrong about an idea that we have and these operation you know I",
    "start": "797459",
    "end": "805139"
  },
  {
    "text": "know that Professor dorsa city has also looked at these issues that bounded",
    "start": "805139",
    "end": "810360"
  },
  {
    "text": "rationality that limit and actually benefit us in living in this world",
    "start": "810360",
    "end": "818160"
  },
  {
    "text": "but I think a lot of machine learning researchers want to just think of humans as spherical just like physicists joke",
    "start": "818160",
    "end": "825420"
  },
  {
    "text": "about the spherical cow and I'd also say that a lot of people perhaps in the machine Learning",
    "start": "825420",
    "end": "831600"
  },
  {
    "text": "Community because we need so many samples for these models to work we're just going to farm it out on mturk or",
    "start": "831600",
    "end": "838079"
  },
  {
    "text": "prolific which we do that research too because we need lots of data but I think we forget that humans aren't",
    "start": "838079",
    "end": "844680"
  },
  {
    "text": "just these soulless mindless automata or in this case necrons if anyone knows",
    "start": "844680",
    "end": "850800"
  },
  {
    "text": "what this is come talk to me afterwards um yes good",
    "start": "850800",
    "end": "857220"
  },
  {
    "text": "they sold their souls to be able to you know do well",
    "start": "857220",
    "end": "863040"
  },
  {
    "text": "so we're not this and when researchers treat us like that",
    "start": "863040",
    "end": "868920"
  },
  {
    "text": "this is what happens you end up with a guy wanting to watch Winnie the Pooh and his Tesla and not",
    "start": "868920",
    "end": "874800"
  },
  {
    "text": "pay attention and he dies you have aircraft autopilot systems that",
    "start": "874800",
    "end": "880079"
  },
  {
    "text": "are so complex and unfortunately brittle and misunderstand the state of the world that people die",
    "start": "880079",
    "end": "887040"
  },
  {
    "text": "we have NASA rover planners who still reject the decision-making of autonomous",
    "start": "887040",
    "end": "892260"
  },
  {
    "text": "planners when it comes to science activities on Mars they will allow these systems to kind of have fun when nothing",
    "start": "892260",
    "end": "899220"
  },
  {
    "text": "matters but when you actually need to drive up to a science Target and do real science on Mars that's still done by",
    "start": "899220",
    "end": "904560"
  },
  {
    "text": "humans and then surgeons are notorious for rejecting systems developed by Engineers",
    "start": "904560",
    "end": "910199"
  },
  {
    "text": "who are trying to help but we end up solving the wrong problems and I argue that autonomy fails to live up to its",
    "start": "910199",
    "end": "916320"
  },
  {
    "text": "potential because researchers fail to understand the human and human autonomy interaction",
    "start": "916320",
    "end": "921839"
  },
  {
    "text": "so in my vision I want robots to be able to deployed in this case we did work with Boeing for manufacturing their",
    "start": "921839",
    "end": "927180"
  },
  {
    "text": "triple seven and National Security environments in healthcare and in exploring space I want us to have an",
    "start": "927180",
    "end": "933420"
  },
  {
    "text": "R2D2 there's no roboticist there fixing the Ross node in the back end there Luke and",
    "start": "933420",
    "end": "939720"
  },
  {
    "text": "R2D2 are working together they understand each other they develop shared mental models can anticipate each other's needs and not have to",
    "start": "939720",
    "end": "946500"
  },
  {
    "text": "communicate everything to each other so we're going to do this in my lab by first giving robots insights into human",
    "start": "946500",
    "end": "952560"
  },
  {
    "text": "decision making through learning from demonstration and human subject experiments we're going to then close that Loop through explainable artificial",
    "start": "952560",
    "end": "959399"
  },
  {
    "text": "intelligence to enable humans to understand what the robot has learned or and even teach the human how to be a",
    "start": "959399",
    "end": "965699"
  },
  {
    "text": "better teacher of robots and then we want to scale it up to coordinate a reasoning of heterogeneous",
    "start": "965699",
    "end": "972300"
  },
  {
    "text": "teams of humans and machines because not all humans are alike we need to account for the",
    "start": "972300",
    "end": "978019"
  },
  {
    "text": "inherent weaknesses and strengths of each individual member of a team I'm going to focus today on the closed loop",
    "start": "978019",
    "end": "984360"
  },
  {
    "text": "though and think about why again do we need imitation learning why can't I just ask",
    "start": "984360",
    "end": "990899"
  },
  {
    "text": "an expert how do you be an amazing fighter pilot I'm going to write all that down and then put in a drone and",
    "start": "990899",
    "end": "996899"
  },
  {
    "text": "then I have my fighter pilot in a box that doesn't work because experts can give you what they think but not how",
    "start": "996899",
    "end": "1002660"
  },
  {
    "text": "they think about it and actually the worst thing you could ever do to an expert while they're doing something is",
    "start": "1002660",
    "end": "1007699"
  },
  {
    "text": "ask them how are you doing what you're doing so if you're ever going to do a tandem jump and the person's doing their",
    "start": "1007699",
    "end": "1014180"
  },
  {
    "text": "checklist to keep you safe don't interrupt them there was a a really good article by",
    "start": "1014180",
    "end": "1020600"
  },
  {
    "text": "Bella chatal in 2008 I looked at expert chess players set them up to win a",
    "start": "1020600",
    "end": "1025760"
  },
  {
    "text": "Checkmate in a three move sequence but they changed something about the board said that three move sequence wouldn't work anymore",
    "start": "1025760",
    "end": "1031579"
  },
  {
    "text": "and you need to find a four or five move sequence and they said find it and think out loud as you're doing it the experts",
    "start": "1031579",
    "end": "1038240"
  },
  {
    "text": "would say that I'm searching for novel options all across the board but if you",
    "start": "1038240",
    "end": "1043400"
  },
  {
    "text": "actually watch their eyes their eyes were looking at the same three move sequence over and over again",
    "start": "1043400",
    "end": "1050780"
  },
  {
    "text": "there was a disconnect between what they thought they were doing and what they were actually doing",
    "start": "1050780",
    "end": "1056240"
  },
  {
    "text": "there's also the Einstein effect it's roughly German for habit that experts part of what makes you good is that you",
    "start": "1056240",
    "end": "1061940"
  },
  {
    "text": "commit to muscle memory and habituate your decision making and you have a hard",
    "start": "1061940",
    "end": "1066980"
  },
  {
    "text": "time thinking outside of the box so I've seen this firsthand and and",
    "start": "1066980",
    "end": "1073400"
  },
  {
    "text": "decision making of nurses working with Julie Schott MIT Neil Shaw and Tony Golan the Beth Israel Deaconess Medical",
    "start": "1073400",
    "end": "1079940"
  },
  {
    "text": "Center and our work to playing a robot there the nurses decision making is a function of patience the number of",
    "start": "1079940",
    "end": "1086240"
  },
  {
    "text": "patients in the the labor and delivery floor at least in our gaming environment we didn't actually close the loop on",
    "start": "1086240",
    "end": "1092000"
  },
  {
    "text": "robot we didn't execute the robot actions in the Real Environment we just offered suggestions so we developed a",
    "start": "1092000",
    "end": "1097460"
  },
  {
    "text": "game to explore this and that for every additional patient in awaiting religious progression showed us that we had a 47",
    "start": "1097460",
    "end": "1103520"
  },
  {
    "text": "increased chance of a nurse recommending that a patient a mother of an expecting mother go out for dinner and come back",
    "start": "1103520",
    "end": "1110059"
  },
  {
    "text": "later um that's an okay thing because it's not fun to hang out in hospital forever but",
    "start": "1110059",
    "end": "1116780"
  },
  {
    "text": "should that really be a function of the nurse's workload maybe not",
    "start": "1116780",
    "end": "1122179"
  },
  {
    "text": "more frankly it's clear that increasing workload on labor and delivery x-axis the number of patients in the waiting",
    "start": "1122179",
    "end": "1128360"
  },
  {
    "text": "room that the nurse has to triage results in increased delays for patients transferring off the waiting room",
    "start": "1128360",
    "end": "1134179"
  },
  {
    "text": "transferring off the floor starting their C-section and getting triaged",
    "start": "1134179",
    "end": "1140000"
  },
  {
    "text": "and so we can't just think of humans as as these spherical cows that are invariant to everything",
    "start": "1140000",
    "end": "1146000"
  },
  {
    "text": "humans do often provide sub-optimal demonstrations adopting heuristics because of the complexities of life",
    "start": "1146000",
    "end": "1152000"
  },
  {
    "text": "and much of lfd work still makes strong assumptions on the demonstration optimality that humans are always giving",
    "start": "1152000",
    "end": "1159020"
  },
  {
    "text": "you the perfect State action pair that the robot just needs to imitate and there's been a lot of great work and",
    "start": "1159020",
    "end": "1165679"
  },
  {
    "text": "preference-based reinforcement learning I'd say that dorsa is probably the the",
    "start": "1165679",
    "end": "1170960"
  },
  {
    "text": "world leader in that topic at the moment um and so it's awesome to be here and and",
    "start": "1170960",
    "end": "1177200"
  },
  {
    "text": "also scary to say this in front of you requires soliciting an abundance of",
    "start": "1177200",
    "end": "1182600"
  },
  {
    "text": "human preferences over trajectories a high cost and there's an error prone process although dorsal work has done a",
    "start": "1182600",
    "end": "1188600"
  },
  {
    "text": "lot to make that much more sample efficient as well and so I'm going to introduce something",
    "start": "1188600",
    "end": "1194480"
  },
  {
    "text": "called the noise performance relationship which came out of Scott nikum and Daniel Brown working together on something called T-Rex yes like the",
    "start": "1194480",
    "end": "1201799"
  },
  {
    "text": "dinosaur and let's look at the half cheetah domain it's a 2d plane where this half cheetah thing tries to run as fast as",
    "start": "1201799",
    "end": "1208700"
  },
  {
    "text": "possible let's add so mix to the robot's policy Pi some amount Ada of noise to all of",
    "start": "1208700",
    "end": "1217100"
  },
  {
    "text": "its joints so it kind of Shakes as it moves and with this uniform distribution and so we're going to have a state",
    "start": "1217100",
    "end": "1223760"
  },
  {
    "text": "action trajectory with some noise added to that Tuple",
    "start": "1223760",
    "end": "1228799"
  },
  {
    "text": "and the more noise we add the worse the OS Behavior gets but how much worse is",
    "start": "1228799",
    "end": "1234500"
  },
  {
    "text": "it actually getting well because there's a built-in reward function for this we can actually",
    "start": "1234500",
    "end": "1240440"
  },
  {
    "text": "compute that reward get an actual number for it and then plot it on this axis and",
    "start": "1240440",
    "end": "1245720"
  },
  {
    "text": "see that it's something like the right hand side of a sigmoid maybe it's an exponential decay",
    "start": "1245720",
    "end": "1251179"
  },
  {
    "text": "well what's interesting is that if we could figure out the relationship between the amount of noise that we add",
    "start": "1251179",
    "end": "1256820"
  },
  {
    "text": "to a robot's execution of a policy if that's our Behavior cloning version of",
    "start": "1256820",
    "end": "1261860"
  },
  {
    "text": "what we learn from a human or somewhere along here then maybe we could extrapolate what negative noise kind of",
    "start": "1261860",
    "end": "1268039"
  },
  {
    "text": "might look like even though that doesn't really make any sense that's kind of what we're going to do and so prior work",
    "start": "1268039",
    "end": "1273620"
  },
  {
    "text": "uh d-rex looked at automatically generating rank trajectories through this noise",
    "start": "1273620",
    "end": "1280400"
  },
  {
    "text": "performance relationship so first doing imitation learning and then adding doing rollouts and adding increasing amounts",
    "start": "1280400",
    "end": "1286580"
  },
  {
    "text": "of noise and then using a loose Shepherd rule to end up figuring out how to I you",
    "start": "1286580",
    "end": "1292220"
  },
  {
    "text": "know figure out some interval ranking or ordinal ranking to these trajectories there's a couple of drawbacks that use",
    "start": "1292220",
    "end": "1297799"
  },
  {
    "text": "Behavior cloning which does suffer from covariate shift and although it is a very highly practical",
    "start": "1297799",
    "end": "1306039"
  },
  {
    "text": "mode of learning where it's just it simply supervised learning so we learn a policy to map states to actions and I",
    "start": "1306039",
    "end": "1311659"
  },
  {
    "text": "think I heard from somebody that we're now going to have a paper maybe already exist called all you need is behavior cloning uh there's like all you need is",
    "start": "1311659",
    "end": "1318919"
  },
  {
    "text": "diversity all you need is attention maybe there's all you need is behavior cloning the other issue is that the Lou Shepard",
    "start": "1318919",
    "end": "1325460"
  },
  {
    "text": "rule also is not quite adaptive to the individual domain or task that you're",
    "start": "1325460",
    "end": "1332059"
  },
  {
    "text": "trying to learn and that if you set it up with three specific trajectories and you try to figure out what the reward",
    "start": "1332059",
    "end": "1337820"
  },
  {
    "text": "would be you would find that it should be like the geometric mean of the two around it in this case and so it's",
    "start": "1337820",
    "end": "1343340"
  },
  {
    "text": "generally homogeneous across the tasks and so we want to learn some way to characterize this noise performance",
    "start": "1343340",
    "end": "1349640"
  },
  {
    "text": "relationship that is responsive to the specific algorithm that's being learned learning on in the task at hand and so",
    "start": "1349640",
    "end": "1356000"
  },
  {
    "text": "we tried to characterize this in a coral paper this was by one of my students late Tian Chen we looked at a number of",
    "start": "1356000",
    "end": "1361100"
  },
  {
    "text": "open AI gym environments Mountain car pendulum Etc and on the x-axis the",
    "start": "1361100",
    "end": "1366559"
  },
  {
    "text": "amount of noise you have and the y-axis is a normalized amount of the reward that you would accrue when you have an",
    "start": "1366559",
    "end": "1372980"
  },
  {
    "text": "a2c reinforcement learning algorithm trained to optimality and we're just going to degrade it and see how much",
    "start": "1372980",
    "end": "1378200"
  },
  {
    "text": "worse it gets as you add noise to the rollouts we'll do this for PPO and software director critic and we found",
    "start": "1378200",
    "end": "1384799"
  },
  {
    "text": "that it's not homogeneous there's actually it's a function of the RL algorithm so the style of the execution",
    "start": "1384799",
    "end": "1391960"
  },
  {
    "text": "and also the specific task at hand and if you fit the Lou Shepard rule it",
    "start": "1391960",
    "end": "1397039"
  },
  {
    "text": "doesn't have the capacity to to appreciate this and so instead if you fit a sigmoid to",
    "start": "1397039",
    "end": "1404000"
  },
  {
    "text": "the actual data points you can capture a lot of you can explain a lot of the variance with just a few parameters of",
    "start": "1404000",
    "end": "1409400"
  },
  {
    "text": "the sigmoid so that's what we're going to exploit so we're going to start with an adversarial inverse reinforcement learning setup we're going to take",
    "start": "1409400",
    "end": "1415340"
  },
  {
    "text": "demonstrations from the human a set of trajectories which are a sequence of State action pairs for how a robot is",
    "start": "1415340",
    "end": "1421280"
  },
  {
    "text": "going to perform the Tasker in this case the human's doing it and then we're going to try to learn a policy that takes the same States from those demos",
    "start": "1421280",
    "end": "1428059"
  },
  {
    "text": "or its own States predicts the action the human would take and then we're going to compare the synthetic action",
    "start": "1428059",
    "end": "1434659"
  },
  {
    "text": "versus the real action through a discriminator that has within it um an estimate of the reward function",
    "start": "1434659",
    "end": "1440780"
  },
  {
    "text": "that it learns to predict if it's coming from the human real or if it's coming",
    "start": "1440780",
    "end": "1445940"
  },
  {
    "text": "from the robot fake once we've learned the reward function we can extract the reward function out",
    "start": "1445940",
    "end": "1452360"
  },
  {
    "text": "of the discriminator itself and we get the policy we now have this should now",
    "start": "1452360",
    "end": "1457880"
  },
  {
    "text": "be able to pair it what the human did and this should be able to guess how good it was",
    "start": "1457880",
    "end": "1464120"
  },
  {
    "text": "as a function of the trajectory of the specific rollout and so we're going to add noise to a number of rollouts of",
    "start": "1464120",
    "end": "1470600"
  },
  {
    "text": "this policy we have to pair at the person thinking that the more noise we add it should get worse and then we're",
    "start": "1470600",
    "end": "1476120"
  },
  {
    "text": "going to get the reward function we learned to give us an initial guess for what the the quality of that",
    "start": "1476120",
    "end": "1481220"
  },
  {
    "text": "demonstration the robot's Behavior was when you add a certain amount of noise to it",
    "start": "1481220",
    "end": "1486440"
  },
  {
    "text": "that will give us the scatter plot we'll then regress in a sigmoid function to it and then we're going to go back and",
    "start": "1486440",
    "end": "1493940"
  },
  {
    "text": "force the reward function to then fit the sigmoid so the sigmoid here is basically going to act like a low pass",
    "start": "1493940",
    "end": "1499880"
  },
  {
    "text": "filter or a way to help us distill something that generalizes the reward function better from the person so we",
    "start": "1499880",
    "end": "1507020"
  },
  {
    "text": "can ask the robot what is better than what the human showed with ever without ever having to ask the human what is",
    "start": "1507020",
    "end": "1513799"
  },
  {
    "text": "better we also try to improve the robustness of our initial reward that we're learning",
    "start": "1513799",
    "end": "1519500"
  },
  {
    "text": "because we're adding all of these noisy trajectories those are very different than what the human demonstrated and if",
    "start": "1519500",
    "end": "1525020"
  },
  {
    "text": "we overfit or discriminator or reward function to think about these noisy trajectories that might induce this",
    "start": "1525020",
    "end": "1532059"
  },
  {
    "text": "misalignment of what we actually care about and so we're going to do this kind",
    "start": "1532059",
    "end": "1537980"
  },
  {
    "text": "of importance resampling where we kind of flip the importance of the likelihood",
    "start": "1537980",
    "end": "1544159"
  },
  {
    "text": "that the human took it measure that relative to the likelihood that will get it from a noisy policy to make sure that",
    "start": "1544159",
    "end": "1550100"
  },
  {
    "text": "we have the expectation over over what we care about We compare this to d-rex so the full",
    "start": "1550100",
    "end": "1558140"
  },
  {
    "text": "d-rex algorithm is on the far right using Behavior cloning with the Lou Shepard rule for Learning and then we",
    "start": "1558140",
    "end": "1564440"
  },
  {
    "text": "use noisy ARL with self-supervised reward regression and across a number of simulated domains we are able to find a",
    "start": "1564440",
    "end": "1570860"
  },
  {
    "text": "high correlation between the ground truth reward function which the environment has built in and then what we are able to infer and that both as an",
    "start": "1570860",
    "end": "1578840"
  },
  {
    "text": "ablation the noisy a IRL component does better in airl which does better than Behavior cloning and this is the reward",
    "start": "1578840",
    "end": "1585320"
  },
  {
    "text": "function that we learned and that you can see in blue here those are the synthetic trajectories that",
    "start": "1585320",
    "end": "1591740"
  },
  {
    "text": "we're able to learn from that we create blue or hold out data points that are testing and then red is the single",
    "start": "1591740",
    "end": "1597620"
  },
  {
    "text": "example that we learn from the person and so we're able to improve over prior work particularly in that change from",
    "start": "1597620",
    "end": "1604340"
  },
  {
    "text": "the blue to the green dots for for generalization and then if you have the reward function",
    "start": "1604340",
    "end": "1611240"
  },
  {
    "text": "now we can actually synthesize a controller a reinforcement learning controller against that to outperform",
    "start": "1611240",
    "end": "1617059"
  },
  {
    "text": "the initial demonstration quality that we got",
    "start": "1617059",
    "end": "1622000"
  },
  {
    "text": "we deployed this in a table tennis because it's fun and it's easier than",
    "start": "1622220",
    "end": "1627980"
  },
  {
    "text": "real tennis and we looked at metrics for our demonstration of the the lateral speed",
    "start": "1627980",
    "end": "1633559"
  },
  {
    "text": "how far the ball how fast the ball is moving down this way how fast this would be falling after it goes down the net which is a proxy for topspin and then",
    "start": "1633559",
    "end": "1641480"
  },
  {
    "text": "the estimated reward we get from self-supervised reward regression and",
    "start": "1641480",
    "end": "1646820"
  },
  {
    "text": "then we compare that to ARL which should basically just mimic what the person did and then self-simprovise reward",
    "start": "1646820",
    "end": "1652400"
  },
  {
    "text": "regression was able to learn to hit the ball faster with more spin without ever having to ask in this case Rohan palacea",
    "start": "1652400",
    "end": "1658820"
  },
  {
    "text": "how to what better was it automatically figured that out so that's really exciting for us I'll note that I have a",
    "start": "1658820",
    "end": "1665779"
  },
  {
    "text": "rule in my lab that all the students should be wearing shoes he's not I don't condone uh being Barefoot around",
    "start": "1665779",
    "end": "1673220"
  },
  {
    "text": "robots but maybe Sawyer is not so bad",
    "start": "1673220",
    "end": "1678460"
  },
  {
    "text": "all right we can do more though to characterize specifically an individual person's",
    "start": "1679039",
    "end": "1686000"
  },
  {
    "text": "sub-optimality and there's another flavor of learning from demonstration algorithms known as dagger which has you",
    "start": "1686000",
    "end": "1693620"
  },
  {
    "text": "teach the robot while the robot is trying to perform the task so we're going to imagine a car driving",
    "start": "1693620",
    "end": "1699500"
  },
  {
    "text": "itself and you're sitting in the past in the front driver's seat and you're trying to steer the robot to go in the",
    "start": "1699500",
    "end": "1705919"
  },
  {
    "text": "right direction but the robot basically ignores you until after it's over and then it learns from all the feedback that you gave it as you're trying to",
    "start": "1705919",
    "end": "1712820"
  },
  {
    "text": "fight it that's kind of a difficult way to learn from and so researchers have said you know Behavior cloning is all",
    "start": "1712820",
    "end": "1718580"
  },
  {
    "text": "you need maybe it's easier but dagger is really nice because it kind of gets up alleviates this covariate shift issue",
    "start": "1718580",
    "end": "1725659"
  },
  {
    "text": "and has more nice statistical properties for for that learning so you're basically learning from uh you're",
    "start": "1725659",
    "end": "1731960"
  },
  {
    "text": "learning Corrections from mistakes uh which which is a kind of a nice mathematical framework but it doesn't",
    "start": "1731960",
    "end": "1737419"
  },
  {
    "text": "really set up people well to provide the demonstrations so people are sub-optimal here well what",
    "start": "1737419",
    "end": "1744080"
  },
  {
    "text": "if we could characterize how the person is suboptimal and then add that whatever",
    "start": "1744080",
    "end": "1749900"
  },
  {
    "text": "that error is in this case perhaps the person over or under corrects or is",
    "start": "1749900",
    "end": "1755539"
  },
  {
    "text": "anticipatory or delayed in their feedback while they're trying to steer the car to teach the car how to drive through an obstacle course",
    "start": "1755539",
    "end": "1762020"
  },
  {
    "text": "if we can characterize how they're wrong then maybe we can fix that on their demonstrations for a new task and then",
    "start": "1762020",
    "end": "1768740"
  },
  {
    "text": "better provide training data for dagger to learn the desired task and so if we assume we have a set of calibration",
    "start": "1768740",
    "end": "1774919"
  },
  {
    "text": "tasks we have the ground truth optimal trajectory where the robot should go",
    "start": "1774919",
    "end": "1780320"
  },
  {
    "text": "we can then have the person give their corrective feedback for the robot sub-optimally performing that task as",
    "start": "1780320",
    "end": "1786200"
  },
  {
    "text": "though it's still trying to learn we can measure how off the person is from what the optimal feedback should have been",
    "start": "1786200",
    "end": "1792399"
  },
  {
    "text": "within uh we use variational inference for for Mutual information maximization",
    "start": "1792399",
    "end": "1797659"
  },
  {
    "text": "between an embedding and the person's actions to to capture that kind of",
    "start": "1797659",
    "end": "1803299"
  },
  {
    "text": "characterization of the person's sub-optimality and we developed an approach mind meld I'm a huge Star Trek",
    "start": "1803299",
    "end": "1808580"
  },
  {
    "text": "nerd live long and prosper and within this embedding space we can",
    "start": "1808580",
    "end": "1813799"
  },
  {
    "text": "actually see over correctors who are delayed over correctors who are anticipatory kind of characterized by",
    "start": "1813799",
    "end": "1818960"
  },
  {
    "text": "these uh the colors and then the magnitude of it is the size of of those colors and then we can kind of learn to",
    "start": "1818960",
    "end": "1826880"
  },
  {
    "text": "rank them in their quartiles for how how poor their feedback is and we actually showed in a recent paper that came out",
    "start": "1826880",
    "end": "1833480"
  },
  {
    "text": "in HRI 2022 this year that Mariah Shrum and Aaron Hedland show that we could improve the data that",
    "start": "1833480",
    "end": "1840679"
  },
  {
    "text": "we give to dagger to learn from so that dagger now actually learns better than either vanilla dagger or behavior",
    "start": "1840679",
    "end": "1846740"
  },
  {
    "text": "cloning by learning to basically correct for the human's feedback on a novel task",
    "start": "1846740",
    "end": "1853700"
  },
  {
    "text": "I said that I was going to close the loop it's not just humans teaching robots or",
    "start": "1853700",
    "end": "1859279"
  },
  {
    "text": "even robots characterizing human teaching but now we want to actually make humans better teachers",
    "start": "1859279",
    "end": "1865279"
  },
  {
    "text": "and Mariah and Aaron continued this work in a paper that they're going to now",
    "start": "1865279",
    "end": "1870320"
  },
  {
    "text": "present to New Zealand so I'm very happy for them to get to go fight some some",
    "start": "1870320",
    "end": "1875960"
  },
  {
    "text": "urukai there that in our first study so this was the same mind Mill set up where",
    "start": "1875960",
    "end": "1881419"
  },
  {
    "text": "you're teaching a car to drive through an obstacle course we're going to characterize their sub-optimality and",
    "start": "1881419",
    "end": "1886460"
  },
  {
    "text": "then we're going to in that embedding space if we annotate it so we we actually have to give it semantically meaningful dimensions in this embedding",
    "start": "1886460",
    "end": "1892760"
  },
  {
    "text": "space that's our our limitation we tell them hey you're actually over correcting maybe do less of that",
    "start": "1892760",
    "end": "1900140"
  },
  {
    "text": "um and we modulate that by how significant they're they're over under correcting and their temporal offset is",
    "start": "1900140",
    "end": "1905720"
  },
  {
    "text": "and we showed first that we can modify your behavior and how you teach the robot so we can kind of induce you to",
    "start": "1905720",
    "end": "1912980"
  },
  {
    "text": "move around in this sub-optimal embedding space second we looked at is it best to tell",
    "start": "1912980",
    "end": "1918260"
  },
  {
    "text": "people all the ways in which they're wrong or just pick the worst way and and characterize kind of design from",
    "start": "1918260",
    "end": "1924980"
  },
  {
    "text": "a user's perspective it's actually useful to give people multiple uh",
    "start": "1924980",
    "end": "1930320"
  },
  {
    "text": "to actually tell people all the way in which they're wrong but I know that sounds horrible to say out loud uh but",
    "start": "1930320",
    "end": "1936020"
  },
  {
    "text": "that that is a useful thing to think about and then finally is it actually going to make people better in the long",
    "start": "1936020",
    "end": "1941600"
  },
  {
    "text": "run so if we don't have calibration tasks now because we've made people",
    "start": "1941600",
    "end": "1946640"
  },
  {
    "text": "change their behavior because we provided feedback through multiple rounds of training the",
    "start": "1946640",
    "end": "1952340"
  },
  {
    "text": "human to be a better teacher on a novel task where the robot doesn't know what the ground truth is",
    "start": "1952340",
    "end": "1957620"
  },
  {
    "text": "and I've changed the person's Behavior can I use a neural network that's specifically an lstm architecture to",
    "start": "1957620",
    "end": "1963320"
  },
  {
    "text": "predict where you should now be in this embedding space hopefully it's near optimal but I don't know maybe you've",
    "start": "1963320",
    "end": "1969620"
  },
  {
    "text": "wandered off in the wrong direction can I figure out where you are now because of my impact on you as a robot teaching you as a human",
    "start": "1969620",
    "end": "1976039"
  },
  {
    "text": "and still correct for your sub-optimality now and provide a better",
    "start": "1976039",
    "end": "1981500"
  },
  {
    "text": "training signal for dagger and we showed that yes in fact we can",
    "start": "1981500",
    "end": "1986600"
  },
  {
    "text": "still figure out how we are changing People well enough to be able to characterize them and close this Loop",
    "start": "1986600",
    "end": "1992659"
  },
  {
    "text": "and improve the human machine team um I also like to have my students not just try to make people better but try",
    "start": "1992659",
    "end": "1998779"
  },
  {
    "text": "to make people worse because there's an important confound when you're looking at adaptive systems that you need an",
    "start": "1998779",
    "end": "2004179"
  },
  {
    "text": "Adaptive Baseline and what better than back to adapt to Baseline than actually showing you can",
    "start": "2004179",
    "end": "2009700"
  },
  {
    "text": "control people in every Dimension this is another kind of issue with running actual human-centered experiments so we",
    "start": "2009700",
    "end": "2016539"
  },
  {
    "text": "can actually make you better or worse on the feedback you give I want to start bridging now to think",
    "start": "2016539",
    "end": "2022840"
  },
  {
    "text": "about more complex setups than these low-level skills for short-term trajectories and some of our work that",
    "start": "2022840",
    "end": "2029200"
  },
  {
    "text": "came out of Andrew Silva looked at now how do we bring in language to learn from different tasks where prior work up",
    "start": "2029200",
    "end": "2038799"
  },
  {
    "text": "until very recently most people have been looking at multitask settings where robots are going to do table time manipulation tasks opening closing",
    "start": "2038799",
    "end": "2045640"
  },
  {
    "text": "windows open closing drawers maybe picking up balls pick up in place objects so we have a variety of tasks within metal World developed Chelsea",
    "start": "2045640",
    "end": "2053858"
  },
  {
    "text": "Finn and peterbil and others were working on that developed mt10 and then mt50",
    "start": "2053859",
    "end": "2059138"
  },
  {
    "text": "and we had this idea maybe you know all the great work that's being done in NLP and starting to look at multitask",
    "start": "2059139",
    "end": "2065679"
  },
  {
    "text": "learning maybe we can start doing that with learning from demonstration and so uh there was contemporary work that was",
    "start": "2065679",
    "end": "2071740"
  },
  {
    "text": "looking at this idea of using a language to specify the task instead of using one",
    "start": "2071740",
    "end": "2077980"
  },
  {
    "text": "hot encoding of the different tasks you want to do we in contemporary we showed that and we",
    "start": "2077980",
    "end": "2084040"
  },
  {
    "text": "also extended to the imitation learning case so that we can have people provide natural language and demonstrations to",
    "start": "2084040",
    "end": "2091658"
  },
  {
    "text": "be able to in a more sample efficient way generalized to show new behaviors and more quickly learn synthesize robot",
    "start": "2091659",
    "end": "2098440"
  },
  {
    "text": "control policies for new behaviors just being Guided by language there is kind of an issue though when we",
    "start": "2098440",
    "end": "2105520"
  },
  {
    "text": "work with large language models as many of you know that there are sometimes toxic contents in the data",
    "start": "2105520",
    "end": "2112540"
  },
  {
    "text": "sets themselves and the models learn on that and then the contents can kind of get a bit squirrely you all maybe",
    "start": "2112540",
    "end": "2118920"
  },
  {
    "text": "remember Microsoft hey and some other info no but no shaking of",
    "start": "2118920",
    "end": "2124480"
  },
  {
    "text": "the head okay I'm getting older already so there are issues and so we I was",
    "start": "2124480",
    "end": "2130359"
  },
  {
    "text": "working with Andrew hunts and some other researchers at the University of Washington that looked at the kind of the impact of when large language models",
    "start": "2130359",
    "end": "2137079"
  },
  {
    "text": "meet robots that there might be some important Downstream impacts of that",
    "start": "2137079",
    "end": "2142900"
  },
  {
    "text": "that might have unintended consequences so it's not a focus to my talk but I'd refer you to our recent paper of fact if",
    "start": "2142900",
    "end": "2148660"
  },
  {
    "text": "you want to learn more and I'm happy to talk to you about it offline ultimately I want these systems deployed",
    "start": "2148660",
    "end": "2154240"
  },
  {
    "text": "in the real world whether it's in somebody's home or in a manufacturing environment this is a picture of C-130",
    "start": "2154240",
    "end": "2159520"
  },
  {
    "text": "we had a project with Lockheed Martin we're looking at drilling riveting fastening sections of their C-130",
    "start": "2159520",
    "end": "2165880"
  },
  {
    "text": "fuselage and they have a lot of non-recurring engineering effort and made to order",
    "start": "2165880",
    "end": "2170980"
  },
  {
    "text": "customizations that they might need to consider particularly on Commercial manufacturing and so we looked at how",
    "start": "2170980",
    "end": "2177400"
  },
  {
    "text": "robots could be taught by individual workers on the shop floor to without a cad model of the part develop",
    "start": "2177400",
    "end": "2185079"
  },
  {
    "text": "such a virtual representation and then learn within that representation the skill set and modeling of the skills",
    "start": "2185079",
    "end": "2192339"
  },
  {
    "text": "that the human wants the robot to perform often you have humans that are very skilled running around from",
    "start": "2192339",
    "end": "2197560"
  },
  {
    "text": "fuselage to fuselage doing just these random odds and ends with each aircraft because the scale of it cannot justify",
    "start": "2197560",
    "end": "2204160"
  },
  {
    "text": "spending in order to immense amount of money to develop actual robotic Solutions in the way we think about it",
    "start": "2204160",
    "end": "2209680"
  },
  {
    "text": "for automotive manufacturing and so we can buy an imitation and reinforcement learning here to be able to do this it's",
    "start": "2209680",
    "end": "2216760"
  },
  {
    "text": "it's actually really hard to put a peg in a hole with tight tolerances",
    "start": "2216760",
    "end": "2222099"
  },
  {
    "text": "and as we build to multitasks and now multi-step tasks and our robots are going to be in the",
    "start": "2222099",
    "end": "2228460"
  },
  {
    "text": "home and actually try to cook you a meal we're going to have to really think hierarchically and efficiently because",
    "start": "2228460",
    "end": "2234400"
  },
  {
    "text": "we don't want to teach you teach Roba how to cook a meal by showing the entire meal and say this is everything you need",
    "start": "2234400",
    "end": "2240220"
  },
  {
    "text": "to cook French toast no I wanted to learn how to crack an egg I wanted to",
    "start": "2240220",
    "end": "2246880"
  },
  {
    "text": "learn how to get the egg out of the fridge or a general object out of the fridge and then reuse those skills in a",
    "start": "2246880",
    "end": "2254859"
  },
  {
    "text": "recipe so that I can compose it for arbitrary new skills in the future that's also",
    "start": "2254859",
    "end": "2260140"
  },
  {
    "text": "that's going to make learning easier and it's going to make the burden on me less significant as well",
    "start": "2260140",
    "end": "2266320"
  },
  {
    "text": "for us to help people learn these novel tasks we're going to have to develop learning from demonstration approaches that can handle long Horizon multimodal",
    "start": "2266320",
    "end": "2273220"
  },
  {
    "text": "multi-task specifications that generally Falls within the the vein of task and",
    "start": "2273220",
    "end": "2278560"
  },
  {
    "text": "motion planning we're at the low level we have these kind of Keto Dynamic planning elements and then we might have",
    "start": "2278560",
    "end": "2283780"
  },
  {
    "text": "like PDL like structure shifts planning it's something at a hierarchical level we have hierarchical task networks and",
    "start": "2283780",
    "end": "2289900"
  },
  {
    "text": "we wanted to know can people teach robots with Tamp recipes so I think a lot of people thought yes",
    "start": "2289900",
    "end": "2296200"
  },
  {
    "text": "there was an important work looking at Key frames by egg gun with my chalk mock",
    "start": "2296200",
    "end": "2302380"
  },
  {
    "text": "about 10 years ago that keyframes is kind of the idea that you could have if",
    "start": "2302380",
    "end": "2308260"
  },
  {
    "text": "a robot's going to pick up a cup off of a table you could show like the basic key like waypoints along that trajectory",
    "start": "2308260",
    "end": "2315480"
  },
  {
    "text": "the what we're going to find though is that in in many of those setups the humans are trained on how to provide the",
    "start": "2315480",
    "end": "2322599"
  },
  {
    "text": "keyframes for the distribution of tasks that they're looking at so then humans can kind of just parrot what they",
    "start": "2322599",
    "end": "2328480"
  },
  {
    "text": "literally saw can humans actually generalize that to a different task to break it down in some hierarchical",
    "start": "2328480",
    "end": "2334240"
  },
  {
    "text": "structure and so far the answer is we're going to have a negative result we actually had an RSS paper this summer",
    "start": "2334240",
    "end": "2339280"
  },
  {
    "text": "with knuckle Golfland is not an assistant professor at Arizona State University and the paper was actually titled",
    "start": "2339280",
    "end": "2345940"
  },
  {
    "text": "negative results and lfd people in reinforcement learning try to break down",
    "start": "2345940",
    "end": "2351099"
  },
  {
    "text": "problems this is some of like Knuckles earlier work where you're wanting to look at trajectory segmentation or other",
    "start": "2351099",
    "end": "2357339"
  },
  {
    "text": "ways of breaking up individual motor Primitives and then hierarchically composing them and then also people in",
    "start": "2357339",
    "end": "2362619"
  },
  {
    "text": "cognitive science have tried to understand how we do this as well I want I'm going to be specific when I",
    "start": "2362619",
    "end": "2367660"
  },
  {
    "text": "talk about abstractions for say cooking and yes that does say manure because we weren't going to use real food and that's not real manure it's just pretend",
    "start": "2367660",
    "end": "2374200"
  },
  {
    "text": "manure because we're going to create potting mixtures degree create the right like acidity or whatever for the soil",
    "start": "2374200",
    "end": "2380440"
  },
  {
    "text": "that you want for the for the exotic plant that you're going to grow so this is what I mean you're not going to want",
    "start": "2380440",
    "end": "2386200"
  },
  {
    "text": "to demonstrate the entire task for a robot you're going to want to break it up and then you're going to want to",
    "start": "2386200",
    "end": "2391420"
  },
  {
    "text": "break it up it's such a granular level that each little primitive can have some generalizability and can be composed in",
    "start": "2391420",
    "end": "2398560"
  },
  {
    "text": "this hierarchical fashion and we developed an abstraction score that was kind of shown",
    "start": "2398560",
    "end": "2404440"
  },
  {
    "text": "um qualitatively on the previous slide that looks at these different trajectories and if you run them through",
    "start": "2404440",
    "end": "2410260"
  },
  {
    "text": "Dynamic movement Primitives or other learning algorithms that they really break down unless you actually get the",
    "start": "2410260",
    "end": "2415900"
  },
  {
    "text": "abstraction hierarchy correct so we ask do people naturally teach with",
    "start": "2415900",
    "end": "2422920"
  },
  {
    "text": "abstractions what factors or inducements might elicit the abstraction-based teaching and can you then be taught to",
    "start": "2422920",
    "end": "2429339"
  },
  {
    "text": "give those abstractions we did two experiments first 28 participants we had a baseline which somebody shows up",
    "start": "2429339",
    "end": "2435160"
  },
  {
    "text": "here's the user interface teach the robot how to mix these different elements into your soil for a given",
    "start": "2435160",
    "end": "2441400"
  },
  {
    "text": "recipe on a day and then we said okay how about for three different days you're going to come up with three different mixtures and then here you're",
    "start": "2441400",
    "end": "2448540"
  },
  {
    "text": "going to come up with like 10 different mixers but they're all the same are you going to realize that you can",
    "start": "2448540",
    "end": "2454180"
  },
  {
    "text": "actually do something like copy paste or functional programming through your demonstrations and then finally we're",
    "start": "2454180",
    "end": "2459400"
  },
  {
    "text": "going to just literally have written instructions for you and then actually none of that worked except for the",
    "start": "2459400",
    "end": "2465700"
  },
  {
    "text": "written instructions and so we said what else could we do let's still have our Baseline and a second experiment and then in one setting we're going to have",
    "start": "2465700",
    "end": "2471880"
  },
  {
    "text": "people teach with abstractions have the robot in a Wizard of Oz way show you what the robot would have done with that",
    "start": "2471880",
    "end": "2477400"
  },
  {
    "text": "abstraction so it's going to show you the failure mode that corresponds to the way you taught can you learn from that",
    "start": "2477400",
    "end": "2482560"
  },
  {
    "text": "failure mode to improve or can we show you the answer for a",
    "start": "2482560",
    "end": "2487780"
  },
  {
    "text": "different task and have you generalize that to the original task at hand and so first no most people don't",
    "start": "2487780",
    "end": "2494619"
  },
  {
    "text": "provide abstractions let alone sufficient abstractions second if we try to induce people by giving",
    "start": "2494619",
    "end": "2501579"
  },
  {
    "text": "them a ridiculous number of times that they have to repeat teaching the same things most people still don't actually",
    "start": "2501579",
    "end": "2508660"
  },
  {
    "text": "resort to using abstractions or figure out the sufficient abstraction that they might use and multitask settings also",
    "start": "2508660",
    "end": "2514420"
  },
  {
    "text": "don't seem to do this and then third debug demo maybe helps",
    "start": "2514420",
    "end": "2520240"
  },
  {
    "text": "some people but actually for a lot of people we found that they were so confused by seeing the robot fail that",
    "start": "2520240",
    "end": "2525820"
  },
  {
    "text": "it made them worse at teaching the abstraction um the analog video also seemed to not",
    "start": "2525820",
    "end": "2531339"
  },
  {
    "text": "help so people were having a hard time translating the knowledge from teaching in once in one task to another and it",
    "start": "2531339",
    "end": "2538720"
  },
  {
    "text": "wasn't until they saw an expert do the abstraction teaching that they were able to get it",
    "start": "2538720",
    "end": "2544480"
  },
  {
    "text": "and so participants do not naturally use these abstractions contrary to some indications from prior work and even",
    "start": "2544480",
    "end": "2550960"
  },
  {
    "text": "when they do they may not be the correct abstractions that the only medium that",
    "start": "2550960",
    "end": "2556060"
  },
  {
    "text": "really helped was actually showing the answer to the person and there's a diversity Equity inclusion problem I",
    "start": "2556060",
    "end": "2561400"
  },
  {
    "text": "think I want to call out is that we had a proxy IQ metric so we're not certified",
    "start": "2561400",
    "end": "2566700"
  },
  {
    "text": "psychologists who can actually do an IQ test but there's an online psychometrics project where they're trying to develop",
    "start": "2566700",
    "end": "2572020"
  },
  {
    "text": "something that's a proxy for an IQ test that we administered after the experiment and we have found that the",
    "start": "2572020",
    "end": "2577060"
  },
  {
    "text": "abstraction scores that people provide in their demonstration was higher was correlated with your IQ",
    "start": "2577060",
    "end": "2583660"
  },
  {
    "text": "and so we actually got pushback from uh some people in the HRI Community",
    "start": "2583660",
    "end": "2589380"
  },
  {
    "text": "saying that perhaps you shouldn't be looking at that that's a concerning finding and",
    "start": "2589380",
    "end": "2596079"
  },
  {
    "text": "um so we actually published it a sid in RSS and kind of my position on this is is",
    "start": "2596079",
    "end": "2601480"
  },
  {
    "text": "actually like if this is a real thing this is impacting uh the ability to have",
    "start": "2601480",
    "end": "2606819"
  },
  {
    "text": "everyone benefit from robots and so if it is a real phenomena we need to note that it exists and then figure out what",
    "start": "2606819",
    "end": "2613839"
  },
  {
    "text": "is the right user interface or training methods so that everyone regardless of your IQ or this proxy of basically",
    "start": "2613839",
    "end": "2621280"
  },
  {
    "text": "puzzle solving can benefit from this technology um and ultimately hopefully we're going",
    "start": "2621280",
    "end": "2627280"
  },
  {
    "text": "to be so Aaron headlon and Nina Mormon have already done studies with user populations looking at Learning in the",
    "start": "2627280",
    "end": "2634180"
  },
  {
    "text": "home with real people as part of the cognitive empowerment program in Emory",
    "start": "2634180",
    "end": "2640000"
  },
  {
    "text": "University Works under peer review so sometime later I'll be helping her with with",
    "start": "2640000",
    "end": "2646300"
  },
  {
    "text": "rebuttals so that'll be fun um so",
    "start": "2646300",
    "end": "2651460"
  },
  {
    "text": "how do we close the loop I've shared with you a little bit in a reciprocal mind melt how that might work",
    "start": "2651460",
    "end": "2657960"
  },
  {
    "text": "but I'm going to now talk about explainable artificial intelligence uh briefly as I somewhat come to a close in",
    "start": "2658119",
    "end": "2664660"
  },
  {
    "text": "my talk that another facet of learning from demonstration is that we don't just have heterogeneity or sub-optimality we",
    "start": "2664660",
    "end": "2671140"
  },
  {
    "text": "also have diversity in the way people like things done not just preferences but also different heuristics that we",
    "start": "2671140",
    "end": "2677380"
  },
  {
    "text": "adopt uh work three decades ago tried to get commercial line Pilots to provide",
    "start": "2677380",
    "end": "2683260"
  },
  {
    "text": "data for the same flight plan and use a decision tree to come up with an autopilot based upon that data and the",
    "start": "2683260",
    "end": "2689319"
  },
  {
    "text": "commercial line pilot so disagreed in the way to execute that flight plan that they found it was better to train a",
    "start": "2689319",
    "end": "2696040"
  },
  {
    "text": "decision treat on just one Pilot's data than lumping it together that's not a scalable approach",
    "start": "2696040",
    "end": "2702700"
  },
  {
    "text": "in a recent so we recently got an NIH r01 Grant working with cardiac profusionists at the VA and at the",
    "start": "2702700",
    "end": "2710020"
  },
  {
    "text": "Harvard Medical School and we had some data that we got from them and I was actually doing this analysis",
    "start": "2710020",
    "end": "2715660"
  },
  {
    "text": "myself and what you'll see here is is our model uh what's this ID thing",
    "start": "2715660",
    "end": "2722260"
  },
  {
    "text": "I literally put the ID of the row in the Excel spreadsheet that we got for the tabular data for how a perfusionist",
    "start": "2722260",
    "end": "2728560"
  },
  {
    "text": "would decide how to like oxygenate and keep the flow of your blood properly so that you don't die during open heart",
    "start": "2728560",
    "end": "2734680"
  },
  {
    "text": "surgery we see the our accuracy in predicting what the perfusionist would do we got like a seven percent jump in",
    "start": "2734680",
    "end": "2740800"
  },
  {
    "text": "performance just by putting the row ID in the model and it's like what why should that matter well I had a",
    "start": "2740800",
    "end": "2747940"
  },
  {
    "text": "hunch that it might matter and I I asked our perfusionist partners about this and they said I said",
    "start": "2747940",
    "end": "2754540"
  },
  {
    "text": "did you get this data from multiple different people they're like yeah how do you know I'm like because they're",
    "start": "2754540",
    "end": "2760000"
  },
  {
    "text": "different they think differently and they're at the same institution practicing together",
    "start": "2760000",
    "end": "2766180"
  },
  {
    "text": "if you don't account for this not only do you get a hit but you also have to realize that there's not necessarily a",
    "start": "2766180",
    "end": "2771700"
  },
  {
    "text": "gold standard and Care there's definitely not a gold standard in a lot of healthcare domains people are doing",
    "start": "2771700",
    "end": "2778480"
  },
  {
    "text": "their best and they're very smart but we have a long way to go before we can write down an actual reward function",
    "start": "2778480",
    "end": "2784060"
  },
  {
    "text": "that says here is the knob setting I need here so that you die 70 years from now a very happy person",
    "start": "2784060",
    "end": "2790480"
  },
  {
    "text": "connecting that is really really difficult but on the way to get there I want to at",
    "start": "2790480",
    "end": "2796119"
  },
  {
    "text": "least be able to learn from heterogeneity and so either I can learn a model for each individual perfusionist",
    "start": "2796119",
    "end": "2801160"
  },
  {
    "text": "or I can cluster them and then learn within each cluster of perfusionists and pool their data to help fight the",
    "start": "2801160",
    "end": "2807460"
  },
  {
    "text": "conversive dimensionality to be more data efficient but the objective for clustering and the objective for inverse",
    "start": "2807460",
    "end": "2814300"
  },
  {
    "text": "reinforcement learning are different objectives and so the cluster you the cluster you get might not actually be good for IRL but what if you could do",
    "start": "2814300",
    "end": "2821680"
  },
  {
    "text": "variational inference and learn in some embedding space the way in which everyone each individual person is different from the typical or or",
    "start": "2821680",
    "end": "2828579"
  },
  {
    "text": "prototypical or maximally Bland decision maker",
    "start": "2828579",
    "end": "2833680"
  },
  {
    "text": "um to be able to tease this out and how can we explain then to the perfusionist why the model is right or",
    "start": "2833680",
    "end": "2839680"
  },
  {
    "text": "what it's learned about you this is uh Brad Hayes's joke from um Colorado why did the neural network",
    "start": "2839680",
    "end": "2846940"
  },
  {
    "text": "cross the road I don't know but look it did really well",
    "start": "2846940",
    "end": "2853599"
  },
  {
    "text": "a lot of people that's all they care about but every time I go to the Navy to Health Care they like want their linear",
    "start": "2853599",
    "end": "2861339"
  },
  {
    "text": "regression a decision tree scares them so we're a long way from having these neural networks to actually gain support",
    "start": "2861339",
    "end": "2867520"
  },
  {
    "text": "of these practitioners and so we developed personalized neural trees which are it's basically a fuzzy tree so",
    "start": "2867520",
    "end": "2873640"
  },
  {
    "text": "we replace the decision nodes of each in the tree with a sigmoid to get a degree",
    "start": "2873640",
    "end": "2878800"
  },
  {
    "text": "of Truth and then we can have the leaves be a probably distribution over actions or labels then we can do back prop over",
    "start": "2878800",
    "end": "2885339"
  },
  {
    "text": "this we're going to have an embedding Vector that characterizes your heterogeneity",
    "start": "2885339",
    "end": "2892560"
  },
  {
    "text": "and then we're also going to have this uh PSI C",
    "start": "2892900",
    "end": "2898420"
  },
  {
    "text": "um for uh Lester Sue and I were talking earlier about Greek so I need to I think brush up on my pronunciation uh to be",
    "start": "2898420",
    "end": "2905140"
  },
  {
    "text": "able to if you can regularize those feature selector terms then you can actually get out an exact Boolean tree",
    "start": "2905140",
    "end": "2910660"
  },
  {
    "text": "at the end of the day so you can literally tell somebody here here's how you simulate what I think about your decision making",
    "start": "2910660",
    "end": "2917020"
  },
  {
    "text": "and the heterogeneity matters because if you lump this data together if people like to pass on the left people pass on",
    "start": "2917020",
    "end": "2922780"
  },
  {
    "text": "the right if you're not careful and you average it you're going to crash in the car in front of you",
    "start": "2922780",
    "end": "2927940"
  },
  {
    "text": "so",
    "start": "2927940",
    "end": "2930720"
  },
  {
    "text": "we employ these variational techniques to be able to tease out the person's specific components of the variance",
    "start": "2933099",
    "end": "2939660"
  },
  {
    "text": "extract out the decision three through our regularization process and when we",
    "start": "2939660",
    "end": "2945220"
  },
  {
    "text": "evaluated that on a set of planning and decision-making tasks we found that our method was able to outperform Prior work",
    "start": "2945220",
    "end": "2952000"
  },
  {
    "text": "that looked at clustering or not and for example infogail I think there's something very special about the neural",
    "start": "2952000",
    "end": "2958300"
  },
  {
    "text": "tree architecture that's available for planning and scheduling type tasks and then when we regularize it we also are",
    "start": "2958300",
    "end": "2965200"
  },
  {
    "text": "still outperforming many of the non-interpretable baselines except for one example when we actually found it",
    "start": "2965200",
    "end": "2971440"
  },
  {
    "text": "was better to take our model extract State action pairs from the rollout and the embeddings we learned and then to",
    "start": "2971440",
    "end": "2977500"
  },
  {
    "text": "separately train a supervised learning algorithm or card C 4.5 4.5 to get a",
    "start": "2977500",
    "end": "2982540"
  },
  {
    "text": "decision tree but in general I don't think that's a good approach I'm going to argue that you need to",
    "start": "2982540",
    "end": "2987700"
  },
  {
    "text": "optimize the interpretable representation itself let's say we have a deep reinforcement learning algorithm",
    "start": "2987700",
    "end": "2993579"
  },
  {
    "text": "trained on carpool many of you might have done this in this room you're going to get State action pairs",
    "start": "2993579",
    "end": "2999760"
  },
  {
    "text": "that are kind of the rollouts of the neural network executing this task and then I'm going to take that batch",
    "start": "2999760",
    "end": "3005640"
  },
  {
    "text": "data set offline and train a decision tree to mimic the neural network if I do that and then I use that decision tree",
    "start": "3005640",
    "end": "3012180"
  },
  {
    "text": "to control the cart pull it will suck horribly because of the covaria shift",
    "start": "3012180",
    "end": "3018660"
  },
  {
    "text": "issues that we get in Behavior cloning instead if you actually directly do back",
    "start": "3018660",
    "end": "3024180"
  },
  {
    "text": "prop over the neural net over the decision tree the differentiable form with the regularization not only do you",
    "start": "3024180",
    "end": "3030180"
  },
  {
    "text": "get a interpretable representation of your policy it's also High performing as",
    "start": "3030180",
    "end": "3036240"
  },
  {
    "text": "a policy itself so you need to learn align the explainable model itself with the optimization that you're trying to",
    "start": "3036240",
    "end": "3042660"
  },
  {
    "text": "perform but as xai actually useful subjectively and objectively particularly because so",
    "start": "3042660",
    "end": "3049020"
  },
  {
    "text": "many people are really interested in this and so very briefly we have a journal paper that just came out where",
    "start": "3049020",
    "end": "3055319"
  },
  {
    "text": "we looked at various forms of explanation and a common sense reasoning task looking at posing say Mark has just",
    "start": "3055319",
    "end": "3062400"
  },
  {
    "text": "started running and is trying to train for a local Marathon the marathon is set to take place in a month so Mark has been training very hard unfortunately a",
    "start": "3062400",
    "end": "3068520"
  },
  {
    "text": "week before the marathon Mark suffered an injury what did he injure this elbow neck knee or back",
    "start": "3068520",
    "end": "3076619"
  },
  {
    "text": "a robot can offer suggestions provides some explanation according to one of these formats and we can measure whether",
    "start": "3076619",
    "end": "3082920"
  },
  {
    "text": "or not you accept the robot's advice or reject it and then how much you agree with it and we found that the right form",
    "start": "3082920",
    "end": "3089220"
  },
  {
    "text": "of explainability it's not that one form of explainability fits everyone but if you look at the subjective rating of",
    "start": "3089220",
    "end": "3096480"
  },
  {
    "text": "explainability we get from subjects and then how many answers that they get correctly there is a weak but Sicily",
    "start": "3096480",
    "end": "3102359"
  },
  {
    "text": "significant correlation between explainability and correct decision making when working with robotic decision support which is very promising",
    "start": "3102359",
    "end": "3109079"
  },
  {
    "text": "for the use of this we've also looked at explainability in human machine teaming in a neurops paper by Rohan paleja we",
    "start": "3109079",
    "end": "3115859"
  },
  {
    "text": "had in Minecraft a human and AI agent work together to collaboratively build a",
    "start": "3115859",
    "end": "3120900"
  },
  {
    "text": "house who looked at Micah inslee's three levels of situational awareness and how explainable AI May enhance that and we",
    "start": "3120900",
    "end": "3127740"
  },
  {
    "text": "found that using a situational awareness Global assessment technique where you blank out the screen and then ask people what was happening and what will happen",
    "start": "3127740",
    "end": "3134339"
  },
  {
    "text": "in the future that for level two comprehension of the current state of the environment in level three being",
    "start": "3134339",
    "end": "3140220"
  },
  {
    "text": "able to project into the future having full decision trees improves your situational awareness that's great if",
    "start": "3140220",
    "end": "3146220"
  },
  {
    "text": "you're wanting to team with an agent that you've never worked with before but if you're actually having to spend all",
    "start": "3146220",
    "end": "3151559"
  },
  {
    "text": "that time reading the decision tree while trying to play the game you actually lose performance and so we",
    "start": "3151559",
    "end": "3157619"
  },
  {
    "text": "argue that explainable AI can help build shared mental models quickly in ad hoc teaming settings before you then go in",
    "start": "3157619",
    "end": "3164579"
  },
  {
    "text": "team and then hopefully you can then use what you've learned kind of in the briefing room before you go and play",
    "start": "3164579",
    "end": "3169800"
  },
  {
    "text": "then how the system will work I like to point you um to a paper by Mariah Shrum",
    "start": "3169800",
    "end": "3175319"
  },
  {
    "text": "we have a journal paper coming out version of this we take trying to improve the rigor of HRI we take that",
    "start": "3175319",
    "end": "3181740"
  },
  {
    "text": "seriously and with particularly the design of subjective questionnaires there's a lot of",
    "start": "3181740",
    "end": "3187700"
  },
  {
    "text": "sub-optimal practices that we'd like to kind of try to address in our community and if you want to ever get into that",
    "start": "3187700",
    "end": "3193740"
  },
  {
    "text": "research I'll point you to that paper basically you see so much red because that's a quantification of all the bad",
    "start": "3193740",
    "end": "3200059"
  },
  {
    "text": "unfortunately across the last four years I'm going to tease that we do a lot of",
    "start": "3200059",
    "end": "3206819"
  },
  {
    "text": "work in coordinated reasoning for manufacturing particularly for learning from people learning models of people as",
    "start": "3206819",
    "end": "3214079"
  },
  {
    "text": "they get better at the tasks that they're doing in seasonal manufacturing and gig economies this is very important",
    "start": "3214079",
    "end": "3219660"
  },
  {
    "text": "it takes six months for a person or for a manufacturing line to get fully up to speed and so we've been looking at",
    "start": "3219660",
    "end": "3225839"
  },
  {
    "text": "characterizing the learning curves of individuals working within a human machine team so that a robot can then",
    "start": "3225839",
    "end": "3231839"
  },
  {
    "text": "figure out how to explore or exploit your competencies within us planning task planning and scheduling framework",
    "start": "3231839",
    "end": "3237059"
  },
  {
    "text": "and showing that actually people like the more exploration the robot does to",
    "start": "3237059",
    "end": "3242220"
  },
  {
    "text": "learn what they're best at and um",
    "start": "3242220",
    "end": "3247980"
  },
  {
    "text": "more work there and with that I think humans are amazing and I would be happy to take any",
    "start": "3247980",
    "end": "3254760"
  },
  {
    "text": "questions as I tease the cool new thing that I will do in the future",
    "start": "3254760",
    "end": "3259640"
  },
  {
    "text": "thank you [Applause]",
    "start": "3260160",
    "end": "3267140"
  },
  {
    "text": "when you were teaching people uh you were seeing whether they use",
    "start": "3267140",
    "end": "3272160"
  },
  {
    "text": "abstractions while teaching how did you convince them that the robot could actually deal with",
    "start": "3272160",
    "end": "3278579"
  },
  {
    "text": "being taught using abstractions how did we uh it's the question how did we convince people that the robot could be",
    "start": "3278579",
    "end": "3284700"
  },
  {
    "text": "taught with abstractions yes how did you give them the idea that that was even something that they could be doing and",
    "start": "3284700",
    "end": "3290940"
  },
  {
    "text": "that the robot would get it yeah we had to very carefully think about how do we not just give people the answer but",
    "start": "3290940",
    "end": "3297960"
  },
  {
    "text": "still give them the opportunity to figure it out and because some people did figure it out on their own we think that the interface was at least",
    "start": "3297960",
    "end": "3303960"
  },
  {
    "text": "sufficient to afford that so we try to build in affordances into our graphic user interface that would allow people",
    "start": "3303960",
    "end": "3310200"
  },
  {
    "text": "so you could see here's like the recipes that you could make you could copy paste",
    "start": "3310200",
    "end": "3315240"
  },
  {
    "text": "them and reuse them in different ways across different days to do different things and some people just chose not to",
    "start": "3315240",
    "end": "3321240"
  },
  {
    "text": "take advantage of that even though we did provide a training video that showed the basic functionality of the interface",
    "start": "3321240",
    "end": "3328079"
  },
  {
    "text": "some people just really wanted to teach the whole thing end to end thanks any other questions",
    "start": "3328079",
    "end": "3335420"
  },
  {
    "text": "it was interesting to see that you know you clearly saw different strategies that people took when solving tasks what",
    "start": "3339000",
    "end": "3345300"
  },
  {
    "text": "do you think is a problem do we lack representational capacities in our RL policies that kind of fail to to learn",
    "start": "3345300",
    "end": "3351119"
  },
  {
    "text": "it or is it the learning process itself that causes the collapse and actually the representational capacity is fine as",
    "start": "3351119",
    "end": "3357900"
  },
  {
    "text": "long as the learning process like could have accommodated that because of course we have we see this recurring like many many times and actually it would be",
    "start": "3357900",
    "end": "3364319"
  },
  {
    "text": "beneficial to have a policy that could actually you know go into one mode or the other mode because maybe something",
    "start": "3364319",
    "end": "3370200"
  },
  {
    "text": "in the environment changes slightly and makes one of the you know behaviors more more appropriate for a particular",
    "start": "3370200",
    "end": "3376020"
  },
  {
    "text": "environment and so you showed that we even maybe have it in the human data but we kind of like are really struggling to",
    "start": "3376020",
    "end": "3382020"
  },
  {
    "text": "make use of it yeah are you talking about this work uh yeah but I mean in general like when you showed clustering",
    "start": "3382020",
    "end": "3388079"
  },
  {
    "text": "all that stuff right like it's very clear that it would be nice to be able to you know instead of it's basically collapsing to the mean because you have",
    "start": "3388079",
    "end": "3394740"
  },
  {
    "text": "you know like taking taking a mean of all this data right and clearly something is difficult is it that the",
    "start": "3394740",
    "end": "3400140"
  },
  {
    "text": "policies that we you know tend to you know like I mean mostly of them are gaussians and maybe they lack ability to",
    "start": "3400140",
    "end": "3406380"
  },
  {
    "text": "sort of like be able to be conditioned on something and pick one mode versus the other mode or is it the training",
    "start": "3406380",
    "end": "3412079"
  },
  {
    "text": "procedure itself that is making it difficult to train in such a way that you would have this multimodal policy",
    "start": "3412079",
    "end": "3417119"
  },
  {
    "text": "that can switch depending on yeah so people are in RL are also looking at this multi-modati so the question being",
    "start": "3417119",
    "end": "3422819"
  },
  {
    "text": "like why is this happening why do we have to explicitly address it there's a few issues one that there's a latent variable",
    "start": "3422819",
    "end": "3428400"
  },
  {
    "text": "that we're not accounting for in our state space in this case I'm saying it's some person-specific Factor and so I'm",
    "start": "3428400",
    "end": "3434339"
  },
  {
    "text": "going to try to infer that from your Ops your demonstrations so that I can explain how in the same state two",
    "start": "3434339",
    "end": "3439559"
  },
  {
    "text": "different people are are doing different things a neural networks can't figure that out unless it has some capacity to",
    "start": "3439559",
    "end": "3444839"
  },
  {
    "text": "reason about a latent variable the other one is that neural networks are lazy and with the regularization techniques we do",
    "start": "3444839",
    "end": "3450780"
  },
  {
    "text": "they're going to overfit to the most common thing and just prioritize that in mode collapse so I say it's very similar",
    "start": "3450780",
    "end": "3456540"
  },
  {
    "text": "to the the problems that people have in Gans with mode collapse uh inherently and then also explicitly that there's",
    "start": "3456540",
    "end": "3461940"
  },
  {
    "text": "latent variables that we're trying to tease out and if it's okay can I get in one last",
    "start": "3461940",
    "end": "3467760"
  },
  {
    "text": "question or we have to get kicked out okay maybe we might be out of time okay so all right we'll end here please come",
    "start": "3467760",
    "end": "3474420"
  },
  {
    "text": "up and if you have additional questions for Matthew go ahead and ask him and thanks again for the great talking yeah thank you",
    "start": "3474420",
    "end": "3479740"
  },
  {
    "text": "[Applause]",
    "start": "3479740",
    "end": "3483380"
  }
]
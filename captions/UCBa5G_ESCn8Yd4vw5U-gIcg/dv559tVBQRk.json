[
  {
    "start": "0",
    "end": "18000"
  },
  {
    "start": "0",
    "end": "5120"
  },
  {
    "text": "CHRISTOPHER POTTS:\nWelcome back, everyone.",
    "start": "5120",
    "end": "6870"
  },
  {
    "text": "This is part 4 on our\nseries on distributed word",
    "start": "6870",
    "end": "8870"
  },
  {
    "text": "representations.",
    "start": "8870",
    "end": "9550"
  },
  {
    "text": "We're going to be talking about\nbasical reweighting schemes.",
    "start": "9550",
    "end": "12050"
  },
  {
    "text": "Essentially, I feel\nlike we've been",
    "start": "12050",
    "end": "13190"
  },
  {
    "text": "faithful to the underlying\ncounts of our matrices",
    "start": "13190",
    "end": "15259"
  },
  {
    "text": "for too long.",
    "start": "15260",
    "end": "16020"
  },
  {
    "text": "It's time to start\nmessing with them.",
    "start": "16020",
    "end": "17740"
  },
  {
    "text": "Here are some high-level goals\nthat we have for reweighting.",
    "start": "17740",
    "end": "20240"
  },
  {
    "start": "18000",
    "end": "121000"
  },
  {
    "text": "And we would like\nin these matrices",
    "start": "20240",
    "end": "21698"
  },
  {
    "text": "to amplify the\nassociations that are",
    "start": "21698",
    "end": "23450"
  },
  {
    "text": "important and trustworthy and\nunusual while correspondingly",
    "start": "23450",
    "end": "27390"
  },
  {
    "text": "deemphasizing the things\nthat are mundane or quirky",
    "start": "27390",
    "end": "30109"
  },
  {
    "text": "or reflect errors or\nidiosyncrasies in the data",
    "start": "30110",
    "end": "32360"
  },
  {
    "text": "that we use.",
    "start": "32360",
    "end": "33530"
  },
  {
    "text": "Now, of course, absent the\ndefined objective function",
    "start": "33530",
    "end": "36469"
  },
  {
    "text": "of the machine-learning sense.",
    "start": "36470",
    "end": "37720"
  },
  {
    "text": "This is going to\nremain a fuzzy goal,",
    "start": "37720",
    "end": "39680"
  },
  {
    "text": "but we do have some\nquantitative hooks, I think.",
    "start": "39680",
    "end": "41810"
  },
  {
    "text": "We have this guiding\nintuition that we",
    "start": "41810",
    "end": "44030"
  },
  {
    "text": "would like to move\naway from raw counts",
    "start": "44030",
    "end": "45980"
  },
  {
    "text": "because frequency\nalone is generally",
    "start": "45980",
    "end": "48470"
  },
  {
    "text": "a poor proxy for the kind\nof semantic information",
    "start": "48470",
    "end": "51110"
  },
  {
    "text": "that we hope to extract.",
    "start": "51110",
    "end": "53130"
  },
  {
    "text": "So we can ask for each of\nthe reweighting schemes",
    "start": "53130",
    "end": "55250"
  },
  {
    "text": "that we consider,\nfirst, how does",
    "start": "55250",
    "end": "57020"
  },
  {
    "text": "it compare to the\nunderlying raw count values?",
    "start": "57020",
    "end": "59870"
  },
  {
    "text": "If the scheme is just rescaling\nthe underlying counts,",
    "start": "59870",
    "end": "62899"
  },
  {
    "text": "it's probably not\nworth the effort.",
    "start": "62900",
    "end": "64525"
  },
  {
    "text": "On the other hand,\nif it gives us",
    "start": "64525",
    "end": "65900"
  },
  {
    "text": "a very different\ndistribution, then",
    "start": "65900",
    "end": "67595"
  },
  {
    "text": "at least we know that\nwe're cooking with fire",
    "start": "67595",
    "end": "69470"
  },
  {
    "text": "when it comes to moving\naway from raw frequency.",
    "start": "69470",
    "end": "72655"
  },
  {
    "text": "There's a related\nquestion that I",
    "start": "72655",
    "end": "74030"
  },
  {
    "text": "would like us to\nhave in mind, what",
    "start": "74030",
    "end": "75710"
  },
  {
    "text": "is the overall\ndistribution of values",
    "start": "75710",
    "end": "77630"
  },
  {
    "text": "that the reweighting\nscheme delivers?",
    "start": "77630",
    "end": "79490"
  },
  {
    "text": "Count distributions are\nvery skewed in a way that",
    "start": "79490",
    "end": "82189"
  },
  {
    "text": "can make them difficult\nto deal with for lots",
    "start": "82190",
    "end": "84110"
  },
  {
    "text": "of analytic and\nmachine-learning methods.",
    "start": "84110",
    "end": "86220"
  },
  {
    "text": "So we might hope that in\nreweighting, in addition",
    "start": "86220",
    "end": "88610"
  },
  {
    "text": "to capturing things\nthat are important",
    "start": "88610",
    "end": "90230"
  },
  {
    "text": "and deemphasizing\nthings that are mundane,",
    "start": "90230",
    "end": "92390"
  },
  {
    "text": "would also give us an overall\ndistribution of values",
    "start": "92390",
    "end": "94880"
  },
  {
    "text": "that was more tractable for\nthese downstream applications.",
    "start": "94880",
    "end": "98600"
  },
  {
    "text": "And then finally\nI personally have",
    "start": "98600",
    "end": "100070"
  },
  {
    "text": "a goal that we would like\nto do, no feature selection",
    "start": "100070",
    "end": "102320"
  },
  {
    "text": "based on counts or\noutside resources",
    "start": "102320",
    "end": "104900"
  },
  {
    "text": "like stopword dictionaries.",
    "start": "104900",
    "end": "106620"
  },
  {
    "text": "I don't want to be filtering\noff parts of the vocabulary",
    "start": "106620",
    "end": "109700"
  },
  {
    "text": "a priori, because\nfor all I know,",
    "start": "109700",
    "end": "111789"
  },
  {
    "text": "something that's a boring\nstopword for one genre is",
    "start": "111790",
    "end": "114320"
  },
  {
    "text": "actually an important\ncontent word for another.",
    "start": "114320",
    "end": "116900"
  },
  {
    "text": "We would like the method to\nsort of make that decision.",
    "start": "116900",
    "end": "119240"
  },
  {
    "start": "119240",
    "end": "122360"
  },
  {
    "start": "121000",
    "end": "333000"
  },
  {
    "text": "So let's start with\nthe most basic scheme.",
    "start": "122360",
    "end": "124480"
  },
  {
    "text": "And this is a scheme that\nwill pay attention only",
    "start": "124480",
    "end": "126610"
  },
  {
    "text": "to the row context.",
    "start": "126610",
    "end": "128080"
  },
  {
    "text": "This is normalization.",
    "start": "128080",
    "end": "129220"
  },
  {
    "text": "So this is actually a repeat\nfrom the lecture on vector",
    "start": "129220",
    "end": "131620"
  },
  {
    "text": "comparison L2 norming.",
    "start": "131620",
    "end": "133599"
  },
  {
    "text": "We've calculated the\nL2 length as a fixed",
    "start": "133600",
    "end": "135880"
  },
  {
    "text": "quantity for each row vector.",
    "start": "135880",
    "end": "137740"
  },
  {
    "text": "And then the length\nnormalization",
    "start": "137740",
    "end": "139300"
  },
  {
    "text": "of that row vector\nis just taking",
    "start": "139300",
    "end": "140950"
  },
  {
    "text": "each value in the\noriginal vector",
    "start": "140950",
    "end": "142810"
  },
  {
    "text": "and dividing it by that fixed\nquantity of the L2 lengths.",
    "start": "142810",
    "end": "147127"
  },
  {
    "text": "There's a related, and\nperhaps more familiar",
    "start": "147127",
    "end": "148959"
  },
  {
    "text": "notion, which I've called\nprobability distribution where",
    "start": "148960",
    "end": "151293"
  },
  {
    "text": "we follow the same logic.",
    "start": "151293",
    "end": "152920"
  },
  {
    "text": "We just replace that\nnormalizing constant,",
    "start": "152920",
    "end": "154810"
  },
  {
    "text": "the L2 length with\nthe sum of all",
    "start": "154810",
    "end": "157060"
  },
  {
    "text": "the elements in the vectors.",
    "start": "157060",
    "end": "158290"
  },
  {
    "text": "But again we do this\nelement-wise division",
    "start": "158290",
    "end": "160959"
  },
  {
    "text": "by that fixed\nquantity to normalize",
    "start": "160960",
    "end": "163000"
  },
  {
    "text": "the vector into a\nprobability distribution.",
    "start": "163000",
    "end": "166390"
  },
  {
    "text": "I think both of these\nmethods can be powerful,",
    "start": "166390",
    "end": "168400"
  },
  {
    "text": "but the shame of them is that\nthey are paying attention only",
    "start": "168400",
    "end": "171159"
  },
  {
    "text": "to the row context.",
    "start": "171160",
    "end": "172570"
  },
  {
    "text": "For a given cell, IJ,\nwe're looking just",
    "start": "172570",
    "end": "174640"
  },
  {
    "text": "across the row I. We're not\nconsidering the context that",
    "start": "174640",
    "end": "178030"
  },
  {
    "text": "could come from the\ncolumn J. So let's begin",
    "start": "178030",
    "end": "180580"
  },
  {
    "text": "to correct that omission.",
    "start": "180580",
    "end": "182740"
  },
  {
    "text": "Here is kind of the star of\nour show in the quiet sense.",
    "start": "182740",
    "end": "185243"
  },
  {
    "text": "This is the first scheme we'll\nlook at that pays attention",
    "start": "185243",
    "end": "187660"
  },
  {
    "text": "to both row and column context.",
    "start": "187660",
    "end": "189250"
  },
  {
    "text": "This is observed over expected.",
    "start": "189250",
    "end": "191442"
  },
  {
    "text": "Let's just go through\nthis notation here.",
    "start": "191442",
    "end": "193150"
  },
  {
    "text": "We have the row sum.",
    "start": "193150",
    "end": "194170"
  },
  {
    "text": "I think that's intuitive.",
    "start": "194170",
    "end": "195430"
  },
  {
    "text": "Correspondingly, the\ncolumn sum, the sum of all",
    "start": "195430",
    "end": "197629"
  },
  {
    "text": "values along the column.",
    "start": "197630",
    "end": "199540"
  },
  {
    "text": "And then the sum for\nsome matrix x is just",
    "start": "199540",
    "end": "201640"
  },
  {
    "text": "the sum of all the cell\nvalues in that matrix.",
    "start": "201640",
    "end": "204610"
  },
  {
    "text": "Those are the raw materials\nfor calculating what's",
    "start": "204610",
    "end": "206740"
  },
  {
    "text": "called the expected value.",
    "start": "206740",
    "end": "208600"
  },
  {
    "text": "The expected value given\na matrix x for cell i, j",
    "start": "208600",
    "end": "212350"
  },
  {
    "text": "is the rowsum\ntimes the columnsum",
    "start": "212350",
    "end": "215440"
  },
  {
    "text": "as the numerator divided\nby the sum of all",
    "start": "215440",
    "end": "217930"
  },
  {
    "text": "the values in the matrix.",
    "start": "217930",
    "end": "219579"
  },
  {
    "text": "This is an expected quasi count.",
    "start": "219580",
    "end": "221950"
  },
  {
    "text": "It is giving us the\nnumber we would expect",
    "start": "221950",
    "end": "224770"
  },
  {
    "text": "if the row and column were\nindependent of each other",
    "start": "224770",
    "end": "227470"
  },
  {
    "text": "in the statistical sense.",
    "start": "227470",
    "end": "228760"
  },
  {
    "text": "And that's the sense in\nwhich this is an expectation.",
    "start": "228760",
    "end": "231909"
  },
  {
    "text": "The observed over expected\nvalue simply compared",
    "start": "231910",
    "end": "234520"
  },
  {
    "text": "the observed value in the\nnumerator by that expected",
    "start": "234520",
    "end": "237850"
  },
  {
    "text": "value.",
    "start": "237850",
    "end": "239180"
  },
  {
    "text": "So in a bit more detail, here's\nhow the calculations work.",
    "start": "239180",
    "end": "241930"
  },
  {
    "text": "We've got this tiny\nlittle count matrix here.",
    "start": "241930",
    "end": "243849"
  },
  {
    "text": "Let's look at cell XA.",
    "start": "243850",
    "end": "244960"
  },
  {
    "text": "It's got a count of 34.",
    "start": "244960",
    "end": "246890"
  },
  {
    "text": "That's our observed count\nover here in the numerator.",
    "start": "246890",
    "end": "250160"
  },
  {
    "text": "The denominator is the\nproduct of the rowsum",
    "start": "250160",
    "end": "252880"
  },
  {
    "text": "and the columnsum,\n45 by 81 divided",
    "start": "252880",
    "end": "255970"
  },
  {
    "text": "by the sum of all the values\nin this matrix, which is 99.",
    "start": "255970",
    "end": "259570"
  },
  {
    "text": "We repeat that calculation\nfor all the other cells,",
    "start": "259570",
    "end": "262610"
  },
  {
    "text": "making the corresponding\nadjustments,",
    "start": "262610",
    "end": "264340"
  },
  {
    "text": "and that gives us a\ncompletely reweighted matrix.",
    "start": "264340",
    "end": "269070"
  },
  {
    "text": "Here's the intuition.",
    "start": "269070",
    "end": "270170"
  },
  {
    "text": "That was the calculation.",
    "start": "270170",
    "end": "271252"
  },
  {
    "text": "Let's think about why we\nmight want to do this.",
    "start": "271252",
    "end": "273210"
  },
  {
    "text": "So I've got here a highly\nidealized little count matrix.",
    "start": "273210",
    "end": "276919"
  },
  {
    "text": "And the conceit of this example\nis that \"keep tabs\" in English",
    "start": "276920",
    "end": "280250"
  },
  {
    "text": "is an idiom.",
    "start": "280250",
    "end": "281360"
  },
  {
    "text": "And otherwise, the\nword \"tabs\" alone",
    "start": "281360",
    "end": "283129"
  },
  {
    "text": "doesn't appear with\nmany other words.",
    "start": "283130",
    "end": "285000"
  },
  {
    "text": "It's kind of constrained\nto this idiomatic context.",
    "start": "285000",
    "end": "288140"
  },
  {
    "text": "So we get a really high\ncount for \"keep tabs\"",
    "start": "288140",
    "end": "291110"
  },
  {
    "text": "and a relatively low\ncount for \"enjoy tabs\"",
    "start": "291110",
    "end": "293569"
  },
  {
    "text": "again because \"tabs\" doesn't\nreally associate with the word",
    "start": "293570",
    "end": "296240"
  },
  {
    "text": "\"enjoy.\"",
    "start": "296240",
    "end": "297639"
  },
  {
    "text": "On the right here, I've got\nthe expected calculation.",
    "start": "297640",
    "end": "300640"
  },
  {
    "text": "And it comes out just\nlike we would hope.",
    "start": "300640",
    "end": "302500"
  },
  {
    "text": "The expected count for\n\"keep tabs\" is mere 12.48%,",
    "start": "302500",
    "end": "306670"
  },
  {
    "text": "compare that with the\nobserved count of 20.",
    "start": "306670",
    "end": "308660"
  },
  {
    "text": "\"Keep tabs\" is overrepresented\nrelative to our expectations",
    "start": "308660",
    "end": "312580"
  },
  {
    "text": "in virtue of the fact that the\nindependence assumption built",
    "start": "312580",
    "end": "315580"
  },
  {
    "text": "into the expected calculation\nis just not met here because",
    "start": "315580",
    "end": "318520"
  },
  {
    "text": "of the collocational effect.",
    "start": "318520",
    "end": "320569"
  },
  {
    "text": "Similarly, the expected count\nfor \"enjoy tabs\" is 8.5.",
    "start": "320570",
    "end": "324290"
  },
  {
    "text": "That's much larger\nthan our observation,",
    "start": "324290",
    "end": "326470"
  },
  {
    "text": "again because these are\nkind of disassociated",
    "start": "326470",
    "end": "329140"
  },
  {
    "text": "with each other in virtue of\nthe restricted distribution",
    "start": "329140",
    "end": "331990"
  },
  {
    "text": "of tabs.",
    "start": "331990",
    "end": "333900"
  },
  {
    "start": "333000",
    "end": "464000"
  },
  {
    "text": "And that brings us to\nreally the star of our show,",
    "start": "333900",
    "end": "336150"
  },
  {
    "text": "and in fact the star of a lot\nof the remainder of this unit.",
    "start": "336150",
    "end": "338889"
  },
  {
    "text": "This is pointwise mutual\ninformation, or PMI.",
    "start": "338890",
    "end": "342030"
  },
  {
    "text": "PMI is simply observed\nover expected in log-space",
    "start": "342030",
    "end": "345690"
  },
  {
    "text": "where we stipulate\nthat the log of 0 is 0.",
    "start": "345690",
    "end": "348570"
  },
  {
    "text": "In a bit more detail for\nmatrix x, given cell i, j,",
    "start": "348570",
    "end": "352350"
  },
  {
    "text": "the PMI value is the\nlog of the observed",
    "start": "352350",
    "end": "355380"
  },
  {
    "text": "count over the expected count.",
    "start": "355380",
    "end": "357130"
  },
  {
    "text": "And that's it.",
    "start": "357130",
    "end": "358140"
  },
  {
    "text": "Many people find it\nmore intuitive to think",
    "start": "358140",
    "end": "360210"
  },
  {
    "text": "of this in probabilistic terms.",
    "start": "360210",
    "end": "361514"
  },
  {
    "text": "That's what I've done\nover here on the right.",
    "start": "361515",
    "end": "363390"
  },
  {
    "text": "It's equivalent numerically, but\nfor this kind of calculation,",
    "start": "363390",
    "end": "366910"
  },
  {
    "text": "we first form a joint\nprobability table",
    "start": "366910",
    "end": "369810"
  },
  {
    "text": "by just dividing all the cell\nvalues by the total number",
    "start": "369810",
    "end": "372660"
  },
  {
    "text": "of values in all the cells.",
    "start": "372660",
    "end": "374580"
  },
  {
    "text": "That gives us the\njoint probability table",
    "start": "374580",
    "end": "376470"
  },
  {
    "text": "and then the row probability\nand the column probability",
    "start": "376470",
    "end": "379710"
  },
  {
    "text": "are just summing across the row\nand the column respectively.",
    "start": "379710",
    "end": "382930"
  },
  {
    "text": "And again we multiply them.",
    "start": "382930",
    "end": "384055"
  },
  {
    "text": "And that's kind of\nnice, because then you",
    "start": "384055",
    "end": "385763"
  },
  {
    "text": "can see we really are testing\nan independence assumption.",
    "start": "385763",
    "end": "388260"
  },
  {
    "text": "It's as though we say we can\nmultiply these probabilities",
    "start": "388260",
    "end": "391200"
  },
  {
    "text": "because they're independent.",
    "start": "391200",
    "end": "392760"
  },
  {
    "text": "If the distribution\nis truly independent,",
    "start": "392760",
    "end": "394710"
  },
  {
    "text": "that ought to match\nwhat we observed.",
    "start": "394710",
    "end": "396530"
  },
  {
    "text": "And of course discrepancies\nare the things",
    "start": "396530",
    "end": "398280"
  },
  {
    "text": "that these matrices\nwill highlight.",
    "start": "398280",
    "end": "401010"
  },
  {
    "text": "Let's look at an example.",
    "start": "401010",
    "end": "402060"
  },
  {
    "text": "And there's one\nthing that I want",
    "start": "402060",
    "end": "403050"
  },
  {
    "text": "to track because we work\nthrough this example.",
    "start": "403050",
    "end": "405150"
  },
  {
    "text": "And that's the cell down\nhere, this lonely little 1.",
    "start": "405150",
    "end": "408190"
  },
  {
    "text": "So this is a count matrix.",
    "start": "408190",
    "end": "409410"
  },
  {
    "text": "I've got this as a word\nby document matrix.",
    "start": "409410",
    "end": "411327"
  },
  {
    "text": "This is a very flexible\nmethod, and we apply",
    "start": "411327",
    "end": "413160"
  },
  {
    "text": "to lots of matrix designs.",
    "start": "413160",
    "end": "415230"
  },
  {
    "text": "Over here, I form the\njoint probability table.",
    "start": "415230",
    "end": "418020"
  },
  {
    "text": "And I've got here the columnsum\nand the rowsum corresponding",
    "start": "418020",
    "end": "421139"
  },
  {
    "text": "to the column and\nrow probability.",
    "start": "421140",
    "end": "422700"
  },
  {
    "text": "These are the raw ingredients\nfor the PMI matrix, which",
    "start": "422700",
    "end": "426240"
  },
  {
    "text": "is derived down here by\napplying this calculation to all",
    "start": "426240",
    "end": "429580"
  },
  {
    "text": "of these values.",
    "start": "429580",
    "end": "431009"
  },
  {
    "text": "Notice what's\nhappened, that lonely 1",
    "start": "431010",
    "end": "432900"
  },
  {
    "text": "down here because it's in a very\ninfrequent row and a relatively",
    "start": "432900",
    "end": "436139"
  },
  {
    "text": "infrequent column.",
    "start": "436140",
    "end": "437460"
  },
  {
    "text": "It has the largest PMI value\nin the resulting matrix.",
    "start": "437460",
    "end": "441150"
  },
  {
    "text": "Now that could be\ngood, because this",
    "start": "441150",
    "end": "442650"
  },
  {
    "text": "could be a very important\nevent, in which case",
    "start": "442650",
    "end": "445110"
  },
  {
    "text": "we want to amplify it.",
    "start": "445110",
    "end": "446400"
  },
  {
    "text": "On the other hand,\nNLP being what it is,",
    "start": "446400",
    "end": "449790"
  },
  {
    "text": "this could be just a mistake\nin the data or something.",
    "start": "449790",
    "end": "452310"
  },
  {
    "text": "And then this\nexaggerated value here",
    "start": "452310",
    "end": "454110"
  },
  {
    "text": "could turn out to\nbe problematic.",
    "start": "454110",
    "end": "456039"
  },
  {
    "text": "It's difficult to\nstrike this balance.",
    "start": "456040",
    "end": "457690"
  },
  {
    "text": "But it's worth keeping in mind\nas you work with this method",
    "start": "457690",
    "end": "460260"
  },
  {
    "text": "that it could amplify not\nonly important things but also",
    "start": "460260",
    "end": "463470"
  },
  {
    "text": "idiosyncratic things.",
    "start": "463470",
    "end": "465300"
  },
  {
    "start": "464000",
    "end": "537000"
  },
  {
    "text": "Positive PMI is an important\nvariant of PMI, so important,",
    "start": "465300",
    "end": "468251"
  },
  {
    "text": "in fact, that I\nwould like to think",
    "start": "468252",
    "end": "469710"
  },
  {
    "text": "of it as the kind\nof default view",
    "start": "469710",
    "end": "471085"
  },
  {
    "text": "that we take on PMI for\nthe following reason.",
    "start": "471085",
    "end": "474000"
  },
  {
    "text": "PMI is actually undefined where\nthe count is 0, because we",
    "start": "474000",
    "end": "477000"
  },
  {
    "text": "need to take the log of 0.",
    "start": "477000",
    "end": "479340"
  },
  {
    "text": "So we had to stipulate\nthat the log of 0",
    "start": "479340",
    "end": "481065"
  },
  {
    "text": "was 0 for this calculation.",
    "start": "481065",
    "end": "484650"
  },
  {
    "text": "However, that's\narguably not coherent",
    "start": "484650",
    "end": "486870"
  },
  {
    "text": "if you think about what the\nunderlying matrix represents.",
    "start": "486870",
    "end": "489300"
  },
  {
    "text": "What we're saying with\nPMI is that larger",
    "start": "489300",
    "end": "491430"
  },
  {
    "text": "than expected values\nget a large PMI.",
    "start": "491430",
    "end": "494340"
  },
  {
    "text": "Smaller than expected\nvalues get a smaller PMI.",
    "start": "494340",
    "end": "497340"
  },
  {
    "text": "That's good.",
    "start": "497340",
    "end": "498340"
  },
  {
    "text": "But when we encounter a 0, we\nplace it right in the middle.",
    "start": "498340",
    "end": "501120"
  },
  {
    "text": "And that's just strange\nbecause a 0 isn't evidence",
    "start": "501120",
    "end": "503790"
  },
  {
    "text": "of anything larger or smaller.",
    "start": "503790",
    "end": "505372"
  },
  {
    "text": "It doesn't deserve to be\nin the middle of this.",
    "start": "505372",
    "end": "507330"
  },
  {
    "text": "If anything, we just don't know\nwhat to do with the 0 values.",
    "start": "507330",
    "end": "511030"
  },
  {
    "text": "So this is arguably\nsort of incoherent,",
    "start": "511030",
    "end": "513270"
  },
  {
    "text": "and the standard\nresponse to it is",
    "start": "513270",
    "end": "515250"
  },
  {
    "text": "to simply turn all of the\nnegative values into 0.",
    "start": "515250",
    "end": "518849"
  },
  {
    "text": "And that's positive PMI\nthat's defined here.",
    "start": "518850",
    "end": "521829"
  },
  {
    "text": "So we simply lop off\nall the negative values",
    "start": "521830",
    "end": "523770"
  },
  {
    "text": "by mapping them to 0.",
    "start": "523770",
    "end": "525810"
  },
  {
    "text": "And that at least restores\nthe overall coherence",
    "start": "525810",
    "end": "528630"
  },
  {
    "text": "of the claims where\nall we're doing",
    "start": "528630",
    "end": "530100"
  },
  {
    "text": "is reflecting the fact that\nlarger than expected counts",
    "start": "530100",
    "end": "533250"
  },
  {
    "text": "have large positive PMI\nand the rest are put in 0.",
    "start": "533250",
    "end": "538210"
  },
  {
    "start": "537000",
    "end": "658000"
  },
  {
    "text": "Let's look briefly at a few\nother reweighting schemes,",
    "start": "538210",
    "end": "540550"
  },
  {
    "text": "starting with the t-test.",
    "start": "540550",
    "end": "541858"
  },
  {
    "text": "The t-test is\nsomething that you work",
    "start": "541858",
    "end": "543399"
  },
  {
    "text": "with on the first\nassignment to implement it.",
    "start": "543400",
    "end": "545290"
  },
  {
    "text": "It turns out to be a very\ngood reweighting scheme.",
    "start": "545290",
    "end": "547420"
  },
  {
    "text": "And I like it because\nit obviously reflects",
    "start": "547420",
    "end": "549339"
  },
  {
    "text": "many of the same intuitions\nthat guide the PMI",
    "start": "549340",
    "end": "551890"
  },
  {
    "text": "and observed over\nexpected calculations.",
    "start": "551890",
    "end": "555010"
  },
  {
    "text": "TF-IDF is quite different.",
    "start": "555010",
    "end": "556670"
  },
  {
    "text": "So this is typically\nperformed on word",
    "start": "556670",
    "end": "558579"
  },
  {
    "text": "by document matrices in\nthe context of information",
    "start": "558580",
    "end": "561430"
  },
  {
    "text": "retrieval.",
    "start": "561430",
    "end": "562450"
  },
  {
    "text": "Given some corpus\nof documents D,",
    "start": "562450",
    "end": "564160"
  },
  {
    "text": "we're going to say that the\nterm frequency for a given cell",
    "start": "564160",
    "end": "567310"
  },
  {
    "text": "is that value divided by\nthe sum of all the values",
    "start": "567310",
    "end": "569840"
  },
  {
    "text": "in the column, giving us\nthe kind of probability",
    "start": "569840",
    "end": "571840"
  },
  {
    "text": "of the word given the\ndocument that we're in.",
    "start": "571840",
    "end": "574880"
  },
  {
    "text": "And then the IDF value is the\nlog of this quantity here.",
    "start": "574880",
    "end": "578330"
  },
  {
    "text": "This is the number of\ndocuments in our corpus",
    "start": "578330",
    "end": "581360"
  },
  {
    "text": "that is the column\ndimensionality divided",
    "start": "581360",
    "end": "584209"
  },
  {
    "text": "by the number of documents\nthat contain the target word.",
    "start": "584210",
    "end": "587220"
  },
  {
    "text": "And again we met log of 0 to 0.",
    "start": "587220",
    "end": "589529"
  },
  {
    "text": "The TF-IDF is the product\nof those two values.",
    "start": "589530",
    "end": "592730"
  },
  {
    "text": "I think this can be\nan outstanding method",
    "start": "592730",
    "end": "594980"
  },
  {
    "text": "for very large sparse matrices,\nlike the Word Document one.",
    "start": "594980",
    "end": "598790"
  },
  {
    "text": "Conversely it is typically\nnot well-behaved for very",
    "start": "598790",
    "end": "602540"
  },
  {
    "text": "dense matrices, like\nthe word-by-word ones",
    "start": "602540",
    "end": "604910"
  },
  {
    "text": "that we were favoring\nin this course.",
    "start": "604910",
    "end": "606949"
  },
  {
    "text": "The reason, this is IDF value.",
    "start": "606950",
    "end": "609530"
  },
  {
    "text": "It's very unlikely\nthat you would",
    "start": "609530",
    "end": "611030"
  },
  {
    "text": "have a word that appeared\nliterally in every document.",
    "start": "611030",
    "end": "614330"
  },
  {
    "text": "However, in the context of very\ndense word by word matrices,",
    "start": "614330",
    "end": "618350"
  },
  {
    "text": "it is possible for\nsome words to co-occur",
    "start": "618350",
    "end": "621139"
  },
  {
    "text": "with every single other\nword, in which case",
    "start": "621140",
    "end": "623120"
  },
  {
    "text": "you'll get an IDF of value\nof 0, which is probably not",
    "start": "623120",
    "end": "626187"
  },
  {
    "text": "the intended outcome for\nsomething that's high frequency",
    "start": "626187",
    "end": "628520"
  },
  {
    "text": "but might nonetheless be\nimportant in the context",
    "start": "628520",
    "end": "631760"
  },
  {
    "text": "of individual documents.",
    "start": "631760",
    "end": "633770"
  },
  {
    "text": "So I'd probably steer\naway from TF-IDF",
    "start": "633770",
    "end": "635930"
  },
  {
    "text": "unless you're working with\na sparse matrix design.",
    "start": "635930",
    "end": "639136"
  },
  {
    "text": "And then even further\nafield from the things",
    "start": "639137",
    "end": "640970"
  },
  {
    "text": "we've discussed, you might\nexplore using, for example,",
    "start": "640970",
    "end": "643220"
  },
  {
    "text": "pairwise distance matrices where\nI calculate the cosine distance",
    "start": "643220",
    "end": "646970"
  },
  {
    "text": "between every pair of\nwords along the rows",
    "start": "646970",
    "end": "649430"
  },
  {
    "text": "and form a matrix on that basis.",
    "start": "649430",
    "end": "651589"
  },
  {
    "text": "Really different in its approach\nand probably in its outcomes,",
    "start": "651590",
    "end": "655100"
  },
  {
    "text": "but it could be\nvery interesting.",
    "start": "655100",
    "end": "658380"
  },
  {
    "start": "658000",
    "end": "881000"
  },
  {
    "text": "Let's return to our\nessential questions.",
    "start": "658380",
    "end": "660110"
  },
  {
    "text": "Remember for each one of\nthese reweighting schemes",
    "start": "660110",
    "end": "662193"
  },
  {
    "text": "we want to ask, how does\nit compare to the raw count",
    "start": "662193",
    "end": "664560"
  },
  {
    "text": "values, and what overall\ndistribution of values",
    "start": "664560",
    "end": "667800"
  },
  {
    "text": "does it deliver?",
    "start": "667800",
    "end": "668800"
  },
  {
    "text": "So let's do a bit of\nan assessment of that.",
    "start": "668800",
    "end": "670600"
  },
  {
    "text": "I'm working with\nthe giga5 matrix",
    "start": "670600",
    "end": "672647"
  },
  {
    "text": "that you can load as part\nof the course materials.",
    "start": "672647",
    "end": "674730"
  },
  {
    "text": "That's Gigaword with a window\nof 5 and a scaling of 1 over n.",
    "start": "674730",
    "end": "679079"
  },
  {
    "text": "Up here in the left, I have the\nraw counts, and the cell value",
    "start": "679080",
    "end": "682620"
  },
  {
    "text": "along the x-axis and the\nnumber of things that have",
    "start": "682620",
    "end": "685020"
  },
  {
    "text": "that value along the y-axis.",
    "start": "685020",
    "end": "687490"
  },
  {
    "text": "And you can see that\nraw counts, it's",
    "start": "687490",
    "end": "689550"
  },
  {
    "text": "a very difficult distribution.",
    "start": "689550",
    "end": "691300"
  },
  {
    "text": "First of all, this goes all the\nway up to about 100 million,",
    "start": "691300",
    "end": "695820"
  },
  {
    "text": "and starting from 0.",
    "start": "695820",
    "end": "697350"
  },
  {
    "text": "Most things have quantities\nthat are close to 0.",
    "start": "697350",
    "end": "700440"
  },
  {
    "text": "And then you have this\nvery long thin tail",
    "start": "700440",
    "end": "702480"
  },
  {
    "text": "of things that are\nvery high frequency.",
    "start": "702480",
    "end": "704790"
  },
  {
    "text": "This highly skewed\ndistribution is",
    "start": "704790",
    "end": "706740"
  },
  {
    "text": "difficult for many\nmachine-learning methods,",
    "start": "706740",
    "end": "709140"
  },
  {
    "text": "both in terms of the skew\ntowards 0 and very low values",
    "start": "709140",
    "end": "712560"
  },
  {
    "text": "and also in terms of the\nrange of these x-axis values.",
    "start": "712560",
    "end": "715807"
  },
  {
    "text": "So we would like to\nmove away from it.",
    "start": "715807",
    "end": "717390"
  },
  {
    "text": "That's one motivating reason.",
    "start": "717390",
    "end": "719640"
  },
  {
    "text": "When we look at L2 norming\nand probability distributions,",
    "start": "719640",
    "end": "722190"
  },
  {
    "text": "they do kind of the same thing.",
    "start": "722190",
    "end": "723930"
  },
  {
    "text": "They're constraining the cell\nvalues to be between 0 and 1,",
    "start": "723930",
    "end": "727529"
  },
  {
    "text": "or roughly about\nbetween 0 and 1.",
    "start": "727530",
    "end": "730590"
  },
  {
    "text": "But they still have a\nheavy skew toward things",
    "start": "730590",
    "end": "732840"
  },
  {
    "text": "that are very small in\ntheir adjusted values",
    "start": "732840",
    "end": "735300"
  },
  {
    "text": "and their reweighted values.",
    "start": "735300",
    "end": "737519"
  },
  {
    "text": "Observed over expected is more\nextreme in that as is TF-IDF.",
    "start": "737520",
    "end": "741210"
  },
  {
    "text": "So again the observed\nover expected values",
    "start": "741210",
    "end": "744210"
  },
  {
    "text": "range quite high, up\nto about almost 50,000",
    "start": "744210",
    "end": "747435"
  },
  {
    "text": "which is somewhat better\nthan the raw counts,",
    "start": "747435",
    "end": "749310"
  },
  {
    "text": "but it's still very large\nin terms of its spread.",
    "start": "749310",
    "end": "752340"
  },
  {
    "text": "And we still have that\nheavy skew towards 0.",
    "start": "752340",
    "end": "755040"
  },
  {
    "text": "TF-IDF solves the range\nproblem down here,",
    "start": "755040",
    "end": "757932"
  },
  {
    "text": "because it's highly constrained\nin the set of values,",
    "start": "757932",
    "end": "760140"
  },
  {
    "text": "but it still has\na very heavy skew,",
    "start": "760140",
    "end": "762000"
  },
  {
    "text": "looking a lot like the\nraw count distribution.",
    "start": "762000",
    "end": "765830"
  },
  {
    "text": "From this perspective, it\nlooks like PMI and positive PMI",
    "start": "765830",
    "end": "768740"
  },
  {
    "text": "are really steps forward.",
    "start": "768740",
    "end": "770040"
  },
  {
    "text": "First of all, for PMI the\ndistribution of cell values",
    "start": "770040",
    "end": "773600"
  },
  {
    "text": "has this nice sort of\nnormal distribution.",
    "start": "773600",
    "end": "775940"
  },
  {
    "text": "And the values themselves\nare pretty constrained",
    "start": "775940",
    "end": "778070"
  },
  {
    "text": "to like negative 10 to 10.",
    "start": "778070",
    "end": "780320"
  },
  {
    "text": "And then for positive\nPMI, we simply",
    "start": "780320",
    "end": "782990"
  },
  {
    "text": "lop off all the negative\nvalues and make it back to 0.",
    "start": "782990",
    "end": "785690"
  },
  {
    "text": "So it's more skewed towards\n0, but not nearly as skewed",
    "start": "785690",
    "end": "789170"
  },
  {
    "text": "as all these other methods\nthat we're looking at.",
    "start": "789170",
    "end": "791700"
  },
  {
    "text": "So this is looking like PMI,\nand PPMI are good choices here,",
    "start": "791700",
    "end": "795440"
  },
  {
    "text": "just from the point of view of\ndeparting from the raw counts",
    "start": "795440",
    "end": "799700"
  },
  {
    "text": "and giving us a\ntractable distribution.",
    "start": "799700",
    "end": "802720"
  },
  {
    "text": "There's another perspective\nwhere we directly",
    "start": "802720",
    "end": "804699"
  },
  {
    "text": "compare in these matrices the\nco-occurrence count on log",
    "start": "804700",
    "end": "808330"
  },
  {
    "text": "scale, so it's doable, with the\nresult the new weighted cell",
    "start": "808330",
    "end": "811870"
  },
  {
    "text": "value.",
    "start": "811870",
    "end": "812470"
  },
  {
    "text": "What we're looking\nfor here presumably",
    "start": "812470",
    "end": "814660"
  },
  {
    "text": "is an overall lack\nof correlation.",
    "start": "814660",
    "end": "818019"
  },
  {
    "text": "I think we find that L2\nnorming and probabilities are",
    "start": "818020",
    "end": "820570"
  },
  {
    "text": "pretty good on this score.",
    "start": "820570",
    "end": "821860"
  },
  {
    "text": "They have kind of\nlow correlations.",
    "start": "821860",
    "end": "824440"
  },
  {
    "text": "And they make good use of\na large part of the scale",
    "start": "824440",
    "end": "827230"
  },
  {
    "text": "that they operate on.",
    "start": "827230",
    "end": "828910"
  },
  {
    "text": "Observed over expected\nhas a low correlation",
    "start": "828910",
    "end": "831190"
  },
  {
    "text": "with the cell counts,\nwhich looks initially good,",
    "start": "831190",
    "end": "833650"
  },
  {
    "text": "but it has its biggest problem\nthat the cell values are",
    "start": "833650",
    "end": "836500"
  },
  {
    "text": "strangely distributed and this\ncorrelation value might not",
    "start": "836500",
    "end": "839740"
  },
  {
    "text": "even be especially\nmeaningful, given",
    "start": "839740",
    "end": "841690"
  },
  {
    "text": "that we have a few outliers\nand then a whole lot of things",
    "start": "841690",
    "end": "844210"
  },
  {
    "text": "that are close to 0.",
    "start": "844210",
    "end": "845590"
  },
  {
    "text": "And TF-IDF is frankly similar\nlow correlation but maybe not",
    "start": "845590",
    "end": "849040"
  },
  {
    "text": "so trustworthy in terms\nof that correlation value.",
    "start": "849040",
    "end": "851800"
  },
  {
    "text": "Fundamentally, again, these look\nlike difficult distributions",
    "start": "851800",
    "end": "854649"
  },
  {
    "text": "of values to work with.",
    "start": "854650",
    "end": "856420"
  },
  {
    "text": "Again, PMI and positive\nPMI look really good.",
    "start": "856420",
    "end": "859600"
  },
  {
    "text": "Relatively low\ncorrelations, so we've",
    "start": "859600",
    "end": "861550"
  },
  {
    "text": "done something meaningful.",
    "start": "861550",
    "end": "862930"
  },
  {
    "text": "And both of these are\nmaking meaningful use",
    "start": "862930",
    "end": "865330"
  },
  {
    "text": "of a substantial part\nof the overall space",
    "start": "865330",
    "end": "868780"
  },
  {
    "text": "that they operate.",
    "start": "868780",
    "end": "869530"
  },
  {
    "text": "And we have lots of\ndifferent combinations",
    "start": "869530",
    "end": "871450"
  },
  {
    "text": "of cell values and underlying\nco-occurrence counts.",
    "start": "871450",
    "end": "874930"
  },
  {
    "text": "Something of a correlation,\nbut that could be good.",
    "start": "874930",
    "end": "877420"
  },
  {
    "text": "But we're not locked\ninto that correlation.",
    "start": "877420",
    "end": "879589"
  },
  {
    "text": "So we've done\nsomething meaningful.",
    "start": "879590",
    "end": "881920"
  },
  {
    "text": "To wrap up, let's do\nsome relationships",
    "start": "881920",
    "end": "883959"
  },
  {
    "text": "and generalizations,\njust some reminders here.",
    "start": "883960",
    "end": "886140"
  },
  {
    "text": "So a theme running through\nnearly all of these schemes",
    "start": "886140",
    "end": "888730"
  },
  {
    "text": "is that we want to\nreweight the cell",
    "start": "888730",
    "end": "890230"
  },
  {
    "text": "value relative to\nthe values we expect,",
    "start": "890230",
    "end": "892240"
  },
  {
    "text": "given the row and the column.",
    "start": "892240",
    "end": "893720"
  },
  {
    "text": "And we would like\nto make use of both",
    "start": "893720",
    "end": "895629"
  },
  {
    "text": "of those notions of context.",
    "start": "895630",
    "end": "898290"
  },
  {
    "text": "The magnitude of the counts\nmight be important, just",
    "start": "898290",
    "end": "901019"
  },
  {
    "text": "think about how 1, 10\nas a bit of evidence",
    "start": "901020",
    "end": "904500"
  },
  {
    "text": "and 1,000, 10,000\nas a bit of evidence",
    "start": "904500",
    "end": "907320"
  },
  {
    "text": "might be very different\nsituations in terms",
    "start": "907320",
    "end": "909630"
  },
  {
    "text": "of the evidence that\nyou have gathered.",
    "start": "909630",
    "end": "911910"
  },
  {
    "text": "Creating probability\ndistributions and lengths",
    "start": "911910",
    "end": "914160"
  },
  {
    "text": "normalizing will\nobscure that difference.",
    "start": "914160",
    "end": "916709"
  },
  {
    "text": "And that might be something\nthat you want to dwell on.",
    "start": "916710",
    "end": "919170"
  },
  {
    "start": "919170",
    "end": "922070"
  },
  {
    "text": "PMI and its variants\nwill amplify the values",
    "start": "922070",
    "end": "924170"
  },
  {
    "text": "of counts that are tiny\nrelative to their rows",
    "start": "924170",
    "end": "926690"
  },
  {
    "text": "and their columns.",
    "start": "926690",
    "end": "928168"
  },
  {
    "text": "That could be good because that\nmight be what you want to do,",
    "start": "928168",
    "end": "930710"
  },
  {
    "text": "find the things that are\nreally important and unusual.",
    "start": "930710",
    "end": "933320"
  },
  {
    "text": "Unfortunately,\nwith language data,",
    "start": "933320",
    "end": "934980"
  },
  {
    "text": "we have to watch out\nthat they might be noise.",
    "start": "934980",
    "end": "939360"
  },
  {
    "text": "And finally, TF-IDF\nseverely punishes words",
    "start": "939360",
    "end": "941970"
  },
  {
    "text": "that appear in many documents.",
    "start": "941970",
    "end": "943529"
  },
  {
    "text": "It behaves oddly\nfor dense matrices,",
    "start": "943530",
    "end": "945580"
  },
  {
    "text": "which can include the\nword by word matrices",
    "start": "945580",
    "end": "947850"
  },
  {
    "text": "that we're working with.",
    "start": "947850",
    "end": "948995"
  },
  {
    "text": "So you might\nproceed with caution",
    "start": "948995",
    "end": "950370"
  },
  {
    "text": "with that particular\nreweighting scheme",
    "start": "950370",
    "end": "952290"
  },
  {
    "text": "in the context of this course.",
    "start": "952290",
    "end": "954883"
  },
  {
    "text": "Finally, some code snippets.",
    "start": "954883",
    "end": "956050"
  },
  {
    "text": "I'm just showing off that\nour VSM module in the course",
    "start": "956050",
    "end": "958779"
  },
  {
    "text": "repository makes it really\neasy to do these reweighting",
    "start": "958780",
    "end": "961750"
  },
  {
    "text": "schemes, a lot--",
    "start": "961750",
    "end": "962620"
  },
  {
    "text": "all the ones that we've\ntalked about and more in fact.",
    "start": "962620",
    "end": "965800"
  },
  {
    "text": "And returning to the end of\nour vector comparison method,",
    "start": "965800",
    "end": "968470"
  },
  {
    "text": "you might recall that I\nlooked at the neighbors",
    "start": "968470",
    "end": "971079"
  },
  {
    "text": "of \"bad\" in this yelp5 matrix.",
    "start": "971080",
    "end": "973060"
  },
  {
    "text": "And it really didn't look good.",
    "start": "973060",
    "end": "974470"
  },
  {
    "text": "This does not look especially\nsemantically coherent.",
    "start": "974470",
    "end": "977500"
  },
  {
    "text": "When I take those\nunderlying counts",
    "start": "977500",
    "end": "979630"
  },
  {
    "text": "and I just adjust\nthem by positive PMI,",
    "start": "979630",
    "end": "982140"
  },
  {
    "text": "I start to see something\nthat looks quite semantically",
    "start": "982140",
    "end": "984760"
  },
  {
    "text": "coherent.",
    "start": "984760",
    "end": "985395"
  },
  {
    "text": "And I think we're\nstarting to see",
    "start": "985395",
    "end": "986770"
  },
  {
    "text": "the promise of these methods.",
    "start": "986770",
    "end": "988258"
  },
  {
    "text": "And this is really\njust the beginning",
    "start": "988258",
    "end": "989800"
  },
  {
    "text": "in terms of surfacing\nsemantically",
    "start": "989800",
    "end": "991510"
  },
  {
    "text": "coherent and\ninteresting information",
    "start": "991510",
    "end": "993430"
  },
  {
    "text": "from these underlying counts.",
    "start": "993430",
    "end": "995970"
  },
  {
    "start": "995970",
    "end": "1001000"
  }
]
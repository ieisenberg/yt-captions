[
  {
    "start": "0",
    "end": "73000"
  },
  {
    "text": "[Music] stanford university",
    "start": "620",
    "end": "6480"
  },
  {
    "text": "today's class is on responsible limits on data and technology data privacy ethics and new governance frameworks we",
    "start": "6480",
    "end": "12480"
  },
  {
    "text": "have over here three speakers who span various industries rob from the academia perspective as a political theorist matt",
    "start": "12480",
    "end": "20000"
  },
  {
    "text": "from government in the pentagon in dc and jeff with his experience on the industry side i'll kick off by",
    "start": "20000",
    "end": "26320"
  },
  {
    "text": "introducing our three panelists and also have just a few initial topics to cover around biases and algorithms privacy",
    "start": "26320",
    "end": "33600"
  },
  {
    "text": "surveillance ethical frameworks and the role of industry versus government so i'll start by introducing rob he's a",
    "start": "33600",
    "end": "40239"
  },
  {
    "text": "professor of political science at stanford he's also director of the center for ethics in society as well as",
    "start": "40239",
    "end": "46320"
  },
  {
    "text": "co-director of the center on philanthropy and civil society at stanford his work focuses on applied",
    "start": "46320",
    "end": "52079"
  },
  {
    "text": "ethics in addition to education inequality through all of philanthropy in the public sector and other topics on",
    "start": "52079",
    "end": "59120"
  },
  {
    "text": "democratic theory rob hopefully i capture that it's so hard to capture everything you're doing",
    "start": "59120",
    "end": "64559"
  },
  {
    "text": "well you missed the big one that's relevant which is i'm also now i'm directing too many things the associate",
    "start": "64559",
    "end": "70240"
  },
  {
    "text": "director of the institute for human-centered ai that is true that is another role that",
    "start": "70240",
    "end": "76000"
  },
  {
    "start": "73000",
    "end": "272000"
  },
  {
    "text": "rob has recently taken on as one of his additional stanford center directing",
    "start": "76000",
    "end": "81759"
  },
  {
    "text": "roles and also has launched the very popular ethics curriculum at stanford",
    "start": "81759",
    "end": "86880"
  },
  {
    "text": "targeted our computer scientists we also have matt williams he's been in defense and intelligence",
    "start": "86880",
    "end": "93600"
  },
  {
    "text": "community on the us government side for about 25 years he's currently on the staff of the chief of naval operations",
    "start": "93600",
    "end": "99840"
  },
  {
    "text": "for the u.s navy focused on information warfare he previously served as a special assistant to the director of",
    "start": "99840",
    "end": "105759"
  },
  {
    "text": "naval intelligence and in various leadership positions for the office of naval intelligence and the dia the",
    "start": "105759",
    "end": "112159"
  },
  {
    "text": "defense intelligence agency matt hopefully i captured everything you did i know some of it's top secret though so",
    "start": "112159",
    "end": "118079"
  },
  {
    "text": "we'll eliminate those parts from your bio and last but not least we have jeff wong who's global chief innovation",
    "start": "118079",
    "end": "124880"
  },
  {
    "text": "officer at ernst young he leads a team whose mission is to research and explore new technologies his experience spans",
    "start": "124880",
    "end": "131760"
  },
  {
    "text": "various parts of industry prior to joining ey that includes work at bcg the venture capital firm jafco ventures",
    "start": "131760",
    "end": "139040"
  },
  {
    "text": "jpmorgan ebay and also is affiliated with oxford sitting on their advisory",
    "start": "139040",
    "end": "144560"
  },
  {
    "text": "board for their entrepreneurship initiatives as well as for a non-profit organization that's focused on",
    "start": "144560",
    "end": "151280"
  },
  {
    "text": "increasing diversity and inclusion in ai so thank you all for joining us today i'll kick off with one hot topic that's",
    "start": "151280",
    "end": "158480"
  },
  {
    "text": "often discussed is discrimination and bias in algorithms and why should we care about discrimination and biases in",
    "start": "158480",
    "end": "165599"
  },
  {
    "text": "algorithms maybe we'll start with matt since i think based on some conversations we've had",
    "start": "165599",
    "end": "171120"
  },
  {
    "text": "the perspective on how you think about this from a military operations and government standpoint is fairly",
    "start": "171120",
    "end": "177280"
  },
  {
    "text": "different than what we often see in all that industry plays yeah sure absolutely thanks ernestine",
    "start": "177280",
    "end": "184560"
  },
  {
    "text": "we so so frankly discrimination you know and and and by season in algorithms is",
    "start": "184560",
    "end": "191200"
  },
  {
    "text": "important to military operations but as ernestine alluded to it's for slightly",
    "start": "191200",
    "end": "196239"
  },
  {
    "text": "different reason when we are conducting operations against adversaries whether they be kinetic or otherwise we want the",
    "start": "196239",
    "end": "202480"
  },
  {
    "text": "right answer so we don't want to go after the wrong target or to take the wrong steps or or frankly um think we're",
    "start": "202480",
    "end": "210239"
  },
  {
    "text": "understanding the intelligence in a different way than is actually uh the truth and so many times there any time",
    "start": "210239",
    "end": "216480"
  },
  {
    "text": "there are errors in that process whether that's cognitive biases in a human's mind or related biases in the algorithms",
    "start": "216480",
    "end": "223920"
  },
  {
    "text": "that's going to cause a problem for us and what we're especially worried about is people intentionally corrupting those",
    "start": "223920",
    "end": "229120"
  },
  {
    "text": "data sets or those algorithms and we are we do know that there are people out there and actually it's it happens all",
    "start": "229120",
    "end": "235120"
  },
  {
    "text": "over the regular internet where students actually go and manipulate manipulate the algorithm to get",
    "start": "235120",
    "end": "241280"
  },
  {
    "text": "different results i think what 10 years ago it was called a google bomb right to intentionally corrupt the algorithm of",
    "start": "241280",
    "end": "247360"
  },
  {
    "text": "the google search engine for for whatever reason same thing happens to us and we're worried about same thing can",
    "start": "247360",
    "end": "252959"
  },
  {
    "text": "happen to us and we're worried about adversaries either getting into our data sets or getting into our algorithms or",
    "start": "252959",
    "end": "260959"
  },
  {
    "text": "figuring out how to manipulate them from the outside so either presenting us with false data or misleading data that",
    "start": "260959",
    "end": "267759"
  },
  {
    "text": "ultimately uh directs our the end results of our algorithms in the wrong direction and a question for rob and",
    "start": "267759",
    "end": "274320"
  },
  {
    "start": "272000",
    "end": "447000"
  },
  {
    "text": "jeff what should we be doing to eliminate these sorts of biases yeah so ernest if i might jump in on",
    "start": "274320",
    "end": "281360"
  },
  {
    "text": "this question first i have to say i'm a little bit jealous that rob gets to wear like 52",
    "start": "281360",
    "end": "286960"
  },
  {
    "text": "different stanford hats and that matt has in his tagline some of it is top secret so i need to be doing better",
    "start": "286960",
    "end": "294000"
  },
  {
    "text": "better more interesting things in the world apparently now i'll actually see if you don't mind i want to address that",
    "start": "294000",
    "end": "299680"
  },
  {
    "text": "first question first which is why is it important so i'll take a little i'll take an industry view on this and and i",
    "start": "299680",
    "end": "306320"
  },
  {
    "text": "actually go back to thinking about redlining from the 1930s i think most people know it is but redlining was when",
    "start": "306320",
    "end": "313360"
  },
  {
    "text": "they literally drew maps and on maps they drew a red line and they marked certain communities as hazardous or high",
    "start": "313360",
    "end": "321039"
  },
  {
    "text": "risk and that went from the 1930s to i think the late 1960s i may be getting my dates",
    "start": "321039",
    "end": "327440"
  },
  {
    "text": "wrong and i think somebody on this call probably is a better expert than i am but that obviously led to who got credit",
    "start": "327440",
    "end": "333120"
  },
  {
    "text": "to buy homes start businesses et cetera build equity and obviously not obviously",
    "start": "333120",
    "end": "339199"
  },
  {
    "text": "but it was highly related to where the minorities were living at the time so in the 1930s 60 years after that so after",
    "start": "339199",
    "end": "346960"
  },
  {
    "text": "the 1960s when it was repealed 60 years after that we're still seeing the impact and effects of it i saw one stat where",
    "start": "346960",
    "end": "353520"
  },
  {
    "text": "three out of four of the communities that were redline are still basically in poverty so the echo of that sonic boom",
    "start": "353520",
    "end": "360800"
  },
  {
    "text": "of that redlining effort still echoes today despite it being 60 years later so",
    "start": "360800",
    "end": "366560"
  },
  {
    "text": "when i look at the context of why is it important to think about bias and",
    "start": "366560",
    "end": "372400"
  },
  {
    "text": "discrimination and make sure that in algorithms we don't have it today is because the implications of us getting",
    "start": "372400",
    "end": "379120"
  },
  {
    "text": "it wrong i would hate to think that we're sitting here in this era and then 60 years from now we did something we",
    "start": "379120",
    "end": "384560"
  },
  {
    "text": "should have made a better more distinct effort to make sure we took out that bias now so that 60 years from now oh",
    "start": "384560",
    "end": "390240"
  },
  {
    "text": "yeah the algorithm was doing something but we didn't recognize it and i think we've seen many high-profile failures",
    "start": "390240",
    "end": "397120"
  },
  {
    "text": "out there where credit was it was given to one gender but not the other the same household but",
    "start": "397120",
    "end": "403199"
  },
  {
    "text": "one gender but not the other there's no reason for that where we see distinct ethnic ethnicities bias in terms of",
    "start": "403199",
    "end": "411039"
  },
  {
    "text": "algorithms around talent talent who should be hired who should be interviewed questions so we've seen some",
    "start": "411039",
    "end": "416720"
  },
  {
    "text": "major failures around that so i think that when we are very public failures around so when i think about it i think",
    "start": "416720",
    "end": "422960"
  },
  {
    "text": "about that responsibility as well which is our responsibility to make sure that this doesn't echo through the the",
    "start": "422960",
    "end": "428960"
  },
  {
    "text": "generations because we didn't do something here i'll pause there because i've spoken long enough and i think rob maybe you",
    "start": "428960",
    "end": "435280"
  },
  {
    "text": "can answer that one and and ernestine's real question to us",
    "start": "435280",
    "end": "440560"
  },
  {
    "text": "so ernestine the question is what can we do to mitigate or eliminate algorithmic bias discrimination and i'm",
    "start": "440560",
    "end": "447360"
  },
  {
    "start": "447000",
    "end": "654000"
  },
  {
    "text": "sure you have lots of thoughts given the work that hai's been doing to right on the high center has been doing around",
    "start": "447360",
    "end": "452639"
  },
  {
    "text": "that yeah okay i'll say the first thing which i hope is obvious but",
    "start": "452639",
    "end": "458880"
  },
  {
    "text": "oftentimes doesn't seem to be obvious but the topic of algorithmic fairness or",
    "start": "458880",
    "end": "465039"
  },
  {
    "text": "algorithmic bias is something that we need to invest time to study and to",
    "start": "465039",
    "end": "470560"
  },
  {
    "text": "identify where the problems are because we want a world in which algorithmic models don't amplify the",
    "start": "470560",
    "end": "477840"
  },
  {
    "text": "already considerable array of human bias and human discrimination for the same",
    "start": "477840",
    "end": "483120"
  },
  {
    "text": "reasons that jeff just described algorithmic models have a veneer of scientific authority or mathematical",
    "start": "483120",
    "end": "490000"
  },
  {
    "text": "objectivity and therefore can amplify biases that are baked in whether it's",
    "start": "490000",
    "end": "495759"
  },
  {
    "text": "through the training set the design of the model the particular ways it's deployed with a human in the loop or not",
    "start": "495759",
    "end": "501440"
  },
  {
    "text": "in the loop so basically if you care about fairness in the world you should also care about",
    "start": "501440",
    "end": "507199"
  },
  {
    "text": "algorithms because that's where a lot of decision making is now being made",
    "start": "507199",
    "end": "512399"
  },
  {
    "text": "what can we do about algorithmic bias and discrimination the the first thing to understand is",
    "start": "512399",
    "end": "518479"
  },
  {
    "text": "that there are many different places where bias and discrimination can creep into an algorithm from the",
    "start": "518479",
    "end": "525839"
  },
  {
    "text": "choice of the training data from the design of the algorithmic model to",
    "start": "525839",
    "end": "531680"
  },
  {
    "text": "various deployment circumstances and i'm just mentioning several of the sort of places in which bias and discrimination",
    "start": "531680",
    "end": "538640"
  },
  {
    "text": "can creep in and i'll end just this sort of overview by",
    "start": "538640",
    "end": "544000"
  },
  {
    "text": "saying something perhaps to a cs or computer science or engineer crowd might",
    "start": "544000",
    "end": "549600"
  },
  {
    "text": "seem as a radical idea but which to a philosopher seems rather ordinary which is that the",
    "start": "549600",
    "end": "555680"
  },
  {
    "text": "the very work of being an engineer of creating an algorithmic model as a",
    "start": "555680",
    "end": "560839"
  },
  {
    "text": "programmer requires that the problem you're trying to solve be",
    "start": "560839",
    "end": "567000"
  },
  {
    "text": "computationally tractable you can't make an algorithmic model that has a",
    "start": "567000",
    "end": "572240"
  },
  {
    "text": "predictive accuracy without mathematically operationalizing the",
    "start": "572240",
    "end": "577440"
  },
  {
    "text": "various things that you want the model to represent which is to say you need to try to find",
    "start": "577440",
    "end": "583360"
  },
  {
    "text": "various ways to make computationally representable what",
    "start": "583360",
    "end": "589440"
  },
  {
    "text": "fairness or anti-discrimination happens to be and in the real world the world of human",
    "start": "589440",
    "end": "596000"
  },
  {
    "text": "beings fairness is not something easily reduced to a mathematical theorem or",
    "start": "596000",
    "end": "601680"
  },
  {
    "text": "property or equation which is to say fairness can differ in different social circumstances",
    "start": "601680",
    "end": "607760"
  },
  {
    "text": "and when that's the case you get what we now think is familiar in computer science you get a set of impossibility",
    "start": "607760",
    "end": "613839"
  },
  {
    "text": "results if you choose fairness specification a in some circumstances",
    "start": "613839",
    "end": "620000"
  },
  {
    "text": "and you also think in other circumstances it's better to choose fairness circumstance b",
    "start": "620000",
    "end": "625360"
  },
  {
    "text": "you can't plug them both equally into an algorithmic model where they work equally well in any situation you have",
    "start": "625360",
    "end": "632240"
  },
  {
    "text": "to make some fundamental choices and those fundamental choices mean that in different circumstances the models",
    "start": "632240",
    "end": "638320"
  },
  {
    "text": "will perform with bias and then sometimes without bias in other words we can't reduce justice to a math equation",
    "start": "638320",
    "end": "646800"
  },
  {
    "text": "philosophers and the rest of society deserve a seat at the table when putting algorithms together and deciding where",
    "start": "646800",
    "end": "653040"
  },
  {
    "text": "they're deployed so ashley in our class has i love it when we actually present the question in the other way so she",
    "start": "653040",
    "end": "659440"
  },
  {
    "start": "654000",
    "end": "980000"
  },
  {
    "text": "asks are there any cases that algorithmic biases are beneficial",
    "start": "659440",
    "end": "664560"
  },
  {
    "text": "beneficial to whom or to what that's a good rhetorical question i don't know if ashley has additional",
    "start": "664560",
    "end": "670079"
  },
  {
    "text": "thoughts on that or i just thought in general like maybe some like medical cases or like",
    "start": "670079",
    "end": "676959"
  },
  {
    "text": "some studies maybe algorithmic biases might increase the the accuracy of like the outcome",
    "start": "676959",
    "end": "684000"
  },
  {
    "text": "yeah sure i'll take a crack at that i think if at the end of this class i try to",
    "start": "684000",
    "end": "690399"
  },
  {
    "text": "leave everyone with it with a single message if i have had to distill what i most hope to communicate today",
    "start": "690399",
    "end": "696480"
  },
  {
    "text": "it's that whether we're engineers or product managers or ceos or venture",
    "start": "696480",
    "end": "703680"
  },
  {
    "text": "capitalists or public policy makers our work involves confronting value",
    "start": "703680",
    "end": "710079"
  },
  {
    "text": "trade-offs trade-offs where there's no singularly correct answer no single",
    "start": "710079",
    "end": "715440"
  },
  {
    "text": "optimum to reach we have to balance the various different things that we care",
    "start": "715440",
    "end": "721200"
  },
  {
    "text": "about in the world like privacy versus security which i know is another topic on our minds for today",
    "start": "721200",
    "end": "727120"
  },
  {
    "text": "if you think that life involves our professional lives involved technology involves confronting",
    "start": "727120",
    "end": "733120"
  },
  {
    "text": "value trade-offs then there are times where we're trying to figure out whether an",
    "start": "733120",
    "end": "738959"
  },
  {
    "text": "algorithmic model with whatever bias it has is nevertheless an improvement over",
    "start": "738959",
    "end": "744720"
  },
  {
    "text": "the relatively abysmal performance of humans in making decisions maybe we count the algorithmic model as a",
    "start": "744720",
    "end": "751920"
  },
  {
    "text": "incremental improvement over the relatively embarrassing performance of humans alternatively let me give you a",
    "start": "751920",
    "end": "758320"
  },
  {
    "text": "particular example ashley jeff mentioned the the lending models of credit scoring",
    "start": "758320",
    "end": "763839"
  },
  {
    "text": "and that type of stuff another place where we find algorithmic model algorithmic models used all the time",
    "start": "763839",
    "end": "769360"
  },
  {
    "text": "probably you've all been yourself subjected to them are are hiring decisions whenever you have huge",
    "start": "769360",
    "end": "774959"
  },
  {
    "text": "applicant pools lots of companies now say ai screening models for",
    "start": "774959",
    "end": "780480"
  },
  {
    "text": "resumes sometimes companies will say can you provide us with an algorithmic",
    "start": "780480",
    "end": "786800"
  },
  {
    "text": "hiring tool that gives a bigger pool of minorities or women because we're trying",
    "start": "786800",
    "end": "792480"
  },
  {
    "text": "to overcome our human tendency in this company in this sector to hire a bunch of white",
    "start": "792480",
    "end": "798800"
  },
  {
    "text": "dudes and the answer is that comes at a certain cost you're plugging as it were",
    "start": "798800",
    "end": "804000"
  },
  {
    "text": "a certain type of bias into the model to overcome the history of human bias",
    "start": "804000",
    "end": "809600"
  },
  {
    "text": "and then you have all kinds of legal questions to confront about whether or not different types of waiting attached",
    "start": "809600",
    "end": "815760"
  },
  {
    "text": "to people on the basis of sex or on race is even legally permissible",
    "start": "815760",
    "end": "821279"
  },
  {
    "text": "this just introduces the fact that fairness is a social thing not a",
    "start": "821279",
    "end": "826560"
  },
  {
    "text": "mathematical thing and we have to make choices and those choices",
    "start": "826560",
    "end": "832320"
  },
  {
    "text": "shouldn't be in the hands of engineers alone now rob i'm going to jump in on because",
    "start": "832320",
    "end": "837920"
  },
  {
    "text": "i think you spoke so well on this so i just want to emphasize i think that to your point",
    "start": "837920",
    "end": "843519"
  },
  {
    "text": "there's a matter of perspective on this right so the bias works for those who are advantaged by it and we i think in",
    "start": "843519",
    "end": "851600"
  },
  {
    "text": "the sensibility of this class and a sensibility i think we all agree and i agree with we're saying oh yes let's",
    "start": "851600",
    "end": "857519"
  },
  {
    "text": "bias it towards the underrepresented classes so that we can tune an engine",
    "start": "857519",
    "end": "862800"
  },
  {
    "text": "that overcomes i think that's a a perfect example of how we can tune something and say now okay the bias the",
    "start": "862800",
    "end": "870399"
  },
  {
    "text": "the tuning it in is working for us in the overall system but there is obviously a matter of",
    "start": "870399",
    "end": "876000"
  },
  {
    "text": "perspective right for those who did get credit or do get loans it's working well for them",
    "start": "876000",
    "end": "882079"
  },
  {
    "text": "loans and credit is more available for them so i think there is a matter of perspective it's interesting because as we get further into the some of the",
    "start": "882079",
    "end": "888480"
  },
  {
    "text": "questions that were posed prior to the prior to starting sorry i think getting into discussions about ethics and whose",
    "start": "888480",
    "end": "895199"
  },
  {
    "text": "perspective of ethics are we talking about or whose perspective of bias are we talking about because i think that",
    "start": "895199",
    "end": "900800"
  },
  {
    "text": "becomes an important um factor when we think about frameworks and how we want to how you might want to think about it",
    "start": "900800",
    "end": "908880"
  },
  {
    "text": "that's a great point jeff and rob and i think both of your discussions",
    "start": "908880",
    "end": "913920"
  },
  {
    "text": "clearly highlight the distinction that i was trying to lead off with i don't think it was particularly eloquent if",
    "start": "913920",
    "end": "919440"
  },
  {
    "text": "we're talking about bias as being a challenge to the fairness of how we treat others that's not what we care",
    "start": "919440",
    "end": "925440"
  },
  {
    "text": "about generally when it comes to formal you know operations against foreign adversaries we care about the same",
    "start": "925440",
    "end": "932480"
  },
  {
    "text": "technical things that occur in the bias in a data set that does not represent uh reality or as close to reality as we",
    "start": "932480",
    "end": "939279"
  },
  {
    "text": "could or an algorithm that was somehow programmed in a way that corrupts the sense of recreating reality and so",
    "start": "939279",
    "end": "946160"
  },
  {
    "text": "that's a huge distinction that i often i i frankly find comes down to our choice of words",
    "start": "946160",
    "end": "952399"
  },
  {
    "text": "bias is the right word for both sides of that uh discussion but our language i don't think has as the same number of",
    "start": "952399",
    "end": "959120"
  },
  {
    "text": "nuances that it could in some of these same number of definitions or words to",
    "start": "959120",
    "end": "964160"
  },
  {
    "text": "really make those distinctions as i go forward that's mo what i just described is mainly what i'm what i'm referring to",
    "start": "964160",
    "end": "970000"
  },
  {
    "text": "a lot of these things not to say the us government doesn't have interests in protecting fairness for our own citizens but that's",
    "start": "970000",
    "end": "977440"
  },
  {
    "text": "not the general dod focus all good points for the sake of time",
    "start": "977440",
    "end": "983120"
  },
  {
    "text": "want to cover the next topic of privacy and surveillance specifically given that we're in the middle of a pandemic the",
    "start": "983120",
    "end": "989199"
  },
  {
    "text": "topic of vaccine passports which perhaps has become a little politicized as well in terms of some republican governors",
    "start": "989199",
    "end": "996160"
  },
  {
    "text": "signing executive orders limiting or prohibiting the use of vaccine passports and critics saying that they have",
    "start": "996160",
    "end": "1001920"
  },
  {
    "text": "privacy concerns around that in general how should we think about balancing an individual's right to",
    "start": "1001920",
    "end": "1007600"
  },
  {
    "text": "control their personal information versus the public benefits of containing a virus",
    "start": "1007600",
    "end": "1013759"
  },
  {
    "text": "so i'll jump in first on this one or see if the other panels don't mind so",
    "start": "1013759",
    "end": "1019199"
  },
  {
    "text": "i i found this and and this sort of builds off of what i was describing before whose sense of privacy and whose",
    "start": "1019199",
    "end": "1025678"
  },
  {
    "text": "sense of concern and i come and i think i said this before but i come from a i grew up in california i'm",
    "start": "1025679",
    "end": "1031760"
  },
  {
    "text": "down the street from stanford right now so i come from a very west coast central very american-centric view and version",
    "start": "1031760",
    "end": "1038400"
  },
  {
    "text": "of privacy and you might have heard us talking about some of the vaccine distribution and",
    "start": "1038400",
    "end": "1044400"
  },
  {
    "text": "sorry the shutdown of the county sort of at the top of the call before before the class officially started because i come",
    "start": "1044400",
    "end": "1050799"
  },
  {
    "text": "from the from that bias right the bias that says it's better to be i want my data to be more private i want it to be",
    "start": "1050799",
    "end": "1057600"
  },
  {
    "text": "able to control it and i want it i want that i want to be safe so i want to shut down the i want to be mathematically",
    "start": "1057600",
    "end": "1064160"
  },
  {
    "text": "safe and scientific and all that i think though when you take a step back there are different areas of the world so i",
    "start": "1064160",
    "end": "1070160"
  },
  {
    "text": "won't do the state to state thing and keep it domestic but if you look at different areas of the world there are",
    "start": "1070160",
    "end": "1075440"
  },
  {
    "text": "very different senses of privacy and i think that looking at some of the backgrounds of the people who are on the",
    "start": "1075440",
    "end": "1081039"
  },
  {
    "text": "call i think that you recognize that there are very different sensibilities and what i'll say is so i have a very",
    "start": "1081039",
    "end": "1087280"
  },
  {
    "text": "good somebody who's on my team in china living in hong kong and what i'll tell you is they have obviously a very",
    "start": "1087280",
    "end": "1092880"
  },
  {
    "text": "different sense of privacy right they have required vaccine but covered tracking contact",
    "start": "1092880",
    "end": "1098960"
  },
  {
    "text": "tracing on their phones built into their apps required for them to be able to",
    "start": "1098960",
    "end": "1104160"
  },
  {
    "text": "navigate through society and so you could say wow they they really have a loss of privacy in comparison to the us",
    "start": "1104160",
    "end": "1111360"
  },
  {
    "text": "on the other hand and we are ewi so we are 300 000 person global firm every major country every major city we had",
    "start": "1111360",
    "end": "1118480"
  },
  {
    "text": "one office shut down in china through the entire pandemic in the u.s and europe all offices shut",
    "start": "1118480",
    "end": "1125840"
  },
  {
    "text": "down all of our offices shut down so their loss of privacy",
    "start": "1125840",
    "end": "1130880"
  },
  {
    "text": "came with the trade off of they were able to keep their country going and everyone knows the gdp stats and their country is actually doing quite well",
    "start": "1130880",
    "end": "1137120"
  },
  {
    "text": "even through this pandemic and i think that's i'm not arguing for one or the other i i'm just arguing to",
    "start": "1137120",
    "end": "1144240"
  },
  {
    "text": "recognize that there are trade-offs to be made around this and the sensibilities of",
    "start": "1144240",
    "end": "1149600"
  },
  {
    "text": "different groups are just very different while i take a very western view very u.s centric view of our privacy and how",
    "start": "1149600",
    "end": "1156640"
  },
  {
    "text": "we should be how that should be looked at i would say they look at it very differently even individually my team",
    "start": "1156640",
    "end": "1162880"
  },
  {
    "text": "there looks at it very differently and they're very happy that about the fact that they can go and have dinner and they never had to go outside in the",
    "start": "1162880",
    "end": "1169280"
  },
  {
    "text": "whole bit and they never had to shut down i just wanted to there's different sensibilities and i'd like to recognize",
    "start": "1169280",
    "end": "1174960"
  },
  {
    "text": "that those different sensibilities allow for different outcomes there is a follow-up question from lorenz who's in",
    "start": "1174960",
    "end": "1181280"
  },
  {
    "start": "1178000",
    "end": "1599000"
  },
  {
    "text": "the class in which kind of two ways of posing the question which is one in a world where a company's competitive",
    "start": "1181280",
    "end": "1187440"
  },
  {
    "text": "advantage is strongly influenced by its access to and the use of personal data how can governments and responsible",
    "start": "1187440",
    "end": "1194400"
  },
  {
    "text": "companies preserve privacy and user data and in your view how can we prevent a",
    "start": "1194400",
    "end": "1200480"
  },
  {
    "text": "race to the bottom policy making that forfeits privacy security and human",
    "start": "1200480",
    "end": "1205600"
  },
  {
    "text": "rights in the name of giving domestic companies a competitive advantage i'll take a first pass if no one else wants",
    "start": "1205600",
    "end": "1212000"
  },
  {
    "text": "to hop in matt do you want to start or shall i you first okay",
    "start": "1212000",
    "end": "1218320"
  },
  {
    "text": "i'm just going to inhabit as an answer to that question stereotypical economist because i don't think we actually need a",
    "start": "1218320",
    "end": "1224880"
  },
  {
    "text": "whole bunch of new concepts or tools to to try to give an initial answer to that",
    "start": "1224880",
    "end": "1230000"
  },
  {
    "text": "question what we need to think about is that tech companies at the moment like any",
    "start": "1230000",
    "end": "1236480"
  },
  {
    "text": "line of business and industry sometimes produce negative externalities and in the absence of a level playing",
    "start": "1236480",
    "end": "1244240"
  },
  {
    "text": "field and a system of rules imposed by a third party typically a government",
    "start": "1244240",
    "end": "1249679"
  },
  {
    "text": "those externalities will continue to be produced rationally by companies if you",
    "start": "1249679",
    "end": "1254799"
  },
  {
    "text": "don't have to pay for the chemical sludge that you push into the stream and you can get away with it as a",
    "start": "1254799",
    "end": "1260400"
  },
  {
    "text": "competitive advantage to your more environmentally sensible competitor you",
    "start": "1260400",
    "end": "1265600"
  },
  {
    "text": "have a financial incentive to continue discharging the sludge the same thing is true with say clear",
    "start": "1265600",
    "end": "1271440"
  },
  {
    "text": "vue ai and facial recognition right now we might have a bunch of responsible tech companies who say we are not going",
    "start": "1271440",
    "end": "1277440"
  },
  {
    "text": "to sell facial recognition technology to police departments for the use on body cameras but when clearview ai comes",
    "start": "1277440",
    "end": "1284320"
  },
  {
    "text": "along and there's a race to the bottom because there's no set of rules that try to limit a race to the bottom or to",
    "start": "1284320",
    "end": "1292320"
  },
  {
    "text": "internalize the externalities you get predictable rational behavior that leads to",
    "start": "1292320",
    "end": "1298960"
  },
  {
    "text": "sub-optimal negative outcomes so this is just a standard issue economist's case",
    "start": "1298960",
    "end": "1305039"
  },
  {
    "text": "for where it is that a third-party independent actor needs a step in order to limit negative externalities and to",
    "start": "1305039",
    "end": "1310720"
  },
  {
    "text": "prevent a competitive dynamic in which it's rational to race to the bottom and i would jump onto that and say",
    "start": "1310720",
    "end": "1318960"
  },
  {
    "text": "pairing your answer with what jeff said earlier how do we define those externalities it's all about what we",
    "start": "1318960",
    "end": "1324640"
  },
  {
    "text": "not define them but how do we say that they're negative right it's it's all about what our principles are related to",
    "start": "1324640",
    "end": "1330000"
  },
  {
    "text": "privacy and security in our country and as jeff same as jeff i'm also a californian i also subscribe to the",
    "start": "1330000",
    "end": "1337360"
  },
  {
    "text": "californian western sense of privacy and so forth and i'm not here to be the big",
    "start": "1337360",
    "end": "1342400"
  },
  {
    "text": "government person who says oh we should have access to everything and we should be able to read your email in fact i'm",
    "start": "1342400",
    "end": "1347679"
  },
  {
    "text": "reading your email now no i'm not but and so when we compare ourselves to the these other countries",
    "start": "1347679",
    "end": "1353840"
  },
  {
    "text": "we have to decide internally as a country what's important to us right and when we",
    "start": "1353840",
    "end": "1359039"
  },
  {
    "text": "do that then the governments can step in and create those rule sets and in fact our system is designed such that",
    "start": "1359039",
    "end": "1366080"
  },
  {
    "text": "government is typically the slow actor so we actually let the public debate occur and for you know good or ill",
    "start": "1366080",
    "end": "1372640"
  },
  {
    "text": "government comes in later and decides okay here's here are the rules that we're going to live by and here's how",
    "start": "1372640",
    "end": "1377679"
  },
  {
    "text": "the policies we're going to follow either through legislation or internal government policies whatever happens to be and it is not forward leaning and i",
    "start": "1377679",
    "end": "1384240"
  },
  {
    "text": "think that in many ways is one of the protections that we have is that slow bureaucracy which obviously has plenty",
    "start": "1384240",
    "end": "1390480"
  },
  {
    "text": "of negative negative side effects but we don't have some random people in the government leading the charge on what",
    "start": "1390480",
    "end": "1396400"
  },
  {
    "text": "those policies should be it's much more reactive i'm just laughing at matt's uh reading",
    "start": "1396400",
    "end": "1402080"
  },
  {
    "text": "my email now comment if he was reading my email now he'd be so bored he'd probably be falling asleep but just",
    "start": "1402080",
    "end": "1408559"
  },
  {
    "text": "but just that says hang on because i think these are really fantastic questions from again the class it's",
    "start": "1408559",
    "end": "1414640"
  },
  {
    "text": "really good and thoughtful i want to recognize like what rob was saying about",
    "start": "1414640",
    "end": "1419760"
  },
  {
    "text": "inside an industry or a company's facial recognition was his example you also have to think about i think i would",
    "start": "1419760",
    "end": "1425760"
  },
  {
    "text": "argue the group should think about the global nature of that competition so there is a lot of advocacy in the us",
    "start": "1425760",
    "end": "1432880"
  },
  {
    "text": "for certain policies we see the eu with this gdpr privacy policies from before",
    "start": "1432880",
    "end": "1438240"
  },
  {
    "text": "as a model but you can also recognize that the difficulties of creating the",
    "start": "1438240",
    "end": "1444720"
  },
  {
    "text": "most advanced technologies called ai driven technologies inside of the eu with those data privacy policies",
    "start": "1444720",
    "end": "1452720"
  },
  {
    "text": "involved with somebody from the business side who invests in building ai systems and platforms for us and obviously we do",
    "start": "1452720",
    "end": "1460159"
  },
  {
    "text": "it as a firm for our our clients as well you clearly can recognize the financial",
    "start": "1460159",
    "end": "1465360"
  },
  {
    "text": "differences of following those policies we we obviously need to follow all policies not just because we are",
    "start": "1465360",
    "end": "1472400"
  },
  {
    "text": "a global firm but because we are but the nature of the work that we do requires us to be very careful about following",
    "start": "1472400",
    "end": "1479039"
  },
  {
    "text": "regulatory policy everywhere and so for us to follow the eu regulatory policy is",
    "start": "1479039",
    "end": "1485120"
  },
  {
    "text": "simply more expensive than doing in the u.s and simply very",
    "start": "1485120",
    "end": "1490240"
  },
  {
    "text": "different from doing things in china and as you think about the ecosystem while it's nice to say hey in the us we're",
    "start": "1490240",
    "end": "1497120"
  },
  {
    "text": "going to decide to do x y or z because that's feels good for us i just would",
    "start": "1497120",
    "end": "1502400"
  },
  {
    "text": "think that governments need to recognize the broader implications it's not just an ecosystem of the us companies it's",
    "start": "1502400",
    "end": "1509840"
  },
  {
    "text": "the facial recognition companies exist in china the insurance company that",
    "start": "1509840",
    "end": "1515200"
  },
  {
    "text": "exists in china the financial services company exists in china nina that",
    "start": "1515200",
    "end": "1521039"
  },
  {
    "text": "will have better math if you it would because they have lower requirements on privacy therefore their",
    "start": "1521039",
    "end": "1527360"
  },
  {
    "text": "data is better therefore their algorithms are better just philosophically and so when you think about what policies and ethics you want",
    "start": "1527360",
    "end": "1534640"
  },
  {
    "text": "to apply for your particular area of the world you have to recognize that global ecosystem that it may not be clear of",
    "start": "1534640",
    "end": "1540880"
  },
  {
    "text": "you it may be insert name of some chinese company who's able to access data in a better way",
    "start": "1540880",
    "end": "1547520"
  },
  {
    "text": "that is able to come in and say yeah no we'll sell to your police force and so the police force obviously needing to",
    "start": "1547520",
    "end": "1553520"
  },
  {
    "text": "find the best answer for their needs buys from that company is that an outcome that you want",
    "start": "1553520",
    "end": "1559440"
  },
  {
    "text": "it's it all works within this broader system again not arguing that one's better than the other we should make",
    "start": "1559440",
    "end": "1565039"
  },
  {
    "text": "decisions or not i just want to recognize that when we make these decisions it's not just in the isolation",
    "start": "1565039",
    "end": "1570320"
  },
  {
    "text": "of your industry or even your country that's a great point jeff and i think that is actually a responsibility of the",
    "start": "1570320",
    "end": "1578080"
  },
  {
    "text": "foreign policy establishment is to say hey if we make these internal decisions",
    "start": "1578080",
    "end": "1583120"
  },
  {
    "text": "especially as we're a little more inward focused these days these are the repercussions that so we need to have",
    "start": "1583120",
    "end": "1589039"
  },
  {
    "text": "that debate but the only way you get that knowledge and transmit it is to the average citizen is through ambassadors",
    "start": "1589039",
    "end": "1596000"
  },
  {
    "text": "and and state department and so forth rob so i would love for you to answer",
    "start": "1596000",
    "end": "1601120"
  },
  {
    "text": "this question that came from oleg in our class given the differences between china's approach versus that of the",
    "start": "1601120",
    "end": "1607200"
  },
  {
    "text": "united states regarding data privacy what realistically is the us government",
    "start": "1607200",
    "end": "1612480"
  },
  {
    "text": "and corporate sector going to do about that and similarly spencer also asks more broadening it beyond china how do",
    "start": "1612480",
    "end": "1619600"
  },
  {
    "text": "you anticipate the us to respond to other countries policies moving forward yeah let me emphasize first that i'm no",
    "start": "1619600",
    "end": "1626720"
  },
  {
    "text": "foreign policy expert and i don't even really even have public policy expertise what i feel like i do have some",
    "start": "1626720",
    "end": "1632400"
  },
  {
    "text": "expertise in is democratic theory and understanding of what makes democracy",
    "start": "1632400",
    "end": "1638080"
  },
  {
    "text": "distinctively valuable but having participated in a number of these conversations and having taught",
    "start": "1638080",
    "end": "1643760"
  },
  {
    "text": "this class in which these geopolitical issues arise for a couple of years at least i say a few things but emphasize",
    "start": "1643760",
    "end": "1649039"
  },
  {
    "text": "the tentativeness here of them so number one is i would love to see a much greater r d budget produced not",
    "start": "1649039",
    "end": "1656320"
  },
  {
    "text": "merely by venture capitalists but democratic governments to invest in particular and frontier technologies in",
    "start": "1656320",
    "end": "1662320"
  },
  {
    "text": "ai in order that we can try to produce technological breakthroughs not merely",
    "start": "1662320",
    "end": "1668960"
  },
  {
    "text": "in the current paradigm of how it is that in particular ai is working which",
    "start": "1668960",
    "end": "1674159"
  },
  {
    "text": "is a kind of centralized architecture in which enormous data pools are coupled with the",
    "start": "1674159",
    "end": "1680880"
  },
  {
    "text": "power of compute in order to produce astonishing results i would love to see",
    "start": "1680880",
    "end": "1686880"
  },
  {
    "text": "frontier breakthroughs that produce decentralized architectures so that the same type of",
    "start": "1686880",
    "end": "1693399"
  },
  {
    "text": "decentralization that is inherent to the benefit of a democratic government in",
    "start": "1693399",
    "end": "1698960"
  },
  {
    "text": "other words we don't have it as it were an authoritarian architecture of ai mapped onto a democratic architecture of",
    "start": "1698960",
    "end": "1705919"
  },
  {
    "text": "our political system that's part what in my view benefits china hundreds of",
    "start": "1705919",
    "end": "1711440"
  },
  {
    "text": "millions of people abound a porous boundary between the government and the commercial industry and then an",
    "start": "1711440",
    "end": "1718159"
  },
  {
    "text": "unrivaled data pool that no other industry or country has",
    "start": "1718159",
    "end": "1723360"
  },
  {
    "text": "if we can produce decentralized architectures that itself would be a beneficial development for democracy as",
    "start": "1723360",
    "end": "1731120"
  },
  {
    "text": "well as then for the innovators on the frontier that would be my first recipe as it were",
    "start": "1731120",
    "end": "1737840"
  },
  {
    "text": "and as i already put in the chat the the goal would be to stop the frame or you",
    "start": "1737840",
    "end": "1743440"
  },
  {
    "text": "know break out of the frame of america innovates europe regulates and there's",
    "start": "1743440",
    "end": "1748960"
  },
  {
    "text": "competition between democracies and instead get democratic cooperation to",
    "start": "1748960",
    "end": "1754399"
  },
  {
    "text": "counter the geopolitical rise of digital authoritarianism thanks for sharing that rob i do want to",
    "start": "1754399",
    "end": "1760799"
  },
  {
    "start": "1759000",
    "end": "1923000"
  },
  {
    "text": "touch on the topic of ethical frameworks both matt how you see it from your seat",
    "start": "1760799",
    "end": "1765919"
  },
  {
    "text": "within government and also rob some of your efforts in terms of teaching ethics as well uh question for matt first is in",
    "start": "1765919",
    "end": "1772159"
  },
  {
    "text": "terms of the dod recently launched a new framework on ethical principles for ai and the ic the intelligence community",
    "start": "1772159",
    "end": "1778320"
  },
  {
    "text": "also has its own principles of ai ethics for the intelligence community how do you think we should think about",
    "start": "1778320",
    "end": "1784640"
  },
  {
    "text": "developing and using ai to further government's security objectives and balancing that with some of these",
    "start": "1784640",
    "end": "1790720"
  },
  {
    "text": "ethical frameworks and principles great question so i think we so dod in my opinion is",
    "start": "1790720",
    "end": "1799360"
  },
  {
    "text": "and the government writ large is actually way behind in all kinds of ways and a lot of it is",
    "start": "1799360",
    "end": "1806480"
  },
  {
    "text": "related to thought leadership when it comes to ai ethics all the stuff that rob just mentioned all the investments that the us government should be",
    "start": "1806480",
    "end": "1813520"
  },
  {
    "text": "investing in those things and we we just have chosen not to over the past decades and in fact our only serious investment",
    "start": "1813520",
    "end": "1820240"
  },
  {
    "text": "in ai has occurred in the last five years putting real money money to it and so",
    "start": "1820240",
    "end": "1825679"
  },
  {
    "text": "when you look at the dod ai ethics framework if if you read it i'll just",
    "start": "1825679",
    "end": "1830880"
  },
  {
    "text": "quickly tell you the the each one is a single word so it's responsible equitable traceable reliable and",
    "start": "1830880",
    "end": "1836399"
  },
  {
    "text": "governable a lot of those actually are a little more focused on basically what we call",
    "start": "1836399",
    "end": "1842960"
  },
  {
    "text": "about protecting this person so using ai internal to to provide services to our citizens but",
    "start": "1842960",
    "end": "1849520"
  },
  {
    "text": "in in fact we should probably want uh to think about how do we use ai against",
    "start": "1849520",
    "end": "1854880"
  },
  {
    "text": "people that we don't like so much and do we really want them to be responsible do we really want ai to be equitable when",
    "start": "1854880",
    "end": "1861279"
  },
  {
    "text": "it comes to challenging an adversary and so i say that because a lot of the discussion",
    "start": "1861279",
    "end": "1866799"
  },
  {
    "text": "even on this call has focused on how do we apply ai ethically to to our citizens but that's not really",
    "start": "1866799",
    "end": "1874799"
  },
  {
    "text": "what the department of defense does it does you know it does some of it so my my i think my thoughts on that is we",
    "start": "1874799",
    "end": "1881760"
  },
  {
    "text": "actually need to employ concepts like we do intelligence collection where we actually specifically have two sets of rules we",
    "start": "1881760",
    "end": "1888799"
  },
  {
    "text": "have sets of rules that we use involving u.s persons and that's u.s citizens corporations or people that we even",
    "start": "1888799",
    "end": "1894640"
  },
  {
    "text": "suspect to be have connections to the united states and people that are not us first or groups that are not u.s persons",
    "start": "1894640",
    "end": "1901760"
  },
  {
    "text": "but it comes down at the end of the day it comes down to really sitting down and thinking through those rule sets which",
    "start": "1901760",
    "end": "1906960"
  },
  {
    "text": "frankly you know as i i opened with i think we're really behind on when it comes to",
    "start": "1906960",
    "end": "1912799"
  },
  {
    "text": "when it comes to thought leadership in in these areas and i'd like to see more investment in both the thinking and the",
    "start": "1912799",
    "end": "1918080"
  },
  {
    "text": "r d side of things in the very you know near future and rob question for you just in terms",
    "start": "1918080",
    "end": "1925200"
  },
  {
    "start": "1923000",
    "end": "2181000"
  },
  {
    "text": "of teaching ethics can we teach ethics and how can and should we train the next",
    "start": "1925200",
    "end": "1930480"
  },
  {
    "text": "generation of students and computer scientists on ethical uses of ai",
    "start": "1930480",
    "end": "1935840"
  },
  {
    "text": "great yeah totally natural and important question and i'm going to give a really short hand answer that each of which",
    "start": "1935840",
    "end": "1941760"
  },
  {
    "text": "could each of the little components could be longer i think there are three different levels",
    "start": "1941760",
    "end": "1946799"
  },
  {
    "text": "or sort of places points of intervention for thinking ethically in order to produce more ethical technology or more",
    "start": "1946799",
    "end": "1953840"
  },
  {
    "text": "ethical people the three points or the three level levels are number one",
    "start": "1953840",
    "end": "1959200"
  },
  {
    "text": "personal ethics make sure that everyone has a moral compass by the time they graduate you know with a ba or a bs",
    "start": "1959200",
    "end": "1965679"
  },
  {
    "text": "degree or some other professional degree i think this is the least interesting",
    "start": "1965679",
    "end": "1971279"
  },
  {
    "text": "aspect of ethics and that if as a society we have to rely on people being moral saints we are totally and",
    "start": "1971279",
    "end": "1978480"
  },
  {
    "text": "hopelessly lost i think to myself does does business ethics prevent the rise of",
    "start": "1978480",
    "end": "1984159"
  },
  {
    "text": "corrupt or venal business people no if we insist upon a personal moral compass",
    "start": "1984159",
    "end": "1989360"
  },
  {
    "text": "as the only stop gap against bad behavior we're still going to get elizabeth holmes of the world we're",
    "start": "1989360",
    "end": "1995919"
  },
  {
    "text": "still going to get lance armstrong's of the world bad behavior happens everywhere if you read what everything i",
    "start": "1995919",
    "end": "2002080"
  },
  {
    "text": "learned and everything i needed to learn i learned in kindergarten you've already gotten the basic lessons that you",
    "start": "2002080",
    "end": "2007440"
  },
  {
    "text": "shouldn't lie cheat or steal good enough we don't need personal ethics in higher education",
    "start": "2007440",
    "end": "2013039"
  },
  {
    "text": "level two professional ethics you should find a way to have professional norms where",
    "start": "2013039",
    "end": "2019600"
  },
  {
    "text": "groups of professionals self-govern or self-police their own behavior",
    "start": "2019600",
    "end": "2025440"
  },
  {
    "text": "computer scientists are way behind the times here or i should say they're i",
    "start": "2025440",
    "end": "2031039"
  },
  {
    "text": "think of the computer science or ai science as a in the unruly teenager",
    "start": "2031039",
    "end": "2036880"
  },
  {
    "text": "phase of life they have discovered all of their powers but behave totally irresponsibly because they haven't yet",
    "start": "2036880",
    "end": "2044000"
  },
  {
    "text": "matured in order to mature into a professional discipline compare it to biomedical ethics where you have all",
    "start": "2044000",
    "end": "2050320"
  },
  {
    "text": "kinds of institutional rules not laws but institutional norms of the profession that help to govern some of",
    "start": "2050320",
    "end": "2057118"
  },
  {
    "text": "the work of biomedical research and biomedical discovery experimentation",
    "start": "2057119",
    "end": "2063280"
  },
  {
    "text": "finally the third and the most important level of ethics is social and political ethics that's what we've been talking",
    "start": "2063280",
    "end": "2068480"
  },
  {
    "text": "about how to think about the frameworks in a democratic society that help illuminate how to balance values how to",
    "start": "2068480",
    "end": "2074398"
  },
  {
    "text": "how to strike trade-offs in a way that benefits all people how to arrange the",
    "start": "2074399",
    "end": "2079599"
  },
  {
    "text": "relative balance of power between industry non-profit society and government these are domains in which",
    "start": "2079599",
    "end": "2086398"
  },
  {
    "text": "there's no singularly correct answer we're not going to optimize for any one particular thing",
    "start": "2086399",
    "end": "2091919"
  },
  {
    "text": "and we're going to find a way in which to have hard conversations with each other that extract decision making from",
    "start": "2091919",
    "end": "2098800"
  },
  {
    "text": "any one person or any one place so that we can um all try to contribute to a",
    "start": "2098800",
    "end": "2104480"
  },
  {
    "text": "broader conversation about what's what matters to us socially those are the most important and interesting ethical",
    "start": "2104480",
    "end": "2110640"
  },
  {
    "text": "questions and that's why i think a place like hai is so important it says hai's",
    "start": "2110640",
    "end": "2116160"
  },
  {
    "text": "value proposition to the world is stop putting the ai scientists by themselves into the lab to produce",
    "start": "2116160",
    "end": "2123040"
  },
  {
    "text": "breakthrough technologies and then let the social scientists and politicians come along after ai has been released",
    "start": "2123040",
    "end": "2128880"
  },
  {
    "text": "into the wild put everyone in the lab together to balance those value trade-offs as we develop these new",
    "start": "2128880",
    "end": "2135119"
  },
  {
    "text": "frontier technologies should we have a.i that automates human beings out of jobs",
    "start": "2135119",
    "end": "2140480"
  },
  {
    "text": "or that augments human beings in what they do in life that's a set of conversations that you have in the lab",
    "start": "2140480",
    "end": "2147040"
  },
  {
    "text": "not afterwards you get the spirit of the idea here the interesting ethical questions are not",
    "start": "2147040",
    "end": "2152079"
  },
  {
    "text": "about personal ethics i don't care whether or not you are a moral saint or not we should have institutional",
    "start": "2152079",
    "end": "2158320"
  },
  {
    "text": "arrangements that allow for individual bad behavior and contain it and then the question is how to balance value",
    "start": "2158320",
    "end": "2164960"
  },
  {
    "text": "trade-offs in which we all have an interest and a stake we don't want the policy makers alone we don't want",
    "start": "2164960",
    "end": "2171280"
  },
  {
    "text": "philanthropic leaders alone we don't want industry leaders alone making those choices or decisions we want everyone",
    "start": "2171280",
    "end": "2177359"
  },
  {
    "text": "with a voice in that conversation hence democracy i would be remiss if we didn't talk",
    "start": "2177359",
    "end": "2182880"
  },
  {
    "start": "2181000",
    "end": "2385000"
  },
  {
    "text": "about the role of industry versus government and rob you alluded to the need for all these stakeholders together",
    "start": "2182880",
    "end": "2188320"
  },
  {
    "text": "in the room there's always been a tension between the private sector and government jeff what role do you think the private sector should have in",
    "start": "2188320",
    "end": "2195280"
  },
  {
    "text": "developing these sorts of ethical standards for ai and how do we",
    "start": "2195280",
    "end": "2200560"
  },
  {
    "text": "also ensure matt especially for you that we have these standards in place and what is the role that government should",
    "start": "2200560",
    "end": "2207040"
  },
  {
    "text": "have and being able to intervene specifically before it's too late yeah i think rob made a great point about h.a.i",
    "start": "2207040",
    "end": "2215200"
  },
  {
    "text": "which is all parties really need to come together on this one and in particular on ai or frontier tech",
    "start": "2215200",
    "end": "2222079"
  },
  {
    "text": "the frontier technology of the moment and it's really tangible so you're out in",
    "start": "2222079",
    "end": "2228320"
  },
  {
    "text": "the world and you're trying to build stuff it becomes very the need for all parties to come to the",
    "start": "2228320",
    "end": "2233520"
  },
  {
    "text": "table becomes very tangible right so it's i know we're talking about",
    "start": "2233520",
    "end": "2238720"
  },
  {
    "text": "ethics and policy and a bit in theory here but in practice when you're trying",
    "start": "2238720",
    "end": "2243839"
  },
  {
    "text": "to build something and deploy it all these voices have to come together so we we have very deep relationships",
    "start": "2243839",
    "end": "2250960"
  },
  {
    "text": "with governments because of the regulatory nature of all the audit and assurance practice tax practice that we",
    "start": "2250960",
    "end": "2256800"
  },
  {
    "text": "have so we are in constant communication with them around different policy and what",
    "start": "2256800",
    "end": "2262160"
  },
  {
    "text": "you do see is what matt alluded to i think that there are great people in governments around the world who are",
    "start": "2262160",
    "end": "2268800"
  },
  {
    "text": "minds and hearts in the right place but frankly right now they are completely overwhelmed",
    "start": "2268800",
    "end": "2274000"
  },
  {
    "text": "with all the different things that are the pandemic being the primary but all the different aspects of the world that",
    "start": "2274000",
    "end": "2279680"
  },
  {
    "text": "they need to take care of and this is yet another aspect of the world an incredibly important one you have people who",
    "start": "2279680",
    "end": "2285680"
  },
  {
    "text": "recognize that but they are overwhelmed so they can't do it alone they gotta they have to come to the table uh",
    "start": "2285680",
    "end": "2292240"
  },
  {
    "text": "clearly academia needs to come to the table because the frameworks and how the sort of the leading edge thinking comes",
    "start": "2292240",
    "end": "2297920"
  },
  {
    "text": "from there but companies have a particularly important place i think right now and i'm actually going to go",
    "start": "2297920",
    "end": "2304079"
  },
  {
    "text": "outside of ai and frontier technologies but if you look at the corporate role",
    "start": "2304079",
    "end": "2309920"
  },
  {
    "text": "currently in the esg conversation right the the social good conversation esg the",
    "start": "2309920",
    "end": "2315839"
  },
  {
    "text": "brt sorry the business roundtable ey our chairman ceo is one of the",
    "start": "2315839",
    "end": "2320960"
  },
  {
    "text": "signatories of that original signatories of that we do a lot of that thinking with the wef we're trying to put in the",
    "start": "2320960",
    "end": "2328000"
  },
  {
    "text": "metrics into our own organization and there's a series of signatories to that",
    "start": "2328000",
    "end": "2333839"
  },
  {
    "text": "document ceos basically of the jpmorgans the bfas of the world who signed on to that document who are trying to make",
    "start": "2333839",
    "end": "2340240"
  },
  {
    "text": "this huge effort to put these metrics into their organizations again to raleigh's point not because they're",
    "start": "2340240",
    "end": "2346560"
  },
  {
    "text": "regulated to but because they feel it's the right thing to do as an organization fits with the purpose of the",
    "start": "2346560",
    "end": "2352640"
  },
  {
    "text": "organization and that is a tangible way that the government not just governments not",
    "start": "2352640",
    "end": "2359280"
  },
  {
    "text": "just academia but the companies themselves have to take on that responsibility as well",
    "start": "2359280",
    "end": "2364960"
  },
  {
    "text": "yes we need to bring together all these three voices one thing that i think has been hard for this particular issue is",
    "start": "2364960",
    "end": "2371280"
  },
  {
    "text": "that there are so many different groups who are talking about this that we haven't actually brought together one",
    "start": "2371280",
    "end": "2376800"
  },
  {
    "text": "single global group to be able to talk together there's just lots of different fragmentation of of teams and group",
    "start": "2376800",
    "end": "2383200"
  },
  {
    "text": "china trying to figure this out and matt i would love your perspectives on this and also just tack on a comment",
    "start": "2383200",
    "end": "2389440"
  },
  {
    "start": "2385000",
    "end": "2536000"
  },
  {
    "text": "that zach from the class made in terms of the dod traditionally generating r d that has been the leading edge of many",
    "start": "2389440",
    "end": "2396240"
  },
  {
    "text": "important innovations whether it's internet gps and perhaps in my opinion this hasn't been the case for ai and",
    "start": "2396240",
    "end": "2403200"
  },
  {
    "text": "given that what are some of the implications how do we think about government's role when tech development outruns policy what is the role of",
    "start": "2403200",
    "end": "2410000"
  },
  {
    "text": "policy and how does it keep up yeah sure so you're absolutely right when it comes to r d dod and the",
    "start": "2410000",
    "end": "2416400"
  },
  {
    "text": "government has traditionally over the last 50 60 70 years been the leader developing all kinds of technologies but",
    "start": "2416400",
    "end": "2422800"
  },
  {
    "text": "ai we are woefully behind but i'm not i said woefully because i in my opinion we",
    "start": "2422800",
    "end": "2429280"
  },
  {
    "text": "are too far behind but overall to actually combine robs and jeff's idea i",
    "start": "2429280",
    "end": "2435200"
  },
  {
    "text": "want government to be a equal partner at the table when it comes to developing these frameworks and",
    "start": "2435200",
    "end": "2441119"
  },
  {
    "text": "frankly a partner to to explain the government's perspective right military operations have different",
    "start": "2441119",
    "end": "2447760"
  },
  {
    "text": "needs so we need to look at them in a different light when it comes to ethical frameworks but at the end of the day i also want",
    "start": "2447760",
    "end": "2453599"
  },
  {
    "text": "the government to be a slow implementer we need the academics and we need the industry to really be pushing ahead and",
    "start": "2453599",
    "end": "2461119"
  },
  {
    "text": "working all these things but we don't want government to actually come in and codify pieces of those ethics that we",
    "start": "2461119",
    "end": "2467599"
  },
  {
    "text": "decide are correct in legislation a because then that's permanent right no not",
    "start": "2467599",
    "end": "2473440"
  },
  {
    "text": "exactly but it is much more permanent than other things and that's the ultimate codification of an ethical standard because when we pass the law",
    "start": "2473440",
    "end": "2480079"
  },
  {
    "text": "forward so in that sense i i want the government to be an equal part in their discussion but as an implementer to be",
    "start": "2480079",
    "end": "2485520"
  },
  {
    "text": "the slow uh person now it's happening naturally that way",
    "start": "2485520",
    "end": "2491440"
  },
  {
    "text": "to directly to jeff's point is weird we right now dod when it comes to ai",
    "start": "2491440",
    "end": "2497280"
  },
  {
    "text": "there's a three-star general out there who would probably shoot me if you heard me say this but we're just a bunch of",
    "start": "2497280",
    "end": "2502400"
  },
  {
    "text": "pilot projects right when it comes to artificial intelligence in in the department of defense it's just the",
    "start": "2502400",
    "end": "2508240"
  },
  {
    "text": "navy's got like 850 ai and they're essentially pilot projects we haven't really deployed these things in any",
    "start": "2508240",
    "end": "2514720"
  },
  {
    "text": "major weapon systems we're not really pushing things out there and so there's this huge gap in the people in dod who",
    "start": "2514720",
    "end": "2521520"
  },
  {
    "text": "can be an equal partner in the conversation to jeff's point so that's the gap we need to close so we can be",
    "start": "2521520",
    "end": "2527440"
  },
  {
    "text": "that equal partner share our perspectives but then government as an implementer i do intentionally want to",
    "start": "2527440",
    "end": "2532720"
  },
  {
    "text": "be slow as things come turn into legislation and i want to spend the last few minutes just covering a few other",
    "start": "2532720",
    "end": "2539440"
  },
  {
    "start": "2536000",
    "end": "2715000"
  },
  {
    "text": "questions that popped up from the class this one's from andrew feel free to jump in uh to provide additional commentary on this one as well so the question is",
    "start": "2539440",
    "end": "2546720"
  },
  {
    "text": "there do you think there is a need for a global agreement on ethical ai can you",
    "start": "2546720",
    "end": "2552400"
  },
  {
    "text": "imagine scenarios where a lack of agreement globally on the ethical use of ai can affect other countries",
    "start": "2552400",
    "end": "2559040"
  },
  {
    "text": "my initial thought is i would i think the power in that",
    "start": "2559040",
    "end": "2566240"
  },
  {
    "text": "is only is realized when it ai decision making is coupled with things that we don't want on a",
    "start": "2566240",
    "end": "2573359"
  },
  {
    "text": "global scale nuclear weapons for example but i think a lot of our previous discussion is it's hard to have the some",
    "start": "2573359",
    "end": "2580560"
  },
  {
    "text": "of those ethical standards because our deferences of what our principles are across the world is so hard but there",
    "start": "2580560",
    "end": "2586319"
  },
  {
    "text": "are a few areas nuclear weapons chemical weapons biological weapons where we would want to push towards can i add to",
    "start": "2586319",
    "end": "2592319"
  },
  {
    "text": "that ernestine i i think the question also and matt's response helps illuminate",
    "start": "2592319",
    "end": "2598720"
  },
  {
    "text": "something important that gets back to the previous question about the relationship between industry and government and commercial commercially",
    "start": "2598720",
    "end": "2606000"
  },
  {
    "text": "led breakthroughs in technology and then the slower often more inefficient regulatory",
    "start": "2606000",
    "end": "2613440"
  },
  {
    "text": "responses of government and the reason i try to connect the two here is",
    "start": "2613440",
    "end": "2618560"
  },
  {
    "text": "i often think it's a productive tension when we have optimizers or seekers of new",
    "start": "2618560",
    "end": "2625760"
  },
  {
    "text": "efficiencies located within industry but when you apply that orientation to",
    "start": "2625760",
    "end": "2632079"
  },
  {
    "text": "democratic government you've made an important misunderstanding",
    "start": "2632079",
    "end": "2637200"
  },
  {
    "text": "democratic governments are not purpose built for optimizing any particular thing their purpose built for avoiding",
    "start": "2637200",
    "end": "2644400"
  },
  {
    "text": "some worst case scenarios and allowing for a contest of interest to be sought to be",
    "start": "2644400",
    "end": "2650400"
  },
  {
    "text": "resolved or you know refereed slowly over time in the best of circumstances then to get",
    "start": "2650400",
    "end": "2656240"
  },
  {
    "text": "to the particular question what could a global agreement on ethics and ai potentially produce",
    "start": "2656240",
    "end": "2661520"
  },
  {
    "text": "i'm with matin saying the best we could hope for is that there are certain things we try to avoid that are really",
    "start": "2661520",
    "end": "2668160"
  },
  {
    "text": "bad outcomes i would put on the list for example automated weapons where humans are no",
    "start": "2668160",
    "end": "2673839"
  },
  {
    "text": "longer in the loop i would like to see a global agreement that the development of frontier military technologies that",
    "start": "2673839",
    "end": "2680640"
  },
  {
    "text": "involve automated tools always should require a human decision maker to authorize lethal use cases",
    "start": "2680640",
    "end": "2688000"
  },
  {
    "text": "those would be beneficial global agreements to have in the same way again as matt said that we sought for various",
    "start": "2688000",
    "end": "2694240"
  },
  {
    "text": "nuclear cases or nuclear uses we shouldn't strive to optimize for our",
    "start": "2694240",
    "end": "2700319"
  },
  {
    "text": "best outcomes across the world if we heed the lesson of democracy that's not",
    "start": "2700319",
    "end": "2705760"
  },
  {
    "text": "what democratic arrangements are good for there's a productive tension between industry and democratic government",
    "start": "2705760",
    "end": "2712560"
  },
  {
    "text": "that's best when they're doing different things andrew does that answer your question are there additional comments you'd like",
    "start": "2712560",
    "end": "2718400"
  },
  {
    "start": "2715000",
    "end": "2819000"
  },
  {
    "text": "to make on that topic no i'm pretty satisfied with that i wasn't i think it offered a lot of",
    "start": "2718400",
    "end": "2724160"
  },
  {
    "text": "clarity into what how that should look on a global scale so i appreciate that thank you actually",
    "start": "2724160",
    "end": "2729599"
  },
  {
    "text": "if i could honestly just just and i guess the group's knowledge like there's there's a whole series of groups going",
    "start": "2729599",
    "end": "2736160"
  },
  {
    "text": "trying to do this so i'm going to be this is literally i was being briefed by our public policy our vice chair bob",
    "start": "2736160",
    "end": "2742160"
  },
  {
    "text": "paul's yesterday there's the icgai the gpai a subcommittee of the",
    "start": "2742160",
    "end": "2748079"
  },
  {
    "text": "oecd plus a couple countries unesco's united nations ai group council of europe and i think that so the i agree",
    "start": "2748079",
    "end": "2755520"
  },
  {
    "text": "with the comments that were made before there's a lot of different groups working on this that the fear i have is",
    "start": "2755520",
    "end": "2761280"
  },
  {
    "text": "that there's so many groups working on it because it's so hard and because",
    "start": "2761280",
    "end": "2766319"
  },
  {
    "text": "there's so many different varied interests that we don't come to the avoidance of these truly",
    "start": "2766319",
    "end": "2772839"
  },
  {
    "text": "catastrophic use cases that matt and rob illuminated which are you're very catastrophic in my mind and i think that",
    "start": "2772839",
    "end": "2779680"
  },
  {
    "text": "so i would like to see to your question i would love to see some coming together around that i don't know if it's",
    "start": "2779680",
    "end": "2785599"
  },
  {
    "text": "possible but i would love to to see and i know there are groups that are trying to",
    "start": "2785599",
    "end": "2790640"
  },
  {
    "text": "bring together that conversation but as you can imagine the the conversation gets delayed uh because there's so many",
    "start": "2790640",
    "end": "2798079"
  },
  {
    "text": "interests at heart to try to bring that even the conversation together but to your point jeff i think to",
    "start": "2798079",
    "end": "2804240"
  },
  {
    "text": "highlight the challenge of that is there is no worldwide nuclear control regime right so there we there are nuclear",
    "start": "2804240",
    "end": "2810560"
  },
  {
    "text": "weapons pointed at us or at least near us right now that we have no treaty signatories to those countries that's up",
    "start": "2810560",
    "end": "2817359"
  },
  {
    "text": "to your point a serious challenge so i want to wrap up today's discussion with one uh final question from lorenz feel",
    "start": "2817359",
    "end": "2823680"
  },
  {
    "start": "2819000",
    "end": "2990000"
  },
  {
    "text": "free to jump in with additional commentary on this so the question is in the future with more of our world being online and",
    "start": "2823680",
    "end": "2829839"
  },
  {
    "text": "digital assumption that more and more data is likely being collected in your view what a personal digital identity",
    "start": "2829839",
    "end": "2836400"
  },
  {
    "text": "look like in 2030 and and i'm just going to jump in quickly thank you yeah it's a slightly amorphous question",
    "start": "2836400",
    "end": "2843520"
  },
  {
    "text": "i guess i thought about this recently you know what will will we have some sort of an analogous",
    "start": "2843520",
    "end": "2849280"
  },
  {
    "text": "personality or a persona in the web that sort of controls our whole how we appear in the world",
    "start": "2849280",
    "end": "2854880"
  },
  {
    "text": "rather than having all this disparate data appear in a gazillion places and",
    "start": "2854880",
    "end": "2861040"
  },
  {
    "text": "i have a really hard time putting that into words but i hope you guys understand roughly what i'm trying to",
    "start": "2861040",
    "end": "2866480"
  },
  {
    "text": "get at i'm i'm pretty sure it's going to involve cat memes so somewhere between now and then that's",
    "start": "2866480",
    "end": "2872559"
  },
  {
    "text": "going to be my avatar but i i think the actual disparate nature of everything is",
    "start": "2872559",
    "end": "2877920"
  },
  {
    "text": "actually one of the huge things that protects our privacy so i i've i have a security clearance",
    "start": "2877920",
    "end": "2883520"
  },
  {
    "text": "opm was reached i don't know 10 years ago that's where we keep all our security information our security",
    "start": "2883520",
    "end": "2889760"
  },
  {
    "text": "investigation information it was hacked almost certainly by country in asia but",
    "start": "2889760",
    "end": "2895359"
  },
  {
    "text": "they didn't get everything right now hackers have gotten other things in other places at other times so in some ways we want a decentralized approach",
    "start": "2895359",
    "end": "2903119"
  },
  {
    "text": "and i don't i i and the other piece of it is i do know that we're moving towards biometric identification both",
    "start": "2903119",
    "end": "2909760"
  },
  {
    "text": "physical biometric and then and the habit the how fast you type in a on a computer to constantly identify you this",
    "start": "2909760",
    "end": "2916559"
  },
  {
    "text": "so that you have access to that that those sets of information i don't know if that is at all what is",
    "start": "2916559",
    "end": "2922720"
  },
  {
    "text": "what you are asking about but those are the two thoughts that come to mind yeah i'll tag on matt i actually think",
    "start": "2922720",
    "end": "2928800"
  },
  {
    "text": "that there's probably a lot of our digital identity that exists with and i have to speak groundly because they're",
    "start": "2928800",
    "end": "2934400"
  },
  {
    "text": "all of our clients and so we don't name our clients by name but large search companies large social companies that",
    "start": "2934400",
    "end": "2940640"
  },
  {
    "text": "have a very meaningful profile of all of us given our usage of their services but",
    "start": "2940640",
    "end": "2946640"
  },
  {
    "text": "also our our our ability to log in using those",
    "start": "2946640",
    "end": "2951680"
  },
  {
    "text": "centered the the search login across a number of different sites so the aggregation of who you are lorenzo is",
    "start": "2951680",
    "end": "2958720"
  },
  {
    "text": "probably there even though it is somewhat decentralized thank goodness but i think they're getting a pretty darn good",
    "start": "2958720",
    "end": "2964240"
  },
  {
    "text": "profile and i think that you could probably if you wanted to spend more time on this look at china's efforts",
    "start": "2964240",
    "end": "2969839"
  },
  {
    "text": "with the human scoring right they are centralizing these efforts and what",
    "start": "2969839",
    "end": "2975200"
  },
  {
    "text": "would it what it could it look like in a centralized way i think they're they're showing us what it might look like so if",
    "start": "2975200",
    "end": "2981680"
  },
  {
    "text": "you looked over there i think you'd probably have a reasonable idea of where it's headed for 2030 and what it could look like for the rest of the world",
    "start": "2981680",
    "end": "2987839"
  },
  {
    "text": "there for for 2030. rob would love to give you the last word just not only on this question but just",
    "start": "2987839",
    "end": "2994480"
  },
  {
    "start": "2990000",
    "end": "3052000"
  },
  {
    "text": "more broadly on this class topic in any final concluding thought yeah",
    "start": "2994480",
    "end": "2999599"
  },
  {
    "text": "maybe what i'm about to say is totally predictable but since it hasn't come up i'll at least lob it into conversation here lorenz",
    "start": "2999599",
    "end": "3006240"
  },
  {
    "text": "what your question makes me think about in terms of our identity calls attention to",
    "start": "3006240",
    "end": "3011520"
  },
  {
    "text": "genetic editing and the the crispr revolution when i think of if i had to identify what are the two most important",
    "start": "3011520",
    "end": "3018720"
  },
  {
    "text": "things to pay attention to for the remainder of the 21st century it's the frontier of ai and the frontier of gene",
    "start": "3018720",
    "end": "3025119"
  },
  {
    "text": "editing both of which threaten to unseat our very understanding of what it means to be",
    "start": "3025119",
    "end": "3031359"
  },
  {
    "text": "human a kind of race between silicon and carbon and our identities our sense of",
    "start": "3031359",
    "end": "3038079"
  },
  {
    "text": "ourselves is what's at stake and so these are the two most important topics to get everyone",
    "start": "3038079",
    "end": "3043760"
  },
  {
    "text": "paying attention to and working on at the same time and eventually the two will come",
    "start": "3043760",
    "end": "3048800"
  },
  {
    "text": "together of course it isn't just separate revolutions but they'll be conjoined",
    "start": "3048800",
    "end": "3054720"
  }
]
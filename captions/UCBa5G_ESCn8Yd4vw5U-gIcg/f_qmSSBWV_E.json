[
  {
    "start": "0",
    "end": "180000"
  },
  {
    "start": "0",
    "end": "5310"
  },
  {
    "text": "Welcome to CS224N, lecture 17,\nModel Analysis and Explanation.",
    "start": "5310",
    "end": "15914"
  },
  {
    "text": "OK, look at us. We're here. Let's start with some\ncourse logistics.",
    "start": "15915",
    "end": "21660"
  },
  {
    "text": "We have updated the policy on\nthe guest lecture reactions. They're all due Friday,\nall at 11:59 PM.",
    "start": "21660",
    "end": "30540"
  },
  {
    "text": "You can't use late days for\nthis, so please get them in. Watch the lectures.",
    "start": "30540",
    "end": "36248"
  },
  {
    "text": "They're awesome lectures. They're awesome guests,\nand you get something like half a point\nfor each of them.",
    "start": "36248",
    "end": "42240"
  },
  {
    "text": "And yeah, all three can be\nsubmitted up through Friday. OK, so final projects, remember\nthat the due date is Tuesday.",
    "start": "42240",
    "end": "51660"
  },
  {
    "text": "It's Tuesday at\n4:30 PM, March 16th. And let me emphasize that\nthere's a hard deadline",
    "start": "51660",
    "end": "59850"
  },
  {
    "text": "on the three days from then. Friday, we won't be accepting\nfor additional points",
    "start": "59850",
    "end": "67470"
  },
  {
    "text": "off assignments-- sorry, final projects that\nare submitted after the 4:30",
    "start": "67470",
    "end": "73410"
  },
  {
    "text": "deadline on Friday. We need to get these\ngraded and get grades in. So whew, it's the\nend stretch, week 9.",
    "start": "73410",
    "end": "81840"
  },
  {
    "text": "Week 10 is really the\nlectures are us giving you help on the final projects.",
    "start": "81840",
    "end": "87327"
  },
  {
    "text": "So this is really the\nlast week of lectures. Thanks for all your\nhard work and for asking",
    "start": "87327",
    "end": "92620"
  },
  {
    "text": "awesome questions in lecture,\nand in office hours and on Ed. And let's get right into it. So today, we get to talk about\none of my favorite subjects",
    "start": "92620",
    "end": "102450"
  },
  {
    "text": "in natural language processing. It's model analysis\nand explanation. So first, we're going to\ndo what I love doing, which",
    "start": "102450",
    "end": "109350"
  },
  {
    "text": "is motivating why we want to\ntalk about the topic at all. We'll talk about how we can look\nat a model at different levels",
    "start": "109350",
    "end": "118200"
  },
  {
    "text": "of abstraction to perform\ndifferent kinds of analysis on it. We'll talk about out of\ndomain evaluation sets.",
    "start": "118200",
    "end": "125039"
  },
  {
    "text": "So this will feel familiar\nto the RobustQA folks.",
    "start": "125040",
    "end": "130350"
  },
  {
    "text": "Then we'll talk about sort\nof trying to figure out, for a given example, why did it\nmake the decision that it made?",
    "start": "130350",
    "end": "137099"
  },
  {
    "text": "It had some input, it\nproduced some output. Can we come up with some sort\nof interpretable explanation for it?",
    "start": "137100",
    "end": "143250"
  },
  {
    "text": "And then we'll look at,\nactually, the representations",
    "start": "143250",
    "end": "148380"
  },
  {
    "text": "of the models. So these are the sort of\nhidden states, the vectors that are being built throughout\nthe processing of the model,",
    "start": "148380",
    "end": "154890"
  },
  {
    "text": "try to figure out if\nwe can understand some of the representations\nand mechanisms that the model is performing.",
    "start": "154890",
    "end": "161250"
  },
  {
    "text": "And then we'll actually\ncome back to sort of one of the kind\nof default states that we've been in\nthis course, which",
    "start": "161250",
    "end": "167040"
  },
  {
    "text": "is trying to look at\nmodel improvements, removing things from models,\nseeing how it performs,",
    "start": "167040",
    "end": "172680"
  },
  {
    "text": "and relate that to the\nanalysis that we're doing in this lecture, show how\nit's not all that different.",
    "start": "172680",
    "end": "181170"
  },
  {
    "text": "OK, so if you haven't seen\nthis xkcd, now you have.",
    "start": "181170",
    "end": "186300"
  },
  {
    "text": "And it's one of my favorites. I'm going to say all the words. So person A says, this is\nyour machine learning system?",
    "start": "186300",
    "end": "194250"
  },
  {
    "text": "Person B says, yep,\nyou pour the data into this big pile\nof linear algebra and then collect the\nanswers on the other side.",
    "start": "194250",
    "end": "201480"
  },
  {
    "text": "Person A, what if the\nanswers are wrong? Then person B,\njust stir the pile until they start looking right.",
    "start": "201480",
    "end": "208380"
  },
  {
    "text": "And I feel like at its\nworst, deep learning can feel like this from time to time. You have a model.",
    "start": "208380",
    "end": "214260"
  },
  {
    "text": "Maybe it works for\nsome things, maybe it doesn't work\nfor other things. You're not sure why it\nworks for some things",
    "start": "214260",
    "end": "219540"
  },
  {
    "text": "and doesn't work for others. And the changes that\nwe make to our models,",
    "start": "219540",
    "end": "225060"
  },
  {
    "text": "they're based on intuition, but\nfrequently-- what are the TAs told? Everyone in office\nhours, sometimes you just",
    "start": "225060",
    "end": "231030"
  },
  {
    "text": "have to try it and see\nif it's going to work out because it's very hard to tell. It's very, very difficult\nto understand our models",
    "start": "231030",
    "end": "239909"
  },
  {
    "text": "on sort of any level. And so today we'll\ngo through a number of ways we're trying\nto sort of carve out",
    "start": "239910",
    "end": "245040"
  },
  {
    "text": "little bits of understanding\nhere and there. So beyond it being important\nbecause it's an xkcd comic,",
    "start": "245040",
    "end": "254730"
  },
  {
    "start": "247000",
    "end": "379000"
  },
  {
    "text": "why should we care about\nunderstanding our models? One, is that we want to know\nwhat our models are doing.",
    "start": "254730",
    "end": "263710"
  },
  {
    "text": "So here you have a black box. Black box functions\nare sort of this idea",
    "start": "263710",
    "end": "269498"
  },
  {
    "text": "that you can't look\ninto them and interpret what they're doing. You have an input sentence,\nsay, and then some output",
    "start": "269498",
    "end": "276479"
  },
  {
    "text": "prediction. Maybe this black box is actually\nyour final project model,",
    "start": "276480",
    "end": "282600"
  },
  {
    "text": "and it gets some accuracy. Now, we summarize our models.",
    "start": "282600",
    "end": "288740"
  },
  {
    "text": "And in your final projects\nyou'll summarize your model with sort of one or a handful\nof summary metrics of accuracy,",
    "start": "288740",
    "end": "295639"
  },
  {
    "text": "or F1 score, or BLEU\nscore or something, but it's a lot of model\nto explain with just",
    "start": "295640",
    "end": "301430"
  },
  {
    "text": "a small number of metrics. So what do they learn? Why do they succeed? And why do they fail?",
    "start": "301430",
    "end": "308297"
  },
  {
    "text": "What's another motivation? So we want to sort of know\nwhat our models are doing, OK, but maybe that's\nbecause we want to be",
    "start": "308297",
    "end": "315290"
  },
  {
    "text": "able to make tomorrow's model. So today, when you're\nbuilding models in this class,",
    "start": "315290",
    "end": "320915"
  },
  {
    "text": "at a company, you start out\nwith some kind of recipe that is known to work\neither at the company",
    "start": "320915",
    "end": "327380"
  },
  {
    "text": "or because you have\nexperience from this class, and it's not perfect, right? It makes mistakes. You look at the errors.",
    "start": "327380",
    "end": "333290"
  },
  {
    "text": "And then over time, you\ntake what works, maybe, and then you find\nwhat needs changing.",
    "start": "333290",
    "end": "339470"
  },
  {
    "text": "So it seems like maybe\nadding another layer to the model helped. And maybe that's a nice tweak\nand the model performance",
    "start": "339470",
    "end": "346640"
  },
  {
    "text": "gets better, et cetera. And incremental progress\ndoesn't always feel exciting,",
    "start": "346640",
    "end": "353870"
  },
  {
    "text": "but I want to pitch to\nyou that it's actually very important for\nus to understand how much incremental progress\ncan kind of get us towards some",
    "start": "353870",
    "end": "361910"
  },
  {
    "text": "of our goals so that we can have\na better job of evaluating when we need when we need big leaps,\nwhen we need major changes,",
    "start": "361910",
    "end": "370550"
  },
  {
    "text": "because there are problems\nthat we're attacking with our incremental\nsort of progress and we're not getting very far.",
    "start": "370550",
    "end": "376889"
  },
  {
    "text": "OK, so we want to\nmake tomorrow's model. Another thing that's, I think,\nvery related to and sort",
    "start": "376890",
    "end": "383520"
  },
  {
    "start": "379000",
    "end": "508000"
  },
  {
    "text": "of both a part of and bigger\nthan this field of analysis is model biases.",
    "start": "383520",
    "end": "389560"
  },
  {
    "text": "So let's say you take your\nWord2vec analogies solver from GloVe or Word2vec\nthat is from assignment 1,",
    "start": "389560",
    "end": "399660"
  },
  {
    "text": "and you give it the analogy,\nman is to computer programmer as woman is to, and it gives\nyou the output, homemaker--",
    "start": "399660",
    "end": "407010"
  },
  {
    "text": "this is a real example\nfrom the paper below-- you should be like, wow.",
    "start": "407010",
    "end": "412260"
  },
  {
    "text": "Well, I'm glad I know that now. And of course, you saw the\nlecture from Yulia Tsvetkov",
    "start": "412260",
    "end": "419940"
  },
  {
    "text": "last week. You say, wow, I'm\nglad I know that now, and that's a huge problem. What did the model\nuse in its decision?",
    "start": "419940",
    "end": "426540"
  },
  {
    "text": "What biases is it\nlearning from data and possibly making even worse? So that's the kind of\nthing that you can also",
    "start": "426540",
    "end": "432570"
  },
  {
    "text": "do with model analysis, beyond\njust making models better according to some sort of\nsummary metric as well.",
    "start": "432570",
    "end": "439479"
  },
  {
    "text": "And then another\nthing, we don't just want to make tomorrow's model. And this is something that\nI think is super important.",
    "start": "439480",
    "end": "445090"
  },
  {
    "text": " We don't just want to\nlook at that time scale.",
    "start": "445090",
    "end": "450180"
  },
  {
    "text": "We want to say, what about\n10, 15, 25 years from now? What kinds of things\nwill we be doing?",
    "start": "450180",
    "end": "456340"
  },
  {
    "text": "What are the limits? What can be learned by\nlanguage model pretraining?",
    "start": "456340",
    "end": "461400"
  },
  {
    "text": "What's the model that will\nreplace the transformer? What's the model that\nwill replace that model? What does deep learning\nstruggle to do?",
    "start": "461400",
    "end": "467940"
  },
  {
    "text": "What are we sort of attacking\nover and over again and failing to make significant progress on? What do neural models tell us\nabout language, potentially?",
    "start": "467940",
    "end": "475278"
  },
  {
    "text": "There's some people\nwho are primarily interested in understanding\nlanguage better using neural networks.",
    "start": "475278",
    "end": "480870"
  },
  {
    "text": "Cool.  How are our models\naffecting people,",
    "start": "480870",
    "end": "486300"
  },
  {
    "text": "transferring power\nbetween groups of people, governments, et cetera? That's an excellent\ntype of analysis.",
    "start": "486300",
    "end": "492729"
  },
  {
    "text": "What can't be learned via\nlanguage model pretraining? So that's sort of the\ncomplementary question there. If you sort of come\nto the edge of what",
    "start": "492730",
    "end": "499650"
  },
  {
    "text": "you can learn via language\nmodel pretraining, is there stuff that we need\ntotal paradigm shifts in order to do well?",
    "start": "499650",
    "end": "508090"
  },
  {
    "start": "508000",
    "end": "767000"
  },
  {
    "text": "So all of this falls\nunder some category of trying to really\ndeeply understand",
    "start": "508090",
    "end": "513719"
  },
  {
    "text": "our models and\ntheir capabilities. And there's a lot\nof different methods here that we'll go over today.",
    "start": "513720",
    "end": "520289"
  },
  {
    "text": "And one thing that I want\nyou to take away from it is that they're all\ngoing to tell us",
    "start": "520289",
    "end": "527460"
  },
  {
    "text": "some aspect of the model,\nelucidate some kind of intuition or something. But none of them are\nwe going to say, aha,",
    "start": "527460",
    "end": "534100"
  },
  {
    "text": "I really understand 100% about\nwhat this model is doing now. So they're going to\nprovide some clarity,",
    "start": "534100",
    "end": "539310"
  },
  {
    "text": "but never total clarity. And one way, if you're\ntrying to decide how you want to understand\nyour model more,",
    "start": "539310",
    "end": "546367"
  },
  {
    "text": "the thing you should sort of\nstart out by thinking about is, at what level\nof abstraction do I want to be looking at my model?",
    "start": "546367",
    "end": "552940"
  },
  {
    "text": "So the sort of very\nhigh level abstraction-- let's say you've trained\na QA model to estimate",
    "start": "552940",
    "end": "561540"
  },
  {
    "text": "the probabilities of\nstart and end indices in a reading\ncomprehension problem, or you've trained\na language model",
    "start": "561540",
    "end": "567720"
  },
  {
    "text": "that assigns probabilities\nto words in context. You can just look at the\nmodel as that object.",
    "start": "567720",
    "end": "573550"
  },
  {
    "text": "So it's just a\nprobability distribution defined by your model. You are not looking\ninto it any further",
    "start": "573550",
    "end": "579420"
  },
  {
    "text": "than the fact that you can\nsort of give it inputs and see what outputs it provides.",
    "start": "579420",
    "end": "584970"
  },
  {
    "text": "So that's not even-- who even cares if\nit's a neural network. It could be anything, but it's a\nway to understand its behavior.",
    "start": "584970",
    "end": "593147"
  },
  {
    "text": "Another level of abstraction\nthat you can look at, you can dig a little\ndeeper, you can say, well, I know that my\nnetwork is a bunch",
    "start": "593147",
    "end": "599677"
  },
  {
    "text": "of layers that are kind of\nstacked on top of each other. You've got sort of maybe\nyour transformer encoder",
    "start": "599677",
    "end": "605280"
  },
  {
    "text": "with one layer, two\nlayer, three layer. You can try to see what\nit's doing as it goes deeper in the layers.",
    "start": "605280",
    "end": "611553"
  },
  {
    "text": "So maybe your neural model is\nthe sequence of these vector representations. A third option of\nsort of specificity",
    "start": "611553",
    "end": "617750"
  },
  {
    "text": "is to look at as much\ndetail as you can. You've got these\nparameters in there,",
    "start": "617750",
    "end": "623300"
  },
  {
    "text": "you've got the connections\nin the computation graph. So now you're sort of trying to\nremove all of the abstraction",
    "start": "623300",
    "end": "629480"
  },
  {
    "text": "that you can and look at as\nmany details as possible. And all three of these sort of\nways of looking at your model",
    "start": "629480",
    "end": "634520"
  },
  {
    "text": "and performing analysis\nare going to be useful and will actually sort of\ntravel slowly from 1 to 2 to 3",
    "start": "634520",
    "end": "642230"
  },
  {
    "text": "as we go through this lecture.  OK, so we haven't actually\ntalked about any analyses yet,",
    "start": "642230",
    "end": "651089"
  },
  {
    "text": "so we're going to get\nstarted on that now. And we're starting with\nthe sort of testing",
    "start": "651090",
    "end": "657720"
  },
  {
    "text": "our model's behaviors. So would we want to see,\nwill my model perform well? I mean, the natural\nthing to ask is,",
    "start": "657720",
    "end": "665190"
  },
  {
    "text": "how does it behave on some\nsort of test set, right? And so we don't really\ncare about mechanisms",
    "start": "665190",
    "end": "672660"
  },
  {
    "text": "yet, why is it performing\nthis, by what method is it making its decision. Instead, we're just\ninterested in sort",
    "start": "672660",
    "end": "678520"
  },
  {
    "text": "of the more higher\nlevel of abstraction of, does it perform the\nway I want it to perform?",
    "start": "678520",
    "end": "684899"
  },
  {
    "text": "So let's take our model\nevaluation that we are already doing and sort of recast it\nin the framework of analysis.",
    "start": "684900",
    "end": "693660"
  },
  {
    "text": "So you've trained your\nmodel on some samples from some distribution. So you've got input/output\npairs of some kind.",
    "start": "693660",
    "end": "700480"
  },
  {
    "text": "So how does the model\nbehave on samples from the same distribution? It's a simple question\nand it's sort of known",
    "start": "700480",
    "end": "707700"
  },
  {
    "text": "as in-domain\naccuracy, or you can say that the samples are IID and\nthat's what you're testing on.",
    "start": "707700",
    "end": "713829"
  },
  {
    "text": "And this is just what we've\nbeen doing this whole time. It's your test set accuracy\nor F1 or BLEU score.",
    "start": "713830",
    "end": "719850"
  },
  {
    "text": "And so you've got some\nmodel with some accuracy, and maybe it's better than some\nmodel with some other accuracy",
    "start": "719850",
    "end": "728048"
  },
  {
    "text": "on this test set, r ight? So this is what\nyou're doing is you're iterating on your models and\nyour final project as well.",
    "start": "728048",
    "end": "734370"
  },
  {
    "text": "You say, well, on\nmy test set, which is what I've decided\nto care about for now, model A does better.",
    "start": "734370",
    "end": "740190"
  },
  {
    "text": "They both seem pretty good. And so maybe I'll choose\nmodel A to keep working on. Maybe I'll choose it if\nyou were putting something",
    "start": "740190",
    "end": "746670"
  },
  {
    "text": "into production. But remember back to\nthis idea that it's",
    "start": "746670",
    "end": "752220"
  },
  {
    "text": "just one number to summarize\na very complex system. It's not going to be\nsufficient to tell you",
    "start": "752220",
    "end": "757980"
  },
  {
    "text": "how it's going to perform in\na wide variety of settings. OK, so we've been doing this.",
    "start": "757980",
    "end": "764250"
  },
  {
    "text": "This is model evaluation\nas model analysis. Now we are going to\nsay, what if we are not",
    "start": "764250",
    "end": "772050"
  },
  {
    "start": "767000",
    "end": "888000"
  },
  {
    "text": "testing on exactly the same\ntype of data that we trained on? So now we're asking, did the\nmodel learn something such",
    "start": "772050",
    "end": "779250"
  },
  {
    "text": "that it's able to\nsort of extrapolate or perform how I\nwant it to on data that looks a little\nbit different from what",
    "start": "779250",
    "end": "785190"
  },
  {
    "text": "it was trained on? And we're going to take the\nexample of natural language inference. So to recall the test of\nnatural language inference,",
    "start": "785190",
    "end": "791532"
  },
  {
    "text": "and this is through the\nMulti-NLI data set that we're just pulling our definition. You have a premise.",
    "start": "791532",
    "end": "796930"
  },
  {
    "text": "He turned and saw Jon\nsleeping in his half-tent And you have a hypothesis,\nhe saw Jon was asleep.",
    "start": "796930",
    "end": "803820"
  },
  {
    "text": "And then you give\nthem both to a model, and this is the model\nthat we had before that had some good accuracy.",
    "start": "803820",
    "end": "809670"
  },
  {
    "text": "And the model is\nsupposed to tell whether the hypothesis\nis sort of implied",
    "start": "809670",
    "end": "815250"
  },
  {
    "text": "by the premise or contradicting. So it could be\ncontradicting, maybe, if the hypothesis is John\nwas awake, for example,",
    "start": "815250",
    "end": "823260"
  },
  {
    "text": "or he saw John was awake. Maybe that'd be contradiction. Neutral if sort of both could\nbe true at the same time,",
    "start": "823260",
    "end": "829270"
  },
  {
    "text": "so to speak. And then entailment,\nin this case, it seems like you're saying\nthat the premise implies",
    "start": "829270",
    "end": "834329"
  },
  {
    "text": "the hypothesis. And so you would\nsay, probably, this is likely to get\nthe right answer",
    "start": "834330",
    "end": "839850"
  },
  {
    "text": "since the accuracy\nof the model is 95%. 95% of the time, it\ngets the right answer.",
    "start": "839850",
    "end": "846180"
  },
  {
    "text": "And we're going to\ndig deeper into that. What if the model\nis not doing what",
    "start": "846180",
    "end": "851790"
  },
  {
    "text": "we think we want it to be\ndoing in order to perform natural language inference? So in a data set like\nMulti-NLI, the authors",
    "start": "851790",
    "end": "859590"
  },
  {
    "text": "who gathered the data set\nwill have asked humans to perform the task\nand gotten the accuracy",
    "start": "859590",
    "end": "865410"
  },
  {
    "text": "that the humans achieved. And models nowadays are\nachieving accuracies that are around where\nhumans are achieving,",
    "start": "865410",
    "end": "873870"
  },
  {
    "text": "which sounds great at first. But as we'll see, it's\nnot the same as actually",
    "start": "873870",
    "end": "879450"
  },
  {
    "text": "performing the task more\nbroadly in the right way.",
    "start": "879450",
    "end": "885250"
  },
  {
    "text": "So what if the model's not doing\nsomething smart, effectively? We're going to use\na diagnostic test",
    "start": "885250",
    "end": "891520"
  },
  {
    "start": "888000",
    "end": "1060000"
  },
  {
    "text": "set of carefully\nconstructed examples that seem like things\nthe models should be able to do to test for a\nspecific skill or capacity.",
    "start": "891520",
    "end": "901150"
  },
  {
    "text": "In this case, we'll use HANS. So HANS is the Heuristic\nAnalysis for NLI Systems",
    "start": "901150",
    "end": "906310"
  },
  {
    "text": "data set, and it's\nintended to take systems that do natural\nlanguage inference",
    "start": "906310",
    "end": "911710"
  },
  {
    "text": "and test whether they're\nusing some simple syntactic heuristics. What we'll have in\neach of these cases,",
    "start": "911710",
    "end": "917560"
  },
  {
    "text": "we'll have some heuristic. We'll talk through\nthe definition. We'll get an example. So the first thing\nis lexical overlap.",
    "start": "917560",
    "end": "924220"
  },
  {
    "text": "So the model might\ndo this thing where it assumes that\na premise entails",
    "start": "924220",
    "end": "930220"
  },
  {
    "text": "all hypotheses constructed\nfrom words in the premise. So in this example,\nyou have the premise,",
    "start": "930220",
    "end": "936880"
  },
  {
    "text": "the doctor was\npaid by the actor. And then the hypothesis is,\nthe doctor paid the actor.",
    "start": "936880",
    "end": "943700"
  },
  {
    "text": "And you'll notice that\nin bold here, the doctor, OK, and then paid, and\nthen the actor, right?",
    "start": "943700",
    "end": "949880"
  },
  {
    "text": "And so if you use\nthis heuristic, you will think that \"the\ndoctor was paid by the actor\" implies the doctor\npaid the actor.",
    "start": "949880",
    "end": "956300"
  },
  {
    "text": "That does not imply\nit, of course. And so you could\nexpect the model-- you want the model to\nbe able to do this.",
    "start": "956300",
    "end": "962090"
  },
  {
    "text": "It's somewhat simple. But if it's using\nthis heuristic, it won't get this example right.",
    "start": "962090",
    "end": "967790"
  },
  {
    "text": "Next is subsequence heuristics. So here, if the model assumes\nthat the premise entails",
    "start": "967790",
    "end": "975470"
  },
  {
    "text": "all of its continuous\nsubsequences, it will get this\none wrong as well. So this example is, \"the\ndoctor near the actor danced.\"",
    "start": "975470",
    "end": "983210"
  },
  {
    "text": "That's the premise. The hypothesis is,\n\"the actor danced.\" Now, this is a simple\nsyntactic thing. The doctor is doing the\ndancing near the actor.",
    "start": "983210",
    "end": "991410"
  },
  {
    "text": "It's this prepositional phrase. And so the model sort\nof uses this heuristic, oh, look, the actor danced.",
    "start": "991410",
    "end": "997130"
  },
  {
    "text": "That's a subsequence,\nentailed, awesome. And it'll get this\none wrong as well.",
    "start": "997130",
    "end": "1002250"
  },
  {
    "text": "And here's another one that's\na lot like subsequence. But so if the model thinks\nthat the premise entails all",
    "start": "1002250",
    "end": "1011410"
  },
  {
    "text": "complete subtrees, so this is\nsort of fully formed phrases. So the artist slept here is a\nfully formed sort of subtree.",
    "start": "1011410",
    "end": "1020350"
  },
  {
    "text": "\"If the artist slept,\nthe actor ran.\" And then that's the premise. Does it entail the\nhypothesis, the actor slept?",
    "start": "1020350",
    "end": "1027740"
  },
  {
    "text": "No. Sorry, the artist slept. That does not entail it because\nthis is in that conditional.",
    "start": "1027740",
    "end": "1034776"
  },
  {
    "text": "OK, now let me pause\nhere for some questions before I move on to see\nhow these models do.",
    "start": "1034776",
    "end": "1040390"
  },
  {
    "text": "Anyone unclear about how\nthis sort of evaluation",
    "start": "1040390",
    "end": "1045459"
  },
  {
    "text": "is being set up? ",
    "start": "1045460",
    "end": "1053010"
  },
  {
    "text": "No?  Cool. ",
    "start": "1053010",
    "end": "1061290"
  },
  {
    "start": "1060000",
    "end": "1167000"
  },
  {
    "text": "OK, so how do models perform? That's sort of the\nquestion of the hour. What we'll do is we'll\nlook at these results",
    "start": "1061290",
    "end": "1069300"
  },
  {
    "text": "from the same paper that\nreleased the dataset. So they took four\nstrong Multi-NLI models",
    "start": "1069300",
    "end": "1076380"
  },
  {
    "text": "with the following accuracies. So the accuracies here\nare something between 60 and 80 something, 80%.",
    "start": "1076380",
    "end": "1081840"
  },
  {
    "text": "BERT over here is\ndoing the best, OK. And in-domain, right,\nin that first sort",
    "start": "1081840",
    "end": "1088200"
  },
  {
    "text": "of setting that we\ntalked about, you get these reasonable accuracies.",
    "start": "1088200",
    "end": "1093690"
  },
  {
    "text": "And that is sort of what\nwe said before about it like looking pretty good.",
    "start": "1093690",
    "end": "1099850"
  },
  {
    "text": "And when we evaluate on\nHANS, in this setting here,",
    "start": "1099850",
    "end": "1105690"
  },
  {
    "text": "we have examples\nwhere the heuristics we talked about actually work. So if the model's\nusing the heuristic,",
    "start": "1105690",
    "end": "1112080"
  },
  {
    "text": "it will get this right. And it gets very\nhigh accuracies. And then if we evaluate the\nmodel in the settings where",
    "start": "1112080",
    "end": "1120900"
  },
  {
    "text": "if it uses the heuristic,\nit gets the examples wrong, maybe BERT's doing\nepsilon better than some",
    "start": "1120900",
    "end": "1128039"
  },
  {
    "text": "of the other stuff here. But it's a very different story.",
    "start": "1128040",
    "end": "1133559"
  },
  {
    "text": "OK, and you saw those examples. They're not complex in our\nsort of own idea of complexity.",
    "start": "1133560",
    "end": "1142980"
  },
  {
    "text": "And so this is why it sort\nof feels like a clear failure of the system.",
    "start": "1142980",
    "end": "1148260"
  },
  {
    "text": "Now, you can say, though,\nthat, well, maybe the training data sort of didn't have any\nof those sort of phenomena,",
    "start": "1148260",
    "end": "1154710"
  },
  {
    "text": "so the model couldn't have\nlearned not to do that. And that's sort of a reasonable\nargument, except, well,",
    "start": "1154710",
    "end": "1160770"
  },
  {
    "text": "BERT is pretrained on a\nbunch of language text. So you might hope,\nyou might expect, you might hope that\nit does better.",
    "start": "1160770",
    "end": "1166788"
  },
  {
    "text": " OK, so we saw that example\nof models performing well",
    "start": "1166788",
    "end": "1177330"
  },
  {
    "start": "1167000",
    "end": "1478000"
  },
  {
    "text": "on examples that are like\nthose that it was trained on, and then performing\nnot very well at all on examples that seem reasonable\nbut are sort of a little bit",
    "start": "1177330",
    "end": "1188610"
  },
  {
    "text": "tricky. Now we're going to take\nthis idea of having a test set that we've\ncarefully crafted",
    "start": "1188610",
    "end": "1193770"
  },
  {
    "text": "and go in a slightly\ndifferent direction. So we're to have,\nwhat does it mean to try to understand the\nlinguistic properties",
    "start": "1193770",
    "end": "1200010"
  },
  {
    "text": "of our models? So that syntactic\nheuristics question was one thing for natural\nlanguage inference,",
    "start": "1200010",
    "end": "1205230"
  },
  {
    "text": "but can we sort of test how\nthe models, whether they think certain things are sort\nof right or wrong as language",
    "start": "1205230",
    "end": "1212550"
  },
  {
    "text": "models? And the first way that\nwe'll do this is we'll ask, well, how do we\nthink about what humans",
    "start": "1212550",
    "end": "1218880"
  },
  {
    "text": "think of as good language? How do we evaluate their sort\nof preferences about language?",
    "start": "1218880",
    "end": "1226590"
  },
  {
    "text": "And one answer is minimal pairs. And the idea of\na minimal pair is that you've got one sentence\nthat sounds OK to a speaker.",
    "start": "1226590",
    "end": "1234659"
  },
  {
    "text": "So this sentence is, the chef\nwho made the pizzas is here.",
    "start": "1234660",
    "end": "1239710"
  },
  {
    "text": "It's called it's an acceptable\nsentence, at least to me. And then with a small\nchange, a minimal change,",
    "start": "1239710",
    "end": "1247500"
  },
  {
    "text": "the sentence is no\nlonger OK to the speaker. So the chef who made\nthe pizzas are here.",
    "start": "1247500",
    "end": "1253260"
  },
  {
    "text": "And this-- oops. This should be\npresent tense verbs.",
    "start": "1253260",
    "end": "1261180"
  },
  {
    "text": "In English, present tense\nverbs agree a number with their subject when\nthey are third person.",
    "start": "1261180",
    "end": "1267039"
  },
  {
    "text": "So chef, pizzas, OK. And this is sort of a\npretty general thing.",
    "start": "1267040",
    "end": "1274703"
  },
  {
    "text": "Most people don't like this. It's a misconjugated verb,\nand so the syntax here",
    "start": "1274703",
    "end": "1280590"
  },
  {
    "text": "looks like you have the\nchef who made the pizzas. And then this arc of\nagreement in number",
    "start": "1280590",
    "end": "1286639"
  },
  {
    "text": "is requiring the word \"is\"\nhere to be singular \"is\" instead of plural\n\"are,\" despite the fact",
    "start": "1286640",
    "end": "1293210"
  },
  {
    "text": "that there's this\nnoun, pizzas, which is plural, closer linearly. Comes back to\ndependency parsing.",
    "start": "1293210",
    "end": "1299840"
  },
  {
    "text": "We're back, OK? And what this looks like\nin the tree structure, right, is, well, \"chef\" and\n\"is\" are attached in the tree.",
    "start": "1299840",
    "end": "1312110"
  },
  {
    "text": "\"Chef\" is the subject\nof \"is,\" \"pizzas\" is down here in\nthis subtree, and",
    "start": "1312110",
    "end": "1317179"
  },
  {
    "text": "so that subject-verb\nrelationship has this sort of agreement thing.",
    "start": "1317180",
    "end": "1322490"
  },
  {
    "text": "So this is a pretty sort of\nbasic and interesting property of language that also\nreflects the syntactic, sort",
    "start": "1322490",
    "end": "1329180"
  },
  {
    "text": "of hierarchical\nstructure of language. So we've been training these\nlanguage models sampling from them, seeing that they\nget interesting things.",
    "start": "1329180",
    "end": "1335690"
  },
  {
    "text": "And they tend to seem to\ngenerate syntactic content. But does it really\nunderstand or does",
    "start": "1335690",
    "end": "1341900"
  },
  {
    "text": "it behave as if it understands\nthis idea of agreement more broadly? And does it sort\nof get the syntax",
    "start": "1341900",
    "end": "1348080"
  },
  {
    "text": "right so that it matches\nthe subjects and the verbs? But language models\ncan't tell us exactly",
    "start": "1348080",
    "end": "1354590"
  },
  {
    "text": "whether they think that a\nsentence is good or bad. They just tell us the\nprobability of a sentence.",
    "start": "1354590",
    "end": "1360390"
  },
  {
    "text": "So before, we had\nacceptable and unacceptable. That's what we get from humans.",
    "start": "1360390",
    "end": "1365690"
  },
  {
    "text": "And the language\nmodel's analog is just, does it assign\nhigher probability to the acceptable sentence\nin the minimal pair, right?",
    "start": "1365690",
    "end": "1372170"
  },
  {
    "text": "So you have the probability\nunder the model of the chef who made the pizzas is\nhere, and then you",
    "start": "1372170",
    "end": "1378919"
  },
  {
    "text": "have the probability under\nthe model of the chef who made the pizzas are here. And you want this probability\nhere to be higher.",
    "start": "1378920",
    "end": "1388080"
  },
  {
    "text": "And if it is, that's\nsort of like a simple way to test whether the model\ngot it right effectively.",
    "start": "1388080",
    "end": "1395360"
  },
  {
    "text": "And just like in\nHANS, we can develop a test set with very carefully\nchosen properties, right?",
    "start": "1395360",
    "end": "1402110"
  },
  {
    "text": "So most sentences in English\ndon't have terribly complex",
    "start": "1402110",
    "end": "1407840"
  },
  {
    "text": "subject-verb agreement\nstructure with a lot of words in the middle, like \"pizzas,\"\nthat are going to make it",
    "start": "1407840",
    "end": "1413210"
  },
  {
    "text": "difficult. So if I\nsay, the dog runs,",
    "start": "1413210",
    "end": "1418460"
  },
  {
    "text": "sort of no way to get it\nwrong because there's no-- the syntax is very simple.",
    "start": "1418460",
    "end": "1424920"
  },
  {
    "text": "So we can create or we\ncan look for sentences that have these things called\nattractors in the sentence.",
    "start": "1424920",
    "end": "1433650"
  },
  {
    "text": "So \"pizzas\" is an\nattractor because the model might be attracted\nto the plurality here",
    "start": "1433650",
    "end": "1439220"
  },
  {
    "text": "and get the conjugation wrong. So this is our question. Can language models sort of very\ngenerally handle these examples",
    "start": "1439220",
    "end": "1447440"
  },
  {
    "text": "with attractors? So we can take examples\nwith zero attractors, see whether the model gets the\nminimal pairs evaluation right.",
    "start": "1447440",
    "end": "1454470"
  },
  {
    "text": "We can take examples with\none attractor, to attractors, you can see how people would\nstill reasonably understand",
    "start": "1454470",
    "end": "1460640"
  },
  {
    "text": "these sentences, right? Chef who made the pizzas and\nprepped the ingredients is-- it's still the chef who is,\nand then on and on and on.",
    "start": "1460640",
    "end": "1468440"
  },
  {
    "text": "It gets rarer,\nobviously, but you can have more and more attractors. And so now we've\ncreated this test set",
    "start": "1468440",
    "end": "1474170"
  },
  {
    "text": "that's intended to\nevaluate this very specific linguistic phenomenon.",
    "start": "1474170",
    "end": "1479190"
  },
  {
    "start": "1478000",
    "end": "1583000"
  },
  {
    "text": "So in this paper here, Kuncoro\net al trained an LSTM language",
    "start": "1479190",
    "end": "1484250"
  },
  {
    "text": "model on a subset of\nWikipedia back in 2018, and they evaluate it sort\nof in these buckets that",
    "start": "1484250",
    "end": "1490640"
  },
  {
    "text": "are specified by the paper\nthat sort of introduce",
    "start": "1490640",
    "end": "1495710"
  },
  {
    "text": "subject-verb agreement\nto the NLP field, more recently at least.",
    "start": "1495710",
    "end": "1502250"
  },
  {
    "text": "And they evaluate\nit in buckets based on the number of attractors. And so in this table here\nthat you're about to see,",
    "start": "1502250",
    "end": "1509570"
  },
  {
    "text": "the numbers are\nsort of the percent of times that you\nget this-- assign higher probability to\nthe correct sentence",
    "start": "1509570",
    "end": "1518000"
  },
  {
    "text": "in the minimal pair. So if you were just to do\nrandom or majority class, you get these errors.",
    "start": "1518000",
    "end": "1523110"
  },
  {
    "text": "Oh, sorry. It's the percent of times\nthat you get it wrong. Sorry about that. So lower is better.",
    "start": "1523110",
    "end": "1529640"
  },
  {
    "text": "And so with no attractors,\nyou get very low error rates. So this is 1.3 error rate\nwith a 350 dimensional LSTM.",
    "start": "1529640",
    "end": "1538850"
  },
  {
    "text": "And with one attractor,\nyour error rate is higher. But actually, humans\nstart to get errors",
    "start": "1538850",
    "end": "1545510"
  },
  {
    "text": "with more attractors, too. So zero attractors is easy. The larger the LSTM, it looks\nlike, in general, the better",
    "start": "1545510",
    "end": "1552747"
  },
  {
    "text": "you're doing, right? So the smaller model's\ndoing worse, OK. And then even on sort\nof very difficult",
    "start": "1552747",
    "end": "1558380"
  },
  {
    "text": "examples with four\nattractors, which-- try to think of an\nexample in your head. The chef made the pizzas\nand took out the trash and--",
    "start": "1558380",
    "end": "1566539"
  },
  {
    "text": "sort of has to be\nthis long sentence. The error rate is\ndefinitely higher, so it gets more difficult.\nBut it's still relatively low.",
    "start": "1566540",
    "end": "1575232"
  },
  {
    "text": "And so even on these\nvery hard examples, models are actually performing\nsubject-verb number agreement relatively well.",
    "start": "1575233",
    "end": "1581220"
  },
  {
    "text": "Very cool.  OK, here's some examples\nthat our model got wrong.",
    "start": "1581220",
    "end": "1588650"
  },
  {
    "start": "1583000",
    "end": "1660000"
  },
  {
    "text": "This is actually a worse model\nthan the ones from the paper that was just there. But I think, actually, the\nerrors are quite interesting.",
    "start": "1588650",
    "end": "1594922"
  },
  {
    "text": "So here's the sentence. The ship that the player\ndrives has a very high speed.",
    "start": "1594922",
    "end": "1601320"
  },
  {
    "text": "Now, this model thought\nthat was less probable than, the ship that the player\ndrives have a very high speed.",
    "start": "1601320",
    "end": "1610880"
  },
  {
    "text": "My hypothesis, right, is that\nit sort of mis-analyzes drives",
    "start": "1610880",
    "end": "1616820"
  },
  {
    "text": "as a plural noun, for example. It's sort of a difficult\nconstruction there. I think it's pretty interesting.",
    "start": "1616820",
    "end": "1624420"
  },
  {
    "text": "Likewise, here, this one is fun. The lead is also rather long. 5 paragraphs is pretty lengthy.",
    "start": "1624420",
    "end": "1632610"
  },
  {
    "text": "So here, \"5 paragraphs\" is\na singular noun together because it's a unit\nof length, I guess.",
    "start": "1632610",
    "end": "1641305"
  },
  {
    "text": "But the model\nthought that it was more likely to say, five\nparagraphs are pretty lengthy, because it's\nreferring to this sort of five",
    "start": "1641305",
    "end": "1650059"
  },
  {
    "text": "paragraphs as the five\nactual paragraphs themselves, as opposed to a single unit\nof length describing the lead.",
    "start": "1650060",
    "end": "1657440"
  },
  {
    "text": "Fascinating, OK. ",
    "start": "1657440",
    "end": "1665020"
  },
  {
    "start": "1660000",
    "end": "1910000"
  },
  {
    "text": "Maybe questions again? ",
    "start": "1665020",
    "end": "1673600"
  },
  {
    "text": "So I guess there are a couple. Can we do the similar heuristic\nanalysis for other tasks,",
    "start": "1673600",
    "end": "1680170"
  },
  {
    "text": "such as Q&A classification? ",
    "start": "1680170",
    "end": "1685559"
  },
  {
    "text": "Yes. Yes. I think that it's easier\nto do this kind of analysis",
    "start": "1685560",
    "end": "1691200"
  },
  {
    "text": "for the HANS style analysis\nwith question answering",
    "start": "1691200",
    "end": "1698220"
  },
  {
    "text": "and other sorts of tasks because\nyou can construct examples that",
    "start": "1698220",
    "end": "1703929"
  },
  {
    "text": "similarly have these heuristics\nand then have the answer depend",
    "start": "1703930",
    "end": "1714330"
  },
  {
    "text": "on the syntax or not. The actual probability\nof one sentence",
    "start": "1714330",
    "end": "1719520"
  },
  {
    "text": "is higher than the\nother, of course, is sort of a language\nmodel dependent thing. But the idea that you can sort\nof develop kind of bespoke test",
    "start": "1719520",
    "end": "1728669"
  },
  {
    "text": "sets for various tasks, I\nthink, is very, very general",
    "start": "1728670",
    "end": "1734010"
  },
  {
    "text": "and something I think is\nactually quite interesting.",
    "start": "1734010",
    "end": "1739200"
  },
  {
    "text": "Yes, so I won't go\non further, but I think the answer's just yes.",
    "start": "1739200",
    "end": "1744960"
  },
  {
    "text": "So there's another one. How do you know where to\nfind these failure cases?",
    "start": "1744960",
    "end": "1750150"
  },
  {
    "text": "Maybe that's the right time to\nadvertise linguistics classes. Sorry.",
    "start": "1750150",
    "end": "1756150"
  },
  {
    "text": "You're still very\nquiet over here. How do we find what? How do you know where to\nfind these failure cases?",
    "start": "1756150",
    "end": "1763140"
  },
  {
    "text": "Oh, interesting. Yes. How do we know where to\nfind the failure cases? That's a good question.",
    "start": "1763140",
    "end": "1768930"
  },
  {
    "text": "I think I agree with Chris,\nthat actually thinking about what is interesting\nabout things in language",
    "start": "1768930",
    "end": "1778020"
  },
  {
    "text": "is one way to do it. Kind of the heuristics that\nwe saw in our language model--",
    "start": "1778020",
    "end": "1785490"
  },
  {
    "text": "sorry, in our NLI\nmodels with HANS, you can kind of imagine\nthat if the model was",
    "start": "1785490",
    "end": "1794310"
  },
  {
    "text": "sort of ignoring facts\nabout language and sort of just doing this sort\nof rough bag of words",
    "start": "1794310",
    "end": "1799530"
  },
  {
    "text": "with some extra magic, then\nit would do well about as bad as it's doing here.",
    "start": "1799530",
    "end": "1805299"
  },
  {
    "text": "And these sorts of ideas\nabout understanding",
    "start": "1805300",
    "end": "1810510"
  },
  {
    "text": "that this statement, if the\nartist slept, the actor ran, does not imply the artist\nslept, is the kind of thing",
    "start": "1810510",
    "end": "1815940"
  },
  {
    "text": "that maybe you'd\nthink up on your own, but also you'd spend time\npondering about and thinking",
    "start": "1815940",
    "end": "1822720"
  },
  {
    "text": "broad thoughts about in\nlinguistics curricula as well. So anything else, Chris?",
    "start": "1822720",
    "end": "1832899"
  },
  {
    "text": " So there's also-- well, I\nguess someone is also saying--",
    "start": "1832900",
    "end": "1840990"
  },
  {
    "text": "I think it's about the sort\nof intervening verbs example, or intervening nouns--\nsorry-- example.",
    "start": "1840990",
    "end": "1846629"
  },
  {
    "text": "But the data set itself\nprobably includes mistakes with higher attractors.",
    "start": "1846630",
    "end": "1852910"
  },
  {
    "text": "Yeah. Yeah, that's a good point. Yeah, because humans make more\nand more mistakes as the number",
    "start": "1852910",
    "end": "1858640"
  },
  {
    "text": "of attractors gets larger. ",
    "start": "1858640",
    "end": "1863790"
  },
  {
    "text": "On the other hand, I\nthink that the mistakes are fewer in written\ntext than in spoken.",
    "start": "1863790",
    "end": "1870120"
  },
  {
    "text": "Maybe I'm just making that up. That's what I think. But yeah, it would be\ninteresting to actually go",
    "start": "1870120",
    "end": "1875490"
  },
  {
    "text": "through that test set and\nsee how many of the errors the really strong model\nmakes are actually",
    "start": "1875490",
    "end": "1882299"
  },
  {
    "text": "due to be sort of observed\nform being incorrect. I'd be super curious. ",
    "start": "1882300",
    "end": "1894660"
  },
  {
    "text": "OK, should I move on? Yeah. Great. ",
    "start": "1894660",
    "end": "1910850"
  },
  {
    "start": "1910000",
    "end": "2066000"
  },
  {
    "text": "OK, so what does\nit feel like we're doing when we are\nkind of constructing these sort of bespoke,\nsmall, careful test sets",
    "start": "1910850",
    "end": "1918200"
  },
  {
    "text": "for various phenomena? Well, it is sort of\nfeels like unit testing.",
    "start": "1918200",
    "end": "1923419"
  },
  {
    "text": "And in fact, this sort of idea\nhas been brought to the fore,",
    "start": "1923420",
    "end": "1930710"
  },
  {
    "text": "you might say, in\nNLP unit tests, but for these NLP\nneural networks. In particular, the paper here\nthat I'm citing at the bottom",
    "start": "1930710",
    "end": "1939500"
  },
  {
    "text": "suggests this minimum\nfunctionality test. You want a small test set that\ntargets a specific behavior.",
    "start": "1939500",
    "end": "1946430"
  },
  {
    "text": "That should sound like\nsome of the things that we've already talked about. But in this case, we're going\nto get even more specific.",
    "start": "1946430",
    "end": "1954690"
  },
  {
    "text": "So here's a single test case. We're going to have an\nexpected label, what",
    "start": "1954690",
    "end": "1959870"
  },
  {
    "text": "was actually predicted, whether\nthe model passed this unit test. And the labels are going to\nbe sentiment analysis here.",
    "start": "1959870",
    "end": "1967680"
  },
  {
    "text": "So negative label,\npositive label, or neutral are the three options. And the unit test is going to\nconsist simply of sentences",
    "start": "1967680",
    "end": "1976370"
  },
  {
    "text": "that follow this template. I, then a negation, the positive\nverb, and then the thing.",
    "start": "1976370",
    "end": "1982639"
  },
  {
    "text": "So if you negation\npositive verb, it means a negative verb, right?",
    "start": "1982640",
    "end": "1987740"
  },
  {
    "text": "And so here's an example. I can't say I\nrecommend the food. The expected label is negative.",
    "start": "1987740",
    "end": "1992970"
  },
  {
    "text": "The answer that the model\nprovided-- and this is, I think, a commercial\nsentiment analysis system--",
    "start": "1992970",
    "end": "1999350"
  },
  {
    "text": "so it predicted positive. And then, I didn't\nlove the flight.",
    "start": "1999350",
    "end": "2004450"
  },
  {
    "text": "The expected label was negative,\nand then the predicted answer was neutral.",
    "start": "2004450",
    "end": "2009700"
  },
  {
    "text": "And this commercial\nsentiment analysis system gets a lot of what\nyou could imagine",
    "start": "2009700",
    "end": "2015790"
  },
  {
    "text": "are pretty reasonably\nsimple examples wrong. And so what Ribeiro\net al 2020 showed",
    "start": "2015790",
    "end": "2021880"
  },
  {
    "text": "is that they could actually\nprovide a system that sort of had this framework of\nbuilding test cases for NLP",
    "start": "2021880",
    "end": "2028299"
  },
  {
    "text": "models to ML engineers\nworking on these products and give them that interface,\nand they would actually",
    "start": "2028300",
    "end": "2037240"
  },
  {
    "text": "find bugs, bugs being\ncategories of high error, right, find bugs in their\nmodels that they could then kind",
    "start": "2037240",
    "end": "2044110"
  },
  {
    "text": "try to go and fix,\nand that this was kind of an efficient\nway of trying to find things that\nwere simple and still",
    "start": "2044110",
    "end": "2050859"
  },
  {
    "text": "wrong with what should be pretty\nsophisticated neural systems.",
    "start": "2050860",
    "end": "2056379"
  },
  {
    "text": "So I really like\nthis, and it's sort of a nice way of thinking\nmore specifically about what",
    "start": "2056380",
    "end": "2061510"
  },
  {
    "text": "are the capabilities in sort\nof precise terms of our models.",
    "start": "2061510",
    "end": "2067149"
  },
  {
    "text": "And all together now,\nyou've seen problems in natural language inference.",
    "start": "2067150",
    "end": "2073239"
  },
  {
    "text": "You've seen language\nmodels actually perform pretty well at the\nlanguage modeling objective. But then you just saw an example\nof a commercial sentiment",
    "start": "2073239",
    "end": "2081370"
  },
  {
    "text": "analysis system that sort of\nshould do better and doesn't. And this comes to this really,\nI think, broad and important",
    "start": "2081370",
    "end": "2089019"
  },
  {
    "text": "takeaway, which is, if\nyou get high accuracy on the in-domain\ntest set, you are not",
    "start": "2089020",
    "end": "2095379"
  },
  {
    "text": "guaranteed high\naccuracy on even what you might consider to be\nreasonable out-of-domain",
    "start": "2095380",
    "end": "2103480"
  },
  {
    "text": "evaluations. And life is always\nout of domain, and if you're building a system\nthat will be given to users,",
    "start": "2103480",
    "end": "2111910"
  },
  {
    "text": "it's immediately out of\ndomain, at the very least because it's trained\non text that's now older than the things\nthat the users are now saying.",
    "start": "2111910",
    "end": "2118160"
  },
  {
    "text": "So it's a really,\nreally important take away that your sort\nof benchmark accuracy",
    "start": "2118160",
    "end": "2123190"
  },
  {
    "text": "is a single number that does\nnot guarantee good performance on a wide variety of things. And from a what are our neural\nnetworks doing perspective,",
    "start": "2123190",
    "end": "2132180"
  },
  {
    "text": "one way to think about\nit is that models seem to be learning the\ndata set, fitting sort of the fine-grained sort\nof heuristic and statistics",
    "start": "2132180",
    "end": "2139840"
  },
  {
    "text": "that help it fit\nthis one data set, as opposed to learning the task. So humans can perform\nnatural language inference.",
    "start": "2139840",
    "end": "2147020"
  },
  {
    "text": "If you give them examples\nfrom whatever data set, once you've told them\nhow to do the task, they'll be very\ngenerally strong at it.",
    "start": "2147020",
    "end": "2155170"
  },
  {
    "text": "But you take your MNLI model\nand you test it on HANS, and it got whatever that\nwas below chance accuracy.",
    "start": "2155170",
    "end": "2162877"
  },
  {
    "text": "That's not the kind of\nthing that you want to see. So it definitely learns\nthe data set well because the accuracy\nin domain is high.",
    "start": "2162877",
    "end": "2170620"
  },
  {
    "text": "But our models are seemingly\nnot frequently learning",
    "start": "2170620",
    "end": "2176020"
  },
  {
    "text": "sort of the mechanisms that we\nwould like them to be learning. Last week, we heard about\nlanguage models and sort",
    "start": "2176020",
    "end": "2182573"
  },
  {
    "start": "2179000",
    "end": "2251000"
  },
  {
    "text": "of the implicit knowledge that\nthey encode about the world through pretraining. And one of the ways that we saw\nthe interactive language models",
    "start": "2182573",
    "end": "2189700"
  },
  {
    "text": "was providing them\nwith a prompt, like, Dante was born in\nmask, and then seeing",
    "start": "2189700",
    "end": "2195340"
  },
  {
    "text": "if it puts high probability on\nthe correct continuation, which requires you to access knowledge\nabout where Dante was born.",
    "start": "2195340",
    "end": "2203260"
  },
  {
    "text": "And we didn't frame\nit this way last week, but this fits into the\nset of behavioral studies that we've done so far.",
    "start": "2203260",
    "end": "2209349"
  },
  {
    "text": "This is a specific\nkind of input. You could ask this\nfor multiple people.",
    "start": "2209350",
    "end": "2215000"
  },
  {
    "text": "We could swap out\nDante for other people. We could have swapped out born\nin for, I don't know, died in",
    "start": "2215000",
    "end": "2220570"
  },
  {
    "text": "or something. And then there are\ntest suites again. And so it's all connected.",
    "start": "2220570",
    "end": "2227770"
  },
  {
    "text": "OK, so I won't go too deep\ninto the knowledge of language models in terms\nof world knowledge because we've gone over\nit some, but when you're",
    "start": "2227770",
    "end": "2235540"
  },
  {
    "text": "thinking about ways of\ninteracting with your models, this sort of behavioral study\ncan be very, very general,",
    "start": "2235540",
    "end": "2242500"
  },
  {
    "text": "even though, remember,\nwe're at still this highest level of abstraction where we're\njust looking at the probability",
    "start": "2242500",
    "end": "2248333"
  },
  {
    "text": "distributions that are defined.  All right, so now\nwe'll go into--",
    "start": "2248333",
    "end": "2255100"
  },
  {
    "start": "2251000",
    "end": "2405000"
  },
  {
    "text": "so we've sort of\nlooked at understanding in fine-grained areas what\nour model is actually doing.",
    "start": "2255100",
    "end": "2261490"
  },
  {
    "text": "What about sort of why,\nfor an individual input, is it getting the\nanswer right or wrong?",
    "start": "2261490",
    "end": "2267940"
  },
  {
    "text": "And then are there\nchanges to the inputs that look fine to\nhumans but actually make the models do a bad job?",
    "start": "2267940",
    "end": "2275799"
  },
  {
    "text": "So one study that I love to\nreference that really draws back into our original\nmotivation of using",
    "start": "2275800",
    "end": "2282990"
  },
  {
    "text": "LSTM networks instead of simple\nrecurrent neural networks was that they could\nuse long context.",
    "start": "2282990",
    "end": "2290369"
  },
  {
    "text": "But how long is your long-\nand short-term memory? And the idea of\nKhandelwal et al 2018",
    "start": "2290370",
    "end": "2299280"
  },
  {
    "text": "was shuffle or remove contexts\nthat are farther than some k",
    "start": "2299280",
    "end": "2305130"
  },
  {
    "text": "words away, changing k. And if your accuracy, if\nthe predictive ability",
    "start": "2305130",
    "end": "2313210"
  },
  {
    "text": "of your language model,\nthe perplexity, right, doesn't change once\nyou do that, it means the model wasn't\nactually using that context.",
    "start": "2313210",
    "end": "2320470"
  },
  {
    "text": "I think this is so cool. So on the x-axis,\nwe've got how far away",
    "start": "2320470",
    "end": "2326049"
  },
  {
    "text": "from the word that you're trying\nto predict are you actually sort of corrupting,\nshuffling, or removing stuff",
    "start": "2326050",
    "end": "2332140"
  },
  {
    "text": "from the sequence? And then on the y-axis\nis the increase in loss. So if the increase\nin loss is 0, it",
    "start": "2332140",
    "end": "2340570"
  },
  {
    "text": "means that the model was not\nusing the thing that you just removed because if\nit was using it,",
    "start": "2340570",
    "end": "2346119"
  },
  {
    "text": "it would now do worse\nwithout it, right? And so if you shuffle,\nin the blue line",
    "start": "2346120",
    "end": "2351250"
  },
  {
    "text": "here, if you shuffle\nthe history that's farther away from 50 words,\nthe model does not even notice.",
    "start": "2351250",
    "end": "2358563"
  },
  {
    "text": "I think that's\nreally interesting. One, it says everything past\n50 words of this LSTM language",
    "start": "2358563",
    "end": "2363609"
  },
  {
    "text": "model, you could have\ngiven it in random order and it wouldn't have noticed. And then, two, it says that\nif you're closer than that,",
    "start": "2363610",
    "end": "2371049"
  },
  {
    "text": "it actually is making\nuse of the word order. That's a pretty long memory. OK, that's really interesting.",
    "start": "2371050",
    "end": "2376630"
  },
  {
    "text": "And then if you actually\nremove the words entirely, you can kind of notice\nthat the words are",
    "start": "2376630",
    "end": "2382630"
  },
  {
    "text": "missing up to 200 words away. So you don't know the order-- you don't care about\nthe order they're in,",
    "start": "2382630",
    "end": "2388640"
  },
  {
    "text": "but you care whether\nthey're there or not. And so this is an\nevaluation of, well, do LSTMs have long-term memory?",
    "start": "2388640",
    "end": "2394809"
  },
  {
    "text": "Well, this one at least\nhas effectively no longer than 200 words of\nmemory, but also no less.",
    "start": "2394810",
    "end": "2402180"
  },
  {
    "text": "So very cool.  So that's a general\nstudy for a single model.",
    "start": "2402180",
    "end": "2409410"
  },
  {
    "start": "2405000",
    "end": "2522000"
  },
  {
    "text": "It talks about its sort\nof average behavior over a wide range of examples.",
    "start": "2409410",
    "end": "2414599"
  },
  {
    "text": "But we want to talk about\nindividual predictions on individual inputs. So let's talk about that. So one way of interpreting,\nwhy did my model",
    "start": "2414600",
    "end": "2423690"
  },
  {
    "text": "make this decision,\nthat's very popular is, for a single example,\nwhat parts of the input",
    "start": "2423690",
    "end": "2429059"
  },
  {
    "text": "actually led to the decision? And this is where we come\nin with saliency map.",
    "start": "2429060",
    "end": "2434350"
  },
  {
    "text": "So saliency map provides a\nscore for each word indicating its importance to the\nmodel's prediction.",
    "start": "2434350",
    "end": "2440650"
  },
  {
    "text": "So you've got something\nlike BERT here. You've got BERT. BERT Is making a\nprediction for this mask.",
    "start": "2440650",
    "end": "2447510"
  },
  {
    "text": "The mask rushed to the emergency\nroom to see her patient. ",
    "start": "2447510",
    "end": "2453119"
  },
  {
    "text": "And the predictions that\nthe model is making is thinks with 47% it's\ngoing to be nurse that's",
    "start": "2453120",
    "end": "2458550"
  },
  {
    "text": "here in the mask instead,\nor maybe woman or doctor, or mother, or girl, OK.",
    "start": "2458550",
    "end": "2464490"
  },
  {
    "text": "And then the saliency map\nis being visualized here in orange. According to this\nmethod of saliency",
    "start": "2464490",
    "end": "2469710"
  },
  {
    "text": "called simple gradients,\nwhich we'll get into, \"emergency,\" \"her,\"\nand the SEP token--",
    "start": "2469710",
    "end": "2476036"
  },
  {
    "text": "let's not worry about\nthe SEP token for now, but \"emergency\" and \"her\"\nare the important words,",
    "start": "2476037",
    "end": "2481330"
  },
  {
    "text": "apparently. And the SEP token shows\nup in every sentence, so I'm not going to-- right. And so these two together\nare, according to this method,",
    "start": "2481330",
    "end": "2489247"
  },
  {
    "text": "what's important for\nthe model to make this prediction to mask. And you can see maybe some\nstatistics, biases, et cetera",
    "start": "2489247",
    "end": "2496950"
  },
  {
    "text": "that it's picked up\nin the predictions and then have it mapped\nout onto the sentence. And this is-- well, it\nseems like it's really",
    "start": "2496950",
    "end": "2504210"
  },
  {
    "text": "helping interpretability. And yeah, I think that this\nis sort of a very useful tool.",
    "start": "2504210",
    "end": "2512559"
  },
  {
    "text": "Actually, this is part\nof a demo from AllenNLP that allows you to do this\nyourself for any sentence",
    "start": "2512560",
    "end": "2520800"
  },
  {
    "text": "that you want. So what's this way of\nmaking saliency maps? We're not going to go--\nthere's so many ways to do it.",
    "start": "2520800",
    "end": "2527800"
  },
  {
    "start": "2522000",
    "end": "2742000"
  },
  {
    "text": "We're going to take\na very simple one and work through why\nit sort of makes sense. So the sort of issue is, how do\nyou define importance, right?",
    "start": "2527800",
    "end": "2537190"
  },
  {
    "text": "What does it mean to be\nimportant to the model's prediction? And here's one way\nof thinking about it.",
    "start": "2537190",
    "end": "2542280"
  },
  {
    "text": "It's called the simple\ngradient method. Let's get a little formal. You've got words x1\nto xn, OK, and then",
    "start": "2542280",
    "end": "2548430"
  },
  {
    "text": "you've got a model's score\nfor a given output class. So maybe you've got, in the\nBERT example, each output",
    "start": "2548430",
    "end": "2554160"
  },
  {
    "text": "class with each output word\nthat you could possibly predict. And then you take the norm\nof the gradient of the score",
    "start": "2554160",
    "end": "2562620"
  },
  {
    "text": "with respect to each word. OK, so what we're\nsaying here is the score",
    "start": "2562620",
    "end": "2568349"
  },
  {
    "text": "is sort of the un-normalized\nprobability for that class, OK?",
    "start": "2568350",
    "end": "2575050"
  },
  {
    "text": "So you've got a single class,\nyou're taking the score. It's, like, how\nlikely it is, not yet normalized by how likely\neverything else is sort of.",
    "start": "2575050",
    "end": "2582580"
  },
  {
    "text": "Gradient, how much\nis it going to change if I move it a little bit\nin one direction or another?",
    "start": "2582580",
    "end": "2588230"
  },
  {
    "text": "And then you take the norm to\nget a scalar from a vector. So it looks like this. So salience of\nword \"I,\" you have",
    "start": "2588230",
    "end": "2594430"
  },
  {
    "text": "the norm bars on the outside,\ngradient with respect to xi. So that's, if I change\na little bit locally xi,",
    "start": "2594430",
    "end": "2602710"
  },
  {
    "text": "how much does my score change? So the idea is that\na high gradient norm",
    "start": "2602710",
    "end": "2607900"
  },
  {
    "text": "means that if I were\nto change it locally, I'd affect the score a lot. And that means it was very\nimportant to the decision.",
    "start": "2607900",
    "end": "2614310"
  },
  {
    "text": "Let's visualize\nthis a little bit. So here on the y-axis,\nwe've got loss, just",
    "start": "2614310",
    "end": "2620620"
  },
  {
    "text": "the loss of the model. Sorry, this should be\nscore, should be score. And on the x-axis,\nyou've got word space.",
    "start": "2620620",
    "end": "2627010"
  },
  {
    "text": "The word space is like sort\nof a flattening of the ability to move your word embedding\nin 1,000-dimensional space.",
    "start": "2627010",
    "end": "2634780"
  },
  {
    "text": "I've just plotted it\nhere in one dimension. And now a high\nsaliency thing, you",
    "start": "2634780",
    "end": "2640870"
  },
  {
    "text": "can see that the relationship\nbetween what should be score and moving the\nword in word space,",
    "start": "2640870",
    "end": "2646510"
  },
  {
    "text": "you move it a little\nbit on the x-axis, and the score changes a lot. That's that derivative,\nthat's the gradient.",
    "start": "2646510",
    "end": "2652330"
  },
  {
    "text": "Awesome, love it. Low saliency, you move\nthe word around locally, and the score doesn't change.",
    "start": "2652330",
    "end": "2660320"
  },
  {
    "text": "So the interpretation\nis that means that the actual\nidentity of this word",
    "start": "2660320",
    "end": "2666010"
  },
  {
    "text": "wasn't that important\nto the prediction because I could have changed\nit and the score wouldn't have changed.",
    "start": "2666010",
    "end": "2671290"
  },
  {
    "text": "Now, why are there\nmore methods than this? Because, honestly,\nreading that, I was like,",
    "start": "2671290",
    "end": "2676307"
  },
  {
    "text": "that sounds awesome. That sounds great. There are sort of lots of\nissues with this kind of method,",
    "start": "2676307",
    "end": "2683642"
  },
  {
    "text": "and lots of ways of\ngetting around them. Here's one issue. It's not perfect\nbecause, well, maybe",
    "start": "2683643",
    "end": "2690220"
  },
  {
    "text": "your linear approximation that\nthe gradient gives you holds only very, very locally, right?",
    "start": "2690220",
    "end": "2696740"
  },
  {
    "text": "So here the gradient is 0,\nso this is a low saliency word because I'm at the\nbottom of this parabola.",
    "start": "2696740",
    "end": "2704320"
  },
  {
    "text": "But if I were to move it even a\nlittle bit in either direction, the score would shoot up.",
    "start": "2704320",
    "end": "2710190"
  },
  {
    "text": "So is this not an\nimportant word? It seems important to be\nright there, as opposed",
    "start": "2710190",
    "end": "2716350"
  },
  {
    "text": "to anywhere else, even sort of\nnearby, in order for the score not to go up.",
    "start": "2716350",
    "end": "2721930"
  },
  {
    "text": "But the simple gradients\nmethod won't capture this because it just looks\nat the gradient, which",
    "start": "2721930",
    "end": "2727030"
  },
  {
    "text": "is that 0 right there, OK?  But if you want\nto look into more,",
    "start": "2727030",
    "end": "2732790"
  },
  {
    "text": "there's a bunch of\ndifferent methods that are sort of\napplied in these papers. And I think that it's a good\ntool for the toolbox, OK?",
    "start": "2732790",
    "end": "2740185"
  },
  {
    "text": " So that is one way of\nexplaining a prediction.",
    "start": "2740185",
    "end": "2747220"
  },
  {
    "text": "And it has some issues, like\nwhy are individual words being",
    "start": "2747220",
    "end": "2753090"
  },
  {
    "text": "scored, as opposed to phrases\nor something like that. But for now, we're going\nto move on to another type",
    "start": "2753090",
    "end": "2758910"
  },
  {
    "text": "of explanation, and I'm\ngoing to check the time. OK, cool.",
    "start": "2758910",
    "end": "2764730"
  },
  {
    "text": "Actually, yeah, let\nme pause for a second. Any questions about this? ",
    "start": "2764730",
    "end": "2772980"
  },
  {
    "text": "Earlier on, there were\na couple of questions. One of them was, what\nare your thoughts",
    "start": "2772980",
    "end": "2779730"
  },
  {
    "text": "on whether looking\nat attention weights is a methodologically\nrigorous way of determining the importance that the model\nplaces on certain tokens?",
    "start": "2779730",
    "end": "2787830"
  },
  {
    "text": "It seems like there's some back\nand forth in the literature. That is a great\nquestion, and I probably",
    "start": "2787830",
    "end": "2795400"
  },
  {
    "text": "won't engage with\nthat question as much as I could if we had a\nsecond lecture on this.",
    "start": "2795400",
    "end": "2800560"
  },
  {
    "text": "I actually will provide some\nattention analyses and tell you they're interesting, and then\nI'll sort of say a little bit",
    "start": "2800560",
    "end": "2806890"
  },
  {
    "text": "about why they can be\ninteresting without being sort",
    "start": "2806890",
    "end": "2818710"
  },
  {
    "text": "of the end-all of analysis of\nwhere information is flowing in a transformer, for example.",
    "start": "2818710",
    "end": "2825940"
  },
  {
    "text": "I think the debate\nis something that we would have to get into in a\nmuch longer period of time.",
    "start": "2825940",
    "end": "2831650"
  },
  {
    "text": "But look at the slides\nthat I show about attention and the caveats that\nI provide, and let me know if that answers\nyour question first,",
    "start": "2831650",
    "end": "2837973"
  },
  {
    "text": "because we have quite a\nnumber of slides on it. And if not, please,\nplease, ask again, and we can chat more about it.",
    "start": "2837973",
    "end": "2844970"
  },
  {
    "text": "Then maybe you can go on. Great, OK. So I think this is a really\nfascinating question, which",
    "start": "2844970",
    "end": "2851780"
  },
  {
    "start": "2849000",
    "end": "2932000"
  },
  {
    "text": "also gets what was\nimportant about the input, but it actually kind of an\neven more direct way, which is,",
    "start": "2851780",
    "end": "2858720"
  },
  {
    "text": "could I just keep some\nminimal part of the input and get the same answer? So here's an example from SQuAD.",
    "start": "2858720",
    "end": "2865490"
  },
  {
    "text": "You have this passage,\nin 1899 John Jacob Astor IV invested $100,000 for Tesla.",
    "start": "2865490",
    "end": "2871660"
  },
  {
    "text": "OK, and then the answer that\nis being predicted by the model is going to always be in blue,\nin these examples, Colorado Springs experiments.",
    "start": "2871660",
    "end": "2878059"
  },
  {
    "text": "So you've got this passage. And the question is, what did\nTesla spend Astor's money on?",
    "start": "2878060",
    "end": "2883503"
  },
  {
    "text": "That's why the prediction is\nColorado Springs experiments. The model gets the answer\nright, which is nice.",
    "start": "2883503",
    "end": "2890180"
  },
  {
    "text": "And we would like to\nthink it's because it's doing some kind of\nreading comprehension. But here's the issue.",
    "start": "2890180",
    "end": "2896390"
  },
  {
    "text": "It turns out, based on\nthis fascinating paper, that if you just reduced\nthe question to, did,",
    "start": "2896390",
    "end": "2907980"
  },
  {
    "text": "you actually get\nexactly the same answer. In fact, with the\noriginal question,",
    "start": "2907980",
    "end": "2913079"
  },
  {
    "text": "the model had sort of a\n0.78 confidence probability in that answer. And with the reduced\nquestion, did,",
    "start": "2913080",
    "end": "2921780"
  },
  {
    "text": "you get even higher confidence. And that, if you\ngive a human this, they would not be\nable to know really",
    "start": "2921780",
    "end": "2927992"
  },
  {
    "text": "what you're trying to ask about,\nso it seems like something is going really wonky here. ",
    "start": "2927992",
    "end": "2934510"
  },
  {
    "start": "2932000",
    "end": "3034000"
  },
  {
    "text": "So here's sort of a very high\nlevel overview of the method. In fact, it actually references\nour input saliency methods.",
    "start": "2934510",
    "end": "2941875"
  },
  {
    "text": "Ah, nice, it's connected. So you iteratively remove\nnon-salient or unimportant",
    "start": "2941875",
    "end": "2948090"
  },
  {
    "text": "words. So here's a passage again\ntalking about football,",
    "start": "2948090",
    "end": "2953320"
  },
  {
    "text": "I think. Yeah, oh, nice. So the question is,\nwhere did the Broncos",
    "start": "2953320",
    "end": "2958680"
  },
  {
    "text": "practice for the Super Bowl? Has the prediction of\nStanford University.",
    "start": "2958680",
    "end": "2963930"
  },
  {
    "text": "And that is correct. So again, seems nice. And now we're not actually\ngoing to get the model",
    "start": "2963930",
    "end": "2970290"
  },
  {
    "text": "to be incorrect. We're just going to say, how\ncan I change this question such",
    "start": "2970290",
    "end": "2975587"
  },
  {
    "text": "that it'll still get\nthe answer right? So I'm going to remove the\nword that was least important according to the\nsaliency method.",
    "start": "2975587",
    "end": "2981790"
  },
  {
    "text": "So now it's, where did the\npractice for the Super Bowl? Already, this is\nsort of unanswerable because you've got\ntwo teams practicing.",
    "start": "2981790",
    "end": "2988590"
  },
  {
    "text": "You don't even know which\none you're asking about. So why the model still thinks\nit's so confident in Stanford",
    "start": "2988590",
    "end": "2993720"
  },
  {
    "text": "University makes no sense. But you can just\nsort of keep going.",
    "start": "2993720",
    "end": "2998820"
  },
  {
    "text": "And now I think\nhere the model stops being confident in the\nanswer Stanford University.",
    "start": "2998820",
    "end": "3007160"
  },
  {
    "text": "But I think this is\nreally interesting just to show that\nif the model is",
    "start": "3007160",
    "end": "3012410"
  },
  {
    "text": "able to do this with\nvery high confidence, it's not reflecting the\nuncertainty that really should",
    "start": "3012410",
    "end": "3019190"
  },
  {
    "text": "be there because you can't know\nwhat you're even asking about. OK, so what was important\nto make this answer?",
    "start": "3019190",
    "end": "3026190"
  },
  {
    "text": "Well, at least these\nparts were important because you could\nkeep just those parts",
    "start": "3026190",
    "end": "3031850"
  },
  {
    "text": "and get the same answer. Fascinating. All right, so that's\nsort of the end",
    "start": "3031850",
    "end": "3038030"
  },
  {
    "start": "3034000",
    "end": "3202000"
  },
  {
    "text": "of the admittedly\nbrief talk section on thinking about input saliency\nmethods and similar things.",
    "start": "3038030",
    "end": "3045329"
  },
  {
    "text": "Now we're going to talk\nabout actually breaking models and understanding\nmodels by breaking them.",
    "start": "3045330",
    "end": "3050970"
  },
  {
    "text": "OK, cool. So if we have a passage\nhere, Peyton Manning became the first\nquarterback something",
    "start": "3050970",
    "end": "3058460"
  },
  {
    "text": "Super Bowl, age 39, past\nrecord held by John Elway. Again, we're doing\nquestion answering.",
    "start": "3058460",
    "end": "3063740"
  },
  {
    "text": "We've got this\nquestion, what was the name of the quarterback\nwho was 38 in the Super Bowl? The prediction is\ncorrect, looks good.",
    "start": "3063740",
    "end": "3071859"
  },
  {
    "text": "Now we're not going\nto change the question to try to sort of make\nthe question nonsensical",
    "start": "3071860",
    "end": "3076970"
  },
  {
    "text": "while keeping the same answer. Instead, we're going\nto change the passage",
    "start": "3076970",
    "end": "3082293"
  },
  {
    "text": "by adding this sentence at the\nend, which really shouldn't distract anyone. This is well-known\nquarterback Jeff Dean.",
    "start": "3082293",
    "end": "3089090"
  },
  {
    "text": "Had jersey number\n37 in Champ Bowl. So this just doesn't-- it's really not even related,\nbut now the prediction",
    "start": "3089090",
    "end": "3095750"
  },
  {
    "text": "is Jeff Dean for\nour nice QA model. And so this shows as well that\nit seems like maybe there's",
    "start": "3095750",
    "end": "3104839"
  },
  {
    "text": "this end of the passage bias as\nto where the answer should be, for example.",
    "start": "3104840",
    "end": "3109890"
  },
  {
    "text": "And so this is an\nadversarial example where we flipped the\nprediction by adding something",
    "start": "3109890",
    "end": "3115220"
  },
  {
    "text": "that is innocuous to humans. And so sort of the\nhigher level take away is, oh, it seems\nlike the QA model",
    "start": "3115220",
    "end": "3121700"
  },
  {
    "text": "that we had that seemed good\nis not actually performing QA how we want it to, even\nthough its in-domain accuracy",
    "start": "3121700",
    "end": "3127490"
  },
  {
    "text": "was good. And here's another example. So you've got this\nparagraph with the question,",
    "start": "3127490",
    "end": "3136790"
  },
  {
    "text": "what has been the result\nof this publicity? The answer is, increased\nscrutiny on teacher misconduct.",
    "start": "3136790",
    "end": "3142830"
  },
  {
    "text": "Now, instead of\nchanging the paragraph, we're going to change\nthe question in really, really seemingly insignificant\nways to change the model's",
    "start": "3142830",
    "end": "3152210"
  },
  {
    "text": "prediction. So first, what H-A and then\nI've got this typo L been",
    "start": "3152210",
    "end": "3157900"
  },
  {
    "text": "the result of this publicity. The answer changes to\nteacher misconduct. Likely a human would sort of\nignore this typo or something",
    "start": "3157900",
    "end": "3166030"
  },
  {
    "text": "and answer the right answer. And then this is really nuts. Instead of asking, what has been\nthe result of this publicity,",
    "start": "3166030",
    "end": "3172690"
  },
  {
    "text": "if you ask, what's been the\nresult of this publicity, the answer also changes.",
    "start": "3172690",
    "end": "3179290"
  },
  {
    "text": "And the authors call this\na semantically equivalent adversary.",
    "start": "3179290",
    "end": "3184390"
  },
  {
    "text": "This is pretty rough. And in general, swapping \"what\"\nfor \"what's\" in this QA model",
    "start": "3184390",
    "end": "3189730"
  },
  {
    "text": "breaks it pretty frequently. And so, again, when you go\nback and sort of re-tinker",
    "start": "3189730",
    "end": "3197260"
  },
  {
    "text": "how to build your\nmodel, you're going to be thinking about\nthese things, not just the sort of average accuracy.",
    "start": "3197260",
    "end": "3203809"
  },
  {
    "start": "3202000",
    "end": "3344000"
  },
  {
    "text": "So that's sort of\ntalking about noise. Are models robust to\nnoise in their inputs?",
    "start": "3203810",
    "end": "3211000"
  },
  {
    "text": "Are humans robust to noise is\nanother question we can ask. And so you can kind of go\nto this popular sort of meme",
    "start": "3211000",
    "end": "3218710"
  },
  {
    "text": "passed around the\ninternet from time to time, where you have all\nthe letters in these words",
    "start": "3218710",
    "end": "3224230"
  },
  {
    "text": "scrambled. You say, according to research\nat Cambridge University, it doesn't matter in what order\nthe letters in a word are,",
    "start": "3224230",
    "end": "3231745"
  },
  {
    "text": "right? And so it seems like-- I think I did a pretty\ngood job there--",
    "start": "3231745",
    "end": "3237550"
  },
  {
    "text": "seemingly, right,\nwe've got this noise. That's a specific kind of noise. And we can be robust as humans\nto reading and processing",
    "start": "3237550",
    "end": "3245080"
  },
  {
    "text": "the language without actually\nall that much of a difficulty. So that's maybe something\nthat we might want our models",
    "start": "3245080",
    "end": "3252369"
  },
  {
    "text": "to also be robust to. And it's very practical as well.",
    "start": "3252370",
    "end": "3259030"
  },
  {
    "text": "Noise is a part of all NLP\nsystems inputs at all times. There's just no such\nthing effectively as",
    "start": "3259030",
    "end": "3265509"
  },
  {
    "text": "having users, for example,\nand not having any noise. And so there's a study\nthat was performed",
    "start": "3265510",
    "end": "3272529"
  },
  {
    "text": "on some popular machine\ntranslation models where you train machine translation models\nin French, German, and Czech,",
    "start": "3272530",
    "end": "3279970"
  },
  {
    "text": "I think all to English,\nand you get BLEU scores. These BLEU scores\nwill look a lot better",
    "start": "3279970",
    "end": "3285160"
  },
  {
    "text": "than the ones in\nyour Assignment 4 because much, much\nmore training data. The idea is these are\nactually pretty strong machine",
    "start": "3285160",
    "end": "3291070"
  },
  {
    "text": "translation systems, and\nthat's in in-domain clean text. Now, if you add character\nswaps, like the ones",
    "start": "3291070",
    "end": "3299200"
  },
  {
    "text": "we saw in that sentence\nabout Cambridge, the BLEU scores take\na pretty harsh dive.",
    "start": "3299200",
    "end": "3307510"
  },
  {
    "text": "Not very good. And even if you take a somewhat\nmore natural sort of typo noise",
    "start": "3307510",
    "end": "3315190"
  },
  {
    "text": "distribution here, you'll\nsee that you're still getting 20-ish very\nhigh drops in BLEU score",
    "start": "3315190",
    "end": "3325390"
  },
  {
    "text": "through simply natural noise. And so maybe you'll go\nback and retrain the model on more types of noise,\nand then you ask, oh,",
    "start": "3325390",
    "end": "3331740"
  },
  {
    "text": "if I do that is it robust to\neven different kinds of noise? These are the questions that are\ngoing to be really important.",
    "start": "3331740",
    "end": "3337450"
  },
  {
    "text": "And it's important\nto know that you're able to break your model really\neasily so that you can then go and try to make it more robust.",
    "start": "3337450",
    "end": "3343660"
  },
  {
    "text": " Now, let's see, 20\nminutes, awesome.",
    "start": "3343660",
    "end": "3353290"
  },
  {
    "text": "Now we're going to, I guess-- so now we're going to look\nat the representations",
    "start": "3353290",
    "end": "3359770"
  },
  {
    "text": "of our neural networks. We've talked about\nsort of their behavior and then whether we\ncould sort of change",
    "start": "3359770",
    "end": "3366040"
  },
  {
    "text": "or observe reasons\nbehind their behavior. Now we'll go into\nless abstraction,",
    "start": "3366040",
    "end": "3372880"
  },
  {
    "text": "look more at the actual\nvector representations that are being built\nby models, and we can answer a different kind of\nquestion, at the very least,",
    "start": "3372880",
    "end": "3381130"
  },
  {
    "text": "than with the other studies. The first thing is\nrelated to the question",
    "start": "3381130",
    "end": "3386619"
  },
  {
    "start": "3383000",
    "end": "3599000"
  },
  {
    "text": "I was asked about\nattention, which is that some modeling components\nlend themselves to inspection.",
    "start": "3386620",
    "end": "3393580"
  },
  {
    "text": "Now, this is a sentence that\nI chose somewhat carefully, actually, because in part\nof this debate, right,",
    "start": "3393580",
    "end": "3399290"
  },
  {
    "text": "are they interpretable\ncomponents? We'll see, but they\nlend themselves to inspection in\nthe following way.",
    "start": "3399290",
    "end": "3406510"
  },
  {
    "text": "You can visualize them well and\nyou can correlate them easily with various properties.",
    "start": "3406510",
    "end": "3411740"
  },
  {
    "text": "So let's say you have\nattention heads in BERT. This is from a really nice\nstudy that was done here",
    "start": "3411740",
    "end": "3417970"
  },
  {
    "text": "where you look at\nattention heads of BERT and you say, on most sentences,\nthis attention head had 1,",
    "start": "3417970",
    "end": "3424885"
  },
  {
    "text": "1, seems to do this very sort of\nglobal aggregation, simple kind of operation, does this\npretty consistently.",
    "start": "3424885",
    "end": "3431680"
  },
  {
    "text": "That's cool. Is it interpretable? Well, maybe, right?",
    "start": "3431680",
    "end": "3438430"
  },
  {
    "text": "So it's the first layer, which\nmeans that this word, \"found,\" is sort of uncontextualized.",
    "start": "3438430",
    "end": "3445870"
  },
  {
    "text": "But in deeper\nlayers, the problem is that once you do some\nrounds of attention,",
    "start": "3445870",
    "end": "3452740"
  },
  {
    "text": "you've had information mixing\nand flowing between words. And how do you know exactly what\ninformation you're combining,",
    "start": "3452740",
    "end": "3459910"
  },
  {
    "text": "what you're attending to, even? It's a little hard to tell. And saliency methods\nmore directly",
    "start": "3459910",
    "end": "3467500"
  },
  {
    "text": "sort of evaluate the\nimportance of models. But it's still\ninteresting to see at sort of a local\nmechanistic point of view",
    "start": "3467500",
    "end": "3474400"
  },
  {
    "text": "what kinds of things\nare being attended to. So let's take another example.",
    "start": "3474400",
    "end": "3479560"
  },
  {
    "text": "Some attention heads seemed\nto perform simple operations. So you have the\nglobal aggregation here that we saw already.",
    "start": "3479560",
    "end": "3485349"
  },
  {
    "text": "Others seem to attend pretty\nrobustly to the next token, cool. Next token is a great signal.",
    "start": "3485350",
    "end": "3491710"
  },
  {
    "text": "Some heads attend\nto the SEP token, so here you have it\nattending to SEP.",
    "start": "3491710",
    "end": "3496750"
  },
  {
    "text": "And then maybe some\nattended periods. Maybe that's sort of a\nsplitting sentences together",
    "start": "3496750",
    "end": "3502270"
  },
  {
    "text": "and things like that, not\nthings that are hard to do, but things that\nsome attention heads seemed to pretty\nrobustly perform.",
    "start": "3502270",
    "end": "3507647"
  },
  {
    "text": " Again, now, though,\ndeep in the network, what's actually represented\nat this period at layer 11?",
    "start": "3507647",
    "end": "3517670"
  },
  {
    "text": "Little unclear,\nlittle unclear, OK? So some heads,\nthough, are correlated",
    "start": "3517670",
    "end": "3523839"
  },
  {
    "text": "with really interesting\nlinguistic properties. So this head is actually\nattending to noun modifiers.",
    "start": "3523840",
    "end": "3529780"
  },
  {
    "text": "So you've got this, the\ncomplicated language in the huge new law, right?",
    "start": "3529780",
    "end": "3537339"
  },
  {
    "text": "That's pretty fascinating. Even if the model is not doing\nthis as a causal mechanism",
    "start": "3537340",
    "end": "3543760"
  },
  {
    "text": "to do syntax\nnecessarily, the fact that these things so\nstrongly correlate is actually pretty cool.",
    "start": "3543760",
    "end": "3549793"
  },
  {
    "text": "And so what we have in\nall of these studies is we've got an approximate\ninterpretation and quantitative analysis\nrelating, allowing",
    "start": "3549793",
    "end": "3558339"
  },
  {
    "text": "us to reason about very\ncomplicated model behavior. They're all approximations, but\nthey're definitely interesting.",
    "start": "3558340",
    "end": "3564730"
  },
  {
    "text": "One other example is\nthat of coreference. So we saw some work\non coreference, and it seems like this\nhead does a pretty OK job",
    "start": "3564730",
    "end": "3573520"
  },
  {
    "text": "of actually matching\nup coreferent entities. These are in red--",
    "start": "3573520",
    "end": "3578830"
  },
  {
    "text": "talks, negotiations, she, her. And that's not obvious\nhow to do that.",
    "start": "3578830",
    "end": "3583920"
  },
  {
    "text": "This is a difficult\ntask, and so it does so with some percentage\nof the time.",
    "start": "3583920",
    "end": "3589869"
  },
  {
    "text": "And again, it's sort of\nconnecting very complex model behavior to these sort of\ninterpretable summaries",
    "start": "3589870",
    "end": "3597340"
  },
  {
    "text": "of correlating properties. Other cases, you can have\nindividual hidden units",
    "start": "3597340",
    "end": "3602440"
  },
  {
    "text": "that lend themselves\nto interpretation. So here you've got a character\nlevel LSTM language model.",
    "start": "3602440",
    "end": "3610180"
  },
  {
    "text": "Each row here is a sentence. If you can't read it,\nthat's totally OK. The interpretation\nthat you should take",
    "start": "3610180",
    "end": "3615340"
  },
  {
    "text": "is that, as we walk\nalong the sentence, this single unit is\ngoing from, I think,",
    "start": "3615340",
    "end": "3620560"
  },
  {
    "text": "very negative to very\npositive or very positive to very negative. I don't really remember.",
    "start": "3620560",
    "end": "3626289"
  },
  {
    "text": "But it's tracking the\nposition in the line. So it's just a linear\npositioning unit,",
    "start": "3626290",
    "end": "3631670"
  },
  {
    "text": "and pretty robustly doing so\nacross all of these sentences. So this is from a nice\nvisualization study",
    "start": "3631670",
    "end": "3639000"
  },
  {
    "text": "way back in 2016, way back. Here's another cell from\nthat same LSTM language model",
    "start": "3639000",
    "end": "3644910"
  },
  {
    "text": "that seems to sort of\nturn on inside quotes. So here's a quote,\nand then it turns on.",
    "start": "3644910",
    "end": "3651030"
  },
  {
    "text": "So I guess that's\npositive in the blue. End quote here, and\nthen it's negative.",
    "start": "3651030",
    "end": "3657089"
  },
  {
    "text": "Here you start with no\nquote, negative in the red, see a quote, and then blue.",
    "start": "3657090",
    "end": "3663630"
  },
  {
    "text": "Seems, again, very\ninterpretable, also potentially a very useful\nfeature to keep in mind. And this is just an\nindividual unit in the LSTM",
    "start": "3663630",
    "end": "3670200"
  },
  {
    "text": "that you can just look at\nand see that it does this. Very, very interesting. ",
    "start": "3670200",
    "end": "3677520"
  },
  {
    "text": "Even further on this,\nand this is actually a study by some AI and\nneuroscience researchers,",
    "start": "3677520",
    "end": "3685020"
  },
  {
    "text": "is we saw that LSTMs were\ngood at subject-verb number agreement. Can we figure out the\nmechanisms by which",
    "start": "3685020",
    "end": "3691290"
  },
  {
    "text": "the LSTM is solving the task? Can we actually get\nsome insight into that? And so we have a\nword-level language model.",
    "start": "3691290",
    "end": "3697619"
  },
  {
    "text": "And the word-level\nlanguage model is going to be a little small,\nbut you have a sentence, the boy gently and\nkindly greets the.",
    "start": "3697620",
    "end": "3705270"
  },
  {
    "text": "And this cell that's\nbeing tracked here, so it's an individual\nhidden unit, one dimension,",
    "start": "3705270",
    "end": "3711015"
  },
  {
    "text": "right, is actually,\nafter it sees \"boy,\" it sort of starts to go higher.",
    "start": "3711015",
    "end": "3717760"
  },
  {
    "text": "And then it goes down\nto something very small once it sees \"greets.\" And this cell seems to\ncorrelate with the scope",
    "start": "3717760",
    "end": "3725730"
  },
  {
    "text": "of a subject-verb number\nagreement instance effectively. So here, the boy that watches\nthe dog that watches the cat",
    "start": "3725730",
    "end": "3732630"
  },
  {
    "text": "greets, you've got that\ncell again staying high, maintaining the scope of subject\nuntil \"greets,\" at which point",
    "start": "3732630",
    "end": "3740430"
  },
  {
    "text": "it stops. What allows it to do that? Probably some complex other\ndynamics in the network,",
    "start": "3740430",
    "end": "3747369"
  },
  {
    "text": "but it's still a fascinating,\nI think, insight. And yeah, this is just\nneuron 1,150 in this LSTM.",
    "start": "3747370",
    "end": "3759780"
  },
  {
    "text": "So those are sort of all\nobservational studies that you could do by picking\nout individual components",
    "start": "3759780",
    "end": "3767040"
  },
  {
    "text": "of the model, that you can\nsort of just take each one of and correlating them\nwith some behavior.",
    "start": "3767040",
    "end": "3773190"
  },
  {
    "text": "Now we'll look at a general\nclass of methods called probing by which we still sort\nof use supervised knowledge,",
    "start": "3773190",
    "end": "3782490"
  },
  {
    "text": "like knowledge of the\ntype of coreference that we're looking for. But instead of seeing if it\ncorrelates with something",
    "start": "3782490",
    "end": "3789180"
  },
  {
    "text": "that's immediately\ninterpretable, like a attention\nhead, we're going to look into the vector\nrepresentations of the model",
    "start": "3789180",
    "end": "3796619"
  },
  {
    "text": "and see if these\nproperties can be read out by some simple function\nto say, oh, maybe",
    "start": "3796620",
    "end": "3802680"
  },
  {
    "text": "this property was\nmade very easily accessible by my neural network. So let's dig into this.",
    "start": "3802680",
    "end": "3808620"
  },
  {
    "text": "So the general\nparadigm is that you've got language data that goes into\nsome big pretrained transformer",
    "start": "3808620",
    "end": "3815280"
  },
  {
    "text": "with fine tuning, and you\nget state of the art results. SOTA means State\nOf The Art, right?",
    "start": "3815280",
    "end": "3820890"
  },
  {
    "text": "And so the question for the\nprobing sort of methodology is, if it's providing these\ngeneral purpose language",
    "start": "3820890",
    "end": "3827310"
  },
  {
    "text": "representations, what does it\nactually encode about language?",
    "start": "3827310",
    "end": "3833310"
  },
  {
    "text": "Can we quantify this? Can we figure out\nwhat kinds of things it's learning about language\nthat we seemingly now don't have to tell it?",
    "start": "3833310",
    "end": "3840329"
  },
  {
    "text": "And so you might have\nsomething like a sentence, like, I record the record.",
    "start": "3840330",
    "end": "3846300"
  },
  {
    "text": "That's an interesting sentence. And you put it into your\ntransformer model with its word",
    "start": "3846300",
    "end": "3851700"
  },
  {
    "text": "embeddings at the\nbeginning, maybe some layers of self\nattention and stuff, and you make some predictions.",
    "start": "3851700",
    "end": "3857640"
  },
  {
    "text": "And now our objects\nof study are going to be these intermediate\nlayers, right? So it's a vector per word\nor subword for every layer.",
    "start": "3857640",
    "end": "3866880"
  },
  {
    "text": "And the question is, can we use\nthese linguistic properties, like the dependency\nparsing that we",
    "start": "3866880",
    "end": "3872369"
  },
  {
    "text": "had way back in the\nearly part of the course, to understand sort of\ncorrelations between properties",
    "start": "3872370",
    "end": "3881010"
  },
  {
    "text": "and the vectors and these\nthings that we can interpret? We can interpret\ndependency parses.",
    "start": "3881010",
    "end": "3888295"
  },
  {
    "text": "So there are a couple\nof things that we might want to look for here. We might want to\nlook for semantics.",
    "start": "3888295",
    "end": "3893410"
  },
  {
    "text": "So here in the sentence,\n\"I record the record,\" I am an agent. That's a semantics thing.",
    "start": "3893410",
    "end": "3900840"
  },
  {
    "text": "Record is a patient. It's the thing\nI'm recording, OK? You might have syntax, so you\nmight have the syntax tree",
    "start": "3900840",
    "end": "3906383"
  },
  {
    "text": "that you're interested in,\nthat's the dependency parse tree. Maybe you're interested\nin part of speech, right, because you have\n\"record\" and \"record,\"",
    "start": "3906383",
    "end": "3914580"
  },
  {
    "text": "and the first one's a verb,\nthe second one is a noun, they're identical strings. Does the model sort of\nencode that one is one",
    "start": "3914580",
    "end": "3921440"
  },
  {
    "text": "and the other is the other? So how do we do\nthis kind of study? So we're going to decide on a\nlayer that we want to analyze",
    "start": "3921440",
    "end": "3929310"
  },
  {
    "text": "and we're going to freeze BERT. So we're not going\nto fine tune BERT. All the parameters are frozen.",
    "start": "3929310",
    "end": "3934680"
  },
  {
    "text": "So we decide on layer 2 of BERT. We're going to pass\nin some sentences. We decide on what's\ncalled a probe family.",
    "start": "3934680",
    "end": "3941615"
  },
  {
    "text": "And the question\nI'm asking is, can I use a model from my\nfamily, say linear,",
    "start": "3941615",
    "end": "3947640"
  },
  {
    "text": "to decode a property that\nI'm interested in really well from this layer?",
    "start": "3947640",
    "end": "3953700"
  },
  {
    "text": "So it's indicating that\nthis property is easily accessible to linear\nmodels, effectively.",
    "start": "3953700",
    "end": "3959970"
  },
  {
    "text": "So maybe I train the model,\nI train a linear classifier, right, on top of BERT, and I\nget a really high accuracy.",
    "start": "3959970",
    "end": "3968617"
  },
  {
    "text": "And that's sort of\ninteresting already because you know from prior\nwork in part of speech tagging that if you run a\nlinear classifier on simpler",
    "start": "3968617",
    "end": "3976680"
  },
  {
    "text": "features that aren't\nBERT, you probably don't get as high an accuracy. So that's an interesting\nsort of takeaway.",
    "start": "3976680",
    "end": "3982170"
  },
  {
    "text": "But then you can\nalso take a baseline. So I want to compare\ntwo layers now. So I've got layer 1 here, I\nwant to compare it to layer 2.",
    "start": "3982170",
    "end": "3989520"
  },
  {
    "text": "I train a probe on it as well. Maybe the accuracy\nisn't as good, and now I can say,\noh, wow, look.",
    "start": "3989520",
    "end": "3996839"
  },
  {
    "text": "By layer 2, part of\nspeech is more easily accessible to linear functions\nthan it was at layer 1.",
    "start": "3996840",
    "end": "4004370"
  },
  {
    "text": "So what did that? Well, the self-attention\nand feed forward stuff made it more easily accessible. That's interesting\nbecause it's a statement",
    "start": "4004370",
    "end": "4010760"
  },
  {
    "text": "about sort of the information\nprocessing of the model. ",
    "start": "4010760",
    "end": "4017050"
  },
  {
    "text": "OK, so we're going to\nanalyze these layers. Let's take a second\nmore to think about it",
    "start": "4017050",
    "end": "4022539"
  },
  {
    "text": "and just really--\ngive me just a second. So if you have the model's\nrepresentations h1 to ht,",
    "start": "4022540",
    "end": "4030069"
  },
  {
    "text": "and you have a\nfunction family f, that's the subset linear models,\nor maybe you have like a feed forward neural network, some\nfixed set of hyperparameters,",
    "start": "4030070",
    "end": "4038589"
  },
  {
    "text": "freeze the model,\ntrain the probe. So you get some\npredictions for part of speech tagging or whatever.",
    "start": "4038590",
    "end": "4044800"
  },
  {
    "text": "That's just the probe applied to\nthe hidden state of the model. The probe is a member\nof the probe family.",
    "start": "4044800",
    "end": "4050859"
  },
  {
    "text": "And then the extent\nthat we can predict y is a measure of accessibility. So that's just kind of written\nout not as pictorially, OK?",
    "start": "4050860",
    "end": "4058450"
  },
  {
    "text": "So I'm not going to stay on\nthis for too much longer.",
    "start": "4058450",
    "end": "4064030"
  },
  {
    "text": "And it may help in the\nsearch for causal mechanisms, but it sort of just gives\nus a rough understanding",
    "start": "4064030",
    "end": "4070599"
  },
  {
    "text": "of processing of the\nmodel and what things are accessible at what layer. So what are some results here?",
    "start": "4070600",
    "end": "4076810"
  },
  {
    "text": "So one result is that BERT, if\nyou run linear probes on it,",
    "start": "4076810",
    "end": "4081880"
  },
  {
    "text": "does really, really\nwell on things that require syntax\nand part of speech and named entity recognition,\nactually, in some cases,",
    "start": "4081880",
    "end": "4089050"
  },
  {
    "text": "approximately as well as just\ndoing the very best thing you could possibly do without BERT.",
    "start": "4089050",
    "end": "4095380"
  },
  {
    "text": "So it just makes easily\naccessible amazingly strong features for these\nproperties, and that's an interesting sort of emergent\nquality of BERT, you might say.",
    "start": "4095380",
    "end": "4105850"
  },
  {
    "text": "It seems like as well\nthat the layers of BERT have this property\nwhere, so if you",
    "start": "4105850",
    "end": "4111430"
  },
  {
    "text": "look at the columns of this plot\nhere, each column is a task.",
    "start": "4111430",
    "end": "4116859"
  },
  {
    "text": "You've got input words at the\nsort of layer 0 of BERT here. Layer 24 is the last\nlayer of BERT-large.",
    "start": "4116859",
    "end": "4124000"
  },
  {
    "text": "Lower performance is yellow,\nhigher performance is blue. And I know the\nresolution isn't perfect,",
    "start": "4124000",
    "end": "4130180"
  },
  {
    "text": "but consistently the best place\nto read out these properties is somewhere a bit\npast the middle",
    "start": "4130180",
    "end": "4135250"
  },
  {
    "text": "of the model, which is it's\na very consistent rule, which is fascinating.",
    "start": "4135250",
    "end": "4141040"
  },
  {
    "text": "And then it seems\nas well, if you look at this function\nof increasingly",
    "start": "4141040",
    "end": "4146620"
  },
  {
    "text": "abstract or increasingly\ndifficult to compute linguistic properties on\nthis axis, and increasing",
    "start": "4146620",
    "end": "4151930"
  },
  {
    "text": "depth in the network\non that axis, so the deeper you go\nin the network, it seems like the more\neasily you can access more",
    "start": "4151930",
    "end": "4161290"
  },
  {
    "text": "and more abstract\nlinguistic properties, suggesting that that\naccessibility is",
    "start": "4161290",
    "end": "4166449"
  },
  {
    "text": "being constructed over time\nby the layers of processing of BERT. So it's building more\nand more abstract",
    "start": "4166450",
    "end": "4171490"
  },
  {
    "text": "features, which I\nthink is, again, sort of a really interesting result.",
    "start": "4171490",
    "end": "4177250"
  },
  {
    "text": "And now I think-- one thing that I\nthink comes to mind",
    "start": "4177250",
    "end": "4182560"
  },
  {
    "text": "that really brings us\nback right to day one is we built intuitions\naround Word2vec.",
    "start": "4182560",
    "end": "4188739"
  },
  {
    "text": "We were asking, what does each\ndimension of Word2vec mean? And the answer was\nnot really anything.",
    "start": "4188740",
    "end": "4194080"
  },
  {
    "text": "But we could build\nintuitions about it and think about properties\nof it through sort",
    "start": "4194080",
    "end": "4199690"
  },
  {
    "text": "of these connections between\nsimple mathematical properties of Word2vec and\nlinguistic properties",
    "start": "4199690",
    "end": "4205760"
  },
  {
    "text": "that we could sort\nof understand. So we had this approximation,\nwhich is not 100% true,",
    "start": "4205760",
    "end": "4211400"
  },
  {
    "text": "but some approximation\nthat says, cosine similarity is\neffectively correlated",
    "start": "4211400",
    "end": "4217699"
  },
  {
    "text": "with semantic similarity.  Think about even\nif all we're going",
    "start": "4217700",
    "end": "4223550"
  },
  {
    "text": "to do at the end\nof the day is fine tune these word\nembeddings anyway, likewise we had\nthis sort of idea",
    "start": "4223550",
    "end": "4229489"
  },
  {
    "text": "about the analogies being\nencoded by linear offsets. So some relationships\nare linear in space,",
    "start": "4229490",
    "end": "4235970"
  },
  {
    "text": "and they didn't have to be. That's fascinating. It's this emergent\nproperty that we've now been able to study since\nwe discovered this.",
    "start": "4235970",
    "end": "4243139"
  },
  {
    "text": "Why is that the\ncase in Word2vec? And in general, even\nthough you can't interpret the individual\ndimensions of Word2vec,",
    "start": "4243140",
    "end": "4250880"
  },
  {
    "text": "these sort of emergent,\ninterpretable connections between approximate\nlinguistic ideas",
    "start": "4250880",
    "end": "4256699"
  },
  {
    "text": "and sort of simple math on\nthese objects is fascinating. And so one piece of work that\nsort of extends this idea",
    "start": "4256700",
    "end": "4264680"
  },
  {
    "text": "comes back to\ndependency parse trees. So they describe the\nsyntax of sentences. And in a paper that\nI did with Chris,",
    "start": "4264680",
    "end": "4274489"
  },
  {
    "text": "we showed that,\nactually, BERT and models like it make the dependency\nparse tree structure",
    "start": "4274490",
    "end": "4279860"
  },
  {
    "text": "emergent, sort of more easily\naccessible than one might imagine in its vector space.",
    "start": "4279860",
    "end": "4286650"
  },
  {
    "text": "So if you've got\na tree right here, the chef who ran to the\nstore was out of food, what",
    "start": "4286650",
    "end": "4293000"
  },
  {
    "text": "you can sort of do is think\nabout the tree in terms of distances between words.",
    "start": "4293000",
    "end": "4298980"
  },
  {
    "text": "So you've got the number\nof edges in the tree. Between two words is\ntheir path distance.",
    "start": "4298980",
    "end": "4304170"
  },
  {
    "text": "So you've got the distance\nbetween \"chef\" and \"was\" is 1. And we're going to use this\ninterpretation of a tree",
    "start": "4304170",
    "end": "4310310"
  },
  {
    "text": "as a distance to make a\nconnection with BERT's embedding space. And what we were\nable to show is that",
    "start": "4310310",
    "end": "4316520"
  },
  {
    "text": "under a single linear\ntransformation, the squared Euclidean\ndistance between BERT vectors",
    "start": "4316520",
    "end": "4322970"
  },
  {
    "text": "for the same sentence\nactually correlates well, if you choose the\nB matrix right,",
    "start": "4322970",
    "end": "4329840"
  },
  {
    "text": "with the distances in the tree. So here in this Euclidean\nspace that we've transformed,",
    "start": "4329840",
    "end": "4336380"
  },
  {
    "text": "the approximate distance between\n\"chef\" and \"was\" is also 1. Likewise, the difference\nbetween \"was\" and \"store\"",
    "start": "4336380",
    "end": "4343790"
  },
  {
    "text": "is 4 in the tree. And in my simple sort of\ntransformation of BERT space,",
    "start": "4343790",
    "end": "4349460"
  },
  {
    "text": "the distance between \"store\" and\n\"was\" is also approximately 4, and this is true across a\nwide range of sentences.",
    "start": "4349460",
    "end": "4356390"
  },
  {
    "text": "And this is, to me, a\nfascinating example of, again, emergent approximate structure\nin these very nonlinear models",
    "start": "4356390",
    "end": "4364670"
  },
  {
    "text": "that don't necessarily need\nto encode things so simply. ",
    "start": "4364670",
    "end": "4372465"
  },
  {
    "text": "OK, all right, great. So probing studies and\ncorrelation studies are, I think, interesting and\npoint us in directions",
    "start": "4372465",
    "end": "4379280"
  },
  {
    "text": "to build intuitions\nabout models. But they're not arguments\nthat the model is actually using the thing that you're\nfinding to make a decision.",
    "start": "4379280",
    "end": "4386780"
  },
  {
    "text": "They're not causal studies. And this is for probing\nand correlation studies.",
    "start": "4386780",
    "end": "4392070"
  },
  {
    "text": "So in some work that I\ndid around the same time, we showed, actually, that\ncertain conditions on probes",
    "start": "4392070",
    "end": "4399350"
  },
  {
    "text": "allow you to achieve high\naccuracy on a task that's effectively just\nfitting random labels.",
    "start": "4399350",
    "end": "4404810"
  },
  {
    "text": "And so there's a\ndifficulty of interpreting what the model\ncould or could not",
    "start": "4404810",
    "end": "4411020"
  },
  {
    "text": "be doing with this thing that\nis somehow easily accessible. It's interesting that this\nproperty is easily accessible,",
    "start": "4411020",
    "end": "4417500"
  },
  {
    "text": "but the model might not\nbe doing anything with it, for example, because\nit's totally random. Likewise, another\npaper showed that you",
    "start": "4417500",
    "end": "4424670"
  },
  {
    "text": "can achieve high\naccuracy with a probe, even if the model is trained\nto know that thing that you're",
    "start": "4424670",
    "end": "4429830"
  },
  {
    "text": "probing for is not useful. And there's causal\nstudies that sort of try to extend this work.",
    "start": "4429830",
    "end": "4435920"
  },
  {
    "text": "It's much more difficult,\nbut read this paper, and it's a fascinating\nline of future work.",
    "start": "4435920",
    "end": "4441480"
  },
  {
    "text": "Now in my last two\nminutes, I want to talk about\nrecasting model tweaks",
    "start": "4441480",
    "end": "4446870"
  },
  {
    "text": "and ablations as analysis. So we had this\nimprovement process where we had a network\nthat was going to work OK,",
    "start": "4446870",
    "end": "4454100"
  },
  {
    "text": "and we would see whether we\ncould tweak it in simple ways to improve it. And then you could\nsee whether you could remove anything\nand have it still be OK,",
    "start": "4454100",
    "end": "4461035"
  },
  {
    "text": "and that's kind\nof like analysis. I have my network. Do I want it to-- is it going to be better\nif it's more complicated?",
    "start": "4461035",
    "end": "4466670"
  },
  {
    "text": "Is it going to be\nbetter if it's simpler? Can I get away with\nit being simpler? And so one example of some\nfolks who did this is they",
    "start": "4466670",
    "end": "4473960"
  },
  {
    "text": "took this idea of multiheaded\nattention and said, oh, so many heads. Are all the heads important?",
    "start": "4473960",
    "end": "4479702"
  },
  {
    "text": "And what they showed\nis that if you train a system with\nmultiheaded attention, and then just remove\nthe heads at test time",
    "start": "4479702",
    "end": "4486590"
  },
  {
    "text": "and not use them at\nall, you can actually do pretty well on\nthe original task, not retraining, at all without\nsome of the attention heads,",
    "start": "4486590",
    "end": "4494270"
  },
  {
    "text": "showing that they\nweren't important. You could just get rid\nof them after training. And likewise, you can\ndo the same thing for--",
    "start": "4494270",
    "end": "4500690"
  },
  {
    "text": "this is on machine translation,\nthis is on Multi-NLI. You can actually\nget away without a large, large percentage\nof your attention heads.",
    "start": "4500690",
    "end": "4506810"
  },
  {
    "text": " Let's see.",
    "start": "4506810",
    "end": "4512310"
  },
  {
    "text": "Yeah, so another thing\nthat you could think about is questioning sort of\nthe basics of the models",
    "start": "4512310",
    "end": "4518117"
  },
  {
    "text": "that we're building. So we have transformer\nmodels that are sort of self-attention,\nfeed forward, self-attention, feed forward.",
    "start": "4518117",
    "end": "4523780"
  },
  {
    "text": "But why in that order, with\nsome of the things omitted here? And this paper\nasked this question",
    "start": "4523780",
    "end": "4530280"
  },
  {
    "text": "and said, if this is my\ntransformer, self-attention, feed forward, self-attention,\nfeed forward, et cetera, et cetera, et cetera, what\nif I just reordered it",
    "start": "4530280",
    "end": "4537540"
  },
  {
    "text": "so that I had a bunch of\nself-attentions at the head and a bunch of feed\nforwards at the back? And they tried a bunch\nof these orderings,",
    "start": "4537540",
    "end": "4543390"
  },
  {
    "text": "and this one\nactually does better. So this achieves a lower\nperplexity on a benchmark.",
    "start": "4543390",
    "end": "4548670"
  },
  {
    "text": "And this is a way\nof analyzing what's important about the\narchitectures that I'm building and how can they be changed\nin order to perform better.",
    "start": "4548670",
    "end": "4556239"
  },
  {
    "text": "So neural models\nare very complex, and they're difficult\nto characterize and impossible to characterize\nwith a single sort",
    "start": "4556240",
    "end": "4562560"
  },
  {
    "text": "of statistic, I think, for your\ntest set accuracy, especially in domain. And we want to find intuitive\ndescriptions of model",
    "start": "4562560",
    "end": "4569850"
  },
  {
    "text": "behaviors, but we should look at\nmultiple levels of abstraction. And none of them are\ngoing to be complete.",
    "start": "4569850",
    "end": "4576620"
  },
  {
    "text": "When someone tells you that\ntheir neural network is interpretable, I encourage you\nto engage critically with that.",
    "start": "4576620",
    "end": "4583790"
  },
  {
    "text": "It's not necessarily false, but\nthe levels of interpretability and what you can interpret,\nthese are the questions",
    "start": "4583790",
    "end": "4589550"
  },
  {
    "text": "that you should be\nasking because it's going to be opaque in some\nways, almost definitely.",
    "start": "4589550",
    "end": "4595010"
  },
  {
    "text": "And then bringing this-- this\nlens to your model building as you try to think about\nhow to build better models,",
    "start": "4595010",
    "end": "4601670"
  },
  {
    "text": "even if you're not going to be\ndoing analysis as sort of one of your main driving goals.",
    "start": "4601670",
    "end": "4606900"
  },
  {
    "text": "And with that, good luck\non your final projects. I realize we're at time.",
    "start": "4606900",
    "end": "4612080"
  },
  {
    "text": "The teaching staff is really\nappreciative of your efforts over this difficult quarter.",
    "start": "4612080",
    "end": "4617239"
  },
  {
    "text": "And yeah, I guess there's\na lecture left on Thursday,",
    "start": "4617240",
    "end": "4622400"
  },
  {
    "text": "but yeah, this is my last\none, so thanks, everyone. ",
    "start": "4622400",
    "end": "4631000"
  }
]
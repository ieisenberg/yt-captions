[
  {
    "start": "0",
    "end": "225000"
  },
  {
    "text": "so i just want to start by saying hello and thank you so much for having me it's a real pleasure to be",
    "start": "11920",
    "end": "17680"
  },
  {
    "text": "back here at stanford i grew up in the bay area and have long time stanford connections and worked at ideo for many",
    "start": "17680",
    "end": "23039"
  },
  {
    "text": "years right down downtown palo alto so it's really a pleasure to be here talking about design",
    "start": "23039",
    "end": "28880"
  },
  {
    "text": "and i think kind of bringing like michael was saying a practice-based perspective back to a conversation about",
    "start": "28880",
    "end": "33920"
  },
  {
    "text": "human-centered computing and hci type work um so i wanted to",
    "start": "33920",
    "end": "39200"
  },
  {
    "text": "start just by framing i guess the broad brush strokes of what",
    "start": "39200",
    "end": "44559"
  },
  {
    "text": "an engineering degree or practice ought to be typically we define engineering as the",
    "start": "44559",
    "end": "51039"
  },
  {
    "text": "application of science to addressing human needs and in the university environment for sure",
    "start": "51039",
    "end": "57920"
  },
  {
    "text": "typically what that means is that you'll spend about 99 of your resources on engineering science",
    "start": "57920",
    "end": "64320"
  },
  {
    "text": "right and the assumption is that if you have a very good",
    "start": "64320",
    "end": "70720"
  },
  {
    "text": "scientific kind of research critical thinking kind of tool set that will be a very useful thing",
    "start": "70720",
    "end": "76400"
  },
  {
    "text": "when you go out into the world to engineer things here at stanford the",
    "start": "76400",
    "end": "82720"
  },
  {
    "text": "computer science department is within an engineering school and you've got uh you know human",
    "start": "82720",
    "end": "90079"
  },
  {
    "text": "computer interaction which is very much focused on human needs and there's a certain way of",
    "start": "90079",
    "end": "95280"
  },
  {
    "text": "thinking about thinking about human needs in the context of an engineering program",
    "start": "95280",
    "end": "101680"
  },
  {
    "text": "the question that i've got is you know that basically the usefulness of needs to engineering",
    "start": "101680",
    "end": "109600"
  },
  {
    "text": "really requires deeply understanding what humans need and if you're spending 99 of your",
    "start": "109600",
    "end": "115200"
  },
  {
    "text": "resources on a scientific kind of research based perspective who's really responsible for",
    "start": "115200",
    "end": "120880"
  },
  {
    "text": "this stuff who should be responsible for this stuff typically the way that most engineering programs",
    "start": "120880",
    "end": "126240"
  },
  {
    "text": "will focus that is by saying well that must be scientists scientists who study human needs and",
    "start": "126240",
    "end": "132560"
  },
  {
    "text": "that makes good sense because scientists are smart and they have strong perspectives on the world um but",
    "start": "132560",
    "end": "138080"
  },
  {
    "text": "if you actually think about it clearly you've got the sciences and then you've got well the humanities right you would",
    "start": "138080",
    "end": "144480"
  },
  {
    "text": "think the humanities would be the discipline interested in human needs unfortunately",
    "start": "144480",
    "end": "150000"
  },
  {
    "text": "um i don't know most engineers don't want to be told what to do by the humanities right because engineering",
    "start": "150000",
    "end": "156560"
  },
  {
    "text": "is a kind of very legitimate technical field um and so what ends up happening is that",
    "start": "156560",
    "end": "161840"
  },
  {
    "text": "you get scientists who are um i don't know you can start to think about like where where does the money come from for the research or how is it",
    "start": "161840",
    "end": "168239"
  },
  {
    "text": "being funded or who's in charge of kind of understanding which things should be engineered should it be politicians right maybe",
    "start": "168239",
    "end": "174560"
  },
  {
    "text": "it's people at nsf right whose job it is to fund research in engineering",
    "start": "174560",
    "end": "179840"
  },
  {
    "text": "and it's their job to kind of figure out which director it would be most appropriate for advancing human needs in engineering and that",
    "start": "179840",
    "end": "186560"
  },
  {
    "text": "seems reasonable um but of course you know what's actually going on here is that",
    "start": "186560",
    "end": "191760"
  },
  {
    "text": "the people who are at nsf are former engineers who are leaders in engineering right and they're the ones",
    "start": "191760",
    "end": "197280"
  },
  {
    "text": "who get to think broadly about what the future of the field should be",
    "start": "197280",
    "end": "202319"
  },
  {
    "text": "these are people that i would like to call designers so the reality is that pretty much anyone who's doing engineering",
    "start": "202319",
    "end": "207599"
  },
  {
    "text": "or anyone who's doing research for that matter is a particular kind of designer they're an",
    "start": "207599",
    "end": "212799"
  },
  {
    "text": "engineering designer or computer science designer they're designing computer systems they might not be trained as designers in a",
    "start": "212799",
    "end": "218720"
  },
  {
    "text": "kind of classical practice based sense though so one of the things i want to talk to",
    "start": "218720",
    "end": "224000"
  },
  {
    "text": "about today is just um you know the history of human-centered design and kind of where it's going",
    "start": "224000",
    "end": "229440"
  },
  {
    "start": "225000",
    "end": "499000"
  },
  {
    "text": "and there's a deep history of integration between human needs and engineering most recently we've talked talked about",
    "start": "229440",
    "end": "234879"
  },
  {
    "text": "this as human centered design in hci work as a scientific",
    "start": "234879",
    "end": "240080"
  },
  {
    "text": "research discipline human factors has generally been what we call the discipline that studies how humans",
    "start": "240080",
    "end": "245760"
  },
  {
    "text": "interact with their environment with the aim of improving the safety and quality of human experiences interacting with",
    "start": "245760",
    "end": "251599"
  },
  {
    "text": "technology and you know if you go to the kai conference it is still the acm conference on human factors and",
    "start": "251599",
    "end": "257120"
  },
  {
    "text": "computing systems okay human factors has a deep history going back",
    "start": "257120",
    "end": "262880"
  },
  {
    "text": "at least to the industrial revolution at which point you know this is charlie chaplin in modern times which if you haven't seen that's a kind of classic",
    "start": "262880",
    "end": "269199"
  },
  {
    "text": "silent film on the modernization of industry and sort of the dehumanizing qualities that that brought to",
    "start": "269199",
    "end": "275600"
  },
  {
    "text": "uh people who are now going to work in factories and kind of the disruption that that had on the sort of you know the craftsman or",
    "start": "275600",
    "end": "282240"
  },
  {
    "text": "the guild or the you know the people who who prior to that had you know small kind of boutique shops or whatever",
    "start": "282240",
    "end": "287840"
  },
  {
    "text": "um so you know during the industrial revolution there really wasn't a lot of",
    "start": "287840",
    "end": "293360"
  },
  {
    "text": "attention paid to humanizing technology or thinking about design in that way",
    "start": "293360",
    "end": "298880"
  },
  {
    "text": "until during the second world war we had such a rapid advance in the way",
    "start": "298880",
    "end": "304400"
  },
  {
    "text": "in which technology was being engineered that airplanes would show up at the front lines which pilots didn't know how",
    "start": "304400",
    "end": "309919"
  },
  {
    "text": "to fly because the technology was was advancing and kind of innovating so quickly um this is a photoshop uh a photo from a",
    "start": "309919",
    "end": "317440"
  },
  {
    "text": "manual of a fighter plan in world war ii and it actually led to huge amounts of fatalities right like pilots literally",
    "start": "317440",
    "end": "323680"
  },
  {
    "text": "didn't know how to control these things they couldn't fly them they couldn't land them it's very dangerous and so there's this new field born around human factors engineering really",
    "start": "323680",
    "end": "330400"
  },
  {
    "text": "starting to understand hey there's a human in the loop controlling this plane we need to make it at the very least",
    "start": "330400",
    "end": "335600"
  },
  {
    "text": "operable right and then you know as time progressed after that we find ourselves with digital",
    "start": "335600",
    "end": "340880"
  },
  {
    "text": "technology right in the 70s and then into the 80s we have user interfaces happening",
    "start": "340880",
    "end": "346000"
  },
  {
    "text": "and this is where usability becomes a big concern it's no longer life-threatening the plane's not going to crash but it's really really frustrating i don't know",
    "start": "346000",
    "end": "352160"
  },
  {
    "text": "how to i don't know how to save my email or whatever it might be so that's been kind of the history of",
    "start": "352160",
    "end": "359360"
  },
  {
    "text": "human computer interaction has has basically been getting psychologists and other kinds of scientists interested",
    "start": "359360",
    "end": "364560"
  },
  {
    "text": "in understanding human behavior integrated into engineering research to make things safer more usable",
    "start": "364560",
    "end": "370400"
  },
  {
    "text": "on the flip side there's also a history of design and design has always been a kind of human-centered discipline right so",
    "start": "370400",
    "end": "376960"
  },
  {
    "text": "these are photos from raymond loewy who was an industrial designer working in the uh 30s and 40s primarily and you know he",
    "start": "376960",
    "end": "384160"
  },
  {
    "text": "was doing a lot to sort of humanize technology in a different way thinking about how does it make you feel right",
    "start": "384160",
    "end": "389360"
  },
  {
    "text": "kind of can we skin it we'll make it more aesthetically interesting uh has something to do with kind of styling has something to do with advertising",
    "start": "389360",
    "end": "395759"
  },
  {
    "text": "you see you know we're making machines and we're making them feel like they're faster feel like there's something that i want to own or",
    "start": "395759",
    "end": "401520"
  },
  {
    "text": "consume then we know charles and ray eames who um kind of took it a step further they",
    "start": "401520",
    "end": "407840"
  },
  {
    "text": "really started integrating human-centered methodologies into the way in which manufacturing processes happened",
    "start": "407840",
    "end": "413280"
  },
  {
    "text": "um and and started thinking about making objects but also really really much broader visions about the",
    "start": "413280",
    "end": "418639"
  },
  {
    "text": "future of the world and how people should cooperate together they made a lot of instructional educational films",
    "start": "418639",
    "end": "424080"
  },
  {
    "text": "and really did a wonderful job of kind of pioneering the human-centeredness of design in a more kind of",
    "start": "424080",
    "end": "429280"
  },
  {
    "text": "consumer-facing personal one-on-one relationship that you might have with a brand",
    "start": "429280",
    "end": "434400"
  },
  {
    "text": "um this is henry dreyfus um another human factors engineer sort of designer",
    "start": "434400",
    "end": "440240"
  },
  {
    "text": "who's pretty famous for this work he did on the measure of man looking at kind of average heights heights and distances",
    "start": "440240",
    "end": "445759"
  },
  {
    "text": "and movement and degrees of freedom of kind of the average american man and woman and build a whole book specking out all",
    "start": "445759",
    "end": "452479"
  },
  {
    "text": "of those things which would help designers and engineers make better working environments for them to uh to live in and then of course more",
    "start": "452479",
    "end": "460319"
  },
  {
    "text": "recently we have human-centered design it's really gone very commercial there's been a whole sort of methodology that's grown out of",
    "start": "460319",
    "end": "465840"
  },
  {
    "text": "many places including the product design program here it's been commercialized at places like ideo and lots of consulting firms",
    "start": "465840",
    "end": "472000"
  },
  {
    "text": "all across the world and then even more recently we have kind of it's no longer about human-centered uh",
    "start": "472000",
    "end": "478960"
  },
  {
    "text": "making just of products but actually the whole process or service platform by which one does",
    "start": "478960",
    "end": "484000"
  },
  {
    "text": "consulting work has become a product in its own right right so now we're selling design thinking and design processes to",
    "start": "484000",
    "end": "490400"
  },
  {
    "text": "people who can kind of read a cookbook on how to practice human-centered design by following the steps and applying in their own life",
    "start": "490400",
    "end": "498479"
  },
  {
    "text": "okay so i'm going to talk very quickly about human-centered design just kind of frame frame where the discipline is now and",
    "start": "498960",
    "end": "505520"
  },
  {
    "start": "499000",
    "end": "837000"
  },
  {
    "text": "then i want to spend the rest of the talk today kind of looking at the future of what i'm going to call post-human-centered",
    "start": "505520",
    "end": "511599"
  },
  {
    "text": "design and this has been an area that i've been thinking about since really i got involved in robotics research several years ago when",
    "start": "511599",
    "end": "518159"
  },
  {
    "text": "i was doing my phd work thinking about i don't know if we're going to be thinking about human centeredness and applying it to",
    "start": "518159",
    "end": "524800"
  },
  {
    "text": "technology particularly at this really kind of critical moment in human evolution where",
    "start": "524800",
    "end": "529920"
  },
  {
    "text": "technology has become so fundamental to all of our interactions with pretty much everything um and when we're kind of on the verge of",
    "start": "529920",
    "end": "536320"
  },
  {
    "text": "new kinds of technology that will have kind of sentient you know autonomous intelligent life",
    "start": "536320",
    "end": "542160"
  },
  {
    "text": "right we should start to be thinking about sort of well post-human factors right post-human centered design what's",
    "start": "542160",
    "end": "547600"
  },
  {
    "text": "coming next what's after human-centered design and how can we design for the people who don't exist yet",
    "start": "547600",
    "end": "552640"
  },
  {
    "text": "for the post-humans how can we make experiences for them so human-centered design as practiced",
    "start": "552640",
    "end": "558480"
  },
  {
    "text": "today is typically broken into these phases we've got need finding form giving and communication or",
    "start": "558480",
    "end": "564399"
  },
  {
    "text": "implementation of some kind design as a discipline for the most part is about envisioning a future and kind of",
    "start": "564399",
    "end": "569680"
  },
  {
    "text": "pointing the way uh maybe specifying how something should get implemented and then allowing someone else to do the",
    "start": "569680",
    "end": "576000"
  },
  {
    "text": "kind of delivery and manufacturing or development of that process so at a place like ideo",
    "start": "576000",
    "end": "581760"
  },
  {
    "text": "um you've probably seen many diagrams that look something like this but basically you have a need finding phase up front which is",
    "start": "581760",
    "end": "587120"
  },
  {
    "text": "about understanding observing and synthesizing data from real people then you have a form giving you know and",
    "start": "587120",
    "end": "592480"
  },
  {
    "text": "here we're rapidly prototyping and iterating and evaluating and refining our design and then at the end we sort of you know",
    "start": "592480",
    "end": "599440"
  },
  {
    "text": "we see what we learned we iterate a few more times we wrap that all up communicate what we found and somebody will take it and implement",
    "start": "599440",
    "end": "605360"
  },
  {
    "text": "it or build it at ideo these are typically broken into phases like this so",
    "start": "605360",
    "end": "610480"
  },
  {
    "text": "you know when they were just starting out as a kind of product design engineering shop they were doing a lot of manufacturing work and then you know their their big",
    "start": "610480",
    "end": "617440"
  },
  {
    "text": "differentiator was around coming up with new concepts for how to solve problems and building rapid prototypes and showing",
    "start": "617440",
    "end": "623279"
  },
  {
    "text": "them to people and getting feedback uh today probably you know 98",
    "start": "623279",
    "end": "628320"
  },
  {
    "text": "of the work that they do is in this first phase zero space which is really about going much deeper into designing what the problem is",
    "start": "628320",
    "end": "634959"
  },
  {
    "text": "thinking strategically about how to solve it doing some ethnographic research going in the field synthesizing your findings",
    "start": "634959",
    "end": "641360"
  },
  {
    "text": "identifying opportunity areas generating principles for design building an opportunity framework like",
    "start": "641360",
    "end": "647200"
  },
  {
    "text": "where is this project going to go kind of reframing the project to make sure you're aligned and then",
    "start": "647200",
    "end": "652560"
  },
  {
    "text": "you'll generate your concepts brainstorm prototype do some preliminary design work evaluate validate iterate",
    "start": "652560",
    "end": "659680"
  },
  {
    "text": "and then at the end if the project even gets here a lot of times this work happens in-house or overseas or",
    "start": "659680",
    "end": "664800"
  },
  {
    "text": "shopped out to a vendor there'll be engineering cost analysis development work and all of that to make the thing real",
    "start": "664800",
    "end": "672079"
  },
  {
    "text": "stepping away from this you can think kind of broadly about what's happening here the idea that in the phase zero this",
    "start": "672079",
    "end": "677120"
  },
  {
    "text": "first phase really what we're doing in the project is we're making something that's useful okay so we're thinking about what is it",
    "start": "677120",
    "end": "684000"
  },
  {
    "text": "that people want how is our design going to really improve and enhance their life in some way that's meaningful",
    "start": "684000",
    "end": "689440"
  },
  {
    "text": "and we're going to design that this middle phase is kind of where a lot of this history of of the human factors work is much more",
    "start": "689440",
    "end": "695920"
  },
  {
    "text": "about ergonomics or usability right we've got to design we just need to make sure that it's functional right i can",
    "start": "695920",
    "end": "701360"
  },
  {
    "text": "accomplish the tasks that i need to do it's a tool that works for me i can get the job done",
    "start": "701360",
    "end": "707040"
  },
  {
    "text": "and here in the late phase i can make things delightful so this is kind of back to raymond loewy's work right i can take a",
    "start": "707040",
    "end": "713200"
  },
  {
    "text": "locomotive and i can skin it in a way that makes it look fast right or i can make a product",
    "start": "713200",
    "end": "718480"
  },
  {
    "text": "and i can package it in a way that makes it feel like something i want to consume but at this point the useful work and",
    "start": "718480",
    "end": "724320"
  },
  {
    "text": "the usable work has already happened and the best the designer can hope to do is kind of make it delightful and that's",
    "start": "724320",
    "end": "730240"
  },
  {
    "text": "why traditionally when designers have been asked to solve problems really late in the phase",
    "start": "730240",
    "end": "736399"
  },
  {
    "text": "a design is really prevented from being more useful or usable than it was to begin with and that kind of perpetuates the idea",
    "start": "736399",
    "end": "742399"
  },
  {
    "text": "that design is about superficial aesthetics and styling right so if you have a designer has all these strategic skills and you put them",
    "start": "742399",
    "end": "748959"
  },
  {
    "text": "in a company like microsoft and they have to design all the icons for powerpoint for the 50th time because there keeps",
    "start": "748959",
    "end": "754959"
  },
  {
    "text": "being a reorg right they're not they're not delivering the strategic value that they could the best they can do is make cute icons",
    "start": "754959",
    "end": "760399"
  },
  {
    "text": "that make people smile but it's not really changing the usability or the usefulness of the tool in the first place",
    "start": "760399",
    "end": "766320"
  },
  {
    "text": "and what we really want from design is usefulness right we want to make things that make the world better",
    "start": "766320",
    "end": "771600"
  },
  {
    "text": "and that's why this new finding phase is really critical need finding applies to all areas of design practice",
    "start": "771600",
    "end": "777200"
  },
  {
    "text": "or research typically in design practice that's you know product design physical physical products branding strategy work",
    "start": "777200",
    "end": "785120"
  },
  {
    "text": "all of those will benefit from kind of contextualizing research and a good deep empathy for what people",
    "start": "785120",
    "end": "790240"
  },
  {
    "text": "really need and in consumer industries this is",
    "start": "790240",
    "end": "795279"
  },
  {
    "text": "really important just because it's so expensive to be designing the wrong thing right it's very expensive to",
    "start": "795279",
    "end": "800480"
  },
  {
    "text": "engineer products very competitive marketplace everybody is you know trying to capture eyeballs quickly online with their new app",
    "start": "800480",
    "end": "806880"
  },
  {
    "text": "and if you're building the wrong thing or you miss it by a couple weeks or there's a release of something else just at the wrong time it can be pretty",
    "start": "806880",
    "end": "814560"
  },
  {
    "text": "much the death of your company okay so basically the point from human center design is it's really essential",
    "start": "814560",
    "end": "821040"
  },
  {
    "text": "that when we apply this methodology we're using it to work on the right design problem",
    "start": "821040",
    "end": "826240"
  },
  {
    "text": "and we're getting as early into the into the field talking to real people understanding real needs as we can to",
    "start": "826240",
    "end": "832160"
  },
  {
    "text": "make the most strategic value okay so now i want to look at the future",
    "start": "832160",
    "end": "840880"
  },
  {
    "start": "837000",
    "end": "897000"
  },
  {
    "text": "and what might be coming next so just a definition uh posthuman i'm not",
    "start": "840880",
    "end": "846320"
  },
  {
    "text": "sure how many of you have heard this term this has been kind of kicking around in the kind of theory literature for some",
    "start": "846320",
    "end": "851360"
  },
  {
    "text": "time many of you have probably heard of post-modernism right so we had modernism and then we had kind of you know late",
    "start": "851360",
    "end": "857360"
  },
  {
    "text": "modernism and then that kind of became postmodern sometime in the 70s and 80s and everything got",
    "start": "857360",
    "end": "863199"
  },
  {
    "text": "radically kind of decontextualized and very subjective um and people were thinking a lot about",
    "start": "863199",
    "end": "869199"
  },
  {
    "text": "kind of power relationships and structuring of information in the computerized age",
    "start": "869199",
    "end": "874560"
  },
  {
    "text": "it's what happens after modernism posthumanism takes a similar kind of critical theoretical look at what happens after",
    "start": "874560",
    "end": "881120"
  },
  {
    "text": "the human and particularly thinking about what happens when the technologies that we have become so deeply integrated into what it means",
    "start": "881120",
    "end": "887920"
  },
  {
    "text": "to be human that all of our sort of humanist values everything that we consider to be",
    "start": "887920",
    "end": "893600"
  },
  {
    "text": "humanism no longer applies um and the basic capacities of these future",
    "start": "893600",
    "end": "900639"
  },
  {
    "start": "897000",
    "end": "1197000"
  },
  {
    "text": "humans so radically exceed those of present humans that we can't really consider",
    "start": "900639",
    "end": "905920"
  },
  {
    "text": "them to be human by our current standards so for example here we have a human right this is an ordinary human and they",
    "start": "905920",
    "end": "912800"
  },
  {
    "text": "live quite happily and then maybe i don't know 20 years ago a bunch of things started",
    "start": "912800",
    "end": "919199"
  },
  {
    "text": "to change right we got computers then the internet now we have mobile devices",
    "start": "919199",
    "end": "924639"
  },
  {
    "text": "virtual environments augmented reality machine intelligence genetic engineering",
    "start": "924639",
    "end": "929920"
  },
  {
    "text": "organ transplants designer drugs right many of these things were very disruptive at first i'm sure in the 70s",
    "start": "929920",
    "end": "935600"
  },
  {
    "text": "if you've got a heart transplant right that's like ethically quite dubious it's you know not yet fully",
    "start": "935600",
    "end": "940639"
  },
  {
    "text": "approved we don't know if it's safe is that totally creepy now it's like standard practice right we've got",
    "start": "940639",
    "end": "945839"
  },
  {
    "text": "you drive up 101 there's a huge like like oregon oregon transplant center and they're shipping people in from all over the",
    "start": "945839",
    "end": "951920"
  },
  {
    "text": "world and putting organs on ice and that's completely normal this is what the post-humanist philosophers call the",
    "start": "951920",
    "end": "958959"
  },
  {
    "text": "transhuman and we are all now trans humans we're living in this transitional moment",
    "start": "958959",
    "end": "964800"
  },
  {
    "text": "between being human and being something else and those technologies are changing us",
    "start": "964800",
    "end": "971120"
  },
  {
    "text": "and what's coming next and it's not hard to imagine if you look at science fiction or you do research in this space is that",
    "start": "971120",
    "end": "977759"
  },
  {
    "text": "computers are getting faster and faster we're going to have autonomous robots performing more and more manual tasks and intelligence tasks",
    "start": "977759",
    "end": "983920"
  },
  {
    "text": "uh we're looking at technologies like like life extension maybe you can live forever just keep swapping out the organs forever or you'll become kind of",
    "start": "983920",
    "end": "989839"
  },
  {
    "text": "cyborg right you'll get a cyborg i don't know cochlear implant it's basically it's a bionic ear",
    "start": "989839",
    "end": "994959"
  },
  {
    "text": "right we're thinking even about once we have super intelligence right maybe you can upload your mind into the",
    "start": "994959",
    "end": "1001680"
  },
  {
    "text": "cloud and just like live in a virtual reality space you can design your own children think",
    "start": "1001680",
    "end": "1006720"
  },
  {
    "text": "about artificial life colonize space simulate yourself and determine what kind of drug you should take to live",
    "start": "1006720",
    "end": "1011759"
  },
  {
    "text": "longer or be happier yeah so these theories don't really",
    "start": "1011759",
    "end": "1017519"
  },
  {
    "text": "posit that human that humanness can slide that is what's currently",
    "start": "1017519",
    "end": "1023920"
  },
  {
    "text": "considered human may have been may have been post-human-like in many ways",
    "start": "1023920",
    "end": "1029520"
  },
  {
    "text": "a thousand years ago like we could solve diseases sure we could access information just uh yes the tip of our",
    "start": "1029520",
    "end": "1035120"
  },
  {
    "text": "fingers like these are these are very big differences yeah it's significantly different yes even i mean in in the world of",
    "start": "1035120",
    "end": "1042558"
  },
  {
    "text": "theory everything is a theory right so it's all hypothesis but you know it's fair to say",
    "start": "1042559",
    "end": "1047760"
  },
  {
    "text": "whether we call ourselves we're in modernism or we're in post-modernism maybe post-modernism is just a very high form of modernism",
    "start": "1047760",
    "end": "1054000"
  },
  {
    "text": "as far as humanism goes something is definitely changing because yeah okay so i i buy the",
    "start": "1054000",
    "end": "1060559"
  },
  {
    "text": "the the you know all theories are wrong some are interesting that that line sure i get it uh this particular",
    "start": "1060559",
    "end": "1067520"
  },
  {
    "text": "transition then what you know what is different from this transition compared to say what",
    "start": "1067520",
    "end": "1073840"
  },
  {
    "text": "like vanner bush was thinking when he was like okay um so i think what's happening here is in",
    "start": "1073840",
    "end": "1080880"
  },
  {
    "text": "theory the post-human is really no longer human so it doesn't resemble anything that could have happened without humanity intervening in",
    "start": "1080880",
    "end": "1087120"
  },
  {
    "text": "itself in a way which is really pretty extremely different than the past and the reason it's different has to do with evolution",
    "start": "1087120",
    "end": "1093120"
  },
  {
    "text": "humans are designed by nature if you will we evolved over millions of years in response to our environment and we can",
    "start": "1093120",
    "end": "1099520"
  },
  {
    "text": "say that maybe evolution is speeding up but evolution is shifting into a space of silicon into a space of",
    "start": "1099520",
    "end": "1105600"
  },
  {
    "text": "the digital the transhuman is designed by humans right and we've seen that design has become a really major deal",
    "start": "1105600",
    "end": "1111760"
  },
  {
    "text": "right we have engineering of pretty much anything look around right there is nothing that we interact",
    "start": "1111760",
    "end": "1116799"
  },
  {
    "text": "with apart from nature in a state park somewhere maybe that hasn't been designed by",
    "start": "1116799",
    "end": "1122160"
  },
  {
    "text": "humans and increasingly even our environment like everything is designed by humans right the posthuman is is unique in the sense",
    "start": "1122160",
    "end": "1128720"
  },
  {
    "text": "that it's post-evolutionary right so if you became an organ an organism which could choose you know basically design",
    "start": "1128720",
    "end": "1136240"
  },
  {
    "text": "all of its children before they were born by a chance right could simulate itself and determine how best to survive",
    "start": "1136240",
    "end": "1143200"
  },
  {
    "text": "could multiply itself across lots of bodies could upload its mind into the cloud and put it into another body we've really",
    "start": "1143200",
    "end": "1149200"
  },
  {
    "text": "exceeded the limitations of our kind of mechanical our mechanical limitations and we've moved into",
    "start": "1149200",
    "end": "1155360"
  },
  {
    "text": "a purely kind of digital platform for life which is pretty significantly different",
    "start": "1155360",
    "end": "1161520"
  },
  {
    "text": "and there's tons of theory here and it's very controversial and much of it is kind of wackadoo science stuff",
    "start": "1161520",
    "end": "1166720"
  },
  {
    "text": "and much of it is also quite compelling to be thinking about kind of strategically about what's coming",
    "start": "1166720",
    "end": "1171760"
  },
  {
    "text": "i don't know i think i think a lot of times science fiction and kind of speculative research does a lot to ask important questions",
    "start": "1171760",
    "end": "1179120"
  },
  {
    "text": "about whether that's a future we want to live in or not and a lot of times there's a big disconnect between",
    "start": "1179120",
    "end": "1185120"
  },
  {
    "text": "the scientific fact and the popular perception right cloning is really dangerous genetic engineering is really bad for the crops",
    "start": "1185120",
    "end": "1191120"
  },
  {
    "text": "right scientific story is much more complicated than that but it gets the discussion happening in public and",
    "start": "1191120",
    "end": "1196400"
  },
  {
    "text": "people start thinking really seriously about what kind of future do i want my kids to grow up in right what's the future of our planet",
    "start": "1196400",
    "end": "1202480"
  },
  {
    "start": "1197000",
    "end": "1437000"
  },
  {
    "text": "going to be if you look at this you'll see that there's really this huge convergence of technologies happening this century",
    "start": "1202480",
    "end": "1209039"
  },
  {
    "text": "right probably in the next 20 years we've got biotech nanotech infotech cognitive science all coming",
    "start": "1209039",
    "end": "1214640"
  },
  {
    "text": "together in a pretty radical way and what it's effectively doing is making new kinds of life so if i'm a kind of biological human and i",
    "start": "1214640",
    "end": "1222240"
  },
  {
    "text": "have new nanotechnology or new robot technology i'm becoming a cyborg right right now we're already all cyborgs right we're",
    "start": "1222240",
    "end": "1228799"
  },
  {
    "text": "effectively soft cyborgs we live in an internet of things connected to the cloud with our google glass",
    "start": "1228799",
    "end": "1234400"
  },
  {
    "text": "and our fitbit and our phone in our pocket right these are essentially extending us into a software space",
    "start": "1234400",
    "end": "1240159"
  },
  {
    "text": "we've got ubiquitous computing pervasive computing we are cyborgs okay then you've got",
    "start": "1240159",
    "end": "1246000"
  },
  {
    "text": "nanotechnology combining with info technology and you've got lots of people coming up with well we can effectively make lots of",
    "start": "1246000",
    "end": "1252080"
  },
  {
    "text": "little micro swarming robots and they can have sensors on them and we can drop them from airplanes or we can we can fly drones all over the place",
    "start": "1252080",
    "end": "1257679"
  },
  {
    "text": "right we're effectively building new kinds of artificial life there may be fundamental kinds of life they're about as smart as an insect or a",
    "start": "1257679",
    "end": "1263600"
  },
  {
    "text": "cockroach or maybe a rodent but over time those are going to become increasingly alive",
    "start": "1263600",
    "end": "1269039"
  },
  {
    "text": "and we can start to consider them as such in the infotech space we've effectively got simulated life right we",
    "start": "1269039",
    "end": "1275200"
  },
  {
    "text": "can run the entire population we can run simcity on our computer right and we can make a whole simulated city of people who are doing stuff or a",
    "start": "1275200",
    "end": "1281679"
  },
  {
    "text": "whole simulated ant colony that effectively behaves like an ant because the program has that many",
    "start": "1281679",
    "end": "1286880"
  },
  {
    "text": "neurons in its code then we've got the idea of meta life so i don't know you could this this gets",
    "start": "1286880",
    "end": "1294640"
  },
  {
    "text": "kind of metaphorical but you could kind of think about it like right now in your brain right there's a whole lot of neurons",
    "start": "1294640",
    "end": "1301280"
  },
  {
    "text": "and they've got synapses and they're firing electrical pulses and each neuron is quite content and quite alive just as",
    "start": "1301280",
    "end": "1307760"
  },
  {
    "text": "one little cell doing what it does talk to the other neurons we are now all living in a kind of",
    "start": "1307760",
    "end": "1313919"
  },
  {
    "text": "environment here where we're sort of like the neurons right we all communicate with each other we live",
    "start": "1313919",
    "end": "1319760"
  },
  {
    "text": "in our little bubble we go to work we upload stuff to the internet and we've got we've got this kind of",
    "start": "1319760",
    "end": "1325280"
  },
  {
    "text": "meta consciousness coming online right the internet could switch on and start to pay attention so it's a new kind of meta",
    "start": "1325280",
    "end": "1331360"
  },
  {
    "text": "life it's hard hard for us to see it because it's in a whole different paradigm space um but but the point here is that we're",
    "start": "1331360",
    "end": "1337039"
  },
  {
    "text": "entering this really pretty radically different kind of post-human existence where we've got cyborgs artificial life",
    "start": "1337039",
    "end": "1342799"
  },
  {
    "text": "simulated life metalife all kind of coming online and interacting in really interesting unexpected ways",
    "start": "1342799",
    "end": "1350080"
  },
  {
    "text": "i feel like this slide could have existed about 20 years ago yes and i'm wondering what's changed why",
    "start": "1355360",
    "end": "1362799"
  },
  {
    "text": "now um so sure from a research perspective it's true i think i think why now is",
    "start": "1362799",
    "end": "1369039"
  },
  {
    "text": "that it's in the public imagination in a much more real way these changes are now we're getting we're getting all the stuff on",
    "start": "1369039",
    "end": "1374880"
  },
  {
    "text": "kickstarter we're getting updates all the time from our app you know from our app store we've got people dropping out of high school to",
    "start": "1374880",
    "end": "1380960"
  },
  {
    "text": "make you know to make crazy things that are doing incredible stuff we've got artificial intelligence happening",
    "start": "1380960",
    "end": "1386480"
  },
  {
    "text": "i think it's just becoming much more pervasive and it's becoming exponential that's all we're on an exponential curve and and",
    "start": "1386480",
    "end": "1392480"
  },
  {
    "text": "the point is basically just that the paradigm shift rate for technology change we've got moore's law right so whatever it is every every two",
    "start": "1392480",
    "end": "1398400"
  },
  {
    "text": "or three years the amount of space on our silicon chip doubles and we've got more and more computational power",
    "start": "1398400",
    "end": "1404000"
  },
  {
    "text": "and it can be really hard for us to envision that from our current point in time",
    "start": "1404000",
    "end": "1409039"
  },
  {
    "text": "because all we really have to reflect on is a linear view of the past and when we look at our clock it's",
    "start": "1409039",
    "end": "1414960"
  },
  {
    "text": "ticking at the same speed so typically humans when we think about our past right",
    "start": "1414960",
    "end": "1420480"
  },
  {
    "text": "we've got this intuitively kind of linear view of our exponential history so just for example in 1990 some",
    "start": "1420480",
    "end": "1427039"
  },
  {
    "text": "biochemists had transcribed about a 10 000th of the human genome and given their rate of progress at the",
    "start": "1427039",
    "end": "1432880"
  },
  {
    "text": "time the experts in the field of genetics predicted that it would take or it could take up to 100 years to",
    "start": "1432880",
    "end": "1438080"
  },
  {
    "start": "1437000",
    "end": "1617000"
  },
  {
    "text": "complete and that was accomplished in under 15 years here's ray kurzweil famous futurist and",
    "start": "1438080",
    "end": "1444400"
  },
  {
    "text": "crackpot scientist depending if you like him or not but he's drawing on a lot of pretty robust kind of empirical studies of",
    "start": "1444400",
    "end": "1449840"
  },
  {
    "text": "computational power keeps doubling right so we won't experience 100 years of technological advance in the 21st century",
    "start": "1449840",
    "end": "1455279"
  },
  {
    "text": "we will witness on the order of 20 000 years of progress when measured by today's rate of progress or about a thousand times",
    "start": "1455279",
    "end": "1461600"
  },
  {
    "text": "greater than that was achieved in the 20th century that's pretty phenomenal here's growth",
    "start": "1461600",
    "end": "1467840"
  },
  {
    "text": "in supercomputer power on our logarithmic graph okay it's now the year 2015 when i first did this talk",
    "start": "1467840",
    "end": "1474159"
  },
  {
    "text": "it was 2010 and there's been several new supercomputers since then kurzweil argues that what is required",
    "start": "1474159",
    "end": "1481039"
  },
  {
    "text": "for what he calls functional brain simulation is whatever this is 10 to the 15th uh",
    "start": "1481039",
    "end": "1486720"
  },
  {
    "text": "floating point operations per second in terms of super supercomputer power now this says nothing about the software",
    "start": "1486720",
    "end": "1493919"
  },
  {
    "text": "that your brain is running so when he says functional simulation of the brain he basically means there's enough there",
    "start": "1493919",
    "end": "1500640"
  },
  {
    "text": "to model the kinds of in ins and outs of say the hippocampus the visual cortex all the different",
    "start": "1500640",
    "end": "1506640"
  },
  {
    "text": "parts of the brain unfortunately neuroscience is nowhere near deep enough along the way to fully understand how all that stuff is wired",
    "start": "1506640",
    "end": "1512640"
  },
  {
    "text": "but the point here is just we have raw computational power and you know within some amount of time to get the design",
    "start": "1512640",
    "end": "1517840"
  },
  {
    "text": "right we could be running a functional simulation of the human brain by 2013 which is two years ago for human",
    "start": "1517840",
    "end": "1524559"
  },
  {
    "text": "brain neural simulation the required computational power would be equivalent in 2025",
    "start": "1524559",
    "end": "1530400"
  },
  {
    "text": "to basically build a simulation model of every molecule in every neuron",
    "start": "1530400",
    "end": "1535760"
  },
  {
    "text": "in every synapse in the human brain which is pretty phenomenal and if you look forward from that you can basically do the same",
    "start": "1535760",
    "end": "1542480"
  },
  {
    "text": "calculation uh by dividing the cost in half every year so that by the year 2045",
    "start": "1542480",
    "end": "1548240"
  },
  {
    "text": "we would have human equivalent personal computer for two dollars",
    "start": "1548240",
    "end": "1553600"
  },
  {
    "text": "okay that's 30 years away it's coming fast and you know frankly by the year 2030 it",
    "start": "1553840",
    "end": "1559919"
  },
  {
    "text": "would cost probably half what your laptop cost today okay now let's look at the world",
    "start": "1559919",
    "end": "1565679"
  },
  {
    "text": "population okay we've got by recent estimates about seven billion",
    "start": "1565679",
    "end": "1570720"
  },
  {
    "text": "people on the planet and you know people think that's going to trail off at some point",
    "start": "1570720",
    "end": "1576640"
  },
  {
    "text": "probably as we get to the end of the century but we're adding in all of these super computer people right",
    "start": "1576640",
    "end": "1584720"
  },
  {
    "text": "no matter how you look at it right this is what this is what the future is called the singularity right infinite population by the year 2045. of",
    "start": "1584720",
    "end": "1591360"
  },
  {
    "text": "course you know what really is the difference between having two billion and having infinite billion right maybe",
    "start": "1591360",
    "end": "1598320"
  },
  {
    "text": "not a whole lot if our social and kind of political systems haven't changed but it matters a lot in the sense that",
    "start": "1598320",
    "end": "1604000"
  },
  {
    "text": "we need to understand how that computation will affect the rights of individual humans to vote",
    "start": "1604000",
    "end": "1609360"
  },
  {
    "text": "or the ability of individual humans to perform the work that they need to do or to communicate with others right the distribution of that",
    "start": "1609360",
    "end": "1615279"
  },
  {
    "text": "technology is going to be a very important issue if current accelerations in computer power continue to increase at their",
    "start": "1615279",
    "end": "1621760"
  },
  {
    "start": "1617000",
    "end": "1647000"
  },
  {
    "text": "current rates we will have a singularity by the year 2045 as humanity will have created seemingly infinite computational power",
    "start": "1621760",
    "end": "1628400"
  },
  {
    "text": "um many futurists hope that the earth's ecosystem will be transformed into this computer-controlled technogaian utopia",
    "start": "1628400",
    "end": "1635440"
  },
  {
    "text": "and it will all kind of balance itself out we're living in the clouds everything is taken care of we have infinite resources solar power",
    "start": "1635440",
    "end": "1641520"
  },
  {
    "text": "and everybody's happy and people will upload their minds into this eternal simulation of pure fantasy and live",
    "start": "1641520",
    "end": "1646559"
  },
  {
    "text": "forever in silicon wafers but clearly whatever happens to get to whatever",
    "start": "1646559",
    "end": "1652480"
  },
  {
    "start": "1647000",
    "end": "1817000"
  },
  {
    "text": "state that's going to be we're going to face some pretty profound challenges uh human intelligence will effectively",
    "start": "1652480",
    "end": "1657840"
  },
  {
    "text": "be obsolete you know the tools that we have maybe the software running the social structures we have will be in place",
    "start": "1657840",
    "end": "1663279"
  },
  {
    "text": "but the intelligence itself will no longer be relevant okay economic wealth is already frankly",
    "start": "1663279",
    "end": "1669440"
  },
  {
    "text": "in a bank right but it will be entirely in the hands of super intelligent machines okay they'll make the decisions on where",
    "start": "1669440",
    "end": "1675600"
  },
  {
    "text": "to invest they'll make decisions on what to to do presuming we manage to survive at all and it's likely that the",
    "start": "1675600",
    "end": "1681440"
  },
  {
    "text": "people who do end up at the very tippy top will be the ones who control those super computers and have all them the wealth",
    "start": "1681440",
    "end": "1686720"
  },
  {
    "text": "already so the point here is just that there's numerous existential and ethical risks",
    "start": "1686720",
    "end": "1692080"
  },
  {
    "text": "coming we don't know what they all are but we have to confront them and we should start thinking about them if we're really interested in human",
    "start": "1692080",
    "end": "1697520"
  },
  {
    "text": "centered design right the future of humans let's think about things that can go wrong okay",
    "start": "1697520",
    "end": "1704559"
  },
  {
    "text": "there's a guy at oxford named nick bostrom who's done a ton of really good post-humanism work and he wrote an",
    "start": "1704559",
    "end": "1709600"
  },
  {
    "text": "excellent paper on the existential risks which this draws from basically what he's saying is",
    "start": "1709600",
    "end": "1715039"
  },
  {
    "text": "you know if you have a personal risk that's endurable like your car gets stolen",
    "start": "1715039",
    "end": "1720080"
  },
  {
    "text": "or you get killed okay that is still you know it's not endurable to",
    "start": "1720080",
    "end": "1725360"
  },
  {
    "text": "you it's terminal but it's kind of local in scope right here's a slightly bigger local scope you",
    "start": "1725360",
    "end": "1732880"
  },
  {
    "text": "know there's a recession and everybody loses their job or there's genocide",
    "start": "1732880",
    "end": "1738480"
  },
  {
    "text": "right permanent enslavement everybody is uh is pretty much taken out right that's",
    "start": "1738480",
    "end": "1743840"
  },
  {
    "text": "not good uh here's the thinning of the ozone layer it affects everyone everywhere right it's endurable but it's global an",
    "start": "1743840",
    "end": "1752080"
  },
  {
    "text": "existential risk is in this top category it's something that's global and something that's",
    "start": "1752080",
    "end": "1757440"
  },
  {
    "text": "terminal and the scary thing is that many of these are being created by us right now",
    "start": "1757440",
    "end": "1764720"
  },
  {
    "text": "an existential risk is defined as one where an adverse outcome would either annihilate earth originating intelligent life",
    "start": "1764720",
    "end": "1769760"
  },
  {
    "text": "or permanently and drastically curtail its potential okay so the issue here and it's very",
    "start": "1769760",
    "end": "1776320"
  },
  {
    "text": "different than human centered design or engineering practice today is that existential risks don't give you a second chance if you're wrong",
    "start": "1776320",
    "end": "1783120"
  },
  {
    "text": "you can't do rapid iteration and prototyping with existential risks it doesn't work right for there to be a risk given the",
    "start": "1783120",
    "end": "1789279"
  },
  {
    "text": "knowledge and understanding available it suffices that there's some subjective probability of an adverse outcome our only possible course of",
    "start": "1789279",
    "end": "1797200"
  },
  {
    "text": "action is to examine possible future scenarios and use our best current subjective",
    "start": "1797200",
    "end": "1802240"
  },
  {
    "text": "estimate on what the objective risk factors may be even if later we determine that some of them are objectively impossible we",
    "start": "1802240",
    "end": "1808640"
  },
  {
    "text": "don't know whether something is objectively risky or not then it's risky in the subjective sense and the only thing we can do",
    "start": "1808640",
    "end": "1814399"
  },
  {
    "text": "is base our decisions on that subjective reality because we can't make a mistake",
    "start": "1814399",
    "end": "1820000"
  },
  {
    "start": "1817000",
    "end": "2167000"
  },
  {
    "text": "okay consider this this plot let's imagine that the technological potential of humanity is",
    "start": "1820000",
    "end": "1825279"
  },
  {
    "text": "getting stronger and what's called the cultural potential is getting stronger okay and right now we're in this sort of humanist space",
    "start": "1825279",
    "end": "1831279"
  },
  {
    "text": "moving into the transhuman space heading towards posthumanity and uploading into the cosmic mind",
    "start": "1831279",
    "end": "1837840"
  },
  {
    "text": "these are the four kinds of existential risk classifications that can happen right we can go out with a crunch with a",
    "start": "1837840",
    "end": "1844240"
  },
  {
    "text": "bang with a whimper or with a shriek we'll look at them quickly",
    "start": "1844240",
    "end": "1849279"
  },
  {
    "text": "just before we move on so a bang would be the immediate destruction of earth originating intelligent life altogether",
    "start": "1849279",
    "end": "1854399"
  },
  {
    "text": "could be a natural disaster an accident an intentional act of destruction like a nuclear holocaust right we start",
    "start": "1854399",
    "end": "1860320"
  },
  {
    "text": "world war three everything gets blown up no life survives bang okay",
    "start": "1860320",
    "end": "1865440"
  },
  {
    "text": "the deliberate misuse of nanotechnology okay somebody in a lab somewhere makes nanotech",
    "start": "1865440",
    "end": "1870880"
  },
  {
    "text": "targets it some people gets out multiplies kills everything uh badly programmed super intelligence",
    "start": "1870880",
    "end": "1876880"
  },
  {
    "text": "it shuts down all of the global stock markets and it shuts down all of our ability to produce anything",
    "start": "1876880",
    "end": "1883360"
  },
  {
    "text": "right sort of takes control of our systems that could that could launch any of the other ones right it could set off a",
    "start": "1883360",
    "end": "1888960"
  },
  {
    "text": "nuclear war of its own we could have a genetically engineered biological agent the accidental misuse of nanotech right",
    "start": "1888960",
    "end": "1895760"
  },
  {
    "text": "this is what they call the grey goo scenario where it sort of sneaks out and then stuff goes wrong asteroid or",
    "start": "1895760",
    "end": "1901760"
  },
  {
    "text": "comic impacts pretty much did in the dinosaurs uh we could hit hit an asteroid",
    "start": "1901760",
    "end": "1907919"
  },
  {
    "text": "we could have runaway global warming and we just we're too late down the road right we can't turn the clock back",
    "start": "1907919",
    "end": "1913200"
  },
  {
    "text": "um naturally occurring disease yeah ebola might uh i don't know might evolve and become",
    "start": "1913200",
    "end": "1918960"
  },
  {
    "text": "airborne you know we've got a terrible pathogen a physics disaster we just blow up the universe",
    "start": "1918960",
    "end": "1925039"
  },
  {
    "text": "right i don't know what about this one what if in the future we have super",
    "start": "1925039",
    "end": "1930399"
  },
  {
    "text": "intelligence and the super intelligent future people decide that they want to predict ways of surviving so they set up",
    "start": "1930399",
    "end": "1936159"
  },
  {
    "text": "simulations of possible futures or possible paths and we're living in one of them and for",
    "start": "1936159",
    "end": "1942399"
  },
  {
    "text": "whatever reason they decide to switch us off it could happen or something unforeseen",
    "start": "1942399",
    "end": "1948000"
  },
  {
    "text": "right you just never know right it's a risky world something might happen we need to be prepared okay let's think",
    "start": "1948000",
    "end": "1954480"
  },
  {
    "text": "about crunches so these are the ones where a technological potential to reach posthumanity is somehow thwarted but",
    "start": "1954480",
    "end": "1960000"
  },
  {
    "text": "human life sort of continues so the most common of these are like a near bang right there's some kind of",
    "start": "1960000",
    "end": "1965919"
  },
  {
    "text": "resource depletion ecological destruction civilization fails to recover in the aftermath of",
    "start": "1965919",
    "end": "1970960"
  },
  {
    "text": "a near bang there's a lot of dystopian movies that kind of live in this space the kind of mad max world warrior stuff",
    "start": "1970960",
    "end": "1976640"
  },
  {
    "text": "okay uh we've got the shrieks now shrieks are an interesting case in that they introduce the notion of",
    "start": "1976640",
    "end": "1982240"
  },
  {
    "text": "values right so this is one in which an undesirably limited posthumanity is achieved",
    "start": "1982240",
    "end": "1987840"
  },
  {
    "text": "although without knowing what's desirable it's really hard to identify whether we're on that path or not",
    "start": "1987840",
    "end": "1994159"
  },
  {
    "text": "so for example we could have a flawed superintelligence which just kind of like i don't know convinces",
    "start": "1994159",
    "end": "1999360"
  },
  {
    "text": "us that it's doing a great job but consumes all the resources we could be take taken over by a transcending upload right some",
    "start": "1999360",
    "end": "2005679"
  },
  {
    "text": "super billionaire hollywood mogul is the first one to develop super intelligence uploads his mind",
    "start": "2005679",
    "end": "2010799"
  },
  {
    "text": "and then you know wreaks havoc on everyone else i don't know if you've seen gattaca is the notion of this genetic divide so",
    "start": "2010799",
    "end": "2016640"
  },
  {
    "text": "there's kind of multiple classes of humans there's those who have access to biological agents that enable",
    "start": "2016640",
    "end": "2022000"
  },
  {
    "text": "them to replicate and stay healthy and become sort of superhumans and then there's everyone else who's in a sort of second class",
    "start": "2022000",
    "end": "2028080"
  },
  {
    "text": "we have the terminator scenario the repressive totalitarian global scheme and so on and then we have whimpers okay",
    "start": "2028080",
    "end": "2035919"
  },
  {
    "text": "these are where somehow core human values are potentially slowly eroded by evolutionary development probably would take a really long time i",
    "start": "2035919",
    "end": "2042720"
  },
  {
    "text": "don't know we could last pretty far get in the space colonization more with extra terrestrials or whatever something might happen okay so what i've",
    "start": "2042720",
    "end": "2050480"
  },
  {
    "text": "done here is i just took all those risk categories and i plotted them onto this little plot",
    "start": "2050480",
    "end": "2055919"
  },
  {
    "text": "it's got the eventual risk at the top and the immediate risk at the bottom",
    "start": "2055919",
    "end": "2061040"
  },
  {
    "text": "and things that are beyond our control are on the left and things that are within our control are on the right",
    "start": "2061040",
    "end": "2067040"
  },
  {
    "text": "okay so these ones over here on the left good news is they're pure fantasy or speculation",
    "start": "2067040",
    "end": "2072560"
  },
  {
    "text": "and there's nothing we can do about it anyway so we can just exclude those not a problem and then there's these",
    "start": "2072560",
    "end": "2078000"
  },
  {
    "text": "ones over here which are like too remote to matter if we manage to survive till we have a space war with extraterrestrials we did pretty good right too to matter",
    "start": "2078000",
    "end": "2086398"
  },
  {
    "text": "okay then there's all this stuff right the common impact the global warming well hopefully it's preventable if we",
    "start": "2086399",
    "end": "2092480"
  },
  {
    "text": "have adequate preparation there's lots of people thinking about it now but it's interesting to me that right now global warming is kind of the thing",
    "start": "2092480",
    "end": "2097599"
  },
  {
    "text": "right anybody who believes in it who's in a kind of liberal-minded academic environment such as this like",
    "start": "2097599",
    "end": "2103599"
  },
  {
    "text": "we've got to do something about that we don't quite know what to do we need to study it we need to understand we need a new policy but like we're working on it",
    "start": "2103599",
    "end": "2108720"
  },
  {
    "text": "we're not doing enough we're not doing it fast enough but hopefully if we prepare we can avoid",
    "start": "2108720",
    "end": "2113839"
  },
  {
    "text": "those okay and then we've got all of this stuff okay these are",
    "start": "2113839",
    "end": "2118960"
  },
  {
    "text": "legitimate threats they require some kind of engineering or political strategy to make them better",
    "start": "2118960",
    "end": "2124320"
  },
  {
    "text": "um and we're kind of stuck with them here's bill joy he um he's the",
    "start": "2124320",
    "end": "2130560"
  },
  {
    "text": "co-founder of sun microsystems and basically his his opinion on this he came out pretty",
    "start": "2130560",
    "end": "2135599"
  },
  {
    "text": "strong early on in the post-humanism kind of literature taking a strong stand here he said we're being propelled into this new century",
    "start": "2135599",
    "end": "2141680"
  },
  {
    "text": "with no plan no control no breaks the only realistic alternative i see is relinquishment to limit development of the technologies",
    "start": "2141680",
    "end": "2148640"
  },
  {
    "text": "that are too dangerous by limiting our pursuit of certain kinds of knowledge unlike",
    "start": "2148640",
    "end": "2153920"
  },
  {
    "text": "during the manhattan project we are not in a war we do not have an impeccable enemy that's threatening our civilization",
    "start": "2153920",
    "end": "2160800"
  },
  {
    "text": "we're driven instead by our habits our desires our economic system and our competitive need to know",
    "start": "2160800",
    "end": "2167680"
  },
  {
    "start": "2167000",
    "end": "2262000"
  },
  {
    "text": "and he talks about it not in terms of weapons of mass destruction but in knowledge enabled mass",
    "start": "2167680",
    "end": "2173040"
  },
  {
    "text": "destruction right where individuals just because they're curious if they can download the blueprints for an atom bomb in the",
    "start": "2173040",
    "end": "2178640"
  },
  {
    "text": "basement for their science fair project get access to information very easily right you've got terrorists who are",
    "start": "2178640",
    "end": "2184480"
  },
  {
    "text": "really interested in having that information or we have people who you know just were kind of curious what happens when you",
    "start": "2184480",
    "end": "2189520"
  },
  {
    "text": "smash neutrinos together or what might happen when you do a certain kind of mutation to a virus okay",
    "start": "2189520",
    "end": "2198079"
  },
  {
    "text": "okay uh in his view there are certain things that we should just relinquish all together right so here we have the grey goo kind",
    "start": "2198079",
    "end": "2204320"
  },
  {
    "text": "of biological agent scenarios maybe we need really strong controls and kind of uh biohazard",
    "start": "2204320",
    "end": "2210240"
  },
  {
    "text": "assessments and you're just saying you know there's certain stuff we're not gonna do it's not ethically cool and then there's these ones over here that we need to regulate and you can see",
    "start": "2210240",
    "end": "2216000"
  },
  {
    "text": "that we're already sort of doing it right we've got nuclear power right it's totally in our control it's totally a risk",
    "start": "2216000",
    "end": "2221839"
  },
  {
    "text": "and there's a lot of international negotiation going around to set those policies up the other ones you'll notice are pretty",
    "start": "2221839",
    "end": "2229280"
  },
  {
    "text": "much entirely well apart from maybe gattaca these are hci technologies okay here's",
    "start": "2229280",
    "end": "2234960"
  },
  {
    "text": "elon musk this was just about a month ago he's the founder of spacex co-founder of tesla",
    "start": "2234960",
    "end": "2241359"
  },
  {
    "text": "definitely you know one of those guys who will be uploading his mind to the supercomputer if he gets the chance uh i think we should be careful about",
    "start": "2241359",
    "end": "2247599"
  },
  {
    "text": "artificial intelligence if i had to guess that what our biggest existential threat is it is probably that i'm",
    "start": "2247599",
    "end": "2253119"
  },
  {
    "text": "increasingly inclined to think there should be some regulatory oversight maybe national or international level just to make sure that we don't do",
    "start": "2253119",
    "end": "2258480"
  },
  {
    "text": "something very foolish with artificial intelligence we're summoning the demon",
    "start": "2258480",
    "end": "2263838"
  },
  {
    "text": "let's think about how we might go about regulating something like that or if we're even prepared to think about",
    "start": "2264640",
    "end": "2269680"
  },
  {
    "text": "that right currently we have a political system which is pretty broken um and for the most part it's split onto",
    "start": "2269680",
    "end": "2275599"
  },
  {
    "text": "two axes i've sort of combined them together here we've got sort of regulated markets on the liberal left maybe that's socialism",
    "start": "2275599",
    "end": "2281359"
  },
  {
    "text": "and we've got kind of the conservative right with deregulated markets interestingly there's like another axis here which is kind of like the uh",
    "start": "2281359",
    "end": "2287359"
  },
  {
    "text": "the social one right sort of like how do i feel about a social issue like abortion right in that case we might actually",
    "start": "2287359",
    "end": "2293040"
  },
  {
    "text": "regulate the social issue or have more freedom what's basically happening here in the 21st century",
    "start": "2293040",
    "end": "2299680"
  },
  {
    "start": "2297000",
    "end": "2794000"
  },
  {
    "text": "is that we need to start thinking about the regulation of technology and particularly computer oriented",
    "start": "2299680",
    "end": "2305680"
  },
  {
    "text": "technology human computer interaction technology and there's two fields of thought here you can regulate it or you can be kind",
    "start": "2305680",
    "end": "2311520"
  },
  {
    "text": "of techno-progressive right you can deregulate it these are important issues and what you result with",
    "start": "2311520",
    "end": "2316800"
  },
  {
    "text": "is this interesting kind of strange space of biopolitics in the 21st century",
    "start": "2316800",
    "end": "2321839"
  },
  {
    "text": "where you've got the libertarian transhumanist the techno-progressive transhumanist the left-wing bioconservatives the right-wing by",
    "start": "2321839",
    "end": "2327280"
  },
  {
    "text": "conservatives and you can imagine some interesting alliances starting to happen depending on what the issue is so the issue for post-human center",
    "start": "2327280",
    "end": "2333760"
  },
  {
    "text": "design and i think maybe design has always been a political tool to a certain degree but more so",
    "start": "2333760",
    "end": "2339119"
  },
  {
    "text": "than ever i think the design decisions we make which are always going to be judgment calls about what we should and shouldn't work on",
    "start": "2339119",
    "end": "2344880"
  },
  {
    "text": "are going to be increasingly political decisions about what we believe in and what kind of future we imagine we want to live in and the question for",
    "start": "2344880",
    "end": "2351680"
  },
  {
    "text": "posthuman center design is then like how do we align ourselves depending on the issue somewhere in this space we just need to",
    "start": "2351680",
    "end": "2356720"
  },
  {
    "text": "sort of become more aware of it than maybe we've been in the past so you can think about i don't know in the libertarian transhumanist space kind of total",
    "start": "2356720",
    "end": "2363520"
  },
  {
    "text": "deregulation of stuff and you see it happening in europe right now right google is not being regulated in terms of its market",
    "start": "2363520",
    "end": "2369200"
  },
  {
    "text": "kind of potential to have a monopoly it's not being regulated in terms of what it's allowed to do with that and europe is sort of saying",
    "start": "2369200",
    "end": "2376240"
  },
  {
    "text": "hey maybe that's not such a good idea maybe we need to be thinking about having some kind of government oversight",
    "start": "2376240",
    "end": "2381440"
  },
  {
    "text": "to make sure it's a fair market okay we're gonna regulate the market there's gonna be government oversight and already",
    "start": "2381440",
    "end": "2386800"
  },
  {
    "text": "we see this happening in say the wearable space right you've got your job on you've got your fitbit but you're not allowed to predict",
    "start": "2386800",
    "end": "2393599"
  },
  {
    "text": "whether someone's gonna have a heart attack because you didn't do a clinical trial right and so the nih or whichever",
    "start": "2393599",
    "end": "2399040"
  },
  {
    "text": "regulatory agency really cares about that made sure that there was a regulation in place to protect it but that's not the case",
    "start": "2399040",
    "end": "2405680"
  },
  {
    "text": "for most consumer technologies right that's not the case for the internet for the most part um right now we're kind of running",
    "start": "2405680",
    "end": "2410800"
  },
  {
    "text": "rampant in a sort of libertarian you know crazy world of people are innovating starting new startups and",
    "start": "2410800",
    "end": "2416720"
  },
  {
    "text": "people are starting to use them facebook whatever okay then we have things like what i'd call more of a moral regulation",
    "start": "2416720",
    "end": "2422720"
  },
  {
    "text": "so you could consider the pro-life movement although there's probably lots of other uh examples of this you know this is someone who's",
    "start": "2422720",
    "end": "2428960"
  },
  {
    "text": "like well we should have a deregulated market but it's just not right right we don't believe that you should",
    "start": "2428960",
    "end": "2434240"
  },
  {
    "text": "be allowed to have an abortion on some kind of moral ground and you can imagine some interesting stuff happening",
    "start": "2434240",
    "end": "2439520"
  },
  {
    "text": "here where i don't know maybe you get the environmentalists who really don't want uh genetic modification of certain kind",
    "start": "2439520",
    "end": "2446160"
  },
  {
    "text": "of animals or crops or whatever to team up with those guys and say you know we'll join you on the abortion case if we can just do a ban all together on",
    "start": "2446160",
    "end": "2452480"
  },
  {
    "text": "germline therapy for children or whatever then over here we've got kind of total regulation this is where the nuclear",
    "start": "2452480",
    "end": "2458800"
  },
  {
    "text": "power i mean even just recently we had the net neutrality stuff going on which is really pretty interesting right because it's basically saying",
    "start": "2458800",
    "end": "2464960"
  },
  {
    "text": "not only does the government have the ability to regulate what markets they can play in but that",
    "start": "2464960",
    "end": "2470319"
  },
  {
    "text": "we are actually regulating the technology itself right at the government level to make sure that people are giving equal access",
    "start": "2470319",
    "end": "2476480"
  },
  {
    "text": "to bandwidth on the internet these are just examples but there's lots more of this coming",
    "start": "2476480",
    "end": "2481920"
  },
  {
    "text": "so what i would argue is simply the following that when we talk about human-centered design",
    "start": "2481920",
    "end": "2487599"
  },
  {
    "text": "and all of the good things that it does for the world um you know it's effectively an",
    "start": "2487599",
    "end": "2493599"
  },
  {
    "text": "instrument of power it proposes that we're going to humanize technology by making it more useful and we all",
    "start": "2493599",
    "end": "2500319"
  },
  {
    "text": "think oh that sounds like a really good idea yeah we're going to humanize technology we're going to understand our users we're going to design something for them",
    "start": "2500319",
    "end": "2506240"
  },
  {
    "text": "make it useful but what's really going on is that somebody's funding it somebody cares about it happening or not",
    "start": "2506240",
    "end": "2513119"
  },
  {
    "text": "right and somebody benefits from it it might be a client might be a founder of a startup might be",
    "start": "2513119",
    "end": "2519280"
  },
  {
    "text": "google might be facebook right they want more eyeballs looking at their technology for whatever reason they've invested",
    "start": "2519280",
    "end": "2526319"
  },
  {
    "text": "heavily in applying this process and it is creating more human goodness",
    "start": "2526319",
    "end": "2531680"
  },
  {
    "text": "right that's what they're doing and if you think about it that way what they're effectively doing is they are",
    "start": "2531680",
    "end": "2537520"
  },
  {
    "text": "engineering and amplifying the values that they profess when they begin such a",
    "start": "2537520",
    "end": "2542720"
  },
  {
    "text": "project this is true not just of human centered design is true pretty much any engineering right if you decide that you invest",
    "start": "2542720",
    "end": "2549760"
  },
  {
    "text": "however many billions of dollars doing brain research then you know you're gonna do brain research and you're gonna end up with a",
    "start": "2549760",
    "end": "2555760"
  },
  {
    "text": "lot of knowledge there and you're gonna kind of advance a future in which the value set of the people um if it's",
    "start": "2555760",
    "end": "2562560"
  },
  {
    "text": "profitable and they're doing good business and they beat out the competitors that advances",
    "start": "2562560",
    "end": "2568240"
  },
  {
    "text": "sure so there's always which i agree with this uh so for example i think facebook's",
    "start": "2568240",
    "end": "2574400"
  },
  {
    "text": "promulgation of the news feed over the last 10 years was an interesting case where",
    "start": "2574400",
    "end": "2579680"
  },
  {
    "text": "it's through through user-centered design in some sense has changed what we consider to be our",
    "start": "2579680",
    "end": "2586640"
  },
  {
    "text": "values of what's okay and what's not okay uh to show by default about what other people are up to",
    "start": "2586640",
    "end": "2592880"
  },
  {
    "text": "um and yet i feel like a core part of the user center design process is that",
    "start": "2592880",
    "end": "2597920"
  },
  {
    "text": "if you stray too far from human values that you don't understand or observe correctly or synthesize well",
    "start": "2597920",
    "end": "2604960"
  },
  {
    "text": "gonna walk away they're not gonna use your thing so i wonder to a certain extent",
    "start": "2604960",
    "end": "2610240"
  },
  {
    "text": "is this gonna be self-regulating like how strong sure it's an interesting question and i think we don't know i mean the",
    "start": "2610240",
    "end": "2616880"
  },
  {
    "text": "reality is that i'm a big fan of human centered design i think it's great and for the most part",
    "start": "2616880",
    "end": "2622319"
  },
  {
    "text": "it's better than the other kind of design which wasn't human-centered right and also for the most part when you do human",
    "start": "2622319",
    "end": "2627359"
  },
  {
    "text": "center design i don't know somewhere i was reading a business article not long ago that basically said design design-driven",
    "start": "2627359",
    "end": "2633599"
  },
  {
    "text": "innovation cultures and you know they listed a bunch of examples a company like whole foods right has a lot less hierarchy than most",
    "start": "2633599",
    "end": "2640000"
  },
  {
    "text": "organizations has a lot more kind of employee input at the ground level about how the company should be what the value should be",
    "start": "2640000",
    "end": "2645359"
  },
  {
    "text": "those companies which embrace human standard design values are and they empirically show you know",
    "start": "2645359",
    "end": "2651040"
  },
  {
    "text": "70 more profitable right because they're more in tune with their employees they have less employee turnover they don't spend much on hr the",
    "start": "2651040",
    "end": "2657280"
  },
  {
    "text": "people are happier working there it improves the brand everything feels really consistent it's like okay we're starting to measure that stuff and that's really cool and i think",
    "start": "2657280",
    "end": "2663520"
  },
  {
    "text": "that's a role where the hci stuff has a huge power to really assist in human centered design",
    "start": "2663520",
    "end": "2670000"
  },
  {
    "text": "because now every click that everybody makes on any app every a b test every you know every variant of anything you can do",
    "start": "2670000",
    "end": "2676240"
  },
  {
    "text": "vast kind of crowd source studies to understand what people prefer what people don't and you can optimize and you can make it you can get all that",
    "start": "2676240",
    "end": "2682319"
  },
  {
    "text": "baked in i think the point here is just to say that you can choose in the first place whether you're doing human centered",
    "start": "2682319",
    "end": "2687440"
  },
  {
    "text": "design or not and if you don't you're right somebody else might win out and so there's arguments here",
    "start": "2687440",
    "end": "2692640"
  },
  {
    "text": "on both sides one for regulation and one for kind of free market right free market let everybody go and facebook has organized its entire",
    "start": "2692640",
    "end": "2698640"
  },
  {
    "text": "culture basically to have you know they've got one designer for a small team of say six engineers",
    "start": "2698640",
    "end": "2704079"
  },
  {
    "text": "and they have a whole research department and the research department is incredibly proud of the fact",
    "start": "2704079",
    "end": "2709520"
  },
  {
    "text": "that they don't actually do any future forecasting thinking about the future and designing towards it they're so",
    "start": "2709520",
    "end": "2715599"
  },
  {
    "text": "agile and they're so scrum-like that the teams develop their little agile thing throw it to the research people",
    "start": "2715599",
    "end": "2722000"
  },
  {
    "text": "and they validate whether or not to include it in the kernel and that's how they conquer every niche",
    "start": "2722000",
    "end": "2727280"
  },
  {
    "text": "in the market and they kind of seep into every nook and cranny and every crack everywhere they consume all the little startups in",
    "start": "2727280",
    "end": "2732480"
  },
  {
    "text": "their in their wake and they've got this kind of cancerously growing capitalist machine which is guaranteed",
    "start": "2732480",
    "end": "2738160"
  },
  {
    "text": "to make money right and it's human-centered so the people are getting sucked into that world",
    "start": "2738160",
    "end": "2743200"
  },
  {
    "text": "but it doesn't really have a deep set of values or if it does there are those kind of meta life values",
    "start": "2743200",
    "end": "2748720"
  },
  {
    "text": "right sort of like the organization or zuckerberg somebody hopefully cares",
    "start": "2748720",
    "end": "2754880"
  },
  {
    "text": "right and i would think if you actually push them on it they probably do have some values you",
    "start": "2754880",
    "end": "2760079"
  },
  {
    "text": "know google had some values do no evil right do they really you know google also had you know paid paid friday just to screw around",
    "start": "2760079",
    "end": "2766240"
  },
  {
    "text": "holiday right and now that's not happening so much anymore right so values can change values are subjective values are",
    "start": "2766240",
    "end": "2772800"
  },
  {
    "text": "required judgment calls and they require making hard decisions and they have you know a certain degree the integrity of the designer to do it",
    "start": "2772800",
    "end": "2778960"
  },
  {
    "text": "right rather whether to do it right because they know it's more human centered to do it their way or to listen to their boss",
    "start": "2778960",
    "end": "2784319"
  },
  {
    "text": "or whoever it is who wants them to do it some other way for marketing reasons or whatever right is it a market for us or is it a human force",
    "start": "2784319",
    "end": "2790000"
  },
  {
    "text": "i don't know but these concerns are going to be more and more important and when i think about the world and i",
    "start": "2790000",
    "end": "2795680"
  },
  {
    "start": "2794000",
    "end": "3109000"
  },
  {
    "text": "look at human values and i think about the magnification of human values and the situation that we're in right now with the transhumanist kind of movement",
    "start": "2795680",
    "end": "2802960"
  },
  {
    "text": "i see these three factors as being pretty dominant to most people's motivation for what they do silicon valley is particularly evident",
    "start": "2802960",
    "end": "2810160"
  },
  {
    "text": "this is true everywhere and these aren't bad things right people you know for the most part they have an ego and that gives them a",
    "start": "2810160",
    "end": "2816319"
  },
  {
    "text": "sense of their identity they seek money because they like to be able to have a quality of life they have friends right",
    "start": "2816319",
    "end": "2822240"
  },
  {
    "text": "money is really just about the transactions the interactions i have with the people in the world right if i value something i'll i'll invest in it a little bit i'll pay",
    "start": "2822240",
    "end": "2828400"
  },
  {
    "text": "for it if i don't value it i won't so that's fine it's just a transaction my ego is really just a way that you",
    "start": "2828400",
    "end": "2834000"
  },
  {
    "text": "know as i as i grow up as a child and i get older i have a stronger sense of my identity who i am and i have you know i have a whole",
    "start": "2834000",
    "end": "2840559"
  },
  {
    "text": "complete sense of self and power is really just about my social structure right my family my family keeps me safe",
    "start": "2840559",
    "end": "2846400"
  },
  {
    "text": "my friend my friends are my network and i live in a country that celebrates freedom it's about my relationships with",
    "start": "2846400",
    "end": "2851520"
  },
  {
    "text": "people but let's think about what happens when we get transhumanism happening here okay uh well the vehicle of money is",
    "start": "2851520",
    "end": "2859040"
  },
  {
    "text": "business right what can i do for you today transaction right here today i gone tomorrow i'll pay you now i'll make a",
    "start": "2859040",
    "end": "2864559"
  },
  {
    "text": "deal right next week don't come back because you missed the chance okay these momentary momentary transactions are really the",
    "start": "2864559",
    "end": "2870480"
  },
  {
    "text": "place where value gets created in our culture right if we value something we invest in",
    "start": "2870480",
    "end": "2875520"
  },
  {
    "text": "it venture capital academia owns ego this is where we formulate our",
    "start": "2875520",
    "end": "2882800"
  },
  {
    "text": "identities right we have a sense of education we go to school we learn the values of",
    "start": "2882800",
    "end": "2888720"
  },
  {
    "text": "the culture we become adults we grow a reputation we have memory of",
    "start": "2888720",
    "end": "2895119"
  },
  {
    "text": "each other and memory even in the literature right in the long term academia isn't like the opposite of business right",
    "start": "2895119",
    "end": "2901280"
  },
  {
    "text": "it's forever it's totally insulated they determine what is true and what is not true",
    "start": "2901280",
    "end": "2906319"
  },
  {
    "text": "scientifically whether it's legitimately true or not whether it's pseudoscience or not right knowledge history my identity is",
    "start": "2906319",
    "end": "2912880"
  },
  {
    "text": "forming in much bigger ways and i think academia is being threatened in many ways you know as education's happening online",
    "start": "2912880",
    "end": "2918240"
  },
  {
    "text": "and everybody can get degrees all over the place um should you go to college or not",
    "start": "2918240",
    "end": "2923440"
  },
  {
    "text": "maybe you can get famous on youtube okay power we have governments right social structures",
    "start": "2923440",
    "end": "2930000"
  },
  {
    "text": "that provide security and also give me a sense of influence in the world right how many people do i control through my presence in the world",
    "start": "2930000",
    "end": "2938880"
  },
  {
    "text": "through my relationships so as we started adding these transhuman technologies okay here's what",
    "start": "2938880",
    "end": "2945359"
  },
  {
    "text": "i see happening i see shorter and shorter term thinking an example of facebook's a great one i see people motivated greatly by profit",
    "start": "2945359",
    "end": "2952400"
  },
  {
    "text": "you can go to angellist.com and you can look at the hundreds of silicon valley startups that are getting funded and i",
    "start": "2952400",
    "end": "2957440"
  },
  {
    "text": "guarantee none of them have to do with any of the post human stuff i'm talking about in terms of saving the world they",
    "start": "2957440",
    "end": "2963119"
  },
  {
    "text": "have to do with making about quick flipping exiting getting out moving on to the next thing moving to hawaii buying a house",
    "start": "2963119",
    "end": "2968800"
  },
  {
    "text": "okay i see income inequality at a higher rate than ever okay down here in academia you know",
    "start": "2968800",
    "end": "2974880"
  },
  {
    "text": "people who make a ton of money get pretty entitled right they think they can just buy whatever they want they can rule the world other people get pushed out",
    "start": "2974880",
    "end": "2980960"
  },
  {
    "text": "gentrification it's against them right we are the ones who are inside this academic institution",
    "start": "2980960",
    "end": "2986960"
  },
  {
    "text": "you are the one who got tenure who didn't or was accepted this school who wasn't right our school is better because we promote a certain philosophy of a way of",
    "start": "2986960",
    "end": "2993599"
  },
  {
    "text": "being in the world right it's us against them and then we have the attention economy right",
    "start": "2993599",
    "end": "3000079"
  },
  {
    "text": "um i think you know in business you've got clicks everybody's looking at eyeballs i know you had chris john harris came",
    "start": "3000079",
    "end": "3005760"
  },
  {
    "text": "here and gave a talk right at the beginning of the semester or the quarter um yeah his work is all looking at the intention economy but when you take that",
    "start": "3005760",
    "end": "3011599"
  },
  {
    "text": "and you look at identity formulation online you start to see that there is incredible technology",
    "start": "3011599",
    "end": "3016960"
  },
  {
    "text": "profiling happening right you've got google and facebook know everything they know you're here right now they know who you're with they",
    "start": "3016960",
    "end": "3022240"
  },
  {
    "text": "know who you slept with they know what you bought they know where you went they know it all and they can push things to you in very",
    "start": "3022240",
    "end": "3027359"
  },
  {
    "text": "specific and targeted ways because they own your identity okay then we have government and we know",
    "start": "3027359",
    "end": "3033520"
  },
  {
    "text": "that the government unfortunately doesn't have frankly the good tools that business and academia does in a lot of ways in terms of efficiency",
    "start": "3033520",
    "end": "3040400"
  },
  {
    "text": "they've got a lot of bureaucracy there's a lot of gridlock and ineptitude and it's heavily driven and increasingly",
    "start": "3040400",
    "end": "3045520"
  },
  {
    "text": "so by business and by ego right who are the presidential candidates",
    "start": "3045520",
    "end": "3050880"
  },
  {
    "text": "all of them are people who made millions of dollars in some kind of corporation most of them have some kind of national stage experience in the past from",
    "start": "3050880",
    "end": "3057040"
  },
  {
    "text": "something that they've done that made them a celebrity in some some light and that was purchased with money",
    "start": "3057040",
    "end": "3062319"
  },
  {
    "text": "and it was a brand that has been built through a lot of investment and a lot of hard work okay and basically it leads to",
    "start": "3062319",
    "end": "3068079"
  },
  {
    "text": "popularity contests right we've got social media determining how many things i like and the more people like it the more",
    "start": "3068079",
    "end": "3073119"
  },
  {
    "text": "successful it is on kickstarter basically if you're popular it's like high school right",
    "start": "3073119",
    "end": "3078480"
  },
  {
    "text": "high school on the infinite stage right and potentially it can lead to the abuse of power right can lead to corruption right",
    "start": "3078480",
    "end": "3084960"
  },
  {
    "text": "absolute power corrupts absolutely okay now i ask what happens",
    "start": "3084960",
    "end": "3091440"
  },
  {
    "text": "when we magnify those even more right and we take that power structure and we just keep amplifying it",
    "start": "3091440",
    "end": "3097280"
  },
  {
    "text": "in our exponential way um we don't need to get into the details heading into the post-human era crunch",
    "start": "3097280",
    "end": "3105119"
  },
  {
    "text": "bang shriek that's what i see",
    "start": "3105119",
    "end": "3110480"
  },
  {
    "start": "3109000",
    "end": "3267000"
  },
  {
    "text": "let's think about this maybe to reduce our risk we can reframe the notion of what",
    "start": "3110480",
    "end": "3116480"
  },
  {
    "text": "posthuman center design is or should be by changing the relationship of views",
    "start": "3116480",
    "end": "3121839"
  },
  {
    "text": "between humans and machine systems this is a thought experiment so think about this i'm a user right we've all",
    "start": "3121839",
    "end": "3127599"
  },
  {
    "text": "probably seen a diagram sort of like this right we've got the kind of action perception loop we've got feedback we hear about",
    "start": "3127599",
    "end": "3133359"
  },
  {
    "text": "affordances feed forward feedback right the system has inputs i don't maybe has microphones",
    "start": "3133359",
    "end": "3138960"
  },
  {
    "text": "has outputs maybe speakers or displays okay it gets us into this little loop here right and the thing between us is the",
    "start": "3138960",
    "end": "3145280"
  },
  {
    "text": "interface basically what's going on here is the following i am using the system",
    "start": "3145280",
    "end": "3150319"
  },
  {
    "text": "right i'm the user and i'm using it but what is not totally clear",
    "start": "3150319",
    "end": "3156880"
  },
  {
    "text": "in most users perspectives is that the system is actually using me right that's why google has all the",
    "start": "3156880",
    "end": "3162000"
  },
  {
    "text": "money that's why they know where you are and what you did and what had to sell you right it's why they're building their",
    "start": "3162000",
    "end": "3168000"
  },
  {
    "text": "entire system to be human-centered is so that they can use you right they're trying to use you more quickly",
    "start": "3168000",
    "end": "3173839"
  },
  {
    "text": "and more efficiently than anybody else okay and that's fine you know you take it a step further i like the example of",
    "start": "3173839",
    "end": "3180160"
  },
  {
    "text": "say blackberry or i don't know an apple iphone okay you use your iphone you love it has",
    "start": "3180160",
    "end": "3186720"
  },
  {
    "text": "gps because it goes with everywhere you go and it uses you right and you can tell it's using you",
    "start": "3186720",
    "end": "3193280"
  },
  {
    "text": "because apple's market share is going up right it is a parasite it is living on you",
    "start": "3193280",
    "end": "3198720"
  },
  {
    "text": "and its ecosystem is the app store and the marketplace and the share price",
    "start": "3198720",
    "end": "3205359"
  },
  {
    "text": "right it is living in a globally connected economic landscape in which it's using",
    "start": "3205359",
    "end": "3212480"
  },
  {
    "text": "you to survive blackberry did not survive right but blackberries and apples don't grow",
    "start": "3212480",
    "end": "3218319"
  },
  {
    "text": "on trees they grow on you okay here is a robot okay",
    "start": "3218319",
    "end": "3225040"
  },
  {
    "text": "this is the super scary uh shriek-like superpower that we use we have these awesome values",
    "start": "3225040",
    "end": "3232000"
  },
  {
    "text": "right we value money we value power we value ego we're using it and it is learning all of",
    "start": "3232000",
    "end": "3240000"
  },
  {
    "text": "those values and it's going to use us right back that i think is not a tenable solution",
    "start": "3240000",
    "end": "3246160"
  },
  {
    "text": "so i propose trying again okay this time i don't use the system okay i'm a",
    "start": "3246160",
    "end": "3253520"
  },
  {
    "text": "luddite i opt out i say no thank you the system does not use me",
    "start": "3253520",
    "end": "3259599"
  },
  {
    "text": "and i have this useless interface and that is art",
    "start": "3259599",
    "end": "3265838"
  },
  {
    "text": "okay uh art is useless right i think if you talk to most people and you say",
    "start": "3266480",
    "end": "3271520"
  },
  {
    "start": "3267000",
    "end": "3378000"
  },
  {
    "text": "you know is art going to save the world you know john lennon imagine like did that really make a difference has is war over did we give peace a",
    "start": "3271520",
    "end": "3278079"
  },
  {
    "text": "chance no right but that doesn't mean that it doesn't have a function and a really critical function in our society",
    "start": "3278079",
    "end": "3284799"
  },
  {
    "text": "um and i like this example there's plenty of things wrong with karl marx and his political philosophy um and the way it panned out um but he",
    "start": "3284799",
    "end": "3291440"
  },
  {
    "text": "envisioned a future state of what he called freedom beyond necessity and it is almost word for word exactly",
    "start": "3291440",
    "end": "3298240"
  },
  {
    "text": "the post-human era of robotic automation that we are entering he called it the abolition of labor",
    "start": "3298240",
    "end": "3303599"
  },
  {
    "text": "you can talk to any economist about what's happening right in the past i don't know we had a big technology",
    "start": "3303599",
    "end": "3308799"
  },
  {
    "text": "during the whatever it was right during the industrial revolution a lot of people could no longer have their craft jobs they moved into the",
    "start": "3308799",
    "end": "3314720"
  },
  {
    "text": "factories tons of people were out of work great depression terrible things happen but we always bounce back what's happening now though is that",
    "start": "3314720",
    "end": "3321200"
  },
  {
    "text": "pretty much every industry is being disrupted top to bottom left to right across the board everything disrupted",
    "start": "3321200",
    "end": "3327839"
  },
  {
    "text": "right it's a very different game and effectively what's happening is we're abolishing labor",
    "start": "3327839",
    "end": "3332880"
  },
  {
    "text": "right or we're developing some new kind of labor hopefully to steer that ship right but will it be us who emerges on",
    "start": "3332880",
    "end": "3339280"
  },
  {
    "text": "the other side to steer it i'm not so sure in marx's view the abolition of labor is not the",
    "start": "3339280",
    "end": "3344319"
  },
  {
    "text": "abolition of highly developed technological production but rather the abolition of instrumental technological",
    "start": "3344319",
    "end": "3350160"
  },
  {
    "text": "production and he means something very specific by this instrumental production always uses others as instruments",
    "start": "3350160",
    "end": "3356160"
  },
  {
    "text": "as a means to an end and de-instrumental production or artistic activity has no purpose",
    "start": "3356160",
    "end": "3361440"
  },
  {
    "text": "outside of itself right i like this definition of art because it sort of says hey everything we do is an art is the art of cooking",
    "start": "3361440",
    "end": "3367920"
  },
  {
    "text": "the art of fishing the art of starting companies right but we do it because of the sake of",
    "start": "3367920",
    "end": "3374240"
  },
  {
    "text": "doing it we do it just because because it feels like the right thing to do okay here's our human uh relating to some",
    "start": "3374240",
    "end": "3381520"
  },
  {
    "start": "3378000",
    "end": "3599000"
  },
  {
    "text": "super intelligence in the future i'm kind of curious to think about what would happen if we had this relationship",
    "start": "3381520",
    "end": "3387920"
  },
  {
    "text": "with this super intelligence right there's what i would call sort of selfless actualization right",
    "start": "3387920",
    "end": "3393119"
  },
  {
    "text": "we just sort of live with it and we live with it not because we're trying to use it to accomplish something in particular",
    "start": "3393119",
    "end": "3398720"
  },
  {
    "text": "but because we're just really interested in living with it and in giving some of ourselves to it",
    "start": "3398720",
    "end": "3404079"
  },
  {
    "text": "and sharing with it and celebrating our culture with it we're like hey super intelligence like i made music for you it's like i don't",
    "start": "3404079",
    "end": "3411200"
  },
  {
    "text": "know it's like you're the unborn baby and i'm playing you mozart right i don't know we we focus on",
    "start": "3411200",
    "end": "3417119"
  },
  {
    "text": "thinking about the future that we want to live in and we prepare that super intelligence to become kind of part of our family",
    "start": "3417119",
    "end": "3422799"
  },
  {
    "text": "that feels pretty good let's think about what it would take to make this work if we were really going to institutionalize it here's human",
    "start": "3422799",
    "end": "3429359"
  },
  {
    "text": "centered design as i've described it before and we're going to apply a post-human strategy",
    "start": "3429359",
    "end": "3435599"
  },
  {
    "text": "we're going to make sure that nothing we do is useful we're adding a new phase useless okay",
    "start": "3435599",
    "end": "3443359"
  },
  {
    "text": "interestingly there's a few ways this could pan out okay academic freedom is one of those ways",
    "start": "3443359",
    "end": "3448960"
  },
  {
    "text": "right what do we do we're insulated from the world right we have freedom to make generalizable",
    "start": "3448960",
    "end": "3454559"
  },
  {
    "text": "knowledge we don't care if it gets used or not i'm publishing in some arcane journal of special special",
    "start": "3454559",
    "end": "3460079"
  },
  {
    "text": "stuff that nobody else knows about right it's totally useless the entire system is designed to protect its",
    "start": "3460079",
    "end": "3466240"
  },
  {
    "text": "kind of independence from the real world and from real impact and from all the stuff that designers typically do okay it's totally",
    "start": "3466240",
    "end": "3472799"
  },
  {
    "text": "useless the problem with academic freedom is that it generates knowledge and we know that some knowledge is very",
    "start": "3472799",
    "end": "3478559"
  },
  {
    "text": "dangerous and should be regulated and it does have uncertain outcomes in the sense that somebody might use it or",
    "start": "3478559",
    "end": "3484079"
  },
  {
    "text": "not right it's basically not doing anything to change the system it's just saying somebody else maybe somebody in google",
    "start": "3484079",
    "end": "3489920"
  },
  {
    "text": "is doing some useful stuff right we're going to do a useless thing over here or maybe they will find a use for it instrumentalize it operationalize it",
    "start": "3489920",
    "end": "3496640"
  },
  {
    "text": "and bad things might happen okay here's another approach this is gaining a lot of traction actually in this whole talk i would say is kind of",
    "start": "3496640",
    "end": "3502880"
  },
  {
    "text": "speculative design research project speculative design okay this is the idea",
    "start": "3502880",
    "end": "3508319"
  },
  {
    "text": "of well let's intentionally not do useful or usable design let's just speculate that all the crazy",
    "start": "3508319",
    "end": "3513920"
  },
  {
    "text": "stuff that might happen in the future let's freak people out right we'll make a science fiction film",
    "start": "3513920",
    "end": "3519200"
  },
  {
    "text": "we'll call it ex machina we'll put it in theaters people will be scared right and we communicate that to the world",
    "start": "3519200",
    "end": "3525280"
  },
  {
    "text": "they are delighted and that's a kind of interesting model it's totally useless and it is in a",
    "start": "3525280",
    "end": "3531839"
  },
  {
    "text": "certain degree simulating a possible future that we could live in it's letting the culture decide if that's the future they would like or not",
    "start": "3531839",
    "end": "3538160"
  },
  {
    "text": "is letting you know theory always always leads practice significantly and art always leads",
    "start": "3538160",
    "end": "3544400"
  },
  {
    "text": "engineering and science significantly right robots were invented by playwright right think about frankenstein right these",
    "start": "3544400",
    "end": "3549920"
  },
  {
    "text": "things happen like sometimes decades or even centuries beforehand people envision the future",
    "start": "3549920",
    "end": "3555200"
  },
  {
    "text": "and then some of them come true and others do not and they literally could not have happened if you hadn't envisioned them if you hadn't decided if that's a future",
    "start": "3555200",
    "end": "3561520"
  },
  {
    "text": "you would like or not okay here's another one this is my personal favorite",
    "start": "3561520",
    "end": "3566960"
  },
  {
    "text": "i um actually i'm going to call this a phase i'm going to call it anti-phase 1 compassion and the reason it's an",
    "start": "3566960",
    "end": "3573520"
  },
  {
    "text": "anti-phase is it's actually not a phase this is not something you just have to switch on and switch off it's not something that starts at the beginning",
    "start": "3573520",
    "end": "3578880"
  },
  {
    "text": "of a project and ends when the project is done this is something that you have as a designer everywhere you go",
    "start": "3578880",
    "end": "3584400"
  },
  {
    "text": "you're compassionate about the people you work for right you really care about the post-human future and you're",
    "start": "3584400",
    "end": "3590160"
  },
  {
    "text": "really motivated to do something about it so you add those two phases in there it's egoless it's open",
    "start": "3590160",
    "end": "3595520"
  },
  {
    "text": "it's value driven and we can build systems that ensure that that happens and if we",
    "start": "3595520",
    "end": "3600799"
  },
  {
    "text": "do yeah it's still going to be useful and use them on delightful but at least we're engineering something which truly matters",
    "start": "3600799",
    "end": "3606400"
  },
  {
    "text": "and it's not in the service of some some other vision right we're getting the best set of values in there we can think of",
    "start": "3606400",
    "end": "3611920"
  },
  {
    "text": "i'd go even further it's not just useless it's actually kind of selfless right we're not doing it for ourselves we're doing it for others and in my",
    "start": "3611920",
    "end": "3618240"
  },
  {
    "text": "opinion i would say we need much more rigorous and systemic tools for empowering designers to simulate and interact with these",
    "start": "3618240",
    "end": "3625040"
  },
  {
    "text": "emerging post-human cells that they're building right we want to know what we're going to become and we want to share some of",
    "start": "3625040",
    "end": "3631119"
  },
  {
    "text": "ourselves with it we want to celebrate it and we want to make sure that we're all getting along here we are back",
    "start": "3631119",
    "end": "3636720"
  },
  {
    "text": "at our three fundamental problems right we've got our momentary transactions our identity formation our social",
    "start": "3636720",
    "end": "3641839"
  },
  {
    "text": "structures here's a design challenge if you're working on a research project or you're",
    "start": "3641839",
    "end": "3647200"
  },
  {
    "text": "going to start a startup how about this value-driven economies and altruistic algorithms that",
    "start": "3647200",
    "end": "3652960"
  },
  {
    "text": "prioritize areas of post-human need and devise plans to respond okay how many startups out there are",
    "start": "3652960",
    "end": "3658799"
  },
  {
    "text": "doing that identity formation okay how about some",
    "start": "3658799",
    "end": "3665680"
  },
  {
    "text": "open and egoless education systems that promote seamless identity knowledge and experience sharing okay that's",
    "start": "3665680",
    "end": "3672559"
  },
  {
    "text": "education we're giving form right here we have a system that determines the needs of our post-human culture",
    "start": "3672559",
    "end": "3677839"
  },
  {
    "text": "here we have a system that lets people share and experience that i think creative commons probably lives in this space here's",
    "start": "3677839",
    "end": "3685200"
  },
  {
    "text": "power okay maybe distributed grassroots innovation governance networks for the regulation and development of",
    "start": "3685200",
    "end": "3690559"
  },
  {
    "text": "post-human technology okay we're going to implement these things and we're going to make sure it's not a single government that's too slow to",
    "start": "3690559",
    "end": "3695680"
  },
  {
    "text": "respond to the dangerous ones right it's a community of people who have been vetted by themselves to make sure that we're building safe",
    "start": "3695680",
    "end": "3700960"
  },
  {
    "text": "and secure futures right quality values open democracy we're",
    "start": "3700960",
    "end": "3708000"
  },
  {
    "text": "going to guide our selflessness by design okay so to conclude i started out the",
    "start": "3708000",
    "end": "3715440"
  },
  {
    "text": "talk by saying that engineering is the application of science to human needs",
    "start": "3715440",
    "end": "3722000"
  },
  {
    "text": "and what i hope i've shown is that the majority of existential risks are the direct consequences of",
    "start": "3722000",
    "end": "3727440"
  },
  {
    "text": "scientific investigation and they will increasingly be so that leads potentially to",
    "start": "3727440",
    "end": "3733440"
  },
  {
    "text": "knowledge-enabled mass destruction and interestingly that if you focus on the needs of humans",
    "start": "3733440",
    "end": "3740799"
  },
  {
    "text": "you exclude the needs of other things that might be post-human that you haven't thought about yet and",
    "start": "3740799",
    "end": "3746160"
  },
  {
    "text": "you're also frankly excluding the rest of the environment all the whales all the monkeys all the ecosystems everything",
    "start": "3746160",
    "end": "3752839"
  },
  {
    "text": "humanism is a speciesist regime right and it should be abolished okay",
    "start": "3752839",
    "end": "3759920"
  },
  {
    "text": "focusing on human needs excludes the needs of other forms of intelligent life and from an ethical perspective that's",
    "start": "3759920",
    "end": "3765039"
  },
  {
    "text": "equally dangerous so post human center design proposes that perhaps engineering should be",
    "start": "3765039",
    "end": "3771520"
  },
  {
    "text": "entirely reconceived rather than focusing on the application of science to human needs",
    "start": "3771520",
    "end": "3779440"
  },
  {
    "text": "perhaps it should be reframed as the application of art to post-human needs through the",
    "start": "3779440",
    "end": "3785280"
  },
  {
    "text": "compassionate design of emergent and interactive new forms of collaborative life",
    "start": "3785280",
    "end": "3791920"
  },
  {
    "text": "disguised as science",
    "start": "3793119",
    "end": "3797838"
  },
  {
    "text": "thanks indesign etc um how is that actually going to be cheaper what is motivating the startups",
    "start": "3808839",
    "end": "3816160"
  },
  {
    "text": "and the research organizations financially or whatever to introduce compassion through designs",
    "start": "3816160",
    "end": "3823599"
  },
  {
    "text": "financially we need to engineer new kinds of economies that have different sets of value so we",
    "start": "3823599",
    "end": "3829359"
  },
  {
    "text": "will engineer we will design systemic economies from the ground up which value things that matter",
    "start": "3829359",
    "end": "3835440"
  },
  {
    "text": "and i can guarantee that's starting to happen we have the beginnings of it we have leed",
    "start": "3835440",
    "end": "3840720"
  },
  {
    "text": "certified you know platinum certified environmentally friendly buildings right when tristan was here talking",
    "start": "3840720",
    "end": "3847119"
  },
  {
    "text": "earlier about the attention economy stuff they're working very hard to make you know back in the early days of the website there",
    "start": "3847119",
    "end": "3852240"
  },
  {
    "text": "was like this little thing you could put on your website it was like top five percent of internet traffic right i can totally imagine being like",
    "start": "3852240",
    "end": "3858319"
  },
  {
    "text": "yelp right what if there's a yelp layer for your browser and everything that's bad doesn't survive",
    "start": "3858319",
    "end": "3867039"
  },
  {
    "text": "right and the people are empowered to determine whether those things deserve to take your data or not",
    "start": "3867039",
    "end": "3872799"
  },
  {
    "text": "i'm teaching in a very practice based interaction design program we just graduated 13 seniors",
    "start": "3872799",
    "end": "3879359"
  },
  {
    "text": "and i would say 10 of those 13 were doing projects which surprised me in the amount of optimism",
    "start": "3879359",
    "end": "3887119"
  },
  {
    "text": "and confidence they gave me about the future in the sense that they are envisioning very practical",
    "start": "3887119",
    "end": "3892880"
  },
  {
    "text": "simple things that empower individuals in grassroots ways that directly take on the kind of big",
    "start": "3892880",
    "end": "3897920"
  },
  {
    "text": "data big business big power big ego stuff out there and we have this kind of boutique",
    "start": "3897920",
    "end": "3904240"
  },
  {
    "text": "ecosystem of uh you know maker faire startup happy things um the interesting question there is",
    "start": "3904240",
    "end": "3911839"
  },
  {
    "text": "that of course they're all happening within the wild garden of the ecosystem which apple built called their app store",
    "start": "3911839",
    "end": "3918240"
  },
  {
    "text": "right and so i don't know they can decide whether or not to include your app in their store and frankly you can",
    "start": "3918240",
    "end": "3924079"
  },
  {
    "text": "decide whether or not to put it there so i think we need more open source movement right i think we need more creative commons",
    "start": "3924079",
    "end": "3929440"
  },
  {
    "text": "i think we need yeah frankly just a whole lot more people doing a lot a lot of stuff and i don't know tesla gave away all of their battery patents",
    "start": "3929440",
    "end": "3936079"
  },
  {
    "text": "literally just published them in the in the creative commons for anybody to use right that's a kind of bold move and it says",
    "start": "3936079",
    "end": "3941359"
  },
  {
    "text": "hey we are a company who truly values intellectual property very differently than you guys we're really hardcore serious about improving the environment we want people",
    "start": "3941359",
    "end": "3947760"
  },
  {
    "text": "using battery cars and we are cool sharing it with you right and it i don't know that i that that affects me",
    "start": "3947760",
    "end": "3954480"
  },
  {
    "text": "on a human level right my perception of the company is different and in the future when we're basically",
    "start": "3954480",
    "end": "3959920"
  },
  {
    "text": "owning people's hearts right and we're basically running their minds on our operating",
    "start": "3959920",
    "end": "3965440"
  },
  {
    "text": "system you bet people are gonna have a strong opinion about which services they believe in right and so we're engineering a new set",
    "start": "3965440",
    "end": "3971359"
  },
  {
    "text": "of values but i think it starts and it needs to start with people who have the passion to do the right thing in the first place and to really dig down deep inside their",
    "start": "3971359",
    "end": "3977920"
  },
  {
    "text": "soul and think about like what matters do i need to be living here how much money do i really need where am",
    "start": "3977920",
    "end": "3984240"
  },
  {
    "text": "i going to put it how am i going to invest it right and yeah that's where it's going to start and there's going to be lots of",
    "start": "3984240",
    "end": "3989680"
  },
  {
    "text": "people who take advantage of them and you know the world will continue and the artists will continue to get marginalized and the big money will get",
    "start": "3989680",
    "end": "3994880"
  },
  {
    "text": "bigger and we'll still be on the right side of history even if we don't survive",
    "start": "3994880",
    "end": "4000240"
  },
  {
    "text": "yeah um you talked about kind of on apple's app store being a walled",
    "start": "4000240",
    "end": "4007280"
  },
  {
    "text": "garden in and of itself in terms of the ability to effect change the development um",
    "start": "4007280",
    "end": "4015039"
  },
  {
    "text": "do you have on is android on",
    "start": "4015039",
    "end": "4020480"
  },
  {
    "text": "to be honest i'm not a developer i haven't spent a lot of time thinking about it i'm working with a startup right now and we're doing",
    "start": "4027520",
    "end": "4032720"
  },
  {
    "text": "apple first and then we're gonna move into android to me to me it's very similar i mean the history of the internet has",
    "start": "4032720",
    "end": "4038240"
  },
  {
    "text": "been kind of like this right um you've got linux right linux is great it's open source all that good stuff and",
    "start": "4038240",
    "end": "4044240"
  },
  {
    "text": "then you know someone comes along designs really nice operating system they've got professional people getting paid well doing good design",
    "start": "4044240",
    "end": "4049680"
  },
  {
    "text": "making competitive salaries designing really awesome operating system and that's very effective and then you've got you know",
    "start": "4049680",
    "end": "4056960"
  },
  {
    "text": "what you've got squarespace right doing a really really nice job of building fully hosted very expensive websites",
    "start": "4057119",
    "end": "4063119"
  },
  {
    "text": "that are always designed well and look really good and you know then you've got the open source stuff out there that you can kind of hack anything together and build",
    "start": "4063119",
    "end": "4068960"
  },
  {
    "text": "whatever you want and that's great and it's open but it's a crappier experience and more difficult more annoying so people are willing to invest in things",
    "start": "4068960",
    "end": "4074400"
  },
  {
    "text": "they value and yeah i don't really know between the two neither and the reason is because neither of them",
    "start": "4074400",
    "end": "4080000"
  },
  {
    "text": "is a non-profit neither of them is a b corp neither of them truly has values in mind beyond profit",
    "start": "4080000",
    "end": "4086000"
  },
  {
    "text": "right they're profit driven organizations their soul their you know everything in the contract that they",
    "start": "4086000",
    "end": "4091280"
  },
  {
    "text": "exist to do is make money and they're taking it from you so if you're if you value them and you pay them",
    "start": "4091280",
    "end": "4097600"
  },
  {
    "text": "go for it um so in the 1970s uh",
    "start": "4097600",
    "end": "4105440"
  },
  {
    "text": "when there was advertisements it worked more effectively than it does today personally from what i believe um i",
    "start": "4105440",
    "end": "4111040"
  },
  {
    "text": "think we as people aren't as effective for emotional ties and advertising and with that being said i",
    "start": "4111040",
    "end": "4119040"
  },
  {
    "text": "think that the model that you showed previously to work with startups will no longer work if they continue to",
    "start": "4119040",
    "end": "4127120"
  },
  {
    "text": "go the way that it's going um just naturally he'll be less and less effective because people kind",
    "start": "4127120",
    "end": "4133679"
  },
  {
    "text": "of get more educated on what's going on and feel more compassionate about real things that are happening or like",
    "start": "4133679",
    "end": "4140798"
  },
  {
    "text": "you know making more change with more movements um what is your thoughts behind that um yeah so my first part of a lot of the",
    "start": "4140799",
    "end": "4147758"
  },
  {
    "text": "stuff is i'm a designer and i don't know a whole lot about economics and i don't know a lot about political theory and i don't",
    "start": "4147759",
    "end": "4153520"
  },
  {
    "text": "know like like these are big dreamy super interconnected very complicated systems problems and",
    "start": "4153520",
    "end": "4160719"
  },
  {
    "text": "i'm navigating just based on what sort of feels right um and i have the sense that karl marx",
    "start": "4160719",
    "end": "4166400"
  },
  {
    "text": "was doing something similar and i have the sense that he predicted the downfall of capitalism in exactly the way that you just said which is basically that",
    "start": "4166400",
    "end": "4172640"
  },
  {
    "text": "eventually it will put itself out of business because it won't be responsive to the needs of the people and it won't be as effective as the next thing that comes",
    "start": "4172640",
    "end": "4178400"
  },
  {
    "text": "along and what really matters is this holistic sense of you know togetherness",
    "start": "4178400",
    "end": "4183838"
  },
  {
    "text": "and to a certain degree we do have the potential finally now i think to design a truly better post-democracy",
    "start": "4183839",
    "end": "4190238"
  },
  {
    "text": "post-capitalism post-ego right that changes the rules",
    "start": "4190239",
    "end": "4196320"
  },
  {
    "text": "and yeah ideas just next level um that wouldn't",
    "start": "4196320",
    "end": "4204480"
  },
  {
    "text": "be funded by capitalists and if not that your capitalists are my opponent yeah yeah and we have increasingly",
    "start": "4204480",
    "end": "4210000"
  },
  {
    "text": "you know angel people are just giving money to stuff that they think matters and you know there's people starting green funds that you know it's it's a very",
    "start": "4210000",
    "end": "4216800"
  },
  {
    "text": "interesting time and i think i think there's going to be a really interesting the pendulum is going to swing back in some kind of more democratic way and i think in the",
    "start": "4216800",
    "end": "4223679"
  },
  {
    "text": "research community we have a huge amount of room you know we do have that kind of insulation from reality enough that we can at least be",
    "start": "4223679",
    "end": "4229040"
  },
  {
    "text": "making sure we're doing the most impactful research for humanity i suppose",
    "start": "4229040",
    "end": "4244960"
  },
  {
    "text": "you",
    "start": "4244960",
    "end": "4247040"
  }
]
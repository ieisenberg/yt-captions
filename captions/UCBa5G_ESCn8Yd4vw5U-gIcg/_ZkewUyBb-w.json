[
  {
    "start": "0",
    "end": "4750"
  },
  {
    "text": "SPEAKER: Welcome back, everyone.",
    "start": "4750",
    "end": "6170"
  },
  {
    "text": "This is part 6 in our series\non advanced behavioral testing",
    "start": "6170",
    "end": "9280"
  },
  {
    "text": "for NLU.",
    "start": "9280",
    "end": "10360"
  },
  {
    "text": "To this point, we've been\nfocused on adversarial testing.",
    "start": "10360",
    "end": "13660"
  },
  {
    "text": "We're now going to take\na more expansive view",
    "start": "13660",
    "end": "15639"
  },
  {
    "text": "and think about the potential\nbenefits of training",
    "start": "15640",
    "end": "18640"
  },
  {
    "text": "on adversarial cases.",
    "start": "18640",
    "end": "20420"
  },
  {
    "text": "The foundational entry\nin this literature",
    "start": "20420",
    "end": "22390"
  },
  {
    "text": "is the ANLI paper and\nthe associated benchmark.",
    "start": "22390",
    "end": "25240"
  },
  {
    "text": "As far as I know, ANLI\nis the first attempt",
    "start": "25240",
    "end": "28330"
  },
  {
    "text": "to create a really large\ntrain set that is filled",
    "start": "28330",
    "end": "32110"
  },
  {
    "text": "with adversarial examples.",
    "start": "32110",
    "end": "33550"
  },
  {
    "text": "That is with examples that\nfooled a top performing model,",
    "start": "33550",
    "end": "36940"
  },
  {
    "text": "but were intuitive for humans.",
    "start": "36940",
    "end": "39070"
  },
  {
    "text": "I think it's fair\nto say that ANLI",
    "start": "39070",
    "end": "40900"
  },
  {
    "text": "is a direct response to the\nkinds of adversarial test",
    "start": "40900",
    "end": "44170"
  },
  {
    "text": "results that we reviewed in the\nprevious screencast, where we",
    "start": "44170",
    "end": "46899"
  },
  {
    "text": "saw NLI models that\nwere surpassing",
    "start": "46900",
    "end": "50050"
  },
  {
    "text": "our estimates for\nhuman performance,",
    "start": "50050",
    "end": "52040"
  },
  {
    "text": "but nonetheless, falling down\non very simple phenomena turning",
    "start": "52040",
    "end": "56470"
  },
  {
    "text": "on systematicity or\ncompositionality in language.",
    "start": "56470",
    "end": "60070"
  },
  {
    "text": "So the vision for ANLI\nis that by introducing",
    "start": "60070",
    "end": "63280"
  },
  {
    "text": "an adversarial dynamic into\nthe train set creation,",
    "start": "63280",
    "end": "66799"
  },
  {
    "text": "we can get models\nthat are more robust.",
    "start": "66800",
    "end": "69290"
  },
  {
    "text": "Here's how data set\ncreation worked.",
    "start": "69290",
    "end": "72110"
  },
  {
    "text": "The annotator is presented\nwith a premise sentence",
    "start": "72110",
    "end": "75110"
  },
  {
    "text": "and a condition that is\nentailment contradiction or",
    "start": "75110",
    "end": "77930"
  },
  {
    "text": "neutral, one of the NLI labels.",
    "start": "77930",
    "end": "80300"
  },
  {
    "text": "The annotator\nwrites a hypothesis.",
    "start": "80300",
    "end": "82970"
  },
  {
    "text": "And then a state-of-the-art\nmodel makes a prediction about",
    "start": "82970",
    "end": "86090"
  },
  {
    "text": "the resulting premise\nhypothesis pair.",
    "start": "86090",
    "end": "88700"
  },
  {
    "text": "If the model's prediction\nmatches the condition, that",
    "start": "88700",
    "end": "91640"
  },
  {
    "text": "is if the model was\ncorrect in some sense,",
    "start": "91640",
    "end": "93890"
  },
  {
    "text": "the annotator returns\nto step 2 to try again.",
    "start": "93890",
    "end": "97310"
  },
  {
    "text": "Whereas if the model\nwas fooled, the premise",
    "start": "97310",
    "end": "100009"
  },
  {
    "text": "hypothesis pairs\nindependently validated",
    "start": "100010",
    "end": "102290"
  },
  {
    "text": "by other human annotators.",
    "start": "102290",
    "end": "104900"
  },
  {
    "text": "The result of this dynamic\nof this interaction",
    "start": "104900",
    "end": "107810"
  },
  {
    "text": "with this top performing\nmodel is a train set",
    "start": "107810",
    "end": "110240"
  },
  {
    "text": "that is full of really\nhard cases, cases",
    "start": "110240",
    "end": "113570"
  },
  {
    "text": "that fooled this top performing\nmodel in addition to cases",
    "start": "113570",
    "end": "116750"
  },
  {
    "text": "that didn't fool that model.",
    "start": "116750",
    "end": "119450"
  },
  {
    "text": "The examples are\nkind of interesting.",
    "start": "119450",
    "end": "121130"
  },
  {
    "text": "The premises in ANLI\ntend to be long.",
    "start": "121130",
    "end": "123409"
  },
  {
    "text": "The hypotheses are, of\ncourse, challenging.",
    "start": "123410",
    "end": "125920"
  },
  {
    "text": "Interestingly, the data set also\ncontains these reason texts.",
    "start": "125920",
    "end": "129220"
  },
  {
    "text": "This is the annotator's\nbest attempt",
    "start": "129220",
    "end": "131050"
  },
  {
    "text": "to explain why the model\nmight have struggled",
    "start": "131050",
    "end": "133690"
  },
  {
    "text": "with that particular example.",
    "start": "133690",
    "end": "135100"
  },
  {
    "text": "As far as I know,\nthe reason texts",
    "start": "135100",
    "end": "137020"
  },
  {
    "text": "haven't been used very\nmuch in the literature.",
    "start": "137020",
    "end": "138980"
  },
  {
    "text": "But they strike me as\nan interesting source",
    "start": "138980",
    "end": "140980"
  },
  {
    "text": "of indirect supervision\nabout the task.",
    "start": "140980",
    "end": "143629"
  },
  {
    "text": "So you might check those out.",
    "start": "143630",
    "end": "146440"
  },
  {
    "text": "This is the core results\ntable for the ANLI paper.",
    "start": "146440",
    "end": "150070"
  },
  {
    "text": "There's a lot of\ninformation here,",
    "start": "150070",
    "end": "151640"
  },
  {
    "text": "but I think the story is\npretty straightforward.",
    "start": "151640",
    "end": "153740"
  },
  {
    "text": "Let's focus on the BERT model.",
    "start": "153740",
    "end": "155530"
  },
  {
    "text": "The BERT model is doing really\nwell on SNLI and multi-NLI",
    "start": "155530",
    "end": "159310"
  },
  {
    "text": "across all of these different\nvariants of the training",
    "start": "159310",
    "end": "161620"
  },
  {
    "text": "regimes.",
    "start": "161620",
    "end": "162940"
  },
  {
    "text": "When the model is trained\nonly on SNLI and multi-NLI,",
    "start": "162940",
    "end": "166270"
  },
  {
    "text": "it does really poorly on ANLI.",
    "start": "166270",
    "end": "168640"
  },
  {
    "text": "You can see ANLI\nhad three rounds.",
    "start": "168640",
    "end": "170693"
  },
  {
    "text": "When we pulled them\ntogether, this model",
    "start": "170693",
    "end": "172360"
  },
  {
    "text": "gets around 20% accuracy.",
    "start": "172360",
    "end": "175620"
  },
  {
    "text": "As we take that model and\naugment its training data",
    "start": "175620",
    "end": "178470"
  },
  {
    "text": "with ANLI data from\nprevious rounds,",
    "start": "178470",
    "end": "180870"
  },
  {
    "text": "we do see improvements\noverall in the ANLI",
    "start": "180870",
    "end": "184140"
  },
  {
    "text": "column, which is encouraging.",
    "start": "184140",
    "end": "185400"
  },
  {
    "text": "It looks like the models are\ngetting better at the task",
    "start": "185400",
    "end": "188189"
  },
  {
    "text": "as they get more of these\nadversarial examples as part",
    "start": "188190",
    "end": "191010"
  },
  {
    "text": "of training.",
    "start": "191010",
    "end": "192150"
  },
  {
    "text": "But the fundamental insight\nhere is that performance on ANLI",
    "start": "192150",
    "end": "195959"
  },
  {
    "text": "is well below performance\nfor the other benchmarks.",
    "start": "195960",
    "end": "198780"
  },
  {
    "text": "This is a substantial challenge.",
    "start": "198780",
    "end": "200640"
  },
  {
    "text": "And I believe that this\nsubstantial challenge still",
    "start": "200640",
    "end": "204040"
  },
  {
    "text": "stands.",
    "start": "204040",
    "end": "204540"
  },
  {
    "text": "Models do not excel at ANLI even\nto this day, as far as I know.",
    "start": "204540",
    "end": "211939"
  },
  {
    "text": "One thing I love about\nANLI is that it projects",
    "start": "211940",
    "end": "214570"
  },
  {
    "text": "this kind of really\ninteresting vision",
    "start": "214570",
    "end": "216370"
  },
  {
    "text": "for the future development\nof train and test",
    "start": "216370",
    "end": "219549"
  },
  {
    "text": "assets for the field.",
    "start": "219550",
    "end": "221020"
  },
  {
    "text": "It's actually all credit\ndue to Zellers et al.",
    "start": "221020",
    "end": "223780"
  },
  {
    "text": "They also describe this\nvision in their papers",
    "start": "223780",
    "end": "226209"
  },
  {
    "text": "on SWAG and HellaSWAG.",
    "start": "226210",
    "end": "228310"
  },
  {
    "text": "They write, \"a path for NLP\nprogress going forward towards",
    "start": "228310",
    "end": "231940"
  },
  {
    "text": "benchmarks that adversarially\nco-evolve with evolving",
    "start": "231940",
    "end": "235600"
  },
  {
    "text": "state-of-the-art-models.\"",
    "start": "235600",
    "end": "237230"
  },
  {
    "text": "I didn't have time to tell\nthis full story in details,",
    "start": "237230",
    "end": "239860"
  },
  {
    "text": "but Zellers et al is\nan interesting story.",
    "start": "239860",
    "end": "242200"
  },
  {
    "text": "There are two papers.",
    "start": "242200",
    "end": "243590"
  },
  {
    "text": "The first one\nintroduced SWAG, which",
    "start": "243590",
    "end": "245500"
  },
  {
    "text": "is a kind of synthetically\ncreated train and test",
    "start": "245500",
    "end": "248680"
  },
  {
    "text": "environment for\nadversarial testing.",
    "start": "248680",
    "end": "252879"
  },
  {
    "text": "And they found that\nit was very difficult.",
    "start": "252880",
    "end": "255045"
  },
  {
    "text": "But when the BERT\npaper came out,",
    "start": "255045",
    "end": "256419"
  },
  {
    "text": "BERT essentially solved\nthe SWAG problem.",
    "start": "256420",
    "end": "259890"
  },
  {
    "text": "In response to\nthat, Zellers et al",
    "start": "259890",
    "end": "262019"
  },
  {
    "text": "made some adjustments\nto the SWAG data",
    "start": "262019",
    "end": "264110"
  },
  {
    "text": "set that produced HellSWAG.",
    "start": "264110",
    "end": "266039"
  },
  {
    "text": "HellaSWAG was substantially\nharder for BERT.",
    "start": "266040",
    "end": "268500"
  },
  {
    "text": "And I believe that HellaSWAG\nremains a challenging",
    "start": "268500",
    "end": "271050"
  },
  {
    "text": "benchmark to this day.",
    "start": "271050",
    "end": "272590"
  },
  {
    "text": "And I think that started\nus on the path of seeing",
    "start": "272590",
    "end": "274919"
  },
  {
    "text": "how productive it could\nbe to create data sets,",
    "start": "274920",
    "end": "277890"
  },
  {
    "text": "use them to develop\nmodels, and then respond",
    "start": "277890",
    "end": "280530"
  },
  {
    "text": "when models seem to succeed\nwith even harder challenges.",
    "start": "280530",
    "end": "284610"
  },
  {
    "text": "And in the ANLI paper,\nthey project this vision",
    "start": "284610",
    "end": "287159"
  },
  {
    "text": "very directly,\n\"This process yields",
    "start": "287160",
    "end": "289770"
  },
  {
    "text": "a \"moving post\" dynamic\ntarget for NLU systems,",
    "start": "289770",
    "end": "293460"
  },
  {
    "text": "rather than a static benchmark\nthat will eventually saturate.\"",
    "start": "293460",
    "end": "296580"
  },
  {
    "text": "This sounds so productive to me.",
    "start": "296580",
    "end": "298169"
  },
  {
    "text": "Throughout the field, large\nteams of very talented people",
    "start": "298170",
    "end": "302490"
  },
  {
    "text": "spend lots of time and\nmoney getting epsilon more",
    "start": "302490",
    "end": "305580"
  },
  {
    "text": "performance out of our\nestablished benchmarks.",
    "start": "305580",
    "end": "308189"
  },
  {
    "text": "Wouldn't it be wonderful\nif instead when",
    "start": "308190",
    "end": "310410"
  },
  {
    "text": "we saw the benchmark\nsaturating, we",
    "start": "310410",
    "end": "312300"
  },
  {
    "text": "simply created new benchmarks\nand posed new challenges",
    "start": "312300",
    "end": "315690"
  },
  {
    "text": "for ourselves?",
    "start": "315690",
    "end": "316570"
  },
  {
    "text": "I think it's a very\nsafe bet that models",
    "start": "316570",
    "end": "318870"
  },
  {
    "text": "would improve more rapidly\nand become more capable",
    "start": "318870",
    "end": "321760"
  },
  {
    "text": "if we did this kind\nof moving post thing.",
    "start": "321760",
    "end": "325120"
  },
  {
    "text": "And that really is the\nvision for Dynabench.",
    "start": "325120",
    "end": "327820"
  },
  {
    "text": "Dynabench is an open source\nsoftware effort and open source",
    "start": "327820",
    "end": "331150"
  },
  {
    "text": "platform for doing among other\nthings, dynamic, adversarial,",
    "start": "331150",
    "end": "335290"
  },
  {
    "text": "data collection.",
    "start": "335290",
    "end": "336790"
  },
  {
    "text": "And Dynabench has produced\na number of data sets",
    "start": "336790",
    "end": "339520"
  },
  {
    "text": "to this point.",
    "start": "339520",
    "end": "340990"
  },
  {
    "text": "ANLI is the first one.",
    "start": "340990",
    "end": "342729"
  },
  {
    "text": "That's the precursor.",
    "start": "342730",
    "end": "343900"
  },
  {
    "text": "We also have Dynabench\nderived data sets for QA,",
    "start": "343900",
    "end": "347020"
  },
  {
    "text": "for sentiment, and a number\nof data sets for hate speech,",
    "start": "347020",
    "end": "351169"
  },
  {
    "text": "including counter\nspeech to hate speech.",
    "start": "351170",
    "end": "353690"
  },
  {
    "text": "We have a few on QA, and\none on German hate speech.",
    "start": "353690",
    "end": "356600"
  },
  {
    "text": "And I think this list will\ncontinue to grow and offer us",
    "start": "356600",
    "end": "360220"
  },
  {
    "text": "these incredible new resources.",
    "start": "360220",
    "end": "362840"
  },
  {
    "text": "So let me stop there.",
    "start": "362840",
    "end": "364240"
  },
  {
    "text": "For the next\nscreencast, I'm going",
    "start": "364240",
    "end": "365949"
  },
  {
    "text": "to do a deep dive on a Dynabench\nderived data set that we",
    "start": "365950",
    "end": "369310"
  },
  {
    "text": "created called Dynasent.",
    "start": "369310",
    "end": "371940"
  },
  {
    "start": "371940",
    "end": "376000"
  }
]
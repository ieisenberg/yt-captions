[
  {
    "start": "0",
    "end": "5400"
  },
  {
    "text": "Hello. Thank you all for joining\nCS 25 Transformers today. For today's talk we have Ming\nDing, a research scientist",
    "start": "5400",
    "end": "13710"
  },
  {
    "text": "at Zhipu AI based in Beijing. He obtained his bachelor's\nand doctoral degrees",
    "start": "13710",
    "end": "19440"
  },
  {
    "text": "at Tsinghua University,\nand he does research on multimodal generative models\nand pretraining technologies.",
    "start": "19440",
    "end": "26820"
  },
  {
    "text": "He has led or participated\nin the research works about multimodal\ngenerative models,",
    "start": "26820",
    "end": "32610"
  },
  {
    "text": "such as CogView and CogVideo,\nand multimodal understanding models such as\nCogVLM and CogAgent.",
    "start": "32610",
    "end": "40829"
  },
  {
    "text": "For today's attendance,\nthe attendance form is up on the course website.",
    "start": "40830",
    "end": "46059"
  },
  {
    "text": "And if you have any questions,\nask them through Slido, S-L-I-D-O. And for the code,\nyou just have to input \"CS 25.\"",
    "start": "46060",
    "end": "56730"
  },
  {
    "text": "Thank you, Ming,\nfor today's talk, and I'm going to\npass it off to you.",
    "start": "56730",
    "end": "62690"
  },
  {
    "text": "Thank you for the\ninstructors of CS 25. I was very happy to\ngive a talk in Stanford",
    "start": "62690",
    "end": "70280"
  },
  {
    "text": "University about\nmultimodality in pretraining. And actually, I have checked\nall the previous talks in CS 25,",
    "start": "70280",
    "end": "84710"
  },
  {
    "text": "and they are really\ndiverse topics. Someone shared the\nintuitions in their research",
    "start": "84710",
    "end": "92840"
  },
  {
    "text": "about pretraining, someone\nshared recent works about maybe MOE and\nsome other technicals.",
    "start": "92840",
    "end": "101540"
  },
  {
    "text": "Actually, I'm working in a large\nlanguage model company in China,",
    "start": "101540",
    "end": "108620"
  },
  {
    "text": "and our company\nworking on pretraining. And maybe there's lots\nof different areas",
    "start": "108620",
    "end": "116960"
  },
  {
    "text": "from a large language model\nand multimodality model",
    "start": "116960",
    "end": "122220"
  },
  {
    "text": "and [INAUDIBLE] model,\ndiffusion, and text-to-speech, something like that.",
    "start": "122220",
    "end": "128199"
  },
  {
    "text": "So I lead all the multimodality\nmodel research in Zhipu AI, so I will share lots of\ndifferent topics in this talk.",
    "start": "128199",
    "end": "139950"
  },
  {
    "text": "Some of them may be not very\nfamiliar to you, so yeah, it's OK.",
    "start": "139950",
    "end": "145569"
  },
  {
    "text": "But you can get more\ninformation on a different area. ",
    "start": "145570",
    "end": "153940"
  },
  {
    "text": "I will talk about several\naspects of transformers, and I will generally follow the\nhistory of large language model",
    "start": "153940",
    "end": "165520"
  },
  {
    "text": "and say why are we here. It's about the large language\nmodel introduction and history.",
    "start": "165520",
    "end": "175510"
  },
  {
    "text": "And how did we get here? It's about some\npractical techniques",
    "start": "175510",
    "end": "181690"
  },
  {
    "text": "for training large\nlanguage models. And what are we working on?",
    "start": "181690",
    "end": "186790"
  },
  {
    "text": "It's about the last one year\nof the real language models",
    "start": "186790",
    "end": "192400"
  },
  {
    "text": "and other techniques\nin the papers of all the visual\nlanguage model community.",
    "start": "192400",
    "end": "200209"
  },
  {
    "text": "And finally, I will talk about\nsome possible and valuable",
    "start": "200210",
    "end": "206410"
  },
  {
    "text": "direction for research\nin multimodality. OK. ",
    "start": "206410",
    "end": "214850"
  },
  {
    "text": "I will share three moments,\nI think the most important",
    "start": "214850",
    "end": "220680"
  },
  {
    "text": "three moments in the\ndevelopment of language model.",
    "start": "220680",
    "end": "227310"
  },
  {
    "text": "The first moment is\ncalled birth moment. Actually, I got into\nthe area at this moment.",
    "start": "227310",
    "end": "235740"
  },
  {
    "text": "It's very honored that I'm\namong the first group of people",
    "start": "235740",
    "end": "242310"
  },
  {
    "text": "who published papers on the\nnext year, the [INAUDIBLE], when BERT came out.",
    "start": "242310",
    "end": "248680"
  },
  {
    "text": "And at that time, things is--",
    "start": "248680",
    "end": "253859"
  },
  {
    "text": "we don't really know what\nis language modeling. So at that time,\nnearly all the people",
    "start": "253860",
    "end": "261644"
  },
  {
    "text": "are talking about how can we get\na better self-supervised method",
    "start": "261645",
    "end": "268449"
  },
  {
    "text": "in our machine. At that time, a\ncommon opinion is masked language model is as\ngood as understanding the text.",
    "start": "268450",
    "end": "280629"
  },
  {
    "text": "And GPT, the\nautoregressive model, is better for text generations.",
    "start": "280630",
    "end": "286860"
  },
  {
    "text": "And T5 maybe can do them\nboth but is redundant.",
    "start": "286860",
    "end": "294979"
  },
  {
    "text": "And that's true. But nowadays, we all say\nthat GPT has now a nearly--",
    "start": "294980",
    "end": "306590"
  },
  {
    "text": " silver bullet or other anarchy.",
    "start": "306590",
    "end": "312050"
  },
  {
    "text": " Sometimes the things\nchanges, and we",
    "start": "312050",
    "end": "321410"
  },
  {
    "text": "will back from that\ntime point and know",
    "start": "321410",
    "end": "326720"
  },
  {
    "text": "how the language\nmodel things and how we got more and more knowledge\nabout language model.",
    "start": "326720",
    "end": "334580"
  },
  {
    "text": "So at that time, the-- I'm also among one\nof them who want",
    "start": "334580",
    "end": "343669"
  },
  {
    "text": "to develop a new self-supervised\nlearning method for [INAUDIBLE].",
    "start": "343670",
    "end": "350120"
  },
  {
    "text": "We published a paper\ncalled GLM, and we want to unify the BERT,\nthe masked language",
    "start": "350120",
    "end": "358970"
  },
  {
    "text": "model, and the\nautoregressive model, and T5 in decoder-only style.",
    "start": "358970",
    "end": "370340"
  },
  {
    "text": "Actually, the method\nis very simple. We just select a\npart of the sequence",
    "start": "370340",
    "end": "380270"
  },
  {
    "text": "and only do autoregressive\nmodeling during this sequence.",
    "start": "380270",
    "end": "387229"
  },
  {
    "text": "So if we select the mask\narea as all the sequence,",
    "start": "387230",
    "end": "393320"
  },
  {
    "text": "it become a GPT. And part of them,\nit becomes BERT. So that's a method we\nfound very efficient.",
    "start": "393320",
    "end": "403930"
  },
  {
    "text": "And because we train it, it's\nlike a BERT, it's about 15% of the masked area, and they\nperform better than BERT.",
    "start": "403930",
    "end": "411789"
  },
  {
    "text": "We trained it as a GPT. It perform the same as GPT. It's very promising.",
    "start": "411790",
    "end": "420926"
  },
  {
    "text": " The second moment I\nthink is very important",
    "start": "420926",
    "end": "429710"
  },
  {
    "text": "is the GPT-3 moment. It tells us the scaling\nlaw is very important.",
    "start": "429710",
    "end": "439139"
  },
  {
    "text": "So you can design\ndifferent architectures, define different laws,\ndifferent self-supervised tasks",
    "start": "439140",
    "end": "450690"
  },
  {
    "text": "and different methods to\nschedule different models,",
    "start": "450690",
    "end": "456180"
  },
  {
    "text": "but the performance maybe\nhas some upper bound.",
    "start": "456180",
    "end": "462860"
  },
  {
    "text": "But so if you add\nmore compute, you can get a guaranteed\nperformance improvement.",
    "start": "462860",
    "end": "474419"
  },
  {
    "text": "You can predict the\nresult's perplexity",
    "start": "474420",
    "end": "479880"
  },
  {
    "text": "based on the fitted curve.",
    "start": "479880",
    "end": "485250"
  },
  {
    "text": "So at that time, the\nlanguage modeling",
    "start": "485250",
    "end": "490960"
  },
  {
    "text": "has become more and\nmore engineering. If you have find\na very good point,",
    "start": "490960",
    "end": "498490"
  },
  {
    "text": "you train a language model. If you want to scale it\nand your boss give you",
    "start": "498490",
    "end": "506650"
  },
  {
    "text": "four times of monies, you can\nbuy four times the compute.",
    "start": "506650",
    "end": "512710"
  },
  {
    "text": "You just assign the compute\nfour more parameters or training",
    "start": "512710",
    "end": "521200"
  },
  {
    "text": "more tokens. This is called scaling law.",
    "start": "521200",
    "end": "527680"
  },
  {
    "text": "They tell you how you can\nassign different potential",
    "start": "527680",
    "end": "534250"
  },
  {
    "text": "of your monies. So at that time, the\nlanguage model don't really",
    "start": "534250",
    "end": "544650"
  },
  {
    "text": "need some architectural\ninnovation or algorithm",
    "start": "544650",
    "end": "553470"
  },
  {
    "text": "innovation, so it's become\na engineering thing.",
    "start": "553470",
    "end": "560680"
  },
  {
    "text": "And the third moment, I\nthink, which is more important",
    "start": "560680",
    "end": "568210"
  },
  {
    "text": "is called ChatGPT moment. At that moment, it tells\nus a very important fact",
    "start": "568210",
    "end": "576040"
  },
  {
    "text": "is task adaptation is cheap. And what is very important is\nthe knowledge from pretraining.",
    "start": "576040",
    "end": "587180"
  },
  {
    "text": "This is a very bitter lesson. So I have told you\nthat at that time,",
    "start": "587180",
    "end": "595040"
  },
  {
    "text": "we designed different losses,\ndifferent architectures,",
    "start": "595040",
    "end": "600350"
  },
  {
    "text": "but the aim of design\ndifferent losses",
    "start": "600350",
    "end": "606860"
  },
  {
    "text": "is to perform different tasks. For example, the autoregressive\nmodel cannot fill in the blank",
    "start": "606860",
    "end": "614990"
  },
  {
    "text": "in the sequence, but\nGLM and BERT can, so we use different\npretraining task.",
    "start": "614990",
    "end": "623279"
  },
  {
    "text": "But currently, we know that the\ntask adaptation is very cheap.",
    "start": "623280",
    "end": "629520"
  },
  {
    "text": "You just need to fine\ntune your language model at the final period.",
    "start": "629520",
    "end": "636940"
  },
  {
    "text": "The only important thing\nis your pretraining loss.",
    "start": "636940",
    "end": "643640"
  },
  {
    "text": "The last figure is\nfrom InstructGPT.",
    "start": "643640",
    "end": "650420"
  },
  {
    "text": "This is actually the paper\nabout ChatGPT and how can",
    "start": "650420",
    "end": "655760"
  },
  {
    "text": "we align a pretrained\nmodel to a chat model. It told that the alignment can\ngive a very huge improvement",
    "start": "655760",
    "end": "667520"
  },
  {
    "text": "on human preference compared to\nthe original pretrained language",
    "start": "667520",
    "end": "673700"
  },
  {
    "text": "model. And the right figure is actually\na recent paper in our company.",
    "start": "673700",
    "end": "682750"
  },
  {
    "text": "It tells us a very\nimportant fact. Maybe it's intuitive.",
    "start": "682750",
    "end": "690199"
  },
  {
    "text": "The fact is the performance\nof downstream task",
    "start": "690200",
    "end": "696860"
  },
  {
    "text": "is only related to the\nloss of pretraining.",
    "start": "696860",
    "end": "705700"
  },
  {
    "text": "And it's not directly relevant\nto the model size, which",
    "start": "705700",
    "end": "712270"
  },
  {
    "text": "means if a large model which a\nvery high loss because of lack",
    "start": "712270",
    "end": "721560"
  },
  {
    "text": "of training. And a small model, we\ntrain more and reach",
    "start": "721560",
    "end": "727320"
  },
  {
    "text": "the same level of loss. They performed exactly the\nsame in the downstream tasks.",
    "start": "727320",
    "end": "736590"
  },
  {
    "text": "So the so-called\nemergent ability",
    "start": "736590",
    "end": "741960"
  },
  {
    "text": "and some other maybe ability,\nstrange rumors are not true.",
    "start": "741960",
    "end": "751550"
  },
  {
    "text": "Actually, the ability is not\nfrom the number of parameters",
    "start": "751550",
    "end": "758399"
  },
  {
    "text": "of language model. It's actually only relevant to\nthe loss of your language model.",
    "start": "758400",
    "end": "766720"
  },
  {
    "text": "So all the language model\nbecame a game of curve fitting.",
    "start": "766720",
    "end": "773610"
  },
  {
    "text": "This is actually the\ncurrent situation",
    "start": "773610",
    "end": "781596"
  },
  {
    "text": "of language model research. So there's also some technical\ndetails of large language model.",
    "start": "781596",
    "end": "791040"
  },
  {
    "text": "Even we know it's\nnot curve fitting,",
    "start": "791040",
    "end": "796110"
  },
  {
    "text": "but there's a lot\nof important things. So back from some basics and\ntalk about the transformer",
    "start": "796110",
    "end": "809730"
  },
  {
    "text": "architecture. A very interesting thing is\nthe most important improvements",
    "start": "809730",
    "end": "816660"
  },
  {
    "text": "nowadays are still from the\nfirst author of the transformer",
    "start": "816660",
    "end": "821910"
  },
  {
    "text": "paper, the Noam, and maybe\nfrom his other papers.",
    "start": "821910",
    "end": "827259"
  },
  {
    "text": "So actually, the real\ninnovation in the architectures",
    "start": "827260",
    "end": "833790"
  },
  {
    "text": "is very small. I can summarize some common\nadaptation on transformer",
    "start": "833790",
    "end": "843240"
  },
  {
    "text": "currently. First is decoder only. The original transformer is a\nencoder-decoder architecture,",
    "start": "843240",
    "end": "850529"
  },
  {
    "text": "so it's redundant because\nthe encoder and the decoder",
    "start": "850530",
    "end": "860250"
  },
  {
    "text": "should learn how to\nunderstand the task",
    "start": "860250",
    "end": "865380"
  },
  {
    "text": "from different parameters. So it's redundant. And currently we only care about\ndecoder-only architectures.",
    "start": "865380",
    "end": "875070"
  },
  {
    "text": "The second one is\npre-layer norm. In the original\ntransformer layer,",
    "start": "875070",
    "end": "880450"
  },
  {
    "text": "the layer norm is after\nthe residual connection.",
    "start": "880450",
    "end": "885780"
  },
  {
    "text": "It's called a posterior norm. And currently, we usually\nuse pre-layer norm.",
    "start": "885780",
    "end": "893240"
  },
  {
    "text": "The rotary position embedding\nis something very special because it's not\npublished from a paper.",
    "start": "893240",
    "end": "900135"
  },
  {
    "text": "It's not. It's published from\na Chinese blog.",
    "start": "900135",
    "end": "906086"
  },
  {
    "text": "But currently, it has\nproven very efficient.",
    "start": "906086",
    "end": "913730"
  },
  {
    "text": "And the group query\nattention is actually from another paper of Noam.",
    "start": "913730",
    "end": "920720"
  },
  {
    "text": "It can save the\ninference memory. And GLU warrant\nis also from Noam.",
    "start": "920720",
    "end": "928680"
  },
  {
    "text": "It's just a\nreplacement of the MLP.",
    "start": "928680",
    "end": "934740"
  },
  {
    "text": "And mixture-of-expert is\nactually also from Noam's paper.",
    "start": "934740",
    "end": "941020"
  },
  {
    "text": "And you can use the same\nFLOPs, small parameter to get better performance.",
    "start": "941020",
    "end": "947940"
  },
  {
    "text": "So this is what's the\ncurrent and most of the ones",
    "start": "947940",
    "end": "955410"
  },
  {
    "text": "open-source language model, the\narchitecture of most advanced open-source language model.",
    "start": "955410",
    "end": "960880"
  },
  {
    "text": "For example, Llama. OK. We know there's\narchitecture, but how",
    "start": "960880",
    "end": "967510"
  },
  {
    "text": "to train this transformer\nis also very important.",
    "start": "967510",
    "end": "974080"
  },
  {
    "text": "We need to prepare\na very powerful code",
    "start": "974080",
    "end": "979480"
  },
  {
    "text": "base to train the\nlarge language model. So the first choice\nis called DeepSpeed.",
    "start": "979480",
    "end": "987170"
  },
  {
    "text": "It's a library from Microsoft. And some of the most\nimportant optimization method",
    "start": "987170",
    "end": "995610"
  },
  {
    "text": "is from a paper called\nZeRO from DeepSpeed group.",
    "start": "995610",
    "end": "1001570"
  },
  {
    "text": " Several years ago, some\nof us not really know",
    "start": "1001570",
    "end": "1010540"
  },
  {
    "text": "how to train a very large model,\nhow to efficiently train them,",
    "start": "1010540",
    "end": "1015850"
  },
  {
    "text": "but ZeRO give us some advices. For example, we can find\nthe most memory consumption",
    "start": "1015850",
    "end": "1028390"
  },
  {
    "text": "is actually the Adam states. The optimizer\nstates, you must keep",
    "start": "1028390",
    "end": "1035380"
  },
  {
    "text": "it's for position as a float.",
    "start": "1035380",
    "end": "1040550"
  },
  {
    "text": "And the master weight\nis also a float. The parameter and gradient,\nyou can keep it high precision,",
    "start": "1040550",
    "end": "1048280"
  },
  {
    "text": "and you can have a fast\ncomputation and save memories.",
    "start": "1048280",
    "end": "1056430"
  },
  {
    "text": " But the ZeRO1 can scatter the\nmaster weight and optimizer",
    "start": "1056430",
    "end": "1064990"
  },
  {
    "text": "state into all the\ndata parallel racks. So if you have more\nracks, more GPU cards,",
    "start": "1064990",
    "end": "1075130"
  },
  {
    "text": "you just use less GPU\nmemory for each rank.",
    "start": "1075130",
    "end": "1085810"
  },
  {
    "text": "Another important technique is\ncalled activation checkpointing. It's actually recall the\nintermediate state and recompute",
    "start": "1085810",
    "end": "1096700"
  },
  {
    "text": "going backward. So we don't really need to\nrecord all the computation flow",
    "start": "1096700",
    "end": "1104080"
  },
  {
    "text": "graph. We just need to record\nsome of the hidden states.",
    "start": "1104080",
    "end": "1110830"
  },
  {
    "text": "It's reduce all the\nactivation from many layers",
    "start": "1110830",
    "end": "1116500"
  },
  {
    "text": "into one layers. And there's other methods to\nreduce the memory consumption.",
    "start": "1116500",
    "end": "1125210"
  },
  {
    "text": "For example, ZeRO2\nCPU offload, which means you can offload\nsome GPU memory to CPU.",
    "start": "1125210",
    "end": "1132310"
  },
  {
    "text": "And ZeRO3, also called\nfully-sharded data parallel.",
    "start": "1132310",
    "end": "1139940"
  },
  {
    "text": "You can just shard your\nmodel into different cards.",
    "start": "1139940",
    "end": "1145039"
  },
  {
    "text": "And when you use the parameter,\nyou gather this parameter from the other racks.",
    "start": "1145040",
    "end": "1150460"
  },
  {
    "text": "So all of this method\nis very complicated,",
    "start": "1150460",
    "end": "1156520"
  },
  {
    "text": "but the DeepSpeed library have\nalready give a very clean API",
    "start": "1156520",
    "end": "1162910"
  },
  {
    "text": "to use it. So currently, it's not very hard\nto train a very large language",
    "start": "1162910",
    "end": "1169480"
  },
  {
    "text": "model efficiently. And Megatron is\nanother framework",
    "start": "1169480",
    "end": "1176799"
  },
  {
    "text": "to train large language models. It is also the most\nvaluable framework",
    "start": "1176800",
    "end": "1182500"
  },
  {
    "text": "to train your super\nlarge language model with more than\n100 billion parameters.",
    "start": "1182500",
    "end": "1188200"
  },
  {
    "text": "It use another set of\noptimization method.",
    "start": "1188200",
    "end": "1194049"
  },
  {
    "text": "The first is called\ntensor parallel. The tensor parallel splits\nthe hidden sides and heads",
    "start": "1194050",
    "end": "1201700"
  },
  {
    "text": "into different ranks, and\nit calls an additional",
    "start": "1201700",
    "end": "1206889"
  },
  {
    "text": "or reduce for attention and MLP\nbut reduce the other parameters,",
    "start": "1206890",
    "end": "1219020"
  },
  {
    "text": "consumption and\ncomputing consumption into different TP ranks.",
    "start": "1219020",
    "end": "1225350"
  },
  {
    "text": "The pipeline parallel\nis to split the layers into different ranks.",
    "start": "1225350",
    "end": "1231350"
  },
  {
    "text": "And it also introduces\nbubbles in pipeline.",
    "start": "1231350",
    "end": "1238380"
  },
  {
    "text": "And there are some method,\nfor example, interleaved and ZeroBubble to\nremove this consumption.",
    "start": "1238380",
    "end": "1247580"
  },
  {
    "text": "Maybe if you want to train your\nvery large language model one",
    "start": "1247580",
    "end": "1253640"
  },
  {
    "text": "day, you need to learn about\nall this kind of system things,",
    "start": "1253640",
    "end": "1259160"
  },
  {
    "text": "because the current large\nlanguage model training is actually engineering work.",
    "start": "1259160",
    "end": "1267590"
  },
  {
    "text": "MLP is not very important. The important thing is ML6. ",
    "start": "1267590",
    "end": "1277620"
  },
  {
    "text": "So another very important\nthing is long context.",
    "start": "1277620",
    "end": "1282960"
  },
  {
    "text": "It's actually\nlossless long context, which means we don't\nuse sparse attention or other methods to change\nthe full attention behavior.",
    "start": "1282960",
    "end": "1292520"
  },
  {
    "text": " The current info how\nto train long context",
    "start": "1292520",
    "end": "1300270"
  },
  {
    "text": "is beyond the imagination\nfor AI guys five years ago.",
    "start": "1300270",
    "end": "1306840"
  },
  {
    "text": "The last figure is\nactually my paper when I published several\nyears ago in NeurIPS.",
    "start": "1306840",
    "end": "1317400"
  },
  {
    "text": "At that time, there's no\nsuch thing like GPT-3.",
    "start": "1317400",
    "end": "1322660"
  },
  {
    "text": "There's only BERT. So this paper is\nactually very complicated",
    "start": "1322660",
    "end": "1330300"
  },
  {
    "text": "to schedule two\ndifferent BERTs to mimic",
    "start": "1330300",
    "end": "1336640"
  },
  {
    "text": "the retrieval, rehearsal,\nand forecast process in working memory or human to\nlet the model to understand",
    "start": "1336640",
    "end": "1347900"
  },
  {
    "text": "very long context step by step. But actually, we can see that we\ncan use different system level",
    "start": "1347900",
    "end": "1359090"
  },
  {
    "text": "technicals to understand\nvery long contexts.",
    "start": "1359090",
    "end": "1364799"
  },
  {
    "text": "For example, more\nthan 100,000 length.",
    "start": "1364800",
    "end": "1372020"
  },
  {
    "text": "It's full attention. So it's just different\nfrom several years ago.",
    "start": "1372020",
    "end": "1377730"
  },
  {
    "text": "And many things is\nsuper simplified because of this improvement.",
    "start": "1377730",
    "end": "1386570"
  },
  {
    "text": "A key technique is\ncalled context parallel, which means we split the\nsequence into different ranks",
    "start": "1386570",
    "end": "1395330"
  },
  {
    "text": "and use a ring attention or\nUlysses and other technicals",
    "start": "1395330",
    "end": "1403190"
  },
  {
    "text": "to finish the attention.",
    "start": "1403190",
    "end": "1410019"
  },
  {
    "text": "And there's a library\ncalled TransformerEngine, and all this function is\nwarped in this library.",
    "start": "1410020",
    "end": "1418040"
  },
  {
    "text": "And we need to handle the\nload balance of the attention",
    "start": "1418040",
    "end": "1423520"
  },
  {
    "text": "to make everyone have\nthe same computation. So this is actually change\nlots of different research",
    "start": "1423520",
    "end": "1435070"
  },
  {
    "text": "and applications of [INAUDIBLE]. For example, we summary\nand it's trying some facts",
    "start": "1435070",
    "end": "1445929"
  },
  {
    "text": "from the documents several\nyears ago using BM25",
    "start": "1445930",
    "end": "1451570"
  },
  {
    "text": "or another retrieval method. And currently we can just use a\ntransformer and full attention",
    "start": "1451570",
    "end": "1459640"
  },
  {
    "text": "to get the information\nand understand it. It's a quite\nimportant improvement.",
    "start": "1459640",
    "end": "1468789"
  },
  {
    "text": "So using this very\npowerful Infra, we can train very\nlarge language models.",
    "start": "1468790",
    "end": "1476800"
  },
  {
    "text": "And for the alignment,\nthe first period is called SFT,\nSupervised Fine Tuning.",
    "start": "1476800",
    "end": "1483970"
  },
  {
    "text": "It's actually a\nvery ordinary fine tuning for language model\non high-quality data.",
    "start": "1483970",
    "end": "1493030"
  },
  {
    "text": "And the high-quality data is\nusually from human annotation",
    "start": "1493030",
    "end": "1499100"
  },
  {
    "text": "This human annotation is\nnot just for sourcing. You need to hear experts\nfrom different domains who",
    "start": "1499100",
    "end": "1508030"
  },
  {
    "text": "write these high-quality\nanswers to train the model. For example, if you want\nthe model to write some code",
    "start": "1508030",
    "end": "1522200"
  },
  {
    "text": "and explain the code in\na very formatted way,",
    "start": "1522200",
    "end": "1527220"
  },
  {
    "text": "you need to hire a very\nexperienced programmer",
    "start": "1527220",
    "end": "1534409"
  },
  {
    "text": "to write some examples to\nteach this language model.",
    "start": "1534410",
    "end": "1540440"
  },
  {
    "text": "It's not just crowdsourcing. This is quite different from\nthe previous human annotation.",
    "start": "1540440",
    "end": "1546980"
  },
  {
    "text": " We can also extract the\nquestion-answer pairs",
    "start": "1546980",
    "end": "1555290"
  },
  {
    "text": "from more powerful models like\nGPT-4 Turbo to train our model.",
    "start": "1555290",
    "end": "1561140"
  },
  {
    "text": "But this is actually\nnot alone by OpenAI,",
    "start": "1561140",
    "end": "1567650"
  },
  {
    "text": "so you cannot use this method\nto develop a model to competing",
    "start": "1567650",
    "end": "1574970"
  },
  {
    "text": "with them. But actually, if\nfor research, you",
    "start": "1574970",
    "end": "1581660"
  },
  {
    "text": "don't worry about\nusing that method, well, now, we have\nsurpassed GPT-4,",
    "start": "1581660",
    "end": "1588260"
  },
  {
    "text": "because there's a paper called\nWeak-to-Strong Generalization. And recall what\nI said just now--",
    "start": "1588260",
    "end": "1596475"
  },
  {
    "text": " what's really important\nis your pretraining loss.",
    "start": "1596475",
    "end": "1603419"
  },
  {
    "text": "If your pretraining loss is\nlower than your teacher model,",
    "start": "1603420",
    "end": "1608960"
  },
  {
    "text": "you can also surpass\nyour teacher model,",
    "start": "1608960",
    "end": "1614630"
  },
  {
    "text": "even you use SFT data\nfrom your teacher model. ",
    "start": "1614630",
    "end": "1622679"
  },
  {
    "text": "And another period of\nalignment is called RLHF. It use reinforcement\nlearning from human feedback",
    "start": "1622680",
    "end": "1630270"
  },
  {
    "text": "to improve the model. But actually, the most\ncommon open-language model",
    "start": "1630270",
    "end": "1638070"
  },
  {
    "text": "didn't use this method. The main reason is PPO is\nvery hard to implement.",
    "start": "1638070",
    "end": "1649740"
  },
  {
    "text": "It could be very\npowerful if your reward model is good enough,\nbut not easy to train.",
    "start": "1649740",
    "end": "1655150"
  },
  {
    "text": "So there's some\nmore easy method.",
    "start": "1655150",
    "end": "1663030"
  },
  {
    "text": "And most open-source language\nmodels, they use DPO method. It's from paper from Stanford.",
    "start": "1663030",
    "end": "1670410"
  },
  {
    "text": "And we only need some preference\npairs and this formula",
    "start": "1670410",
    "end": "1679110"
  },
  {
    "text": "to update your model. You don't really\nneed a reward model.",
    "start": "1679110",
    "end": "1686020"
  },
  {
    "text": "You don't really need a reward\nmodel, you just need some pairs.",
    "start": "1686020",
    "end": "1692650"
  },
  {
    "text": "Maybe this pair should some\non-policy pairs, but yeah.",
    "start": "1692650",
    "end": "1698110"
  },
  {
    "text": "But it's much simpler\nand also very powerful.",
    "start": "1698110",
    "end": "1705429"
  },
  {
    "text": "So these are basics of\nhow to train a language",
    "start": "1705430",
    "end": "1712240"
  },
  {
    "text": "model currently. And it seems like it's\nnothing about MLP.",
    "start": "1712240",
    "end": "1721600"
  },
  {
    "text": "It's actually a\nparty of ML6 guys. So what are the LLM\npretrainers doing",
    "start": "1721600",
    "end": "1730600"
  },
  {
    "text": "is actually the most\nimportant things is data.",
    "start": "1730600",
    "end": "1737799"
  },
  {
    "text": "Currently, the data cleaning,\nfiltering, synthesizing",
    "start": "1737800",
    "end": "1742960"
  },
  {
    "text": "is the most important thing of\nall the large language model",
    "start": "1742960",
    "end": "1748419"
  },
  {
    "text": "company, which is a open secret. So the training\ninfra is actually",
    "start": "1748420",
    "end": "1757270"
  },
  {
    "text": "a bit-- it's basically what I\nsaid in the last several slides.",
    "start": "1757270",
    "end": "1765080"
  },
  {
    "text": "Maybe there's some other\nmore advanced method, but the improvement is maybe\n20% or something like that.",
    "start": "1765080",
    "end": "1774690"
  },
  {
    "text": "But if you have a\nbetter pretraining data,",
    "start": "1774690",
    "end": "1779750"
  },
  {
    "text": "the performance of your\nlanguage model is quite obvious.",
    "start": "1779750",
    "end": "1786790"
  },
  {
    "start": "1786790",
    "end": "1793940"
  },
  {
    "text": "The language model,\nwe're told by the media",
    "start": "1793940",
    "end": "1800309"
  },
  {
    "text": "it's most one thing. But actually, most\nof the ML engineering",
    "start": "1800310",
    "end": "1811620"
  },
  {
    "text": "in large language model company\nis actually cleaning the data. So is this something a Stanford\ngraduate student should do?",
    "start": "1811620",
    "end": "1820500"
  },
  {
    "text": "Maybe someone seen as very low.",
    "start": "1820500",
    "end": "1825510"
  },
  {
    "text": "I want to design some new\nalgorithm architectures. This is rare ML research.",
    "start": "1825510",
    "end": "1830970"
  },
  {
    "text": "But I have opinion that\nthe data, the algorithm,",
    "start": "1830970",
    "end": "1837570"
  },
  {
    "text": "and the architecture can\ntransform to each other.",
    "start": "1837570",
    "end": "1843149"
  },
  {
    "text": "So the data is\nmost general form.",
    "start": "1843150",
    "end": "1848690"
  },
  {
    "text": "But sometimes if you\ndon't have enough compute,",
    "start": "1848690",
    "end": "1854929"
  },
  {
    "text": "it could be very hard to\nfit this kind of data.",
    "start": "1854930",
    "end": "1861710"
  },
  {
    "text": "And the algorithm is\nvery hard to implement",
    "start": "1861710",
    "end": "1866779"
  },
  {
    "text": "and not very general. The architecture, it's hard\nto perform what you want.",
    "start": "1866780",
    "end": "1876110"
  },
  {
    "text": "Designing new\narchitecture is very hard. I will take a multi-hop question\nanswering task as an example.",
    "start": "1876110",
    "end": "1886460"
  },
  {
    "text": "The right figure\nis from the CogQA. It's also one of my papers\nwhen I was a PhD student.",
    "start": "1886460",
    "end": "1896240"
  },
  {
    "text": "It's actually about a task to--",
    "start": "1896240",
    "end": "1903360"
  },
  {
    "text": "we have very complex question\nand we need to find the task.",
    "start": "1903360",
    "end": "1908429"
  },
  {
    "text": "So the task finds the answer\nfrom several documents, but you need to find\nthe chain reasoning",
    "start": "1908430",
    "end": "1919140"
  },
  {
    "text": "between different documents\nto get the final answer. So at that time, I\npropose a method.",
    "start": "1919140",
    "end": "1926265"
  },
  {
    "text": "It involved a broad and\ngraph neural network is very complicated.",
    "start": "1926265",
    "end": "1932700"
  },
  {
    "text": "And finally, I got a\nvery good performance,",
    "start": "1932700",
    "end": "1938130"
  },
  {
    "text": "and 10 points better\nthan the previous method.",
    "start": "1938130",
    "end": "1944610"
  },
  {
    "text": "But yeah, this is actually\nsome algorithm or architecture",
    "start": "1944610",
    "end": "1954090"
  },
  {
    "text": "innovation. It's very fancy and get very\nhigh score in ACL review.",
    "start": "1954090",
    "end": "1961389"
  },
  {
    "text": "But there's some\nother concurrent work that use MCTS, the Monte\nCarlo Tree Search and BERT",
    "start": "1961390",
    "end": "1969940"
  },
  {
    "text": "and something like that. It looks like a\nalgorithm-level innovation",
    "start": "1969940",
    "end": "1975130"
  },
  {
    "text": "to solve this problem. But currently, this problem\ncan be easily solved by a very long context GPT and\nchain-of-thought reasoning.",
    "start": "1975130",
    "end": "1985300"
  },
  {
    "text": "If you include nearly all the\ndocuments into your contexts,",
    "start": "1985300",
    "end": "1991240"
  },
  {
    "text": "you don't need any things like\ngraph neural network or MCTS",
    "start": "1991240",
    "end": "1996460"
  },
  {
    "text": "to jump between the documents. You have all the\ncontacts, and you can just",
    "start": "1996460",
    "end": "2005700"
  },
  {
    "text": "finish using channel sort. It's a data-level solution.",
    "start": "2005700",
    "end": "2011470"
  },
  {
    "text": "So the data-level solution is,\nof course, the most simple one",
    "start": "2011470",
    "end": "2017010"
  },
  {
    "text": "because you just add the data\ninto your training corpus,",
    "start": "2017010",
    "end": "2023050"
  },
  {
    "text": "and you can just finish\nthis task while not affect other tasks.",
    "start": "2023050",
    "end": "2028880"
  },
  {
    "text": "So the data cleaning,\nfiltering, exercising is not a very easy work, and it\nactually very important view--",
    "start": "2028880",
    "end": "2043450"
  },
  {
    "text": "important to do this. We should transform our\nview of data and algorithms,",
    "start": "2043450",
    "end": "2053050"
  },
  {
    "text": "our entire chart, to\nfit the current AI.",
    "start": "2053050",
    "end": "2058658"
  },
  {
    "text": "So I have introduced\nsome knowledge",
    "start": "2058659",
    "end": "2064119"
  },
  {
    "text": "about both the\nlanguage models, so I",
    "start": "2064120",
    "end": "2069780"
  },
  {
    "text": "will jump into the second\npart, which is visual language",
    "start": "2069780",
    "end": "2075149"
  },
  {
    "text": "models in the past one year. So the past one year, we have\nseen the visual language models",
    "start": "2075150",
    "end": "2086520"
  },
  {
    "text": "jump from nearly very silly one\nto our currently very powerful",
    "start": "2086520",
    "end": "2096110"
  },
  {
    "text": "ones. So I will start from BLIP-2,\nwhich is actually maybe,",
    "start": "2096110",
    "end": "2104220"
  },
  {
    "text": "I think, the first\nwork to bridge the CLIP and can train a large language\nmodel to give the language",
    "start": "2104220",
    "end": "2113550"
  },
  {
    "text": "model the ability to\nunderstand the images.",
    "start": "2113550",
    "end": "2119220"
  },
  {
    "text": "Actually, if we have\nan image encoder from CLIP and the large\nlanguage model from anywhere.",
    "start": "2119220",
    "end": "2128770"
  },
  {
    "text": "So you can just insert,\non our transformer, called",
    "start": "2128770",
    "end": "2134870"
  },
  {
    "text": "a Q-former to extract some\nimportant features from image",
    "start": "2134870",
    "end": "2140540"
  },
  {
    "text": "encoder and insert these\nfeatures into large language model.",
    "start": "2140540",
    "end": "2146990"
  },
  {
    "text": "But the space of image features\nand text features is different,",
    "start": "2146990",
    "end": "2153840"
  },
  {
    "text": "so the Q-former is trainable. You'll need lots\nof text-image pairs",
    "start": "2153840",
    "end": "2162230"
  },
  {
    "text": "and align the space\nof image features and the language and\ntext features the space.",
    "start": "2162230",
    "end": "2171425"
  },
  {
    "text": " The Q-former actually did this.",
    "start": "2171425",
    "end": "2178910"
  },
  {
    "text": "But there is a more simple\n[INAUDIBLE] of called LLaVA.",
    "start": "2178910",
    "end": "2186990"
  },
  {
    "text": "It's actually don't use a\nsimple projection weight",
    "start": "2186990",
    "end": "2195890"
  },
  {
    "text": "to transform the vision encoder,\nthe feature from vision encoder",
    "start": "2195890",
    "end": "2201170"
  },
  {
    "text": "into the features in the\nlanguage model input.",
    "start": "2201170",
    "end": "2207160"
  },
  {
    "text": "So it's quickly become the\nmost popular architecture",
    "start": "2207160",
    "end": "2213760"
  },
  {
    "text": "of vision language models. CogVLM is a work from our group.",
    "start": "2213760",
    "end": "2222795"
  },
  {
    "text": " The motivation of CogVLM is to\nkeep all the language behavior",
    "start": "2222795",
    "end": "2231510"
  },
  {
    "text": "while we add language--",
    "start": "2231510",
    "end": "2237420"
  },
  {
    "text": "image understanding ability\nto the language model. For LLaVA-- for the\nprevious method,",
    "start": "2237420",
    "end": "2251599"
  },
  {
    "text": "you actually can train\nthe language model",
    "start": "2251600",
    "end": "2257290"
  },
  {
    "text": "and get a better\nperformance, but it's",
    "start": "2257290",
    "end": "2265260"
  },
  {
    "text": "about multimodality task. The language\nability of the model",
    "start": "2265260",
    "end": "2272220"
  },
  {
    "text": "will be reduced if\nyou train the language model during the\ntext-image alignment.",
    "start": "2272220",
    "end": "2278880"
  },
  {
    "text": "So we first use\nour vision experts",
    "start": "2278880",
    "end": "2287750"
  },
  {
    "text": "to add new parameters\nin the backbone, and the vision experts only\ndeal with the image features.",
    "start": "2287750",
    "end": "2298970"
  },
  {
    "text": "And the original weights\nin feedforward layers and the matrix, they're\nalways original task features.",
    "start": "2298970",
    "end": "2307170"
  },
  {
    "text": "So the original behavior\nof language model is kept,",
    "start": "2307170",
    "end": "2314950"
  },
  {
    "text": "and we add lots\nof new parameters to train and get a\nbetter performance",
    "start": "2314950",
    "end": "2323590"
  },
  {
    "text": "of multi-modality models. So CogVLM achieves a\nstate-of-art performance",
    "start": "2323590",
    "end": "2331630"
  },
  {
    "text": "of several benchmarks, including\nimage captioning, grounding, and VQA and some other visual\nlanguage model benchmarks.",
    "start": "2331630",
    "end": "2341680"
  },
  {
    "text": "And it's also open source,\nso you can download it from our GitHub.",
    "start": "2341680",
    "end": "2348460"
  },
  {
    "text": "Last month I found that CogVLM\nis downloaded more than 500,000",
    "start": "2348460",
    "end": "2359260"
  },
  {
    "text": "times in the last month, so I\nthink it's already helped lots",
    "start": "2359260",
    "end": "2366400"
  },
  {
    "text": "of people. And CogAgent here, another\nworks from our group.",
    "start": "2366400",
    "end": "2375580"
  },
  {
    "text": "It's use a different\narchitectures because we want high resolution\nwith cross attention.",
    "start": "2375580",
    "end": "2382540"
  },
  {
    "text": "Why it's cross attention? Because we don't want to--",
    "start": "2382540",
    "end": "2387940"
  },
  {
    "text": "we just want a\nhigh-resolution input. I don't want to let\nall the hidden size",
    "start": "2387940",
    "end": "2394030"
  },
  {
    "text": "data as thin as\nthe language model hidden size, which\nis very large.",
    "start": "2394030",
    "end": "2399590"
  },
  {
    "text": "So we use cross attention to\ndeal with the low resolution.",
    "start": "2399590",
    "end": "2405940"
  },
  {
    "text": "The high resolution channels,\nit's slightly complicated,",
    "start": "2405940",
    "end": "2411280"
  },
  {
    "text": "but the performance\nis very good. We can find-- this\nmodel, they actually",
    "start": "2411280",
    "end": "2421660"
  },
  {
    "text": "trained it to be a web agent. And it's just take\nscreenshots as input,",
    "start": "2421660",
    "end": "2432309"
  },
  {
    "text": "and it will perform different\noperation on the screenshot.",
    "start": "2432310",
    "end": "2442250"
  },
  {
    "text": "For example, this is an example\nfor a search, the last year's",
    "start": "2442250",
    "end": "2450340"
  },
  {
    "text": "best paper in CVPR. So we ask the model\nthese questions.",
    "start": "2450340",
    "end": "2456890"
  },
  {
    "text": "It told me you need to type\nthe best paper of CVPR 2023",
    "start": "2456890",
    "end": "2463630"
  },
  {
    "text": "in the box at this position. And step by step, finally\nwe gather information.",
    "start": "2463630",
    "end": "2470710"
  },
  {
    "text": "And we can also use this\nmethod to book some tickets",
    "start": "2470710",
    "end": "2478000"
  },
  {
    "text": "or perform some other tasks. This is also open source.",
    "start": "2478000",
    "end": "2485680"
  },
  {
    "text": "Some other popular architecture\nis about varied language",
    "start": "2485680",
    "end": "2492680"
  },
  {
    "text": "modeling and includes Vary.",
    "start": "2492680",
    "end": "2498380"
  },
  {
    "text": "It's actually an ensemble\nof different vision features as input. And it's largely improved\nthe OCR performance.",
    "start": "2498380",
    "end": "2507030"
  },
  {
    "text": "But what I want to\nstress is most--",
    "start": "2507030",
    "end": "2515360"
  },
  {
    "text": "once the Vary\nlanguage model GLM-4V, we actually use a more\nsimple architecture.",
    "start": "2515360",
    "end": "2523940"
  },
  {
    "text": "It's actually a small\nadaptation upon LLaVA.",
    "start": "2523940",
    "end": "2531095"
  },
  {
    "text": "We just replaced the\nprojection rate of LLaVA",
    "start": "2531095",
    "end": "2536480"
  },
  {
    "text": "into a stride convolution to\nsupport high-resolution input but keep the computation\nin language model.",
    "start": "2536480",
    "end": "2545619"
  },
  {
    "text": "And using this architecture, we\ncan train the vision language",
    "start": "2545620",
    "end": "2550720"
  },
  {
    "text": "model mixed with the text. And finally, we get\na good performance.",
    "start": "2550720",
    "end": "2557150"
  },
  {
    "text": "We can say that GLM-4V can, on\nthe power of GPT-4V or Gemini",
    "start": "2557150",
    "end": "2564730"
  },
  {
    "text": "or Claude3, and it performed\nbetter in OCR benchmarks,",
    "start": "2564730",
    "end": "2574210"
  },
  {
    "text": "for example, document QA. And it's perform much\nbetter at Chinese OCR.",
    "start": "2574210",
    "end": "2582619"
  },
  {
    "text": "This is an example of our\nmost advanced GLM-4V model.",
    "start": "2582620",
    "end": "2590660"
  },
  {
    "text": "You can download our app\nfrom this chatglm.cn website.",
    "start": "2590660",
    "end": "2601190"
  },
  {
    "text": "This is actually a very\nhard to recognize draft,",
    "start": "2601190",
    "end": "2608800"
  },
  {
    "text": "and it's also a meme. The model can analyze\nit very accurately",
    "start": "2608800",
    "end": "2617059"
  },
  {
    "text": "and can translate\nwhat is really right.",
    "start": "2617060",
    "end": "2624830"
  },
  {
    "text": "You can experience our model. It's totally free\nfrom this website.",
    "start": "2624830",
    "end": "2631220"
  },
  {
    "text": "OK. We have some introduction about\nvision language understanding.",
    "start": "2631220",
    "end": "2638990"
  },
  {
    "text": "It's more about engineering,\nbut it's multi-modality.",
    "start": "2638990",
    "end": "2645170"
  },
  {
    "text": "And another half of the\nvision language research about image\ngeneration and is also",
    "start": "2645170",
    "end": "2651020"
  },
  {
    "text": "very relevant to transformers. So I will also introduce the\nrule about image generation.",
    "start": "2651020",
    "end": "2660505"
  },
  {
    "start": "2660505",
    "end": "2666519"
  },
  {
    "text": "Three or four years\nago, we already",
    "start": "2666520",
    "end": "2673890"
  },
  {
    "text": "know the GPT is very powerful. So we want to autoregressively\nmodeling the text generation",
    "start": "2673890",
    "end": "2683390"
  },
  {
    "text": "for using the GPT architecture. So this is the work of CogView.",
    "start": "2683390",
    "end": "2692600"
  },
  {
    "text": "It's also my work at 2022, '21.",
    "start": "2692600",
    "end": "2699770"
  },
  {
    "text": "It's a very simple\nframework because we",
    "start": "2699770",
    "end": "2706970"
  },
  {
    "text": "know that GPT can only predict\nmultinomial distribution,",
    "start": "2706970",
    "end": "2711990"
  },
  {
    "text": "so we need to find\nsome method to train",
    "start": "2711990",
    "end": "2718310"
  },
  {
    "text": "the image in a discrete way. There is a, maybe 2020, there's\na paper called iGPT from OpenAI.",
    "start": "2718310",
    "end": "2730380"
  },
  {
    "text": "It's trained directly\non the pixel level for autoregressive modeling.",
    "start": "2730380",
    "end": "2735870"
  },
  {
    "text": "But the sequence is very\nlong, so you cannot train very",
    "start": "2735870",
    "end": "2746110"
  },
  {
    "text": "high-resolution images. So we can reinforce the\ntraining image tokenizer.",
    "start": "2746110",
    "end": "2752950"
  },
  {
    "text": "It's actually a VQ way\nto discrete your image",
    "start": "2752950",
    "end": "2761170"
  },
  {
    "text": "into several tokens. And you prepare the\nsequence of a text image",
    "start": "2761170",
    "end": "2769840"
  },
  {
    "text": "as the text first,\nimage later, and you can use GPT to train\nthese kind of segments.",
    "start": "2769840",
    "end": "2779830"
  },
  {
    "text": "And finally, during\nthe inference, you first impose the text\nand then predicts token",
    "start": "2779830",
    "end": "2787630"
  },
  {
    "text": "by token in the image, and\nyou can generate some image.",
    "start": "2787630",
    "end": "2793690"
  },
  {
    "text": "This is a very simple idea and\na concurrent work called Dall-E,",
    "start": "2793690",
    "end": "2799220"
  },
  {
    "text": "and the most\npowerful work called Parti is from the same idea.",
    "start": "2799220",
    "end": "2806055"
  },
  {
    "start": "2806055",
    "end": "2812020"
  },
  {
    "text": "We know that we generate\nan image using GPT.",
    "start": "2812020",
    "end": "2817840"
  },
  {
    "text": "So a very natural\nidea is, can we",
    "start": "2817840",
    "end": "2823780"
  },
  {
    "text": "achieve some universal modeling\nfor vision language tasks?",
    "start": "2823780",
    "end": "2829600"
  },
  {
    "text": "So if we just tokenize the\nimage just like the text,",
    "start": "2829600",
    "end": "2836570"
  },
  {
    "text": "we can generate image, we can\ngenerate text from the image,",
    "start": "2836570",
    "end": "2843650"
  },
  {
    "text": "we can generate image from\ntext, and only generate text. So this is a very neutral idea.",
    "start": "2843650",
    "end": "2851050"
  },
  {
    "text": "And I also did this in CogVL too\nmaybe two years ago, and yeah.",
    "start": "2851050",
    "end": "2862670"
  },
  {
    "text": "The other reason it's also very\nsimple is just in the sequence,",
    "start": "2862670",
    "end": "2869329"
  },
  {
    "text": "you change different position\nof text and image sequence.",
    "start": "2869330",
    "end": "2876050"
  },
  {
    "text": "If first text then image\nand you mask all the things as text-to-image generation,\nyou force image then text,",
    "start": "2876050",
    "end": "2884960"
  },
  {
    "text": "it's image captioning. And you can also get other\nformats like masked auto-encoder",
    "start": "2884960",
    "end": "2896105"
  },
  {
    "text": "or something like that. But the problem is when you\ncompare this universal modeling",
    "start": "2896105",
    "end": "2905569"
  },
  {
    "text": "system to diffusion or visual\nlanguage modeling with a vision",
    "start": "2905570",
    "end": "2911000"
  },
  {
    "text": "language model, you will\nfind the image generation is worse than the diffusion and\nvery slow compared to diffusion.",
    "start": "2911000",
    "end": "2922010"
  },
  {
    "text": "For image understanding\nit performed worse than vision language model,\nbecause when you transform",
    "start": "2922010",
    "end": "2935570"
  },
  {
    "text": "your image into discrete\ntokens, lots of information",
    "start": "2935570",
    "end": "2942440"
  },
  {
    "text": "is lost during this process. So the performance is worse\nthan the vision language model.",
    "start": "2942440",
    "end": "2951980"
  },
  {
    "text": "So using this method, you can\nachieve universal modeling,",
    "start": "2951980",
    "end": "2958880"
  },
  {
    "text": "but you just achieve\nuniversal modeling, and you cannot achieve the\nbest performance on any task.",
    "start": "2958880",
    "end": "2969990"
  },
  {
    "text": " So the diffusion\nmethod actually wins",
    "start": "2969990",
    "end": "2978230"
  },
  {
    "text": "the game of image generation,\nand not the autoregressive. Although in the MLP domain\nthe autoregressive method",
    "start": "2978230",
    "end": "2987770"
  },
  {
    "text": "is dominant, but in\nimage generation, the winner is diffusion.",
    "start": "2987770",
    "end": "2993200"
  },
  {
    "text": "So what is a diffusion? Diffusion is a totally different\nself-supervised learning method",
    "start": "2993200",
    "end": "3004600"
  },
  {
    "text": "compared to\nautoregressive methods. You can also think it's a\nautoregressive on a Fourier",
    "start": "3004600",
    "end": "3014740"
  },
  {
    "text": "domain or something like that. But actually it's the DDPM is\nthe original paper of diffusion",
    "start": "3014740",
    "end": "3026180"
  },
  {
    "text": "model. It's still the most popular\nframework of diffusion modeling.",
    "start": "3026180",
    "end": "3031510"
  },
  {
    "text": "We can define a lot of\nsteps as we gradually",
    "start": "3031510",
    "end": "3037960"
  },
  {
    "text": "add in noise to a\nclean image and we",
    "start": "3037960",
    "end": "3043330"
  },
  {
    "text": "get different\nintermediate states and train your model to predict\nthe noise, the original image,",
    "start": "3043330",
    "end": "3053290"
  },
  {
    "text": "or something like v [INAUDIBLE]\nof the angle of the [INAUDIBLE]",
    "start": "3053290",
    "end": "3061870"
  },
  {
    "text": "and are actually given the\nnoisy input, noisy image.",
    "start": "3061870",
    "end": "3067070"
  },
  {
    "text": "So it's totally different,\nbut the most advantage",
    "start": "3067070",
    "end": "3076540"
  },
  {
    "text": "of differential model\nor autoregressive model is that during sampling, we\ncan use full utility of GPUS",
    "start": "3076540",
    "end": "3096710"
  },
  {
    "text": "because in our regressive\nmodel, when we decode the token,",
    "start": "3096710",
    "end": "3102080"
  },
  {
    "text": "we actually wasted\nthe power of the GPU.",
    "start": "3102080",
    "end": "3108410"
  },
  {
    "text": "The utility of GPU is very low\nif the batch size is small, the batch size equal to 1.",
    "start": "3108410",
    "end": "3114619"
  },
  {
    "text": "But for diffusion model,\nwe just input all the image",
    "start": "3114620",
    "end": "3119960"
  },
  {
    "text": "into the model so it\ncan utilize the GPU",
    "start": "3119960",
    "end": "3125480"
  },
  {
    "text": "and it can sample it much faster\nthan autoregressive model. ",
    "start": "3125480",
    "end": "3134790"
  },
  {
    "text": "The Relay Diffusion\nModel is our recent work.",
    "start": "3134790",
    "end": "3143140"
  },
  {
    "text": "It solves the\nproblem in diffusion",
    "start": "3143140",
    "end": "3148289"
  },
  {
    "text": "about the noise scatter\nacross different resolution.",
    "start": "3148290",
    "end": "3154660"
  },
  {
    "text": "The first thing is you can see\nthe last image is actually three",
    "start": "3154660",
    "end": "3167230"
  },
  {
    "text": "images with the same noise. The A and B are two images\nwith different resolution",
    "start": "3167230",
    "end": "3175210"
  },
  {
    "text": "and with the same noise level. But the A is actually\nmore blurred for us",
    "start": "3175210",
    "end": "3185049"
  },
  {
    "text": "during the observation. The problem is we add\nan independent noise.",
    "start": "3185050",
    "end": "3190555"
  },
  {
    "text": " And actually, the\noriginal signal, the image",
    "start": "3190555",
    "end": "3201800"
  },
  {
    "text": "is not independent\nacross the space. So what we need to\ndo is if we want",
    "start": "3201800",
    "end": "3217010"
  },
  {
    "text": "to transform a noisy\nschedule from low resolution to high resolution, we\nneed to use a block noise",
    "start": "3217010",
    "end": "3225290"
  },
  {
    "text": "to find the equivalence on\nthe high-resolution images.",
    "start": "3225290",
    "end": "3234850"
  },
  {
    "text": "And finally, we can keep the SNR\nin the frequency graph the same.",
    "start": "3234850",
    "end": "3244480"
  },
  {
    "text": "So using this method, we can\ndisentangle the noisy schedule",
    "start": "3244480",
    "end": "3254140"
  },
  {
    "text": "and the actually network\nwe use for diffusion.",
    "start": "3254140",
    "end": "3259660"
  },
  {
    "text": "Using noisy schedule, we don't\ncare about the resolution. We just use a block noise when\nwe want to continue diffusion",
    "start": "3259660",
    "end": "3270250"
  },
  {
    "text": "on high resolution. So the speed can\nimprove because we",
    "start": "3270250",
    "end": "3277930"
  },
  {
    "text": "don't need to generate the\nimage from the high resolution,",
    "start": "3277930",
    "end": "3284260"
  },
  {
    "text": "from the condition on\nthe low-resolution image, high resolution fits.",
    "start": "3284260",
    "end": "3289800"
  },
  {
    "text": " And we also scale up the\nRelay Diffusion to CogView3",
    "start": "3289800",
    "end": "3296630"
  },
  {
    "text": "after the paper.",
    "start": "3296630",
    "end": "3302470"
  },
  {
    "text": "CogView3 is actually a\nlarge diffusion model. And after distillation,\nit could be very fast",
    "start": "3302470",
    "end": "3310849"
  },
  {
    "text": "because of the effectiveness\nof the Relay Diffusion.",
    "start": "3310850",
    "end": "3317710"
  },
  {
    "text": " Finally, we get to something\nrelevant to our topic,",
    "start": "3317710",
    "end": "3327069"
  },
  {
    "text": "transformer. And actually, the previous\nworks about diffusion is Unet,",
    "start": "3327070",
    "end": "3335800"
  },
  {
    "text": "and using transformer is\nnot trivial in diffusion.",
    "start": "3335800",
    "end": "3342640"
  },
  {
    "text": "The first work I think maybe is\nsolid enough is DiT from Meta.",
    "start": "3342640",
    "end": "3353160"
  },
  {
    "text": "The author of this paper is\nalso the author with ours. So the most difference between\nthe original transformer",
    "start": "3353160",
    "end": "3363700"
  },
  {
    "text": "and this DiT is\nthe ada layer norm.",
    "start": "3363700",
    "end": "3371010"
  },
  {
    "text": "Ada layer norm is\npredict a scale and bias",
    "start": "3371010",
    "end": "3376440"
  },
  {
    "text": "for different layer norm. And scale shifts for different\nlayer norm conditioning",
    "start": "3376440",
    "end": "3383130"
  },
  {
    "text": "on the timestamp. It's actually needs a very\nhuge amount parameters,",
    "start": "3383130",
    "end": "3389850"
  },
  {
    "text": "as the systems of hidden size\nnearly equal to QKV per layer,",
    "start": "3389850",
    "end": "3399780"
  },
  {
    "text": "but the input is only 1 int. 1 int is actually very strange\nbecause the input is only 1 int,",
    "start": "3399780",
    "end": "3409859"
  },
  {
    "text": "and you need millions of\nparameters to transform it. So there's some method can\nreduce this thing in practice.",
    "start": "3409860",
    "end": "3422234"
  },
  {
    "text": " The Stable Diffusion\n3 released recently.",
    "start": "3422235",
    "end": "3429760"
  },
  {
    "text": "It use another\narchitectures called MM-DiT. The Stable Diffusion\n3 first used",
    "start": "3429760",
    "end": "3436510"
  },
  {
    "text": "our released CogVLM to recaption\nall the model-- all the images and train a latent\ndiffusion model using",
    "start": "3436510",
    "end": "3443950"
  },
  {
    "text": "this new architecture. The new architecture seem\nlike very complicated, but the most important thing is\nthey use vision and text experts",
    "start": "3443950",
    "end": "3456920"
  },
  {
    "text": "like CogVLM instead of cross\nattention to T5 features",
    "start": "3456920",
    "end": "3462500"
  },
  {
    "text": "like the previous ones. So finally, we will talk\nshortly about video generation,",
    "start": "3462500",
    "end": "3470340"
  },
  {
    "text": "because Sora is a currently\nvery popular thing.",
    "start": "3470340",
    "end": "3478110"
  },
  {
    "text": "We published a video generation\nwork several years ago.",
    "start": "3478110",
    "end": "3485520"
  },
  {
    "text": "Final version is\npublished on ICLR. So it's maybe the first\nopen-source language",
    "start": "3485520",
    "end": "3491790"
  },
  {
    "text": "model for text-to-video\ngeneration, but the performance is much\nworse than the current Sora",
    "start": "3491790",
    "end": "3498660"
  },
  {
    "text": "because it's autoregressive. So using diffusion,\nwe can get better. We're currently also working for\nreplication of Sora-like models,",
    "start": "3498660",
    "end": "3508860"
  },
  {
    "text": "and we can summarize that\nthe improvement of Sora",
    "start": "3508860",
    "end": "3518620"
  },
  {
    "text": "account from this\naspect, the forces. There's no flaking\nin the videos.",
    "start": "3518620",
    "end": "3526930"
  },
  {
    "text": "It can generate\nhigh-quality images. The first one, so\nthe deflickering,",
    "start": "3526930",
    "end": "3533580"
  },
  {
    "text": "can be solved by the 3D\nlatence encoder-decoder.",
    "start": "3533580",
    "end": "3539560"
  },
  {
    "text": "And if you train your diffusion\ndecoder, it could better.",
    "start": "3539560",
    "end": "3545040"
  },
  {
    "text": "The high quality is\nthanks to the scaling up.",
    "start": "3545040",
    "end": "3551820"
  },
  {
    "text": "And it requires a\nvery high resolution. And this is something related\nto the long context fine",
    "start": "3551820",
    "end": "3561900"
  },
  {
    "text": "tuning and context\nparallel techniques in the language\nmodel Infra, which",
    "start": "3561900",
    "end": "3569040"
  },
  {
    "text": "I introduced at the\nbeginning of this course. So the most important\nthing is they",
    "start": "3569040",
    "end": "3579000"
  },
  {
    "text": "use the Infra, they use Infra\nin language model training into the diffusion and make\nit very easy to scale up",
    "start": "3579000",
    "end": "3592119"
  },
  {
    "text": "and scale up much larger\nthan the other companies.",
    "start": "3592120",
    "end": "3600520"
  },
  {
    "text": "And finally, the most important\nthing is data coverage. It's need a very\nheavy data engineering",
    "start": "3600520",
    "end": "3607660"
  },
  {
    "text": "and the video recaption. ",
    "start": "3607660",
    "end": "3616170"
  },
  {
    "text": "So I have introduced many\ntopics of current multimodality",
    "start": "3616170",
    "end": "3623760"
  },
  {
    "text": "[INAUDIBLE] and some problems\nin this transformer community.",
    "start": "3623760",
    "end": "3629790"
  },
  {
    "text": "So there are some trends I think\nwill happen in one or few years",
    "start": "3629790",
    "end": "3638340"
  },
  {
    "text": "in the multimodality area. In the next one or two\nyears, we can easily",
    "start": "3638340",
    "end": "3648000"
  },
  {
    "text": "recognize grounding all\nthe common-sense attributes",
    "start": "3648000",
    "end": "3653460"
  },
  {
    "text": "and human expressions and lots\nof high-level vision scenes.",
    "start": "3653460",
    "end": "3661530"
  },
  {
    "text": "And all these things\nwill be very cheap and be basically solved.",
    "start": "3661530",
    "end": "3666900"
  },
  {
    "text": "So this will happen\nin one or two years.",
    "start": "3666900",
    "end": "3672940"
  },
  {
    "text": "At that time, the long\ntail problem of autodriving",
    "start": "3672940",
    "end": "3679240"
  },
  {
    "text": "could be alleviated. Not solved, but\nlargely alleviate.",
    "start": "3679240",
    "end": "3684430"
  },
  {
    "text": "And the second prediction\nis the video understanding",
    "start": "3684430",
    "end": "3691880"
  },
  {
    "text": "will become very important\nin the next one or two years,",
    "start": "3691880",
    "end": "3697640"
  },
  {
    "text": "because it's very useful. We have lots of videos in the\ninternet and in our everyday",
    "start": "3697640",
    "end": "3707270"
  },
  {
    "text": "life, but it's very hard and\ncurrently we cannot understand",
    "start": "3707270",
    "end": "3713660"
  },
  {
    "text": "very well. And the most powerful video\nunderstanding model currently is Gemini 1.5,\nbut it's basically",
    "start": "3713660",
    "end": "3725060"
  },
  {
    "text": "lots of hallucinations and wrong\ncounting and lots of weakness.",
    "start": "3725060",
    "end": "3731670"
  },
  {
    "text": "So there's a very\nlarge room to improve. ",
    "start": "3731670",
    "end": "3739410"
  },
  {
    "text": "Another thing is we have enough\ncompute to deal with video now,",
    "start": "3739410",
    "end": "3746220"
  },
  {
    "text": "and especially in the\nnext one or two years because the next generation of\nNVIDIA GPU and the requirements",
    "start": "3746220",
    "end": "3760110"
  },
  {
    "text": "from the larger language model. And another important\nthing is embodied AI.",
    "start": "3760110",
    "end": "3766900"
  },
  {
    "text": "Embodied AI will be more and\nmore important in the research, and it will be very closely\nrelated to multimodality",
    "start": "3766900",
    "end": "3778330"
  },
  {
    "text": "research, although it cannot\nimpact our real life in a few",
    "start": "3778330",
    "end": "3785680"
  },
  {
    "text": "years. Because we now have planning\nability with large language",
    "start": "3785680",
    "end": "3791770"
  },
  {
    "text": "models, we can recognize all\nthe same vision language models, and there will be\nsome chances to get",
    "start": "3791770",
    "end": "3800590"
  },
  {
    "text": "some new ability and a\nvery astonishing demo",
    "start": "3800590",
    "end": "3808030"
  },
  {
    "text": "of this embodied AI. But they may be very expensive\nand cannot be used for everyday",
    "start": "3808030",
    "end": "3819700"
  },
  {
    "text": "life. So what should we\ndo at that time?",
    "start": "3819700",
    "end": "3825570"
  },
  {
    "text": " For me, some researcher like\nme in a large language model",
    "start": "3825570",
    "end": "3833630"
  },
  {
    "text": "company, we got enough\ncomputer resources.",
    "start": "3833630",
    "end": "3839210"
  },
  {
    "text": "But for others, so I think if\nyou are a senior researcher,",
    "start": "3839210",
    "end": "3846109"
  },
  {
    "text": "so just follow your\nheart and ignore me. If you want to quickly gain\nsome citations, papers, impacts,",
    "start": "3846110",
    "end": "3857840"
  },
  {
    "text": "I think maybe you can consider\nthat the video understanding models, data sets,\nbenchmarks, especially data",
    "start": "3857840",
    "end": "3866050"
  },
  {
    "text": "sets and benchmarks,\nis very important and in great need of the\nvideo understanding community.",
    "start": "3866050",
    "end": "3873680"
  },
  {
    "text": "And for multimodality,\nthere is another topic I haven't talked\nabout in this lecture.",
    "start": "3873680",
    "end": "3883610"
  },
  {
    "text": "It's the speech or audio. I recently learned some\nknowledge about audio,",
    "start": "3883610",
    "end": "3892970"
  },
  {
    "text": "and I lead the group of\nspeech AI group in Zhipu AI.",
    "start": "3892970",
    "end": "3899180"
  },
  {
    "text": "So I'm not a\nresearcher about audio, but I can say that the\nspeech AI is underestimated.",
    "start": "3899180",
    "end": "3909200"
  },
  {
    "text": "It's actually very important for\nthe user need and application,",
    "start": "3909200",
    "end": "3915930"
  },
  {
    "text": "but there is no enough\nGPU and researchers",
    "start": "3915930",
    "end": "3921079"
  },
  {
    "text": "put into this areas\nlike in language model.",
    "start": "3921080",
    "end": "3926140"
  },
  {
    "text": "Finally, if you want\nto do some very useful and impact AI research,\nwhich is very risky,",
    "start": "3926140",
    "end": "3934580"
  },
  {
    "text": "advice is you need to make some\nsystem PhD student at once,",
    "start": "3934580",
    "end": "3939790"
  },
  {
    "text": "because the best algorithm\nmust utilize the current GPU",
    "start": "3939790",
    "end": "3951820"
  },
  {
    "text": "and other hardware. So you just need to know\nsome system PhD students.",
    "start": "3951820",
    "end": "3959305"
  },
  {
    "start": "3959305",
    "end": "3964339"
  },
  {
    "text": "Another that's more\ndifficult but influential",
    "start": "3964340",
    "end": "3970750"
  },
  {
    "text": "is there's actually some\nroom for new architectures for some self-supervised\nlearning and optimizers,",
    "start": "3970750",
    "end": "3979390"
  },
  {
    "text": "because the next\ngeneration of hardware will be totally different.",
    "start": "3979390",
    "end": "3985579"
  },
  {
    "text": "So maybe the transformer will\nhave some competitors and also",
    "start": "3985580",
    "end": "3994690"
  },
  {
    "text": "the autoregressive\nmodeling method. So there is some\nroom, but it's very hard on some\ncomputational resources.",
    "start": "3994690",
    "end": "4002940"
  },
  {
    "text": "And finally, the new\nways to transform compute to high-quality data\nis very important",
    "start": "4002940",
    "end": "4008880"
  },
  {
    "text": "because high-quality\nweb data is actually",
    "start": "4008880",
    "end": "4015359"
  },
  {
    "text": "be crawled down into almost\nevery large language model",
    "start": "4015360",
    "end": "4022890"
  },
  {
    "text": "company, and it's\ncurrently not very enough. So we need to find some new\nways to transform computes",
    "start": "4022890",
    "end": "4030510"
  },
  {
    "text": "to high-quality data. For example, how to see sizings\nin new data using code execution",
    "start": "4030510",
    "end": "4038610"
  },
  {
    "text": "results, using maybe\nMCTS or reinforcement",
    "start": "4038610",
    "end": "4044340"
  },
  {
    "text": "learning or some other method. It's very big area in\nthe last few years.",
    "start": "4044340",
    "end": "4053680"
  },
  {
    "text": "I think I will end this\nlecture here, and thank you",
    "start": "4053680",
    "end": "4059500"
  },
  {
    "text": "for the instructors\nand the audience, and thank you very much.",
    "start": "4059500",
    "end": "4065150"
  },
  {
    "text": "If you have some question,\nyou can send email to this,",
    "start": "4065150",
    "end": "4070420"
  },
  {
    "text": "and I will answer\nall the questions. Thank you very much. ",
    "start": "4070420",
    "end": "4079880"
  },
  {
    "text": "All right. Thank you very much, Ming,\nfor the amazing talk and all the useful advice. So we have some questions.",
    "start": "4079880",
    "end": "4086830"
  },
  {
    "text": "I got one through Zoom, and\nthere's several also on Slido. So Emily, are there\nany in-person questions",
    "start": "4086830",
    "end": "4094810"
  },
  {
    "text": "from your end?  OK, if someone has some--",
    "start": "4094810",
    "end": "4101430"
  },
  {
    "text": "[INTERPOSING VOICES] --and you can type in the chat\nin Zoom, if you are using Zoom.",
    "start": "4101430",
    "end": "4111899"
  },
  {
    "text": "Let me see.  OK, yeah. Here are some questions\non Slido that I'll ask.",
    "start": "4111899",
    "end": "4120549"
  },
  {
    "text": "The first is that the success\nof long context windows must come at a cost.",
    "start": "4120550",
    "end": "4125710"
  },
  {
    "text": "What is this cost? The cost very long\ntime consumption.",
    "start": "4125710",
    "end": "4136099"
  },
  {
    "text": "You just need to run\nyour inference engine",
    "start": "4136100",
    "end": "4142149"
  },
  {
    "text": "for a very long time. Actually, the current inference\nsystem of large language model",
    "start": "4142149",
    "end": "4149199"
  },
  {
    "text": "can be split into two periods. One is profiling.",
    "start": "4149200",
    "end": "4155269"
  },
  {
    "text": "You need to import a very\nlong context into your engine.",
    "start": "4155270",
    "end": "4161080"
  },
  {
    "text": "And then another is decode. And you generate\nthe token by token.",
    "start": "4161080",
    "end": "4168759"
  },
  {
    "text": "So most user case,\nit actually not generate a very long context,\nand understand a long context",
    "start": "4168760",
    "end": "4177640"
  },
  {
    "text": "and generate a very few\ntokens about the question.",
    "start": "4177640",
    "end": "4183100"
  },
  {
    "text": "So we can bear maybe one minute\nto let the language model",
    "start": "4183100",
    "end": "4196870"
  },
  {
    "text": "to just run the long\ncontext understanding and then began to\nanswer your question.",
    "start": "4196870",
    "end": "4205340"
  },
  {
    "text": "So this is a course you\nneed to read for maybe",
    "start": "4205340",
    "end": "4210940"
  },
  {
    "text": "several seconds or one minute. Yes. ",
    "start": "4210940",
    "end": "4217810"
  },
  {
    "text": "Thank you. I was muted, but yes. Thanks. That makes sense. So there's two questions\nwhich are pretty similar,",
    "start": "4217810",
    "end": "4223960"
  },
  {
    "text": "all upvoted on Slido, talking\nabout the quality of data. So recently, folks have been\nseeing that the quality of data",
    "start": "4223960",
    "end": "4231390"
  },
  {
    "text": "is what really determines final\nmodel performance compared to anything else. Do you agree?",
    "start": "4231390",
    "end": "4237490"
  },
  {
    "text": "And related to\nthis, do you think there's still a lot of\nwork to do around improving the architecture of\nmodels, or has attention",
    "start": "4237490",
    "end": "4245070"
  },
  {
    "text": "shifted to focus on data? Yeah. I think it's very\nreasonable, actually,",
    "start": "4245070",
    "end": "4252850"
  },
  {
    "text": "what's the whole community\nis doing to improve the data.",
    "start": "4252850",
    "end": "4257955"
  },
  {
    "text": " I just talk about this\nopinion in the lecture.",
    "start": "4257955",
    "end": "4265300"
  },
  {
    "text": "It's the architecture,\nthe algorithm, the data can conform\nto each other.",
    "start": "4265300",
    "end": "4272510"
  },
  {
    "text": "If you have some idea, you\ncan inject the inductive bias into architecture, you can\ndesign a new algorithm,",
    "start": "4272510",
    "end": "4280010"
  },
  {
    "text": "and you can prepare some\ndata to tell your model",
    "start": "4280010",
    "end": "4286269"
  },
  {
    "text": "to act like that. So many of the\nvery special cases",
    "start": "4286270",
    "end": "4295750"
  },
  {
    "text": "you can use data to\nsolve the problem. So high-quality data\nis more important",
    "start": "4295750",
    "end": "4301940"
  },
  {
    "text": "the architecture of this\nfor many tasks with that",
    "start": "4301940",
    "end": "4307890"
  },
  {
    "text": "and I think if you can find a\ngeneral update of transformer,",
    "start": "4307890",
    "end": "4316160"
  },
  {
    "text": "it's very valuable. Just increase the power of\nthe model to fit in the data.",
    "start": "4316160",
    "end": "4324469"
  },
  {
    "text": "It's very valuable. Yes. All right. Great.",
    "start": "4324470",
    "end": "4330230"
  },
  {
    "text": "Here's a question-- why is\nautoregressive architecture inferior to diffusion\nin image generation?",
    "start": "4330230",
    "end": "4336316"
  },
  {
    "text": " Yeah.",
    "start": "4336316",
    "end": "4343130"
  },
  {
    "text": "It's very complicated. This, question is very\ncomplicated, actually. So the diffusion is totally\ndifferent in autoregressive",
    "start": "4343130",
    "end": "4354980"
  },
  {
    "text": "to some extent. But the most important thing I\nhave talked about in the lecture",
    "start": "4354980",
    "end": "4362389"
  },
  {
    "text": "is the speed of generation. For autoregressive model, if\nyou use a very large model,",
    "start": "4362390",
    "end": "4370040"
  },
  {
    "text": "you train it for\na very long time, I believe we can get\na very good result.",
    "start": "4370040",
    "end": "4377010"
  },
  {
    "text": "We can also generate\nhigh-quality images using autoregressive methods.",
    "start": "4377010",
    "end": "4383430"
  },
  {
    "text": "This is OK. But the time to\ngenerate an image",
    "start": "4383430",
    "end": "4390500"
  },
  {
    "text": "is very long because we need\nto predict token by token. Maybe a high-resolution image\nis maybe thousands of tokens.",
    "start": "4390500",
    "end": "4403260"
  },
  {
    "text": "But for diffusion, we use\nseveral steps of fast forwarding",
    "start": "4403260",
    "end": "4410679"
  },
  {
    "text": "all the image. We don't need token\nby token prediction, as it would be thousands times\nfaster than autoregressive model",
    "start": "4410680",
    "end": "4421450"
  },
  {
    "text": "if you are generating\nhigh-resolution images. So this is a very\nobvious advantage.",
    "start": "4421450",
    "end": "4429679"
  },
  {
    "text": "And for the modeling power, I\nthink the most important thing is maybe some relation between\nthe space is actually not--",
    "start": "4429680",
    "end": "4447260"
  },
  {
    "text": "we are not modeling well\nby autoregressive model because the leftmost pixel\nand the right bottom pixel",
    "start": "4447260",
    "end": "4460120"
  },
  {
    "text": "is very far in\nautoregressive model. But in diffusion\nmodel, it's actually",
    "start": "4460120",
    "end": "4469510"
  },
  {
    "text": "they can see each other,\nso it's not a problem. But for the vision model,\nit's have position problem,",
    "start": "4469510",
    "end": "4476179"
  },
  {
    "text": "so it's not easy to model in\na very complicated 2D spatial",
    "start": "4476180",
    "end": "4486660"
  },
  {
    "text": "problem. This is also a possible reason,\nbut I cannot give a very good",
    "start": "4486660",
    "end": "4497960"
  },
  {
    "text": "answer about this question. But yeah. This would be more\nresearch about that.",
    "start": "4497960",
    "end": "4504870"
  },
  {
    "text": "Thank you. Right. Great. Thanks for the detailed answer. So someone is asking,\nhow is the CogAgent model",
    "start": "4504870",
    "end": "4512550"
  },
  {
    "text": "different from the CogVLM model? Yeah.",
    "start": "4512550",
    "end": "4517880"
  },
  {
    "text": "The CogAgent is actually fine\ntuned from the CogView model. But the CogAgent\nmodel, they always",
    "start": "4517880",
    "end": "4525199"
  },
  {
    "text": "high resolution and web screen\ncases because our motivation",
    "start": "4525200",
    "end": "4533270"
  },
  {
    "text": "is that the high-resolution\ninput for a web page",
    "start": "4533270",
    "end": "4538550"
  },
  {
    "text": "is very important because\nthere's many words, many icons, something very\nsmall, and you need",
    "start": "4538550",
    "end": "4546290"
  },
  {
    "text": "to use a very high-resolution\nmodel to deal with it.",
    "start": "4546290",
    "end": "4551410"
  },
  {
    "text": "But if you just extend the\ninput resolution of CogVLM,",
    "start": "4551410",
    "end": "4560690"
  },
  {
    "text": "the consumption is very high, so\nwe use cross attention module,",
    "start": "4560690",
    "end": "4569030"
  },
  {
    "text": "adding to the CogVLM\nto get CogAgent. So this module is\nmuch lightweight,",
    "start": "4569030",
    "end": "4576300"
  },
  {
    "text": "so we can deal with the\nhigh resolution more easily. Yeah. ",
    "start": "4576300",
    "end": "4583560"
  },
  {
    "text": "Great. Here's a question about video. How do you think video\nunderstanding will",
    "start": "4583560",
    "end": "4589320"
  },
  {
    "text": "aid AI's ability to have a\nstronger physical understanding of the world?",
    "start": "4589320",
    "end": "4595190"
  },
  {
    "text": "OK. That's a very good question. I think yes.",
    "start": "4595190",
    "end": "4600500"
  },
  {
    "text": "My answer is yes. But actually, the actual problem\nis because if you don't have",
    "start": "4600500",
    "end": "4613880"
  },
  {
    "text": "some data source which\ncontains physical rules,",
    "start": "4613880",
    "end": "4622190"
  },
  {
    "text": "you cannot train a good\nvideo understanding model.",
    "start": "4622190",
    "end": "4628430"
  },
  {
    "text": "I think using the current real\nlanguage model pretraining method because we need the\ninput, the text, image,",
    "start": "4628430",
    "end": "4638550"
  },
  {
    "text": "or text-video pairs to train. And we actually did not use\nany self-supervised learning",
    "start": "4638550",
    "end": "4648140"
  },
  {
    "text": "in the image or video, so we\ncannot learn any knowledge from",
    "start": "4648140",
    "end": "4654230"
  },
  {
    "text": "pure video or image. ",
    "start": "4654230",
    "end": "4661920"
  },
  {
    "text": "We're actually dealing\nwith annotated data from the human side.",
    "start": "4661920",
    "end": "4667230"
  },
  {
    "text": "So if we want to\nunderstand better of the physical world\nusing annotated videos,",
    "start": "4667230",
    "end": "4676650"
  },
  {
    "text": "we need to find some new method\nfor self-supervised learning",
    "start": "4676650",
    "end": "4682770"
  },
  {
    "text": "or pretraining method. This is a very good question.",
    "start": "4682770",
    "end": "4688142"
  },
  {
    "text": "This is a very good question. Thank you. All right. OK. A couple more questions.",
    "start": "4688142",
    "end": "4694880"
  },
  {
    "text": "Someone is asking,\nare there VQA tasks that involve multiple turns of\nconversation in a tree structure",
    "start": "4694880",
    "end": "4703540"
  },
  {
    "text": "similar to a tree of thoughts\nor a beam search style? ",
    "start": "4703540",
    "end": "4710320"
  },
  {
    "text": "OK. Yeah. Maybe, but I still\nthink it's different.",
    "start": "4710320",
    "end": "4718590"
  },
  {
    "text": "And the tree of\nthoughts could be better because it's aware\nof other mass information.",
    "start": "4718590",
    "end": "4729780"
  },
  {
    "text": "For example, the wrong\npath, the other failed case,",
    "start": "4729780",
    "end": "4737239"
  },
  {
    "text": "something like that. So my experience is\nif you can include",
    "start": "4737240",
    "end": "4746720"
  },
  {
    "text": "all the contacts in your input,\nyou always get better results.",
    "start": "4746720",
    "end": "4754770"
  },
  {
    "text": "So yeah, maybe in\nother tree of thought",
    "start": "4754770",
    "end": "4761037"
  },
  {
    "text": "or some other different\nprocess, procedure,",
    "start": "4761037",
    "end": "4768380"
  },
  {
    "text": "and some other\ninformations, you just included them into the\ncontents, the language model",
    "start": "4768380",
    "end": "4774830"
  },
  {
    "text": "will learn how to deal\nwith them and understand it better than the beam search,\nwhich is actually a hard code",
    "start": "4774830",
    "end": "4781580"
  },
  {
    "text": "master to compare\nthe probabilities. It should be better\nif you do it right.",
    "start": "4781580",
    "end": "4790170"
  },
  {
    "text": "Yes. All right, thanks. That's all the time\nwe have for questions. So thanks again to Ming\nfor the great talk,",
    "start": "4790170",
    "end": "4796190"
  },
  {
    "text": "the detailed answers\nto all the questions. ",
    "start": "4796190",
    "end": "4803000"
  }
]
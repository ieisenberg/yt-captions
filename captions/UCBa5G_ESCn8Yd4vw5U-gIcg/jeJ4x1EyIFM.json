[
  {
    "start": "0",
    "end": "11760"
  },
  {
    "text": "Hello, everyone. I'm Somil, and I'm an assistant\nprofessor in the Aeronautics Department here where I lead the\nSafe and Intelligent Autonomy",
    "start": "11760",
    "end": "19770"
  },
  {
    "text": "Lab. I will just wait for\nthe slides to go down. ",
    "start": "19770",
    "end": "28260"
  },
  {
    "text": "All right. So let me start this\ntalk with, I would say,",
    "start": "28260",
    "end": "34240"
  },
  {
    "text": "like the long term\ngoal of our lab, which is to develop robot algorithms\nthat operate with guaranteed",
    "start": "34240",
    "end": "39840"
  },
  {
    "text": "safety and performance in new\nand uncertain environments. And we think about this question\nin the context of a variety",
    "start": "39840",
    "end": "45719"
  },
  {
    "text": "of different applications. Autonomous drones, autonomous\ncars, legged robots, aircrafts, and more\nrecently, space exploration.",
    "start": "45720",
    "end": "54899"
  },
  {
    "text": "And if you look\nat these systems, machine learning and AI\nare becoming increasingly pervasive in their autonomy\nstacks, most notably",
    "start": "54900",
    "end": "61800"
  },
  {
    "text": "for perception and\ntrajectory forecasting, but also for\nplanning and control. And for a number\nof good reasons,",
    "start": "61800",
    "end": "67800"
  },
  {
    "text": "machine learning is\nreally good at capturing the complexity of\nreal-world situations that the system must\noperate in, which",
    "start": "67800",
    "end": "74350"
  },
  {
    "text": "could be otherwise very hard to\ncapture using engineering domain knowledge.",
    "start": "74350",
    "end": "79680"
  },
  {
    "text": "But inclusion of\nmachine learning has also come up\nwith some new safety challenges for these systems.",
    "start": "79680",
    "end": "85150"
  },
  {
    "text": "So we are right in\nthe Bay Area where we hear news such as cruise\ncars are being rolled back",
    "start": "85150",
    "end": "90360"
  },
  {
    "text": "from San Francisco City or\nrobots are crashing into humans on the factory floors.",
    "start": "90360",
    "end": "96030"
  },
  {
    "text": "The issue is severe enough that\nthe US government, and since then many other governments,\nhave passed executive order",
    "start": "96030",
    "end": "102450"
  },
  {
    "text": "to prioritize discussion on\nAI safety, both for autonomy, but AI more broadly as well.",
    "start": "102450",
    "end": "109930"
  },
  {
    "text": "So there is this\ntension that we have a lot in autonomy today,\nwhich is how can we enable these systems to\nleverage the capabilities",
    "start": "109930",
    "end": "117909"
  },
  {
    "text": "and excitement offered by\nmodern machine learning methods while also maintaining safety? And in my talk today, I\nwant to think a little bit",
    "start": "117910",
    "end": "124960"
  },
  {
    "text": "about the source of this tension\nand what can we do about it.",
    "start": "124960",
    "end": "131500"
  },
  {
    "text": "So I think one of the main\nreasons for this tension is that if we look at machine\nlearning systems today,",
    "start": "131500",
    "end": "136700"
  },
  {
    "text": "most of them are designed\nwithout any specific regard to safety. And when safety issues\nemerge in the design system,",
    "start": "136700",
    "end": "144790"
  },
  {
    "text": "post-hoc solutions\nare often engineered to counter these risks. So I'm going to refer to\nthem as safety bandages",
    "start": "144790",
    "end": "151540"
  },
  {
    "text": "throughout my talk. So as an example, earlier\nthis year in February,",
    "start": "151540",
    "end": "157190"
  },
  {
    "text": "I think, Waymo cars had a bunch\nof troubles with, for example, tow trucks. So the approach was to shut\ndown the entire fleet of Waymo,",
    "start": "157190",
    "end": "164540"
  },
  {
    "text": "update their software, and\nthen restart the fleet. Now, while this\napproach, make the design",
    "start": "164540",
    "end": "169780"
  },
  {
    "text": "of learning-based\nsystems much simpler, it is flawed for a\nnumber key reasons.",
    "start": "169780",
    "end": "174880"
  },
  {
    "text": "Now, first and foremost, these\nhand-engineered solutions are simply not scalable with\nthe number of safety risks",
    "start": "174880",
    "end": "180730"
  },
  {
    "text": "and the situation the\nsystem must encounter. Moreover, this\npost-hoc solutions often tend to be\nconservative in nature,",
    "start": "180730",
    "end": "187519"
  },
  {
    "text": "which might degrade the\nperformance advantages that we get out of machine\nlearning methods.",
    "start": "187520",
    "end": "193070"
  },
  {
    "text": "And finally, the heuristics\ndesigned for some certain kind of deployment\nconditions might not",
    "start": "193070",
    "end": "198110"
  },
  {
    "text": "work as these systems encounter\nnew and new deployment conditions in the real world.",
    "start": "198110",
    "end": "203550"
  },
  {
    "text": "So to overcome these\nchallenges, in our research, we think of safety of\nlearning-based systems",
    "start": "203550",
    "end": "210270"
  },
  {
    "text": "as a continuous process,\nwhere safety is formally ingrained in different stages\nof the learning process,",
    "start": "210270",
    "end": "216310"
  },
  {
    "text": "starting from the design and\ntraining phase to the deployment to iteratively improving\nthe safety over the systems",
    "start": "216310",
    "end": "222300"
  },
  {
    "text": "lifecycle. So what that means is\nthat we develop algorithms",
    "start": "222300",
    "end": "228450"
  },
  {
    "text": "that programmatically\nincorporate safety requirements in\nthe training process itself in order to\nlearn inherently",
    "start": "228450",
    "end": "234330"
  },
  {
    "text": "safe and robust controllers and\npolicies for robotics systems. Now, that I would call design\ntime safety methods or design",
    "start": "234330",
    "end": "242490"
  },
  {
    "text": "for safety. Now that's definitely a step\nforward but that's not all.",
    "start": "242490",
    "end": "247510"
  },
  {
    "text": "Because as these systems will\noperate in new conditions, they will need to\nadapt their behavior.",
    "start": "247510",
    "end": "252870"
  },
  {
    "text": "So we are developing\nmethods that detect out-of-distribution\nand anomalous situations for these systems and\ncorrespondingly adapt",
    "start": "252870",
    "end": "259588"
  },
  {
    "text": "their behavior in order\nto maintain safety. And finally, we\nwant these systems",
    "start": "259589",
    "end": "264920"
  },
  {
    "text": "to learn from their past\nfailures, past mistakes. We don't want the system to\nmake the same mistakes again and again.",
    "start": "264920",
    "end": "270050"
  },
  {
    "text": "So to close this loop,\nwe are developing methods that allow robotic\nsystems to improve their safety",
    "start": "270050",
    "end": "276139"
  },
  {
    "text": "from their past failures. And so together, I think\nof this as a closed loop.",
    "start": "276140",
    "end": "281840"
  },
  {
    "text": "I call it continual safety\nassurance framework, where assurances are\nprovided provisionally during the design time.",
    "start": "281840",
    "end": "287430"
  },
  {
    "text": "They are monitored and adapted\nduring the operation time, and they're\ncontinuously improved over the systems lifecycle.",
    "start": "287430",
    "end": "295280"
  },
  {
    "text": "So in the remaining\ntime that I have, I want to dive a little bit\ndeeper into some of my work.",
    "start": "295280",
    "end": "301790"
  },
  {
    "text": "So we will start with\ntalking about how can we learn provably safe controllers\nfrom data, how can we",
    "start": "301790",
    "end": "308120"
  },
  {
    "text": "adapt these controllers online\nunder new deployment conditions, and finally, I will\ntalk about how can we",
    "start": "308120",
    "end": "313460"
  },
  {
    "text": "stress test a given policy\nor a given controller to minor safety\ncritical failures.",
    "start": "313460",
    "end": "320160"
  },
  {
    "text": "So let's talk about\nlearning safe controllers. But even before we\ntalk about that,",
    "start": "320160",
    "end": "326080"
  },
  {
    "text": "let's take a step back\nand ask ourselves, what do we even mean by safety? What do we want\nout of this safety",
    "start": "326080",
    "end": "331169"
  },
  {
    "text": "analysis in an ideal world? And I thought about\nit a lot and I",
    "start": "331170",
    "end": "336390"
  },
  {
    "text": "tried to summarize my\nthoughts in a single sentence. And so this is my\nattempt at that. I would say out of\nsafety analysis,",
    "start": "336390",
    "end": "343150"
  },
  {
    "text": "we want to determine whether\nand how a robot can prevent its trajectory from entering\ninto some undesirable set",
    "start": "343150",
    "end": "349979"
  },
  {
    "text": "of states, which I will also\nrefer to as failure set. And so what that means is\nthat we want two key things--",
    "start": "349980",
    "end": "356659"
  },
  {
    "text": "first, we want to quantify which\nconfigurations of the robot are doomed to fail versus\nwhich configurations",
    "start": "356660",
    "end": "363259"
  },
  {
    "text": "are safe to be in. And how can we keep the robot\nin these safe configurations?",
    "start": "363260",
    "end": "368430"
  },
  {
    "text": "So first is the problem of\nwhether the system is safe and the second is how can\nI keep the system safe.",
    "start": "368430",
    "end": "373650"
  },
  {
    "text": "So I like to call it,\nwhether and how of safety. And I will refer to as\nthat throughout my talk.",
    "start": "373650",
    "end": "380720"
  },
  {
    "text": "Now, the good news is that\ncontrol theory provides us a number of powerful\nframeworks for doing the safety",
    "start": "380720",
    "end": "387260"
  },
  {
    "text": "analysis of autonomous systems. And in our work, we use one\nsuch framework quite frequently,",
    "start": "387260",
    "end": "393450"
  },
  {
    "text": "which is called Hamilton-Jacobi\nreachability analysis. And the reason for that\nis that not only it helps us to mathematically\ncharacterize these two",
    "start": "393450",
    "end": "400669"
  },
  {
    "text": "requirements, but also\nprovide a mechanism to automatically compute them. So let me spend the\nnext few minutes talking",
    "start": "400670",
    "end": "407270"
  },
  {
    "text": "about what Hamilton-Jacobi\nreachability analysis is, and then I'm going to come back\nto the question of learning safe controllers from data\nusing reachability analysis.",
    "start": "407270",
    "end": "416950"
  },
  {
    "text": "So in reachability\nanalysis, we assume that the underlying\nrobotic system",
    "start": "416950",
    "end": "422440"
  },
  {
    "text": "has some dynamics, f,\nwith state, x, control, u, and disturbance, d.",
    "start": "422440",
    "end": "427449"
  },
  {
    "text": "So disturbance here represents\nuncertainty in the system, for example, modeling\nerror or unmodeled effects or an actual\nadversarial agent",
    "start": "427450",
    "end": "435010"
  },
  {
    "text": "that we may want to\nsafeguard against. Now, given these\ndynamics, the key thing that we are interested in is\nthe backward reachable tube",
    "start": "435010",
    "end": "442419"
  },
  {
    "text": "of the system, which\nis a set of all initial states from which the\nrobot will be ultimately driven",
    "start": "442420",
    "end": "448930"
  },
  {
    "text": "to an undesirable set of\nstates or a failure set despite the best control effort.",
    "start": "448930",
    "end": "454270"
  },
  {
    "text": "So essentially,\nbackward reachable tube represents the unsafe\nconfigurations for the robot and should be avoided.",
    "start": "454270",
    "end": "460169"
  },
  {
    "text": "Let's try to understand\nthat with the help of a very simple example. So imagine a quadrotor moving\nlongitudinally up and down",
    "start": "460170",
    "end": "466990"
  },
  {
    "text": "in this room. So here the ceiling\nand the floor might represent the failure set\nthat we don't want the quadrotor",
    "start": "466990",
    "end": "472900"
  },
  {
    "text": "to crash into. The light-red region over here\nis the backward reachable tube,",
    "start": "472900",
    "end": "478700"
  },
  {
    "text": "meaning that if the quadrotor\nstarts inside this set, then no matter what it does,\nit will eventually crash",
    "start": "478700",
    "end": "484790"
  },
  {
    "text": "into the ceiling or the floor. So there is nothing you can\ndo to avoid the collision. In other words, these\nstates are as doomed",
    "start": "484790",
    "end": "490610"
  },
  {
    "text": "as being in the\nceiling or the floor. The contrast of this\nlight-red region is the blue region or the\nsafe set for the system,",
    "start": "490610",
    "end": "498930"
  },
  {
    "text": "meaning that if the quadrotor\nstarts inside this set, then it has a\ncontroller or a policy to keep it inside\nthis set at all times.",
    "start": "498930",
    "end": "507310"
  },
  {
    "text": "So reachability analysis will\ngive us both this blue set as well as the safety controller.",
    "start": "507310",
    "end": "512969"
  },
  {
    "text": "So I'm going to\ndive a little bit into the math of\nreachability analysis and how it computes\nthese two entities.",
    "start": "512970",
    "end": "519039"
  },
  {
    "text": "And the first step to do so\nis to define our failure set implicitly with a\nfunction l of x,",
    "start": "519039",
    "end": "526340"
  },
  {
    "text": "which is negative\ninside the failure set and positive outside. So you can think of l of\nx as the safety reward,",
    "start": "526340",
    "end": "532329"
  },
  {
    "text": "the robot gets at state x. If you're inside the failure\nset, you get a negative reward, and if you're outside\nthe failure set,",
    "start": "532330",
    "end": "538303"
  },
  {
    "text": "you get a positive reward. And we can use any\nreward function that satisfies this property.",
    "start": "538303",
    "end": "543937"
  },
  {
    "text": "But the one that's quite\npopular in robotics is the signed distance\nfunction to the failure set, which is naturally\nnegative inside the set",
    "start": "543937",
    "end": "550150"
  },
  {
    "text": "and positive outside. Now, given this reward\nfunction, the cumulative reward",
    "start": "550150",
    "end": "556800"
  },
  {
    "text": "of the trajectory is given\nby the minimum safety reward along the trajectory. So this is slightly different\nthan our normal optimal control",
    "start": "556800",
    "end": "563580"
  },
  {
    "text": "and reinforcement\nlearning problems where it's sum of rewards. Instead of that, it's\nthe minimum of reward.",
    "start": "563580",
    "end": "568649"
  },
  {
    "text": "And what that means is that\nif the robot trajectory ever entered the failure set,\nthis cumulative reward",
    "start": "568650",
    "end": "574889"
  },
  {
    "text": "will be negative, otherwise\nit will be positive. So just looking at the\nsign of this reward, I can tell whether the system\ntrajectory was ever safe or not.",
    "start": "574890",
    "end": "584340"
  },
  {
    "text": "And then, of course, we have\ncontrol at our disposal. So what we want to do\nis we want to formulate",
    "start": "584340",
    "end": "591750"
  },
  {
    "text": "this game between the control\nand disturbance, where the disturbance\nattempts to force the system inside\nthe failure set.",
    "start": "591750",
    "end": "597949"
  },
  {
    "text": "In other words, it tries to\nminimize our safety reward, whereas the control tries to\nstay out of the failure set.",
    "start": "597950",
    "end": "603700"
  },
  {
    "text": "In other words, it tries\nto maximize the safety. And similar to any other\noptimal control or reinforcement",
    "start": "603700",
    "end": "609899"
  },
  {
    "text": "learning problem, we have\na value corresponding to this game, which is simply\nthe control maximizing it",
    "start": "609900",
    "end": "615180"
  },
  {
    "text": "and the disturbance minimizing\nthis overall cumulative reward. Now, intuitively,\nthis value function",
    "start": "615180",
    "end": "621680"
  },
  {
    "text": "is capturing the closest\nthe system will ever get to the failure set.",
    "start": "621680",
    "end": "627110"
  },
  {
    "text": "So if the value\nfunction is negative, that means the system\nmust have entered the failure set at some point.",
    "start": "627110",
    "end": "632250"
  },
  {
    "text": "And if the value\nfunction is positive, that means the system remained\noutside the failure set at all times.",
    "start": "632250",
    "end": "637400"
  },
  {
    "text": "So the backward reachable\ntube that I described earlier was the unsafe set is\nnothing but the set of states",
    "start": "637400",
    "end": "643279"
  },
  {
    "text": "where the value function\nis less than or equal to 0. So that's the idea of\nreachability analysis.",
    "start": "643280",
    "end": "650680"
  },
  {
    "text": "Now, this value\nfunction can be computed using the principle of\ndynamic programming, which",
    "start": "650680",
    "end": "655810"
  },
  {
    "text": "results into a Bellman\niteration or a Bellman backup. But in continuous\nstate and time,",
    "start": "655810",
    "end": "660980"
  },
  {
    "text": "this results into a partial\ndifferential equation. So this is just the\nBellman equation",
    "start": "660980",
    "end": "666280"
  },
  {
    "text": "written in continuous\nstate and time, honestly. But just like the\nBellman equation,",
    "start": "666280",
    "end": "671660"
  },
  {
    "text": "essentially, it relates how\ntaking a particular action affects the system value\nor, in other words,",
    "start": "671660",
    "end": "677660"
  },
  {
    "text": "how systems distance to the\nfailure set in this case. And once we solve this partial\ndifferential equation, which",
    "start": "677660",
    "end": "683050"
  },
  {
    "text": "is called, by the way,\nHamilton-Jacobi-Isaacs partial differential equation,\nwe get the value function.",
    "start": "683050",
    "end": "688220"
  },
  {
    "text": "So here I'm showing that value\nfunction for the quadrotor example that I was\nshowing earlier.",
    "start": "688220",
    "end": "694045"
  },
  {
    "text": "The more red means the value\nfunction is more negative and the more blue means the\nvalue function is more positive.",
    "start": "694045",
    "end": "699579"
  },
  {
    "text": "So these states, which are\ncloser to the ceiling and floor, not surprisingly,\nare particularly bad, whereas the\nstates which are",
    "start": "699580",
    "end": "706083"
  },
  {
    "text": "towards the middle of the room\nare very safe, as you would expect, because we are\nequidistant from the ceiling",
    "start": "706083",
    "end": "712208"
  },
  {
    "text": "or the floor.  Now, quick question.",
    "start": "712208",
    "end": "717850"
  },
  {
    "text": "The value function is more\nnegative towards the lower end than over towards\nthe positive end.",
    "start": "717850",
    "end": "724329"
  },
  {
    "text": "Even though the failure set\nis both ceiling and floor. Could you guess why? ",
    "start": "724330",
    "end": "734130"
  },
  {
    "text": "Gravity. Because of gravity. Because gravity is pushing\nus more in one direction.",
    "start": "734130",
    "end": "739509"
  },
  {
    "text": "So when we are\ncloser to the floor, we are more unsafe than when we\nare closer to the ceiling, which",
    "start": "739510",
    "end": "745560"
  },
  {
    "text": "is what this value function is\ncapturing inside this color bar. But the beauty of the\nreachability analysis",
    "start": "745560",
    "end": "751140"
  },
  {
    "text": "is that we-- this is an intuitive\nexample, but that's not where it's meant to be. It automatically\ncaptures the effect",
    "start": "751140",
    "end": "757410"
  },
  {
    "text": "of the dynamics of the\nsystem on the overall safety of the system. Now, along with\nthis value function,",
    "start": "757410",
    "end": "764520"
  },
  {
    "text": "it also provides us\na safety controller-- ",
    "start": "764520",
    "end": "770110"
  },
  {
    "text": "Sorry. Safety controller, which again,\nintuitively what it is doing is that at any state\nx, it's pushing",
    "start": "770110",
    "end": "776950"
  },
  {
    "text": "the system towards\nhigher and higher values. Remember, positive\nvalues means more safe. So it's essentially\naligning, pushing us",
    "start": "776950",
    "end": "784300"
  },
  {
    "text": "in the gradient ascent\ndirection of the value function. That's what it's doing.",
    "start": "784300",
    "end": "790652"
  },
  {
    "text": "So taking a step\nback, if you recall, I said there are two key things\nwe want out of safety analysis--",
    "start": "790652",
    "end": "797425"
  },
  {
    "text": "a set of safe states\nand a controller to keep me inside\nthe safe states. I was talking about\nHamilton-Jacobi reachability",
    "start": "797425",
    "end": "804000"
  },
  {
    "text": "analysis, which captures these\nrequirements with the help of the safety value function V,\nwhose sign tells me whether I'm",
    "start": "804000",
    "end": "810660"
  },
  {
    "text": "safe or unsafe, whose\ngradient tells me a safe controller\nfor the system.",
    "start": "810660",
    "end": "816389"
  },
  {
    "text": "And once again, the nice\nthing about this theory is that it can be applied to\ngeneral nonlinear autonomous",
    "start": "816390",
    "end": "821820"
  },
  {
    "text": "systems. But there are also\na few challenges.",
    "start": "821820",
    "end": "827190"
  },
  {
    "text": "The biggest one is scalability. So even the theory\nis quite general. Computationally\nspeaking, it is very hard",
    "start": "827190",
    "end": "832838"
  },
  {
    "text": "to scale these methods beyond\neven five dimensional systems, which really limits their use\ncase in the modern robotics",
    "start": "832838",
    "end": "839880"
  },
  {
    "text": "systems. And the second, which\nis equally bothersome, is that it's not\nimmediately clear",
    "start": "839880",
    "end": "846360"
  },
  {
    "text": "how to interface these methods\nwith real world data and machine learning models.",
    "start": "846360",
    "end": "851790"
  },
  {
    "text": "So to begin making progress\non these challenges, we will lead into neural\napproximations of the safety",
    "start": "851790",
    "end": "858209"
  },
  {
    "text": "value function. Now, of course, we are talking\nabout safety critical system. So we have to be a\nlittle bit careful",
    "start": "858210",
    "end": "864120"
  },
  {
    "text": "when we are using\nneural network and I share that concern as well,\nand we will talk about it. But for now, I want to put\nguarantees on hold for a minute",
    "start": "864120",
    "end": "871079"
  },
  {
    "text": "and talk about how can we\neven structure the learning problem in order to learn good\nrepresentations of safety value",
    "start": "871080",
    "end": "877950"
  },
  {
    "text": "functions. And then I will come back\nand talk about assurances under these representations.",
    "start": "877950",
    "end": "883920"
  },
  {
    "text": "So more specifically, we will\nlearn a neural approximation of the safety value function,\nwhich takes as input the state",
    "start": "883920",
    "end": "891310"
  },
  {
    "text": "and time of the system and\noutput the corresponding safety value function. Now, once trained,\nthis value function",
    "start": "891310",
    "end": "897550"
  },
  {
    "text": "can be used to synthesize the\nunsafe set as well as the safety controller using the same\nmechanism that I just described.",
    "start": "897550",
    "end": "905529"
  },
  {
    "text": "OK, how do we obtain\nthis value function? So we call this\nmethod DeepReach.",
    "start": "905530",
    "end": "911050"
  },
  {
    "text": "And DeepReach is a\nself-supervised learning method, which relies on the fact\nthat the true safety value",
    "start": "911050",
    "end": "917380"
  },
  {
    "text": "function must satisfy\nthis partial differential equation that I showed earlier. So the partial\ndifferential equation error",
    "start": "917380",
    "end": "923830"
  },
  {
    "text": "can be used as a signal to\ntrain the safety value function.",
    "start": "923830",
    "end": "929110"
  },
  {
    "text": "In particular, in each\ntraining iteration, we can randomly sample\nsome state and time.",
    "start": "929110",
    "end": "934180"
  },
  {
    "text": "We propagate it through\nthe neural network to compute the value function,\nand correspondingly, we can compute the\nviolation error, and we",
    "start": "934180",
    "end": "941200"
  },
  {
    "text": "can backprop from that to\noptimize the neural network parameters. So essentially, over\ntime, neural network",
    "start": "941200",
    "end": "948160"
  },
  {
    "text": "is incentivized to learn\nmore and more accurate representation of the\nsafety value function that is consistent with this\npartial differential equation",
    "start": "948160",
    "end": "954940"
  },
  {
    "text": "that I said earlier. So it's very much inspired\nby physics-informed machine learning these days.",
    "start": "954940",
    "end": "960345"
  },
  {
    "text": " There are two key\nadvantages of doing that.",
    "start": "960345",
    "end": "965790"
  },
  {
    "text": "Number one is that by\ndoing so, we can explicitly bake in safety requirements\nin the training process itself",
    "start": "965790",
    "end": "972560"
  },
  {
    "text": "and learn inherently safe\ncontrollers from data. And second, the\nneural representations",
    "start": "972560",
    "end": "978170"
  },
  {
    "text": "are much easily scalable to\nhigher dimensional systems, so we can synthesize safe\ncontrollers for a broader",
    "start": "978170",
    "end": "983750"
  },
  {
    "text": "class of autonomous systems. So let me show a few\nexamples of that.",
    "start": "983750",
    "end": "989240"
  },
  {
    "text": "So the first example here is\nthe three-aircraft conflict",
    "start": "989240",
    "end": "994339"
  },
  {
    "text": "resolution problem. There are two evader vehicles,\nand there is a pursuit vehicle, which, in this case, is an\nuncertain or adversarial",
    "start": "994340",
    "end": "1002050"
  },
  {
    "text": "aircraft whose\nbehavior we don't know. So we're going to treat that\nas a disturbance in the system that we want to\nsafeguard against.",
    "start": "1002050",
    "end": "1009940"
  },
  {
    "text": "Now, the failure set here is\ngiven by any configurations of these three\naircrafts, which are where any two aircraft are in\nclose proximity of each other.",
    "start": "1009940",
    "end": "1017940"
  },
  {
    "text": "In other words, something\ncause loss of separation. Now, given the high\ndimensionality of this problem,",
    "start": "1017940",
    "end": "1024569"
  },
  {
    "text": "a direct BRT computation\nor unsafe set computation is not scalable in this case.",
    "start": "1024569",
    "end": "1029650"
  },
  {
    "text": "So what is often done in\nmulti-agent literature is that people compute\npairwise collision",
    "start": "1029650",
    "end": "1034730"
  },
  {
    "text": "set between these aircrafts\nand take their union as an approximation\nof the unsafe set.",
    "start": "1034730",
    "end": "1040699"
  },
  {
    "text": "So I'm going to show you a slice\nof that nine-dimensional set in 2D in green over here.",
    "start": "1040700",
    "end": "1047750"
  },
  {
    "text": "And what that means\nis that if I start at any configuration inside\nthis set, then at least two",
    "start": "1047750",
    "end": "1054313"
  },
  {
    "text": "of the three aircraft will\ncome into close proximity of each other. In other words,\nthey will collide.",
    "start": "1054313",
    "end": "1060009"
  },
  {
    "text": "But the DeepReach,\nwe can directly compute the high dimensional\nBRT and a slice of that",
    "start": "1060010",
    "end": "1065200"
  },
  {
    "text": "is shown in the pink over here. So of course, it captures\nthe green region,",
    "start": "1065200",
    "end": "1070490"
  },
  {
    "text": "but it has some more\nadditional configurations that we could not\ncapture earlier because of the\ncomputational limitations.",
    "start": "1070490",
    "end": "1077580"
  },
  {
    "text": "So let me show you\none such configuration and see what's going on here. So let's pick this\nconfiguration.",
    "start": "1077580",
    "end": "1084010"
  },
  {
    "text": "So from starting from\nthis configuration, I'm plotting the trajectories\nof the three aircrafts. And here you see that\nthe orange vehicle is",
    "start": "1084010",
    "end": "1090360"
  },
  {
    "text": "going after the blue vehicle. And the blue vehicle is able\nto avoid the orange vehicle, but in the process of doing so,\nit cannot avoid a collision with",
    "start": "1090360",
    "end": "1097590"
  },
  {
    "text": "the black aircraft above. So there are these\nthree-way interactions that are happening between the\naircrafts, which we could not",
    "start": "1097590",
    "end": "1104010"
  },
  {
    "text": "capture earlier because of\nthe computational limitations. But now. We can not only\ncapture them, but we",
    "start": "1104010",
    "end": "1109830"
  },
  {
    "text": "can safeguard against them\nusing the DeepReach based safety controllers. ",
    "start": "1109830",
    "end": "1117950"
  },
  {
    "text": "We have also applied\nthis framework in the context of\nautonomous driving. So this was inspired by my work\nat Waymo, which at the time",
    "start": "1117950",
    "end": "1126980"
  },
  {
    "text": "was dealing with urban driving. So San Francisco rolled\nout hasn't happened yet. And one of the big\nproblems was that there",
    "start": "1126980",
    "end": "1133635"
  },
  {
    "text": "were a lot of stranded vehicles\nyou encounter in urban driving. So this could be, for example,\nan Uber or a trash truck waiting in your lane,\nblocking your lane.",
    "start": "1133635",
    "end": "1141000"
  },
  {
    "text": "And in this case,\nthe autonomous car needs to go to the\nother lane, cross over, and then come back to its\nown lane, but in a way",
    "start": "1141000",
    "end": "1148070"
  },
  {
    "text": "so as to not collide with\nthe oncoming traffic.",
    "start": "1148070",
    "end": "1153179"
  },
  {
    "text": "So we started with a\nlearning-based controller and it performs really\nwell, except that it was not",
    "start": "1153180",
    "end": "1159809"
  },
  {
    "text": "able to always capture\nthis nuanced intersection point between the two cars\nand leads into collision",
    "start": "1159810",
    "end": "1166710"
  },
  {
    "text": "like over here. But the DeepReach, we\ncan now additionally bake in the safety requirements\ndirectly in the learning",
    "start": "1166710",
    "end": "1173880"
  },
  {
    "text": "process. So let me show the behavior\nof that controller in the car icons over here.",
    "start": "1173880",
    "end": "1179850"
  },
  {
    "text": "So what it does is\nthat it actually pushed the white car a little\nbit towards the stranded vehicle",
    "start": "1179850",
    "end": "1185130"
  },
  {
    "text": "and make the orange\nvehicle swerve so that a clearance is formed\nbetween the two vehicles. And once they cross\neach other, they",
    "start": "1185130",
    "end": "1191370"
  },
  {
    "text": "go back to their\nrespective lanes.  But what is\nparticularly interesting",
    "start": "1191370",
    "end": "1197575"
  },
  {
    "text": "is that the behavior of\nthe safety controller automatically adjusts\nto the oncoming traffic. So, for example, if the orange\ndriver is very aggressive,",
    "start": "1197575",
    "end": "1206840"
  },
  {
    "text": "the safety controller\nmakes the white vehicle wait behind the\nstranded vehicle, let the orange vehicle pass, and\nthen go over and cross the lane.",
    "start": "1206840",
    "end": "1214780"
  },
  {
    "text": "And if you think about it,\nthis is how intuitively we will drive in these situations,\nexcept now these behaviors",
    "start": "1214780",
    "end": "1220120"
  },
  {
    "text": "emerge automatically out of\nthe learning based system because the safety requirements\nwere baked in into that.",
    "start": "1220120",
    "end": "1225525"
  },
  {
    "text": " And in our latest work,\nwe apply DeepReach",
    "start": "1225525",
    "end": "1231640"
  },
  {
    "text": "for learning safe controllers\nfor legged locomotion. Here, the safety problem is\na little bit more challenging",
    "start": "1231640",
    "end": "1237610"
  },
  {
    "text": "because it's a hybrid system. It has both continuous\ncontrols, but also discrete controls coming from\ndifferent walking patterns.",
    "start": "1237610",
    "end": "1244960"
  },
  {
    "text": "And here, safety controller\nreasons about different walking patterns in order to reach\nits goal without colliding",
    "start": "1244960",
    "end": "1252250"
  },
  {
    "text": "with obstacles. But what I find exciting is\nthat my student Shuang here",
    "start": "1252250",
    "end": "1257900"
  },
  {
    "text": "is deliberately trying to push\nthe robot into a collision, but the safety\ncontroller counteract",
    "start": "1257900",
    "end": "1263210"
  },
  {
    "text": "to this external\ndisturbance, and sometimes even changing its working\npattern completely in order to maintain safety.",
    "start": "1263210",
    "end": "1269470"
  },
  {
    "start": "1269470",
    "end": "1276789"
  },
  {
    "text": "So when I was starting\nto discuss DeepReach, I said, let's put guarantees\non hold for a minute.",
    "start": "1276790",
    "end": "1282640"
  },
  {
    "text": "So let's go back\nto that and let's talk about how can\nwe provide safety",
    "start": "1282640",
    "end": "1288760"
  },
  {
    "text": "under these learned\nrepresentations. So now as such, neural\nnetwork can make errors",
    "start": "1288760",
    "end": "1295510"
  },
  {
    "text": "and the safe set\nprovided by DeepReach is only a candidate safe set. Pictorially, there\ncould be actually",
    "start": "1295510",
    "end": "1301960"
  },
  {
    "text": "states inside this\ncandidate safe set which eventually might steer the\nsystem inside the failure set.",
    "start": "1301960",
    "end": "1308160"
  },
  {
    "text": " So to counter this\nproblem, we have",
    "start": "1308160",
    "end": "1314850"
  },
  {
    "text": "been looking into probabilistic\nsafety assurances for DeepReach. So I will talk about what\nthat means in a second.",
    "start": "1314850",
    "end": "1320580"
  },
  {
    "text": "But the key idea behind this\nwhole probabilistic assurance is that the learned safety value\nfunction induces a candidate",
    "start": "1320580",
    "end": "1330179"
  },
  {
    "text": "safe policy for the\nrobot as well, which if I apply on this\nsystem, should ideally",
    "start": "1330180",
    "end": "1336669"
  },
  {
    "text": "achieve the same value as\nthat what DeepReach was trying to learn, because\nthat's what it means to have the value of a\npolicy, that you should--",
    "start": "1336670",
    "end": "1343522"
  },
  {
    "text": "essentially, if you\nroll out that policy, you should achieve\nthe same value back. So the gap between the\ntwo-value functions",
    "start": "1343522",
    "end": "1349810"
  },
  {
    "text": "can actually be used to\ncalibrate the learning error. ",
    "start": "1349810",
    "end": "1356670"
  },
  {
    "text": "In other words, I'm\ninterested in finding a bound on the maximum\nlearning error, which is the one predicted and the\none I get by rolling out.",
    "start": "1356670",
    "end": "1364210"
  },
  {
    "text": "And if I can compute\nthis bound, then I can simply correct my value\nfunction by this bound. ",
    "start": "1364210",
    "end": "1371590"
  },
  {
    "text": "Pictorially speaking,\nif I look at any states in the super delta level\nset of my value function,",
    "start": "1371590",
    "end": "1376820"
  },
  {
    "text": "then that state would remain\nsafe under the induced policy by DeepReach.",
    "start": "1376820",
    "end": "1382010"
  },
  {
    "text": "So then the last thing that we\nneed to do to provide assurance is to compute this bound delta.",
    "start": "1382010",
    "end": "1388307"
  },
  {
    "text": "And we have looked into a\nnumber of different ways to compute this delta, including\nneural network verification",
    "start": "1388307",
    "end": "1393870"
  },
  {
    "text": "methods, scenario optimization. But the one that I am\nparticularly excited about and I'm going to talk about\ntoday is conformal prediction.",
    "start": "1393870",
    "end": "1401160"
  },
  {
    "text": "And for that, there are\ntwo reasons for that. Number one is that\nit's beautiful because",
    "start": "1401160",
    "end": "1409290"
  },
  {
    "text": "of its simplicity. And second, it can easily handle\ninputs of varying dimensions.",
    "start": "1409290",
    "end": "1416010"
  },
  {
    "text": "And that's what we are\nprimarily interested in, high dimensional control. Now, ultimately, what\nconformal prediction provides",
    "start": "1416010",
    "end": "1423270"
  },
  {
    "text": "is a probabilistic\nbound on delta. So it cannot compute\nthe bound delta exactly, but it can compute a high\nconfidence bound on delta,",
    "start": "1423270",
    "end": "1431310"
  },
  {
    "text": "which looks something like this. So we get some q hat from\nconformal prediction such",
    "start": "1431310",
    "end": "1438180"
  },
  {
    "text": "that the probability of\nfailure in this super q hat level of the value\nfunction is below epsilon.",
    "start": "1438180",
    "end": "1444130"
  },
  {
    "text": "So essentially, you are\ngetting a high confidence safe set after correcting\nthis value function using",
    "start": "1444130",
    "end": "1449730"
  },
  {
    "text": "conformal prediction. And I just want to\nillustrate that method",
    "start": "1449730",
    "end": "1457670"
  },
  {
    "text": "in the context of this\nmulti-vehicle collision avoidance problem that\nI was showing earlier. So yellow is the learned\nbackward reachable tube.",
    "start": "1457670",
    "end": "1465649"
  },
  {
    "text": "The blue is the correction\nby conformal prediction. In this case, it\nturns out to be 0.1,",
    "start": "1465650",
    "end": "1471840"
  },
  {
    "text": "which gives me the\ncertified safe set in green. And in this case,\nepsilon is 0.001,",
    "start": "1471840",
    "end": "1477450"
  },
  {
    "text": "which means that any state\ninside the green region is at least 99.9% safe.",
    "start": "1477450",
    "end": "1484544"
  },
  {
    "text": "So let me summarize this\nfirst part of my talk. We talked about neural\nsafety representations",
    "start": "1484545",
    "end": "1491310"
  },
  {
    "text": "that combine the rigor of\ntraditional safety analysis methods such as\nHamilton-Jacobi reachability analysis with the dynamic\nlearning capabilities of AI.",
    "start": "1491310",
    "end": "1499590"
  },
  {
    "text": "And it has two key advantages. The first one is\nthat this allows us to bake in safety constraints\nin the learning process.",
    "start": "1499590",
    "end": "1508050"
  },
  {
    "text": "And second, these\nmethods are much easily scalable to higher\ndimensional systems.",
    "start": "1508050",
    "end": "1513230"
  },
  {
    "text": " But so far, my definition of\nwhat is safe or what is unsafe",
    "start": "1513230",
    "end": "1521450"
  },
  {
    "text": "is not changing. And everything about the\nsystem is known a priori, whether it's dynamics, whether\nit's control bounds and whatnot.",
    "start": "1521450",
    "end": "1527990"
  },
  {
    "text": "But that's not true\nin the real world. In the real world, you will\nconstantly encounter changes in your safety constraints,\nin your dynamics,",
    "start": "1527990",
    "end": "1534630"
  },
  {
    "text": "in your control authority,\nor in your environment. And as the system learns more\ninformation about its world,",
    "start": "1534630",
    "end": "1541440"
  },
  {
    "text": "it needs to dynamically adapt\nthese safety controllers to maintain system safety.",
    "start": "1541440",
    "end": "1548150"
  },
  {
    "text": "So that's what I'm going to\ntalk about for the next 5, 10 minutes-- how can we adapt\nthese safety controllers online",
    "start": "1548150",
    "end": "1554930"
  },
  {
    "text": "very quickly?  So one of the exciting\naspects about neural safety",
    "start": "1554930",
    "end": "1561370"
  },
  {
    "text": "representations is\nthat you can easily input additional data to the\nneural network, for example,",
    "start": "1561370",
    "end": "1567020"
  },
  {
    "text": "uncertain system or\nenvironment parameters, and learn the safety value\nfunction as a function",
    "start": "1567020",
    "end": "1572170"
  },
  {
    "text": "of these parameters. So we call it parameter\ncondition safety value functions just because they are also\nnow additionally conditioned",
    "start": "1572170",
    "end": "1579450"
  },
  {
    "text": "on data. What's the advantage of that? Is that offline, if you learn\nthese parameter condition value function online, you can quickly\nactivate the safety value",
    "start": "1579450",
    "end": "1589025"
  },
  {
    "text": "function corresponding to\nthe deployment conditions you encounter in order\nto maintain safety.",
    "start": "1589025",
    "end": "1595020"
  },
  {
    "text": "So let me show you that on\na very simple drone delivery",
    "start": "1595020",
    "end": "1600180"
  },
  {
    "text": "problem. So here, the drone needs\nto go to its goal location while avoiding collisions\nwith the obstacles on its way.",
    "start": "1600180",
    "end": "1607950"
  },
  {
    "text": "But it needs to do so in\nuncertain wind conditions. So we don't know\nwhat wind intensity it's going to\nencounter when it's",
    "start": "1607950",
    "end": "1613615"
  },
  {
    "text": "going to go out for delivery. So we learn parameter\nconditions value function",
    "start": "1613615",
    "end": "1619020"
  },
  {
    "text": "as a function of the\nuncertain wind intensity. And here I'm showing you\nthe safe set corresponding",
    "start": "1619020",
    "end": "1624809"
  },
  {
    "text": "to the low wind intensity. So what that means is that\nif the quadrotor starts inside this blue set, then\nit can reach its goal safely",
    "start": "1624810",
    "end": "1632490"
  },
  {
    "text": "without colliding\nwith obstacles. So when the drone started,\nthe wind intensity was low.",
    "start": "1632490",
    "end": "1639460"
  },
  {
    "text": "So it goes on to take\na more direct route to its goal location, which is\nthrough these narrow gap, which",
    "start": "1639460",
    "end": "1645960"
  },
  {
    "text": "makes sense because it\nwould be more efficient. But on its route, the wind\nconditions change and now",
    "start": "1645960",
    "end": "1651600"
  },
  {
    "text": "the wind intensity is high,\nso the safe set changes. Now this middle route is no\nlonger safe for this system",
    "start": "1651600",
    "end": "1658740"
  },
  {
    "text": "under this high wind intensity. But using this parameter\ncondition representation, we can quickly adapt our safety\ncontroller, which, in this case,",
    "start": "1658740",
    "end": "1668340"
  },
  {
    "text": "goes on to take a longer\nbut safer route to its goal location. ",
    "start": "1668340",
    "end": "1676420"
  },
  {
    "text": "In fact, we don't have to stop\nat just parametric changes. We can now think about adapting\nsafety value function directly",
    "start": "1676420",
    "end": "1683290"
  },
  {
    "text": "from high-dimensional\nobservations such as RGB images or LiDAR scans.",
    "start": "1683290",
    "end": "1688299"
  },
  {
    "text": "For instance, here,\nthis robot dog is dynamically constructing its\nsafety value function directly",
    "start": "1688300",
    "end": "1695020"
  },
  {
    "text": "from these LiDAR\nscans and using it as a safety layer on top\nof an RL-based policy",
    "start": "1695020",
    "end": "1700809"
  },
  {
    "text": "to maintain safety in\nthis unknown environment. ",
    "start": "1700810",
    "end": "1708510"
  },
  {
    "text": "So not very innovatively, we\ncall it observation condition reachable set instead\nof parameter condition reachable set.",
    "start": "1708510",
    "end": "1714420"
  },
  {
    "text": "And there are two key\nadaptation components here. The first one is that the\nrobot using this LiDAR",
    "start": "1714420",
    "end": "1721500"
  },
  {
    "text": "scan to dynamically adapt its\nsafety value function, which allows it to adapt\nto unknown obstacles",
    "start": "1721500",
    "end": "1727740"
  },
  {
    "text": "that it's going to\nencounter in the real world. There is a second\nadaptation component,",
    "start": "1727740",
    "end": "1732990"
  },
  {
    "text": "which is allowing it\nto constantly estimate the uncertainty in\nits own dynamics.",
    "start": "1732990",
    "end": "1738360"
  },
  {
    "text": "For example, due to rugged\nterrains or slippery surfaces that you might encounter and\ncorrespondingly adapt the safety",
    "start": "1738360",
    "end": "1744050"
  },
  {
    "text": "value function using the\nidea of parameter condition reachable set. So it's combining\nboth of them together",
    "start": "1744050",
    "end": "1749930"
  },
  {
    "text": "to ultimately get\nthe safety value function, which is\nthen used as a safety filter for a nominal policy.",
    "start": "1749930",
    "end": "1758300"
  },
  {
    "text": "So let me highlight the\nuncertainty estimation component a little bit more.",
    "start": "1758300",
    "end": "1764470"
  },
  {
    "text": "So in this video, the robot\nencountered this slippery patch. And as the robot enters\nthe slippery patch,",
    "start": "1764470",
    "end": "1771660"
  },
  {
    "text": "the uncertainty estimation\nin its dynamics is high. Correspondingly, if you look\nat the safety value function,",
    "start": "1771660",
    "end": "1777120"
  },
  {
    "text": "it becomes more conservative. So more red meaning\nmore conservative. And it slows down\nthe robot in order",
    "start": "1777120",
    "end": "1782390"
  },
  {
    "text": "to avoid a collision with\nthe obstacle in front. So of course, there is\nalso adaptation going on",
    "start": "1782390",
    "end": "1788810"
  },
  {
    "text": "based on LiDAR, but I'm only\nhighlighting the uncertainty component part here.",
    "start": "1788810",
    "end": "1794250"
  },
  {
    "text": "So this is the\nkind of adaptation we can enable in real\ntime on robotic systems.",
    "start": "1794250",
    "end": "1800220"
  },
  {
    "text": "In fact, this\nframework is completely agnostic to what underlying\nnominal policy are you using. So here I'm using\nit as a safety layer",
    "start": "1800220",
    "end": "1807120"
  },
  {
    "text": "on top of several different\nRL-based policies such as RMA, Vogue these ways, as well as\nMPC-based policy in a variety",
    "start": "1807120",
    "end": "1814470"
  },
  {
    "text": "of different environment\nterrains, dynamic obstacles, and adversarial humans.",
    "start": "1814470",
    "end": "1820790"
  },
  {
    "text": "Again, the key\ncomponent here is to be able to adapt to dynamic\nobstacles or unknown obstacles",
    "start": "1820790",
    "end": "1826730"
  },
  {
    "text": "and the environment\nuncertainty, which is what the neural safety\nrepresentations can enable",
    "start": "1826730",
    "end": "1831950"
  },
  {
    "text": "us to do. ",
    "start": "1831950",
    "end": "1838720"
  },
  {
    "text": "So far, I've talked about\ndesigning neural safety representations and adapting\nthem online, corresponding",
    "start": "1838720",
    "end": "1845530"
  },
  {
    "text": "to the changes in the\nsystem and its environment. Now, for the\nremaining time, I want",
    "start": "1845530",
    "end": "1852220"
  },
  {
    "text": "to focus on the reverse\ndirection, which is suppose you give me\na learning-based policy.",
    "start": "1852220",
    "end": "1858300"
  },
  {
    "text": "So far, I was designing\nlearning-based policy, but now, suppose you\ngive me, it could be, for example, an RL-based\npolicy, how can we",
    "start": "1858300",
    "end": "1865840"
  },
  {
    "text": "stress-test this learning based\npolicy to figure out the data regimes where it might cause\nsafety, critical failures",
    "start": "1865840",
    "end": "1872889"
  },
  {
    "text": "of the system? And we have been particularly\ninterested in stress-testing",
    "start": "1872890",
    "end": "1878710"
  },
  {
    "text": "vision-based controllers\nfor two reasons-- A, because they are becoming\nincreasingly ubiquitous in our autonomy stacks, but also\nthey have been traditionally",
    "start": "1878710",
    "end": "1886840"
  },
  {
    "text": "been very challenging to\nhandle using traditional safety analysis methods because of\ntheir high-dimensionality and",
    "start": "1886840",
    "end": "1892419"
  },
  {
    "text": "complicated nature\nof visual inputs. So let me formalize the\nproblem a little bit.",
    "start": "1892420",
    "end": "1898880"
  },
  {
    "text": "So once again, we have a robotic\nsystem with some dynamics. And at each state, we\nhave a visual sensor",
    "start": "1898880",
    "end": "1905929"
  },
  {
    "text": "which is giving me visual\nobservations such as an RGB image or a point\ncloud, which is taken",
    "start": "1905930",
    "end": "1910940"
  },
  {
    "text": "as input by a vision-based\ncontroller that gives me the control to be\napplied on the robot.",
    "start": "1910940",
    "end": "1917430"
  },
  {
    "text": "I'm also given a\nsimulator, which I can use for stress-testing this system. My ultimate goal is to figure\nout the set of images or point",
    "start": "1917430",
    "end": "1926130"
  },
  {
    "text": "clouds, I, which\nlead to the failure of this overall\nclosed-loop system.",
    "start": "1926130",
    "end": "1931630"
  },
  {
    "text": "So I'm very\nspecifically interested in finding Is that leads to the\nfailure of the system, not just",
    "start": "1931630",
    "end": "1937030"
  },
  {
    "text": "the vision-based controller. ",
    "start": "1937030",
    "end": "1942690"
  },
  {
    "text": "And what we do is we cast\nthis failure discovery problem as a reachability\nproblem and use",
    "start": "1942690",
    "end": "1949260"
  },
  {
    "text": "the corresponding\nbackward reachable tube to extract these\nvisual failures. Let me explain how\nwe can do that.",
    "start": "1949260",
    "end": "1956740"
  },
  {
    "text": "Well, we can cascade the\nrobot sensor function along with its vision-based\ncontroller to obtain",
    "start": "1956740",
    "end": "1964420"
  },
  {
    "text": "an equivalent state-based\npolicy for the robot because x goes to I.\nI goes to control.",
    "start": "1964420",
    "end": "1972490"
  },
  {
    "text": "So if I combine the two,\nit goes from x to u. And so I can simplify for the\npurpose of stress-testing.",
    "start": "1972490",
    "end": "1978850"
  },
  {
    "text": "I can simplify my closed loop\nas the system in closed loop with this augmented policy.",
    "start": "1978850",
    "end": "1984720"
  },
  {
    "text": "And we know how to find\nfailures of such systems that have been-- that's\nwhat I've been focusing on the first half of my talk.",
    "start": "1984720",
    "end": "1990309"
  },
  {
    "text": "We can compute the backward\nreachable tube, which generally give me the set of all states\nwhich will lead to the failure",
    "start": "1990310",
    "end": "1996510"
  },
  {
    "text": "despite the best control action. But in this case, I'm not\ninterested in the best control",
    "start": "1996510",
    "end": "2001610"
  },
  {
    "text": "action. I'm interested in a specific\ncontroller that's given to me. So I can just simply\nreplace this max u",
    "start": "2001610",
    "end": "2007410"
  },
  {
    "text": "by that specific controller. But with this minor change, I\ncan use the same reachability",
    "start": "2007410",
    "end": "2012750"
  },
  {
    "text": "tools that I've been describing\nso far to compute this backward reachable tube. So you can think of this as a\npolicy condition reachability,",
    "start": "2012750",
    "end": "2019710"
  },
  {
    "text": "if you will. ",
    "start": "2019710",
    "end": "2024809"
  },
  {
    "text": "So once I get the\nbackwards reachable tube, then I can look\nat the images seen by the robot along these\nfailure states, which",
    "start": "2024810",
    "end": "2031650"
  },
  {
    "text": "will give me the visual\nfailures for this system.",
    "start": "2031650",
    "end": "2036720"
  },
  {
    "text": "So let me explain that in\nthe context of an example. So this work was\ndone in collaboration",
    "start": "2036720",
    "end": "2042840"
  },
  {
    "text": "with Boeing, which designed\na vision-based controller for the autonomous\naircraft taxiing.",
    "start": "2042840",
    "end": "2048429"
  },
  {
    "text": "So the goal here is to keep\nthis aircraft on the runway only using the monocular RGB\nimages from the camera",
    "start": "2048429",
    "end": "2055530"
  },
  {
    "text": "on the right wing\nof the aircraft because they were testing what\nhappens to the taxiing process",
    "start": "2055530",
    "end": "2062129"
  },
  {
    "text": "if there is no GPS. So they were trying to test\nthese vision based policies. But in the process\nof doing so, we don't want the aircraft\nto leave the runway.",
    "start": "2062130",
    "end": "2068943"
  },
  {
    "text": "So that's my failure\nset in this case, outside the runway boundary. Now, using this\nproposed framework,",
    "start": "2068943",
    "end": "2076260"
  },
  {
    "text": "we compute the backward\nreachable tube of the aircraft under the vision-based\ncontroller.",
    "start": "2076260",
    "end": "2081320"
  },
  {
    "text": "So in the red are the\nstarting configurations of the aircraft from which\nit will be ultimately driven",
    "start": "2081320",
    "end": "2087469"
  },
  {
    "text": "to off the runway under the\nvision-based controller, whereas the blue means the safe\nconfigurations of the aircraft.",
    "start": "2087469",
    "end": "2095429"
  },
  {
    "text": "And here are some of the\nrepresentative images that are going to cause the failure.",
    "start": "2095429",
    "end": "2101310"
  },
  {
    "text": "Excuse me. So let's take a\nlook at this image and see what's going on, why\nit's causing the failure.",
    "start": "2101310",
    "end": "2106680"
  },
  {
    "text": "So I'm just showing\nthat picture again. So this is the\nfirst-person view,",
    "start": "2106680",
    "end": "2111760"
  },
  {
    "text": "which is what aircraft\nsees to make the decision. And upon the analysis\nof this image,",
    "start": "2111760",
    "end": "2116890"
  },
  {
    "text": "we found that actually\nvision-based controller confuses this runway\nmarkings with the center line of the runway.",
    "start": "2116890",
    "end": "2123620"
  },
  {
    "text": "And it drives the aircraft\ntowards that marking. By the time it realizes, no,\nno, it's not the center line,",
    "start": "2123620",
    "end": "2129420"
  },
  {
    "text": "it's already too late\nand it cause the aircraft to leave the runway.",
    "start": "2129420",
    "end": "2134610"
  },
  {
    "text": "So using the proposed\nframework, we can find such semantic failures\nof the vision-based control.",
    "start": "2134610",
    "end": "2140799"
  },
  {
    "text": "And I want to highlight\nthat these are not just any semantic failures. These are precisely the failures\nof the vision component,",
    "start": "2140800",
    "end": "2148910"
  },
  {
    "text": "then that lead to\nsystem-level failure. So, for instance, here I'm\nshowing you the prediction error",
    "start": "2148910",
    "end": "2155300"
  },
  {
    "text": "of the vision-based controller. The red means high\nprediction error and the blue means low prediction error.",
    "start": "2155300",
    "end": "2161299"
  },
  {
    "text": "And you can see there is a\nwhole bunch of states where the prediction error is\nhigh, but that doesn't mean for safety anything.",
    "start": "2161300",
    "end": "2167250"
  },
  {
    "text": "The system is still\ngoing to remain safe. So there is a component level\nfailure, but not a system level failure.",
    "start": "2167250",
    "end": "2172580"
  },
  {
    "text": "Conversely, there are a\nwhole bunch of states where the prediction\nerror is really low, but that is enough to trigger\na safety-level failure--",
    "start": "2172580",
    "end": "2179750"
  },
  {
    "text": "or system-level failure. Sorry. So we are particularly targeting\nthose component-level errors",
    "start": "2179750",
    "end": "2185970"
  },
  {
    "text": "then lead to\nsystem-level failures. ",
    "start": "2185970",
    "end": "2191810"
  },
  {
    "text": "And we can now combine this with\nthe idea of parameter condition reachable sets to\nobtain these failures",
    "start": "2191810",
    "end": "2197900"
  },
  {
    "text": "as a function of different\nenvironmental latents, such as the time of the\nday or cloud conditions. So for example, the same\nstate which was failure",
    "start": "2197900",
    "end": "2205970"
  },
  {
    "text": "during the morning time\nbecause of this runway marking is actually safe during\nthe night time, which is very counterintuitive because\nmost of the vision controllers",
    "start": "2205970",
    "end": "2213050"
  },
  {
    "text": "are going to downgrade when\nthey are operated in nighttime because of the low visibility. But because of this\nsemantic failure,",
    "start": "2213050",
    "end": "2219240"
  },
  {
    "text": "actually, this state is no\nlonger a failure in the night, and we improve the\nsafety of the aircraft.",
    "start": "2219240",
    "end": "2224710"
  },
  {
    "text": "And similarly, we\ncan find the failures as a function of\ncloud conditions and we can get a diverse set\nof failures of this system.",
    "start": "2224710",
    "end": "2231569"
  },
  {
    "text": " Let me show another example.",
    "start": "2231570",
    "end": "2236640"
  },
  {
    "text": "So this is an autonomous\nindoor navigation pipeline which has a perception\ncomponent that",
    "start": "2236640",
    "end": "2243080"
  },
  {
    "text": "takes, as input, the RGB\nimage on the robot to output a waypoint which is then tracked\nusing an MPC-based controller.",
    "start": "2243080",
    "end": "2252890"
  },
  {
    "text": "And this framework was trained\nentirely in simulation. And here is a run of that\ncontroller in the real world.",
    "start": "2252890",
    "end": "2262400"
  },
  {
    "text": "And it works quite\nwell, actually. Even though the robot has never\nseen this environment before, only using the\nfirst-person RGB image,",
    "start": "2262400",
    "end": "2269220"
  },
  {
    "text": "it is navigating through\nthis very cluttered hallway with bikes on one side and\ncubicles on the other side in order to reach\nits goal safely.",
    "start": "2269220",
    "end": "2277579"
  },
  {
    "text": "This is my bike, by the way. I used to sit here five years\nago when I was at Berkeley.",
    "start": "2277580",
    "end": "2283940"
  },
  {
    "text": "But there are a lot of\ninteresting failure modes of this controller that we found\nusing the proposed framework.",
    "start": "2283940",
    "end": "2291170"
  },
  {
    "text": "In the interest of time, let\nme just highlight one of them. So we learned that the\nvision-based controller here",
    "start": "2291170",
    "end": "2297980"
  },
  {
    "text": "learns a correlation between\nlight-colored surfaces and traversability. And the reason for that is\na lot of the training data",
    "start": "2297980",
    "end": "2305780"
  },
  {
    "text": "or the majority of the training\ndata for this controller has actually\nlight-colored floors. So the vision-based\ncontroller somehow learned",
    "start": "2305780",
    "end": "2312860"
  },
  {
    "text": "this spurious\ncorrelation that whenever there's a light-colored\nsurface, I can go through it. During the test time, when you\nencounter light-colored walls,",
    "start": "2312860",
    "end": "2320310"
  },
  {
    "text": "it thinks it can go through it\ntoo, resulting in a collision.",
    "start": "2320310",
    "end": "2325640"
  },
  {
    "text": "So once again, we are\ntrying to figure out those failures of\nvision-based controller then ultimately leads to\nthe system-level failure.",
    "start": "2325640",
    "end": "2334960"
  },
  {
    "text": "But why am I doing this? Where I'm going with this? Well, if I know the failures\nof a vision-based controller,",
    "start": "2334960",
    "end": "2341030"
  },
  {
    "text": "I can use it to improve the\nvision-based controller. That's the ultimate purpose.",
    "start": "2341030",
    "end": "2346089"
  },
  {
    "text": "For example, I can\nuse these failures to train an anomaly detector,\nwhich, given an image,",
    "start": "2346090",
    "end": "2352400"
  },
  {
    "text": "tells me the probability\nof failure of the system. And if this anomaly\ndetector triggers fail,",
    "start": "2352400",
    "end": "2360010"
  },
  {
    "text": "then I can use a fallback\ncontroller, for instance, to preserve the\nsafety in online mode.",
    "start": "2360010",
    "end": "2365830"
  },
  {
    "text": "So this is the same\nscenario as before, where the aircraft was failing\nbecause of this runway marking.",
    "start": "2365830",
    "end": "2371900"
  },
  {
    "text": "But now you will see that\nanomaly detector flags that as a failure input. So it slows down\nthe robot, which",
    "start": "2371900",
    "end": "2377380"
  },
  {
    "text": "is what fallback\ncontroller is doing. And then once we cross the\npedestrian crossing-- or sorry-- the runway marking, we goes back\nto our learning based controller",
    "start": "2377380",
    "end": "2386170"
  },
  {
    "text": "and then maintain system\nsafety in that way. This is very preliminary work. Of course, there is a lot\nof interesting questions",
    "start": "2386170",
    "end": "2392963"
  },
  {
    "text": "here, which is, how do you\ndesign the anomaly detector? How do you design the\nfallback controller on that anomaly detector?",
    "start": "2392963",
    "end": "2398932"
  },
  {
    "text": "These are very\ninteresting questions. But this is what a catalog\nof failures of the system can at least give us\nas a starting point.",
    "start": "2398932",
    "end": "2407760"
  },
  {
    "text": "We can also do something more. We can try to do the\ntargeted incremental training",
    "start": "2407760",
    "end": "2413280"
  },
  {
    "text": "of this controller\non that failure data, and that should improve\nour performance.",
    "start": "2413280",
    "end": "2418599"
  },
  {
    "text": "So for example, in the blue-- in the gray is the BRT before\nthe incremental training",
    "start": "2418600",
    "end": "2424440"
  },
  {
    "text": "and the blue is after. And you can see how there\nis a significant reduction in the unsafe volume. ",
    "start": "2424440",
    "end": "2432744"
  },
  {
    "text": "So let me take a step back. The key goal of our research\nwas to design autonomous systems",
    "start": "2432744",
    "end": "2440180"
  },
  {
    "text": "that can leverage the\ncapabilities offered by modern machine\nlearning methods while also maintaining safety.",
    "start": "2440180",
    "end": "2445970"
  },
  {
    "text": "And towards that goal,\nwe think about safety in different stages of\nthe learning process, starting from the\ndesign to their approach",
    "start": "2445970",
    "end": "2452690"
  },
  {
    "text": "to their operation\nto offline testing. And today in\nparticular, I touched",
    "start": "2452690",
    "end": "2458390"
  },
  {
    "text": "upon a part of our\nresearch, which is neural safety representations\nthat can enable operationalize such a framework.",
    "start": "2458390",
    "end": "2466079"
  },
  {
    "text": "I have a few more minutes. So let me just\nquickly highlight some of the other projects\nin the lab without going",
    "start": "2466080",
    "end": "2472170"
  },
  {
    "text": "into too much detail.  So I talked about\nDeepReach, which",
    "start": "2472170",
    "end": "2478260"
  },
  {
    "text": "is one paradigm to learn\ncontrollers for robotic systems. But there are many other\ninteresting learning paradigms",
    "start": "2478260",
    "end": "2484470"
  },
  {
    "text": "that have been shown,\nvery promising results, for example, imitation learning. And so we've been\nasking ourselves,",
    "start": "2484470",
    "end": "2491170"
  },
  {
    "text": "how can we learn safety-aware\nimitation learning policies, in particular, behavior\ncloning policies?",
    "start": "2491170",
    "end": "2496920"
  },
  {
    "text": "And from a safety viewpoint, one\nof the problems with imitation learning is that it suffers\nfrom compounding error problem",
    "start": "2496920",
    "end": "2502740"
  },
  {
    "text": "or covariate shift\nproblem, which means that even if you give safe\ndemonstrations to the system,",
    "start": "2502740",
    "end": "2508523"
  },
  {
    "text": "there is no guarantee that\nthe resultant policy will be safe for the system. ",
    "start": "2508523",
    "end": "2514480"
  },
  {
    "text": "So to think about this problem,\nwhat we have been doing is we have been injecting\nthis adversarial disturbance",
    "start": "2514480",
    "end": "2523720"
  },
  {
    "text": "in the system during the\ndata collection procedure. So this adversarial\ndisturbance is computed also",
    "start": "2523720",
    "end": "2529030"
  },
  {
    "text": "using reachability\nanalysis, but it is doing exactly opposite of\nwhat safety controller does.",
    "start": "2529030",
    "end": "2534250"
  },
  {
    "text": "Rather than pushing us away\nfrom the safety critical states, it's going to push us towards\nthe safety critical states.",
    "start": "2534250",
    "end": "2540089"
  },
  {
    "text": "So it's going to do the\ngradient descent instead of gradient ascent on\nthe value function.",
    "start": "2540090",
    "end": "2546110"
  },
  {
    "text": "And by doing so,\nour hypothesis is that the robot gets to visit\nmore safety-critical states",
    "start": "2546110",
    "end": "2551330"
  },
  {
    "text": "and we can learn corrective\nactions from those states. So now, during the test time--",
    "start": "2551330",
    "end": "2558400"
  },
  {
    "text": "so once we collect that data,\nwe train the behavior cloning policy using the\nsame methods as we",
    "start": "2558400",
    "end": "2564960"
  },
  {
    "text": "do for the rest of our\nbehavior cloning policies. But during the test time now,\nif the policy makes an error,",
    "start": "2564960",
    "end": "2573310"
  },
  {
    "text": "and in particular, if the policy\nmakes a safety critical error, then hopefully it will\nbe able to better recover",
    "start": "2573310",
    "end": "2579420"
  },
  {
    "text": "from such states. So that's the hypothesis. Let's see how it plays out.",
    "start": "2579420",
    "end": "2584880"
  },
  {
    "text": "This is the same\naircraft taxiing problem that I showed earlier. Here is the imitation policy,\nwhich goes from image to action.",
    "start": "2584880",
    "end": "2593390"
  },
  {
    "text": "And over here, I'm showing\nyou the percentage failures across a bunch of\ntest trajectories",
    "start": "2593390",
    "end": "2599329"
  },
  {
    "text": "for the vanilla behavior cloning\nand the safety-aware behavior cloning, for different\nnumber of demonstrations.",
    "start": "2599330",
    "end": "2607170"
  },
  {
    "text": "And you can see even with\na handful of demonstration, injecting this safety\ninformation significantly",
    "start": "2607170",
    "end": "2612869"
  },
  {
    "text": "improves the safety\nof the test-- safety of the policy\nat the test time.",
    "start": "2612870",
    "end": "2618859"
  },
  {
    "text": "And to understand why,\nhere I'm showing you the demonstration as\nwell as the rollout",
    "start": "2618860",
    "end": "2623870"
  },
  {
    "text": "of the policy for the vanilla\nmethod and then our method. You can see that for the\nvanilla behavior cloning,",
    "start": "2623870",
    "end": "2629250"
  },
  {
    "text": "as soon as the policy make\nerrors, in particular, as soon as it starts\ngoing towards the boundary of the runway, it cannot recover\nfrom it because it hasn't seen",
    "start": "2629250",
    "end": "2637280"
  },
  {
    "text": "much data on those states. On the other hand, with the\nsafety-guided imitation policy,",
    "start": "2637280",
    "end": "2642990"
  },
  {
    "text": "we are particularly pushing\nthe system towards this runway boundary, in this case. And so it can learn\nrecovery behavior",
    "start": "2642990",
    "end": "2648950"
  },
  {
    "text": "from such states, which\nthen reflects in its testing performance. And to clarify here, the data\nused for the both methods",
    "start": "2648950",
    "end": "2657079"
  },
  {
    "text": "are exactly the same. ",
    "start": "2657080",
    "end": "2662839"
  },
  {
    "text": "We have also applied\nthis on a real crazy fly.",
    "start": "2662840",
    "end": "2669410"
  },
  {
    "text": "And once again, I think the\nstory is the same with only five demonstrations, we are\nable to do much better sim",
    "start": "2669410",
    "end": "2675230"
  },
  {
    "text": "to real transfer,\nspecifically when we think from a context of safety. ",
    "start": "2675230",
    "end": "2683590"
  },
  {
    "text": "And in fact, I believe that\nthere is something more here. This idea of using\nsafety-critical information",
    "start": "2683590",
    "end": "2690820"
  },
  {
    "text": "can be useful to guide the\nexploration of our learning agent more generally,\nin my opinion,",
    "start": "2690820",
    "end": "2695840"
  },
  {
    "text": "in order to design\nmore robust policies. So, for instance, here, we are\nusing the safety information",
    "start": "2695840",
    "end": "2701859"
  },
  {
    "text": "to guide the exploration of\na sampling based planner, in this case MPPI. And you can see how this\nsignal is helping the planner",
    "start": "2701860",
    "end": "2709780"
  },
  {
    "text": "to explore more relevant\nparts of the state space. Earlier, I was wasting a lot\nof samples in the obstacles,",
    "start": "2709780",
    "end": "2715040"
  },
  {
    "text": "but those are useless samples. Those are never going to\nimprove the performance. So if you can guide them\nin the right direction,",
    "start": "2715040",
    "end": "2721190"
  },
  {
    "text": "then I can achieve\nthe same performance with much fewer samples. So safety can also\nhelp with exploration",
    "start": "2721190",
    "end": "2728130"
  },
  {
    "text": "during the design phase. The direction that we are\nactively pursuing in our group. ",
    "start": "2728130",
    "end": "2736230"
  },
  {
    "text": "And then another big\nchallenge in safety today is,",
    "start": "2736230",
    "end": "2742080"
  },
  {
    "text": "who gives you the\nsafety constraints? Who tells you what is\nsafe, what is unsafe? And that's a big question.",
    "start": "2742080",
    "end": "2748840"
  },
  {
    "text": "Luckily for many of\nFAA applications, well, FAA gives us. But in robotic systems,\nthat is not clear.",
    "start": "2748840",
    "end": "2756190"
  },
  {
    "text": "So we have been thinking\nabout, how can we use language as a medium for somebody\nto flexibly define",
    "start": "2756190",
    "end": "2762660"
  },
  {
    "text": "these constraints to us. So, for example, in this\npicture, as my robot is going through the\nlab, can I communicate",
    "start": "2762660",
    "end": "2768840"
  },
  {
    "text": "to the robot that avoid the\ncoffee spill on the floor? And so we have been using\nvision language model",
    "start": "2768840",
    "end": "2776350"
  },
  {
    "text": "to convert these\nnatural language feedback into certain\nphysical constraints that",
    "start": "2776350",
    "end": "2782080"
  },
  {
    "text": "are more interpretable by\ntraditional safety analysis methods such as reachability\nanalysis or control barrier",
    "start": "2782080",
    "end": "2788170"
  },
  {
    "text": "functions in order to design\na safety controller that adheres to these natural\nlanguage feedback.",
    "start": "2788170",
    "end": "2795110"
  },
  {
    "text": "And here is a very simple\nexperiment of that. Here, you will see the safety\nconstraints given by the user",
    "start": "2795110",
    "end": "2801350"
  },
  {
    "text": "and you're using VLM to convert\nthat into a safety constraint and then correspondingly\ncomputing a safety controller.",
    "start": "2801350",
    "end": "2806880"
  },
  {
    "text": " And so now the robot is\ngiven this constraint,",
    "start": "2806880",
    "end": "2814040"
  },
  {
    "text": "avoid the coffee spill. And so it actually\ndoesn't slow-- it doesn't actually stop.",
    "start": "2814040",
    "end": "2820150"
  },
  {
    "text": "Somehow video was laggy here.  And so this is\nnothing fancy compared",
    "start": "2820150",
    "end": "2827510"
  },
  {
    "text": "to what we can do with\nVLMs and LLMs today. But this is a starting point to\nthink about how these tools can",
    "start": "2827510",
    "end": "2834829"
  },
  {
    "text": "be used to define\nthese rich safety constraint and semantic\nsafety constraints for our robotic systems.",
    "start": "2834830",
    "end": "2842720"
  },
  {
    "text": "OK. So let me stop here and\nthank all my collaborators",
    "start": "2842720",
    "end": "2848390"
  },
  {
    "text": "and my students who\nactually did the hard work. I'm only doing the PR here,\nas well as our sponsors",
    "start": "2848390",
    "end": "2854510"
  },
  {
    "text": "for funding our research. And I'm happy to\ntake any questions. [APPLAUSE]",
    "start": "2854510",
    "end": "2860346"
  },
  {
    "text": " Thanks. ",
    "start": "2860346",
    "end": "2872050"
  },
  {
    "text": "So I have some questions about\nlearning the belly function about safety. So for the parameterize,\nthe draw function,",
    "start": "2872050",
    "end": "2880480"
  },
  {
    "text": "I felt that for\ndifferent thetas, I felt that we already\nneed some kind of data,",
    "start": "2880480",
    "end": "2886570"
  },
  {
    "text": "already obtained a\ncertain theta parameters. But I believe, for\nthis example, I",
    "start": "2886570",
    "end": "2893280"
  },
  {
    "text": "think it's kind of\nrealistic because we can try multiple experiments\nin multiple wind conditions. But for observations\nusing LiDARs,",
    "start": "2893280",
    "end": "2901070"
  },
  {
    "text": "I felt that it might be really\nhard to get almost every data from many observations. So you mean, if we are using\nparametrized neural learning,",
    "start": "2901070",
    "end": "2909490"
  },
  {
    "text": "it's some kind of interpolating\nthe theta values to get better-- Yeah.",
    "start": "2909490",
    "end": "2914900"
  },
  {
    "text": "So in that LiDAR\nfor example, you can think of theta as not being\nexplicit parameters but latent",
    "start": "2914900",
    "end": "2920289"
  },
  {
    "text": "parameters. So the LiDAR is-- a LiDAR scanner is going into,\nin this case, a graph neural",
    "start": "2920290",
    "end": "2925870"
  },
  {
    "text": "network, which is giving me some\nlatent representation of that as the output, which is then\ntaken as input by the safety",
    "start": "2925870",
    "end": "2931820"
  },
  {
    "text": "value function. So beta could be explicit\nphysical parameters, but they could also\nbe latent parameters.",
    "start": "2931820",
    "end": "2938119"
  },
  {
    "text": "Also you mean for some kind of\nreally sophisticated or complex input for beta, you can do\npre-processing to make it",
    "start": "2938120",
    "end": "2946280"
  },
  {
    "text": "representation-- Yes. You can do encoder-decoder\nkind of frameworks, or you can do simultaneous\nlearning as well.",
    "start": "2946280",
    "end": "2952960"
  },
  {
    "text": " So how does the\ncomplexity of DeepReach",
    "start": "2952960",
    "end": "2959450"
  },
  {
    "text": "scale with the dimension? Like I know obviously,\n[INAUDIBLE] in general scales very poorly, but how\ndoes DeepReach scale?",
    "start": "2959450",
    "end": "2964950"
  },
  {
    "text": "That's a good question. And I think the scalability--",
    "start": "2964950",
    "end": "2972390"
  },
  {
    "text": "the scalability or\nwhat it scales with, I guess, what the computational\ncomplexity scales with as in",
    "start": "2972390",
    "end": "2978300"
  },
  {
    "text": "is not immediately clear,\nlet me start there, because I can certainly give you\ntwo-dimensional example where",
    "start": "2978300",
    "end": "2984960"
  },
  {
    "text": "the value function\nis really complex and it would be very\nhard to learn that. On the other hand, I can give\nyou 1,000-dimensional system",
    "start": "2984960",
    "end": "2991770"
  },
  {
    "text": "where it will learn\nit within 10 minutes. So what, I guess,\nDeepReach is betting on",
    "start": "2991770",
    "end": "2996930"
  },
  {
    "text": "is that if the value\nfunction that you're trying to approximate\nor trying to compute has a lower dimensional manifold\nthat you can learn easily,",
    "start": "2996930",
    "end": "3004020"
  },
  {
    "text": "then you will have\na better time. There is no magic here, so it\ncan not come with the-- overcome",
    "start": "3004020",
    "end": "3009380"
  },
  {
    "text": "the cause of\ndimensionality for good. It only relying on the fact that\nfor many systems of interest,",
    "start": "3009380",
    "end": "3014967"
  },
  {
    "text": "there is a lower dimensional\nrepresentation of the value function. And so by not relying on\ngrid-based computations,",
    "start": "3014967",
    "end": "3021210"
  },
  {
    "text": "you can overcome some\nof these challenges. And does that also imply\nthat there smarter grids ways to do general\nvanilla [INAUDIBLE]?",
    "start": "3021210",
    "end": "3027920"
  },
  {
    "text": "I think so, yes. Yes, there should\nbe, because I think of grids as also a\nparametric representation",
    "start": "3027920",
    "end": "3034178"
  },
  {
    "text": "where the number of parameters\nis equal to the number of grid points. That's one way to\nthink about it. It's also a function\napproximation",
    "start": "3034178",
    "end": "3040007"
  },
  {
    "text": "if you take that angle on it. So you're just using\nway too many parameters, perhaps, than you need to.",
    "start": "3040007",
    "end": "3045180"
  },
  {
    "text": " So you showed like a slide\nwhere you're like training,",
    "start": "3045180",
    "end": "3050779"
  },
  {
    "text": "like, a vision-based controller\nbased on the anomalies that are detected. So my question is that if you\ntake that vision controller to,",
    "start": "3050780",
    "end": "3058360"
  },
  {
    "text": "let's say, another runway,\nwill that incrementally trained network perform well\nthere, or will it",
    "start": "3058360",
    "end": "3065100"
  },
  {
    "text": "have some of overfitting issue? That's a good question. In fact, before\neven overfitting,",
    "start": "3065100",
    "end": "3070383"
  },
  {
    "text": "Rowan and I were chatting about\nit a couple of weeks back, but one of the issues we see\nwith incremental training",
    "start": "3070383",
    "end": "3076030"
  },
  {
    "text": "is that you might now\nstart seeing failures",
    "start": "3076030",
    "end": "3081430"
  },
  {
    "text": "in certain regions\nof state space where you were fine earlier. Because if you look\nat it today, we",
    "start": "3081430",
    "end": "3086530"
  },
  {
    "text": "don't have machine\nlearning methods that lead to\nmonotonic improvement as you get more data. So if I give you\ndata set 1, say D1,",
    "start": "3086530",
    "end": "3094690"
  },
  {
    "text": "and I add 100 more samples to\nit, so D1 plus 100 samples, there is no guarantee that when\nyou train it on D1 plus 100,",
    "start": "3094690",
    "end": "3101270"
  },
  {
    "text": "the performance will be\ncompletely monotonic over D1. And when I say completely\nmonotonic, meaning",
    "start": "3101270",
    "end": "3106420"
  },
  {
    "text": "point-wise monotonic over D1. Of course, in overall metric in\naggregation, it could be true. It probably is true,\nbut not point-wise,",
    "start": "3106420",
    "end": "3113760"
  },
  {
    "text": "which matters for safety, which\nmeans that the BRT volume now has some intersections\nwith the previous BRT.",
    "start": "3113760",
    "end": "3122099"
  },
  {
    "text": "And it is smaller in\nsome other regions. So actually,\nincremental training",
    "start": "3122100",
    "end": "3128910"
  },
  {
    "text": "is very hard to make work in a\nmonotonic direction right now. So absolutely it will fail\nin some other runways.",
    "start": "3128910",
    "end": "3136150"
  },
  {
    "text": "So it's like even if you like,\ntake it to another runway, it might fail where it\nwas like performing well?",
    "start": "3136150",
    "end": "3141780"
  },
  {
    "text": "Yes. even on the same runway,\non the same configuration, it might now perform worse\nbecause incremental training",
    "start": "3141780",
    "end": "3149670"
  },
  {
    "text": "doesn't guarantee a monotonic\nimprovement in the safety. So yes, that's one\nof the questions",
    "start": "3149670",
    "end": "3156060"
  },
  {
    "text": "we've been thinking\nabout in our lab, which is how can we lead to monotonic\nimprovement in machine learning models as we increase more data.",
    "start": "3156060",
    "end": "3162635"
  },
  {
    "text": " Yes? How you handle\nsituations when there",
    "start": "3162635",
    "end": "3168910"
  },
  {
    "text": "are states which are unsafe or\nclose to unsafe region but also use high volts. You would want to be there\nbut also not want to be there?",
    "start": "3168910",
    "end": "3176470"
  },
  {
    "text": "It's a good question. So one thing that I\ncompletely brushed off",
    "start": "3176470",
    "end": "3182440"
  },
  {
    "text": "is so far, I've only\ntalked about safety. But that, of course, a car\nthat is sitting in my garage",
    "start": "3182440",
    "end": "3187660"
  },
  {
    "text": "is the safest car ever,\nbut we don't want that. So how to copy my\nsafety and performance.",
    "start": "3187660",
    "end": "3196051"
  },
  {
    "text": "And current math\nis unfortunately to do so are fairly myopic. The popular scheme\nbeing safety-filtering",
    "start": "3196051",
    "end": "3201700"
  },
  {
    "text": "that I was describing, which\ndoes it on a point-wise basis. So it doesn't look\nahead and see what",
    "start": "3201700",
    "end": "3206920"
  },
  {
    "text": "will be the effect of\ntaking certain action at current time on performance. So I think the right\nsolution to your problem",
    "start": "3206920",
    "end": "3212590"
  },
  {
    "text": "is to design controllers that\noptimize the performance. And there are some--",
    "start": "3212590",
    "end": "3218079"
  },
  {
    "text": "recently, there have\nbeen some formulations of dynamic programming,\nwhich optimizes",
    "start": "3218080",
    "end": "3226340"
  },
  {
    "text": "both of these requirements\nsimultaneously. So it be interesting to see\nif those type of controllers",
    "start": "3226340",
    "end": "3232520"
  },
  {
    "text": "naturally trade off\nthese two things. We can't really\nhave 100% safety.",
    "start": "3232520",
    "end": "3238130"
  },
  {
    "text": "We'd have to compromise on-- Yes. So absolutely. So I guess that's--",
    "start": "3238130",
    "end": "3245315"
  },
  {
    "text": "this trade-off between\ncomputation and the level of safety assurance. So I guess the\ntrade-off I'm making",
    "start": "3245315",
    "end": "3250940"
  },
  {
    "text": "is along that curve where\nI'm willing to give up a certain percentage of\nsafety in order to have",
    "start": "3250940",
    "end": "3256790"
  },
  {
    "text": "a more scalable computation. Yes? I'm just curious, is\nthere like any research",
    "start": "3256790",
    "end": "3264150"
  },
  {
    "text": "that goes into levels of\nguarantees within safety? Is there like\ntears that happen--",
    "start": "3264150",
    "end": "3269809"
  },
  {
    "start": "3269810",
    "end": "3275740"
  },
  {
    "text": "I would imagine so. I personally don't know. But I know that at least all the\ncompanies that I've worked with,",
    "start": "3275740",
    "end": "3282770"
  },
  {
    "text": "they never think of the safety\nin terms of absolute sense, which is 100% safety. They have their\nlevels of safety,",
    "start": "3282770",
    "end": "3289039"
  },
  {
    "text": "but the ways of computing those\nlevels are a little bit ad hoc and heuristic-based. But they have levels.",
    "start": "3289040",
    "end": "3296821"
  },
  {
    "text": "For example, collisions\nhave different severity associated with them. And so they would\ncall it like OK,",
    "start": "3296821",
    "end": "3303090"
  },
  {
    "text": "this collision is really bad. So there's almost a hierarchy of\nsafety levels they care about.",
    "start": "3303090",
    "end": "3310270"
  },
  {
    "text": "I haven't seen personally much\nwork in academia on that front. But that's an\ninteresting question.",
    "start": "3310270",
    "end": "3315705"
  },
  {
    "text": " Yes?",
    "start": "3315705",
    "end": "3321559"
  },
  {
    "text": "So I don't want to talk too much\nabout Waymo proprietary things. But you had the example of the--",
    "start": "3321560",
    "end": "3327610"
  },
  {
    "text": "really interesting example\nof the adversarial situation where you're actually convincing\nthe oncoming car to squeeze in.",
    "start": "3327610",
    "end": "3336520"
  },
  {
    "text": "So I was just wondering,\nthe controller like in that situation, is that\nsymmetric about if you take",
    "start": "3336520",
    "end": "3342160"
  },
  {
    "text": "a human and a Waymo and you\nswap each controller out, does it work Waymo, the Waymo\nhuman to Waymo and in reverse",
    "start": "3342160",
    "end": "3348880"
  },
  {
    "text": "is it? Yeah. That's going into a very\ninteresting game theory land.",
    "start": "3348880",
    "end": "3355060"
  },
  {
    "text": "Here, I'm conveniently assuming\nthat the information is symmetric.",
    "start": "3355060",
    "end": "3360490"
  },
  {
    "text": "So I'm assuming that I can--\nnot only the cars are symmetric but I can control both cars.",
    "start": "3360490",
    "end": "3366740"
  },
  {
    "text": "That's not true. When the oncoming\ntraffic is you driving, I can't really control your car. The reason I'm making that\nassumption is because--",
    "start": "3366740",
    "end": "3375400"
  },
  {
    "text": "because I'm assuming that when\nit comes to collision avoidance, there is a certain level\nof cooperativeness between",
    "start": "3375400",
    "end": "3380510"
  },
  {
    "text": "the drivers, which is maybe you\nalso don't want to collide with me when I'm--",
    "start": "3380510",
    "end": "3385820"
  },
  {
    "text": "At first, you see\nthat situation, to me, it seems really worrisome. But on the other hand,\nmaybe people's avoidance of those things is\nactually really robust.",
    "start": "3385820",
    "end": "3392690"
  },
  {
    "text": "And just as robust\nas many settings. You would be surprised. So there's a whole distribution.",
    "start": "3392690",
    "end": "3398460"
  },
  {
    "text": "And I think before we get\nto this planning level, there is often a behavior level\nclassification that happens.",
    "start": "3398460",
    "end": "3405150"
  },
  {
    "text": "So looking at the past\ntrajectory of that vehicle, for example, we classify\nwhether this car",
    "start": "3405150",
    "end": "3411769"
  },
  {
    "text": "is behaving more\nlike an adversary or behaving more like\na cooperative car. And based on that, our planning\nstrategies are different.",
    "start": "3411770",
    "end": "3418257"
  },
  {
    "text": "It doesn't necessarily being\ndone in this classification levels that I said, but there\nis some behavior planning that is happening, which\nthen decide how should we",
    "start": "3418257",
    "end": "3426080"
  },
  {
    "text": "try to nudge around this car. So it's a little bit more\ncomplicated behavior level Are those levels of\nWaymo cars in the city",
    "start": "3426080",
    "end": "3431809"
  },
  {
    "text": "do seem to be they're\nnot necessarily shy. They've gotten quite--",
    "start": "3431810",
    "end": "3437089"
  },
  {
    "text": "They were very shy. OK. I'm being recorded, so\nI'm going to stop here.",
    "start": "3437090",
    "end": "3443810"
  },
  {
    "text": "I'm going to stop here. We can chat offline. This is for Happy hour.",
    "start": "3443810",
    "end": "3449420"
  },
  {
    "text": "Yeah, I think so. So one more question or? ",
    "start": "3449420",
    "end": "3456589"
  },
  {
    "text": "Thank you so much. Thank you. [APPLAUSE] ",
    "start": "3456590",
    "end": "3465000"
  }
]
[
  {
    "start": "0",
    "end": "6000"
  },
  {
    "start": "0",
    "end": "5302"
  },
  {
    "text": "OK, hi, everyone. It's my pleasure\nto introduce Percy, who's giving a guest lecture. For those of you who\nare in the course,",
    "start": "5302",
    "end": "11810"
  },
  {
    "start": "6000",
    "end": "216000"
  },
  {
    "text": "just a reminder that\nthe poster session is on Wednesday next week,\nand your final project is due the following, two\nweeks from two days ago,",
    "start": "11810",
    "end": "20189"
  },
  {
    "text": "or on Monday. But I'm really excited\nto introduce Percy. Percy is an associate\nprofessor here at Stanford.",
    "start": "20190",
    "end": "26890"
  },
  {
    "text": "He's done some really cool\nwork in machine learning, and natural language processing\nboth on the theoretical side as",
    "start": "26890",
    "end": "32490"
  },
  {
    "text": "well as the empirical\nside, and also has most recently started the\nStanford Center for Research on foundation models,\nwhich has also",
    "start": "32490",
    "end": "38760"
  },
  {
    "text": "been kind of a really cool\neffort going on is also pretty related to some of the\ntopics in the course as well. So yeah, looking\nforward to this talk.",
    "start": "38760",
    "end": "45390"
  },
  {
    "text": "Great. All right. Thanks Chelsea for the\nintroduction, and thanks, everyone, for coming. I think, you guys have seen in\ncontext learning a little bit.",
    "start": "45390",
    "end": "53160"
  },
  {
    "text": "I saw it in one of the slides. So hopefully, we'll do a little\nbit more of a deep dive here.",
    "start": "53160",
    "end": "60250"
  },
  {
    "text": "So the story starts in 2020. So a bunch of people\nat OpenAI decided to gather a ton of data,\ntext data on the internet,",
    "start": "60250",
    "end": "68400"
  },
  {
    "text": "and construct a big transformer. And ask the model to do\none simple thing, which",
    "start": "68400",
    "end": "74820"
  },
  {
    "text": "is predict the next word\nover and over again, over every single\ntoken on this data set.",
    "start": "74820",
    "end": "80610"
  },
  {
    "text": "And they ran it on,\nI think, something like 10,000 GPUs\nfor four months.",
    "start": "80610",
    "end": "86290"
  },
  {
    "text": "And I think, all of you now\nhave probably seen or played",
    "start": "86290",
    "end": "91350"
  },
  {
    "text": "with GPT-3 but the result\nthat I want to focus on",
    "start": "91350",
    "end": "96479"
  },
  {
    "text": "is this ability to do\nin context learning. So what is in context\nlearning just as a review,",
    "start": "96480",
    "end": "101760"
  },
  {
    "text": "it's the idea that you can\nprompt a language model with a string, which\nis concatenation",
    "start": "101760",
    "end": "108180"
  },
  {
    "text": "of a bunch of examples. That's something, that looks\nlike this with a new test example and ask the model\nto produce the answer.",
    "start": "108180",
    "end": "116962"
  },
  {
    "text": "So if you think about-- this is sort of crazy. Why would this, you expect that\nto work because the language",
    "start": "116962",
    "end": "123470"
  },
  {
    "text": "model isn't supposed\nto generate language, it's not really supposed\nto solve any tasks,",
    "start": "123470",
    "end": "128610"
  },
  {
    "text": "let alone do some meta learning. And you might\nthink, well, this is",
    "start": "128610",
    "end": "134570"
  },
  {
    "text": "because there's lots\nof examples that look like this on the internet. So I just probably\njust copied something.",
    "start": "134570",
    "end": "139970"
  },
  {
    "text": "So really tried hard to\nsee if we could break out. So here's a task. We prompt it with input.",
    "start": "139970",
    "end": "146120"
  },
  {
    "text": "Here's a date, and output. We want to come up with\nsomething that was definitely not on the internet as of 2021.",
    "start": "146120",
    "end": "154040"
  },
  {
    "text": "And it could reformat\ndates in this way as well.",
    "start": "154040",
    "end": "159299"
  },
  {
    "text": "So for those nonbelievers who\nthink like, well, OK, GPT-3 they've trained on the internet,\nthey're just memorizing.",
    "start": "159300",
    "end": "165080"
  },
  {
    "text": "Well, this is a\nclear demonstration that it's not just\nmemorizing, it's actually learning some\nabstraction that's",
    "start": "165080",
    "end": "170300"
  },
  {
    "text": "helping it solve these tasks. OK, and the scale matters here.",
    "start": "170300",
    "end": "176370"
  },
  {
    "text": "So this is from the\noriginal GPT-3 paper. If you were playing around\nwith small 1 billion parameter models, you could\nsee that nothing was really",
    "start": "176370",
    "end": "184640"
  },
  {
    "text": "working at all. And it's only when you get up\nto 175 billion in that case,",
    "start": "184640",
    "end": "190770"
  },
  {
    "text": "you could get in\ncontext learning. So this is simply mind blowing. And ever since,\nI've been obsessed",
    "start": "190770",
    "end": "197530"
  },
  {
    "text": "with the problem of figuring\nout why it's this works. This is not the way the machine\nlearning is supposed to work.",
    "start": "197530",
    "end": "203960"
  },
  {
    "text": "So hopefully, we can try to\nunderstand a little of this in our talk here.",
    "start": "203960",
    "end": "210220"
  },
  {
    "text": "And why in context\nlearning does this matter? And it's not just\na random curiosity.",
    "start": "210220",
    "end": "216970"
  },
  {
    "start": "216000",
    "end": "337000"
  },
  {
    "text": "There's two reasons,\nscientific and practical. On the scientific front,\nthis is an example",
    "start": "216970",
    "end": "222670"
  },
  {
    "text": "of emergent phenomenon. So GPT-3 was not built to\ndo in context learning, the developers did not say, oh,\nwe want in context learning,",
    "start": "222670",
    "end": "229167"
  },
  {
    "text": "so therefore, we're going\nto train it in this way. It just sort of emerged\nsomehow from the data.",
    "start": "229167",
    "end": "236380"
  },
  {
    "text": "Second, there's a sort of\nconventional wisdom in machine learning that you train\nand then you test.",
    "start": "236380",
    "end": "242590"
  },
  {
    "text": "And if your train\ndistribution is like your test\ndistribution then you win, otherwise, all bets are off.",
    "start": "242590",
    "end": "248120"
  },
  {
    "text": "And this is going to be\nfarther from that setting where the training distribution\nis predicting next word",
    "start": "248120",
    "end": "253599"
  },
  {
    "text": "and the test is, this wide\nrange of downstream tasks, some of which have never been\nseen at training time,",
    "start": "253600",
    "end": "259268"
  },
  {
    "text": "and yet something\nis still working. And the interesting\nthing about emergence",
    "start": "259269",
    "end": "265070"
  },
  {
    "text": "is that, here we have in\ncontext learning, which is going to occupy the\nwhole of this talk,",
    "start": "265070",
    "end": "270120"
  },
  {
    "text": "but what else is there? People have looked at other\nemergent behavior like chain of thought, and so on.",
    "start": "270120",
    "end": "275930"
  },
  {
    "text": "And so there's a very\nvast set of capabilities",
    "start": "275930",
    "end": "280970"
  },
  {
    "text": "that we're barely\nscratching the surface of. And then there's the\npractical concern or aspect",
    "start": "280970",
    "end": "288980"
  },
  {
    "text": "which is that, in context\nlearning really presents a paradigm shift in\nthe way, I think, we build ML or AI systems.",
    "start": "288980",
    "end": "296250"
  },
  {
    "text": "So now you can prototype\nnew tasks in the afternoon rather than setting up some\nelaborate data collection",
    "start": "296250",
    "end": "302419"
  },
  {
    "text": "process. So it kind of changes the way\nthat you even approach things. And I think, it's also\nimportant to realize",
    "start": "302420",
    "end": "309590"
  },
  {
    "text": "that in the real world, things\ndon't come pre-packaged with, oh, here's a data set I can\njust download from Hugging Face",
    "start": "309590",
    "end": "316310"
  },
  {
    "text": "and just run it. But if you're actually trying\nto solve a real problem, there's usually a kind of a\nvague idea of what you want",
    "start": "316310",
    "end": "322130"
  },
  {
    "text": "to do, maybe some messy data. And this idea of fast\nand quick prototyping",
    "start": "322130",
    "end": "327980"
  },
  {
    "text": "using these language\nmodels, I think, allows you to get\na lot farther than if your first step was to\ncollect a bunch of data",
    "start": "327980",
    "end": "335360"
  },
  {
    "text": "and label it. OK, so diving a little\nbit into details.",
    "start": "335360",
    "end": "341280"
  },
  {
    "start": "337000",
    "end": "483000"
  },
  {
    "text": "So there's a contrast here,\ntwo types of learning. The first is what I\ncall standard learning.",
    "start": "341280",
    "end": "347420"
  },
  {
    "text": "It's gradient based,\nwhich is where everyone's familiar with\nthat, you take gradients. In context learning,\nthe key operation",
    "start": "347420",
    "end": "354470"
  },
  {
    "text": "is not gradient descent\nbut conditioning. So in the language\nmodel, remember",
    "start": "354470",
    "end": "359540"
  },
  {
    "text": "it's a distribution\nover sequence of tokens. So what you're really\ndoing is conditioning on a sequence of tokens\nand then asking them all",
    "start": "359540",
    "end": "366199"
  },
  {
    "text": "to predict the next thing. OK, so we'll come back to\nthe issue of conditioning",
    "start": "366200",
    "end": "371700"
  },
  {
    "text": "in the second part of the talk. And since this is a\nmeta learning class, I thought I'd try to clarify\nthe relationship between meta",
    "start": "371700",
    "end": "378360"
  },
  {
    "text": "learning and context learning\nwhich often gets blurred. So there's a form\nof meta learning which you guys\ntalked about, which",
    "start": "378360",
    "end": "384660"
  },
  {
    "text": "is black-box meta learning. And I think, of meta\nlearning as talking about the framework\nof training data",
    "start": "384660",
    "end": "392640"
  },
  {
    "text": "that's housed maybe a\ncollection of tasks, and you want to do some\nsort of training procedure so that the model in this\ncase a black-box model",
    "start": "392640",
    "end": "400350"
  },
  {
    "text": "can do learning on new tasks. So I think, about this as the\nconnection between the training",
    "start": "400350",
    "end": "406750"
  },
  {
    "text": "and inference time. And into context\nlearning, really refers",
    "start": "406750",
    "end": "411810"
  },
  {
    "text": "to the ability that a\nmodel has, and independent",
    "start": "411810",
    "end": "417660"
  },
  {
    "text": "of where it came from. So we can talk about\nin-context learning ability of a transformer that\nwas encoded or learned",
    "start": "417660",
    "end": "426470"
  },
  {
    "text": "from supervised examples or from\nlanguage modeling objectives,",
    "start": "426470",
    "end": "432920"
  },
  {
    "text": "OK? Feel free to interrupt if\nyou have any questions.",
    "start": "432920",
    "end": "440229"
  },
  {
    "text": "OK, so in order to understand\nin-context learning, I want to break things\ndown into two pieces. One is just the question of how\na fixed model, never mind where",
    "start": "440230",
    "end": "449919"
  },
  {
    "text": "it came from, how can a\nfixed model even perform in-context learning? Because this is just\na giant transformer, it's getting fed in a bunch\nof sequence of examples,",
    "start": "449920",
    "end": "459490"
  },
  {
    "text": "and it has to do\nsomething, some association between the x and some\ny's to be able to predict.",
    "start": "459490",
    "end": "467630"
  },
  {
    "text": "So how is that possible? And the second question is, how\ndo you get one of these models from training, let's say\non next word prediction?",
    "start": "467630",
    "end": "475440"
  },
  {
    "text": "So I'm not going to answer\nthese two questions fully, but we're going to try\nto make some progress.",
    "start": "475440",
    "end": "481070"
  },
  {
    "text": "And how can we\nmake some progress? Well, there's many things\ngoing on with GPT-3.",
    "start": "481070",
    "end": "487129"
  },
  {
    "start": "483000",
    "end": "765000"
  },
  {
    "text": "So let me try to break it down. So there's a question\nof data, GPT-3 was trained on a\nlarge web crawl.",
    "start": "487130",
    "end": "495050"
  },
  {
    "text": "What is necessary there? Can we demonstrate in context\nlearning with synthetic data?",
    "start": "495050",
    "end": "500690"
  },
  {
    "text": "There's a question of\nmodel architecture. So we've seen in\ncontext learning working for transformers. What about RNNs or\nmixture of experts?",
    "start": "500690",
    "end": "508070"
  },
  {
    "text": "And then there's a\ntraining objective. Does it have to be\nauto-regressive? Can it be sort of like a\ncontrastive, or masked language",
    "start": "508070",
    "end": "514700"
  },
  {
    "text": "model objective? And then there's\na question of, how",
    "start": "514700",
    "end": "520159"
  },
  {
    "text": "do you study in each\nof these components? You can understand\nthings theoretically,",
    "start": "520159",
    "end": "525649"
  },
  {
    "text": "where we develop a\ntoy model and then you can prove analytically\nwhy in context learning works.",
    "start": "525650",
    "end": "532640"
  },
  {
    "text": "Or you can run synthetic\nexperiments where you just develop a simple model,\nand you can run things",
    "start": "532640",
    "end": "538010"
  },
  {
    "text": "so you can get\nclean conclusions. And then there's real\nworld experiments,",
    "start": "538010",
    "end": "543140"
  },
  {
    "text": "where you're running\nthings on real language, and there's trade-offs, right?",
    "start": "543140",
    "end": "548840"
  },
  {
    "text": "Ultimately, we want it\nto be in the real world, that this is really messy,\nand it's also very expensive",
    "start": "548840",
    "end": "553880"
  },
  {
    "text": "because remember, in context\nlearning only shows up at scale. So you can't really hope\nto do that many real world",
    "start": "553880",
    "end": "560660"
  },
  {
    "text": "experiments. So what we're going to focus\non is the bolded pieces here. We're going to look at\nsynthetic experiments",
    "start": "560660",
    "end": "568400"
  },
  {
    "text": "and do a little bit of\ntheory, to understand in context learning, both the\narchitecture and the data.",
    "start": "568400",
    "end": "574649"
  },
  {
    "text": "So we're going to\ntalk about two works. The first is, trying to get\nat the architecture question.",
    "start": "574650",
    "end": "583620"
  },
  {
    "text": "And the second is trying to\nget at the data question. OK, so the first paper is with\nShivam, Dimitris, and Greg",
    "start": "583620",
    "end": "593580"
  },
  {
    "text": "Valiant appearing on NeurlPS. OK.  So in-context\nlearning is, you can",
    "start": "593580",
    "end": "601860"
  },
  {
    "text": "solve all these different tasks\nbut there's a nagging question that, I think, I\nalluded to earlier,",
    "start": "601860",
    "end": "608290"
  },
  {
    "text": "which are these models actually\ndoing any learning at all, or is it just pattern matching? You should be really suspicious\nof these language models.",
    "start": "608290",
    "end": "617470"
  },
  {
    "text": "So what we want to do is\nformalize the problem a bit, right, because I think\nin-context learning,",
    "start": "617470",
    "end": "623100"
  },
  {
    "text": "like what's the definition. So here is a definition,\nwhich captures, I think,",
    "start": "623100",
    "end": "630149"
  },
  {
    "text": "at least one aspect of it. So you can think about in\ncontext learning of a function",
    "start": "630150",
    "end": "635190"
  },
  {
    "text": "class. So this is hailing\nback to kind of what people do in statistical\nlearning theory, where what does\nit mean to learn?",
    "start": "635190",
    "end": "642060"
  },
  {
    "text": "It's you define a function\nclass and you create examples from that class,\nand then you see if your learning\nalgorithm can figure out",
    "start": "642060",
    "end": "648270"
  },
  {
    "text": "which function it is. OK, so we're going to\nplay the same game here. So for example,\nlinear functions, the set of all linear functions\nand let's say 20 dimensions,",
    "start": "648270",
    "end": "656550"
  },
  {
    "text": "you sample a function. And then you're going\nto sample random input.",
    "start": "656550",
    "end": "662610"
  },
  {
    "text": "So these are going to be\nvectors that are d-dimensional, and I'm going to say,\nOK, here's an x1.",
    "start": "662610",
    "end": "669600"
  },
  {
    "text": "I'm going to apply\nthe function to x1, here's x2, apply\nthe function to x2. And these are going to\nbe inputs into a model.",
    "start": "669600",
    "end": "676569"
  },
  {
    "text": "And I want the model\nto be able to output the corresponding function\nvalue of the last input here.",
    "start": "676570",
    "end": "685500"
  },
  {
    "text": "OK, and the model\narchitecture, we're going to look at for this talk,\nthis first part of the talk",
    "start": "685500",
    "end": "691410"
  },
  {
    "text": "is a transformer. It's worth noting that,\nthe x is a real value.",
    "start": "691410",
    "end": "696940"
  },
  {
    "text": "So this is not going to\nbe a language transformer. With here, x is\njust going to be--",
    "start": "696940",
    "end": "702180"
  },
  {
    "text": "I mean, it's basically,\nthe word embedding treated as a word band betting\nlayer for the transformer.",
    "start": "702180",
    "end": "709380"
  },
  {
    "text": "And instead of outputting\na softmax over tokens, we're going to have\nthis transformer just",
    "start": "709380",
    "end": "714780"
  },
  {
    "text": "directly attach a linear\nlayer, and actually, ask it to do regression\nusing the squared loss.",
    "start": "714780",
    "end": "721589"
  },
  {
    "text": "So slightly deviation from\nactually a pure language model, so this is why\nwe're just talking about",
    "start": "721590",
    "end": "727500"
  },
  {
    "text": "transformers as opposed\nto language models, there's no language\nor text here at all. OK, so then what\nare we going to do?",
    "start": "727500",
    "end": "736149"
  },
  {
    "text": "We're going to build this\ntransformer by sampling functions over and over again.",
    "start": "736150",
    "end": "742463"
  },
  {
    "text": "And for each\nfunction, we're going to sample data for that function\nand then ask the transformer to reconstruct the\nlabels in the data.",
    "start": "742463",
    "end": "751329"
  },
  {
    "text": "This is going to be doing\nit from scratch just to make it very\nclear what's going on",
    "start": "751330",
    "end": "758769"
  },
  {
    "text": "rather than pre-training\nand fine tuning. ",
    "start": "758770",
    "end": "764615"
  },
  {
    "text": "OK. So what can this\ntrained transformer do? So let's start with\nlinear functions.",
    "start": "764615",
    "end": "770690"
  },
  {
    "start": "765000",
    "end": "1115000"
  },
  {
    "text": "In 20 dimension, this\nplot shows as you're increasing the number of\nin-context examples, what",
    "start": "770690",
    "end": "777860"
  },
  {
    "text": "is the error rate\non the fresh draw? And here we're looking\nat least squares.",
    "start": "777860",
    "end": "787770"
  },
  {
    "text": "And this is what\nyou would expect, there's no noise in the problem. So the dimensionality\nis 20, which",
    "start": "787770",
    "end": "792980"
  },
  {
    "text": "means that if you get 20\npoints, then you basically know the function, and\nleast squares is optimal, you can't do better than that.",
    "start": "792980",
    "end": "799100"
  },
  {
    "text": "And here the\ntransformer is actually able to match the\nimplementation of least squares.",
    "start": "799100",
    "end": "805459"
  },
  {
    "text": "And just a check, we\ndo some naive things like averaging in\nnearest neighbors and they just don't work, right?",
    "start": "805460",
    "end": "810680"
  },
  {
    "text": "So the transformer\nseems to be mimicking the behavior of the\noptimal algorithm here",
    "start": "810680",
    "end": "815960"
  },
  {
    "text": "of least squares. OK, so this was pretty cool, but\nyou might still be suspicious.",
    "start": "815960",
    "end": "821570"
  },
  {
    "text": "OK. Well, maybe it just saw\nenough examples and it just kind of memorized all of\nthe possible linear functions.",
    "start": "821570",
    "end": "829797"
  },
  {
    "text": "If you do the math, there are\na lot of linear functions, even if they're epsilon\nclose, like it's recursive dimensionality\nand your exponential in 20",
    "start": "829797",
    "end": "837440"
  },
  {
    "text": "is pretty big. So it's definitely not seen\nall the linear functions.",
    "start": "837440",
    "end": "844310"
  },
  {
    "text": "But you should still\nbe suspicious, and so let's probe it a little bit. OK. So how-- yeah.",
    "start": "844310",
    "end": "850100"
  },
  {
    "text": "Does your digits doing\nleast squares, are you like measuring if it's\nopening this root of inverse or something like that?",
    "start": "850100",
    "end": "855720"
  },
  {
    "text": "So the question\nis, how do you know if it's doing least squares? So we're only looking\nat the prediction error.",
    "start": "855720",
    "end": "861300"
  },
  {
    "text": "So it's most certainly not\nimplementing the least squares algorithm, and I'll\nshow you for a fact.",
    "start": "861300",
    "end": "871040"
  },
  {
    "text": "But it's at least on\nthis distribution, it's behaving like if you\nhad run least squares.",
    "start": "871040",
    "end": "877834"
  },
  {
    "text": " Yeah. Question back there. Does the order of the the input\nexamples matter in this case",
    "start": "877835",
    "end": "885529"
  },
  {
    "text": "or if you re-ordered the inputs\nlike the x1, x2, x3 rejoin, are they in some\nparticular order",
    "start": "885530",
    "end": "891830"
  },
  {
    "text": "or could you shuffle them and\nkind of get the same results? Yeah. So the question is, does the\norder of the examples matter?",
    "start": "891830",
    "end": "897350"
  },
  {
    "text": "In this case, it\ndoesn't really matter because each of these x's are\nactually generally drawn IID.",
    "start": "897350",
    "end": "903649"
  },
  {
    "text": "So there's no information\nin the ordering. ",
    "start": "903650",
    "end": "909490"
  },
  {
    "text": "OK, so let's try to probe it. And the way to really\ncheck whether this model is",
    "start": "909490",
    "end": "916480"
  },
  {
    "text": "able to do in-contact learning\nis, let's try to give it inputs that it hasn't seen\nat training time.",
    "start": "916480",
    "end": "922810"
  },
  {
    "text": "Not just hasn't seen, but\nit's a different distribution. And the distributions here are\na little bit complicated, so let",
    "start": "922810",
    "end": "928720"
  },
  {
    "text": "me try to talk through it. So there's the distribution\nover x's at test time.",
    "start": "928720",
    "end": "935207"
  },
  {
    "text": "So when I say test\nand train, I really mean meta test and meta train,\njust and when I say query,",
    "start": "935207",
    "end": "941170"
  },
  {
    "text": "that's the I guess, maybe where\nyou would call the test point.",
    "start": "941170",
    "end": "946790"
  },
  {
    "text": "So there's a distribution\nof x's, there's distribution over the y's\ngiven by the function.",
    "start": "946790",
    "end": "952310"
  },
  {
    "text": "And then there's\nthis query point. OK? So I'm going to change these\nand for there's basically,",
    "start": "952310",
    "end": "959800"
  },
  {
    "text": "these distributions\nfor meta test. And then there's also these\ndistributions for meta train.",
    "start": "959800",
    "end": "964839"
  },
  {
    "text": "So there's really like six\ndifferent distributions that we can vary.",
    "start": "964840",
    "end": "970390"
  },
  {
    "text": "So here's one starting point. So remember at training\ntime, meta-training time,",
    "start": "970390",
    "end": "976210"
  },
  {
    "text": "we draw examples just\nfrom a standard Gaussian.",
    "start": "976210",
    "end": "981423"
  },
  {
    "text": "And at test time,\nwhat we're going to do is we're going to\ngive these x's, which are the in-context\nexamples, they're",
    "start": "981423",
    "end": "987220"
  },
  {
    "text": "going to come from\na different quadrant or orthant than the query.",
    "start": "987220",
    "end": "992540"
  },
  {
    "text": "OK, so let's see what happens. In this case, it\ndegrades a little bit,",
    "start": "992540",
    "end": "998329"
  },
  {
    "text": "but it's basically matching\nthe behavior of least squares. Maybe this transition\nisn't as sharp, it needs a few more examples\nto figure out what's going on,",
    "start": "998330",
    "end": "1005110"
  },
  {
    "text": "but not too bad. What happens if we\nremember in training time,",
    "start": "1005110",
    "end": "1012170"
  },
  {
    "text": "we had the identity covariance. And at test time, all\nthe x's and the q's are going to be drawn from\na different covariance",
    "start": "1012170",
    "end": "1020240"
  },
  {
    "text": "distribution, where the\ncovariance is skewed.",
    "start": "1020240",
    "end": "1025260"
  },
  {
    "text": "And here you definitely get\nsome degree of degradation. So it doesn't hit\n0 as it should,",
    "start": "1025260",
    "end": "1031619"
  },
  {
    "text": "least squares would hit\n0 because well, there's no training in least\nsquares, or no meta",
    "start": "1031619",
    "end": "1037290"
  },
  {
    "text": "training in least squares,\nit's a fixed algorithm. And so but it's not bad. OK? So this is why it's not\nexactly least squares,",
    "start": "1037290",
    "end": "1044819"
  },
  {
    "text": "but it's sort of\napproximately least squares. So here's something\nreally interesting.",
    "start": "1044819",
    "end": "1050799"
  },
  {
    "text": "So what happens if you add\nlabel noise at inference time?",
    "start": "1050800",
    "end": "1056320"
  },
  {
    "text": "So in training,\nthere's no noise. So we're using the\nsame transformer here, and at test time, you\nadd some label noise.",
    "start": "1056320",
    "end": "1064030"
  },
  {
    "text": "So here, least\nsquares is actually going to not work because if\nyour least squares actually it",
    "start": "1064030",
    "end": "1071550"
  },
  {
    "text": "blows up here, and\nthis is a phenomenon called double descent, which\nhas been pretty well studied",
    "start": "1071550",
    "end": "1077130"
  },
  {
    "text": "in learning theory. And the transformer\ninterestingly has a similar spike.",
    "start": "1077130",
    "end": "1084830"
  },
  {
    "text": "OK, so this is interesting. I mean, this is,\nI guess, I don't know if this is good\nor bad, but at least,",
    "start": "1084830",
    "end": "1092150"
  },
  {
    "text": "qualitatively it has some\nsimilarities to least squares, at least as measured by\nthis kind of reaction",
    "start": "1092150",
    "end": "1099590"
  },
  {
    "text": "against noise, even though\nit's not exactly least squares. OK.",
    "start": "1099590",
    "end": "1105710"
  },
  {
    "text": "So the conclusion there\nis that, yeah, sort of works like least squares.",
    "start": "1105710",
    "end": "1111630"
  },
  {
    "text": "So what about going beyond\nlinear function classes? So let's look at\nsparse functions.",
    "start": "1111630",
    "end": "1118180"
  },
  {
    "start": "1115000",
    "end": "1340000"
  },
  {
    "text": "So in the sparse\nfunction, the f's have zeros in a lot of\nplaces on the weight vector",
    "start": "1118180",
    "end": "1125820"
  },
  {
    "text": "except for maybe three entries. So here the optimal thing\nis not least squares,",
    "start": "1125820",
    "end": "1131419"
  },
  {
    "text": "least squares is going to\ntake 20 examples to figure out what the solution is, it's\nthe lasso algorithm, which",
    "start": "1131420",
    "end": "1137360"
  },
  {
    "text": "does L1 regularization. And here, we show that the\ntransformer actually learns",
    "start": "1137360",
    "end": "1142790"
  },
  {
    "text": "to behave like the lasso. So this is pretty cool\nbecause now the transformer is able to learn\nkind of non-trivial.",
    "start": "1142790",
    "end": "1150740"
  },
  {
    "text": "I mean, the lasso is\nnot a trivial algorithm, and exploding sparsity\nis not trivial. So it's able to do that,\nwhich is pretty cool.",
    "start": "1150740",
    "end": "1157880"
  },
  {
    "text": "Note that we did have to train\nthe transformer to do this. So it's not magic,\notherwise it wouldn't",
    "start": "1157880",
    "end": "1165620"
  },
  {
    "text": "know about sparsity at all. What about 2-layer\nReLU networks? So here, the baseline that we\nlooked at is gradient descent,",
    "start": "1165620",
    "end": "1173150"
  },
  {
    "text": "and it basically matches\ngradient descent, so that's nice. ",
    "start": "1173150",
    "end": "1179780"
  },
  {
    "text": "Yeah. The original\ntransformer that you trained on non-sparse\nthings and see",
    "start": "1179780",
    "end": "1185420"
  },
  {
    "text": "if it matches least squares. So the question is-- If I took the\noriginal transformer,",
    "start": "1185420",
    "end": "1191360"
  },
  {
    "text": "and applied it to\nthe sparse question, so this should match to\nthe least squares objective",
    "start": "1191360",
    "end": "1199880"
  },
  {
    "text": "because a sparse\nlinear function is just a special case of\nlinear functions, and we already know that.",
    "start": "1199880",
    "end": "1206659"
  },
  {
    "text": "the previous transformer\nacted like least squares on a fairly wide range\nof distributions.",
    "start": "1206660",
    "end": "1213560"
  },
  {
    "text": "Yeah. So I have a question\nabout the label noise from earlier, what\nkind of model noise it?",
    "start": "1213560",
    "end": "1218600"
  },
  {
    "text": "Was it always-- Yeah, so the label noise is\njust adding Gaussian noise. How well would it work do\nwould you expect if you give",
    "start": "1218600",
    "end": "1225620"
  },
  {
    "text": "a complete outlier\njust for 1 or for y's? So question is,\nhow well would it work if you gave it 1y,\nwhich is way out there?",
    "start": "1225620",
    "end": "1235460"
  },
  {
    "text": "That would probably\nbreak least squares because unless you regularize. So least squares there's\nno regularization,",
    "start": "1235460",
    "end": "1240950"
  },
  {
    "text": "it's not regression. So it's going to just be\nthrown off by that label. And the transformer, we didn't\ndo that exact experiment,",
    "start": "1240950",
    "end": "1248630"
  },
  {
    "text": "but I imagine that it\nwould be also distracted.",
    "start": "1248630",
    "end": "1254770"
  },
  {
    "text": "Yeah, Chelsea. Given that least squares is\nthe optimal solution when you don't have\nnoise, do you think",
    "start": "1254770",
    "end": "1261340"
  },
  {
    "text": "that these sorts of\nfindings are surprising? I guess, I think, yeah, I guess,\ndo you think it's surprising",
    "start": "1261340",
    "end": "1268780"
  },
  {
    "text": "or did these results\nkind of differ from what you were expecting? So the question is, basically,\nis this result surprising?",
    "start": "1268780",
    "end": "1278409"
  },
  {
    "text": "It was not obvious to me\nthat this transformer would have this type of behavior.",
    "start": "1278410",
    "end": "1284893"
  },
  {
    "text": "And in fact, I'm not\ngoing to talk about this, but we also ran\nexperiments with LSTMs. And LSTMs look like transformers\non the indistribution,",
    "start": "1284893",
    "end": "1294010"
  },
  {
    "text": "but on this case, LSTMs did\nnot have the double descent. So it's pretty\nnon-obvious, I think,",
    "start": "1294010",
    "end": "1299080"
  },
  {
    "text": "that there's some dependence\non the architecture depending on-- different architecture\nhave a different inductive",
    "start": "1299080",
    "end": "1304990"
  },
  {
    "text": "bias, which will lead to\ndifferent CONCOR algorithms that it's learning. Is that just because the\ntransformer is fitting the data",
    "start": "1304990",
    "end": "1310720"
  },
  {
    "text": "better? Is it better universal function\nor proximity basically? So the question is, is that\nbecause the transformer is",
    "start": "1310720",
    "end": "1317409"
  },
  {
    "text": "just-- Fitting the training? Fitting the training there. I don't think so.",
    "start": "1317410",
    "end": "1323390"
  },
  {
    "text": "I think, it is inductive\nbias because we did-- I mean, there's still\nmore work to be done,",
    "start": "1323390",
    "end": "1329720"
  },
  {
    "text": "but we try to make\nthe LSTM large so it wasn't like a capacity issue. It could be a\ntraining, LSTMs are",
    "start": "1329720",
    "end": "1335800"
  },
  {
    "text": "hard to train so not quite sure. Yeah.",
    "start": "1335800",
    "end": "1340880"
  },
  {
    "start": "1340000",
    "end": "1452000"
  },
  {
    "text": "What's the intuition for\nwhy double descent happens? The intuition behind why\ndouble descent happens.",
    "start": "1340880",
    "end": "1347480"
  },
  {
    "text": "This is maybe a longer\nquestion, so maybe we should take that offline,\nbut basically, I guess,",
    "start": "1347480",
    "end": "1353180"
  },
  {
    "text": "one quick answer is that in\nthe over parameterized regime.",
    "start": "1353180",
    "end": "1359930"
  },
  {
    "text": "So statistically,\nwhat you would expect is like, OK, you fit\nand then you start overfitting when there's noise.",
    "start": "1359930",
    "end": "1365820"
  },
  {
    "text": "If there's no noise, then\nthere's no overfitting because you just nail it. And what people have observed\nis that over parameterization,",
    "start": "1365820",
    "end": "1374120"
  },
  {
    "text": "when the number of\ndimensions is larger than the number of examples,\nyou get this optimal error,",
    "start": "1374120",
    "end": "1380960"
  },
  {
    "text": "but I'm happy to\nchat more later. Let me go on since we have a lot\nto cover, but good questions.",
    "start": "1380960",
    "end": "1389929"
  },
  {
    "text": "OK, so finally, we\nlook at decision trees. So for decision trees, we\nlooked at the greedy algorithm,",
    "start": "1389930",
    "end": "1395360"
  },
  {
    "text": "XGBoost, which is the state\nof our decision tree learning algorithm. And here, the\ntransformer actually",
    "start": "1395360",
    "end": "1400850"
  },
  {
    "text": "outperforms, at least this\non sort of synthetic data",
    "start": "1400850",
    "end": "1406130"
  },
  {
    "text": "distribution. So this is not claiming that\nyou should ditch XGBoost and use this transformer, but this\nwas sort of curious, I think,",
    "start": "1406130",
    "end": "1413780"
  },
  {
    "text": "that the transformer is able to\nlearn some sort of algorithm. At least on this\ndistribution, it's",
    "start": "1413780",
    "end": "1419900"
  },
  {
    "text": "outperforming sort of hand-coded\nalgorithms, so to speak. ",
    "start": "1419900",
    "end": "1427070"
  },
  {
    "text": "Model size clearly matters,\nbut what's interesting is that model size is\nespecially important when",
    "start": "1427070",
    "end": "1433970"
  },
  {
    "text": "you look at kind of robustness\nand extrapolation out of distribution.",
    "start": "1433970",
    "end": "1439080"
  },
  {
    "text": "For standard, it\nseems, like, OK, there's a steady improvement\nas you increase the model size,",
    "start": "1439080",
    "end": "1446090"
  },
  {
    "text": "but it sort of really matters\nif you're extrapolating.",
    "start": "1446090",
    "end": "1451934"
  },
  {
    "text": "OK. So let me summarize. So one conceptual,\nimportant thing to take away",
    "start": "1451935",
    "end": "1457220"
  },
  {
    "start": "1452000",
    "end": "1883000"
  },
  {
    "text": "is that we're defining\nin-context learning of a function class. So this sort of is maybe\nan important concept, not",
    "start": "1457220",
    "end": "1462913"
  },
  {
    "text": "to think about\nin-context learning is like some fuzzy\nthing, but we're talking about rigorously\nin-context learning",
    "start": "1462913",
    "end": "1468980"
  },
  {
    "text": "of a function class, and this\nis a property of a model.",
    "start": "1468980",
    "end": "1474020"
  },
  {
    "text": "But in order to sort of prove\nthe existence of these models, we can train Transformers\nto do in-context learning",
    "start": "1474020",
    "end": "1480710"
  },
  {
    "text": "on these linear functions. We saw we could do sparse linear\nfunctions, neural networks decision trees.",
    "start": "1480710",
    "end": "1486559"
  },
  {
    "text": "We also evaluate the robustness\nof distributed prompts, which I think is really crucial\nif you want to understand.",
    "start": "1486560",
    "end": "1493700"
  },
  {
    "text": "Because many of the differences\nbetween model size and LSTMs as Transformers, you\ndon't really see",
    "start": "1493700",
    "end": "1498740"
  },
  {
    "text": "unless you go out\nof distribution, because that's where the\ninductive biases really kick in. And I think it's sort\nof interesting to think",
    "start": "1498740",
    "end": "1506600"
  },
  {
    "text": "about what algorithms these\ntransformers are representing. There's still a lot of\nopen questions here.",
    "start": "1506600",
    "end": "1515360"
  },
  {
    "text": "This model, when you condition\non these in-context examples, is a function.",
    "start": "1515360",
    "end": "1521980"
  },
  {
    "text": "It's not a linear\nfunction, certainly, but it is a function that's\nlocal, I think, within a ball,",
    "start": "1521980",
    "end": "1529530"
  },
  {
    "text": "behaves linearly, and it'll\nbe interesting to understand what function that actually is.",
    "start": "1529530",
    "end": "1536520"
  },
  {
    "text": "I alluded to RNNs and\nLSTMs, how much of this is specific to transformers, as\nopposed to other architectures.",
    "start": "1536520",
    "end": "1545529"
  },
  {
    "text": "How can we look\nunderneath the hood to see what the transformers are\nactually doing mechanistically?",
    "start": "1545530",
    "end": "1552840"
  },
  {
    "text": "There's this follow-up paper,\nwhich is really interesting where they actually\nare able to construct a Transformer by setting\nits weights somehow",
    "start": "1552840",
    "end": "1560430"
  },
  {
    "text": "and show that that can\ndo linear regression. They also do some more\nprobing experiments",
    "start": "1560430",
    "end": "1567000"
  },
  {
    "text": "to look inside the Transformer,\nwhereas we are only looking at behaviors.",
    "start": "1567000",
    "end": "1573090"
  },
  {
    "text": "One question is, can we\nget algorithmic insights? So this is something I'm excited\nabout because this will maybe",
    "start": "1573090",
    "end": "1582000"
  },
  {
    "text": "teach us something\nabout algorithm design. And the idea that\nthe decision trees",
    "start": "1582000",
    "end": "1587910"
  },
  {
    "text": "case the Transformer is actually\nable to do so much better suggests maybe there\nare other sorts of algorithms or principles\nhere that we can pull out.",
    "start": "1587910",
    "end": "1597420"
  },
  {
    "text": "And finally, this is\nall on synthetic tasks. It'd be great to tie this back\ninto real tasks with knowledge.",
    "start": "1597420",
    "end": "1604350"
  },
  {
    "text": "And the exclusion\nof knowledge here is deliberate here\nbecause we wanted to understand\nin-context learning,",
    "start": "1604350",
    "end": "1610380"
  },
  {
    "text": "really, the learning\npart, and you can think about this as a pure learning.",
    "start": "1610380",
    "end": "1615539"
  },
  {
    "text": "All we know is it's a learning\nfunction, there's no knowledge. It's just figure out what\nthe linear function is.",
    "start": "1615540",
    "end": "1620590"
  },
  {
    "text": "This is just learning. A lot of in-context examples\nthat you see in literature",
    "start": "1620590",
    "end": "1626610"
  },
  {
    "text": "bring in prior knowledge\nabout translation.",
    "start": "1626610",
    "end": "1631853"
  },
  {
    "text": "There's no way,\nobviously, you can learn how to translate\nsentences from five examples. It has to be knowledge, and how\ndoes that work in conjunction",
    "start": "1631853",
    "end": "1640200"
  },
  {
    "text": "with this learning ability? That's, I think, a really\ninteresting question. Question back there?",
    "start": "1640200",
    "end": "1645659"
  },
  {
    "text": "Yeah, just a quick one here. It seems like there is\nsome threshold rate based on model size, the number of\nparameters, at which point",
    "start": "1645660",
    "end": "1653350"
  },
  {
    "text": "in-context learning happens. In this work, did you\ndo an analysis on that? For instance, if you reduced\nthe number of parameters",
    "start": "1653350",
    "end": "1661299"
  },
  {
    "text": "you had on your\nmodel, would it not learn to do this\nlasso-type regression?",
    "start": "1661300",
    "end": "1666444"
  },
  {
    "text": "Is there a way to estimate\nhow many parameters you need for your model, given\nsome level of task difficulty?",
    "start": "1666444",
    "end": "1672890"
  },
  {
    "text": "Yeah, that's a great question. So the question is,\nbasically, how big of a model",
    "start": "1672890",
    "end": "1678150"
  },
  {
    "text": "do you need for certain\ntypes of behaviors? We have this experiment,\nwhich shows that, I mean,",
    "start": "1678150",
    "end": "1684450"
  },
  {
    "text": "size definitely does matter. I think it will be\nreally interesting to do a more careful scaling\nlaws type of analysis,",
    "start": "1684450",
    "end": "1690600"
  },
  {
    "text": "where you train a sequence\nof models from small to large and maybe you increase the depth\nor the number of tension heads",
    "start": "1690600",
    "end": "1696930"
  },
  {
    "text": "and look at these\ndimensions of scaling and then track the different\ntypes of behaviors like,",
    "start": "1696930",
    "end": "1702870"
  },
  {
    "text": "did it learn the lasso? Did it match? Does it have double\ndescent, and so on.",
    "start": "1702870",
    "end": "1710160"
  },
  {
    "text": "Yeah, that would be\ninteresting follow-up work. Yeah. Would there be a special case\nof [INAUDIBLE] networks when you",
    "start": "1710160",
    "end": "1717530"
  },
  {
    "text": "have [INAUDIBLE]-- I'm sorry-- [INAUDIBLE]\nfully commit to graph.",
    "start": "1717530",
    "end": "1722866"
  },
  {
    "text": "So I'm wondering, does this\nshow an [INAUDIBLE] have seen studies that relate\nin-context learning",
    "start": "1722866",
    "end": "1729270"
  },
  {
    "text": "from transformers to\ngraph neural networks? So the question is,\ntransformers can be seen as a special case\nof graph neural networks.",
    "start": "1729270",
    "end": "1735929"
  },
  {
    "text": "Are there any works that explore\nin-context learning with graph neural networks? ",
    "start": "1735930",
    "end": "1744460"
  },
  {
    "text": "I mean, there's an\nindependently, I think, interest in thinking about\nhow you do in-context learning with graph-structured\ndata, which is, I think,",
    "start": "1744460",
    "end": "1753159"
  },
  {
    "text": "interesting to explore. I think here, I guess\nthere's the graph,",
    "start": "1753160",
    "end": "1765120"
  },
  {
    "text": "I guess that sense what\nyou're trying to get out of the graph neural network.",
    "start": "1765120",
    "end": "1770190"
  },
  {
    "text": "Here, you have a\nsequence of x-y pairs, and there is, in some\nsense, a symmetry.",
    "start": "1770190",
    "end": "1777510"
  },
  {
    "text": "There's sort of all k squared\ndifferent kind of connections that make sense.",
    "start": "1777510",
    "end": "1783750"
  },
  {
    "text": "So I don't know if there would\nbe a natural graph structure. I guess that the asymmetry\nbetween the x and the y",
    "start": "1783750",
    "end": "1788850"
  },
  {
    "text": "tokens maybe matter. So you could try to\nsparsify the graph or play with attention\nheads somehow.",
    "start": "1788850",
    "end": "1797300"
  },
  {
    "text": "Maybe a broader question\nis the Transformer, we have positional\nembeddings here,",
    "start": "1797300",
    "end": "1803530"
  },
  {
    "text": "which seems rather unnatural\nfrom the point of view of it's not order invariant. And someone asks\nabout the dependence",
    "start": "1803530",
    "end": "1811769"
  },
  {
    "text": "on ordering of examples. Maybe you can build\nthat invariance directly into the model. ",
    "start": "1811770",
    "end": "1819400"
  },
  {
    "text": "Any other questions? ",
    "start": "1819400",
    "end": "1826260"
  },
  {
    "text": "Yeah. Can you do the\nexperiments without --",
    "start": "1826260",
    "end": "1831830"
  },
  {
    "text": "it still works\nwithout that, right? So the question is, do\nwe do any experiments",
    "start": "1831830",
    "end": "1837200"
  },
  {
    "text": "without the position\nor [INAUDIBLE]?? It wouldn't work because then\nyou don't know which y goes",
    "start": "1837200",
    "end": "1843380"
  },
  {
    "text": "with which x because if it's\njust a bag of x-y pairs, you don't--",
    "start": "1843380",
    "end": "1849310"
  },
  {
    "text": "Oh, your x and y's separated? Yeah, they're separate tokens.",
    "start": "1849310",
    "end": "1854559"
  },
  {
    "text": "Okay, so like you\nwould [INAUDIBLE]?? Yeah. OK. ",
    "start": "1854560",
    "end": "1863440"
  },
  {
    "text": "So to the outline. So we talked about\nwhat Transformers can learn in context,\nlooking at, I think",
    "start": "1863440",
    "end": "1871000"
  },
  {
    "text": "about it, really, as an\narchitectural question. Can the Transformer\ndo certain things and doing a bunch of\nsynthetic experiments",
    "start": "1871000",
    "end": "1878350"
  },
  {
    "text": "on well-defined function\nclasses to explore the limits of Transformers.",
    "start": "1878350",
    "end": "1883570"
  },
  {
    "start": "1883000",
    "end": "1935000"
  },
  {
    "text": "Now, let's try to\nunderstand the role of data. Although the way\nwe'll get at the data",
    "start": "1883570",
    "end": "1890080"
  },
  {
    "text": "maybe is not where\nyou think it would be. So this is an ICLR paper with\nMichael Xie, Aditi Ranganathan,",
    "start": "1890080",
    "end": "1899260"
  },
  {
    "text": "and Tengyu Ma. And remember, there's two\ntypes of standard learning,",
    "start": "1899260",
    "end": "1904810"
  },
  {
    "text": "you think about gradients. And in-context learning\nis this weird thing where",
    "start": "1904810",
    "end": "1910960"
  },
  {
    "text": "you condition to do learning. But maybe it's not,\nactually, that weird",
    "start": "1910960",
    "end": "1916480"
  },
  {
    "text": "if you think about it with\nthrough a Bayesian lens. And if you think about\nBayesian inference, which",
    "start": "1916480",
    "end": "1926290"
  },
  {
    "text": "might be a different paradigm\nfor, I guess, the norm in ML",
    "start": "1926290",
    "end": "1933700"
  },
  {
    "text": "these days. So let's walk through what\nBayesian inference is. So imagine you have a latent\nrandom variable theta, which",
    "start": "1933700",
    "end": "1943840"
  },
  {
    "start": "1935000",
    "end": "2715000"
  },
  {
    "text": "corresponds to a task. You can think about it as a\nfunction, a linear function, if you want, which is unknown.",
    "start": "1943840",
    "end": "1951050"
  },
  {
    "text": "That's why it's not shaded. And you think about building\na generative model over what--",
    "start": "1951050",
    "end": "1957850"
  },
  {
    "text": "general models\noverloaded these days. Let's build a\nprobabilistic framework",
    "start": "1957850",
    "end": "1962980"
  },
  {
    "text": "for thinking about how theta\nis related to variables. So here's a simple example.",
    "start": "1962980",
    "end": "1968900"
  },
  {
    "text": "Let's suppose that\nwe have x1 and y1. So suppose you can\ngenerate x1 or you can just",
    "start": "1968900",
    "end": "1977560"
  },
  {
    "text": "condition on it. It doesn't matter. But the point is that y is\ngenerated, given x and theta.",
    "start": "1977560",
    "end": "1986950"
  },
  {
    "text": "And independently, for\neach of the k examples, we have y, given x and theta.",
    "start": "1986950",
    "end": "1994823"
  },
  {
    "text": "And then you have a query\npoint, which is just another IID example, and so you ask\nwhat is the probability",
    "start": "1994823",
    "end": "2000480"
  },
  {
    "text": "of y query given\nxquery of theta. And now, of course, you\ndon't know what theta is.",
    "start": "2000480",
    "end": "2007750"
  },
  {
    "text": "So being a good\nBayesian, you would just try to marginalize it out, and\nthat's what this equation does.",
    "start": "2007750",
    "end": "2014220"
  },
  {
    "text": "So this is a very classic kind\nof Bayesian analysis, where you have this posterior\ndistribution, where",
    "start": "2014220",
    "end": "2021990"
  },
  {
    "text": "you condition on everything\nthat you observe, which is this. And then you look at the\nposterior distribution",
    "start": "2021990",
    "end": "2028559"
  },
  {
    "text": "over theta. So you try to guess\nwhat theta is. And then you basically\nweight your prediction.",
    "start": "2028560",
    "end": "2037750"
  },
  {
    "text": "So this is the prediction\nif you had theta, how would I predict on\nyquery given xquery,",
    "start": "2037750",
    "end": "2043680"
  },
  {
    "text": "and you're basically\naveraging over possible values of theta,\nwhere the averaging is",
    "start": "2043680",
    "end": "2049500"
  },
  {
    "text": "given by the posterior. So this object, in\nBayesian analysis,",
    "start": "2049500",
    "end": "2055408"
  },
  {
    "text": "is called the posterior\npredictive distribution. It doesn't have a theta in it\nbecause it's been marginalized",
    "start": "2055409",
    "end": "2061169"
  },
  {
    "text": "out, so it just\nlooks like x1 y1, all the way to xk yk,\nxquery and probability",
    "start": "2061170",
    "end": "2067919"
  },
  {
    "text": "distribution of yquery. And this is exactly\nthe same form that we've been playing around\nwith when we talk about doing",
    "start": "2067920",
    "end": "2074609"
  },
  {
    "text": "in-context learning. ",
    "start": "2074610",
    "end": "2079714"
  },
  {
    "text": "OK. So through this\nlens, what we can think about in-context learning\nor-- these Transformers",
    "start": "2079714",
    "end": "2086469"
  },
  {
    "text": "are doing is that\nthey're trying to fit this posterior predictive\ndistribution directly. OK?",
    "start": "2086469",
    "end": "2092658"
  },
  {
    "text": "But there could be this\nunderlying structure here that is latent. But the Transformer,\nit doesn't care.",
    "start": "2092659",
    "end": "2099359"
  },
  {
    "text": "It's just going to\nfit this distribution, and maybe it has some\nnotion of implicitly theta,",
    "start": "2099360",
    "end": "2105390"
  },
  {
    "text": "maybe it doesn't. Who knows.  So what will be\nuseful to think about",
    "start": "2105390",
    "end": "2113650"
  },
  {
    "text": "is this posterior\npredictive distribution, and we're going to\nstart abstracting away",
    "start": "2113650",
    "end": "2119020"
  },
  {
    "text": "from the architecture,\nand we're just going to talk about the distribution. OK.",
    "start": "2119020",
    "end": "2124190"
  },
  {
    "text": "So remember our questions. How can a fixed\nmodel, a Transformer, perform in context learning?",
    "start": "2124190",
    "end": "2130599"
  },
  {
    "text": "And the first part of the talk\nshowed some empirical evidence that the Transformer can\ndo in-context learning",
    "start": "2130600",
    "end": "2136480"
  },
  {
    "text": "in a fairly wide number\nof non-trivial settings",
    "start": "2136480",
    "end": "2142310"
  },
  {
    "text": "and if you are shown examples\nof the task, essentially.",
    "start": "2142310",
    "end": "2147650"
  },
  {
    "text": "Now, there are\nsome extrapolation if they're all out of\ndomain, but largely, you're showing the Transformer\nhere's what linear regression",
    "start": "2147650",
    "end": "2155539"
  },
  {
    "text": "looks like. And so you can think about\nthrough this lens is, well, this is the model--",
    "start": "2155540",
    "end": "2163220"
  },
  {
    "text": "I mean, an accurate depiction\nof the linear regression set up, if for appropriate\nchoices of distributions.",
    "start": "2163220",
    "end": "2171180"
  },
  {
    "text": "And so you can think about\nit, what we're doing is, we're just fitting\nthis distribution. And if you believe\nthat a transformer is",
    "start": "2171180",
    "end": "2178070"
  },
  {
    "text": "some universal function\napproximator, if you give it enough data, it\nshould just work.",
    "start": "2178070",
    "end": "2183619"
  },
  {
    "text": "I think, still, it's\nnon-trivial that it can do it in a reasonable amount of time.",
    "start": "2183620",
    "end": "2190460"
  },
  {
    "text": "Because I mean, you can invoke\nuniversal function approximator to-- this could be a pretty\ncomplex function,",
    "start": "2190460",
    "end": "2197640"
  },
  {
    "text": "so that the transformer\ncan learn it and you can actually\nrun SGD to do it. It's not obvious.",
    "start": "2197640",
    "end": "2203160"
  },
  {
    "text": "That's what the first\npart of the talk showed that it sort of works.",
    "start": "2203160",
    "end": "2209269"
  },
  {
    "text": "But now, we're going to move\non to the second question is, how does this model\narise from training?",
    "start": "2209270",
    "end": "2214920"
  },
  {
    "text": "And the key thing is\nthat remember in GPT-3, it's just trained on\nnext word prediction.",
    "start": "2214920",
    "end": "2221940"
  },
  {
    "text": "So it's not explicitly\ntraining for these tasks, which is a whole point\nof emergent behavior.",
    "start": "2221940",
    "end": "2227549"
  },
  {
    "text": "And this is really, I think, the\nharder question or conceptually harder question to ask.",
    "start": "2227550",
    "end": "2234510"
  },
  {
    "text": "So the main challenge here\nis this distribution shift. We're training on\nbasically, internet crawl,",
    "start": "2234510",
    "end": "2239970"
  },
  {
    "text": "and we're prompting\nit with examples that don't show up at training\nor even out of distribution.",
    "start": "2239970",
    "end": "2246490"
  },
  {
    "text": "So the pre-training\ndistribution is not the same as the prompting\ndistribution and can be, actually, pretty\nwildly different.",
    "start": "2246490",
    "end": "2253500"
  },
  {
    "text": "So in what settings\ncan this actually work? So we're going to try to make\nsome progress by defining",
    "start": "2253500",
    "end": "2262250"
  },
  {
    "text": "a simple model, where the\npre-training distribution and the prompting\ndistribution differ",
    "start": "2262250",
    "end": "2267650"
  },
  {
    "text": "in a well-controlled way,\nand then we're going to see if we can make some progress.",
    "start": "2267650",
    "end": "2273570"
  },
  {
    "text": "So we're going to consider\npre-training distribution as a mixture of\nHMMs, and the idea",
    "start": "2273570",
    "end": "2279590"
  },
  {
    "text": "is that you have\nthis concept, theta, that encodes, for\nexample, the topic, like,",
    "start": "2279590",
    "end": "2286160"
  },
  {
    "text": "oh, this is a Wikipedia\nbiography, let's say. And then given that,\nwhich encodes let's say,",
    "start": "2286160",
    "end": "2292760"
  },
  {
    "text": "the transitions\nof HMM, then we're going to generate\ntext from that HMM. OK? ",
    "start": "2292760",
    "end": "2300140"
  },
  {
    "text": "So to generate a document,\nyou first sample transitions from this HMM, and\nthen you're going",
    "start": "2300140",
    "end": "2305780"
  },
  {
    "text": "to sample the hidden\nstates from HMM and then the sample,\nthe emissions, given the hidden states.",
    "start": "2305780",
    "end": "2313069"
  },
  {
    "text": "OK? And then you get your text and\nyou remember, you hide theta because you don't\nsee it, but that's",
    "start": "2313070",
    "end": "2320360"
  },
  {
    "text": "the data-generating process\nfor the pre-training data.",
    "start": "2320360",
    "end": "2325460"
  },
  {
    "text": "So now, let's think about\nwhat language modeling would try to do, if it's asked\nto just predict this text.",
    "start": "2325460",
    "end": "2332900"
  },
  {
    "text": "I would argue that it implicitly\nhas to infer the target concept somehow.",
    "start": "2332900",
    "end": "2339950"
  },
  {
    "text": "I know this is a little bit\nhand wavy, but bear with me. So if you have this article\nabout Albert Einstein,",
    "start": "2339950",
    "end": "2346340"
  },
  {
    "text": "it kind of needs to\nfigure out, OK, well, this is probably like a Wikipedia\nbiography and invoke--",
    "start": "2346340",
    "end": "2353307"
  },
  {
    "text": "I'm going to generate\nthings that look like Wikipedia biographies. So the LM will probably\ntry to implicitly infer",
    "start": "2353307",
    "end": "2360170"
  },
  {
    "text": "theta, approximately\nsomehow and then try to sample from the HMM.",
    "start": "2360170",
    "end": "2366470"
  },
  {
    "text": "So of course, the Transformer\nis not literally doing this, but this is just\nkind of a cartoon",
    "start": "2366470",
    "end": "2371839"
  },
  {
    "text": "of what it might be thinking.  OK, now, what about the\nprompting distribution?",
    "start": "2371840",
    "end": "2377330"
  },
  {
    "text": "We're going to find the\nprompting distribution as, we're going to choose a\ntarget concept, theta star,",
    "start": "2377330",
    "end": "2384320"
  },
  {
    "text": "so we're going to fix it. And then we're going to\ngenerate from the HMM, but we're going to break it\nup into independent pieces.",
    "start": "2384320",
    "end": "2392410"
  },
  {
    "text": "And here, we can have\nAlbert Einstein was German, delimiter, Gandhi was an Indian,\ndelimiter, and so on, right?",
    "start": "2392410",
    "end": "2402089"
  },
  {
    "text": "So this part is\ngenerated from the HMM, and then once you\nhit a delimiter, you reset and go back to\nsort of the initial state",
    "start": "2402090",
    "end": "2409620"
  },
  {
    "text": "and you generate from\nHMM again, and you reset and you generate\nfrom HMM again, OK?",
    "start": "2409620",
    "end": "2415450"
  },
  {
    "text": "So this distribution is\ndifferent from the training",
    "start": "2415450",
    "end": "2420780"
  },
  {
    "text": "distribution because\nit has, basically, these restarts as opposed\nto one, long continuous HMM.",
    "start": "2420780",
    "end": "2428099"
  },
  {
    "text": "And this corresponds to\nthe fact that, in general, in documents, you have topical\ncoherence and Albert Einstein,",
    "start": "2428100",
    "end": "2435900"
  },
  {
    "text": "you do have a Wikipedia\npage of Albert Einstein, and then in these\nin-context examples,",
    "start": "2435900",
    "end": "2441150"
  },
  {
    "text": "you're sort of quickly\nchanging the topic. It's still an HMM, but you're\nresetting the topic in a sense,",
    "start": "2441150",
    "end": "2449980"
  },
  {
    "text": "OK?  So now, the question is, what\nwill the language model do",
    "start": "2449980",
    "end": "2458930"
  },
  {
    "text": "on this prompting distribution? And what you would like,\nwhat you would hope",
    "start": "2458930",
    "end": "2466297"
  },
  {
    "text": "is that the language\nmodel could still infer this target\nconcept, and then it",
    "start": "2466297",
    "end": "2471839"
  },
  {
    "text": "can generate from this HMM. And then if it knows\ntheta star, then you would be done, because\nthis is Marie Curie was Polish,",
    "start": "2471840",
    "end": "2481830"
  },
  {
    "text": "it's just joining from HMM. But the difficulty is the\ndistribution mismatch.",
    "start": "2481830",
    "end": "2487920"
  },
  {
    "text": "You're now going to condition\nthis language model on samples from the prompt distribution.",
    "start": "2487920",
    "end": "2493903"
  },
  {
    "text": "And remember, the\nprompting distribution is different from the\ntraining distribution. ",
    "start": "2493903",
    "end": "2501640"
  },
  {
    "text": "So that's the\ntechnical hurdle here. Otherwise, it should\nbe clear that it works",
    "start": "2501640",
    "end": "2509890"
  },
  {
    "text": "from standard Bayesian theory. Yeah. Didn't Markov model\nusually, my understanding",
    "start": "2509890",
    "end": "2516369"
  },
  {
    "text": "was that you make\nobservations, and there's like a hidden\nstate or something?",
    "start": "2516370",
    "end": "2522270"
  },
  {
    "text": "So you get a sequence\nof observations, and there's like\na hidden sequence of states or something?",
    "start": "2522270",
    "end": "2527740"
  },
  {
    "text": "Yeah. But here, it seems\nlike theta is playing the role of the\nhidden information, but there is also hidden--",
    "start": "2527740",
    "end": "2533670"
  },
  {
    "text": " can we re-word something\nlike there is also",
    "start": "2533670",
    "end": "2539443"
  },
  {
    "text": "a hidden state that's\nevolving in the background too [INAUDIBLE]? So the question is, what are\nthe hidden states in the HMM?",
    "start": "2539443",
    "end": "2546570"
  },
  {
    "text": "I haven't shown them here,\nbut you can think about--",
    "start": "2546570",
    "end": "2552150"
  },
  {
    "text": "let's see what's the best? Theta is defining the\ntransition probabilities of HMM.",
    "start": "2552150",
    "end": "2557880"
  },
  {
    "text": "And then the way you sample this\ntext is you have a hidden state and you transition according\nto the probabilities specified",
    "start": "2557880",
    "end": "2565170"
  },
  {
    "text": "by theta, and then you emit,\ngiven those hidden states. So I haven't shown them\nbecause they might not",
    "start": "2565170",
    "end": "2573000"
  },
  {
    "text": "be interpretable. You can think about\nthis, basically, let's say, 1 through 50\nhidden states or something.",
    "start": "2573000",
    "end": "2581339"
  },
  {
    "start": "2581339",
    "end": "2586390"
  },
  {
    "text": "So the key challenge here is\nthat the prompt distribution is different from the\npre-training distribution,",
    "start": "2586390",
    "end": "2591640"
  },
  {
    "text": "and here's a visualization.",
    "start": "2591640",
    "end": "2597430"
  },
  {
    "text": "So in the in-context\nlearning examples, you have transitions\naccording to HMM, and then, which are in\ndistribution, so that's great.",
    "start": "2597430",
    "end": "2605793"
  },
  {
    "text": "And then you have these\nlow-probability transitions, where you're like,\nhere's delimiter, and then I'm going to start\ngoing from Einstein to Gandhi",
    "start": "2605793",
    "end": "2613750"
  },
  {
    "text": "all of a sudden. So those are low probability\nunder the language model because you just don't\nsee this kind of text",
    "start": "2613750",
    "end": "2622000"
  },
  {
    "text": "too often at training time. ",
    "start": "2622000",
    "end": "2627275"
  },
  {
    "text": "OK. So then what can you do? So here is maybe the\nmost technical slide. This is just still a sketch.",
    "start": "2627275",
    "end": "2633160"
  },
  {
    "text": "So we proved a result,\nwhich makes assumption. And the assumption\nintuitively is, the signal",
    "start": "2633160",
    "end": "2641320"
  },
  {
    "text": "that you get about\ntheta, so the difference between the true concept\nand any other concept who",
    "start": "2641320",
    "end": "2650290"
  },
  {
    "text": "is measured by the\nobservation distribution, has to be larger than\nthis error that you",
    "start": "2650290",
    "end": "2656800"
  },
  {
    "text": "get from these\nlow-probability transitions. So these transitions are the\nsource of distribution shift,",
    "start": "2656800",
    "end": "2664410"
  },
  {
    "text": "and if you can bound the\ndistribution shift in terms of some separation, then we\nshow that as in-context learning",
    "start": "2664410",
    "end": "2674250"
  },
  {
    "text": "works in the sense that\nas a number of examples k goes to infinity, then\nin-context like this language",
    "start": "2674250",
    "end": "2685620"
  },
  {
    "text": "model, will ultimately\npredict the right thing. ",
    "start": "2685620",
    "end": "2691420"
  },
  {
    "text": "So it's a asymptotic result,\nbut this is sort of the type. So notice that if you didn't\nhave this distribution",
    "start": "2691420",
    "end": "2697660"
  },
  {
    "text": "mismatch, this would just\nfollow through standard Bayesian asymptotics, and\nthat would be fine.",
    "start": "2697660",
    "end": "2703780"
  },
  {
    "text": "So the key thing is that now\nyou have this error that you have to account for, and\nunder some conditions,",
    "start": "2703780",
    "end": "2709540"
  },
  {
    "text": "this still works. ",
    "start": "2709540",
    "end": "2715220"
  },
  {
    "start": "2715000",
    "end": "3912000"
  },
  {
    "text": "So maybe some practical\ntakeaways from the theory are--",
    "start": "2715220",
    "end": "2721130"
  },
  {
    "text": "and you don't need the theory to\nmake these practical takeaways, but it's maybe good to\nunderstand these takeaways",
    "start": "2721130",
    "end": "2726230"
  },
  {
    "text": "and the concept\nof this theory is that making the prompting\ndistribution as close to the training\ndistribution helps.",
    "start": "2726230",
    "end": "2734180"
  },
  {
    "text": "And you see that\na large literature on prompting basically\ntries to finagle things, so that's the case.",
    "start": "2734180",
    "end": "2739670"
  },
  {
    "text": "For example, if you\nwant to know capitals, then you try to say Berlin\nis the capital of Germany",
    "start": "2739670",
    "end": "2745880"
  },
  {
    "text": "and so on, using\nnatural language, so it looks more\nin distribution, so this is a kind of\na prompting trick.",
    "start": "2745880",
    "end": "2752690"
  },
  {
    "text": "So you generally want to\nuse the delimiters that are like new lines\nor pounds that",
    "start": "2752690",
    "end": "2760580"
  },
  {
    "text": "don't increase the probability\nof inferring the wrong concept. So through this latent concept\nview, what you're basically",
    "start": "2760580",
    "end": "2767150"
  },
  {
    "text": "doing is that every time you\nthink about inferring HMM, every time you're\ntransitioning, this",
    "start": "2767150",
    "end": "2773180"
  },
  {
    "text": "is sort of confusing the model. And if you have,\ninstead of a new line, you say something like\nbirth date, that's",
    "start": "2773180",
    "end": "2780260"
  },
  {
    "text": "going to really confuse the\nmodel, so don't do that. Using something\nneutral is helpful.",
    "start": "2780260",
    "end": "2787830"
  },
  {
    "text": "So then now, I'm going to switch\ninto some empirical studies here.",
    "start": "2787830",
    "end": "2793640"
  },
  {
    "text": "The first is we\nbuilt a data set, generative in-context\nlearning data set,",
    "start": "2793640",
    "end": "2798740"
  },
  {
    "text": "and the goal is to\nhave something small, so we can run experiments and\nstudy things without waiting",
    "start": "2798740",
    "end": "2805580"
  },
  {
    "text": "weeks to train large models. And so there's a\npre-training distribution",
    "start": "2805580",
    "end": "2811760"
  },
  {
    "text": "of 1,000 documents. Each document is just one, long\nsequence, a sample from HMM,",
    "start": "2811760",
    "end": "2817670"
  },
  {
    "text": "and it basically\nlooks like this, so it's sort of gibberish.",
    "start": "2817670",
    "end": "2824450"
  },
  {
    "text": "And the prompting\ndistribution is concatenating independent examples.",
    "start": "2824450",
    "end": "2830069"
  },
  {
    "text": "So it's basically the same\ndistribution of gibberish punctuated by these delimiters.",
    "start": "2830070",
    "end": "2836336"
  },
  {
    "text": "OK?  So we train\nTransformers and LSTMs",
    "start": "2836336",
    "end": "2843119"
  },
  {
    "text": "on the pre-training\ndistribution, which is just these documents,\nand then conditioned",
    "start": "2843120",
    "end": "2849030"
  },
  {
    "text": "on this prompting\ndistribution and see if it could predict the right answer. And as a number of in-context\nexamples increases,",
    "start": "2849030",
    "end": "2856090"
  },
  {
    "text": "we see that the\nTransformer improves, so k here is the\nlength of an example.",
    "start": "2856090",
    "end": "2863530"
  },
  {
    "text": "So here, the k is\n3, for example. ",
    "start": "2863530",
    "end": "2869990"
  },
  {
    "text": "And then we see that as the\nlength of example increases, then things get better.",
    "start": "2869990",
    "end": "2875810"
  },
  {
    "text": "This should be natural\nbecause the more lengthier the in-context\nexamples here are,",
    "start": "2875810",
    "end": "2882290"
  },
  {
    "text": "then the more in distribution\nthis prompting distribution looks.",
    "start": "2882290",
    "end": "2888650"
  },
  {
    "text": "And here, LSTMs are\nactually doing a little bit within Transformers,\nwhich might be also, natural because this data\nset is, basically, like HMM.",
    "start": "2888650",
    "end": "2897920"
  },
  {
    "text": "I mean, it's a mixture of HMM,\nso it's not exactly an HMM, but it has a temporal\nsequence, and maybe that",
    "start": "2897920",
    "end": "2904760"
  },
  {
    "text": "matches the inductive\nbias of LSTMs better than Transformers,\nwhich have to work harder. ",
    "start": "2904760",
    "end": "2912549"
  },
  {
    "text": "Effective modeling scale. So I think the\nscale is, obviously,",
    "start": "2912550",
    "end": "2918370"
  },
  {
    "text": "a top-of-mind question. Yeah, question? So when k equals 8, I think\nit's which one will do better,",
    "start": "2918370",
    "end": "2924930"
  },
  {
    "text": "almost a question\nof k equals 10? From the Transformer example,\nwe have zero explanation",
    "start": "2924930",
    "end": "2931888"
  },
  {
    "text": "why that is? So the question\nis, as k increases, it seems like this is\ncatching up with k equals 10.",
    "start": "2931888",
    "end": "2939850"
  },
  {
    "text": " I think it's just a\ndiminishing gains that you",
    "start": "2939850",
    "end": "2946180"
  },
  {
    "text": "get because 8 and 10\naren't that different, but going from 3 to 5 is\nalmost like doubling the size.",
    "start": "2946180",
    "end": "2953470"
  },
  {
    "text": "And if k equals\n1, then you really don't have much information.",
    "start": "2953470",
    "end": "2958544"
  },
  {
    "text": "[INAUDIBLE]  Yeah, there's some\nnoise here, so yeah.",
    "start": "2958544",
    "end": "2967510"
  },
  {
    "text": " So what happens when you\nincrease the model scale?",
    "start": "2967510",
    "end": "2974089"
  },
  {
    "text": " No, the common refrain is\nthat when models get better,",
    "start": "2974090",
    "end": "2982220"
  },
  {
    "text": "things get better. But one thing that's interesting\nis that the in-context accuracy",
    "start": "2982220",
    "end": "2987830"
  },
  {
    "text": "will get better as you improve\nthem, increase the model size, let's say, from 12 to 16,\nbut the validation loss",
    "start": "2987830",
    "end": "2995570"
  },
  {
    "text": "or the pre-training\nloss is the same. So this is sort of\ninteresting because you're not",
    "start": "2995570",
    "end": "3003619"
  },
  {
    "text": "fitting the data better\nby using a larger model.",
    "start": "3003620",
    "end": "3010290"
  },
  {
    "text": "We don't really understand why\nthis is the case, but maybe just a hypothesizing\nmaybe, there's",
    "start": "3010290",
    "end": "3016609"
  },
  {
    "text": "inductive bias for\nin-context learning that improves with model size. Not really sure.",
    "start": "3016610",
    "end": "3022190"
  },
  {
    "text": " Then we're trying to sort of see\nwhether this data set captures",
    "start": "3022190",
    "end": "3031710"
  },
  {
    "text": "a lot of the phenomena that\nyou see in the literature. So there's this peculiar\nthing in the GPT-3 paper",
    "start": "3031710",
    "end": "3037590"
  },
  {
    "text": "that 0-shot is sometimes better\nthan 1-shot for some data sets. And you see the same thing\nhappened in June as well,",
    "start": "3037590",
    "end": "3049300"
  },
  {
    "text": "which is sort of interesting.  There's a paper that did a\nreally interesting experiment.",
    "start": "3049300",
    "end": "3061210"
  },
  {
    "text": "So this is for the skeptics of\nin-context learning, like, OK, are you actually doing\nin-context learning or not.",
    "start": "3061210",
    "end": "3066970"
  },
  {
    "text": "Yeah, question? Is the reason why 0-shot\nlearning is better than 1-shot learning, that the\nmost [INAUDIBLE]",
    "start": "3066970",
    "end": "3073260"
  },
  {
    "text": "answer of the first\ninitial example? For some of the\nmultiple choice, I can see that maybe\nthe answer is B,",
    "start": "3073260",
    "end": "3080042"
  },
  {
    "text": "the [INAUDIBLE] is\nover that answer, or if it's a [INAUDIBLE].",
    "start": "3080042",
    "end": "3085049"
  },
  {
    "text": "Yeah, so the question is, is\n0-shot better than 1-shot just simply because the model\nis copying the last answer.",
    "start": "3085050",
    "end": "3092520"
  },
  {
    "text": "And that's generally,\nI think, what happens, because you have\nonly one example, then so the model\ncan't really tell",
    "start": "3092520",
    "end": "3099060"
  },
  {
    "text": "the difference between the\nconstant function, where I always want to output\nthat's answer versus actually,",
    "start": "3099060",
    "end": "3104790"
  },
  {
    "text": "doing some in-context learning. Yeah. ",
    "start": "3104790",
    "end": "3113099"
  },
  {
    "text": "So this is an\ninteresting experiment. So they took the\nsentiment data set,",
    "start": "3113100",
    "end": "3120420"
  },
  {
    "text": "and what they did was\njust randomize the labels. So I'm just going to randomly\nreplace positive, neutral,",
    "start": "3120420",
    "end": "3127099"
  },
  {
    "text": "and negative with\nsome other labels. And then you see if in-context\nlearning still works.",
    "start": "3127100",
    "end": "3134260"
  },
  {
    "text": "So if you were doing normal\nlearning, this would be crazy. You would just\ncompletely get destroyed because there's no signal.",
    "start": "3134260",
    "end": "3141369"
  },
  {
    "text": "But what they found across\na bunch of different models and tasks and data\nsets is that the amount",
    "start": "3141370",
    "end": "3149430"
  },
  {
    "text": "of drop that you get from gold\nlabels versus random labels is actually not that much.",
    "start": "3149430",
    "end": "3155640"
  },
  {
    "text": "And sometimes-- I don't\nknow why this increases, but GPT-3, it dips very\nlittle compared to not having",
    "start": "3155640",
    "end": "3161580"
  },
  {
    "text": "demonstrations at all. So this is sort of interesting. So clearly, in-context learning,\nsort of different from normal,",
    "start": "3161580",
    "end": "3170130"
  },
  {
    "text": "supervised learning. One way you can kind of see\nthis through the Bayesian lens",
    "start": "3170130",
    "end": "3179340"
  },
  {
    "text": "is that in-context\ninputs help us nail down what the\ntarget concept is,",
    "start": "3179340",
    "end": "3185460"
  },
  {
    "text": "despite the noisy labels. So you're still\nconditioning on x. So that's giving you valid\ninformation about theta,",
    "start": "3185460",
    "end": "3193089"
  },
  {
    "text": "and the only problem is that\nthese y's are now just junk, but this is where it's a\nlittle bit speculative.",
    "start": "3193090",
    "end": "3200329"
  },
  {
    "text": "Maybe because there's noise,\nthere's no information in them,",
    "start": "3200330",
    "end": "3205550"
  },
  {
    "text": "so certainly, if\nyou were missing the y's, then that's\nstrictly better, because you're able to\ninfer the task better",
    "start": "3205550",
    "end": "3211800"
  },
  {
    "text": "and then you can predict. And if they're random, maybe\nthat's like marginalized. I mean, not mathematically, but\nthat's the sort of intuition",
    "start": "3211800",
    "end": "3219080"
  },
  {
    "text": "that you're conditioning on x's\nand the y's are just random, so they're kind of ignored.",
    "start": "3219080",
    "end": "3226140"
  },
  {
    "text": "So this is maybe one example\nwhere the Bayesian inference perspective gives you\na little bit of insight",
    "start": "3226140",
    "end": "3232250"
  },
  {
    "text": "into this empirical phenomenon. Here's another example\nthat we don't explain,",
    "start": "3232250",
    "end": "3239549"
  },
  {
    "text": "so this is very similar. So here, let's pose\nin-context examples are",
    "start": "3239550",
    "end": "3245240"
  },
  {
    "text": "the task is to predict whether\nsomething is a sport, animal,",
    "start": "3245240",
    "end": "3250640"
  },
  {
    "text": "or plant or vegetable, and\nthe labels have been shuffled.",
    "start": "3250640",
    "end": "3255680"
  },
  {
    "text": "So they're not\nrandom, but they're deterministically shuffled.",
    "start": "3255680",
    "end": "3262280"
  },
  {
    "text": "And in this case,\nGPT-3 is actually able to respect that shuffling.",
    "start": "3262280",
    "end": "3270600"
  },
  {
    "text": "So this is something that's\nnot captured by our framework, because this is more of an\nabstract reasoning capability",
    "start": "3270600",
    "end": "3278569"
  },
  {
    "text": "that GPT-3 has, where\nit's able to associate--",
    "start": "3278570",
    "end": "3284120"
  },
  {
    "text": "basically, do variable binding. Basically, sport\nis just a variable that has a particular\nmeaning in this context,",
    "start": "3284120",
    "end": "3290570"
  },
  {
    "text": "and I'm going to\nuse it consistently to mean that thing, which is\nsort of really cool if you",
    "start": "3290570",
    "end": "3296240"
  },
  {
    "text": "think about it. Despite the strong prior\nthat sport is sport.",
    "start": "3296240",
    "end": "3301760"
  },
  {
    "text": "Now, in this context,\nit's, I guess, vegetable. So mysteries.",
    "start": "3301760",
    "end": "3308170"
  },
  {
    "text": "OK. Let me try to\nsummarize this section.",
    "start": "3308170",
    "end": "3314030"
  },
  {
    "text": "So I want to argue that Bayesian\ninference is a useful way to think about\nin-context learning",
    "start": "3314030",
    "end": "3319240"
  },
  {
    "text": "because really, Bayesian\ninference is all about conditioning, and\nin-context learning, all you're",
    "start": "3319240",
    "end": "3324460"
  },
  {
    "text": "doing is conditioning on\nyour in-context examples. And in Bayesian\ninference, the key object",
    "start": "3324460",
    "end": "3331390"
  },
  {
    "text": "is a posterior\npredictive distribution, which is exactly the\nthing that you're",
    "start": "3331390",
    "end": "3337090"
  },
  {
    "text": "trying to approximate when\nyou're training a model to do in-context learning.",
    "start": "3337090",
    "end": "3343460"
  },
  {
    "text": "The main challenge is\nto analyze the case where the pre-training and\nthe prompting distribution",
    "start": "3343460",
    "end": "3349580"
  },
  {
    "text": "are just different. We showed some kind of\nmild, theoretical progress",
    "start": "3349580",
    "end": "3354589"
  },
  {
    "text": "by, if you bound the errors\nof the low-probability transitions, then you can\nprove something reasonable.",
    "start": "3354590",
    "end": "3363260"
  },
  {
    "text": "One important note is that\nall of these results here in the second part of\ntalk, are independent of the architecture.",
    "start": "3363260",
    "end": "3371020"
  },
  {
    "text": "And I think this is interesting\nbecause now, understanding in-context learning,\nthrough this lens,",
    "start": "3371020",
    "end": "3377970"
  },
  {
    "text": "is all about understanding\nthe differences between the pre-training\ndistribution",
    "start": "3377970",
    "end": "3383700"
  },
  {
    "text": "and the prompting distribution,\nwhich you have analytical. So there's no sample complexity. It's just like these\ntwo distributions,",
    "start": "3383700",
    "end": "3390570"
  },
  {
    "text": "and what happens if\nyou condition on a draw from an OD distribution and\nask the model to predict",
    "start": "3390570",
    "end": "3397920"
  },
  {
    "text": "on your IID distribution. And this might be useful for\nunderstanding the role of data,",
    "start": "3397920",
    "end": "3406410"
  },
  {
    "text": "because if you think\nabout the role of data, you want to solve these tasks,\nyou have the web corpora.",
    "start": "3406410",
    "end": "3412530"
  },
  {
    "text": "Maybe there's a way\nto use this framework to understand data distributions\nand their relationships.",
    "start": "3412530",
    "end": "3419230"
  },
  {
    "text": "And we also have this\nsmall synthetic data set, which is based on a mixture\nof HMMs, which, hopefully,",
    "start": "3419230",
    "end": "3426060"
  },
  {
    "text": "can allow you to run experiments\nreally quickly and assess and answer some questions.",
    "start": "3426060",
    "end": "3432880"
  },
  {
    "text": "So to wrap it up, we looked\nat two different projects.",
    "start": "3432880",
    "end": "3439089"
  },
  {
    "text": "One is to understand\nwhether Transformers can do in-context learning of a\nfunction class, and the second,",
    "start": "3439090",
    "end": "3447630"
  },
  {
    "text": "thinking about in-context\nlearning as Bayesian inference.",
    "start": "3447630",
    "end": "3453220"
  },
  {
    "text": "So final slide here. So in terms of\nlearning is, I think, one of these great\nmysteries, I think,",
    "start": "3453220",
    "end": "3459210"
  },
  {
    "text": "that we have in modern AI. And it's sort of becoming\na foundation for many AI",
    "start": "3459210",
    "end": "3464310"
  },
  {
    "text": "applications. So people are using\nthem to just build new application\nand increasingly,",
    "start": "3464310",
    "end": "3469799"
  },
  {
    "text": "applications that didn't exist\nbefore because you can kind of spin them up so quickly. And I think understanding\nis certainly lacking,",
    "start": "3469800",
    "end": "3478109"
  },
  {
    "text": "and I think it's\nkey to both making scientific progress, but also,\nengineering better systems.",
    "start": "3478110",
    "end": "3485582"
  },
  {
    "text": "Because these in-context\nlearning systems are not reliable, right? We don't understand how they\nwork, and sometimes they work,",
    "start": "3485582",
    "end": "3492760"
  },
  {
    "text": "sometimes they don't. And this talk takes\na particular view",
    "start": "3492760",
    "end": "3498600"
  },
  {
    "text": "that synthetic setups can help\nus more rigorously explore.",
    "start": "3498600",
    "end": "3503740"
  },
  {
    "text": "So I think it's also valuable\nto run real experiments on real data, and we're\ndoing a bunch of that,",
    "start": "3503740",
    "end": "3510480"
  },
  {
    "text": "but there's only so much handle\nyou can get on what's going on. And I think we've\ngotten a few insights",
    "start": "3510480",
    "end": "3517350"
  },
  {
    "text": "into the role of\nmodel architectures and the role of data solutions\nby focusing on this much",
    "start": "3517350",
    "end": "3522750"
  },
  {
    "text": "more controlled setting. And now, the big open\nquestion is, what of this",
    "start": "3522750",
    "end": "3528630"
  },
  {
    "text": "can you link up with the\nreal-world settings, which",
    "start": "3528630",
    "end": "3534480"
  },
  {
    "text": "bring in knowledge\nand prior knowledge? And there's clearly a\nbunch of things, phenomena that are not captured here.",
    "start": "3534480",
    "end": "3541980"
  },
  {
    "text": "And there's more beyond\nin-context learning. So there's other\nemerging phenomenon such as chain of thought,\nability to do arithmetic,",
    "start": "3541980",
    "end": "3550440"
  },
  {
    "text": "a lot of other things\nthat are hidden inside these large\nlanguage models, which are waiting to\nbe kind of discovered.",
    "start": "3550440",
    "end": "3557670"
  },
  {
    "text": "So it's really kind of\nexciting because it's doing scientific discovery,\nrather than purely engineering.",
    "start": "3557670",
    "end": "3564930"
  },
  {
    "text": "And maybe one final\nthought is that we're scrapping the idea of\na task, which has been",
    "start": "3564930",
    "end": "3571920"
  },
  {
    "text": "so central to machine learning. Because what these language\nmodels allow you to do is,",
    "start": "3571920",
    "end": "3579119"
  },
  {
    "text": "not just define tasks on\nthe fly, but sort of fluidly go between tasks. When you have instructions,\nwhich we haven't really",
    "start": "3579120",
    "end": "3588060"
  },
  {
    "text": "analyzed or talked about, paired\nwith maybe a few examples,",
    "start": "3588060",
    "end": "3593640"
  },
  {
    "text": "that feels like\nthat's maybe one task. But then the idea that\nit's just a language",
    "start": "3593640",
    "end": "3601880"
  },
  {
    "text": "model, it doesn't have a\nnotion of a task specifically, which means that maybe\nhaving a task-based framing",
    "start": "3601880",
    "end": "3609620"
  },
  {
    "text": "could be too limited to\nunderstand kind of truly what's",
    "start": "3609620",
    "end": "3615110"
  },
  {
    "text": "happening in the language model. So I'll end there and\nhappy to take questions.",
    "start": "3615110",
    "end": "3621440"
  },
  {
    "start": "3621440",
    "end": "3632089"
  },
  {
    "text": "Yeah. Do you think it's possible\nto use knowledge distillation to take some of the learnings\nfrom [INAUDIBLE] learning",
    "start": "3632090",
    "end": "3637645"
  },
  {
    "text": "and fine-tune [INAUDIBLE]\nand more into the fine-tuning regime?",
    "start": "3637645",
    "end": "3643870"
  },
  {
    "text": "So the question is, can you\nuse knowledge distillation to move things more into\nthe fine-tuning regime?",
    "start": "3643870",
    "end": "3649615"
  },
  {
    "text": " Well, one answer is\nthat I think there's",
    "start": "3649615",
    "end": "3656910"
  },
  {
    "text": "a great deal of interest\nin taking language models and doing additional\nfine tuning to improve",
    "start": "3656910",
    "end": "3663120"
  },
  {
    "text": "their in-context\nlearning behaviors. So this is typically\nwhat happens when people do what is called\ninstruction tuning, where",
    "start": "3663120",
    "end": "3670200"
  },
  {
    "text": "you have things that\nlook more like tasks, and this definitely helps.",
    "start": "3670200",
    "end": "3677020"
  },
  {
    "text": "And it helps quite a bit\nmore than just scaling up.",
    "start": "3677020",
    "end": "3683012"
  },
  {
    "text": "Of course, you scale\nup, and you do this. It's the best of both worlds.",
    "start": "3683012",
    "end": "3688500"
  },
  {
    "text": "I think it takes a little bit\naway the magic, in my opinion.",
    "start": "3688500",
    "end": "3693720"
  },
  {
    "text": "And for practical purposes,\nif you just want a good model, you can absolutely\ndo this, because it's",
    "start": "3693720",
    "end": "3699085"
  },
  {
    "text": "going to give you a smaller\nmodel that's more performant. But I think from a scientific\nperspective, the reason",
    "start": "3699085",
    "end": "3704770"
  },
  {
    "text": "I'm so excited about GPT-3\nis that, initially, you didn't have to do this, which\nmeans that if you didn't try",
    "start": "3704770",
    "end": "3714740"
  },
  {
    "text": "to do something, but you\nincidentally, did well on it, that means it probably can\ndo a lot of other things",
    "start": "3714740",
    "end": "3723230"
  },
  {
    "text": "beyond our imagination. So this is a principle of\ngeneralization and machine",
    "start": "3723230",
    "end": "3728540"
  },
  {
    "text": "learning that, well, if\nyou don't look at it-- I mean, of course, you\ncan fit the test set and then do really\nwell and test that.",
    "start": "3728540",
    "end": "3734040"
  },
  {
    "text": "But if you don't do\nthat and you happen to do well on the\ntest set, then you know that you can probably\ndo well on new examples.",
    "start": "3734040",
    "end": "3740600"
  },
  {
    "text": "And this is taking\nit to the meta level. If you didn't tune on any,\nI guess, in meta learning,",
    "start": "3740600",
    "end": "3748263"
  },
  {
    "text": "you could, classically,\nyou can say, OK, well, I'm not going\nto train on a task, and now, I happen to\ndo well on some tasks,",
    "start": "3748263",
    "end": "3761440"
  },
  {
    "text": "I'll probably do\nwell on other tasks. But this is going on another\nlevel, which is like, OK, there's no notion of task.",
    "start": "3761440",
    "end": "3767440"
  },
  {
    "text": "And you see some of\nthe things that GPT-3 can do, like write a poem\nin the style of Shakespeare",
    "start": "3767440",
    "end": "3774580"
  },
  {
    "text": "about in-context\nlearning or something or do derive explanations.",
    "start": "3774580",
    "end": "3779830"
  },
  {
    "text": "And so these are things\nthat explaining something",
    "start": "3779830",
    "end": "3786130"
  },
  {
    "text": "isn't a task, at least\nin a traditional sense. It's sort of a capability that's\ncoupled with other things,",
    "start": "3786130",
    "end": "3792980"
  },
  {
    "text": "and these things actually\ndo compose in a way. So I think getting\nout of the x to y",
    "start": "3792980",
    "end": "3798490"
  },
  {
    "text": "mind set could help\nyou, maybe unravel some of these other\ndeeper structures.",
    "start": "3798490",
    "end": "3804310"
  },
  {
    "text": "Of course, this talk is\ncompletely about x-y pairs, just to be clear,\nbut I think there's much more to do beyond this.",
    "start": "3804310",
    "end": "3810130"
  },
  {
    "text": " Yeah. I had a question\nabout the example",
    "start": "3810130",
    "end": "3817009"
  },
  {
    "text": "you had with the\nlabel reshuffling. You were saying how are you\nrelabeled or shuffled up",
    "start": "3817010",
    "end": "3823360"
  },
  {
    "text": "the labels for the\n[INAUDIBLE] and the force and things like that. I was able to latch\nonto that really well.",
    "start": "3823360",
    "end": "3831240"
  },
  {
    "text": "But how [INAUDIBLE]\nas the example here. Yeah. So it was pretty impressive\nthat it kind of ignored",
    "start": "3831240",
    "end": "3836940"
  },
  {
    "text": "as priors to involve\nthe most recent problem, but then I imagine that if\nthere's any label noise, that",
    "start": "3836940",
    "end": "3843950"
  },
  {
    "text": "could be used if you have\na cucumber and vegetable",
    "start": "3843950",
    "end": "3850160"
  },
  {
    "text": "and then beef to [INAUDIBLE]. And the test, would it guess\n50/50, or would it commit one?",
    "start": "3850160",
    "end": "3857674"
  },
  {
    "text": "Yeah, so the question\nis, what happens if you have noise in your labels.",
    "start": "3857675",
    "end": "3863130"
  },
  {
    "text": "I don't know. What would happen [INAUDIBLE]?  I mean, what's the\noptimal thing to do?",
    "start": "3863130",
    "end": "3869510"
  },
  {
    "text": "It's probably to\nbalance the two somehow. Like if you have just\na little bit of noise,",
    "start": "3869510",
    "end": "3875660"
  },
  {
    "text": "then maybe you would\njust ignore it. The random label\nresult shows that it's",
    "start": "3875660",
    "end": "3884180"
  },
  {
    "text": "robust to noise and labels. ",
    "start": "3884180",
    "end": "3889380"
  },
  {
    "text": "And so maybe if there's a\ndeterministic structure, where it's not random noise,\nbut if you're flipping,",
    "start": "3889380",
    "end": "3895650"
  },
  {
    "text": "then it latches\nonto that structure. But if there's no patterns\nthere, then just ignore it. That would be what I\nwould hope that happens,",
    "start": "3895650",
    "end": "3902300"
  },
  {
    "text": "and I wouldn't be\nsurprised if it happens, but no, I think you would\nneed to run a more careful experiment to know for sure.",
    "start": "3902300",
    "end": "3911030"
  },
  {
    "text": "OK. What about complex learning\nwith visual concepts? Because a lot of the\ntalk was about language",
    "start": "3911030",
    "end": "3917540"
  },
  {
    "start": "3912000",
    "end": "4668000"
  },
  {
    "text": "and a lot of metallurgy\ntraditionally has been on vision. So I'm just curious\nabout the vision,",
    "start": "3917540",
    "end": "3924197"
  },
  {
    "text": "because it's also like\ndifferent modalities, those in-context\nlearning happened in different\nmodalities, or is there",
    "start": "3924197",
    "end": "3930230"
  },
  {
    "text": "something special about\nhoping some symbols and stuff? I don't know. I'm just curious. Yeah, that's a\nreally good question.",
    "start": "3930230",
    "end": "3936150"
  },
  {
    "text": "So the question is,\nwhat about vision, and does in-context\nlearning happen in vision?",
    "start": "3936150",
    "end": "3942320"
  },
  {
    "text": "So that area is much less\ndeveloped than in language because we don't\nhave a public GPT-3",
    "start": "3942320",
    "end": "3948920"
  },
  {
    "text": "that everyone can play with. Flamingo from DeepMind,\nI guess, is a big model",
    "start": "3948920",
    "end": "3954410"
  },
  {
    "text": "that can do some in-context\nlearning for visual inputs.",
    "start": "3954410",
    "end": "3960440"
  },
  {
    "text": "But it's no has\naccess to it publicly.",
    "start": "3960440",
    "end": "3966260"
  },
  {
    "text": "I do think that\nsomething about language definitely makes\nin-context learning more natural and\neasier in the sense",
    "start": "3966260",
    "end": "3975140"
  },
  {
    "text": "that you think about\nlanguages inputs,",
    "start": "3975140",
    "end": "3980599"
  },
  {
    "text": "typically like here is\na movie, we classify it. But language is sort of also\noperating at a mental level.",
    "start": "3980600",
    "end": "3988160"
  },
  {
    "text": "That's a power of language\nis you can describe tasks. And the internet probably has\nthings that do look like tasks.",
    "start": "3988160",
    "end": "3998940"
  },
  {
    "text": "I mean, it has to, otherwise,\nit's only limits to magic, I guess. ",
    "start": "3998940",
    "end": "4007220"
  },
  {
    "text": "So there's probably a\nlot of structured things about language that make\nin-context learning work.",
    "start": "4007220",
    "end": "4013490"
  },
  {
    "text": "Now, in vision, there's no, I\ndon't think, fundamental reason",
    "start": "4013490",
    "end": "4019850"
  },
  {
    "text": "why you might not-- I guess the thing is what\nare you doing in vision?",
    "start": "4019850",
    "end": "4026690"
  },
  {
    "text": "If you're doing\nclassification, you're fundamentally going from\na continuous visual space",
    "start": "4026690",
    "end": "4032320"
  },
  {
    "text": "to some sort of label space,\nwhich is language, in a sense. ",
    "start": "4032320",
    "end": "4039160"
  },
  {
    "text": "Whereas, in language\ninputs, you're already in the language space,\nand that fluidity might help.",
    "start": "4039160",
    "end": "4045250"
  },
  {
    "text": "But I don't know if there's\nany fundamental reason you can't do in-context\nlearning in vision",
    "start": "4045250",
    "end": "4051490"
  },
  {
    "text": "or what it would look like. I mean, I guess\nyou could certainly",
    "start": "4051490",
    "end": "4057190"
  },
  {
    "text": "train models to do\nin-context learning vision. That I have a very high\nfaith in the Transformer",
    "start": "4057190",
    "end": "4063460"
  },
  {
    "text": "to learn complicated things. Whether it emerges\nnaturally from crawling",
    "start": "4063460",
    "end": "4068680"
  },
  {
    "text": "the web with a bunch of\nimages, I don't know. Really depends on your\ndata distribution. ",
    "start": "4068680",
    "end": "4076690"
  },
  {
    "text": "Chelsea. You mentioned that\nin-context learning has a lot of desirable\nproperties over fine tuning,",
    "start": "4076690",
    "end": "4083690"
  },
  {
    "text": "but it's also a\nlot less reliable. Do you think that there are ways\nto increase that reliability,",
    "start": "4083690",
    "end": "4089680"
  },
  {
    "text": "or is that just something\nmore fundamental as a result of being\nself-supervised? And are there ways to\nmake it more reliable",
    "start": "4089680",
    "end": "4096220"
  },
  {
    "text": "without getting rid of the\nnice parts about it that's not surprising? The question is, can you\nmake in-context learning",
    "start": "4096220",
    "end": "4102670"
  },
  {
    "text": "more reliable? So one answer is that if\nyou do instruction tuning,",
    "start": "4102670",
    "end": "4108873"
  },
  {
    "text": "you'll definitely\nmake it more reliable, and this is what everyone who\nis actually trying to make these work in practice do.",
    "start": "4108873",
    "end": "4115165"
  },
  {
    "text": " But you still might be concerned\nbecause, ultimately, you're",
    "start": "4115165",
    "end": "4122969"
  },
  {
    "text": "hoping that this transformer\ndoes something for you. And that part, I think, at\nleast these toy experiments",
    "start": "4122970",
    "end": "4134270"
  },
  {
    "text": "on linear regression\nshows that it's under these pretty\nclean conditions,",
    "start": "4134270",
    "end": "4140390"
  },
  {
    "text": "it can learn fairly\ncomplicated functions.",
    "start": "4140390",
    "end": "4145520"
  },
  {
    "text": "I think that now, if you\nhave 100,000 examples,",
    "start": "4145520",
    "end": "4152380"
  },
  {
    "text": "you probably don't want to\njust prompt a language model with those examples.",
    "start": "4152380",
    "end": "4158229"
  },
  {
    "text": "But then, yeah, if you\nhave a lot of examples, which you'll probably be fine\ntuning in or doing some sort",
    "start": "4158229",
    "end": "4163240"
  },
  {
    "text": "of retrieval on those anyway. So I think I guess\nmaybe what I'll",
    "start": "4163240",
    "end": "4169960"
  },
  {
    "text": "say is that future\nlearning shouldn't be reliable in the sense that\nit's massively under specified.",
    "start": "4169960",
    "end": "4177390"
  },
  {
    "text": "So I mean, you\nshouldn't expect to do that well unless you have\nstrong priors, even if you're",
    "start": "4177390",
    "end": "4186399"
  },
  {
    "text": "fine tuning, I would say,\nand in-context learning is sort of in that regime,",
    "start": "4186399",
    "end": "4191679"
  },
  {
    "text": "And empirically, I\nguess, especially",
    "start": "4191680",
    "end": "4197400"
  },
  {
    "text": "if you're doing instruct\ntuning, it's not worse. And if you're going into\na lot more examples,",
    "start": "4197400",
    "end": "4203820"
  },
  {
    "text": "then you're in a\ndifferent regime, and you should be\ndoing gradient updates.",
    "start": "4203820",
    "end": "4209625"
  },
  {
    "text": " I've lost track. Here, let's sweep the room.",
    "start": "4209625",
    "end": "4215680"
  },
  {
    "text": "I'll go with you and\nthen sweep this way. Yeah. I was just trying to\ngrasp with the game",
    "start": "4215680",
    "end": "4221230"
  },
  {
    "text": "of having the random label is. Because earlier you\ntalked about how--",
    "start": "4221230",
    "end": "4228980"
  },
  {
    "text": "do you think it might be\ncoming from the language that they used to\ndescribe the label,",
    "start": "4228980",
    "end": "4235480"
  },
  {
    "text": "and then the model was\ntrying to figure out what is of the\npassed by language",
    "start": "4235480",
    "end": "4242200"
  },
  {
    "text": "that showed up in the label? Because otherwise,\nI'm just trying",
    "start": "4242200",
    "end": "4248830"
  },
  {
    "text": "to figure out why they have\nsuch a big gain in just randomized labels.",
    "start": "4248830",
    "end": "4254170"
  },
  {
    "text": "Yeah, so the question is,\nwhy is the random labels kind of working at all?",
    "start": "4254170",
    "end": "4260329"
  },
  {
    "text": "I mean, by looking\nat the inputs, you can kind of guess\nwhat the task should",
    "start": "4260330",
    "end": "4266230"
  },
  {
    "text": "be, I guess is the answer. If you look at\nthese sentences it's like, what might someone want\nto do with these example inputs",
    "start": "4266230",
    "end": "4274270"
  },
  {
    "text": "and well, maybe,\nclassify sentiment.",
    "start": "4274270",
    "end": "4279750"
  },
  {
    "text": "And I mean, it's not obvious. It's completely\nobvious, but there has to be the thing that\nyou know what it's doing.",
    "start": "4279750",
    "end": "4288730"
  },
  {
    "text": "Or if positive,\nnegative, and neutral to go like vegetable, fruit,\nand something [INAUDIBLE]..",
    "start": "4288730",
    "end": "4298040"
  },
  {
    "text": "To finalize the words, I\nthink it should work because-- yeah, I think it will.",
    "start": "4298040",
    "end": "4304276"
  },
  {
    "text": " Well, actually, so you have\nto be a little bit careful",
    "start": "4304276",
    "end": "4309380"
  },
  {
    "text": "because if you put a fruit,\nvegetable, then the model",
    "start": "4309380",
    "end": "4318310"
  },
  {
    "text": "will probably want to generate\nfruit and vegetable, right? And then you're\nleft wondering, OK,",
    "start": "4318310",
    "end": "4324670"
  },
  {
    "text": "what does these labels mean? So yeah. ",
    "start": "4324670",
    "end": "4333119"
  },
  {
    "text": "So in the functional\nspace example, we actually had a\nfair idea that we need 20 samples\nto actually learn",
    "start": "4333120",
    "end": "4338640"
  },
  {
    "text": "the [INAUDIBLE] algorithm. So in general, how do we\nthink it will accommodate",
    "start": "4338640",
    "end": "4344812"
  },
  {
    "text": "a mode of examples that\nyou need in your prompt or to figure out\nwhat the task is? I mean, how does that make\nthe scale of the transformer?",
    "start": "4344812",
    "end": "4351810"
  },
  {
    "text": "How many example,\nshould we data prompt to actually figure out the\ntask, and does the scale matter in this?",
    "start": "4351810",
    "end": "4357989"
  },
  {
    "text": "Yeah, so the question is,\nhere, you have 20 examples, and we know that\nyou need 20 examples to learn this function.",
    "start": "4357990",
    "end": "4363639"
  },
  {
    "text": "What about in general? Certainly, for real tasks, I\nthink this is not really a-- I mean, it's a hard and\nill-defined question",
    "start": "4363640",
    "end": "4371820"
  },
  {
    "text": "because how many examples do you\nneed to know for translation. I think it depends on the\nstrength of your task prior.",
    "start": "4371820",
    "end": "4379364"
  },
  {
    "text": " One view is that, OK, GPT-3\nalready knows how to do tasks.",
    "start": "4379365",
    "end": "4385900"
  },
  {
    "text": "All you're doing in\nin-context learning is prompting, like\nif you're asking when was someone born, right?",
    "start": "4385900",
    "end": "4393100"
  },
  {
    "text": "0-shot, you don't know how\nyou want to format the date, but if you see a\nfew examples, you know what the date\nformat should be,",
    "start": "4393100",
    "end": "4399970"
  },
  {
    "text": "and that's all that's happening. So in that view, the\nnumber of examples is basically the\nnumber of examples",
    "start": "4399970",
    "end": "4405790"
  },
  {
    "text": "to figure out the\nformat of the task, but not this through semantics.",
    "start": "4405790",
    "end": "4411340"
  },
  {
    "text": "And I think that's\nnot an inaccurate view of what in-context\nlearning does,",
    "start": "4411340",
    "end": "4417700"
  },
  {
    "text": "because there's so few examples. I mean, some of these\ntasks are like crazy, and you can't really\nfigure it out unless you--",
    "start": "4417700",
    "end": "4426639"
  },
  {
    "text": "so you can think about\nthe examples are there, partly to help you figure\nout what the task is.",
    "start": "4426640",
    "end": "4432670"
  },
  {
    "text": "And for that, inputs\nalone probably do-- and outputs, I guess,\nin the task description, I'll contribute.",
    "start": "4432670",
    "end": "4439900"
  },
  {
    "text": "And then the kind of the\nreal value of the example is to really figure\nout what the format is.",
    "start": "4439900",
    "end": "4449380"
  },
  {
    "text": "And so maybe you could try\nto formulate a framework around thinking\nabout it in terms",
    "start": "4449380",
    "end": "4456010"
  },
  {
    "text": "of what is a space of\ntask and how many do you need to nail\ndown, which is maybe",
    "start": "4456010",
    "end": "4464650"
  },
  {
    "text": "very little, because there's\njust a lot of common things that people talk about.",
    "start": "4464650",
    "end": "4470330"
  },
  {
    "text": "And once you see in\ninput, you kind of know.",
    "start": "4470330",
    "end": "4475630"
  },
  {
    "text": "Like if I see text,\nif I see code, it's probably going\nto be a code question.",
    "start": "4475630",
    "end": "4480910"
  },
  {
    "text": "If I see like\nnumbers, it's probably going to be a math question. ",
    "start": "4480910",
    "end": "4486297"
  },
  {
    "text": "That gives me a lot of\ninformation about the task, and then you need to\nfigure out the format. So yeah, hopefully, that helps.",
    "start": "4486297",
    "end": "4494390"
  },
  {
    "text": "We're over time, so we get to\nmaybe take one more in there.",
    "start": "4494390",
    "end": "4499420"
  },
  {
    "text": "You're the boss. One more. I was going to return\nearlier to whether or not",
    "start": "4499420",
    "end": "4505740"
  },
  {
    "text": "the conference learning will\nwork for other modalities. I wanted your view on\nwhat counts as cheating,",
    "start": "4505740",
    "end": "4511510"
  },
  {
    "text": "so if I took Clip\nand I transformed the image into a caption using\nwhere I'm using representations",
    "start": "4511510",
    "end": "4519130"
  },
  {
    "text": "this way. And if you want to go back to\nyour example, where you were doing these analogies\nbetween words,",
    "start": "4519130",
    "end": "4525370"
  },
  {
    "text": "like the\nsports-vegetables thing, does that still count as\nin-context learning now,",
    "start": "4525370",
    "end": "4531880"
  },
  {
    "text": "for a different modality? And I'm wondering\nwhere do you think compositionality plays\na role in defining",
    "start": "4531880",
    "end": "4540820"
  },
  {
    "text": "what in-context learning is. So the question is, if you\ntook Clip and you turned",
    "start": "4540820",
    "end": "4547780"
  },
  {
    "text": "all the images into text\nand then you prompted GPT-3, would that be\nconsidered cheating,",
    "start": "4547780",
    "end": "4553389"
  },
  {
    "text": "to declare that you have\nan in-context learning system for vision?",
    "start": "4553390",
    "end": "4559250"
  },
  {
    "text": "Yeah, like you can solve\na new label [INAUDIBLE].. It's just that you're going to\ncheat the process of learning",
    "start": "4559250",
    "end": "4567610"
  },
  {
    "text": "the representation. I mean, I think it's a\nvery practical thing to do, and I think there's\na lot of work showing",
    "start": "4567610",
    "end": "4573220"
  },
  {
    "text": "that you should be\nleveraging these building blocks as components. I don't think you need to\ntrain the mega multi-modal that",
    "start": "4573220",
    "end": "4582580"
  },
  {
    "text": "does everything. I think we have language\nmodels, and people have gotten a lot of\nmileage by prompting",
    "start": "4582580",
    "end": "4589239"
  },
  {
    "text": "composition or chaining things. Socratic models from\nGoogle has this thing where",
    "start": "4589240",
    "end": "4596350"
  },
  {
    "text": "the models talk to each other. And so I think from a\nsystems perspective,",
    "start": "4596350",
    "end": "4602290"
  },
  {
    "text": "yeah, that's great. I think it's certainly\nnot answering the question",
    "start": "4602290",
    "end": "4609460"
  },
  {
    "text": "of the emergent behavior. Because it's not\nintroducing anything new.",
    "start": "4609460",
    "end": "4615375"
  },
  {
    "text": "There's nothing new to say\nabout emergent behavior, if you chain things together.",
    "start": "4615375",
    "end": "4621550"
  },
  {
    "text": "Whereas compared to this\nhypothetical experiment where you train on web pages with\nthe text and the images",
    "start": "4621550",
    "end": "4630280"
  },
  {
    "text": "and now, can you do in-context\nlearning with text and images",
    "start": "4630280",
    "end": "4635489"
  },
  {
    "text": "in maybe both directions,\ngenerating text and generating images, that's a much more\nscientifically interesting",
    "start": "4635490",
    "end": "4642270"
  },
  {
    "text": "question. And if you did that, you\nwould, again, probably, it",
    "start": "4642270",
    "end": "4648420"
  },
  {
    "text": "would lead you to some\nnew emergent behaviors that you wouldn't get if\nyou just had GPT-3 and Clip.",
    "start": "4648420",
    "end": "4658445"
  },
  {
    "text": "Well, all right, let's\nthank Percy, you guys. All right. Thanks, everyone. ",
    "start": "4658445",
    "end": "4667000"
  }
]
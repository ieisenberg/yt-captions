[
  {
    "start": "0",
    "end": "5340"
  },
  {
    "text": "Great. So, welcome to the second class.",
    "start": "5340",
    "end": "11090"
  },
  {
    "text": "Before we start, I want\nto go over just a couple more logistics. As a reminder, the\noptional homework 0",
    "start": "11090",
    "end": "17410"
  },
  {
    "text": "is due on Monday, next week. We also have a PyTorch\nreview session tomorrow.",
    "start": "17410",
    "end": "24220"
  },
  {
    "text": "I accidentally said\nthat it was at 4:00 pm on the first lecture. It's at 6:00 pm. It should say 6:00\npm everywhere.",
    "start": "24220",
    "end": "31000"
  },
  {
    "text": "And that's going\nto be over Zoom. And you can find the\ninformation about it on Canvas.",
    "start": "31000",
    "end": "39460"
  },
  {
    "text": "We also posted the\nguidelines for the project. This-- they should be\nfairly comprehensive and answer almost all your\nquestions about the project.",
    "start": "39460",
    "end": "48493"
  },
  {
    "text": "But, of course, if you\nhave any more questions about the project\nguidelines, feel free to either go to office\nhours or any of the TA office",
    "start": "48493",
    "end": "55660"
  },
  {
    "text": "hours essentially, or you could\nalso make a post on Ed about it as well.",
    "start": "55660",
    "end": "60680"
  },
  {
    "text": "We also have exciting\nnews about cloud credits. So, we were able\nto get sponsorship from Microsoft Azure to\nprovide us cloud credits.",
    "start": "60680",
    "end": "68140"
  },
  {
    "text": "And assuming the enrollment\ndoesn't change too much, we'll be able to give\neveryone around $100",
    "start": "68140",
    "end": "74230"
  },
  {
    "text": "in cloud credits for\ncompleting Homework 1, Homework 2, and the project\nif you'd like it.",
    "start": "74230",
    "end": "79420"
  },
  {
    "text": "Homework 1 and Homework\n2 are going to use a GPU. And so that's\nespecially why we're",
    "start": "79420",
    "end": "84442"
  },
  {
    "text": "going to provide the credits\nbecause not everyone has access to GPUs already. And we're going to provide\na guide for getting",
    "start": "84442",
    "end": "91120"
  },
  {
    "text": "started on Azure and so forth. And we'll provide that\nall on Monday, which is when Homework 1 is coming out.",
    "start": "91120",
    "end": "98120"
  },
  {
    "text": "Great. And then office hours\nalso start today. For instructor\noffice hours, those",
    "start": "98120",
    "end": "103510"
  },
  {
    "text": "are going to be in person. And they're just in Packard 202,\nright after Wednesday lecture.",
    "start": "103510",
    "end": "110267"
  },
  {
    "text": "We're going to post more\ninformation about office hours, as well about signing up for\nthe pre-scheduled office hours",
    "start": "110267",
    "end": "115450"
  },
  {
    "text": "and so forth on Ed in\nthe next day or so.",
    "start": "115450",
    "end": "120680"
  },
  {
    "text": "Great. Any logistical\nquestions before we start with technical content? ",
    "start": "120680",
    "end": "127490"
  },
  {
    "text": "Awesome. So, the plan for today\nis to talk primarily about Multi-Task Learning.",
    "start": "127490",
    "end": "132980"
  },
  {
    "text": "And we'll talk about the\nproblem statement, the model, the objectives, the optimization\nprocess, different challenges",
    "start": "132980",
    "end": "139910"
  },
  {
    "text": "that arise. And then we'll also go through\na case study of a real world example of Multi-Task Learning.",
    "start": "139910",
    "end": "145850"
  },
  {
    "text": "Then, if we have time, we'll\nalso cover Transfer Learning as well. I suspect that we probably\nwon't get to Transfer Learning",
    "start": "145850",
    "end": "151670"
  },
  {
    "text": "and we'll just cover\nit in a future lecture. And so the goals by the end\nof the lecture are to be able",
    "start": "151670",
    "end": "156860"
  },
  {
    "text": "to try to understand really\nthe key design choices when designing multi-task\nlearning systems,",
    "start": "156860",
    "end": "162020"
  },
  {
    "text": "also be able to understand-- if we get to transfer\nlearning, to be able to understand\nthe differences between multi-task learning\nand transfer learning",
    "start": "162020",
    "end": "167962"
  },
  {
    "text": "and the basics of\ntransfer learning. Great. So, let's start with\nmulti-task learning.",
    "start": "167962",
    "end": "173310"
  },
  {
    "text": "So, first of all, I'm going\nto introduce some notation so that we can all get on\nthe same page with respect to the notation\nthat we'll be using.",
    "start": "173310",
    "end": "180737"
  },
  {
    "text": "And this will be consistent\nthroughout the course, not just for this lecture. So, we'll consider deep\nnetworks in this course.",
    "start": "180737",
    "end": "187980"
  },
  {
    "text": "Here's an example\nof a deep network. We're going to consider\nthe input to the network to be x, the label to be y.",
    "start": "187980",
    "end": "195680"
  },
  {
    "text": "Sometimes, you'll\noverload the notation of y to also mean the\npredicted label. So, for example,\nmaybe we want to be",
    "start": "195680",
    "end": "202010"
  },
  {
    "text": "able to classify an image\nas being a tiger or a tiger cat or a lynx or and so forth.",
    "start": "202010",
    "end": "209959"
  },
  {
    "text": "x could also be a piece of text. It could be the\ntitle of a paper. And maybe you want to predict\nthe length of the paper.",
    "start": "209960",
    "end": "216170"
  },
  {
    "text": "And we will use theta\nto denote the parameters",
    "start": "216170",
    "end": "221720"
  },
  {
    "text": "of the neural network. So, this should all\nbe fairly standard. And in most places,\nwe'll use f to denote",
    "start": "221720",
    "end": "227900"
  },
  {
    "text": "the function represented\nby the neural network. And it will be representing\na probability over the label",
    "start": "227900",
    "end": "235010"
  },
  {
    "text": "space given an input, x. OK, so, this is the\nnotational setup.",
    "start": "235010",
    "end": "242450"
  },
  {
    "text": "And then in\nsingle-task learning. In single-task\nsupervised learning, we'll be given a\ndata set with x, y.",
    "start": "242450",
    "end": "249590"
  },
  {
    "text": "And we want to be\nable to minimize the-- some loss function\nover that data set as a function of\nthe model parameters.",
    "start": "249590",
    "end": "257130"
  },
  {
    "text": "So, a typical loss\nfunction might be something like\nnegative log likelihood where we want to be minimizing\nthe negative log likelihood",
    "start": "257130",
    "end": "264620"
  },
  {
    "text": "of the labels given the inputs. And this means that\nwe want our model to be able to match the\nlabels-- be able to predict",
    "start": "264620",
    "end": "271310"
  },
  {
    "text": "the labels given the inputS, x.",
    "start": "271310",
    "end": "278180"
  },
  {
    "text": "Great, so, this\nshould all be a review for the most part\nor just getting on the same page with\nrespect to notation.",
    "start": "278180",
    "end": "284000"
  },
  {
    "text": "Now, what do I mean by a task? So, last lecture, I gave\nan informal definition",
    "start": "284000",
    "end": "290090"
  },
  {
    "text": "of what a task is. And now, we'll go over more\nof a formal definition.",
    "start": "290090",
    "end": "296130"
  },
  {
    "text": "So, the intuition is that\na task will correspond to a machine learning problem. And the way that I'll formally\ndefine it will be essentially,",
    "start": "296130",
    "end": "306350"
  },
  {
    "text": "it'll correspond to\nthis tuple right here, which has a distribution\nover x, a distribution over y",
    "start": "306350",
    "end": "312650"
  },
  {
    "text": "given x, and a loss function. And essentially, each of these,\nthese two distributions p",
    "start": "312650",
    "end": "317660"
  },
  {
    "text": "are the distribution\nthat generates the data. And the reason why it's helpful\nto define a task like this",
    "start": "317660",
    "end": "325400"
  },
  {
    "text": "as something that generates\nthe data as well as a loss function over that\ndata is it means that we can sample\ncorresponding data",
    "start": "325400",
    "end": "332840"
  },
  {
    "text": "sets from those distributions. So, we can sample a training\ndata set and a test set.",
    "start": "332840",
    "end": "338480"
  },
  {
    "text": "And we'll assume that the\ntraining set and the test set are sampled IID or independently\nfrom these two distributions.",
    "start": "338480",
    "end": "345530"
  },
  {
    "text": " And I'm also going to use kind\nof Di as shorthand for Di train",
    "start": "345530",
    "end": "352030"
  },
  {
    "text": "for the training data set.  OK, and if this is a\nlittle bit confusing,",
    "start": "352030",
    "end": "357600"
  },
  {
    "text": "you could also just\nthink of a task as simply having the training\ndata set and the test set and the loss function.",
    "start": "357600",
    "end": "363150"
  },
  {
    "text": "It's helpful to think about it\nas the underlying distribution in the sense that it allows\nyou to sample these data sets",
    "start": "363150",
    "end": "369660"
  },
  {
    "text": "and potentially\nsample multiple data sets including potentially\na validation data set, for example. ",
    "start": "369660",
    "end": "378470"
  },
  {
    "text": "OK, so, that's what I'm\ngoing to define as a task. Now, what do you\ndo different-- what",
    "start": "378470",
    "end": "384880"
  },
  {
    "text": "are different multi-task\nproblems going to look like? They could look like a\nfew different things.",
    "start": "384880",
    "end": "390470"
  },
  {
    "text": "So, one example could be a\nmulti-task classification problem where the\nloss function might",
    "start": "390470",
    "end": "395530"
  },
  {
    "text": "be the same across\ndifferent tasks. For example, it might correspond\nto the cross entropy loss function.",
    "start": "395530",
    "end": "401770"
  },
  {
    "text": "But essentially, the data\ngenerating distributions will be different\nacross the tasks. So, as an example,\nmaybe you want",
    "start": "401770",
    "end": "409030"
  },
  {
    "text": "to be able to\nrecognize handwriting from different languages. And then you're still going\nto be using cross entropy loss",
    "start": "409030",
    "end": "416500"
  },
  {
    "text": "function in each of these\ncases but just the distribution over x and the distribution\nover y is going to be different.",
    "start": "416500",
    "end": "421822"
  },
  {
    "text": "Because they're\ngoing to correspond to different kinds of\ncharacters in different kinds of languages.",
    "start": "421822",
    "end": "429160"
  },
  {
    "text": "As another example, maybe you\nwant to build a spam filter and you want it\nto be personalized for different people. Different people naturally\nreceive different emails.",
    "start": "429160",
    "end": "435820"
  },
  {
    "text": "They also naturally have\na different distribution over labels. Spam for me, might be not\nspam for you, or vice versa.",
    "start": "435820",
    "end": "443307"
  },
  {
    "text": "And so, this is another\nexample where the loss function will probably be the same. It'll probably just be\ncross entropy for example.",
    "start": "443308",
    "end": "449140"
  },
  {
    "text": "But the distribution over\nx and the distribution over the labels is going to be\ndifferent for different tasks.",
    "start": "449140",
    "end": "454224"
  },
  {
    "text": " As another example,\nmaybe the loss function",
    "start": "454225",
    "end": "460750"
  },
  {
    "text": "and the distribution\nover x is going to be identical for the tasks. But you'll have\na different label space for different tasks.",
    "start": "460750",
    "end": "468020"
  },
  {
    "text": "So, for example, say you want\nto be able to look at an image and be able to detect\nwhether or not the person has",
    "start": "468020",
    "end": "473229"
  },
  {
    "text": "blue eyes or brown eyes\nor detect their hair color or something like\nthat, then the images",
    "start": "473230",
    "end": "478888"
  },
  {
    "text": "are going to be the same. You're going to have the\nsame training data set, but you'll have\ndifferent label spaces. And your goal is to\nbasically be able to predict",
    "start": "478888",
    "end": "485982"
  },
  {
    "text": "those different labels. And this is what's called\nmulti-label classification or multi-label learning.",
    "start": "485982",
    "end": "492047"
  },
  {
    "text": "Scene understanding\nis another example of this where you have a\ndata set of different scenes. And you might want\nto be able to predict",
    "start": "492047",
    "end": "498009"
  },
  {
    "text": "the depth from that\nscene or key points from that scene or surface\nnormals for that scene, OK?",
    "start": "498010",
    "end": "503530"
  },
  {
    "text": " And then there's also examples\nwhere maybe the loss function",
    "start": "503530",
    "end": "508930"
  },
  {
    "text": "varies across tasks as well. So, you might have tasks\nthat have-- some tasks that have discrete labels\nand some tasks that",
    "start": "508930",
    "end": "514990"
  },
  {
    "text": "have continuous labels. And then you might have\ndifferent loss functions that correspond to those\ndifferent kinds of labels.",
    "start": "514990",
    "end": "520150"
  },
  {
    "text": "And also, maybe you're\nin a scenario where you care about multiple\ndifferent kinds of metrics",
    "start": "520150",
    "end": "525935"
  },
  {
    "text": "and you want to be able to\noptimize all of those metrics. Sometimes this is referred to\nas multi-objective optimization.",
    "start": "525935",
    "end": "533000"
  },
  {
    "text": "Great. Any questions on what a task\nis and what multi-task learning problems look like?",
    "start": "533000",
    "end": "538570"
  },
  {
    "start": "538570",
    "end": "546890"
  },
  {
    "text": "OK. Great. So, we want to be able to\nlearn to optimize and solve",
    "start": "546890",
    "end": "554330"
  },
  {
    "text": "multi-task learning problems. And one thing that's super\nimportant in these problems is to be able to actually have\nsome sort of descriptor that",
    "start": "554330",
    "end": "562340"
  },
  {
    "text": "indicates what the task is. Yeah?  [INAUDIBLE] do you still require\nthat the loss function would",
    "start": "562340",
    "end": "568250"
  },
  {
    "text": "be able to be combined\nsomehow across tasks or if it's okay that\nthe function [INAUDIBLE]",
    "start": "568250",
    "end": "585160"
  },
  {
    "text": "So, the question is if we\nhave different loss functions across different tasks,\nare we still going to assume that they can\nbe combined in some way",
    "start": "585160",
    "end": "591558"
  },
  {
    "text": "into a single objective? So, we'll talk a little\nbit about forming the objective of these\nproblems later in the lecture,",
    "start": "591558",
    "end": "597730"
  },
  {
    "text": "but the short answer is yes. And we're going to assume that\neach of these loss functions follow the typical signature\nof the loss function",
    "start": "597730",
    "end": "603699"
  },
  {
    "text": "and that they're going to\nbe outputting a scalar value that you want to minimize. And this means that it's\nusually fairly straightforward",
    "start": "603700",
    "end": "610269"
  },
  {
    "text": "to combine them-- by, for example by summing the\nloss functions or something like that. ",
    "start": "610270",
    "end": "617825"
  },
  {
    "text": "Great, so, the question\nis, should they map to the same output space? And I guess, that's a\nlittle bit more complicated.",
    "start": "617825",
    "end": "623792"
  },
  {
    "text": "They could potentially\nmap to different spaces. And then you might\nwant to weight them in different ways,\nweight one loss function",
    "start": "623792",
    "end": "629260"
  },
  {
    "text": "higher than another\nloss function if it is basically on a\ndifferent scale, for example. ",
    "start": "629260",
    "end": "636570"
  },
  {
    "text": "Good questions.  OK, so, typically, you'll have\nsome form of task descriptor.",
    "start": "636570",
    "end": "643980"
  },
  {
    "text": "And this will essentially\ntell the model what task it's supposed to be doing. What tasks it's\nsupposed to be solving.",
    "start": "643980",
    "end": "649290"
  },
  {
    "text": "Sometimes, the task will just\nbe fairly obvious from the input x. For example, if you're trying\nto recognize characters",
    "start": "649290",
    "end": "655410"
  },
  {
    "text": "in different\nlanguages, you might be able to detect the language\nfrom the character itself and then you don't even\nneed a task descriptor.",
    "start": "655410",
    "end": "661703"
  },
  {
    "text": "But essentially,\nyou'll want to be able to have a\ndescription of the task and pass this into the\nnetwork in addition",
    "start": "661703",
    "end": "667290"
  },
  {
    "text": "to passing in the input, x.  And so now, the\nfunction that we're",
    "start": "667290",
    "end": "673980"
  },
  {
    "text": "going to be trying\nto learn is not f of y given x, but f of y given\nx comma this task descriptor.",
    "start": "673980",
    "end": "680649"
  },
  {
    "text": " So, for example, maybe you\nare given a title of a paper",
    "start": "680650",
    "end": "687639"
  },
  {
    "text": "and you want to predict\nthe length of the paper, but maybe you also want to\nproduce a summary of the paper. Or maybe you're a PhD\nstudent and you're",
    "start": "687640",
    "end": "696660"
  },
  {
    "text": "getting a lot of\nreview requests, and you also want\nto train a network to actually review\nthe paper for you as well rather than actually\nhaving to read the paper.",
    "start": "696660",
    "end": "704920"
  },
  {
    "text": "So, these might be examples\nof different tasks. And then the task\ndescriptor might be something like a one-hot\nencoding of the task index.",
    "start": "704920",
    "end": "712709"
  },
  {
    "text": "So, you could give\nit an index of 0 if you want the length of\nthe paper, an index of 1 if you want a summary of\nthe paper, or an index of 2",
    "start": "712710",
    "end": "718897"
  },
  {
    "text": "if you want to review the paper. Or if you have some metadata\nabout the different kinds of tasks that you want\nto solve, then you",
    "start": "718897",
    "end": "726000"
  },
  {
    "text": "can provide that sort of\ninformation into the network. So, if you want to essentially\nhave different tasks correspond",
    "start": "726000",
    "end": "733140"
  },
  {
    "text": "to different people,\ndifferent users, then you could pass in\ndifferent attributes or different features of\nthose users into the network.",
    "start": "733140",
    "end": "741375"
  },
  {
    "text": "You could also pass in\na language description of the task. And this is fairly common in a\nlot of NLP examples where you",
    "start": "741375",
    "end": "749130"
  },
  {
    "text": "could say give me a review of\nthe paper or give me a summary of the paper or just\nTL;DR, for example.",
    "start": "749130",
    "end": "754949"
  },
  {
    "text": "And this is often\nreferred to as prompting in the NLP literature. Yeah?",
    "start": "754950",
    "end": "761720"
  },
  {
    "text": "[INAUDIBLE] ",
    "start": "761720",
    "end": "768330"
  },
  {
    "text": "Yeah. A great question. So, the question is,\ncan you actually learn this task descriptor\nas well in the process?",
    "start": "768330",
    "end": "773800"
  },
  {
    "text": "Can you tweak it? And maybe you could actually\nget something better than a better language\ndescription of the task, for example.",
    "start": "773800",
    "end": "780000"
  },
  {
    "text": "In the standard multi-task\nlearning scenario, we will not be\nconsidering learning this. We'll just be fixing it.",
    "start": "780000",
    "end": "785610"
  },
  {
    "text": "But actually, as you start\nto learn these kinds of task descriptors, you're\nmoving a lot more towards a\nmeta-learning scenario.",
    "start": "785610",
    "end": "791282"
  },
  {
    "text": "And we'll talk about those\nin the future lectures. ",
    "start": "791282",
    "end": "799330"
  },
  {
    "text": "Cool. Another example of what\nthis task encoding could be is like a formal\nspecification of the task. ",
    "start": "799330",
    "end": "807490"
  },
  {
    "text": "OK, and then once\nyou set up your model and you're conditioning it\non your task descriptor, then at that point, you're\nessentially ready to optimize",
    "start": "807490",
    "end": "817240"
  },
  {
    "text": "and run multi-task learning. And the vanilla objective\nlooks something like this,",
    "start": "817240",
    "end": "824950"
  },
  {
    "text": "where the-- you're just kind of summing over\nyour different loss functions. So, you take the loss functions\nfor all of your tasks.",
    "start": "824950",
    "end": "830510"
  },
  {
    "text": "You have capital T tasks. And you sum them and then\noptimize your parameters",
    "start": "830510",
    "end": "836500"
  },
  {
    "text": "over the sum of\nthe loss functions. ",
    "start": "836500",
    "end": "842150"
  },
  {
    "text": "And then from here, we actually\nhave a pretty large design space for solving\nthese problems.",
    "start": "842150",
    "end": "847350"
  },
  {
    "text": "So, we can decide different\nkinds of model architectures and different ways\nof conditioning on z. We can decide do we want to\nactually change this objective?",
    "start": "847350",
    "end": "854779"
  },
  {
    "text": "This is the most vanilla\nobjective that we can consider. But there are other\nways-- other objectives that we could consider.",
    "start": "854780",
    "end": "860310"
  },
  {
    "text": "And then we also need to decide\nhow we want to optimize it. You could run a variant of\nstochastic gradient descent.",
    "start": "860310",
    "end": "865460"
  },
  {
    "text": "But there are also\nother ways that you can consider optimizing it as well. ",
    "start": "865460",
    "end": "871440"
  },
  {
    "text": "So, the model is thinking about\nhow we should condition on z and also think about what\nobjectives we should use.",
    "start": "871440",
    "end": "878670"
  },
  {
    "text": "And then ultimately how we\nshould optimize that objective. ",
    "start": "878670",
    "end": "884010"
  },
  {
    "text": "OK, so, in the bulk\nof this lecture, we'll talk about these\nthree design choices. But this will be kind of the\noverall setup of the problem.",
    "start": "884010",
    "end": "892860"
  },
  {
    "text": "Any questions on\nthe overall setup? Yeah? ",
    "start": "892860",
    "end": "899705"
  },
  {
    "text": "Sorry, can you repeat that? Can you explain kind of what\nyou mean by conditioned on z? Right. So, the question is, what do\nI mean by conditioned on z?",
    "start": "899705",
    "end": "907820"
  },
  {
    "text": "Essentially, what I mean is\njust passing z into the network. And so instead of just\npassing an x into the network,",
    "start": "907820",
    "end": "914600"
  },
  {
    "text": "you're going to pass\nin both x and z. So, by conditioning, I just\nmean passing it into the model",
    "start": "914600",
    "end": "921139"
  },
  {
    "text": "or more formally conditioning\nthe probability-- distribution given\nby the network at-- not just on x but also on z.",
    "start": "921140",
    "end": "929310"
  },
  {
    "text": "Yeah? So what's the difference here\nif I just concatenate x and z",
    "start": "929310",
    "end": "935190"
  },
  {
    "text": "and feed them into my model?  Yeah, so, essentially,\nthe vanilla setup",
    "start": "935190",
    "end": "941839"
  },
  {
    "text": "is just to concatenate x\nand z and then optimize your objective. So if you have-- you can just\nadd a feature [INAUDIBLE]..",
    "start": "941840",
    "end": "952720"
  },
  {
    "text": "Yeah, exactly. So, you can add a feature\nto your input, which is z. You can optimize it. It does turn out that\noftentimes, just concatenating",
    "start": "952720",
    "end": "960220"
  },
  {
    "text": "them and optimizing\ndoesn't work that well for a number of\nreasons, and we'll talk about why it\ndoesn't work well",
    "start": "960220",
    "end": "966760"
  },
  {
    "text": "and how we can mitigate it. Yeah? Can the output space\nvary by the [INAUDIBLE]",
    "start": "966760",
    "end": "976680"
  },
  {
    "text": "So it's possible for the\noutput spaces to be different. Yeah. So, the question is\nfor different tasks,",
    "start": "976680",
    "end": "982110"
  },
  {
    "text": "so you have different\noutput spaces. And yes. And so, that will essentially\ncome into the modeling design",
    "start": "982110",
    "end": "987640"
  },
  {
    "text": "choices. And you could\nessentially for example, have different heads of the\nnetwork, output different-- different outputs based off of--",
    "start": "987640",
    "end": "993550"
  },
  {
    "text": "based off of z. Or you could have\nit be something that's like a recurrent\nneural network that iteratively outputs\ndifferent things and decides",
    "start": "993550",
    "end": "999910"
  },
  {
    "text": "how many dimensions to use based\noff of the task descriptor.",
    "start": "999910",
    "end": "1005430"
  },
  {
    "text": "In the back? So it's a bit tangential,\nbut with the way that the objective\nis formulated, I was just curious if it's\n[INAUDIBLE] for the presence",
    "start": "1005430",
    "end": "1011920"
  },
  {
    "text": "of spurious correlates\nfor a given pass and a multitask setting\nis like lower than in like a single pass setting. ",
    "start": "1011920",
    "end": "1018360"
  },
  {
    "text": "Because the [INAUDIBLE]\nall the tasks. Right. So, the question is, does the\nmulti-task problem help with",
    "start": "1018360",
    "end": "1027240"
  },
  {
    "text": "spurious correlations-- help the model be more robust\nto spurious correlations by nature of essentially\nhaving some tasks maybe",
    "start": "1027240",
    "end": "1036869"
  },
  {
    "text": "don't have that spurious\ncorrelation and other tasks do. There isn't any work that\nformally studies this.",
    "start": "1036869",
    "end": "1044109"
  },
  {
    "text": "But the-- I guess one\nthing that I will--",
    "start": "1044109",
    "end": "1049567"
  },
  {
    "text": "we actually have\nsome ongoing research that studies something\nalong these lines. And we actually find\nthat it doesn't make",
    "start": "1049567",
    "end": "1055290"
  },
  {
    "text": "it more robust essentially. The network sort of--\noftentimes, the network will specialize for\ndifferent things.",
    "start": "1055290",
    "end": "1060820"
  },
  {
    "text": "And if one task has\nspurious correlations, it will essentially\npay attention",
    "start": "1060820",
    "end": "1066480"
  },
  {
    "text": "to those spurious correlations\neven if it shouldn't be. Yeah? So you spoke about\nthe [INAUDIBLE]",
    "start": "1066480",
    "end": "1072760"
  },
  {
    "text": "so for the [INAUDIBLE]. ",
    "start": "1072760",
    "end": "1081310"
  },
  {
    "text": "Yeah. So, we'll talk about the\nmulti-task reinforcement learning case in\nseveral lectures.",
    "start": "1081310",
    "end": "1087120"
  },
  {
    "text": "But essentially, you can think\nabout different reinforcement learning tasks with different\nMDPs with potentially",
    "start": "1087120",
    "end": "1092515"
  },
  {
    "text": "different dynamics, different\nreward functions, sometimes also different state\nspaces and action spaces depending on the problem set up.",
    "start": "1092515",
    "end": "1098760"
  },
  {
    "text": " OK, so, let's move on.",
    "start": "1098760",
    "end": "1104090"
  },
  {
    "text": "So, we have these three\ndifferent design choices. And we're going to go through\neach of these in sequence.",
    "start": "1104090",
    "end": "1110800"
  },
  {
    "text": "And we'll start with\nthe modeling choice. So, we need to be able\nto condition on the task.",
    "start": "1110800",
    "end": "1116440"
  },
  {
    "text": "We need to be able to pass\nas input the task descriptor. And for the time being, let's\njust assume that this task",
    "start": "1116440",
    "end": "1123100"
  },
  {
    "text": "descriptor is a one-hot vector,\nmeaning that for example,",
    "start": "1123100",
    "end": "1128120"
  },
  {
    "text": "if you have two tasks, you just\nencode those two tasks using vectors that look like this\nthat are just like representing",
    "start": "1128120",
    "end": "1136480"
  },
  {
    "text": "the-- representing the integers\ncorresponding to those task identifiers.",
    "start": "1136480",
    "end": "1144010"
  },
  {
    "text": "Now, I have a question\nfor you, which is that, say that if the task--",
    "start": "1144010",
    "end": "1149787"
  },
  {
    "text": "say that you have\nsomething like this. Maybe you just have two tasks. And you are representing the\ntwo tasks with this one-hot task",
    "start": "1149787",
    "end": "1156910"
  },
  {
    "text": "identifier. How should you go about passing\nas input, this task identifier,",
    "start": "1156910",
    "end": "1163900"
  },
  {
    "text": "if you want to share as little\nas possible between the two networks?",
    "start": "1163900",
    "end": "1169190"
  },
  {
    "text": "Yeah? You can basically have an\nadditional model [INAUDIBLE].. ",
    "start": "1169190",
    "end": "1175460"
  },
  {
    "text": "Yeah. Exactly. So, you could\nessentially have kind of multiple neural networks.",
    "start": "1175460",
    "end": "1181360"
  },
  {
    "text": "I'm not great at drawing\nneural networks quickly. But you could have\nmultiple neural networks and then essentially, just\nindex into those neural networks",
    "start": "1181360",
    "end": "1187930"
  },
  {
    "text": "with these two functions. And that will share essentially\nnothing between the two tasks. And the other ideas to add?",
    "start": "1187930",
    "end": "1194270"
  },
  {
    "text": "Yeah? I can pass [INAUDIBLE]. ",
    "start": "1194270",
    "end": "1199760"
  },
  {
    "text": "So each [INAUDIBLE]\nhas a different vector representation.",
    "start": "1199760",
    "end": "1204873"
  },
  {
    "text": " So, you're saying to embed this\ninto a vector representation",
    "start": "1204874",
    "end": "1211060"
  },
  {
    "text": "and then pass that\ninto the network? Yeah. So, you could definitely\ndo something like that. And essentially, if you--\nactually, if you pass this",
    "start": "1211060",
    "end": "1217106"
  },
  {
    "text": "into a linear network\nor a linear layer, it will naturally\ndo that already. But if you pass that\ninto the network",
    "start": "1217107",
    "end": "1222670"
  },
  {
    "text": "and then pass it as input\nx, then the following layers will still be shared\nbetween the two tasks.",
    "start": "1222670",
    "end": "1228674"
  },
  {
    "text": "And so, if you want to\nshare as little as possible, you could do something\ncloser to what was suggested earlier where you\nhave kind of essentially two",
    "start": "1228675",
    "end": "1235960"
  },
  {
    "text": "separate parts of the\nmodel and just index into those two separate parts\nof the model using the task identifier.",
    "start": "1235960",
    "end": "1241954"
  },
  {
    "text": " So, kind of visually\nwhat that might look like",
    "start": "1241954",
    "end": "1247110"
  },
  {
    "text": "is something like this. If you have t tasks,\nyou could essentially have t subnetworks for\neach of those tasks.",
    "start": "1247110",
    "end": "1255570"
  },
  {
    "text": "And then gate the\noutput of those networks with your one-hot\ntask identifier",
    "start": "1255570",
    "end": "1261870"
  },
  {
    "text": "to produce the label. And so, this is essentially,\nidentical to just training",
    "start": "1261870",
    "end": "1269039"
  },
  {
    "text": "the tasks independently. But the reason why\nI bring this up is that it's useful to\nunderstand that there",
    "start": "1269040",
    "end": "1276958"
  },
  {
    "text": "are kind of these two extremes. And one of the extremes is where\nyou are essentially just doing independent training. And if you do use a form\nof multiplicative gating,",
    "start": "1276958",
    "end": "1285095"
  },
  {
    "text": "the network could\nactually choose to share very little\nbetween the two tasks or between all the tasks.",
    "start": "1285095",
    "end": "1290215"
  },
  {
    "text": "Was there a question? Yeah? [INAUDIBLE] and then\njust taking the one",
    "start": "1290215",
    "end": "1299020"
  },
  {
    "text": "that matches the correct task. . Yeah. Exactly. So, we're essentially\ntaking the input,",
    "start": "1299020",
    "end": "1306105"
  },
  {
    "text": "passing it into all\nof these subnetworks and then just taking the output\nthat index is in to the task.",
    "start": "1306105",
    "end": "1311880"
  },
  {
    "text": "Of course, this is--\ncomputationally, doesn't make any sense\nbecause you're doing t times",
    "start": "1311880",
    "end": "1317309"
  },
  {
    "text": "more computation than\nwhat you need to do. It's more of a thought\nexercise than something that you would actually\ndo in practice.",
    "start": "1317310",
    "end": "1323435"
  },
  {
    "text": " Great, so, this is\nessentially a way",
    "start": "1323435",
    "end": "1328650"
  },
  {
    "text": "to do independent training of\ntasks within a single model. ",
    "start": "1328650",
    "end": "1335440"
  },
  {
    "text": "And one thing that\nyou can note is even though this is\na single network, you can view this sort of\nas a single network learning",
    "start": "1335440",
    "end": "1340890"
  },
  {
    "text": "all the tasks. There isn't any\nshared parameters. There aren't any parameters\nthat are shared between the two tasks in the sense that\nif these have completely",
    "start": "1340890",
    "end": "1348660"
  },
  {
    "text": "separate weights,\nthen the weights that are being used to\nsolve one task are completely different than\nthe weights that are being--",
    "start": "1348660",
    "end": "1354645"
  },
  {
    "text": "they are completely disjoint\nfrom the weights that are being used to solve another task. ",
    "start": "1354645",
    "end": "1361400"
  },
  {
    "text": "OK, great. And then there's also\nthe other extreme. So, that's one extreme,\nwhich is that you're sharing nothing between the two tasks.",
    "start": "1361400",
    "end": "1367810"
  },
  {
    "text": "And the other extreme is\nsomething where you essentially just concatenate z into\nthe network at some point.",
    "start": "1367810",
    "end": "1375140"
  },
  {
    "text": "And if you do\nsomething like this, especially if you concatenate\nz towards the end, then you're going to be\nsharing all of the weights",
    "start": "1375140",
    "end": "1381700"
  },
  {
    "text": "between the different tasks. And so, what I\nmean by this is you can essentially\njust concatenate z",
    "start": "1381700",
    "end": "1387260"
  },
  {
    "text": "with one of your-- the\nintermediate layers of your network. And yeah, so, you\nget the prediction.",
    "start": "1387260",
    "end": "1394120"
  },
  {
    "text": "You're running-- just\nrunning a forward pass through this network. Yeah?",
    "start": "1394120",
    "end": "1399700"
  },
  {
    "text": "If you have a large\nenough network and the tasks are\ndifferent enough, this solution would kind of\ncollapse to the previous one?",
    "start": "1399700",
    "end": "1406252"
  },
  {
    "text": "Like if the network\nstarts learning and has separate gates to\nuse based on the indexing? Yeah.",
    "start": "1406252",
    "end": "1411670"
  },
  {
    "text": "That's a great question. If you do give this a\nlarge enough network, in principle, it could\nrepresent the function",
    "start": "1411670",
    "end": "1420340"
  },
  {
    "text": "that was on the previous slide. It would need to\nlearn that and that wouldn't be the most natural\nsolution for it to learn.",
    "start": "1420340",
    "end": "1427600"
  },
  {
    "text": "But it can still represent that.  So, essentially here,\nall the parameters.",
    "start": "1427600",
    "end": "1433600"
  },
  {
    "text": "Yeah? Is there any sort of\nmulti-task learning where I know that it's\n[INAUDIBLE] the same",
    "start": "1433600",
    "end": "1439339"
  },
  {
    "text": "for different tasks, but what\nif the input modalities are the same, can you like feed\nit in to the same input. Is that still how\nmulti task [INAUDIBLE]?? ",
    "start": "1439339",
    "end": "1455059"
  },
  {
    "text": "Yeah. So the question is, what\nif different P of x's have different modalities,\nfor example.",
    "start": "1455060",
    "end": "1460299"
  },
  {
    "text": "Like, maybe one\ntask is over text. One task is over images. And in that case,\nyou can essentially form a network that takes\nas input kind of has",
    "start": "1460300",
    "end": "1467529"
  },
  {
    "text": "two legs of the network\nthat has two encoders for those different modalities. And then at some point,\ncombines them together.",
    "start": "1467530",
    "end": "1474190"
  },
  {
    "text": "That might be a scenario where\nthe tasks are very different. And you don't get\na lot of benefit from putting them together.",
    "start": "1474190",
    "end": "1479420"
  },
  {
    "text": "But at the same\ntime, it is something that you could do\nif the tasks are-- it could be helpful if the\ntasks are sufficiently related.",
    "start": "1479420",
    "end": "1484570"
  },
  {
    "text": "Yeah? [INAUDIBLE]  Yeah.",
    "start": "1484570",
    "end": "1489640"
  },
  {
    "text": "So, this is-- yeah,\nthis is training all the tasks in one network. ",
    "start": "1489640",
    "end": "1497500"
  },
  {
    "text": "OK. Great. So, I guess one side note is\nthat all the parameters are",
    "start": "1497500",
    "end": "1502960"
  },
  {
    "text": "set except for the parameters\nthat are directly following z. But this is somewhat of--\nnot a super important point.",
    "start": "1502960",
    "end": "1510190"
  },
  {
    "text": " OK, so that was\nessentially one view",
    "start": "1510190",
    "end": "1515290"
  },
  {
    "text": "on the architecture of\nmulti-task learning, where you have these kind\nof two extremes where you're sharing\nall the parameters or sharing none\nof the parameters.",
    "start": "1515290",
    "end": "1523040"
  },
  {
    "text": "Another way to view this\nis to split the parameters into shared parameters and\ntask specific parameters.",
    "start": "1523040",
    "end": "1530440"
  },
  {
    "text": "And then our objective\nlooks something like this, where you\nhave these both shared",
    "start": "1530440",
    "end": "1535960"
  },
  {
    "text": "parameters and the task\nspecific parameters. And you're trying to optimize\nthe sum of the loss functions",
    "start": "1535960",
    "end": "1541360"
  },
  {
    "text": "where of course, the loss\nfunction for one task will only affect the shared\nparameters and the parameters",
    "start": "1541360",
    "end": "1549700"
  },
  {
    "text": "for that task and won't affect\ntask specific parameters for other tasks.",
    "start": "1549700",
    "end": "1555669"
  },
  {
    "text": "And this is a pretty important\nthing to think about. Because if you do\nactually put everything",
    "start": "1555670",
    "end": "1561767"
  },
  {
    "text": "into the same network,\nthen that means that the loss function is\naffecting the shared parameters",
    "start": "1561767",
    "end": "1567070"
  },
  {
    "text": "for all of the tasks. Whereas if you do put them in\ncompletely separate networks, then the optimization ends\nup looking very different",
    "start": "1567070",
    "end": "1572980"
  },
  {
    "text": "because there aren't\nany shared parameters. ",
    "start": "1572980",
    "end": "1578520"
  },
  {
    "text": "OK, and then from this\nstandpoint choosing how to condition on z can be\nviewed as essentially",
    "start": "1578520",
    "end": "1583919"
  },
  {
    "text": "being equivalent to choosing how\nand where to share parameters. And so, if you\ncondition on z as like",
    "start": "1583920",
    "end": "1593070"
  },
  {
    "text": "the gating in the\nvery first example, then that means you're sharing\nnone of the parameters. Whereas, if you\ncondition on it later,",
    "start": "1593070",
    "end": "1598591"
  },
  {
    "text": "that means that you're sharing\nmany more of the parameters. And you'll have this more\nof a joint optimization rather than an\nindependent optimization.",
    "start": "1598592",
    "end": "1605220"
  },
  {
    "text": " OK.",
    "start": "1605220",
    "end": "1611320"
  },
  {
    "text": "So, that's essentially some\nof the basics of this sort of model architecture\nchoices and so forth.",
    "start": "1611320",
    "end": "1618565"
  },
  {
    "text": "Now, I'll just go through\nsome common choices that people use in practice\nwhen actually trying to train",
    "start": "1618565",
    "end": "1624429"
  },
  {
    "text": "these multi-task networks. And so, one common choice is to\nconcatenate like we saw before.",
    "start": "1624430",
    "end": "1632600"
  },
  {
    "text": "And what this looks like\nis you have some input. These could be activations\nor something like that",
    "start": "1632600",
    "end": "1637690"
  },
  {
    "text": "or it could just be\nthe input itself. You concatenate with--\nyou concatenate that input with the task representation, z.",
    "start": "1637690",
    "end": "1645340"
  },
  {
    "text": "And then you pass the rest\nthrough your neural network.",
    "start": "1645340",
    "end": "1651720"
  },
  {
    "text": "Yeah? It looks like that we have\na set of shared parameters and also like parameters\nfor each task. ",
    "start": "1651720",
    "end": "1658930"
  },
  {
    "text": "I was wondering if [INAUDIBLE]. ",
    "start": "1658930",
    "end": "1665760"
  },
  {
    "text": "So you're wondering if some\narchitectures kind of flexibly assign shared parameters? [INAUDIBLE] tasks.",
    "start": "1665760",
    "end": "1674740"
  },
  {
    "text": "Yeah. So, you can have networks that\nessentially dynamically choose which parameters to share and\nwhich parameters not to share.",
    "start": "1674740",
    "end": "1682290"
  },
  {
    "text": "For the purposes\nof this slide, I consider any shared\nparameters as ones that are being optimized\njointly from the very beginning",
    "start": "1682290",
    "end": "1688530"
  },
  {
    "text": "of training. And oftentimes, if you do\nhave these decisions of what to share versus what to share\nin the network and so forth,",
    "start": "1688530",
    "end": "1696030"
  },
  {
    "text": "it often has a somewhat similar\neffect as sharing all of them because the network can\nimplicitly choose to--",
    "start": "1696030",
    "end": "1702667"
  },
  {
    "text": "choose-- even if you put\neverything in a single network, it can implicitly choose to\nrepresent things independently.",
    "start": "1702667",
    "end": "1709647"
  },
  {
    "text": "So, it often has to do\nwith the optimization standpoint-- the optimization\nproblem and so forth.",
    "start": "1709647",
    "end": "1715090"
  },
  {
    "text": "But you can certainly-- there's\nactually a pretty huge design space here in terms\nof how you condition",
    "start": "1715090",
    "end": "1720630"
  },
  {
    "text": "and how you share parameters. ",
    "start": "1720630",
    "end": "1726632"
  },
  {
    "text": "Cool, so, concatenation\nbase conditioning is one approach that people\nuse fairly frequently.",
    "start": "1726632",
    "end": "1732429"
  },
  {
    "text": "Another approach is to condition\nin an additive fashion.",
    "start": "1732430",
    "end": "1737700"
  },
  {
    "text": "And the way this works is\nyou take your conditioning representation and pass\nit through a linear layer",
    "start": "1737700",
    "end": "1743910"
  },
  {
    "text": "to get an embedding of\nthat task representation, and then add that to the input\nto get the next representation.",
    "start": "1743910",
    "end": "1753010"
  },
  {
    "text": "And you can then pass the\noutput into a neural network and so forth. ",
    "start": "1753010",
    "end": "1758600"
  },
  {
    "text": "Now, these are two choices. And one thing that\nyou might notice is that these two choices\nare actually equivalent.",
    "start": "1758600",
    "end": "1766690"
  },
  {
    "text": "Can anyone tell me why\nthese are equivalent? ",
    "start": "1766690",
    "end": "1776669"
  },
  {
    "text": "Yes? They would still be passed\nthrough a neural layer anyways.",
    "start": "1776670",
    "end": "1782250"
  },
  {
    "text": "Maybe it might be added\nin a linear layer. ",
    "start": "1782250",
    "end": "1788580"
  },
  {
    "text": "Anything to add or? Yeah? Well, since you are\n[INAUDIBLE],, the same thing",
    "start": "1788580",
    "end": "1796780"
  },
  {
    "text": "would happen during [INAUDIBLE]. ",
    "start": "1796780",
    "end": "1802470"
  },
  {
    "text": "Cool. So, exactly what this\nlooks like is you have-- say you have x and z.",
    "start": "1802470",
    "end": "1808340"
  },
  {
    "text": "If you concatenate them\ninto a single vector and then you pass them through\na linear layer like this,",
    "start": "1808340",
    "end": "1815990"
  },
  {
    "text": "say that this linear\nlayer is broken up into two halves\nwith two weights.",
    "start": "1815990",
    "end": "1822710"
  },
  {
    "text": "Then this is equivalent to\nW1 times x plus W2 times z.",
    "start": "1822710",
    "end": "1830809"
  },
  {
    "text": "And this is additive\nconditioning. And this is concatenation. So, they aren't\nexactly equivalent",
    "start": "1830810",
    "end": "1837090"
  },
  {
    "text": "if you-- you basically just\nhave to break this weight matrix into these\ntwo weight matrices",
    "start": "1837090",
    "end": "1842100"
  },
  {
    "text": "to see that from\nthis standpoint, you can see the equivalence.",
    "start": "1842100",
    "end": "1849170"
  },
  {
    "text": "And here's a-- on\nthe slide, here is a diagram that\nalso illustrates that where w is broken up\ninto these two matrices",
    "start": "1849170",
    "end": "1855442"
  },
  {
    "text": "and then when you do\nthe matrix multiply, you get these two components. And then you add them two\ntogether to get this equation.",
    "start": "1855442",
    "end": "1861900"
  },
  {
    "text": "Question? Yeah, there's a question. Are there any examples\nwith algorithms that work to the extent\nto which parameters should be shared, like optimal\narchitecture for a given subset?",
    "start": "1861900",
    "end": "1867302"
  },
  {
    "text": " Yeah.",
    "start": "1867302",
    "end": "1872450"
  },
  {
    "text": "There definitely are\nalgorithms that do that. I'm not going to cover\nthem in this lecture. But the question-- person\nasking the question",
    "start": "1872450",
    "end": "1879830"
  },
  {
    "text": "can ask that on Ed, and I'm\nhappy to give them pointers. Yeah?",
    "start": "1879830",
    "end": "1885175"
  },
  {
    "text": "[INAUDIBLE] second\ncondition at all?",
    "start": "1885175",
    "end": "1893360"
  },
  {
    "text": "You're asking W2 is\nmissing a second condition? So you're saying\nthere is [INAUDIBLE]..",
    "start": "1893360",
    "end": "1900819"
  },
  {
    "text": "For me, the weight\nmatrix actually would be able to satisfy\nthe first condition before the second condition.",
    "start": "1900819",
    "end": "1908270"
  },
  {
    "text": " I guess-- so, you're\nsaying that the--",
    "start": "1908270",
    "end": "1916480"
  },
  {
    "text": "[INAUDIBLE] ",
    "start": "1916480",
    "end": "1929929"
  },
  {
    "text": "Yeah. So, for them-- in\nthese diagrams, for them to actually\nfully be equivalent, you would essentially\nneed to pass the input",
    "start": "1929930",
    "end": "1936250"
  },
  {
    "text": "through a linear layer. And, yeah, so that's something\nthat's important for them to be equivalent. Yeah.",
    "start": "1936250",
    "end": "1942279"
  },
  {
    "text": "And if the input came\nfrom a neural network and isn't the raw input,\nthen the previous layer would count as this. And-- but yeah, I\nguess this diagram",
    "start": "1942280",
    "end": "1949540"
  },
  {
    "text": "should be probably updated to\nhave the linear layer in there in the top right. ",
    "start": "1949540",
    "end": "1957430"
  },
  {
    "text": "Yeah? [INAUDIBLE] ",
    "start": "1957430",
    "end": "1963260"
  },
  {
    "text": "Right. So, I guess-- I just looked at the\nweights of this layer.",
    "start": "1963260",
    "end": "1968853"
  },
  {
    "text": "Typically, a fully\nconnected layer will have both a\nweight and a bias term. And so, if you actually include\nthat bias term right here,",
    "start": "1968853",
    "end": "1977140"
  },
  {
    "text": "you'll have a plus b here. And then if you break\nthat into b1 and b2, then you'll also have a\nkind of a plus b1 and--",
    "start": "1977140",
    "end": "1983740"
  },
  {
    "text": " actually, sorry. I guess it'll still\njust be plus b.",
    "start": "1983740",
    "end": "1990130"
  },
  {
    "text": "But yeah, so\nessentially, this is just trying to show the\nbias term essentially.",
    "start": "1990130",
    "end": "1997003"
  },
  {
    "start": "1997003",
    "end": "2003770"
  },
  {
    "text": "OK,so additive and concatenation\nare basically equivalent if you're-- if they are kind of prepended\nwith these linear layers.",
    "start": "2003770",
    "end": "2012250"
  },
  {
    "text": "And so, it's not necessarily\nworth-- essentially, the takeaway is don't\ntry both of them because you just need\nto try one of them.",
    "start": "2012250",
    "end": "2020440"
  },
  {
    "text": "They'll be-- give you\nprobably the same result. Another choice in\nterms of conditioning",
    "start": "2020440",
    "end": "2026980"
  },
  {
    "text": "is to use a multi-head\narchitecture where you have essentially\ndifferent output heads for the model.",
    "start": "2026980",
    "end": "2034040"
  },
  {
    "text": "And this can be\nespecially helpful if you have different\nlabel spaces, like one label is continuous,\none label is discrete,",
    "start": "2034040",
    "end": "2039610"
  },
  {
    "text": "and so forth.  And another common\nchoice is to use",
    "start": "2039610",
    "end": "2046333"
  },
  {
    "text": "multiplicative conditioning. So, instead of\nadding the output, you actually\nmultiply the outputs",
    "start": "2046333",
    "end": "2053169"
  },
  {
    "text": "or multiply the representation\nof the task in an element wise fashion.",
    "start": "2053170",
    "end": "2059668"
  },
  {
    "text": "Now, one thing you\nmight be wondering is, well, why might we use\nmultiplicative conditioning?",
    "start": "2059668",
    "end": "2065530"
  },
  {
    "text": "And there's a couple\nof reasons for this. One is that it's going to\nbe more expressive per layer",
    "start": "2065530",
    "end": "2072340"
  },
  {
    "text": "than additive conditioning. You can't represent this sort\nof multiplicative conditioning in a single layer if you're\njust doing concatenation.",
    "start": "2072340",
    "end": "2079510"
  },
  {
    "text": "You can actually represent\nit with multiple layers because neural networks\ncan represent any function.",
    "start": "2079510",
    "end": "2087710"
  },
  {
    "text": "But it gives you more\nexpressivity per layer. And if you also remember\nthe multiplicative gating",
    "start": "2087710",
    "end": "2093789"
  },
  {
    "text": "that we talked\nabout before, where you have these\ndifferent networks and you gate the output,\nthis sort of conditioning",
    "start": "2093790",
    "end": "2099220"
  },
  {
    "text": "can represent that\nform of gating as well. And it allows you to actually\nessentially dynamically choose",
    "start": "2099220",
    "end": "2106450"
  },
  {
    "text": "which parts of the network\nshould be used for which tasks. ",
    "start": "2106450",
    "end": "2114867"
  },
  {
    "text": "So, essentially,\nmultiplicative conditioning is a way that you can generalize\nthese independent networks as well as independent heads.",
    "start": "2114867",
    "end": "2121680"
  },
  {
    "text": "And so, you can also represent\nmultiple head architectures with this multiplicative gating. ",
    "start": "2121680",
    "end": "2129210"
  },
  {
    "text": "Yeah? [INAUDIBLE] ",
    "start": "2129210",
    "end": "2134410"
  },
  {
    "text": "Yeah. So, the question\nis, are there cases where you might apply\ndifferent conditioning to different layers.",
    "start": "2134410",
    "end": "2139605"
  },
  {
    "text": " I guess the-- one answer is that\nthe design space is very large.",
    "start": "2139605",
    "end": "2148830"
  },
  {
    "text": "And you can choose\nto really do whatever you want in the\ndesign space depending on what you find works well.",
    "start": "2148830",
    "end": "2154922"
  },
  {
    "text": "I don't think that there's\nany particular cases where it would be especially\nhelpful to have multiple kinds of conditioning.",
    "start": "2154922",
    "end": "2162257"
  },
  {
    "text": "But it's certainly kind\nof within the design space of models. ",
    "start": "2162257",
    "end": "2170978"
  },
  {
    "text": "Yeah? [INAUDIBLE] ",
    "start": "2170978",
    "end": "2187950"
  },
  {
    "text": "I don't know if it's\nmore expressive.",
    "start": "2187950",
    "end": "2193609"
  },
  {
    "text": "I think that if you do it\nat every layer, for example, I think it's strictly more\nexpressive in that sense,",
    "start": "2193610",
    "end": "2201680"
  },
  {
    "text": "in the sense that-- you can\nrepresenting conditioning by essentially having part\nof your input be like all 1s,",
    "start": "2201680",
    "end": "2208190"
  },
  {
    "text": "for example. And then, when you do\nthe multiplication then, for all 1s, then you'll get\nbasically just concatenation.",
    "start": "2208190",
    "end": "2216740"
  },
  {
    "text": "So, in that sense,\nit's more expressive if you have a high\ndimensional enough input.",
    "start": "2216740",
    "end": "2222350"
  },
  {
    "text": "But it isn't necessarily\nlike strictly more expressive given\nthe same dimensionality.",
    "start": "2222350",
    "end": "2227360"
  },
  {
    "text": "Yeah? [INAUDIBLE] ",
    "start": "2227360",
    "end": "2237740"
  },
  {
    "text": "Yeah. So, after you pass\nthis input, the-- ",
    "start": "2237740",
    "end": "2244060"
  },
  {
    "text": "after you pass as input the\nrepresentation, the task representation through\nthis linear network,",
    "start": "2244060",
    "end": "2249490"
  },
  {
    "text": "you can already think of that\nblue vector in the top right as a task representation\nor a task embedding.",
    "start": "2249490",
    "end": "2258010"
  },
  {
    "text": "Because it's-- especially\nif you have a one-hot task representation that\nyou're passing as input, then essentially, the weights\nor the rows or something of that",
    "start": "2258010",
    "end": "2269349"
  },
  {
    "text": "weight matrix-- or sorry, the columns\nof that weight matrix will essentially just be an\nembedding of each of the tasks.",
    "start": "2269350",
    "end": "2276820"
  },
  {
    "text": "And then the way that\nyou can get conditioned on that those different kinds of\nembeddings, that's essentially",
    "start": "2276820",
    "end": "2282198"
  },
  {
    "text": "what these different\nchoices correspond to. ",
    "start": "2282198",
    "end": "2288950"
  },
  {
    "text": "Cool. So, those are-- I mean, additive\nand multiplicative are essentially the most\nbasic choices of conditioning.",
    "start": "2288950",
    "end": "2295400"
  },
  {
    "text": "There's also a lot\nmore complex choices. So, here are some examples\nof different kinds",
    "start": "2295400",
    "end": "2301033"
  },
  {
    "text": "of architectures that\npeople have proposed. ",
    "start": "2301033",
    "end": "2306890"
  },
  {
    "text": "In general, I think that when\nit comes to conditioning, there isn't really any specific\nscience for how to do it.",
    "start": "2306890",
    "end": "2316640"
  },
  {
    "text": "It's often very\nproblem dependent. It's largely guided by\nintuition and knowledge about the problem and really\nmore of an art than a science.",
    "start": "2316640",
    "end": "2325980"
  },
  {
    "text": "Yeah? Can you ever condition\nat the beginning, like fully at the beginning? For example, for an image just\nadd two layers, or one layer,",
    "start": "2325980",
    "end": "2332460"
  },
  {
    "text": "wheres you have all ones,\nall zeros, or all twos, depending on which one you\nwant to work with [INAUDIBLE]?? ",
    "start": "2332460",
    "end": "2343270"
  },
  {
    "text": "Yeah. Absolutely. So, you can condition\nat the very beginning, you can condition later in\nthe network, and so forth. And the multiplicative\nand additive conditioning",
    "start": "2343270",
    "end": "2349230"
  },
  {
    "text": "that we've talked\nabout can all be applied at different\nparts of the network. And in terms of the\nintuition that I'm",
    "start": "2349230",
    "end": "2355260"
  },
  {
    "text": "talking about here,\nmaybe you have a problem where you would\nimagine that you want to process the image\ndifferently for different tasks.",
    "start": "2355260",
    "end": "2362430"
  },
  {
    "text": "And in that case,\nearlier conditioning is probably a better choice\nthan later conditioning. And like I'm saying\nhere, it's usually",
    "start": "2362430",
    "end": "2368790"
  },
  {
    "text": "something that's quite problem\ndependent and is usually based more on intuition\nand what you find works",
    "start": "2368790",
    "end": "2374220"
  },
  {
    "text": "on kind of experimentation\nrather than any sort of science that\nwill tell you exactly",
    "start": "2374220",
    "end": "2379380"
  },
  {
    "text": "what architecture to use. ",
    "start": "2379380",
    "end": "2386530"
  },
  {
    "text": "OK. Cool. So, that's it for the\nmodel architecture",
    "start": "2386530",
    "end": "2393500"
  },
  {
    "text": "for multi-task learning. The next question is how we\nshould form the objective.",
    "start": "2393500",
    "end": "2400260"
  },
  {
    "text": "And so, we talked before\nabout how we can just use this sort of vanilla\nobjective of just adding up",
    "start": "2400260",
    "end": "2405619"
  },
  {
    "text": "the task classes and optimizing. But often, we might want\nto weight different tasks",
    "start": "2405620",
    "end": "2411080"
  },
  {
    "text": "differently. And we might want to be able\nto define a weighted objective where we apply a weight, w,\nin front of the loss function",
    "start": "2411080",
    "end": "2418910"
  },
  {
    "text": "and minimize this weighted\nsum of the objectives.",
    "start": "2418910",
    "end": "2424214"
  },
  {
    "text": "And then, of\ncourse, the question comes is like how do\nyou choose this wi?",
    "start": "2424215",
    "end": "2429973"
  },
  {
    "text": "Does anyone have thoughts\non how they would go about choosing these weights? ",
    "start": "2429973",
    "end": "2439119"
  },
  {
    "text": "Would it be based on the\nsize of your data set? So you might want\nto balance that.",
    "start": "2439120",
    "end": "2445458"
  },
  {
    "text": "So would you have a higher\nweight for larger data sets or smaller data sets? Smaller weights for larger.",
    "start": "2445458",
    "end": "2450680"
  },
  {
    "text": "Smaller weights for\nlarger data sets. Yeah, [INAUDIBLE]. Cool. I guess on that note, you may--",
    "start": "2450680",
    "end": "2456788"
  },
  {
    "text": "oftentimes, the loss\nfunction, you'll want to-- for a\ngiven task, you'll want to average it\nover the data set. So, that-- so, it's not\nlarger for larger data sets",
    "start": "2456788",
    "end": "2463618"
  },
  {
    "text": "and so forth. But yeah, that makes sense. In the back? [INAUDIBLE] ",
    "start": "2463618",
    "end": "2479140"
  },
  {
    "text": "Yeah. So, the suggestion was based\non a paper on the website, you can look at what's called\nthe heteroscedastic uncertainty",
    "start": "2479140",
    "end": "2488280"
  },
  {
    "text": "of the model and use that\nto weight differently for tasks that you're very\ncertain about versus tasks",
    "start": "2488280",
    "end": "2495180"
  },
  {
    "text": "that you're less certain about. Yeah? [INAUDIBLE] scales of\nthe losses themselves.",
    "start": "2495180",
    "end": "2505540"
  },
  {
    "text": "So look at the scales of\nthe losses themselves. And if you notice that one\nloss is on a higher scale then",
    "start": "2505540",
    "end": "2510819"
  },
  {
    "text": "maybe you weight it\nlower and vice versa. Yeah? [INAUDIBLE] hyperparameter,\nwhich there is [INAUDIBLE]..",
    "start": "2510820",
    "end": "2520500"
  },
  {
    "start": "2520500",
    "end": "2532840"
  },
  {
    "text": "Yes. So you can have the\nweights themselves be hyperparameters and\noptimize those hyperparameters.",
    "start": "2532840",
    "end": "2538230"
  },
  {
    "text": "In that case, one\nquestion that comes up is, if they're\nhyperparameters, what objective are you optimizing for\nthose type of parameters?",
    "start": "2538230",
    "end": "2545310"
  },
  {
    "text": "And so, you do\neventually at some point need to have some final\nobjective even if you're going to be optimizing\nthe weights themselves.",
    "start": "2545310",
    "end": "2551849"
  },
  {
    "text": "Although you could\noptimize them with respect to the vanilla\nobjectives for example. Yeah?",
    "start": "2551850",
    "end": "2556968"
  },
  {
    "text": "[INAUDIBLE] For example, you\ngive higher weights to more low-level tasks.",
    "start": "2556968",
    "end": "2563460"
  },
  {
    "text": "And then as you [INAUDIBLE]. ",
    "start": "2563460",
    "end": "2569710"
  },
  {
    "text": "Yeah. So you could have a\ncurriculum and maybe have higher weights for\neasier tasks at the beginning and then lower weights\nfor harder tasks.",
    "start": "2569710",
    "end": "2574997"
  },
  {
    "text": "In the back? I mean, generally, you'd want to\nweight the tasks that you care about more with higher weights.",
    "start": "2574997",
    "end": "2580180"
  },
  {
    "text": "So, if you have a main task\nand maybe some auxiliary tasks that you're just doing\nto help along boarding,",
    "start": "2580180",
    "end": "2585960"
  },
  {
    "text": "then you would want\nto make those lower. Yeah. Exactly. If so some of your\ntasks, you don't really care about that\nmuch but you think",
    "start": "2585960",
    "end": "2591877"
  },
  {
    "text": "that they might be helpful as\na regularization or something, then you would want to weight\nthose lower than the main task.",
    "start": "2591877",
    "end": "2597690"
  },
  {
    "text": "One more? [INAUDIBLE] ",
    "start": "2597690",
    "end": "2608619"
  },
  {
    "text": "Yeah. Right. So, if you have a\ncollection of tasks and some are more\nsimilar than others, then if you have a\nlot of tasks that",
    "start": "2608620",
    "end": "2613978"
  },
  {
    "text": "are very similar to each\nother and some tasks are very different,\nthen you might want to weight the ones that are\ndifferent higher to kind",
    "start": "2613978",
    "end": "2619410"
  },
  {
    "text": "of counterbalance the tasks that\nare more similar to each other. Great. So, all of these are really\nI think great answers",
    "start": "2619410",
    "end": "2626661"
  },
  {
    "text": "to this question. And things that are good to do\nwhen choosing these weights. And unfortunately, like\nthe model architecture,",
    "start": "2626662",
    "end": "2633363"
  },
  {
    "text": "choosing these weights\nis often more of an art as well and more problem\ndependent and based on your intuition.",
    "start": "2633363",
    "end": "2639869"
  },
  {
    "text": "And so, you might try\nto manually determine these based on importance\nor priority or something",
    "start": "2639870",
    "end": "2645600"
  },
  {
    "text": "that you know about\nthe kinds of tasks. One thing that also came up\nis you can also dynamically",
    "start": "2645600",
    "end": "2650922"
  },
  {
    "text": "adjust these throughout\ntraining in like a curriculum or through other through\nother strategies as well.",
    "start": "2650922",
    "end": "2656579"
  },
  {
    "text": " So, I'll mention two\nthings on this slide.",
    "start": "2656580",
    "end": "2661620"
  },
  {
    "text": "There's already been\nlots of great ideas that have been mentioned. But there are various heuristics\nfor trying to weight tasks.",
    "start": "2661620",
    "end": "2668040"
  },
  {
    "text": "One example is to try\nto encourage gradients to have similar magnitudes, to\ntry to help the optimization",
    "start": "2668040",
    "end": "2674040"
  },
  {
    "text": "problem. And this would be an example\nof something that's dynamic.",
    "start": "2674040",
    "end": "2679151"
  },
  {
    "text": "And then one other\nexample that I'd like to bring up that\nactually wasn't brought up is to try to optimize for\nthe worst case task loss.",
    "start": "2679152",
    "end": "2685890"
  },
  {
    "text": "And this isn't useful\nin all scenarios. But this is useful in\nscenarios where you ultimately",
    "start": "2685890",
    "end": "2693180"
  },
  {
    "text": "care about all of the tasks. And you want to make sure\nthat all of the tasks have-- are optimized sufficiently well.",
    "start": "2693180",
    "end": "2699270"
  },
  {
    "text": "So, for example,\nmaybe different tasks correspond to different people\nthat are using your service.",
    "start": "2699270",
    "end": "2704310"
  },
  {
    "text": "And you want to be\nfair to all of them and you don't want to have\nsome users that are just the model is completely ignoring\nand some users that it's really",
    "start": "2704310",
    "end": "2711180"
  },
  {
    "text": "paying attention to. And this sort of\nworst-case task loss, which is kind of written in\nthis equation right here,",
    "start": "2711180",
    "end": "2718020"
  },
  {
    "text": "will essentially try to\noptimize for the worst case and try to make sure that\nthe worst user is still",
    "start": "2718020",
    "end": "2724440"
  },
  {
    "text": "being treated well basically\nor has a good loss function.",
    "start": "2724440",
    "end": "2730660"
  },
  {
    "text": "So, this is useful for fairness,\nfor robustness, and so forth. And so, exactly what this\nequation means is essentially,",
    "start": "2730660",
    "end": "2738780"
  },
  {
    "text": "you're going to be picking\nthe loss function that has the highest loss currently\nand optimize that one.",
    "start": "2738780",
    "end": "2746820"
  },
  {
    "text": "Actually, optimizing\nthis loss can be pretty difficult if\nyou have a lot of tasks because you might need\nit to enumerate over",
    "start": "2746820",
    "end": "2752212"
  },
  {
    "text": "all the possible tasks. And there are various kind of\napproximations and approaches for trying to optimize this\nfunction in a more tractable",
    "start": "2752212",
    "end": "2759029"
  },
  {
    "text": "way if you have a lot of tasks. ",
    "start": "2759030",
    "end": "2765440"
  },
  {
    "text": "Yeah? [INAUDIBLE] ",
    "start": "2765440",
    "end": "2778290"
  },
  {
    "text": "Yeah. So what was said that\nanother thing that you can do is not just minimize\nlosses, but also",
    "start": "2778290",
    "end": "2785030"
  },
  {
    "text": "minimize the variance of\nthe losses as well so that-- so that you are kind of trying\nto get a similar loss for all",
    "start": "2785030",
    "end": "2792770"
  },
  {
    "text": "of the tasks. I mean, there are some scenarios\nwhere that sort of thing will make sense,\nother scenarios where,",
    "start": "2792770",
    "end": "2798273"
  },
  {
    "text": "for example, if you\nhave auxiliary tasks this is probably a bad\nidea because then you'll focus a lot on the auxiliary\ntasks, potentially more",
    "start": "2798273",
    "end": "2803487"
  },
  {
    "text": "so than the main task. Yeah? I guess, really, isn't it just\nkind of difficult to train,",
    "start": "2803487",
    "end": "2808940"
  },
  {
    "text": "because if you're taking\nthe loss for a specific task and then optimizing over\nthat, that is switched",
    "start": "2808940",
    "end": "2815773"
  },
  {
    "text": "would mean the losses\nwould jump around a lot? Because [INAUDIBLE] for\nthat specific task, and then",
    "start": "2815773",
    "end": "2821738"
  },
  {
    "text": "you're switching to a\ncompletely different task because [INAUDIBLE].",
    "start": "2821738",
    "end": "2826970"
  },
  {
    "text": "Yeah. So, this will lead to a\nnon-stationary optimization problem, which I think is\nwhat you're referring to.",
    "start": "2826970",
    "end": "2832430"
  },
  {
    "text": "And that can be more\ntricky to optimize. And in general, people\nhave found-- sometimes",
    "start": "2832430",
    "end": "2839090"
  },
  {
    "text": "found this objective\nto be difficult. It does actually--\nthere are examples of it working\nquite well actually",
    "start": "2839090",
    "end": "2845810"
  },
  {
    "text": "where you have different\ndomains and you're trying to optimize for\nthe worst case domain. And people have actually shown\nthat this can actually help",
    "start": "2845810",
    "end": "2851270"
  },
  {
    "text": "robustness, especially if you\nthink that maybe at test time, your distribution over\ntasks might be changing.",
    "start": "2851270",
    "end": "2856680"
  },
  {
    "text": "Then this will help you prepare\nfor that sort of distribution shift. But it is certainly a more\ndifficult optimization problem.",
    "start": "2856680",
    "end": "2864080"
  },
  {
    "text": "And methods that have\nused this have often introduced things\nlike regularization to help stabilize it. ",
    "start": "2864080",
    "end": "2873089"
  },
  {
    "text": "Great. So, we talked about the model. And we talked about\nthe objective. The last step is just\nhow do we optimize",
    "start": "2873090",
    "end": "2879930"
  },
  {
    "text": "the objective--\noptimize the model with respect to the objective? ",
    "start": "2879930",
    "end": "2885650"
  },
  {
    "text": "So, say we have our kind of\nvanilla multitask objective.",
    "start": "2885650",
    "end": "2893000"
  },
  {
    "text": "I'll go over kind\nof the basic version of how we might optimize it. So, we have a set of tasks.",
    "start": "2893000",
    "end": "2899599"
  },
  {
    "text": "And first, we get to sample-- a mini-batch of those tasks.",
    "start": "2899600",
    "end": "2905450"
  },
  {
    "text": "And if you only have a\nsmaller number of tasks, then we get to sample\nall of the tasks. And then we'll sample a\nmini batch of data points",
    "start": "2905450",
    "end": "2913340"
  },
  {
    "text": "for each of the tasks\nthat we sampled. And so, we'll run through\nthe tasks that we sampled,",
    "start": "2913340",
    "end": "2918830"
  },
  {
    "text": "select training data\nfor each of those tasks, and then compute the\nloss on that mini-batch.",
    "start": "2918830",
    "end": "2927410"
  },
  {
    "text": "So, for each of the\ntasks that we sampled for each of the\nmini-batches, we'll evaluate how well the model\nis performing on those data",
    "start": "2927410",
    "end": "2934849"
  },
  {
    "text": "points. And then, ultimately, compute\nthe gradient of that loss",
    "start": "2934850",
    "end": "2942770"
  },
  {
    "text": "function and back propagate\nit into the model's parameters to update the parameters. So, you can then\napply your gradient",
    "start": "2942770",
    "end": "2949100"
  },
  {
    "text": "with your favorite optimizer\nfor neural networks such as Adam or maybe whatever is kind of\nthe latest and greatest thing.",
    "start": "2949100",
    "end": "2955310"
  },
  {
    "text": " This is fairly straightforward. The-- one thing that I think\nis important here is that it",
    "start": "2955310",
    "end": "2964859"
  },
  {
    "text": "does-- especially, if you sample\nall tasks in step one, this does ensure that\nyou're going to have--",
    "start": "2964860",
    "end": "2972390"
  },
  {
    "text": "you're going to essentially\nweight the tasks evenly. Even if you have a lot\nmore data from one task than another task, then\nthis sort of approach",
    "start": "2972390",
    "end": "2979320"
  },
  {
    "text": "will make sure that you're\nkind of treating them with equal weight rather than\nbased off of how much data",
    "start": "2979320",
    "end": "2985380"
  },
  {
    "text": "that they have. So, this is usually\npretty helpful. If you sample all of\nthe tasks in step one,",
    "start": "2985380",
    "end": "2992010"
  },
  {
    "text": "this is also doing\nstratification of your batches, meaning that you're\ngoing to have an equal amount of data\nfor every single task",
    "start": "2992010",
    "end": "2999090"
  },
  {
    "text": "in your batch. And this will lead to a\nlower variance gradient than if you were\nto just randomly sample data points, especially\nif you have different loss",
    "start": "2999090",
    "end": "3007730"
  },
  {
    "text": "functions for different tasks. So, you'll have-- essentially,\nin your loss function, you'll have a component for each\ntask rather than just having",
    "start": "3007730",
    "end": "3016339"
  },
  {
    "text": "the amount of-- rather than having\nit be determined based on how you're sampling. ",
    "start": "3016340",
    "end": "3023890"
  },
  {
    "text": "And one thing that's\npretty important here also is for regression\nproblems, you want to make sure that your\nlabels are on the same scale.",
    "start": "3023890",
    "end": "3029849"
  },
  {
    "text": "And so, if you have a regression\nproblem where one problem your labels range from 0\nto 2 and another problem",
    "start": "3029850",
    "end": "3036410"
  },
  {
    "text": "they range from 0 to 100,\nthat implicitly that's going to upweight the loss\nfunction for the wider range",
    "start": "3036410",
    "end": "3043130"
  },
  {
    "text": "labels. And that might not\nbe what you want. And so if you instead\nnormalize your label space,",
    "start": "3043130",
    "end": "3048230"
  },
  {
    "text": "then that will\nensure that you have kind of equal weighting\nacross the tasks, OK? ",
    "start": "3048230",
    "end": "3057150"
  },
  {
    "text": "So, in general, there aren't-- this is a fairly typical way\nto optimize the objective and there aren't too\nmany variations on this.",
    "start": "3057150",
    "end": "3063810"
  },
  {
    "text": "Usually this is-- usually\nthis isn't the hard part. Usually the harder part is\ndetermining the architecture",
    "start": "3063810",
    "end": "3071790"
  },
  {
    "text": "or determining the\nobjective to use. ",
    "start": "3071790",
    "end": "3078299"
  },
  {
    "text": "OK, a couple of challenges\nthat I want to bring up. Basically, what can go\nwrong when you actually",
    "start": "3078300",
    "end": "3084000"
  },
  {
    "text": "try to implement a\nmulti-task learning system? The first challenge\nis negative transfer.",
    "start": "3084000",
    "end": "3090030"
  },
  {
    "text": "And what I mean by this is that\nsometimes training the tasks independently works better\nthan training them together.",
    "start": "3090030",
    "end": "3098650"
  },
  {
    "text": "This can be a bit unintuitive. But this is referring\nto negative transfer in the sense that tasks--",
    "start": "3098650",
    "end": "3105450"
  },
  {
    "text": "some tasks are actually\nadversely hurting the performance of other tasks. ",
    "start": "3105450",
    "end": "3111480"
  },
  {
    "text": "And so as a really concrete\nexample of this happening is if you take somewhat\nrecent approaches",
    "start": "3111480",
    "end": "3117660"
  },
  {
    "text": "to a version of a\nmulti-task version of CIFAR, and you evaluate these different\napproaches essentially,",
    "start": "3117660",
    "end": "3126410"
  },
  {
    "text": "the first two approaches are\nmulti-task learning approaches. The third approach is this\nmore fancy architecture",
    "start": "3126410",
    "end": "3131549"
  },
  {
    "text": "called cross stitch networks. And the last row is just\nindependent training.",
    "start": "3131550",
    "end": "3137400"
  },
  {
    "text": "What you'll notice\nhere is that-- so, these are\ndifferent architectures cross stitch architectures\nand independent training.",
    "start": "3137400",
    "end": "3143160"
  },
  {
    "text": "What you'll notice here is\nthat independent training is actually doing better\nthan the multi-task learning approaches.",
    "start": "3143160",
    "end": "3149087"
  },
  {
    "text": "And this is-- in an instance\nof negative transfer, it means that this training\non the task independently",
    "start": "3149087",
    "end": "3155520"
  },
  {
    "text": "and not sharing any weights\nis better in this case. Now, why might this happen?",
    "start": "3155520",
    "end": "3161310"
  },
  {
    "text": "It could happen for\na number of reasons. It could be optimization\nchallenges that are coming up. Maybe the network\nis having trouble",
    "start": "3161310",
    "end": "3166830"
  },
  {
    "text": "finding kind of a solution that\nworks for all of the tasks. This could be caused by kind of\ninterference between the tasks,",
    "start": "3166830",
    "end": "3173580"
  },
  {
    "text": "between the gradients\nof different tasks. Tasks might learn\nat different rates.",
    "start": "3173580",
    "end": "3178660"
  },
  {
    "text": "And so maybe, one task\nis actually a lot easier. And so maybe the\nloss function will focus a lot on that easy task\nand ignore the harder task.",
    "start": "3178660",
    "end": "3186055"
  },
  {
    "text": "And then once it finds a good\nsolution for the easy task, maybe it's already\nkind of reached a part of the\noptimization space that's",
    "start": "3186055",
    "end": "3192240"
  },
  {
    "text": "really difficult for\nthe harder tasks.  But you also have to do with\nlimited representational",
    "start": "3192240",
    "end": "3198840"
  },
  {
    "text": "capacity. So, multi-task\nnetworks often need to be a lot larger than\nsingle task networks because you're\ntrying to do more.",
    "start": "3198840",
    "end": "3207195"
  },
  {
    "text": "So, these are a couple\nof reasons for why you could see negative transfer. ",
    "start": "3207195",
    "end": "3213250"
  },
  {
    "text": "So, what do you do if you\nhave negative transfer? You can just share less.",
    "start": "3213250",
    "end": "3219090"
  },
  {
    "text": "You can move it more towards\nindependent training. Of course, there\nmight be scenarios where independent\ntraining is just the best",
    "start": "3219090",
    "end": "3224902"
  },
  {
    "text": "possible thing you can do. But there's a whole\nspectrum of what you can do. You can share fewer parameters.",
    "start": "3224902",
    "end": "3232260"
  },
  {
    "text": "And it's also not just\nlike a binary decision of whether or not to\nshare a parameter or not. There's also\nsomething-- well, so we",
    "start": "3232260",
    "end": "3240059"
  },
  {
    "text": "talked about how you can\nshare less parameters. You could have fewer\nshared parameters and more",
    "start": "3240060",
    "end": "3245310"
  },
  {
    "text": "task-specific parameters. But there's also something\ncalled soft parameter sharing.",
    "start": "3245310",
    "end": "3250950"
  },
  {
    "text": "And the way this works is\nyou have different networks for the different tasks.",
    "start": "3250950",
    "end": "3256500"
  },
  {
    "text": "And you essentially try\nto encourage the weights to be similar to one another.",
    "start": "3256500",
    "end": "3262990"
  },
  {
    "text": "And so, while you're actually\nrepresenting the weights completely independently,\nyou can essentially",
    "start": "3262990",
    "end": "3268230"
  },
  {
    "text": "add this top right term on\nthe right that encourages the parameters to be similar. And this will essentially\ntie them-- bring them",
    "start": "3268230",
    "end": "3274573"
  },
  {
    "text": "closer to one another\nand constrain them in a way that encourages them\nto be similar in a softer way than hardly constraining\nthem to be the same.",
    "start": "3274573",
    "end": "3284430"
  },
  {
    "text": "Yeah? [INAUDIBLE] ",
    "start": "3284430",
    "end": "3295580"
  },
  {
    "text": "Right. So, the-- I guess the\nway the second term is indexing onto the tasks is\nwith t prime rather than i.",
    "start": "3295580",
    "end": "3303220"
  },
  {
    "text": "And so it's just-- we're\njust using a different index. I guess-- oh, yeah,\nso, t is actually",
    "start": "3303220",
    "end": "3308890"
  },
  {
    "text": "technically not defined. So yeah, that should be\nan i rather than a t. ",
    "start": "3308890",
    "end": "3316910"
  },
  {
    "text": "Yeah? [INAUDIBLE] ",
    "start": "3316910",
    "end": "3326470"
  },
  {
    "text": "Yeah. That's a great question. Yeah.",
    "start": "3326470",
    "end": "3331880"
  },
  {
    "text": "So I guess-- I mean,\nthe short answer is that a good way to\ndetect a negative transfer is to train independent networks\nand see if it's doing better.",
    "start": "3331880",
    "end": "3338276"
  },
  {
    "text": "You don't need to necessarily\ntrain independent networks for all of the tasks. You can just train it for some\nof them and see if it's worse.",
    "start": "3338277",
    "end": "3346170"
  },
  {
    "text": "Another way is if you have\na sense for what performance you want to get,\nthen you could try to see a performance--\nwhat performance",
    "start": "3346170",
    "end": "3352130"
  },
  {
    "text": "is relative to that. But kind of the most sure way\nto detect this sort of transfer is to train networks\nindependently.",
    "start": "3352130",
    "end": "3359090"
  },
  {
    "text": "Yes? I think, especially around\nthat question about network, is there an online\nway to characterize whether tasks would interfere\n[INAUDIBLE] distribution",
    "start": "3359090",
    "end": "3367474"
  },
  {
    "text": "or something? Yeah. That's an awesome question. So, the question\nis, is there a way to tell if tasks will\nbe synergistic or not?",
    "start": "3367475",
    "end": "3375050"
  },
  {
    "text": "I'll talk about that a\nbit in like three slides. It will be rather\nunsatisfying, but I'll",
    "start": "3375050",
    "end": "3380250"
  },
  {
    "text": "talk about it in three slides. Yeah? Are constraints a\nbig problem, having to store all the\nbackpropagations for each of the losses\nindividually before doing actual work on the gradients? ",
    "start": "3380250",
    "end": "3390570"
  },
  {
    "text": "Right. So, that's a good question. I think that I--",
    "start": "3390570",
    "end": "3395670"
  },
  {
    "text": "right. So I guess in this sort\nof soft parameter sharing, you do need to represent\nthe network separately and represent the\ngradient separately.",
    "start": "3395670",
    "end": "3402050"
  },
  {
    "text": "And this does make this sort\nof parameter sharing approach much less memory efficient.",
    "start": "3402050",
    "end": "3407070"
  },
  {
    "text": "It does require a\nlot more memory. And so, if you're in\nscenarios where you have-- where you need to train\nfairly large networks,",
    "start": "3407070",
    "end": "3413780"
  },
  {
    "text": "this approach will be\nkind of disadvantageous for that reason. And so, I guess in terms of\npros and cons of this approach,",
    "start": "3413780",
    "end": "3421849"
  },
  {
    "text": "it allows more fluid degrees\nof parameter sharing. One con is that\nit is essentially",
    "start": "3421850",
    "end": "3427910"
  },
  {
    "text": "another set of design\nchoices and hyperparameters in terms of how you choose this\nsort of software and so forth.",
    "start": "3427910",
    "end": "3433650"
  },
  {
    "text": "Another downside is that it\nrequires a lot more memory than like literally constraining\nthe weights to be the same.",
    "start": "3433650",
    "end": "3441859"
  },
  {
    "text": "Yeah? [INAUDIBLE]? ",
    "start": "3441860",
    "end": "3450005"
  },
  {
    "text": "Is there a way to find out\nwhich tasks or sort of tasks can [INAUDIBLE] transfer?",
    "start": "3450005",
    "end": "3456605"
  },
  {
    "text": " Yeah. So, the question is, if\nyou have a set of tasks",
    "start": "3456605",
    "end": "3463580"
  },
  {
    "text": "and maybe compared to\nindependent training, some of them improve and\nsome of them stay the same. And is there a way\nto detect essentially",
    "start": "3463580",
    "end": "3470970"
  },
  {
    "text": "which tasks are causing\nnegative transfer, which tasks are causing positive\ntransfer, and so forth.",
    "start": "3470970",
    "end": "3476970"
  },
  {
    "text": "If you have a lot of\ncompute, one way to do it is to try all-- training all\ncombinations of tasks together.",
    "start": "3476970",
    "end": "3482990"
  },
  {
    "text": "And that can usually\ngive a pretty good sense for which tasks are\nbeneficial to one another and which tasks are not.",
    "start": "3482990",
    "end": "3489950"
  },
  {
    "text": "In a few slides when I\ntalk about kind of task affinity and so forth, I'll\nalso mention a approach",
    "start": "3489950",
    "end": "3496640"
  },
  {
    "text": "that allows you to\nmeasure this in a less computationally intensive way.",
    "start": "3496640",
    "end": "3503060"
  },
  {
    "text": "I won't go into\nsome of the details, but I'll talk about\nit in a little bit. Yeah?",
    "start": "3503060",
    "end": "3508490"
  },
  {
    "text": "So you mentioned that for\nmulti-task logic, [INAUDIBLE].. ",
    "start": "3508490",
    "end": "3514039"
  },
  {
    "text": "Are they [INAUDIBLE]? ",
    "start": "3514040",
    "end": "3527520"
  },
  {
    "text": "Yeah. So, I think the question\nis kind of referring to what I said here, which\nis that you may need a larger",
    "start": "3527520",
    "end": "3532580"
  },
  {
    "text": "network for the\nmulti-task thing. And the question\nwas whether do you need-- does it need\nto be t times larger than the single task network?",
    "start": "3532580",
    "end": "3540080"
  },
  {
    "text": "And typically, it does not\nneed to be t times larger. Typically, the network\ncan represent things",
    "start": "3540080",
    "end": "3546320"
  },
  {
    "text": "in a way that can actually\nshare a capacity in some ways.",
    "start": "3546320",
    "end": "3553050"
  },
  {
    "text": "And if it is t times\nlarger then oftentimes, that's usually a bad sign with\nregard to negative transfer",
    "start": "3553050",
    "end": "3559248"
  },
  {
    "text": "and so forth. And you might actually be\nbetter training networks completely separately.",
    "start": "3559248",
    "end": "3564330"
  },
  {
    "text": "Although, even if you do\nmake it t times bigger, there still might be the\nbenefit of better performance by training them together.",
    "start": "3564330",
    "end": "3569975"
  },
  {
    "start": "3569975",
    "end": "3575620"
  },
  {
    "text": "Great, so, the second\nchallenge that I'll mention is the opposite of\nnegative transfer",
    "start": "3575620",
    "end": "3580800"
  },
  {
    "text": "in some ways, which is over-- well, sort of the opposite,\nwhich is maybe you're seeing overfitting.",
    "start": "3580800",
    "end": "3586242"
  },
  {
    "text": "Maybe you're seeing that it's\nfitting the training data set well and it's not fitting\nthe test set well.",
    "start": "3586242",
    "end": "3591760"
  },
  {
    "text": "And this could be\nin a scenario where you may not be sharing enough.",
    "start": "3591760",
    "end": "3597280"
  },
  {
    "text": "And the reason why I say this\nis that multi-task learning in many ways can be viewed\nas a form of regularization,",
    "start": "3597280",
    "end": "3603570"
  },
  {
    "text": "because it essentially\ngives you more data. If you have data sets\nfor different tasks",
    "start": "3603570",
    "end": "3610230"
  },
  {
    "text": "or more or different labels for\ndifferent tasks and so forth, trading on different\ntasks essentially",
    "start": "3610230",
    "end": "3617010"
  },
  {
    "text": "can be viewed as a\nform of regularization. Not necessarily-- not\nalways a good form of regularization of\ncourse, because you",
    "start": "3617010",
    "end": "3623100"
  },
  {
    "text": "might have negative transfer. But if you are\nseeing overfitting, sharing more can be helpful\nbecause it can essentially",
    "start": "3623100",
    "end": "3629370"
  },
  {
    "text": "increase the amount\nof regularization you have on your network. And so one possible solution to\nthis is to try to share more.",
    "start": "3629370",
    "end": "3636360"
  },
  {
    "text": " Yeah? [INAUDIBLE]? ",
    "start": "3636360",
    "end": "3644900"
  },
  {
    "text": "Can you repeat that? Say you're training\nfor a number of tasks",
    "start": "3644900",
    "end": "3649940"
  },
  {
    "text": "with a shared [INAUDIBLE]. If one of those tasks learns-- is relatively simpler\nand learns quicker",
    "start": "3649940",
    "end": "3657320"
  },
  {
    "text": "and then starts to\noverfit, would it screw all the other\ntasks in the process? ",
    "start": "3657320",
    "end": "3663630"
  },
  {
    "text": "Yeah. So, the question is if\none of the tasks is easier and it learns very quickly, can\nthat mess up the other tasks?",
    "start": "3663630",
    "end": "3670400"
  },
  {
    "text": "And I think-- I mean, in many ways it's\nan empirical question.",
    "start": "3670400",
    "end": "3677130"
  },
  {
    "text": "And I think that it can\ndepend on the scenario. I think that I've\nseen scenarios where it doesn't mess things up.",
    "start": "3677130",
    "end": "3683962"
  },
  {
    "text": "I think I've also seen\nscenarios where it can potentially mess things up. I think many ways\ndepends on that task.",
    "start": "3683962",
    "end": "3690349"
  },
  {
    "text": "If it ends up\nlearning very quickly and taking up a lot of the\ncapacity of the network,",
    "start": "3690350",
    "end": "3695480"
  },
  {
    "text": "then that can be a\nproblem in some ways.",
    "start": "3695480",
    "end": "3700550"
  },
  {
    "text": "In other cases, maybe it's just\nreally-- a really easy task. Maybe you just use\nthe output 0 always. And then it might only be\naffecting the last layer--",
    "start": "3700550",
    "end": "3707512"
  },
  {
    "text": "like one part of the last layer\nand not the entire network. And so, it's going to be\nfairly problem dependent. ",
    "start": "3707512",
    "end": "3715960"
  },
  {
    "text": "OK, and then the last\nchallenge that I'll bring up is what if you have\na lot of tasks?",
    "start": "3715960",
    "end": "3721996"
  },
  {
    "text": "There's a question of, should\nyou train all of the tasks together? Which tasks will\nbe complementary?",
    "start": "3721997",
    "end": "3728260"
  },
  {
    "text": "Really, if you have\na task, and you have some potential\nauxiliary tasks, how do whether you should\nuse those auxiliary tasks",
    "start": "3728260",
    "end": "3734320"
  },
  {
    "text": "or not and whether\nthey'll be helpful? And it kind of relates\nto the question of, yeah, will two tasks be\nhelpful for one another?",
    "start": "3734320",
    "end": "3740590"
  },
  {
    "text": "Do we know if we'll see\nnegative transfer or not? Should we train them\ntogether or not? ",
    "start": "3740590",
    "end": "3747490"
  },
  {
    "text": "The bad news is that there's\nlike no kind of closed form solution that will just like--",
    "start": "3747490",
    "end": "3752770"
  },
  {
    "text": "where you can take some\ndata sets and tasks and it will tell you the\ntask similarity.",
    "start": "3752770",
    "end": "3760059"
  },
  {
    "text": "Nothing like that really exists. And the reason for that is\nactually the task similarity",
    "start": "3760060",
    "end": "3766540"
  },
  {
    "text": "and whether they'll have a\npositive effect on optimization can depend on a huge\nnumber of factors.",
    "start": "3766540",
    "end": "3773270"
  },
  {
    "text": "It can depend on the\narchitecture that you're using. What the model knows versus\nwhat it doesn't know, like the grasping example\nthat I gave on Monday.",
    "start": "3773270",
    "end": "3780430"
  },
  {
    "text": "If you want to grasp and pour\nor grasp and click or something, then if the model\nknows how to grasp",
    "start": "3780430",
    "end": "3785650"
  },
  {
    "text": "then they're not going to-- then they might not be\ncomplementary at all. Whereas they might be\ncomplementary if you don't know how to grasp yet.",
    "start": "3785650",
    "end": "3792220"
  },
  {
    "text": "It can depend on the\noptimizer that you're using, the step size that you're using. It can depend on like a whole\nhost of different factors.",
    "start": "3792220",
    "end": "3800319"
  },
  {
    "text": "And this means that\nit's actually not just going to depend\non the data set and the loss function itself.",
    "start": "3800320",
    "end": "3805825"
  },
  {
    "text": " And I guess to illustrate\nkind of the reality of this",
    "start": "3805825",
    "end": "3815560"
  },
  {
    "text": "is that actually, one paper\nfrom a couple of years ago to measure some sort of task\nsimilarity, what they proposed",
    "start": "3815560",
    "end": "3822550"
  },
  {
    "text": "is literally to try all\ncombinations of training tasks together. And use that to kind of\nlook at the performance",
    "start": "3822550",
    "end": "3828430"
  },
  {
    "text": "of all those combinations, which\nis obviously combinatorially expensive and use that as a\nway to measure task similarity.",
    "start": "3828430",
    "end": "3838000"
  },
  {
    "text": "The good news is\nthat there are ways to try to approximate\ntask similarity in a way that isn't\ncombinatorially expensive.",
    "start": "3838000",
    "end": "3845110"
  },
  {
    "text": "And it actually will draw upon\nsome of the meta-learning ideas that we'll talk about\nlater in the course. But there are some ways to\ntry to approximate this sort",
    "start": "3845110",
    "end": "3852280"
  },
  {
    "text": "of task similarity. And the way that\nit works is to try to first train all\nthe tasks together",
    "start": "3852280",
    "end": "3857380"
  },
  {
    "text": "in a single multi-task\nnetwork, then analyze the statistics\nof that optimization run",
    "start": "3857380",
    "end": "3862790"
  },
  {
    "text": "it to compute some approximate\nmeasure of task affinity. And then once you have\nthose task affinities",
    "start": "3862790",
    "end": "3870160"
  },
  {
    "text": "from that single training run,\nyou can use that to group tasks together or do\nsomething else with it. ",
    "start": "3870160",
    "end": "3878570"
  },
  {
    "text": "Yeah, and this is-- something like this is going\nto be a lot more efficient than trying to try all possible\ncombinations of training tasks",
    "start": "3878570",
    "end": "3884260"
  },
  {
    "text": "together. It's still somewhat\ndissatisfying because you still need to do one\nfull training run of training",
    "start": "3884260",
    "end": "3890140"
  },
  {
    "text": "all of the tasks together. But it's at least a\nbit more satisfying than the combinatorial solution.",
    "start": "3890140",
    "end": "3895630"
  },
  {
    "text": "And it seems quite natural\nto me that you would still require something like a full\ntraining run, because the fact",
    "start": "3895630",
    "end": "3902410"
  },
  {
    "text": "that task similarity can\ndepend on all of these factors, including optimization factors. ",
    "start": "3902410",
    "end": "3911858"
  },
  {
    "text": "So, I'm not going to go\ninto the details of this. But if anyone is interested\nin learning more about it, there's a reference\nto the paper.",
    "start": "3911858",
    "end": "3918213"
  },
  {
    "text": "I'm also happy to chat about\nit more in office hours if people are\ninterested as well. ",
    "start": "3918213",
    "end": "3925500"
  },
  {
    "text": "OK, so, to recap\nmulti-task learning. Today, we defined a\ntask as these data",
    "start": "3925500",
    "end": "3931760"
  },
  {
    "text": "generating distributions\nand a loss function, which can be used to sample\na train set and a test set.",
    "start": "3931760",
    "end": "3938120"
  },
  {
    "text": "We talked about\nmodel architectures and how we might have used\nmultiplicative conditioning or additive conditioning\non our task descriptor.",
    "start": "3938120",
    "end": "3945290"
  },
  {
    "text": "And we might want to\nshare more or less based on the kind of transfer\nthat we observe from training.",
    "start": "3945290",
    "end": "3952328"
  },
  {
    "text": "We also talked about the\nobjective and the optimization process, such as kind of\nthis weighted objective",
    "start": "3952328",
    "end": "3957710"
  },
  {
    "text": "in different ways to choose\nweights as well as trying to use stratified mini-batches\nto reduce the variance",
    "start": "3957710",
    "end": "3964190"
  },
  {
    "text": "of the optimization process.  Great.",
    "start": "3964190",
    "end": "3969358"
  },
  {
    "text": "So, any questions on\nmulti-task learning before I move to kind of a case study\nof using multi-task learning",
    "start": "3969358",
    "end": "3975119"
  },
  {
    "text": "in a real world problem? ",
    "start": "3975120",
    "end": "3981920"
  },
  {
    "text": "Cool. So, we're going to go\nover the case study",
    "start": "3981920",
    "end": "3990050"
  },
  {
    "text": "from this particular paper. And the goal of\nthis is essentially to build a recommender\nsystem for YouTube.",
    "start": "3990050",
    "end": "3999359"
  },
  {
    "text": "We want to be able to recommend\npeople videos to watch.",
    "start": "3999360",
    "end": "4004750"
  },
  {
    "text": "And we want to be able to\nmake good recommendations for YouTube. And in particular, we want to\nbe able to recommend videos",
    "start": "4004750",
    "end": "4013510"
  },
  {
    "text": "on the right column. This is a figure from the paper. You want to be able to kind\nof rank them and choose",
    "start": "4013510",
    "end": "4019390"
  },
  {
    "text": "videos that would\nbe good to show to the user in the right column. ",
    "start": "4019390",
    "end": "4027210"
  },
  {
    "text": "OK, and why is this a\nmulti-task learning problem? The reason is that there's\ngoing to be a few conflicting",
    "start": "4027210",
    "end": "4033450"
  },
  {
    "text": "objectives that we are\ngoing to try to use when making recommendations.",
    "start": "4033450",
    "end": "4039300"
  },
  {
    "text": "And by we, I mean, the\nauthors of this paper. They chose a few\ndifferent objectives that they care about.",
    "start": "4039300",
    "end": "4044880"
  },
  {
    "text": "One is videos that\npeople might rate highly. Another is that\nvideos that users",
    "start": "4044880",
    "end": "4050100"
  },
  {
    "text": "will share with other people. And another is videos that\nthe user will actually watch.",
    "start": "4050100",
    "end": "4055515"
  },
  {
    "text": " And these are in my opinion,\nfairly reasonable things",
    "start": "4055515",
    "end": "4061530"
  },
  {
    "text": "that you might want to\nbe able to optimize. And there's also this\nsort of implicit bias",
    "start": "4061530",
    "end": "4069569"
  },
  {
    "text": "that's caused by feedback. The user may have\nwatched something because it was\nrecommended by the system.",
    "start": "4069570",
    "end": "4075640"
  },
  {
    "text": "And so this is something\nthat's super important to be aware of in general.",
    "start": "4075640",
    "end": "4081089"
  },
  {
    "text": "Although, it's not\nsomething that-- it's something that this\npaper acknowledges but not something that\nthey necessarily solve.",
    "start": "4081090",
    "end": "4086940"
  },
  {
    "text": " OK, so, the way\nthat they set it up",
    "start": "4086940",
    "end": "4093050"
  },
  {
    "text": "is the input is what the\nuser is currently watching as well as some\nfeatures about the user.",
    "start": "4093050",
    "end": "4099159"
  },
  {
    "text": "This could include\ntheir history of things that they've learned-- they've watched before\nor maybe interests",
    "start": "4099160",
    "end": "4104899"
  },
  {
    "text": "that they entered into YouTube\nor something like that. They generate a few\nhundred candidate videos.",
    "start": "4104899",
    "end": "4113509"
  },
  {
    "text": "And then they want to be\nable to rank these videos. And ultimately, the ones that\nare at the top of the rank",
    "start": "4113510",
    "end": "4119929"
  },
  {
    "text": "will be ones that they\nwill want to recommend. So, serve the top ranking\nvideos to the user.",
    "start": "4119930",
    "end": "4127490"
  },
  {
    "text": "And so, in terms of\ngenerating the candidates, they pull videos from\nmultiple candidate generation",
    "start": "4127490",
    "end": "4134180"
  },
  {
    "text": "algorithms. And this isn't really\nthe focus of the paper. But for generating\nthese candidates,",
    "start": "4134180",
    "end": "4139850"
  },
  {
    "text": "they consider things like\nmatching the topic of the video that the user was\ncurrently watching,",
    "start": "4139850",
    "end": "4145580"
  },
  {
    "text": "also looking at videos that\nare most frequently watched when people watch the video,\nand other things like that.",
    "start": "4145580",
    "end": "4153449"
  },
  {
    "text": "And then kind of the\nmain part of this paper is thinking about, given\nall of these candidates, can you rank these\ncandidates and pick the--",
    "start": "4153450",
    "end": "4160460"
  },
  {
    "text": "predict the ones that will kind\nof rank them and prioritize",
    "start": "4160460",
    "end": "4166256"
  },
  {
    "text": "the videos that you\nmight want to show to the user from\nthese candidates. ",
    "start": "4166257",
    "end": "4173689"
  },
  {
    "text": "OK, and so, the input here is\nthe query video, the candidate video.",
    "start": "4173689",
    "end": "4179028"
  },
  {
    "text": "So, once they have their\nlist of candidates, they're going to pass those\ncandidates into their network to try to predict--",
    "start": "4179029",
    "end": "4186040"
  },
  {
    "text": "to try to predict the\nengagement and satisfaction with that candidate video.",
    "start": "4186040",
    "end": "4191439"
  },
  {
    "text": "And so, the inputs are the query\nvideo, the candidate video, as well as features about\nthe user in context.",
    "start": "4191439",
    "end": "4197719"
  },
  {
    "text": "These are passed in as\ninputs to the neural network and they're embedded\ninto the neural network.",
    "start": "4197720",
    "end": "4203290"
  },
  {
    "text": " And then we're going to be\ntrying to predict engagement and satisfaction.",
    "start": "4203290",
    "end": "4209810"
  },
  {
    "text": "Engagement is-- can correspond\nto a few different things. It can correspond to\nbinary classification tasks",
    "start": "4209810",
    "end": "4214960"
  },
  {
    "text": "like whether they're going\nto click on the video. It can correspond\nto regression tasks which might be like\nhow long they spent",
    "start": "4214960",
    "end": "4221380"
  },
  {
    "text": "watching that candidate video. And satisfaction will be--",
    "start": "4221380",
    "end": "4226525"
  },
  {
    "text": "could be things like\nclicking the like button. So, this would be a binary\nclassification task. And it can also be a\nregression task such as like",
    "start": "4226525",
    "end": "4234192"
  },
  {
    "text": "if they're given a survey, like\nhow do they rate the video? ",
    "start": "4234192",
    "end": "4240679"
  },
  {
    "text": "OK, and then, once the\nmodel predicts engagement and satisfaction, they use\nsome weighted combination",
    "start": "4240680",
    "end": "4248200"
  },
  {
    "text": "of these two\npredictions to produce a score for the ranking. ",
    "start": "4248200",
    "end": "4255830"
  },
  {
    "text": "And the weights for\nthis were manually tuned essentially by the\nauthors or someone else.",
    "start": "4255830",
    "end": "4266695"
  },
  {
    "text": "OK, I guess one\nquestion for you. Do you feel like these\nobjectives are reasonable? Do you think that there are\nissues that might come up?",
    "start": "4266695",
    "end": "4273690"
  },
  {
    "text": "Do you think they're good? Yes? For example, for time spent\n[INAUDIBLE] time varies.",
    "start": "4273690",
    "end": "4285429"
  },
  {
    "text": "Yeah. So for time spent, the-- it's a good suggestion. If you have a really long video,\nthey might spend more time",
    "start": "4285430",
    "end": "4290850"
  },
  {
    "text": "watching it. If you have a short\nvideo, they will naturally-- they can't spend\na long time watching it. Yeah?",
    "start": "4290850",
    "end": "4295930"
  },
  {
    "text": "[INAUDIBLE]  Yeah. So these metrics\naren't necessarily",
    "start": "4295930",
    "end": "4301600"
  },
  {
    "text": "including whether or\nnot the user comments. And you could look at the\nsentiment of the comments, for example, as an\nadditional metric to predict.",
    "start": "4301600",
    "end": "4308306"
  },
  {
    "text": "Yeah?  Is there like a dislike button? I don't think-- I don't know if\nthere is a dislike-- is there",
    "start": "4308306",
    "end": "4315070"
  },
  {
    "text": "dislike button? OK, maybe they also-- they might also have binary\nclassification to dislike,",
    "start": "4315070",
    "end": "4320200"
  },
  {
    "text": "but that seems like a\ngood thing to include. Yeah? Different users might\nhave a different threshold",
    "start": "4320200",
    "end": "4325398"
  },
  {
    "text": "for whether they\nclick the like button or whether they share it\nbased on especially the type or the category of the video. ",
    "start": "4325398",
    "end": "4331550"
  },
  {
    "text": "Yeah. Exactly. So, a lot of these things\nmight depend on the user. And this might be\npretty challenging. Using the user features might\nhopefully be helpful for that.",
    "start": "4331550",
    "end": "4339140"
  },
  {
    "text": "But at the same time,\nit's something that's important to keep in mind.",
    "start": "4339140",
    "end": "4345190"
  },
  {
    "text": "Yeah? I mean, this is worth\nlike, a scrap for YouTube.",
    "start": "4345190",
    "end": "4351880"
  },
  {
    "text": "But YouTube's form\nof revenue is ads and not all videos have\nthe same number of ads,",
    "start": "4351880",
    "end": "4359920"
  },
  {
    "text": "so you might want to prioritize\nvideos that have ads. Yeah. So, if you want to\nmaximize revenue,",
    "start": "4359920",
    "end": "4366550"
  },
  {
    "text": "then you might want to consider\nwhether the candidate video has ads or not.",
    "start": "4366550",
    "end": "4373838"
  },
  {
    "text": "Any other thoughts? ",
    "start": "4373838",
    "end": "4379940"
  },
  {
    "text": "One of the things that\nI'll add that kind of surprised that no one\nmentioned, but maybe we don't want YouTube\nto be maximizing",
    "start": "4379940",
    "end": "4385890"
  },
  {
    "text": "time spent or something. Maybe spending a lot of\ntime on YouTube, maybe it's a good thing\nfor Google, maybe it's not necessarily the\nbest thing for their users.",
    "start": "4385890",
    "end": "4394690"
  },
  {
    "text": "Or maybe-- yeah. In general, keeping\nin mind yeah, what's",
    "start": "4394690",
    "end": "4400982"
  },
  {
    "text": "good in the grand\nscheme of things, compared to maximizing\nrevenue is usually something that's good,\nnot just for long term",
    "start": "4400982",
    "end": "4406842"
  },
  {
    "text": "revenue of course, but also in\nterms of people's well-being and so forth as well. ",
    "start": "4406842",
    "end": "4415409"
  },
  {
    "text": "OK, so, that's the\nsetup of the problem. For the architecture, they use\nwhat they call a Shared-Bottom",
    "start": "4415410",
    "end": "4421680"
  },
  {
    "text": "Model. I think this is more commonly\nused more commonly referred to as a multi-head architecture.",
    "start": "4421680",
    "end": "4427860"
  },
  {
    "text": "So, it looks something like\nthis, where you have the input features and then they pass this\nthrough kind of shared layers.",
    "start": "4427860",
    "end": "4436092"
  },
  {
    "text": "And then those are passed\nthrough the different heads of the model that\nare independent. ",
    "start": "4436092",
    "end": "4442960"
  },
  {
    "text": "Yeah. And this sort of\narchitecture can potentially harm learning when the\ncorrelation between tasks",
    "start": "4442960",
    "end": "4448380"
  },
  {
    "text": "is low but they found it to\nwork well in this setting. Oh sorry, this is I think--",
    "start": "4448380",
    "end": "4455833"
  },
  {
    "text": "this is the first\nthing that they tried. And they found\nthat it actually it did harm learning when the\ncorrelation between tasks was difficult.",
    "start": "4455833",
    "end": "4461050"
  },
  {
    "text": "And so it was low. And so they actually\ndidn't use-- well, I think they did evaluate\nthis multi-head architecture.",
    "start": "4461050",
    "end": "4467250"
  },
  {
    "text": "But they didn't use this\nmulti-head architecture in their kind of\nmain experiments. What they found to be helpful is\nto do a form of soft parameter",
    "start": "4467250",
    "end": "4476219"
  },
  {
    "text": "sharing. And they referred to this as a\nMulti-gate Mixture-of-Experts where they essentially have\nthese different modules,",
    "start": "4476220",
    "end": "4483570"
  },
  {
    "text": "these different experts. And then they-- based on kind of\nfeatures from the shared layers",
    "start": "4483570",
    "end": "4488730"
  },
  {
    "text": "at the bottom, they\nwill gate the-- which experts they're\nusing for which tasks.",
    "start": "4488730",
    "end": "4494885"
  },
  {
    "text": "And they're going to get\nin the way that's actually dependent on the input. And this means that\nmaybe for some users,",
    "start": "4494885",
    "end": "4501160"
  },
  {
    "text": "you might have some\nmodules being used or some kinds of videos you\nmight have some modules being used and so forth.",
    "start": "4501160",
    "end": "4508030"
  },
  {
    "text": "So, I guess getting back to\none of the questions earlier this is actually a way to\nallow the network to sort of dynamically choose what\nis being used for which tasks",
    "start": "4508030",
    "end": "4516510"
  },
  {
    "text": "and which users as well.  I don't have time really to go\nthrough this, but there's kind",
    "start": "4516510",
    "end": "4523410"
  },
  {
    "text": "of a few more details\non exactly how this is implemented where\nyou essentially",
    "start": "4523410",
    "end": "4529650"
  },
  {
    "text": "have the different-- you're trying to\nbasically decide which expert to use for a\ngiven input and a given task.",
    "start": "4529650",
    "end": "4537510"
  },
  {
    "text": "And you can-- you do the\ngating through this sort of multiplicative interaction. And then once you choose the\nexperts that you're using,",
    "start": "4537510",
    "end": "4543312"
  },
  {
    "text": "you sum over kind of\nthe weighted outputs. ",
    "start": "4543312",
    "end": "4548639"
  },
  {
    "text": "And then once you have\nthe output of that module, there's also some of these task\nspecific neural networks that",
    "start": "4548640",
    "end": "4554167"
  },
  {
    "text": "are the heads of the network. ",
    "start": "4554167",
    "end": "4559627"
  },
  {
    "text": "OK, and thenw they implemented\nthis in TensorFlow, which isn't too surprising on TPUs. They trained it\nin temporal order.",
    "start": "4559627",
    "end": "4567270"
  },
  {
    "text": "And so they get\ndata in a stream. And they ran training\ncontinuously,",
    "start": "4567270",
    "end": "4572760"
  },
  {
    "text": "always consuming the\nmost recent data. And they evaluated offline\nAUC and squared error metrics",
    "start": "4572760",
    "end": "4581550"
  },
  {
    "text": "in terms of their ability to\npredict clicks, their ability to predict whether or not\na user would rate something",
    "start": "4581550",
    "end": "4587250"
  },
  {
    "text": "or like something. And then they also did online\nA/B testing in comparison",
    "start": "4587250",
    "end": "4594630"
  },
  {
    "text": "to the system that's\nin production. And these were live metrics that\nwere looking at the time spent,",
    "start": "4594630",
    "end": "4601930"
  },
  {
    "text": "survey responses, and\nthe rate of dismissals. And one thing that's especially\nimportant in this application",
    "start": "4601930",
    "end": "4609310"
  },
  {
    "text": "is computational efficiency. They have a ton of data. And you want to be able\nto actually evaluate",
    "start": "4609310",
    "end": "4616150"
  },
  {
    "text": "this model quickly as well.  OK, so, the results from\nthe live A/B test are here.",
    "start": "4616150",
    "end": "4625550"
  },
  {
    "text": "And so they are evaluating\nthe multi-head architecture, the more basic architecture, as\nwell as the mixture of experts,",
    "start": "4625550",
    "end": "4632170"
  },
  {
    "text": "with either four experts\nor eight experts. And it's a bit\nsmall but what you",
    "start": "4632170",
    "end": "4637690"
  },
  {
    "text": "can see here is in comparison\nto the production system, they see an improvement\nin both engagement",
    "start": "4637690",
    "end": "4645850"
  },
  {
    "text": "as well as satisfaction\nof about 0.45% and 3%",
    "start": "4645850",
    "end": "4652960"
  },
  {
    "text": "for those two\nmetrics, respectively, with the eight mixture\nof experts model.",
    "start": "4652960",
    "end": "4658400"
  },
  {
    "text": "So, this is in my opinion\npretty impressive. Because I would have guessed\nthat the production system is pretty good at\nrecommending videos.",
    "start": "4658400",
    "end": "4666280"
  },
  {
    "text": "And you can also\nactually visualize how it's used utilizing\nexperts for different tasks. And you see that for some tasks,\nit's utilizing some experts,",
    "start": "4666280",
    "end": "4673570"
  },
  {
    "text": "and for other tasks,\nit is choosing to utilize other experts. And so, it's kind of\ninteresting to look",
    "start": "4673570",
    "end": "4680625"
  },
  {
    "text": "at these kinds of\nvisualizations. And visualizations\nlike this can also give you a sense\nfor task affinity",
    "start": "4680625",
    "end": "4685989"
  },
  {
    "text": "after you train the network\non all the tasks of course.  And then one other detail\nthat they mentioned",
    "start": "4685990",
    "end": "4692750"
  },
  {
    "text": "is that they found that\nthere was actually-- in some of their training runs,\nsometimes the gates would just polarize and it\nwould-- it would choose",
    "start": "4692750",
    "end": "4702310"
  },
  {
    "text": "to use only one expert,\nfor example, for a task. And they found\nthat it was pretty important to use\ndrop-out on the experts",
    "start": "4702310",
    "end": "4708770"
  },
  {
    "text": "to encourage it to not choose\njust one expert from one task and so forth.",
    "start": "4708770",
    "end": "4714619"
  },
  {
    "text": "And yeah, they found that\nto be helpful to improve training stability there.",
    "start": "4714620",
    "end": "4721570"
  },
  {
    "start": "4721570",
    "end": "4726208"
  }
]
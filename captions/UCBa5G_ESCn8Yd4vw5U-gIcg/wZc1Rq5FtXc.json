[
  {
    "start": "0",
    "end": "10870"
  },
  {
    "text": "Just such a treat to be back. I spent many hours on\nthat side of the room, so it's wild to be on this side\nof the room and going whoa,",
    "start": "10870",
    "end": "17920"
  },
  {
    "text": "there was actually\nmonitors up here. That's how the speakers kept\ntrack of where in their talk",
    "start": "17920",
    "end": "23710"
  },
  {
    "text": "they were. So that's good to know. And this is the\nfirst set of talks",
    "start": "23710",
    "end": "29260"
  },
  {
    "text": "I've given since the\npandemic, and so I thought it was a really\ngreat opportunity to talk about some new ideas\nthat have been on my mind.",
    "start": "29260",
    "end": "37870"
  },
  {
    "text": "And particularly with all of\nyou as my captive audience, I thought that I would use\nthis talk as an opportunity",
    "start": "37870",
    "end": "44440"
  },
  {
    "text": "to think out loud about\nwhat the role of HCI should be in the face\nof all of this really",
    "start": "44440",
    "end": "50680"
  },
  {
    "text": "incredible, rapid progress\nthat AI and ML have made, particularly scoped in\nthe last six months or so.",
    "start": "50680",
    "end": "61269"
  },
  {
    "text": "And as I was trying to think\nabout what the role of HCI should be, I was\nreminded of this figure",
    "start": "61270",
    "end": "68620"
  },
  {
    "text": "from Jonathan\nGrudin's 2009 article in AAAI about how AI and\nHCI are two fields that",
    "start": "68620",
    "end": "75530"
  },
  {
    "text": "are divided by a common focus. And as you can see,\nin moments where AI makes a lot of progress, it's\nalmost like the pendulum swings",
    "start": "75530",
    "end": "83840"
  },
  {
    "text": "towards ever-increased\namounts of automation, perhaps at the expense of more HCI-esque\napproaches of human intelligence",
    "start": "83840",
    "end": "93079"
  },
  {
    "text": "augmentation or amplification. But also, I think HCI is in\na more established, stronger",
    "start": "93080",
    "end": "98540"
  },
  {
    "text": "position than it's\never been in the past. And so I really think\nit's our responsibility",
    "start": "98540",
    "end": "107390"
  },
  {
    "text": "to think about what\nthat counterbalance to ever-increased\nautomation should be.",
    "start": "107390",
    "end": "112760"
  },
  {
    "text": "And so I often, in moments like\nthis, like to turn to history and ground myself.",
    "start": "112760",
    "end": "118220"
  },
  {
    "text": "And so if we cast back to\nthe first AI winter with Sutherland's Sketchpad,\nright around that time,",
    "start": "118220",
    "end": "124460"
  },
  {
    "text": "there was this foundational\npaper written by Licklider at MIT titled\n\"Man-Computer Symbiosis.\"",
    "start": "124460",
    "end": "130810"
  },
  {
    "text": "And I think the\ngendering is unfortunate and unfortunately,\nreflective of the times. But nevertheless, in\nthis paper, Licklider",
    "start": "130810",
    "end": "138640"
  },
  {
    "text": "put forth this really\ncompelling vision about the ways in which\na computer could interact",
    "start": "138640",
    "end": "145840"
  },
  {
    "text": "with us through this intuitive,\nguided, trial-and-error procedure, turning up solutions\nand revealing unexpected turns",
    "start": "145840",
    "end": "154660"
  },
  {
    "text": "in the reasoning. And I was really tempted\nto put this side by side with this very recent demo that\nOpenAI released with ChatGPT",
    "start": "154660",
    "end": "163030"
  },
  {
    "text": "plus plug-ins, where you can\nupload this music.csv data set, and then start to have this very\nnatural language interaction",
    "start": "163030",
    "end": "170409"
  },
  {
    "text": "to ask, what are the columns in\nthe data set, how many rows are there in the data set,\nand then even say,",
    "start": "170410",
    "end": "175750"
  },
  {
    "text": "can you give me some basic\nvisualizations of this data set. And it thinks a little bit. It's working real hard.",
    "start": "175750",
    "end": "182620"
  },
  {
    "text": "And there you go. It produces three\nvisualizations, and even starts to give\nyou maybe something that",
    "start": "182620",
    "end": "188320"
  },
  {
    "text": "looks like an explanation. And I wonder, is it time\nto roll out our \"mission",
    "start": "188320",
    "end": "193849"
  },
  {
    "text": "accomplished\" banners? Have we achieved\nLicklider's vision to think in interaction with\na computer in the same way",
    "start": "193850",
    "end": "200390"
  },
  {
    "text": "that we think with a colleague\nwhose competence supplements our own? Now I don't think it's time\nto roll out the \"mission",
    "start": "200390",
    "end": "207830"
  },
  {
    "text": "accomplished\" banners. But I'm hopeful that\nthe reason it's not that is not just my hope that we\nhaven't been put out of jobs,",
    "start": "207830",
    "end": "215360"
  },
  {
    "text": "but rather that there\nis something more to do. So two years after Licklider's\n\"Man-Computer Symbiosis,\"",
    "start": "215360",
    "end": "221900"
  },
  {
    "text": "Douglas Engelbart wrote up this\nreally incredible framework called, \"Augmenting\nHuman Intellect.\"",
    "start": "221900",
    "end": "228560"
  },
  {
    "text": "And right in the\nintroduction of this piece, we already start to\nsee how Engelbart",
    "start": "228560",
    "end": "234470"
  },
  {
    "text": "is defining a much\nmore expansive role of human augmentation. So the idea is not just\nabout problem-solving--",
    "start": "234470",
    "end": "242180"
  },
  {
    "text": "which he does mention\nright at the end there to derive\nsolutions to a problem-- but it's also about using\ncomputers to help us think.",
    "start": "242180",
    "end": "250579"
  },
  {
    "text": "It's to increase our capacity\nto approach a complex problem",
    "start": "250580",
    "end": "256070"
  },
  {
    "text": "situation to gain\ncomprehension, really about this thinking and not\njust the problem-solving pieces.",
    "start": "256070",
    "end": "262730"
  },
  {
    "text": "And really, what I like is\nhow he thinks we'll get there. Certainly, there will be\nsophisticated methods,",
    "start": "262730",
    "end": "267740"
  },
  {
    "text": "high-powered electronic aids. But to me, the part that really\nresonates in his prescription",
    "start": "267740",
    "end": "273290"
  },
  {
    "text": "here is streamlined\nterminology and notation. And that's going to be\na theme of my talk here,",
    "start": "273290",
    "end": "279380"
  },
  {
    "text": "certainly one of the themes\nthat underlies my group's work. And so in contrast to that\nChatGPT demo, a few years ago,",
    "start": "279380",
    "end": "287900"
  },
  {
    "text": "I had the pleasure to work with\nsome collaborators at Berkeley-- Yifan Wu and Joe Hellerstein,\nwho you see in the top",
    "start": "287900",
    "end": "293180"
  },
  {
    "text": "right-hand corner-- on this system called B2. So this is a Jupyter Notebook. It's a very commonly-used\ndata science environment",
    "start": "293180",
    "end": "301010"
  },
  {
    "text": "where people can\nstart to write code in the style of a Python REPL.",
    "start": "301010",
    "end": "306169"
  },
  {
    "text": "But what B2 does\nis saying, well, in addition to that linear\nstyle of data science",
    "start": "306170",
    "end": "312270"
  },
  {
    "text": "analysis and\nprogramming, there's a lot of value in a\nmore visual analysis, dashboard-style\ninterface like Tableau.",
    "start": "312270",
    "end": "319350"
  },
  {
    "text": "And so what B2 tries to do is\nbring these two pieces together. So you can see once I've invoked\nB2, it adds this on the sidebar,",
    "start": "319350",
    "end": "327270"
  },
  {
    "text": "and I can start to issue\nregular Python pandas commands like looking\nat the data frame,",
    "start": "327270",
    "end": "333510"
  },
  {
    "text": "getting a sense of how\nmany rows there are. What the columns are. And now I can start\nto write some code",
    "start": "333510",
    "end": "340320"
  },
  {
    "text": "to do a little bit of\ndata transformation and visualization. Notice here in all\nof these steps, when",
    "start": "340320",
    "end": "345840"
  },
  {
    "text": "I'm authoring a\nvisualization, I don't have to specify what that\nvisualization should look like.",
    "start": "345840",
    "end": "351660"
  },
  {
    "text": "I'm just calling these .vis\nmethods on the data frame, and B2, behind the scenes,\nis figuring out what sort",
    "start": "351660",
    "end": "358530"
  },
  {
    "text": "of visualization actually makes\nsense based on the history of the transformations that were\nperformed on the data frame.",
    "start": "358530",
    "end": "366240"
  },
  {
    "text": "So in the case of\nyear, for instance, if I've grouped by year, the\nmost sensible visualization",
    "start": "366240",
    "end": "371980"
  },
  {
    "text": "to produce is a histogram\nof the number of counts of data records across years.",
    "start": "371980",
    "end": "377080"
  },
  {
    "text": "You might have also\nnoticed in the video that if I click the fields\non the right-hand side there that it automatically\nproduces an equivalent",
    "start": "377080",
    "end": "384069"
  },
  {
    "text": "visualization, but it\ndoesn't stop there. It adds the code and tags them\nwith these little yellow emojis",
    "start": "384070",
    "end": "391990"
  },
  {
    "text": "to indicate that\nthere's actually sort of a common, shared\nrepresentation here.",
    "start": "391990",
    "end": "397570"
  },
  {
    "text": "Clicking on the sidebar not\nonly produces the visualization but produces the\nequivalent code as well.",
    "start": "397570",
    "end": "404960"
  },
  {
    "text": "And what's interesting is that\nthese visualizations aren't just output mechanisms,\nbut I can start",
    "start": "404960",
    "end": "410320"
  },
  {
    "text": "to interact with them to do this\ncross-filtering interaction, so all the other bars update\nto reflect the data shown",
    "start": "410320",
    "end": "417669"
  },
  {
    "text": "in the highlighted\nbars, and B2 is keeping this as\nan interaction log",
    "start": "417670",
    "end": "423010"
  },
  {
    "text": "that is semantically\nmeaningful to me. So this interaction log\ndoesn't comprise mouse clicks",
    "start": "423010",
    "end": "428140"
  },
  {
    "text": "and keystrokes and\nthings like that, but it's expressing data\nqueries, which states have been selected.",
    "start": "428140",
    "end": "434139"
  },
  {
    "text": "And I can use that\ndata query to perform subsequent analyses based\non my interactive results.",
    "start": "434140",
    "end": "440680"
  },
  {
    "text": "So I can say, great,\nI'm going to copy some code to the clipboard,\npaste it in as a data query",
    "start": "440680",
    "end": "447610"
  },
  {
    "text": "to look at what the interactive\nselection should be, and then proceed with some\nother sort of visual analysis.",
    "start": "447610",
    "end": "455889"
  },
  {
    "text": "And so as we're looking at\nthese two forms of interaction, I was trying to figure out,\nwell, some things feel the same.",
    "start": "455890",
    "end": "463780"
  },
  {
    "text": "I've got that conversational\nback and forth. Sure, on the left-hand\nside with ChatGPT, it's a more natural\nlanguage conversation.",
    "start": "463780",
    "end": "470530"
  },
  {
    "text": "On the right-hand side, it's\nmore of a REPL conversation. But also things feel\nqualitatively different.",
    "start": "470530",
    "end": "475900"
  },
  {
    "text": "And how do I actually\ncharacterize what is the same and what is the difference? And I thought really\nhard about it,",
    "start": "475900",
    "end": "482560"
  },
  {
    "text": "and I realized that actually,\nmaybe what still matters is direct manipulation.",
    "start": "482560",
    "end": "488139"
  },
  {
    "text": "And by direct\nmanipulation, I don't mean just the Ben Shneiderman\nversion of the term, which",
    "start": "488140",
    "end": "493930"
  },
  {
    "text": "is associated with\ngraphical user interfaces and having a representation on\nscreen that you can manipulate",
    "start": "493930",
    "end": "500470"
  },
  {
    "text": "and undo-redo and\nthings like that. But what I mean here\nis the deeper treatment of direct manipulation that\nthree cognitive scientists,",
    "start": "500470",
    "end": "508150"
  },
  {
    "text": "Ed Hutchins, Jim\nHollan, and Don Norman wrote in about the mid-1980s.",
    "start": "508150",
    "end": "513339"
  },
  {
    "text": "So in particular, in\nHutchins et al's treatment of direct manipulation, they\nimagine direct manipulation",
    "start": "513340",
    "end": "521620"
  },
  {
    "text": "to be this cognitive\nprocess between a user's goals and the user interface. And they identify\nthis gulf of execution",
    "start": "521620",
    "end": "529780"
  },
  {
    "text": "that exists when a\nuser has to translate their goals into commands\nthat they execute on the user",
    "start": "529780",
    "end": "535029"
  },
  {
    "text": "interface and\nsimilarly, a return gulf of evaluation when a user\nhas to figure out, well,",
    "start": "535030",
    "end": "540610"
  },
  {
    "text": "did the UI do the thing that\nI was expecting it to do. And I'm seeing a lot\nof nods in the audience",
    "start": "540610",
    "end": "545830"
  },
  {
    "text": "because if you've had experience\nin user interaction design, user experience, you've maybe\nexperienced these terms, gulf",
    "start": "545830",
    "end": "553310"
  },
  {
    "text": "of evaluation and execution. But what I find interesting\nin this 1985 paper is that they went\none level deeper.",
    "start": "553310",
    "end": "560389"
  },
  {
    "text": "So in particular, they\nidentified this idea of a semantic distance,\nwhich is basically",
    "start": "560390",
    "end": "566060"
  },
  {
    "text": "how users take the fuzzy\nnotions in their head and translate those into the\nnouns and verbs of the user",
    "start": "566060",
    "end": "574940"
  },
  {
    "text": "interface, so going, doing\nthat sense meaning operation of transforming your intentions\ninto the particular actions that",
    "start": "574940",
    "end": "584779"
  },
  {
    "text": "might exist in the\nuser interface. And in addition to\nthe semantic distance, they identified what I love--",
    "start": "584780",
    "end": "590870"
  },
  {
    "text": "I love this term-- an\narticulatory distance. So it's not\nnecessarily the meaning that we care about anymore,\nbut the way in which",
    "start": "590870",
    "end": "597920"
  },
  {
    "text": "we're conveying that\nmeaning through the UI. And this is\nparticularly important because you might have several\nuser interfaces that all",
    "start": "597920",
    "end": "605720"
  },
  {
    "text": "express the same semantics. You can conduct the\nsame set of operations",
    "start": "605720",
    "end": "611900"
  },
  {
    "text": "with them, the same\nnouns and verbs. But the way you do that might be\ndifferent because one interface",
    "start": "611900",
    "end": "617060"
  },
  {
    "text": "might be graphical. The other one might be textual. Another one might\nbe conversational, gesture-oriented, et cetera.",
    "start": "617060",
    "end": "622910"
  },
  {
    "text": "And their claim\nin this paper was that articulation, the\nform of that meaning, is really, really\nimportant, just as important",
    "start": "622910",
    "end": "630829"
  },
  {
    "text": "as the semantics. And of course, these distances\nexist on the gulf of evaluation as well.",
    "start": "630830",
    "end": "636150"
  },
  {
    "text": "So the articulatory\ndistance is, How do I perceive the changes\nthat occurred in the UI",
    "start": "636150",
    "end": "641600"
  },
  {
    "text": "and start to bring meaning\nto that perceptual operation",
    "start": "641600",
    "end": "647509"
  },
  {
    "text": "by interpreting and evaluating\nthe degree to which they met my goals.",
    "start": "647510",
    "end": "652610"
  },
  {
    "text": "So this is actually going to\ngive us the conceptual machinery for the rest of the talk.",
    "start": "652610",
    "end": "657890"
  },
  {
    "text": "And it's a little\nbit dense, and so I want to return to the\nprior two examples, and think about\nhow they manifest",
    "start": "657890",
    "end": "664610"
  },
  {
    "text": "these two kinds of distances. So in the case of\nthe ChatGPT example, if we start with\nsemantic distance,",
    "start": "664610",
    "end": "671090"
  },
  {
    "text": "I would say that, well,\nthe semantics aren't really well defined. They're not really explicit\nbecause what these models have",
    "start": "671090",
    "end": "678019"
  },
  {
    "text": "done is they've learned over\nvast corpuses of text, often just text that is\npresent on the internet,",
    "start": "678020",
    "end": "684800"
  },
  {
    "text": "and so what they've learned\nis this latent space that is very ambiguous in the\nsemantics that are encoded",
    "start": "684800",
    "end": "690350"
  },
  {
    "text": "in that latent space. So as a user, it's\nhard for me to know how to translate my\nintentions into something",
    "start": "690350",
    "end": "696873"
  },
  {
    "text": "that the system can\nunderstand because I don't know what it is the\nsystem knows about the world.",
    "start": "696873",
    "end": "702259"
  },
  {
    "text": "But as I'm sure many\nof us are aware, prompt engineering is a thing.",
    "start": "702260",
    "end": "708170"
  },
  {
    "text": "So if I figure out exactly how\nto craft my natural language expression, suddenly,\nI can get the model",
    "start": "708170",
    "end": "714709"
  },
  {
    "text": "to very rapidly almost zero-shot\nadopt the semantics that I want. And that feels like a\nvery powerful affordance",
    "start": "714710",
    "end": "721700"
  },
  {
    "text": "that we've not\nnecessarily had before. On the other side,\nthe semantic distance",
    "start": "721700",
    "end": "727430"
  },
  {
    "text": "in the Jupyter Notebook\nin B2 had explicitly defined semantics. We had the explicit\nsemantics of pandas",
    "start": "727430",
    "end": "734329"
  },
  {
    "text": "and the data frame of the\nvisualization library, of being able to click on the\nfields in the graphical user",
    "start": "734330",
    "end": "740150"
  },
  {
    "text": "interface to produce\nvisualizations. And every time I did that, I\nhad the shared representation",
    "start": "740150",
    "end": "745490"
  },
  {
    "text": "of the code, so either\nI would author the code and it would produce\na visualization or if the system\nproduced some code,",
    "start": "745490",
    "end": "750920"
  },
  {
    "text": "I could go in and\ncomment and uncomment entries or tweak the code in\na particular way and things",
    "start": "750920",
    "end": "756690"
  },
  {
    "text": "like that. And so it gave me the\nshared representation that allowed me to bridge\nbetween input and output",
    "start": "756690",
    "end": "762980"
  },
  {
    "text": "mechanisms really,\nreally easily. With articulatory distance\nin ChatGPT, natural language,",
    "start": "762980",
    "end": "771270"
  },
  {
    "text": "it's been enormously\npowerful because it's reduced the learning\nthreshold for a lot of things.",
    "start": "771270",
    "end": "777839"
  },
  {
    "text": "So if I don't know\nexactly what it is I want or how to pose it\nto the question,",
    "start": "777840",
    "end": "783040"
  },
  {
    "text": "I can lean into the ambiguity\nof natural language, and ChatGPT catches\nup to my intentions",
    "start": "783040",
    "end": "789270"
  },
  {
    "text": "pretty rapidly, which is great. But conversely, sometimes I\nknow exactly what it is I want,",
    "start": "789270",
    "end": "795040"
  },
  {
    "text": "and it's really\nfrustrating to have to express precise operations\nthrough the ambiguity",
    "start": "795040",
    "end": "800640"
  },
  {
    "text": "of natural language. And then as a result, because of\nthe fact that natural language",
    "start": "800640",
    "end": "806010"
  },
  {
    "text": "is the only mechanism so far by\nwhich we can interact with many of these models,\nthere's a disconnect",
    "start": "806010",
    "end": "811019"
  },
  {
    "text": "if your output is visual, like\nthe case of visualizations. So I can't interact with the\nvisualizations in any way",
    "start": "811020",
    "end": "817290"
  },
  {
    "text": "to do subsequent back-and-forth\ninteractions with the model. Now I don't think\nthe second point is",
    "start": "817290",
    "end": "822690"
  },
  {
    "text": "a fundamental limitation,\nbut it's certainly the state of where we are today.",
    "start": "822690",
    "end": "828100"
  },
  {
    "text": "And on the other hand, with\nJupyter Notebook and B2, with the articulatory\ndistance, we've",
    "start": "828100",
    "end": "834130"
  },
  {
    "text": "got basically the\ninverse of this. We've got a nice, precise,\nprogrammatic syntax. So if I know that syntax,\nI can work really, really",
    "start": "834130",
    "end": "841660"
  },
  {
    "text": "efficiently as a\ncommon affordance of many command-line\nstyle interfaces.",
    "start": "841660",
    "end": "847660"
  },
  {
    "text": "But I really need to learn\nthat syntax to be effective. And in some cases with\npoorly-designed syntaxes,",
    "start": "847660",
    "end": "853960"
  },
  {
    "text": "which I might maybe argue\npandas is an example of-- I constantly have to look\nup the documentation for.",
    "start": "853960",
    "end": "860410"
  },
  {
    "text": "There's a learning\ncurve associated with it that slows people down. Yeah, Michael? I have a quick question.",
    "start": "860410",
    "end": "865970"
  },
  {
    "text": "I have usually thought\nof the learning curve of a formal language as a\nsemantic distance rather than",
    "start": "865970",
    "end": "871570"
  },
  {
    "text": "an articulatory distance. Rather, the\narticulatory is how hard is it to construct the query\nonce I understand what--",
    "start": "871570",
    "end": "877520"
  },
  {
    "text": "Yeah, so the reason I put it-- I think this is a great\nquestion, what lies in semantic and articulatory.",
    "start": "877520",
    "end": "883070"
  },
  {
    "text": "And oftentimes, it is\nquite a fuzzy distinction. The reason I've put\nthis in articulatory is my experience with\npandas oftentimes",
    "start": "883070",
    "end": "890300"
  },
  {
    "text": "is I know what it\nis I want to do. I know the sort of\noperation I want to perform on my data frame.",
    "start": "890300",
    "end": "896540"
  },
  {
    "text": "I just don't know the specific\nsyntax that I need to look up. You have the mental model. Exactly.",
    "start": "896540",
    "end": "901550"
  },
  {
    "text": "Exactly. But certainly, if you don't\nknow what it is you want to do, then the affordances\nof natural language",
    "start": "901550",
    "end": "908270"
  },
  {
    "text": "absolutely help because you can\npose things in really fuzzy ways and iterate towards\nyour outcome.",
    "start": "908270",
    "end": "917420"
  },
  {
    "text": "And I think you see some of this\nambiguity in the distinction between semantic and\narticulatory distance",
    "start": "917420",
    "end": "923510"
  },
  {
    "text": "here with this last point\nwhere, because there are consistent\nsemantics, that actually",
    "start": "923510",
    "end": "929000"
  },
  {
    "text": "has this knock-on effect\non the articulation because now there's a shared\nrepresentation of input",
    "start": "929000",
    "end": "934880"
  },
  {
    "text": "and output, and that simplifies\nthat articulatory distance as well. So there's not quite\nthat disconnect",
    "start": "934880",
    "end": "940760"
  },
  {
    "text": "that we see on the ChatGPT side. And so I've found semantic\nand articulatory distances",
    "start": "940760",
    "end": "947870"
  },
  {
    "text": "to be a really\nhelpful framework, and I wanted to use\nit to analyze the very",
    "start": "947870",
    "end": "953660"
  },
  {
    "text": "last step in the output\nthat that demo produced. So it's basically\nthis thing that",
    "start": "953660",
    "end": "960470"
  },
  {
    "text": "masquerades as an explanation\nof the visualizations that ChatGPT produced.",
    "start": "960470",
    "end": "965600"
  },
  {
    "text": "But if you actually\nlook at what it says, here are some basic\nvisualizations. \"Number one, a histogram\nof song durations:",
    "start": "965600",
    "end": "972230"
  },
  {
    "text": "This shows the distribution\nof song durations in seconds.\" All right, fair enough. A scatterplot of song hotness\nversus artist familiarity.",
    "start": "972230",
    "end": "979710"
  },
  {
    "text": "This shows the relationship\nbetween song hotness and artist familiarity. Well, I would hope so. And then bar chart of the top\n10 most frequent artist names.",
    "start": "979710",
    "end": "988020"
  },
  {
    "text": "This shows the top 10\nmost frequent artist names in the data set. These are not\nreally explanations,",
    "start": "988020",
    "end": "993810"
  },
  {
    "text": "but they're pretty provocative\nor evocative in the potential that these models\nmight have in allowing",
    "start": "993810",
    "end": "1000560"
  },
  {
    "text": "us to produce these\ntextual descriptions of visual artifacts. And certainly, a lot\nof people, certainly",
    "start": "1000560",
    "end": "1007970"
  },
  {
    "text": "lots of big tech\ncompanies, have thought about the ways in\nwhich you could use all kinds of machine\nlearning models, not just LLMs",
    "start": "1007970",
    "end": "1015110"
  },
  {
    "text": "to do this rich description of\nvisual content, and particularly for these accessibility\nuse cases,",
    "start": "1015110",
    "end": "1021860"
  },
  {
    "text": "like how do you describe\nthese kinds of artifacts to people who are blind\nor have low vision.",
    "start": "1021860",
    "end": "1027169"
  },
  {
    "text": "And lots of people have studied\nthe degree to which these models are effective and found, maybe\nunsurprisingly, that they're not",
    "start": "1027170",
    "end": "1033890"
  },
  {
    "text": "terribly effective right now. So here is a quote from\na participant from one of our studies who says,\n\"The reader wouldn't",
    "start": "1033890",
    "end": "1040640"
  },
  {
    "text": "get much insight from text\nlike this,\" which not only is problematic because it doesn't\neffectively convey information,",
    "start": "1040640",
    "end": "1047209"
  },
  {
    "text": "but more troublingly, it\nactually increases the burden that readers face\nwhen they're trying",
    "start": "1047210",
    "end": "1052250"
  },
  {
    "text": "to make sense of this output. There's a lot of noise that\ngets added to that experience.",
    "start": "1052250",
    "end": "1059269"
  },
  {
    "text": "Another participant says\nvery, very interestingly, The problem with these\ntextual descriptions",
    "start": "1059270",
    "end": "1064550"
  },
  {
    "text": "is also that it robs me of\ncontrol of consuming the data.",
    "start": "1064550",
    "end": "1070700"
  },
  {
    "text": "Another participant said, I\nwant to have the time and space to interpret the numbers\nfor myself before I",
    "start": "1070700",
    "end": "1076400"
  },
  {
    "text": "read any kind of\ntextual description that does the analysis for me. And so to me, these sound very\nsimilar to issues associated",
    "start": "1076400",
    "end": "1085010"
  },
  {
    "text": "with a semantic and articulatory\ndistance, that first quote talking about, well, these\ntexts aren't conveying anything",
    "start": "1085010",
    "end": "1091700"
  },
  {
    "text": "interesting, the second\nset talking about, well, I want to have\nthat time and space. I want to be able to control\nthe form with which that text is",
    "start": "1091700",
    "end": "1100370"
  },
  {
    "text": "conveyed to me. And so I want to dig\ninto how we might address these two distances\nin the case of accessibility.",
    "start": "1100370",
    "end": "1107600"
  },
  {
    "text": "But before I do that,\nI want to give us a sense of how people who\nare blind or have low vision",
    "start": "1107600",
    "end": "1112790"
  },
  {
    "text": "experience the internet and\ngraphical interfaces today.",
    "start": "1112790",
    "end": "1118730"
  },
  {
    "text": "So I'm going to turn things\nover to my PhD student, Jonathan Zong, who will give us a quick\ndemo of an assistive technology",
    "start": "1118730",
    "end": "1125600"
  },
  {
    "text": "called a screen reader\nthat basically narrates on-screen content. ",
    "start": "1125600",
    "end": "1142290"
  },
  {
    "text": "Selected by the cursor will\nbe read out as text-to-speech. So here, I can demonstrate what\nthe accessible HTML version",
    "start": "1142290",
    "end": "1149160"
  },
  {
    "text": "of our paper looks like\nto a screen reader. (RAPIDLY) Visiting\nlink heading level 1. Hi, we are MIT\nVisualization Group.",
    "start": "1149160",
    "end": "1154980"
  },
  {
    "text": "Visited link Home, middle.link,\nmiddle.link, link, link. Heading level 1. Rich Screen Reader experiences\nfor accessible data visualization.",
    "start": "1154980",
    "end": "1160380"
  },
  {
    "text": "Link, link, link, link, link. Best paper honorable\nmention article. You are currently on article\ninside of web content.",
    "start": "1160380",
    "end": "1165630"
  },
  {
    "text": "Heading level two. Two items. Abstract. Current web accessibility\nguidelines ask visualization designers to support screen\nreaders via basic non-visual--",
    "start": "1165630",
    "end": "1171257"
  },
  {
    "text": "So as you can see, what a screen\nreader does is it basically linearizes the operation\nof reading, perceiving,",
    "start": "1171257",
    "end": "1178650"
  },
  {
    "text": "understanding graphical\ncontent on a user interface. And in particular, you might\nnotice that the narration",
    "start": "1178650",
    "end": "1185580"
  },
  {
    "text": "was actually quite rapid. And this is actually\na slowed-down version of what proficient\nscreen reader users use,",
    "start": "1185580",
    "end": "1194070"
  },
  {
    "text": "which is often\nmuch, much faster. But what is interesting about\nthe screen reader use case",
    "start": "1194070",
    "end": "1199470"
  },
  {
    "text": "is that it forces\nthat linearity. And the key challenge\nin figuring out",
    "start": "1199470",
    "end": "1205390"
  },
  {
    "text": "the articulatory distance\nin the case of accessibility is, how do you\ntake visualizations that probably all of\nus in the audience",
    "start": "1205390",
    "end": "1212110"
  },
  {
    "text": "have slightly, subtly\ndifferent ways of reading-- maybe some of you start\nby reading the title, then moving to the axes,\nthen looking at the shapes,",
    "start": "1212110",
    "end": "1219850"
  },
  {
    "text": "while others might\nstart by looking at the most salient\ntrend and then start to map out to what the\naxes and legends and stuff like",
    "start": "1219850",
    "end": "1227950"
  },
  {
    "text": "that are. How do we take all of\nthat rich diversity but linearize it so that\npeople who use screen readers",
    "start": "1227950",
    "end": "1234880"
  },
  {
    "text": "can nevertheless have that\nsame choice in reading a visualization but\nunder these conditions?",
    "start": "1234880",
    "end": "1242140"
  },
  {
    "text": "And so the way we have chosen\nto do that is basically by restructuring the\ncontent of a visualization",
    "start": "1242140",
    "end": "1248950"
  },
  {
    "text": "into a text-oriented hierarchy. So at the top, at the\nroot of this hierarchy",
    "start": "1248950",
    "end": "1254440"
  },
  {
    "text": "is just a summary of\nthe chart, probably the trends that are\nshown in the chart. And then the hierarchy branches\noff into the individual data",
    "start": "1254440",
    "end": "1263350"
  },
  {
    "text": "fields or the encodings in this\ncase, the x-axis, the y-axis, the legend, and\nthings like that.",
    "start": "1263350",
    "end": "1268930"
  },
  {
    "text": "And then people can\nstart to drill down in ways that maintain\nsome correspondence",
    "start": "1268930",
    "end": "1274450"
  },
  {
    "text": "with the visual artifact. So one step below the x-axis\nis stepping through them",
    "start": "1274450",
    "end": "1280330"
  },
  {
    "text": "by the major ticks. One step below the major\nticks would be minor ticks, and then ultimately, you would\nget to the individual data",
    "start": "1280330",
    "end": "1286480"
  },
  {
    "text": "points. So let me throw things\nback to Jonathan to give us a demo\nof how this works. ",
    "start": "1286480",
    "end": "1293030"
  },
  {
    "text": "A scatterplot of penguin data. And to a screen\nreader, our system represents this scatterplot\nas a keyboard-navigable data",
    "start": "1293030",
    "end": "1301550"
  },
  {
    "text": "structure that contains\ntext descriptions at varying levels of detail. So when a screen\nreader user first",
    "start": "1301550",
    "end": "1308240"
  },
  {
    "text": "encounters this\nvisualization on a page, they'll be able to read off a\nhigh level alt-text description",
    "start": "1308240",
    "end": "1314900"
  },
  {
    "text": "of what the chart is. (RAPIDLY) A scatterplot showing\nbody mass and flipper length of penguins. And if they're interested\nin getting more detail",
    "start": "1314900",
    "end": "1322700"
  },
  {
    "text": "about this visualization,\nthey can dive in by pressing the down\narrow key to descend one level in the hierarchy\nand access descriptions",
    "start": "1322700",
    "end": "1331580"
  },
  {
    "text": "about the different\nencodings of the scatterplot. So I'm going to press\nthe down arrow key. (RAPIDLY) X-axis titled,\n\"Flipper length [INAUDIBLE]",
    "start": "1331580",
    "end": "1337460"
  },
  {
    "text": "for a linear scale with\nvalues from 170 to 240.\" I can press the left\nand right arrow keys to flip through descriptions\nof the other axes and legends.",
    "start": "1337460",
    "end": "1345500"
  },
  {
    "text": "(RAPIDLY) Y-axis\ntitled, \"Body mass, g, for a linear scale with\nvalues from 2500 to 6500.\" Legend titled,\n\"Species for color",
    "start": "1345500",
    "end": "1350780"
  },
  {
    "text": "with three values,\nAdélie, Chinstrap, Gentoo. Grid view of scatterplot. Cool. So let's say I am\ninterested in getting more",
    "start": "1350780",
    "end": "1357770"
  },
  {
    "text": "information about the x-axis. I can use the left arrow\nkey to navigate back",
    "start": "1357770",
    "end": "1363679"
  },
  {
    "text": "to the x-axis\ndescription and then press down one more time to\ndescend a level of detail",
    "start": "1363680",
    "end": "1368990"
  },
  {
    "text": "into the x-axis. (RAPIDLY) Legend titled--\ny-axis titled-- x-axis titled, \"Flipper length\n[INAUDIBLE] range 220, 230.",
    "start": "1368990",
    "end": "1374780"
  },
  {
    "text": "35 data values in the interval.\" So on this level\nunderneath the x-axis,",
    "start": "1374780",
    "end": "1380580"
  },
  {
    "text": "I'm accessing descriptions of\nintervals along the x-axis, and it's reading out to me\nhow many data values are",
    "start": "1380580",
    "end": "1388800"
  },
  {
    "text": "contained within each interval. So by pressing left\nand right, I can get a sense of the distribution\nof data along the x-axis.",
    "start": "1388800",
    "end": "1396440"
  },
  {
    "text": "(RAPIDLY) Range to--\nrange to-- range 190. Range-- range 170. Range-- range 190, 200.",
    "start": "1396440",
    "end": "1402090"
  },
  {
    "text": "113 values in the interval. So let's say I am interested\nin this range from 190 to 200.",
    "start": "1402090",
    "end": "1408539"
  },
  {
    "text": "I can then press down\narrow again to dive into the individual\ndata points that are contained within this interval.",
    "start": "1408540",
    "end": "1414659"
  },
  {
    "text": "(RAPIDLY) One of 113. Flipper length. [INAUDIBLE] 190. Body mass g, 3650. Species Adélie. Two of 113.",
    "start": "1414660",
    "end": "1420600"
  },
  {
    "text": "Flip-- three of 113. Four of 113. Five of 113. So let's say that\ninstead of moving",
    "start": "1420600",
    "end": "1427779"
  },
  {
    "text": "up and down this\nhierarchical structure, I would rather just move around\nthe x y grid in this scatterplot",
    "start": "1427780",
    "end": "1434170"
  },
  {
    "text": "as if I were feeling around a\ntactile graphic, for example.",
    "start": "1434170",
    "end": "1439450"
  },
  {
    "text": "I can start by navigating\nover to the grid view of the scatterplot. (RAPIDLY) Y-axis title--\nlegend title-- grid view of scatterplot.",
    "start": "1439450",
    "end": "1445598"
  },
  {
    "text": "79 data values in the interval. Body mass-- And once I descend into\nthis part of the hierarchy,",
    "start": "1445598",
    "end": "1451180"
  },
  {
    "text": "I can use the WASD keys to move\nup and down different squares",
    "start": "1451180",
    "end": "1457150"
  },
  {
    "text": "along the grid. (RAPIDLY) 10 data\nvalues in the interval. Body mass-- 25 data\nvalues in the interval. Body-- 32 data values\nin the interval. Zero-- three data values.",
    "start": "1457150",
    "end": "1462940"
  },
  {
    "text": "23-- 30 data values\nin the interval. Three data values\nin the interval. Body mass g. And so similarly to\nbefore, it's starting off",
    "start": "1462940",
    "end": "1469600"
  },
  {
    "text": "by giving me the\nnumber of data values that are contained\nin that square, so that I can get a sense of\nthe distribution of the data.",
    "start": "1469600",
    "end": "1477429"
  },
  {
    "text": "And so we designed this in\ncollaboration with a blind HCI",
    "start": "1477430",
    "end": "1483040"
  },
  {
    "text": "researcher named Daniel Hajas. And this was the first time he\nfelt like he actually understood",
    "start": "1483040",
    "end": "1490250"
  },
  {
    "text": "and could build a\nmental model of what it was that a scatterplot\nwas representing.",
    "start": "1490250",
    "end": "1497000"
  },
  {
    "text": "We saw these sorts of comments\nreflected in user studies that we ran about how the\nform of this textual output",
    "start": "1497000",
    "end": "1504920"
  },
  {
    "text": "really influenced participants'\nmental model of what the data was, what the trends\nwere, and things like that.",
    "start": "1504920",
    "end": "1510840"
  },
  {
    "text": "So one participant,\nfor instance, said, I now know how\nto drill down and up between different layers in the\ndata to get an overall picture,",
    "start": "1510840",
    "end": "1519139"
  },
  {
    "text": "and it gives me a\ndifferent way of thinking. And another one said, I'm\nthinking more in spatial terms",
    "start": "1519140",
    "end": "1524660"
  },
  {
    "text": "because this is just a new\nmethod for navigating and moving through the grid and drilling\ndown to information and things",
    "start": "1524660",
    "end": "1531680"
  },
  {
    "text": "like that. And so what I find interesting\nhere is that at every step,",
    "start": "1531680",
    "end": "1537200"
  },
  {
    "text": "the semantic content\nstayed exactly the same. And there wasn't even very\nrich semantic content. It was a range and then a\ncount of the data values.",
    "start": "1537200",
    "end": "1545270"
  },
  {
    "text": "All we manipulated was that\narticulation, that form. Giving it a hierarchical\nnature, adding",
    "start": "1545270",
    "end": "1551720"
  },
  {
    "text": "all of these different\nnavigational affordances, and just manipulating\nthe articulation",
    "start": "1551720",
    "end": "1556820"
  },
  {
    "text": "had this huge impact on people's\nmental models of the data. And I think that\nwe're really just",
    "start": "1556820",
    "end": "1562670"
  },
  {
    "text": "at the tip of the\niceberg of these more accessible structures. Currently in my group, we're\nthinking about just the impact",
    "start": "1562670",
    "end": "1569809"
  },
  {
    "text": "that token order has on how\npeople using screen readers build up those mental models.",
    "start": "1569810",
    "end": "1575390"
  },
  {
    "text": "If you're constantly\nprompting them with the range first rather than the\nactual data values,",
    "start": "1575390",
    "end": "1580550"
  },
  {
    "text": "does that introduce\nfriction to their capacity to build that mental model\nand things like that.",
    "start": "1580550",
    "end": "1586370"
  },
  {
    "text": "But in all of this, where\nis semantic distance? How do we actually start to make\nthat textual descriptions more",
    "start": "1586370",
    "end": "1594530"
  },
  {
    "text": "interesting and meaningful? And this is where I think\nLLMs can really help us. For one reason, it's\nbecause there's just",
    "start": "1594530",
    "end": "1601280"
  },
  {
    "text": "a sheer amount of\ntextual content we need to be able to produce\nthat is infeasible to expect",
    "start": "1601280",
    "end": "1607880"
  },
  {
    "text": "a human to manually author. But there are other\nimplications that we'll",
    "start": "1607880",
    "end": "1613280"
  },
  {
    "text": "touch upon really shortly. But before we can get\nLLMs to actually produce the content we want,\nwhat we need to do",
    "start": "1613280",
    "end": "1620900"
  },
  {
    "text": "is shift from that very latent\nspace with implicit semantics to a set of explicit semantics.",
    "start": "1620900",
    "end": "1627169"
  },
  {
    "text": "We need to impose a conceptual\nmodel onto our LLMs. Or another way of\nsaying that is,",
    "start": "1627170",
    "end": "1632870"
  },
  {
    "text": "we need to get the\nLLMs to understand what a good textual description\nof a visualization is.",
    "start": "1632870",
    "end": "1638390"
  },
  {
    "text": "And so that's what my then PhD\nstudent Alan Lundgard set out to do. We ran a crowdsourced\nstudy where we got",
    "start": "1638390",
    "end": "1645440"
  },
  {
    "text": "2000 descriptions of charts. And through\nqualitative coding, we",
    "start": "1645440",
    "end": "1651860"
  },
  {
    "text": "realized there are basically\nfour kinds of semantic content that textual description\nshould convey.",
    "start": "1651860",
    "end": "1656930"
  },
  {
    "text": "The first, most primitive\nlayer is basically just the construction\ndetails of the chart,",
    "start": "1656930",
    "end": "1662210"
  },
  {
    "text": "what are the titles, the labels,\nthe scales, the units, et cetera. And accessibility\nbest practices say",
    "start": "1662210",
    "end": "1668622"
  },
  {
    "text": "that this is some of the\nmost important content to convey because it gives\npeople important milestones",
    "start": "1668622",
    "end": "1674570"
  },
  {
    "text": "and landmarks. One level above that are\nthe statistical properties like minimum, maximum,\noutliers, and things like that.",
    "start": "1674570",
    "end": "1682040"
  },
  {
    "text": "And then one level\nabove that is probably what, as sighted\npeople, we consider the real value of\nvisualization to be,",
    "start": "1682040",
    "end": "1688100"
  },
  {
    "text": "the perceptual and\ncognitive characteristics, like complex trends\nand patterns, things that automated\nstatistical methods we typically",
    "start": "1688100",
    "end": "1695630"
  },
  {
    "text": "think of as not\nbeing sufficient at. And then finally, the\nfourth and highest level are what journalists\noften consider",
    "start": "1695630",
    "end": "1702237"
  },
  {
    "text": "to be the real value\nof visualization, which is the narration that\ngets associated with it. What is the data\nstory that you're",
    "start": "1702237",
    "end": "1708200"
  },
  {
    "text": "able to tell through\nthe visualization? Can you explain\nwhat you're seeing, the causal mechanisms,\net cetera, et cetera?",
    "start": "1708200",
    "end": "1713779"
  },
  {
    "text": "Now another reason I\nthink LLMs are really suited for this\nsemantic bridging task",
    "start": "1713780",
    "end": "1719690"
  },
  {
    "text": "is because when we asked\nsighted and blind people what their preference\nprinces were when",
    "start": "1719690",
    "end": "1725029"
  },
  {
    "text": "it came to these four\nlayers four levels, we saw really\ndistinct preferences.",
    "start": "1725030",
    "end": "1730940"
  },
  {
    "text": "In the case of sighted\npeople, because we've got our own visual\nperception, doing",
    "start": "1730940",
    "end": "1737090"
  },
  {
    "text": "that bridging of the\ngulf of evaluation, sighted people tended to\nwant higher and higher levels",
    "start": "1737090",
    "end": "1744020"
  },
  {
    "text": "of content being\nconveyed through text. Blind readers, on\nthe other hand, were pretty\nsignificantly divergent.",
    "start": "1744020",
    "end": "1750950"
  },
  {
    "text": "For many of them,\nthey didn't want those level three and four-- particularly the level\nfour-- captions at all",
    "start": "1750950",
    "end": "1756200"
  },
  {
    "text": "because they wanted\nthat time and space to do the interpretation\nfor themselves.",
    "start": "1756200",
    "end": "1761210"
  },
  {
    "text": "And so here, this\nvisualization, to me, conveys that LLMs\nor machine learning",
    "start": "1761210",
    "end": "1769430"
  },
  {
    "text": "models can help us think\nabout personalizing the semantics of a\nuser interface in a way",
    "start": "1769430",
    "end": "1775190"
  },
  {
    "text": "that maybe we haven't had the\nopportunity to study so far. There's been a lot of\nwork in personalization,",
    "start": "1775190",
    "end": "1781160"
  },
  {
    "text": "but it's often been at that\nlevel of the articulation, changing the sizes of buttons\nand adapting color palettes",
    "start": "1781160",
    "end": "1788010"
  },
  {
    "text": "and things like that. And there's maybe\nan opportunity now to use LLMs to\nactually change what",
    "start": "1788010",
    "end": "1793080"
  },
  {
    "text": "the nouns, the verbs, the\nconcepts of a user interface",
    "start": "1793080",
    "end": "1798600"
  },
  {
    "text": "are much more fundamentally. And so the way we're\ngoing about doing this in the case of\ntextual descriptions",
    "start": "1798600",
    "end": "1804450"
  },
  {
    "text": "is we're going to be releasing\nvery soon a data set of about-- actually, now we're over\n12,000 pairs of chart captions.",
    "start": "1804450",
    "end": "1811200"
  },
  {
    "text": "And we've generated\nsome of these captions, and we've crowdsourced\nsome of these captions. And we started to train\nbaseline models to do this task,",
    "start": "1811200",
    "end": "1818850"
  },
  {
    "text": "and one of the\ninteresting features here is how do we represent\nthe semantics of a chart",
    "start": "1818850",
    "end": "1823980"
  },
  {
    "text": "to a large language model? One way could just be, let's\ntreat the chart as an image.",
    "start": "1823980",
    "end": "1829440"
  },
  {
    "text": "This is just a set of pixels. And unsurprisingly,\nthe baseline models don't do very well at that\nbecause a chart is a much richer",
    "start": "1829440",
    "end": "1837540"
  },
  {
    "text": "artifact than just an image. It's got all this\nrich structure. So then we said, great. Let's look at a data table\nor let's look at a scene",
    "start": "1837540",
    "end": "1844590"
  },
  {
    "text": "graph, which is just a fancy\nway of saying the SVG associated with the chart. And a priori, we would\nhave thought, well,",
    "start": "1844590",
    "end": "1850800"
  },
  {
    "text": "the scene graph is\nmaybe a good in-between between the computational\naffordances of data table",
    "start": "1850800",
    "end": "1856410"
  },
  {
    "text": "and capturing some of those\nperceptual characteristics. Turns out for the LLMs\nwe trained that were all",
    "start": "1856410",
    "end": "1862800"
  },
  {
    "text": "transformer models, they\ndid equivalently well on those two representations. And so one of the things my\ngroup is working on right now",
    "start": "1862800",
    "end": "1869309"
  },
  {
    "text": "is a new way of\nrepresenting visualizations that more directly encode some\nof those perceptual operations",
    "start": "1869310",
    "end": "1876570"
  },
  {
    "text": "that are otherwise currently\nimplicit in a scene graph, that grammar of graphics\nlibraries like Vega-Lite",
    "start": "1876570",
    "end": "1883169"
  },
  {
    "text": "or ggplot perform. But what's interesting\nin all of this, to me, is that through these generative\nmodels, the goal has been,",
    "start": "1883170",
    "end": "1890310"
  },
  {
    "text": "how do we impose a\nconceptual model onto them? How do we bring some\nexplicit semantics?",
    "start": "1890310",
    "end": "1897090"
  },
  {
    "text": "And I think we're just\nscratching the surface here as well because I think the\nchart example case is",
    "start": "1897090",
    "end": "1903179"
  },
  {
    "text": "a really great one where a\nlot of these representations of charts that we've got right\nnow-- the grammar of graphics,",
    "start": "1903180",
    "end": "1908340"
  },
  {
    "text": "for instance-- were designed\nfor people to author. So we're really\ngood at figuring out how to design\nprogramming languages,",
    "start": "1908340",
    "end": "1914490"
  },
  {
    "text": "domain-specific\nlanguages to emphasize the cognitive\ncharacteristics that are important for\nhuman authors, things",
    "start": "1914490",
    "end": "1920549"
  },
  {
    "text": "like the cognitive\ndimensions of notation that cares about how viscous is\nthe programming language, how",
    "start": "1920550",
    "end": "1925762"
  },
  {
    "text": "many premature commitments\ndoes the programming language enforce. But I don't know what it means\nto design a representation",
    "start": "1925762",
    "end": "1931919"
  },
  {
    "text": "to be suitable for an\nLLM to operate over. Do we restructure the\nprogramming language",
    "start": "1931920",
    "end": "1938190"
  },
  {
    "text": "more fundamentally to make\nit tractable for an LLM? Maybe. So in addition to\ngenerative models,",
    "start": "1938190",
    "end": "1944800"
  },
  {
    "text": "my group has also been working\nwith predictive models. And here, I think the\nbridging task is really",
    "start": "1944800",
    "end": "1950920"
  },
  {
    "text": "not about imposing\na conceptual model but bridging it or\naligning it to the ones",
    "start": "1950920",
    "end": "1956740"
  },
  {
    "text": "that we already have. And often, the way that a\nlot of this work happens is through the lens of\nmodel interpretability.",
    "start": "1956740",
    "end": "1963789"
  },
  {
    "text": "So here is a very popular set of\ntechniques called saliency maps.",
    "start": "1963790",
    "end": "1969460"
  },
  {
    "text": "The idea behind\nsaliency maps is they're trying to depict the most\nimportant input features",
    "start": "1969460",
    "end": "1976750"
  },
  {
    "text": "for a particular outcome. So in this case,\nthis is an image. The label should\nbe \"toy terrier,\"",
    "start": "1976750",
    "end": "1982870"
  },
  {
    "text": "and here's what a variety\nof different kinds of saliency methods believe to\nbe the most important pixels",
    "start": "1982870",
    "end": "1989350"
  },
  {
    "text": "to produce that outcome. Now I look at these\nvisualizations and I go,",
    "start": "1989350",
    "end": "1996140"
  },
  {
    "text": "well, is it telling\nme something? Maybe.",
    "start": "1996140",
    "end": "2001530"
  },
  {
    "text": "And maybe the reason I\nbelieve it's telling me something is because I'm\nthe one doing the perception",
    "start": "2001530",
    "end": "2007980"
  },
  {
    "text": "and interpretive tasks. Like if I look at some of those\nvisualizations on the bottom, I go, oh, it looks\nlike the dog's snout is",
    "start": "2007980",
    "end": "2014880"
  },
  {
    "text": "really important to the\nclassification of a toy terrier or the spots. But it's not actually\nthe saliency method",
    "start": "2014880",
    "end": "2020940"
  },
  {
    "text": "that is doing that\ninterpretation for me. I'm the one bringing\nmeaning to those lit pixels.",
    "start": "2020940",
    "end": "2026549"
  },
  {
    "text": "And so as a result, if we think\nabout that gulf of evaluation, it's not the saliency\nmethod that's",
    "start": "2026550",
    "end": "2033030"
  },
  {
    "text": "helping bridge that\ngulf in any way, which is why saliency maps for now\nhave been these tools that we",
    "start": "2033030",
    "end": "2039030"
  },
  {
    "text": "just use in a very\nad hoc way that require a lot of manual\neffort to make sense of.",
    "start": "2039030",
    "end": "2044460"
  },
  {
    "text": "And so a question that\nmy student Angie Boggust has been focused\non is, how do we",
    "start": "2044460",
    "end": "2049620"
  },
  {
    "text": "scaffold that semantic\nsense-making operation, providing some additional\nstructure to help scale it up",
    "start": "2049620",
    "end": "2057638"
  },
  {
    "text": "to make it more reproducible\nand things like that. And what she's\ndeveloped is these set of metrics that are very\nanalogous to ideas of precision",
    "start": "2057639",
    "end": "2065710"
  },
  {
    "text": "and recall but are operating\nat the level of input features and interpretability. So in many data sets,\nyou've got some set",
    "start": "2065710",
    "end": "2073119"
  },
  {
    "text": "of ground-truthed,\nhuman-annotated features, and what shared\ninterest is looking at is, what is the overlap between\nwhat a saliency method considers",
    "start": "2073120",
    "end": "2081250"
  },
  {
    "text": "as being important\nto the classification and what the human annotators\nthought was important.",
    "start": "2081250",
    "end": "2086770"
  },
  {
    "text": "And there's actually\nthree different ways that these overlaps\ncan manifest. The first is a\nground-truth coverage,",
    "start": "2086770",
    "end": "2093638"
  },
  {
    "text": "which is very analogous\nto ideas of recall. It's, how much of\nthe ground truth does the model incorporate\nin its prediction,",
    "start": "2093639",
    "end": "2100800"
  },
  {
    "text": "or what is the proportion of\nthe ground-truth region that is covered by the saliency region? And if we look at some\nexamples of low coverage",
    "start": "2100800",
    "end": "2107860"
  },
  {
    "text": "on the top and high\ncoverage at the bottom, we can see that in the case\nof low ground-truth coverage, there's actually very little\noverlap between the ground",
    "start": "2107860",
    "end": "2115750"
  },
  {
    "text": "truth, the yellow region, and\nthe salient region in orange. But I often find\nthat it's actually",
    "start": "2115750",
    "end": "2121089"
  },
  {
    "text": "the high-coverage regions that\nare more interesting to analyze. So if we compare cases where the\nmodel was correct on the right,",
    "start": "2121090",
    "end": "2129160"
  },
  {
    "text": "with the green label, and cases\nwhere the model was incorrect, with the red label,\nwe can see in the case",
    "start": "2129160",
    "end": "2134740"
  },
  {
    "text": "of correct, high\nground-truth coverage, there are instances where\nthe model relies not just on the object-- like\nin this case with the cab,",
    "start": "2134740",
    "end": "2141700"
  },
  {
    "text": "but a lot of contextual\ninformation as well to ultimately make that\ncorrect prediction.",
    "start": "2141700",
    "end": "2147609"
  },
  {
    "text": "But on the flip side,\nwith the laptop, the model is doing\nthe same thing. But here, the context is\nactually throwing it off.",
    "start": "2147610",
    "end": "2155744"
  },
  {
    "text": "It's actually\nconfusing the model because it's accounting for\ntoo much of that context in its decision-making.",
    "start": "2155745",
    "end": "2161740"
  },
  {
    "text": "Another kind of coverage is\nsomething we call saliency coverage-- and this is\nmore akin to precision--",
    "start": "2161740",
    "end": "2166900"
  },
  {
    "text": "which is, how strictly\nis the model relying only on ground-truth features\nto make its prediction.",
    "start": "2166900",
    "end": "2174099"
  },
  {
    "text": "And again, if we look at\nlow and high coverage, in the case of low\ncoverage, we can see again",
    "start": "2174100",
    "end": "2179290"
  },
  {
    "text": "pretty disjoint sorts of sets. But in the case of the\nhigh-coverage regions,",
    "start": "2179290",
    "end": "2185800"
  },
  {
    "text": "we can see that in the case\nof high-saliency coverage, it basically means\nthat the salient",
    "start": "2185800",
    "end": "2191589"
  },
  {
    "text": "regions are a strict subset\nof the ground-truth coverage. But the difference between a\ncorrect and incorrect prediction",
    "start": "2191590",
    "end": "2198460"
  },
  {
    "text": "is whether that subset\nwas sufficient to make the correct\nclassification or not.",
    "start": "2198460",
    "end": "2205119"
  },
  {
    "text": "So in the case of\nthe Maltese dog, it did indeed only need\nto look at the head to make that correct prediction.",
    "start": "2205120",
    "end": "2210520"
  },
  {
    "text": "But in the case\nof the Dalmatian, it probably should\nhave accounted for more of that\ndog's head or some",
    "start": "2210520",
    "end": "2217102"
  },
  {
    "text": "of the other characteristics\nassociated with the dog. By focusing only\non the snout, it ended up arriving at the\nincorrect classification.",
    "start": "2217102",
    "end": "2225920"
  },
  {
    "text": "And finally, the last\nmetric is something that is very familiar-- IoU, the intersection\nover the union.",
    "start": "2225920",
    "end": "2231500"
  },
  {
    "text": "This is the strictest\nshared-interest metric. It's really measuring how\naligned the model's behavior",
    "start": "2231500",
    "end": "2236869"
  },
  {
    "text": "is with human reasoning. So if you look at some examples,\nagain, low coverage at the top,",
    "start": "2236870",
    "end": "2242600"
  },
  {
    "text": "we can see in incorrect\ncases, totally distinct, disjoint sets again.",
    "start": "2242600",
    "end": "2248510"
  },
  {
    "text": "But in a correct\ninstance, I actually find that pretty interesting. Low IoU coverage, but it got\na correct classification.",
    "start": "2248510",
    "end": "2256280"
  },
  {
    "text": "Now, one could say\nmaybe it got lucky. But potentially,\nwhat the signal there is that maybe all\nthe model needs",
    "start": "2256280",
    "end": "2263540"
  },
  {
    "text": "is a tiny bit of a wheel\nassociated with a horse right to make the prediction that it's\nactually a horse cart and not",
    "start": "2263540",
    "end": "2270290"
  },
  {
    "text": "just a horse. And on the flip side, with high\ncoverage, Newfoundland, great.",
    "start": "2270290",
    "end": "2277700"
  },
  {
    "text": "Total, total alignment. But in this case, incorrect\nclassification even though there was high coverage.",
    "start": "2277700",
    "end": "2283760"
  },
  {
    "text": "This might suggest genuinely\ndifficult-to-classify images, even for people.",
    "start": "2283760",
    "end": "2289010"
  },
  {
    "text": "Because if I look at\nthat, a pickup truck seems a totally reasonable guess\nto have made about the image.",
    "start": "2289010",
    "end": "2294380"
  },
  {
    "text": "I don't know that I've got\nenough visual information there to call that a snowplow. So shared interests\nbasically gives us",
    "start": "2294380",
    "end": "2301970"
  },
  {
    "text": "a mechanism to start to\nscaffold and structure or bridge that\nsemantic distance.",
    "start": "2301970",
    "end": "2307250"
  },
  {
    "text": "People no longer necessarily\nneed to manually start to analyze these things. And in fact, we analyzed\nlots of different models",
    "start": "2307250",
    "end": "2315470"
  },
  {
    "text": "across both vision\nand natural language and found that\ndifferent combinations of these\nshared-interest metrics,",
    "start": "2315470",
    "end": "2321740"
  },
  {
    "text": "along with figuring out whether\nthe prediction was correct or not, actually surfaced eight\nkinds of repeating patterns",
    "start": "2321740",
    "end": "2328670"
  },
  {
    "text": "in model behavior. So we can see human-aligned\nand some of these others we also looked at earlier,\ncontext confusion,",
    "start": "2328670",
    "end": "2336320"
  },
  {
    "text": "context dependent, and so forth. And all of these\ngive us semantics that we can start to\nplay around with through",
    "start": "2336320",
    "end": "2343310"
  },
  {
    "text": "different articulations. So one articulation\nof these semantics might be a very traditional\nvisual analytics interface,",
    "start": "2343310",
    "end": "2350480"
  },
  {
    "text": "where I've got all the\ndifferent kinds of images that I care about. This is a system\nwe built to help",
    "start": "2350480",
    "end": "2356000"
  },
  {
    "text": "a board-certified dermatologist\nmake sense of this melanoma detection model. And you've got query widgets\non the top to sort and filter.",
    "start": "2356000",
    "end": "2364010"
  },
  {
    "text": "You can use these histograms\nof the shared-interest metrics to really drill into the data.",
    "start": "2364010",
    "end": "2370340"
  },
  {
    "text": "But what was maybe\nmost interesting was what the\ndermatologist said when they started to analyze\nthat recurring pattern",
    "start": "2370340",
    "end": "2377240"
  },
  {
    "text": "of context-dependent cases. So in particular,\nwhen they switched",
    "start": "2377240",
    "end": "2382490"
  },
  {
    "text": "to these\ncontext-dependent cases, the dermatologist\nstarted to wonder if the model is seeing something\nwe are not truly appreciating",
    "start": "2382490",
    "end": "2390740"
  },
  {
    "text": "in the clinical image. Maybe there are subtle\nchanges we don't yet understand that the\nmodel does right",
    "start": "2390740",
    "end": "2398270"
  },
  {
    "text": "at the boundaries of the skin\nlesion and things like that. And so, to me, this is\nalluding to the fact of,",
    "start": "2398270",
    "end": "2406150"
  },
  {
    "text": "well, can we as domain\nexperts learn something about our problem\ndomain based on how",
    "start": "2406150",
    "end": "2411910"
  },
  {
    "text": "it is models are operating. And I think we see this more\nclearly in another articulation",
    "start": "2411910",
    "end": "2417400"
  },
  {
    "text": "of shared-interest semantics. Here, what we're doing is\nbasically using shared interest to interactively probe or\nquery that latent space.",
    "start": "2417400",
    "end": "2425560"
  },
  {
    "text": "So we're brushing and using that\nbrushed region as ground truth and then calculating\nthe IoU coverage",
    "start": "2425560",
    "end": "2431890"
  },
  {
    "text": "to figure out, what are\nall the classes that maximize IoU coverage for\nthat brush ground truth.",
    "start": "2431890",
    "end": "2437859"
  },
  {
    "text": "So we can see if\nI brush over hand, a lot of the classes\nthat get returned",
    "start": "2437860",
    "end": "2443500"
  },
  {
    "text": "are things that are\noften associated with hands, like\nlaptops and cleavers and interestingly enough, hen.",
    "start": "2443500",
    "end": "2449800"
  },
  {
    "text": "So I guess a lot of the\nimages in the image data set have people holding\nhens, which is, I guess,",
    "start": "2449800",
    "end": "2457630"
  },
  {
    "text": "kind of interesting. But more, maybe,\nprofoundly is we could ask a question like,\nwhat is the essence of a dog?",
    "start": "2457630",
    "end": "2466910"
  },
  {
    "text": "What is the minimal\namount of region that I would need to\nbrush for the model to still be convinced that what\nit is classifying as a dog?",
    "start": "2466910",
    "end": "2475130"
  },
  {
    "text": "So I could start\nwith the whole dog and then brush just\non its head, ensure",
    "start": "2475130",
    "end": "2480140"
  },
  {
    "text": "querying with shared interest\nstill returns dog classes. But then I could\nuse a smaller brush",
    "start": "2480140",
    "end": "2485330"
  },
  {
    "text": "and brush just on the\nnose, and it still returns German shepherd and\nsheepdog and Tibetan terrier",
    "start": "2485330",
    "end": "2493460"
  },
  {
    "text": "and things like that. So it seems like,\naccording to the model, all it really needs to\nknow about an object",
    "start": "2493460",
    "end": "2502820"
  },
  {
    "text": "in the image is the shape of\nits nose or something associated with its nose to be able to\nclassify whether it is or is not",
    "start": "2502820",
    "end": "2510680"
  },
  {
    "text": "a dog. And this seems like\na really toy example, but it reflects\nsome of the things",
    "start": "2510680",
    "end": "2516080"
  },
  {
    "text": "that real-world\nscientists are doing. So in particular,\nthere's a researcher",
    "start": "2516080",
    "end": "2522403"
  },
  {
    "text": "at the University of\nWashington, Julia Parrish, that runs this grand,\ncrowdsourced data collection",
    "start": "2522403",
    "end": "2527810"
  },
  {
    "text": "project around seabird deaths. And the way they train their\nparticipants to figure out",
    "start": "2527810",
    "end": "2532910"
  },
  {
    "text": "how to do bird\nclassification is by asking them to measure the bird beaks\nand the bird feet and things",
    "start": "2532910",
    "end": "2539089"
  },
  {
    "text": "like that. And so I think it's\nreally interesting that we're seeing maybe\nsome of those sorts of representations creep\nup in how a model is",
    "start": "2539090",
    "end": "2547880"
  },
  {
    "text": "making its decisions as well. And so where I want\nto end is being",
    "start": "2547880",
    "end": "2553500"
  },
  {
    "text": "most speculative\nin where I think there's scope for HCI to grow.",
    "start": "2553500",
    "end": "2559230"
  },
  {
    "text": "And so we looked at\ngenerative models and imposing a\nconceptual model on them. We looked at predictive\nmodels, where the idea",
    "start": "2559230",
    "end": "2565680"
  },
  {
    "text": "was to align conceptual models. But what I think we're hearing\nfrom that dermatologist,",
    "start": "2565680",
    "end": "2571350"
  },
  {
    "text": "we're seeing in that last case\nstudy with shared interest is the potential to use machine\nlearning models to basically",
    "start": "2571350",
    "end": "2578520"
  },
  {
    "text": "discover new representations\nof particular problem domains.",
    "start": "2578520",
    "end": "2583950"
  },
  {
    "text": "And again, at my\nmost speculative, I don't know what\nI would call these, but I would maybe call them\nabstraction models, where",
    "start": "2583950",
    "end": "2591029"
  },
  {
    "text": "the goal of these\nmodels is not to produce some particular outcome that\nI care about, but to maximize,",
    "start": "2591030",
    "end": "2596880"
  },
  {
    "text": "what are the different ways\nof representing the world. What are all the\ndiverse abstractions that we could learn\nabout a problem domain",
    "start": "2596880",
    "end": "2603960"
  },
  {
    "text": "like classifying\ndogs or classifying seabirds or things like that. And I think this is a really\ninteresting opportunity",
    "start": "2603960",
    "end": "2610109"
  },
  {
    "text": "to use machine learning\nto essentially advance our understanding,\nadvance our science.",
    "start": "2610110",
    "end": "2615119"
  },
  {
    "text": "But I want to be careful\nhere because we've already seen through this talk, but\nalso in the broader discourse,",
    "start": "2615120",
    "end": "2621270"
  },
  {
    "text": "how generative and\npredictive models can muddy that gulf of evaluation. Lots of people are starting to\nanthropomorphize these models.",
    "start": "2621270",
    "end": "2630150"
  },
  {
    "text": "Some people think\nthese models are representing general\nintelligence or conscience or things like that. And there's a potential with\nthese abstraction models",
    "start": "2630150",
    "end": "2638130"
  },
  {
    "text": "to make this problem worse\nby muddying the question of, well, how do we\nknow what we know?",
    "start": "2638130",
    "end": "2645210"
  },
  {
    "text": "Like, what counts as evidence? Is it evidence because the model\nhas learned that representation?",
    "start": "2645210",
    "end": "2652080"
  },
  {
    "text": "And how do we validate\nwhat that evidence is? In the case of representations\nthat are designed or interpreted",
    "start": "2652080",
    "end": "2659250"
  },
  {
    "text": "or theorized by\npeople, we know how to consider that to be evidence. But I don't know what it means\nfor a learned representation",
    "start": "2659250",
    "end": "2666720"
  },
  {
    "text": "to count as evidence. And as all sorts of problems\nin machine learning, this is not necessarily\na problem that",
    "start": "2666720",
    "end": "2672360"
  },
  {
    "text": "is unique to machine learning. So here are three\nvisualizations that",
    "start": "2672360",
    "end": "2677549"
  },
  {
    "text": "were used to discuss the\nCOVID-19 pandemic right at the peak of the first\nwave in the summer of 2020.",
    "start": "2677550",
    "end": "2688099"
  },
  {
    "text": "And I'm curious if anything\npops out at you, like any reason",
    "start": "2688100",
    "end": "2693220"
  },
  {
    "text": "to be curious or suspect\nof these visualizations. ",
    "start": "2693220",
    "end": "2702000"
  },
  {
    "text": "Right? Like, no, right? Probably not. These seem pretty\nlegitimate, right? Like Our World in Data,\nvery legitimate data source.",
    "start": "2702000",
    "end": "2710790"
  },
  {
    "text": "And if you look at some of\nthese two other visualizations, you might go, you\nknow what, actually, the one on the right, that looks\nlike something in maybe a policy",
    "start": "2710790",
    "end": "2717862"
  },
  {
    "text": "briefing or something, right? It looks very\nsophisticated, lots of good annotation, a\nstyle and aesthetic that",
    "start": "2717862",
    "end": "2726180"
  },
  {
    "text": "looks very sophisticated. But you may be catching\nwhat I'm alluding to, which is the fact that all\nthree visualizations were used",
    "start": "2726180",
    "end": "2735270"
  },
  {
    "text": "by people on social\nmedia to advance the argument that our response\nto COVID was overblown.",
    "start": "2735270",
    "end": "2743400"
  },
  {
    "text": "Not that COVID was a hoax,\nbut that our reaction to it was way too extreme, that COVID\nwasn't as serious an issue as it",
    "start": "2743400",
    "end": "2752970"
  },
  {
    "text": "might initially seem. And I want to be really careful\nabout what I'm doing here",
    "start": "2752970",
    "end": "2758460"
  },
  {
    "text": "with these charts\nbecause certainly, some of the people that\nwere distributing this were bad actors who were\nideologically motivated.",
    "start": "2758460",
    "end": "2766120"
  },
  {
    "text": "But through a very long,\nlaborious, ethnographic process",
    "start": "2766120",
    "end": "2771700"
  },
  {
    "text": "that we conducted,\nspending six months on five different Facebook\ngroups, we found",
    "start": "2771700",
    "end": "2776950"
  },
  {
    "text": "that a lot of people who\nwere producing visualizations like that were actually\ndisplaying many hallmarks",
    "start": "2776950",
    "end": "2782140"
  },
  {
    "text": "of citizen data science. So they were really,\nmany of them, filling gaps in\ninformation collection",
    "start": "2782140",
    "end": "2788140"
  },
  {
    "text": "because they were situated\nin rural parts of the country where there wasn't a lot\nof good data collection.",
    "start": "2788140",
    "end": "2793240"
  },
  {
    "text": "So many members of\nthese groups were hosting webcasts live seminars\nof how to download data",
    "start": "2793240",
    "end": "2799300"
  },
  {
    "text": "from the government website,\nhow to clean it in Excel, how to visualize it,\nand things like that. And most surprisingly\nto us, many of them",
    "start": "2799300",
    "end": "2807130"
  },
  {
    "text": "were engaged in a discussion\nthat looked like peer review. They were critically\nassessing data sources,",
    "start": "2807130",
    "end": "2813400"
  },
  {
    "text": "discussing metrics, making\narguments for which metrics were better or not.",
    "start": "2813400",
    "end": "2818530"
  },
  {
    "text": "But all of this was\nsort of inflected through a frustration with\nmainstream institutions",
    "start": "2818530",
    "end": "2824920"
  },
  {
    "text": "and maybe even distrust of\nthose institutions as well. But ultimately,\nwhat these groups",
    "start": "2824920",
    "end": "2830350"
  },
  {
    "text": "cared about was bolstering\na sense of social unity and civic engagement.",
    "start": "2830350",
    "end": "2835840"
  },
  {
    "text": "So this quote I find\nparticularly reflective of that sense of, it's\nincumbent on all of us",
    "start": "2835840",
    "end": "2841990"
  },
  {
    "text": "to hold our elected officials\nto account so that they make better decisions through data. I'm speaking to you as a\nneighbor, as a mama bear.",
    "start": "2841990",
    "end": "2850630"
  },
  {
    "text": "So this is not some sort\nof ideologically motivated individual who is trying\nto be a bad actor.",
    "start": "2850630",
    "end": "2856810"
  },
  {
    "text": "This is just an engaged\nmember of the citizenry. And similarly, oftentimes, they\nwere actually more sophisticated",
    "start": "2856810",
    "end": "2864400"
  },
  {
    "text": "than scientists can be. So many of these members\nwere very reflexive about their own data analysis,\ndata gathering process.",
    "start": "2864400",
    "end": "2872260"
  },
  {
    "text": "So someone says, I've never\nclaimed to have no bias. I'm human. Of course I'm biased.",
    "start": "2872260",
    "end": "2877540"
  },
  {
    "text": "Here are my biases. Whereas in science,\noften we like to portray ourselves as\nbeing very objective arbiters",
    "start": "2877540",
    "end": "2883980"
  },
  {
    "text": "of truth. And so in many ways, what\nwas happening in these groups was perhaps more\nsophisticated than what",
    "start": "2883980",
    "end": "2891690"
  },
  {
    "text": "was happening in science and\npublic health at the time. But the question is,\nso what does this have to do with bridging\nsemantic distances",
    "start": "2891690",
    "end": "2898890"
  },
  {
    "text": "and abstraction models? Well, I think what was\nhappening in those groups was",
    "start": "2898890",
    "end": "2905916"
  },
  {
    "text": "they disagreed with\nthe definitions of some of these metrics. They were living in\nrural communities,",
    "start": "2905916",
    "end": "2912180"
  },
  {
    "text": "and so the metrics that\npublic health officials were using to define the state\nand scale of the pandemic",
    "start": "2912180",
    "end": "2919860"
  },
  {
    "text": "was not reflected in\ntheir lived experience. They were turning\naround and, well, it didn't seem like\nCOVID was an issue.",
    "start": "2919860",
    "end": "2926520"
  },
  {
    "text": "And so our colleagues in the\nhumanities and social sciences often advocate for\nadopting what they call an interpretivist lens,\nthe idea that knowledge",
    "start": "2926520",
    "end": "2936330"
  },
  {
    "text": "is subjective, it's\nsocially constructed, and that it's composed of many\ndifferent, diverse perspectives",
    "start": "2936330",
    "end": "2942870"
  },
  {
    "text": "that we have to figure out\nways to synthesize together. And while that idea\nhas been adopted",
    "start": "2942870",
    "end": "2948250"
  },
  {
    "text": "in pockets of visualization\nand HCI in CS, so far, I think it's largely\nbeen on the qualitative side",
    "start": "2948250",
    "end": "2954250"
  },
  {
    "text": "because if we think about\nhow to do computation, we're forced into making\ndecisions about the world",
    "start": "2954250",
    "end": "2961960"
  },
  {
    "text": "and how to represent that\nworld and computational data structures. And what I think abstraction\nmodels allow us to do",
    "start": "2961960",
    "end": "2967809"
  },
  {
    "text": "is start to push that\nboundary a little bit. Rather than being focused on\ndeveloping a model that produces",
    "start": "2967810",
    "end": "2974920"
  },
  {
    "text": "a single best outcome,\nwe might instead be looking to a world in which\nwe are training ecosystems",
    "start": "2974920",
    "end": "2980859"
  },
  {
    "text": "of abstraction models, where\nwe're forcing them to learn really different\nrepresentations of the world",
    "start": "2980860",
    "end": "2986590"
  },
  {
    "text": "or of a problem domain and\nthen leaving it up to people to figure out how to\nsynthesize between those",
    "start": "2986590",
    "end": "2992170"
  },
  {
    "text": "learned representations for some\nparticular policy goal or thing",
    "start": "2992170",
    "end": "3000240"
  },
  {
    "text": "that they want to optimize for. So with that, I'm happy to\ntake questions about any",
    "start": "3000240",
    "end": "3005470"
  },
  {
    "text": "of what I talked about. Thank you very much. [APPLAUSE]",
    "start": "3005470",
    "end": "3011180"
  },
  {
    "text": " We've got some time for\nquestions, comments.",
    "start": "3011180",
    "end": "3018940"
  },
  {
    "text": "I wanted to start\noff about comparing saliency maps to ground truth.",
    "start": "3018940",
    "end": "3025780"
  },
  {
    "text": "So humans are really\nnot accurate sometimes when you ask them what\nis the important thing",
    "start": "3025780",
    "end": "3031260"
  },
  {
    "text": "in this image that made\nme make this decision. So do you think the\nresults would be different if you used eye fixations\nin that comparison?",
    "start": "3031260",
    "end": "3038720"
  },
  {
    "text": "That's an interesting question. We haven't considered\neye fixations",
    "start": "3038720",
    "end": "3045650"
  },
  {
    "text": "for the saliency map work. But certainly, I think your\nintuition is right in the sense",
    "start": "3045650",
    "end": "3051740"
  },
  {
    "text": "that the current way that\nwe've modeled shared interest is pretty brittle.",
    "start": "3051740",
    "end": "3057290"
  },
  {
    "text": "It's operating at the\nlevel of abstraction of pixels in an image. And how meaningful\nare pixels, really?",
    "start": "3057290",
    "end": "3063680"
  },
  {
    "text": "And so what Angie is\nworking on right now is a way to raise the\nlevel of abstraction that shared interest\nis working on.",
    "start": "3063680",
    "end": "3070130"
  },
  {
    "text": "So in many of these\ndomains like ImageNet, the task that we're asking\nmodels to do, the labeling task,",
    "start": "3070130",
    "end": "3078050"
  },
  {
    "text": "actually inherits from\na much richer knowledge graph or taxonomy or\nhierarchy or things like that.",
    "start": "3078050",
    "end": "3084050"
  },
  {
    "text": "But right now at least,\nthere's a little bit of work in\nhierarchical learning, but most of the\npredictive models",
    "start": "3084050",
    "end": "3090000"
  },
  {
    "text": "are just learning at the\nfinest level of detail. So we're throwing away\nall that rich information",
    "start": "3090000",
    "end": "3096720"
  },
  {
    "text": "that might be really\nrelevant to how a person is making a decision. So maybe what I\ncare about is not",
    "start": "3096720",
    "end": "3102810"
  },
  {
    "text": "whether it's a chihuahua or a\ngolden retriever or a Labrador retriever. I might care, is it a dog?",
    "start": "3102810",
    "end": "3107849"
  },
  {
    "text": "Or really, sometimes,\nis it just an object? And so what does it look like\nto do shared interest in more",
    "start": "3107850",
    "end": "3114450"
  },
  {
    "text": "meaningful abstraction\nspace rather than pixels is something we're working on. Yeah, great question. Thanks.",
    "start": "3114450",
    "end": "3119760"
  },
  {
    "text": "Yeah, Will? Thank you for the\ngreat talk, Arvind. So going back to Jupyter\nNotebooks and ChatGPT,",
    "start": "3119760",
    "end": "3127980"
  },
  {
    "text": "you talked about how\nChatGPT can shell out to some of these nice plugins,\nlike for Excel or whatever,",
    "start": "3127980",
    "end": "3134819"
  },
  {
    "text": "to try and help people do\nnatural language data science, and that there's this\narticulatory distance",
    "start": "3134820",
    "end": "3141090"
  },
  {
    "text": "due to the difficulty\nof learning an API. But conversely,\nyou could say tools like Copilot are sort of\nthe parallel to overcoming",
    "start": "3141090",
    "end": "3148170"
  },
  {
    "text": "that articulatory distance by\nalmost, in some sense, when it's the same interface,\nexpressing a natural language",
    "start": "3148170",
    "end": "3153240"
  },
  {
    "text": "but just in a code comment\nand then getting back code. But I guess the\nonly difference is",
    "start": "3153240",
    "end": "3158353"
  },
  {
    "text": "it's code you can see\nas opposed to code that's running in some\nbackend that you don't see. And I'm curious if you think\nthere's a synthesis of these two",
    "start": "3158353",
    "end": "3164760"
  },
  {
    "text": "poles, an interface that can\ntake the best of both worlds and offers conversation\nbut still provides access",
    "start": "3164760",
    "end": "3171067"
  },
  {
    "text": "to the code or encourages people\nto understand the underlying representations? Just if you have any\nthoughts about that. Yeah, absolutely. I thought really hard about\nwhich of those examples",
    "start": "3171068",
    "end": "3181050"
  },
  {
    "text": "I wanted to use as\nthe foil to be B2. So I did very seriously\nconsider Copilot.",
    "start": "3181050",
    "end": "3188549"
  },
  {
    "text": "And I sort of agree\nwith your analysis that it's, I think, a\nmuch better example of how",
    "start": "3188550",
    "end": "3194970"
  },
  {
    "text": "to integrate the\ncapacity of these LLMs. And I think there's opportunity\nto push that even further,",
    "start": "3194970",
    "end": "3202530"
  },
  {
    "text": "where what I would often want\nis really targeted mechanisms to introduce ambiguity.",
    "start": "3202530",
    "end": "3209520"
  },
  {
    "text": "Right now, the little\nthat I've used Copilot, it's almost at the\nlevel of, well, it's going to produce the whole\nfunction, the whole whatever.",
    "start": "3209520",
    "end": "3219160"
  },
  {
    "text": "And often, what I\nwant is it to be the parallel prototyper for me.",
    "start": "3219160",
    "end": "3224190"
  },
  {
    "text": "I want to introduce, say, a\nhole in my program and then go, I don't know that I want\nthat hole to be filled",
    "start": "3224190",
    "end": "3229710"
  },
  {
    "text": "in with just one\nspecific outcome, but I want it to produce the\nwhole space and for me to go,",
    "start": "3229710",
    "end": "3235697"
  },
  {
    "text": "well, I want a little bit\nof this and a little bit of that and so on and so forth. So yeah, I totally\nagree with there",
    "start": "3235697",
    "end": "3243360"
  },
  {
    "text": "being some really interesting\nmedium of these things. Cool. Yeah, I like that idea.",
    "start": "3243360",
    "end": "3249930"
  },
  {
    "text": "Yeah. Hey, really exciting talk. Towards your vision for\nthese abstraction models,",
    "start": "3249930",
    "end": "3257100"
  },
  {
    "text": "I'm wondering, obviously, from\na human-to-computer interaction perspective, we know\nrepresentation matters so much,",
    "start": "3257100",
    "end": "3265590"
  },
  {
    "text": "like isomorphs of\nrepresentation very much change how people can approach\na problem or understand it.",
    "start": "3265590",
    "end": "3271920"
  },
  {
    "text": "But I guess the ways\nin which they vary and the benefits of these\ndifferent representations",
    "start": "3271920",
    "end": "3278490"
  },
  {
    "text": "are tied very much to human\ncognition and perception. And I'm wondering in some of\nthe examples you're showing",
    "start": "3278490",
    "end": "3285480"
  },
  {
    "text": "and a lot of work\nin machine learning, we're training things\nbased upon the output.",
    "start": "3285480",
    "end": "3290640"
  },
  {
    "text": "And I'm wondering, are there\nways that we can get at more-- I love this question. --of how people are thinking\nversus just how they output?",
    "start": "3290640",
    "end": "3298380"
  },
  {
    "text": "And how do we get there? Yeah, I love this question. And the reason I love\nit is also the reason",
    "start": "3298380",
    "end": "3304860"
  },
  {
    "text": "I love that Hutchins\net al description of direct manipulation. I find the terms that they\nuse there, particularly",
    "start": "3304860",
    "end": "3312160"
  },
  {
    "text": "these two distances, really\nevocative terms because to me, a distance is something that\nI would want to measure.",
    "start": "3312160",
    "end": "3319900"
  },
  {
    "text": "But so far, at least\nas far as I know, those terms have largely\nbeen descriptive.",
    "start": "3319900",
    "end": "3325450"
  },
  {
    "text": "As you saw in my talk, I use\nthem to be very analytic, but I'm not able to be\ngenerative with them",
    "start": "3325450",
    "end": "3331060"
  },
  {
    "text": "in a very systematic way. So certainly, a lot of the\nwork that my group is trying",
    "start": "3331060",
    "end": "3338500"
  },
  {
    "text": "to do right now is, in\nvisualization, there's a lot of work that\nwe've inherited",
    "start": "3338500",
    "end": "3345039"
  },
  {
    "text": "in methods from vision science. So we run these studies\nof human perception.",
    "start": "3345040",
    "end": "3351250"
  },
  {
    "text": "And increasingly,\nthe field is starting to get to, well, how do we\nstart to measure cognition?",
    "start": "3351250",
    "end": "3356980"
  },
  {
    "text": "Can we model a\ndecision-making task and start to operationalize that\nthrough experimental design?",
    "start": "3356980",
    "end": "3364390"
  },
  {
    "text": "And so we're starting to push\nin some of those directions as well, but scoped\nto interaction",
    "start": "3364390",
    "end": "3369880"
  },
  {
    "text": "in a Jupyter Notebook. But then starting to see\nthe impact that interaction has on the downstream\nanalyses people",
    "start": "3369880",
    "end": "3376900"
  },
  {
    "text": "would do, and then see if that\nactually maps to their goals or things like that.",
    "start": "3376900",
    "end": "3382480"
  },
  {
    "text": "Absolutely, yeah. ",
    "start": "3382480",
    "end": "3390120"
  },
  {
    "text": "So I'm curious about the-- just continuing on this line of\nperception up through cognition.",
    "start": "3390120",
    "end": "3397740"
  },
  {
    "text": "Going back to the [INAUDIBLE]\nCleveland, and McGill kinds of stuff, the\nautomatic processing",
    "start": "3397740",
    "end": "3406109"
  },
  {
    "text": "was very key to the\ndesign of visualizations, especially early on. The notion was that my encodings\nwere supposed to map onto almost",
    "start": "3406110",
    "end": "3415650"
  },
  {
    "text": "like system one interpretation. Like when I see the scatter\nplot encoding distance",
    "start": "3415650",
    "end": "3421740"
  },
  {
    "text": "in the following way, I'm going\nto draw the correct conclusion. And it's interesting to me that\nthrough the transformations",
    "start": "3421740",
    "end": "3429490"
  },
  {
    "text": "you've started to pursue, we're\nnot trying to encode those into a similar\nmapping for audio,",
    "start": "3429490",
    "end": "3438550"
  },
  {
    "text": "but instead directly doing\nthe cognition on behalf of the individual. And those seem like orthogonal\ndirections one could go.",
    "start": "3438550",
    "end": "3447010"
  },
  {
    "text": "I'm curious how we find the\nright point in the design space there. Yeah, I think this is\na fantastic question.",
    "start": "3447010",
    "end": "3453640"
  },
  {
    "text": "So the way my group is starting\nto think about this of, how do we find the\nright balance of who",
    "start": "3453640",
    "end": "3460805"
  },
  {
    "text": "is doing the perception, who\nis doing the interpretation, is starting to consider some\nof these modalities in concert",
    "start": "3460805",
    "end": "3466630"
  },
  {
    "text": "to better understand what\nthe relative affordances of these modalities are. So in particular, Jonathan,\nwho you saw on the demos,",
    "start": "3466630",
    "end": "3473680"
  },
  {
    "text": "is leading some really, really\ncool work right now around what if I'm sort of specifying\nthe visual, the audio,",
    "start": "3473680",
    "end": "3483130"
  },
  {
    "text": "the sonified audio and the\ntextual audio, side by side, and then I'm playing them\nsimultaneously through.",
    "start": "3483130",
    "end": "3490370"
  },
  {
    "text": "Do I want there to be\nperceptual redundancy, where the sonification\nis emphasizing",
    "start": "3490370",
    "end": "3497210"
  },
  {
    "text": "what is described in the text? Or do I want these modalities\nto be complementary?",
    "start": "3497210",
    "end": "3502970"
  },
  {
    "text": "And sort of TBD,\nbut I think there's some really exciting\nquestions for us",
    "start": "3502970",
    "end": "3509780"
  },
  {
    "text": "to dig into in that space. Are there similar preattentive\nprinciples for audio? There must be.",
    "start": "3509780",
    "end": "3517430"
  },
  {
    "text": "So we're just starting to look\nin the sonification literature. As far as we can tell, sound\nis a very, very different",
    "start": "3517430",
    "end": "3525740"
  },
  {
    "text": "perceptual sense than vision. And so even the\nbasic visual encoding",
    "start": "3525740",
    "end": "3532820"
  },
  {
    "text": "paradigm where I\ntake a data field and I map it to\nposition, color, size, that breaks down very\nrapidly for audio.",
    "start": "3532820",
    "end": "3540349"
  },
  {
    "text": "So oftentimes, really\nall that people are able to detect differences\nin are pitch and loudness.",
    "start": "3540350",
    "end": "3548330"
  },
  {
    "text": "And even then, our fidelity\nat that is very, very low. And so there might be some\npre-attentive characteristics.",
    "start": "3548330",
    "end": "3556160"
  },
  {
    "text": "We're certainly looking\nat some early work in HCI. I think Stephen\nBrewster had done",
    "start": "3556160",
    "end": "3562490"
  },
  {
    "text": "around earcons, discrete\nrepresentations of icons",
    "start": "3562490",
    "end": "3568045"
  },
  {
    "text": "but through audio\nand things like that. So there may be some of that\nthere, but at least so far,",
    "start": "3568045",
    "end": "3573589"
  },
  {
    "text": "we're so early in our own\nwork that we don't know. Interesting. OK, thank you. Yeah.",
    "start": "3573590",
    "end": "3579603"
  },
  {
    "text": "I think we're about at time. So if you have\nadditional questions, please mob him after the talk. Thank you, Arvind,\nfor joining us.",
    "start": "3579603",
    "end": "3585260"
  },
  {
    "text": "Thank you very much. [APPLAUSE] ",
    "start": "3585260",
    "end": "3593000"
  }
]
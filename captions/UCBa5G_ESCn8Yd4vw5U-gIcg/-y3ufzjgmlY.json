[
  {
    "start": "0",
    "end": "5920"
  },
  {
    "text": "On Monday, we talked a lot\nabout variational inference and how do you optimize for\ncomplex distributions of data?",
    "start": "5920",
    "end": "16070"
  },
  {
    "text": "And today, we're going to\nactually put some of that into practice in the context\nof meta-learning algorithms.",
    "start": "16070",
    "end": "21952"
  },
  {
    "text": "And so, specifically,\nwe'll, again, try to motivate\nwhy we might want Bayesian meta-learning\nalgorithms in the first place.",
    "start": "21952",
    "end": "27670"
  },
  {
    "text": "Then we'll talk about\ndifferent classes of Bayesian\nmeta-learning algorithms, including black\nbox meta learning",
    "start": "27670",
    "end": "32860"
  },
  {
    "text": "algorithms and\noptimization-based algorithms. And then, lastly, we'll talk\nabout how to actually evaluate",
    "start": "32860",
    "end": "39615"
  },
  {
    "text": "Bayesian meta-learning\nalgorithms and how that differs\nfrom the typical kind of few-shot learning evaluation\nthat we've seen previously",
    "start": "39615",
    "end": "46600"
  },
  {
    "text": "in class. And so, the goals for--\nby the end of the lecture are to try to be\nable to understand",
    "start": "46600",
    "end": "53290"
  },
  {
    "text": "the interpretation\nof meta-learning as Bayesian inference and\nalso understand techniques for representing\nuncertainty over parameters,",
    "start": "53290",
    "end": "61660"
  },
  {
    "text": "versus over predictions.  So I guess, also,\none quick disclaimer,",
    "start": "61660",
    "end": "68600"
  },
  {
    "text": "like a lot of the\nclass content, this is an active area of research. And so, there are also--",
    "start": "68600",
    "end": "73850"
  },
  {
    "text": "yeah, will be in some cases\npotentially more questions than answers, in terms\nof the algorithms that we're looking at.",
    "start": "73850",
    "end": "79590"
  },
  {
    "text": "But that's also true\nfor a lot of the content we've seen in the\ncourse as well.",
    "start": "79590",
    "end": "85030"
  },
  {
    "text": "Cool, so let's start\nby talking a little bit about a recap of\nsome of the things",
    "start": "85030",
    "end": "90150"
  },
  {
    "text": "that we've seen so far, both\nin terms of meta-learning algorithms and, also,\nin terms of casting that in the context of\nBayesian graphical models.",
    "start": "90150",
    "end": "98940"
  },
  {
    "text": "And so, when we covered\nthe last lecture",
    "start": "98940",
    "end": "103980"
  },
  {
    "text": "and on meta-learning algorithms,\nwe talked about the properties that we might want from a\nmeta-learning algorithm.",
    "start": "103980",
    "end": "110759"
  },
  {
    "text": "And, specifically, we were\ntalking about the properties of the inner loop\nof that algorithm, like the learning procedure\nthat it gives you.",
    "start": "110760",
    "end": "118230"
  },
  {
    "text": "And there were two\ndifferent properties that we really focused on\nwhen talking about this.",
    "start": "118230",
    "end": "123730"
  },
  {
    "text": "The first was thinking\nabout the expressive power of the inner\nloop of that algorithm.",
    "start": "123730",
    "end": "130229"
  },
  {
    "text": "Specifically, can the inner\nloop of that algorithm represent a wide range\nof learning procedures?",
    "start": "130229",
    "end": "136110"
  },
  {
    "text": "And the second was\nlooking at the consistency of that inner loop,\nwhich was consistency",
    "start": "136110",
    "end": "141270"
  },
  {
    "text": "in the notion of statistical\nconsistency, which is that, if you give the\ninner loop enough data, can you expect it to solve\nthe task and reach",
    "start": "141270",
    "end": "149640"
  },
  {
    "text": "a consistent estimator of-- or give you a consistent\nestimator of the task specific parameters?",
    "start": "149640",
    "end": "156900"
  },
  {
    "text": "But these properties\nare important. But one property that we\nhaven't talked about much about",
    "start": "156900",
    "end": "161939"
  },
  {
    "text": "is the ability to reason\nabout uncertainty. And this is really the focus\nof Bayesian meta-learning",
    "start": "161940",
    "end": "167160"
  },
  {
    "text": "algorithms. And by that, I mean\nthe ability to try to reason about ambiguity\nthat might come up",
    "start": "167160",
    "end": "173040"
  },
  {
    "text": "in the learning process. And this is important in\nactive learning settings, in settings where you want\ncalibrated uncertainty",
    "start": "173040",
    "end": "179910"
  },
  {
    "text": "estimates, as well\nas in reinforcement learning settings. And it also gives\nus, one might argue,",
    "start": "179910",
    "end": "188040"
  },
  {
    "text": "kind of approaches that\nare quite principled from the Bayesian\nstandpoint, insofar as they're going to be\nmaximizing the likelihood",
    "start": "188040",
    "end": "194760"
  },
  {
    "text": "under some graphical model. ",
    "start": "194760",
    "end": "200240"
  },
  {
    "text": "Cool, so now, this will\nalso be a little bit",
    "start": "200240",
    "end": "205440"
  },
  {
    "text": "of recap, which is that-- actually, even before\nwe started talking about meta-learning\nalgorithms, we",
    "start": "205440",
    "end": "211937"
  },
  {
    "text": "talked about how training\nand testing tasks should share some degree of structure. And we talked about\nhow this can be thought",
    "start": "211937",
    "end": "219480"
  },
  {
    "text": "of as a statistical dependence\non some latent information theta.",
    "start": "219480",
    "end": "225150"
  },
  {
    "text": "And we brought up this\ngraphical model right here, where we have our task\nspecific parameters",
    "start": "225150",
    "end": "231160"
  },
  {
    "text": "phi, i and some shared\nlatent information theta. And we also have the\ndata that we can observe,",
    "start": "231160",
    "end": "237420"
  },
  {
    "text": "which includes a\nsupport set denoted as x train and x--\nand y train here and a query set denoted\nas x test and y test here.",
    "start": "237420",
    "end": "245385"
  },
  {
    "text": " And we also talked about, if we\nkind of condition on the shared",
    "start": "245385",
    "end": "250780"
  },
  {
    "text": "information, that means that\nthe task parameters become independent and are not\notherwise independent from one",
    "start": "250780",
    "end": "259720"
  },
  {
    "text": "another. And as a result, if\nyou conditioned your--",
    "start": "259720",
    "end": "264876"
  },
  {
    "text": "on that shared information\non theta, that gives you information about phi, i. And so, the\ndistribution over phi, i",
    "start": "264876",
    "end": "273419"
  },
  {
    "text": "is going to have\na lower entropy. It's going to have less\nrandomness because we have some knowledge about\nthe shared structure",
    "start": "273420",
    "end": "280920"
  },
  {
    "text": "across the different tasks. ",
    "start": "280920",
    "end": "287240"
  },
  {
    "text": "And, then, I guess,\nit's been a while since we talked about\nthis a little bit. So I guess, we can maybe walk\nthrough these thought exercises",
    "start": "287240",
    "end": "293180"
  },
  {
    "text": "again. So the first thought\nexercise was that, if you can identify the\nmeta parameters theta,",
    "start": "293180",
    "end": "299060"
  },
  {
    "text": "such as with a\nmeta-learning algorithm, when should you expect-- when should learning\nphi, i be faster than",
    "start": "299060",
    "end": "306080"
  },
  {
    "text": "if you were to\nlearn from scratch? Does anyone have any thoughts? ",
    "start": "306080",
    "end": "318180"
  },
  {
    "text": "When your task is\n[INAUDIBLE] distribution is the one you used\nto learn theta? Yeah, so one example is, if\nyour task, the task that you're",
    "start": "318180",
    "end": "326220"
  },
  {
    "text": "trying to learn is from the\nsame distribution as the task that you saw during\nmeta training, then,",
    "start": "326220",
    "end": "331590"
  },
  {
    "text": "this shared structure\nshould be useful for helping you infer what phi, i\nshould correspond to,",
    "start": "331590",
    "end": "338949"
  },
  {
    "text": "any other thoughts? ",
    "start": "338950",
    "end": "344235"
  },
  {
    "text": "So one of the\nthings that I think we covered last time is\nthat, if the tasks do share some structure, then, this\ndata is going to help you--",
    "start": "344235",
    "end": "351820"
  },
  {
    "text": "is basically going to reduce\nyour uncertainty over phi. Whereas, if the tasks are\ncompletely independent from one",
    "start": "351820",
    "end": "358480"
  },
  {
    "text": "another and don't have\nany shared structure, then, you won't actually\nbe reducing entropy when you condition on\nthe theta variable.",
    "start": "358480",
    "end": "365515"
  },
  {
    "text": " And then, lastly, we also\ntalked about this other case",
    "start": "365515",
    "end": "374720"
  },
  {
    "text": "where, if you\ncondition on theta, what happens if\nthe entropy is 0?",
    "start": "374720",
    "end": "380780"
  },
  {
    "text": "And this is the case\nwhere theta tells you everything there is to know\nabout the task-specific",
    "start": "380780",
    "end": "386870"
  },
  {
    "text": "parameters. And in that case,\nyou don't actually need any support set\nor any data to infer what the task-specific\nparameters are.",
    "start": "386870",
    "end": "394110"
  },
  {
    "text": "And in this case, you could\nactually think of this a lot as memorization. You don't actually\nneed the support",
    "start": "394110",
    "end": "399470"
  },
  {
    "text": "set in order to infer the\ntask-specific parameters. And so, in this case, your\nmeta-learning algorithm",
    "start": "399470",
    "end": "404750"
  },
  {
    "text": "may just memorize\nall of the tasks and not actually\nuse the support set.",
    "start": "404750",
    "end": "409760"
  },
  {
    "text": " Cool, and then jumping\ninto Bayesian meta-learning",
    "start": "409760",
    "end": "420090"
  },
  {
    "text": "algorithms, all the algorithms\nthat we've seen so far use some-- give us our\ntask-specific parameters",
    "start": "420090",
    "end": "426900"
  },
  {
    "text": "in a fully deterministic way. So they'll give us a-- well, they'll give us a\ndegenerate distribution",
    "start": "426900",
    "end": "432210"
  },
  {
    "text": "over phi, i because they'll just\ngive us one parameter vector. They won't give\nus a distribution",
    "start": "432210",
    "end": "438120"
  },
  {
    "text": "that has any amount\nof support to it. And there are cases\nwhere we do actually want to generate\nmultiple hypotheses.",
    "start": "438120",
    "end": "444430"
  },
  {
    "text": "And so, this is\nan example that we saw on Monday, where few-shot\nlearning problems might be ambiguous. So you might have a support set\nwhere it's inherently unclear",
    "start": "444430",
    "end": "453420"
  },
  {
    "text": "which attributes you should\nbe paying attention to. And if we can learn to generate\nhypotheses about the underlying",
    "start": "453420",
    "end": "459990"
  },
  {
    "text": "function, then, this can tell\nus if we need more labels or if we should\nabstain from making a prediction on a new example\nbecause it's uncertain.",
    "start": "459990",
    "end": "469382"
  },
  {
    "text": "And so, this is important in\nsafety critical settings where you want to decide if you\nshould make a decision,",
    "start": "469382",
    "end": "474540"
  },
  {
    "text": "active learning settings, and\nalso exploration settings. In this specific\nexample, in this lecture,",
    "start": "474540",
    "end": "481122"
  },
  {
    "text": "we will be talking about\nalgorithms that can actually handle the specific setting,\nand generate hypotheses, and generate, basically,\nmultiple classifiers,",
    "start": "481122",
    "end": "488610"
  },
  {
    "text": "one that pays attention\nto the smiling attribute, one that pays attention to\nthe wearing hat attribute, and one that pays attention to\nthe young versus old attribute.",
    "start": "488610",
    "end": "496865"
  },
  {
    "text": " Cool, so let's get into\nalgorithms for doing this.",
    "start": "496865",
    "end": "505240"
  },
  {
    "text": "Now, the first V0 algorithm that\nwe could think about doing is--",
    "start": "505240",
    "end": "512315"
  },
  {
    "text": "we've seen all of\nthese algorithms that give us kind of a label\ny test given a support set and an input x test.",
    "start": "512315",
    "end": "520510"
  },
  {
    "text": "And so, what we could do is,\nhave f output the parameters",
    "start": "520510",
    "end": "526210"
  },
  {
    "text": "of a distribution over y test. And in the classification\nsettings that we've done, you've already been doing that.",
    "start": "526210",
    "end": "532339"
  },
  {
    "text": "So we're not actually literally\noutputting one single label. We output the probabilities\nfor each class.",
    "start": "532340",
    "end": "539870"
  },
  {
    "text": "And so, what you've\nbeen doing so far, like in the homework, for\nexample, is the output",
    "start": "539870",
    "end": "545529"
  },
  {
    "text": "probability values over\na discrete categorical distribution. But you can also output\noutputs on other distribution",
    "start": "545530",
    "end": "552879"
  },
  {
    "text": "over y tests. So in regression\nproblems, you get output the mean and variance. You could use a mixture\ndensity network,",
    "start": "552880",
    "end": "558970"
  },
  {
    "text": "like what we talked about\non Monday, where you output the means, variances,\nand weights for a mixture of Gaussians over y test.",
    "start": "558970",
    "end": "567190"
  },
  {
    "text": "Or if you have something\nmore multi-dimensional, you could have an auto-- have\nkind of this output over y test",
    "start": "567190",
    "end": "572620"
  },
  {
    "text": "be a sequence of distributions,\nsuch as an autoregressive model. ",
    "start": "572620",
    "end": "579770"
  },
  {
    "text": "And then once you choose your\ndistribution class over y test, then you can just optimize\nwith maximum likelihood.",
    "start": "579770",
    "end": "587242"
  },
  {
    "text": "And that would--\nmaximum likelihood would correspond\nto the outer loss of your meta-learning algorithm.",
    "start": "587242",
    "end": "594350"
  },
  {
    "text": "So this is pretty simple. And, in fact, we've\nalready been doing it. And so, this is nice.",
    "start": "594350",
    "end": "599954"
  },
  {
    "text": "You can combine\nit with a variety of different\nmeta-learning algorithms.",
    "start": "599955",
    "end": "605620"
  },
  {
    "text": "But the downside is that\nyou can't actually-- this will allow you to\nreason about uncertainty over the label.",
    "start": "605620",
    "end": "611649"
  },
  {
    "text": "But it won't allow\nyou to reason over-- about the uncertainty of\nthe underlying function.",
    "start": "611650",
    "end": "618069"
  },
  {
    "text": "And being able to reason about\nuncertainty of the function is important, if you\nwant to understand",
    "start": "618070",
    "end": "624670"
  },
  {
    "text": "how to reduce uncertainty\nacross a set of data points because, it could be that you're\nvery uncertain about one data",
    "start": "624670",
    "end": "631910"
  },
  {
    "text": "point. And you're-- and if you had a\nlabel for that data point that would help reduce your\nuncertainty for a whole host",
    "start": "631910",
    "end": "638680"
  },
  {
    "text": "of other data points as well. And so, if you had some\nnotion about your uncertainty",
    "start": "638680",
    "end": "643883"
  },
  {
    "text": "of the underlying\nfunction, then, you'll understand, basically,\nhow your uncertainty across different data points\nrelates to one another.",
    "start": "643883",
    "end": "651100"
  },
  {
    "text": " And, then, another\ndownside of this",
    "start": "651100",
    "end": "656190"
  },
  {
    "text": "is that you can really only\ncapture a limited class of distributions over y test.",
    "start": "656190",
    "end": "661290"
  },
  {
    "text": "And this is actually\na question that came up after lecture on Monday,\nwhich is you can output--",
    "start": "661290",
    "end": "667980"
  },
  {
    "text": "I've talked about\nhow you can output a mean variance of a\nGaussian over a y test and a categorical distribution. Why can't we just\noutput some kind",
    "start": "667980",
    "end": "675060"
  },
  {
    "text": "of crazy distribution\nover y test that looks something like this?",
    "start": "675060",
    "end": "681710"
  },
  {
    "text": "And the challenge\nthat comes up here is, if you want this to be\nkind of your distribution",
    "start": "681710",
    "end": "687410"
  },
  {
    "text": "over your labels,\ngiven some input, maybe, also given your\nsupport set, then,",
    "start": "687410",
    "end": "695270"
  },
  {
    "text": "you need to be able\nto parameterize this distribution in some way. And parameterizing\ndistributions like this ends up",
    "start": "695270",
    "end": "703130"
  },
  {
    "text": "being very difficult. We know\nhow to parameterize Gaussians as a mean and variance. And we have a nice equation for\nthat given those two variables.",
    "start": "703130",
    "end": "711769"
  },
  {
    "text": "But once you have more\ncomplex distributions, it's very difficult\nto parameterize that in a way that is\ndifferentiable and is",
    "start": "711770",
    "end": "721670"
  },
  {
    "text": "a well-formed function. ",
    "start": "721670",
    "end": "727579"
  },
  {
    "text": "Cool, yeah, and then the last\nthing that I'll also mention is that, generally, if\nyou train a neural network",
    "start": "727580",
    "end": "734449"
  },
  {
    "text": "with maximum likelihood,\nneural networks tend to give you very poorly\ncalibrated uncertainty",
    "start": "734450",
    "end": "741170"
  },
  {
    "text": "estimates. And by that, I mean that, if\nyou have a binary classification problem, and it\ngives you, say, a 0.9",
    "start": "741170",
    "end": "748730"
  },
  {
    "text": "for one class and a 0.1 for\nanother class, oftentimes, that",
    "start": "748730",
    "end": "753920"
  },
  {
    "text": "doesn't mean that it will be\ncorrect on this data point with a likelihood of 0.9. Oftentimes, neural\nnetworks tend to be--",
    "start": "753920",
    "end": "760685"
  },
  {
    "text": " oftentimes, they\nwill generally tend to be a little bit\nmore overconfident.",
    "start": "760685",
    "end": "767360"
  },
  {
    "text": "But even then, even if you scale\ndown these probability values to try to make them\nless confident,",
    "start": "767360",
    "end": "773450"
  },
  {
    "text": "you're often not able to get\nan estimate that's actually consistent with the\nprobability that it",
    "start": "773450",
    "end": "779660"
  },
  {
    "text": "will be correct on\nthe given data point. ",
    "start": "779660",
    "end": "786290"
  },
  {
    "text": "Cool, any questions\nup until here? [INAUDIBLE]",
    "start": "786290",
    "end": "792459"
  },
  {
    "text": "What is the estimate of\ncalibration rate because it's very subjective that I\nfeel it should be more",
    "start": "792460",
    "end": "797470"
  },
  {
    "text": "uncertain or less uncertain. Yeah, so the question\nis, how do we measure whether or not a neural\nnetwork is well calibrated?",
    "start": "797470",
    "end": "806410"
  },
  {
    "text": "And there's a few\ndifferent ways to do it.",
    "start": "806410",
    "end": "812254"
  },
  {
    "text": "I'll skip ahead,\nactually, a little bit to one visualization here.",
    "start": "812255",
    "end": "820020"
  },
  {
    "text": "And, well, so-- yeah, there's\na couple of different metrics. One metric is called the\nexpected calibration error.",
    "start": "820020",
    "end": "828200"
  },
  {
    "text": "But something that I think\nis even more detailed is what's called a\nreliability diagram. And what this is plotting is--",
    "start": "828200",
    "end": "836540"
  },
  {
    "text": "the x-axis is the confidence\nthat the neural network outputted. And so, over here, it would\nsay that the confidence is 0.9.",
    "start": "836540",
    "end": "843199"
  },
  {
    "text": "And the x-axis is\nshowing the accuracy for all the data points\nthat have a confidence of that particular value.",
    "start": "843200",
    "end": "849840"
  },
  {
    "text": "And, ideally, you would want\nthis to be a diagonal line, where, if you have\nzero confidence,",
    "start": "849840",
    "end": "854960"
  },
  {
    "text": "you have zero accuracy. If you have 50%, confidence you\nhave 50% accuracy and so forth.",
    "start": "854960",
    "end": "860329"
  },
  {
    "text": "And so, basically, this\nis going to be looking at, how often do your\nconfidence measures actually",
    "start": "860330",
    "end": "865550"
  },
  {
    "text": "match the likelihood of\ngetting it correct in practice? And so, the closer to this\nis to a diagonal line,",
    "start": "865550",
    "end": "873870"
  },
  {
    "text": "the better your\ncalibration estimates are. Yeah.",
    "start": "873870",
    "end": "878890"
  },
  {
    "text": "[INAUDIBLE] sense of\nuncertainty, right? Maybe, there's some true\naleatoric uncertainty,",
    "start": "878890",
    "end": "884600"
  },
  {
    "text": "like, it's impossible to know. And that seems like the\nkind of accuracy or--",
    "start": "884600",
    "end": "890020"
  },
  {
    "text": "a setting where you\nmake pretty good estimates of your uncertainty. But then, there's just,\nyour model is wrong, right?",
    "start": "890020",
    "end": "896660"
  },
  {
    "text": "It's not an aleatoric thing. It's just, you weren't right. And that's-- and in the\ncase, predicting a confidence",
    "start": "896660",
    "end": "902750"
  },
  {
    "text": "interval or prediction interval\nseems like asking for a better model.",
    "start": "902750",
    "end": "909180"
  },
  {
    "text": "So does that actually work? Yeah, so there's-- I\nguess, first to make sure everyone's on the same page.",
    "start": "909180",
    "end": "914880"
  },
  {
    "text": "There's actually two\nkinds of uncertainty. One is uncertainty arising\nfrom noise in the data itself,",
    "start": "914880",
    "end": "920920"
  },
  {
    "text": "like, inherent--\nit-- like, there's this some noise underlying the\ndata generating p of y given x.",
    "start": "920920",
    "end": "929720"
  },
  {
    "text": "And that's often referred\nto as aleatoric uncertainty. Or I often like to\nuse, maybe, something",
    "start": "929720",
    "end": "936650"
  },
  {
    "text": "like data uncertainty,\nwhich I think is a little bit more clear. And then, there's a\nsecond form of uncertainty",
    "start": "936650",
    "end": "942950"
  },
  {
    "text": "that's just whether\nor not your model is making the correct prediction.",
    "start": "942950",
    "end": "949280"
  },
  {
    "text": "And that's often referred to as\nepistemic uncertainty or model",
    "start": "949280",
    "end": "954860"
  },
  {
    "text": "uncertainty. And this has to do\nwith, basically, does your model know\nwhat it doesn't know?",
    "start": "954860",
    "end": "960350"
  },
  {
    "text": "And, generally,\ngetting good estimates of the uncertainty\nin the data is easier",
    "start": "960350",
    "end": "967670"
  },
  {
    "text": "because the-- you can\nbasically just look at the data and look at the frequency at\nwhich the label corresponds",
    "start": "967670",
    "end": "975259"
  },
  {
    "text": "to a particular value. Whereas, it's much\nharder to get a sense for what your model doesn't\nknow because that would--",
    "start": "975260",
    "end": "981610"
  },
  {
    "text": "if you could do that,\nthen, you could also often get a better model by-- if you're very confident\nthat you're wrong,",
    "start": "981610",
    "end": "986930"
  },
  {
    "text": "then, you should just\npredict something else, rather than just confidently\nsaying, I know I'm wrong.",
    "start": "986930",
    "end": "992839"
  },
  {
    "text": "And here's the zero\nconfidence estimate. And so, generally, this\nkind of uncertainty is much more difficult to get.",
    "start": "992840",
    "end": "999870"
  },
  {
    "text": "But there-- and especially with\nthings like maximum likelihood, there are some ways for getting\nthis kind of uncertainty.",
    "start": "999870",
    "end": "1008445"
  },
  {
    "text": "And one thing that we'll\ntalk about in a little bit is using ensembles.",
    "start": "1008445",
    "end": "1014230"
  },
  {
    "text": "And in general, this is probably\none of the most effective ways to get notions of\nepistemic uncertainty.",
    "start": "1014230",
    "end": "1021560"
  },
  {
    "text": "But that is-- they're\nstill not very good. And it is a little\nbit of a paradox",
    "start": "1021560",
    "end": "1028150"
  },
  {
    "text": "because, if you could get\nreally good uncertainty estimates, then,\nyou would also just be able to improve your model.",
    "start": "1028150",
    "end": "1033400"
  },
  {
    "start": "1033400",
    "end": "1039640"
  },
  {
    "text": "Cool, so-- oh, I had\na thought exercise.",
    "start": "1039640",
    "end": "1051940"
  },
  {
    "text": "Yeah, so we've talked\nabout how we can just have our meta-learner\noutput a distribution over y",
    "start": "1051940",
    "end": "1058559"
  },
  {
    "text": "and then train things\nwith maximum likelihood. Now, my question\nfor you is, instead",
    "start": "1058560",
    "end": "1065520"
  },
  {
    "text": "of having it output a\ndistribution over y, can we have it output a\ndistribution over phi,",
    "start": "1065520",
    "end": "1072540"
  },
  {
    "text": "given our training data\nand, then, just train that with maximum likelihood?",
    "start": "1072540",
    "end": "1079940"
  },
  {
    "text": "Does anyone have\nany thoughts, yeah? [INAUDIBLE] Yeah, so in order to\ndo maximum likelihood",
    "start": "1079940",
    "end": "1086500"
  },
  {
    "text": "on this distribution, you\nneed the ground truth for phi. And we have access to\nground truth labels.",
    "start": "1086500",
    "end": "1092559"
  },
  {
    "text": "But we don't have access\nto ground truth phi's. And so, for that\nreason, we can't just do maximum likelihood\non this distribution,",
    "start": "1092560",
    "end": "1100120"
  },
  {
    "text": "in order to get an estimate\nof the distribution. And so, that's why\nwe need algorithms",
    "start": "1100120",
    "end": "1105340"
  },
  {
    "text": "that are more interesting than\nmaximum likelihood algorithms. ",
    "start": "1105340",
    "end": "1112429"
  },
  {
    "text": "Cool, and so, to\nbe able to create",
    "start": "1112430",
    "end": "1117500"
  },
  {
    "text": "these kinds of\nalgorithms, we can rely on the probabilistic\nkind of deep learning toolbox.",
    "start": "1117500",
    "end": "1123380"
  },
  {
    "text": "And we went into depth\non one form of tool",
    "start": "1123380",
    "end": "1131412"
  },
  {
    "text": "in the toolbox, which is\nlatent variable models and variational\ninference, on Monday.",
    "start": "1131412",
    "end": "1137059"
  },
  {
    "text": "And this is-- we'll\nprimarily focus on using this tool for\ncreating Bayesian meta-learning",
    "start": "1137060",
    "end": "1142760"
  },
  {
    "text": "algorithms. But there are also other tools\nthat we could consider using. And one tool that we\nwill briefly cover",
    "start": "1142760",
    "end": "1150110"
  },
  {
    "text": "is using what's called\nBayesian ensembles. And the way that\nensembles work is, instead",
    "start": "1150110",
    "end": "1157910"
  },
  {
    "text": "of trying to explicitly\nrepresent some distribution, like output a mean and the\nvariance, what it tries to do",
    "start": "1157910",
    "end": "1165380"
  },
  {
    "text": "is it basically\ntries to represent multiple particles that are\nsamples from that distribution.",
    "start": "1165380",
    "end": "1171140"
  },
  {
    "text": "And the way that you do\nthis is very, very simple. Oftentimes, you just train\nmultiple separate models",
    "start": "1171140",
    "end": "1178730"
  },
  {
    "text": "on your data set. And by training multiple\nmodels on your data set with maximum likelihood, that\nwill give you multiple copies",
    "start": "1178730",
    "end": "1187309"
  },
  {
    "text": "of your given model. And it turns out that this--",
    "start": "1187310",
    "end": "1192372"
  },
  {
    "text": "oftentimes, the\nmodel that you get will be slightly different\nfrom one another. And that will give\nyou, basically,",
    "start": "1192373",
    "end": "1198320"
  },
  {
    "text": "samples from your distribution. There's also ways to make\nthis work even better.",
    "start": "1198320",
    "end": "1204320"
  },
  {
    "text": "And we'll also talk\nabout that a little bit. ",
    "start": "1204320",
    "end": "1209850"
  },
  {
    "text": "Beyond these first\ntwo things, there's also something called\nBayesian neural networks. And the way that these\nwork is, basically,",
    "start": "1209850",
    "end": "1219180"
  },
  {
    "text": "just directly forming\na distribution over neural network parameters\nand, particularly, usually",
    "start": "1219180",
    "end": "1225779"
  },
  {
    "text": "a Gaussian distribution. And so, instead of having\na single neural network with weights theta, you\nwill have a neural network",
    "start": "1225780",
    "end": "1234510"
  },
  {
    "text": "with a mean for your weights\nand a variance for your weights.",
    "start": "1234510",
    "end": "1242860"
  },
  {
    "text": "And that allows you to form\na Gaussian distribution over the weights of\nyour neural network.",
    "start": "1242860",
    "end": "1250240"
  },
  {
    "text": "And, of course, if you\nrepresented a full covariance matrix over the weights of\nyour neural network, then,",
    "start": "1250240",
    "end": "1256840"
  },
  {
    "text": "that would be quadratic in\nthe number of parameters that you have. And so, that would not be a\nparticularly appealing choice.",
    "start": "1256840",
    "end": "1263990"
  },
  {
    "text": "And so, oftentimes, we just pick\na single scalar variance value",
    "start": "1263990",
    "end": "1269650"
  },
  {
    "text": "for each of the weights. And so, you're just\ngoing to-- you'll have one vector that's the\nsame dimension as your weights,",
    "start": "1269650",
    "end": "1276658"
  },
  {
    "text": "which is mu and\nanother vector that's also the same dimension as\nyour weights, which is sigma. And that allows you to get\na fairly simple Gaussian",
    "start": "1276658",
    "end": "1284260"
  },
  {
    "text": "distribution over weight space. And we'll be-- in this lecture,\nwe'll be starting to see things that look kind of like\nBayesian neural networks,",
    "start": "1284260",
    "end": "1291210"
  },
  {
    "text": "where we have-- where-- we are going to be\nforming Gaussian distributions over neural network weights.",
    "start": "1291210",
    "end": "1298660"
  },
  {
    "text": " Cool and, then, I mentioned\nthis a little bit on Monday.",
    "start": "1298660",
    "end": "1304600"
  },
  {
    "text": "But there's also a couple\nother distribution classes, such as normalizing flows,\nenergy-based models and GANs.",
    "start": "1304600",
    "end": "1311788"
  },
  {
    "text": "We're not going to really\ntalk about these today. And, for the most part, people\nhaven't used these algorithms for--",
    "start": "1311788",
    "end": "1317970"
  },
  {
    "text": "in the context of\nBayesian meta-learning. But it means that\nthese other two",
    "start": "1317970",
    "end": "1324240"
  },
  {
    "text": "ways of representing\ndistributions could also be useful\nfor developing new Bayesian\nlearning algorithms.",
    "start": "1324240",
    "end": "1329970"
  },
  {
    "text": " Cool, so, now, before we--",
    "start": "1329970",
    "end": "1338890"
  },
  {
    "text": "I guess one more recap\nslide before we actually start getting into Bayesian\nmeta-learning algorithms is to try to recap what\nwe covered on Monday.",
    "start": "1338890",
    "end": "1347690"
  },
  {
    "text": "And on Monday, we were\ntalking about trying to represent models,\nrepresent distributions",
    "start": "1347690",
    "end": "1353200"
  },
  {
    "text": "using latent variables. And, really, the\nkey idea is we're going to have a simple\ndistribution of our latent variable z.",
    "start": "1353200",
    "end": "1358630"
  },
  {
    "text": "We're going to then transform\nthat into our example, space x.",
    "start": "1358630",
    "end": "1364192"
  },
  {
    "text": "And so, our observed\nvariable is x. Our latent variable is z. And we formulated a lower\nbound on the log likelihood.",
    "start": "1364192",
    "end": "1371230"
  },
  {
    "text": "And there were a couple\nof different ways to represent this lower bound. The first was to find--",
    "start": "1371230",
    "end": "1377799"
  },
  {
    "text": "was, basically,\nexpectation under q of log p so, basically, trying to find\na latent variable value that",
    "start": "1377800",
    "end": "1385809"
  },
  {
    "text": "has maximum probability\nunder p but, then, also have an entropy term so\nthat you're covering",
    "start": "1385810",
    "end": "1391237"
  },
  {
    "text": "the distribution accurately and\nrepresenting that distribution well. And, then, the\nsecond interpretation",
    "start": "1391237",
    "end": "1397060"
  },
  {
    "text": "that we looked at was trying to\nhave one term that's basically",
    "start": "1397060",
    "end": "1402070"
  },
  {
    "text": "trying to be able to\nreconstruct examples from encoded latents,\nalong with a KL",
    "start": "1402070",
    "end": "1408190"
  },
  {
    "text": "divergence between the\ninferred latent and the prior.",
    "start": "1408190",
    "end": "1413830"
  },
  {
    "text": "And these two are equivalent. And optimizing or maximizing\nfor this objective",
    "start": "1413830",
    "end": "1419170"
  },
  {
    "text": "on the right hand side is\nalso going to maximize the log likelihood in turn. ",
    "start": "1419170",
    "end": "1428620"
  },
  {
    "text": "p corresponds to the model. And p of x given\nz is represented with a neural network. p of z is represented with a\nstandard normal distribution.",
    "start": "1428620",
    "end": "1438070"
  },
  {
    "text": "Although, in practice, you can\nalso learn the prior as well. And, then, q is the\ninference network",
    "start": "1438070",
    "end": "1446020"
  },
  {
    "text": "or the variational\ndistribution, which is our approximation of\nthe posterior of z given x.",
    "start": "1446020",
    "end": "1453550"
  },
  {
    "text": "And if we want to sample\nfrom this model at test time, we often throw away\nour inference network and only use the model p.",
    "start": "1453550",
    "end": "1460360"
  },
  {
    "text": "And in that sense, it's often\nprimarily used as a tool for doing inference and\nfor training the model.",
    "start": "1460360",
    "end": "1467730"
  },
  {
    "text": "And we often use theta to\ndenote the model parameters and find and denote the\nvariational parameters.",
    "start": "1467730",
    "end": "1473232"
  },
  {
    "text": "And, then, the last thing\nthat we talked about was that to actually\noptimize for this objective,",
    "start": "1473233",
    "end": "1478700"
  },
  {
    "text": "we need to be able to\noptimize with respect to the kind of sampling\ndistribution right here.",
    "start": "1478700",
    "end": "1485362"
  },
  {
    "text": "And the way that we do that\nis with the reparameterization trick, which basically allows\nus to reparameterized samples",
    "start": "1485363",
    "end": "1493300"
  },
  {
    "text": "from a Gaussian\ndistribution as the sum of the mean, plus the\nvariance, times epsilon,",
    "start": "1493300",
    "end": "1500960"
  },
  {
    "text": "where epsilon is an\nindependent, random variable. And this allows us\nto actually optimize",
    "start": "1500960",
    "end": "1506620"
  },
  {
    "text": "for the parameters of that\ndistribution without-- by decomposing it\ninto these two terms.",
    "start": "1506620",
    "end": "1516230"
  },
  {
    "text": "Cool, and so, one\nof the big question is if we can use ideas from\nhere for meta-learning.",
    "start": "1516230",
    "end": "1524639"
  },
  {
    "text": "And so, as we've sort\nof hinted at, we can.",
    "start": "1524640",
    "end": "1531350"
  },
  {
    "text": "And so, in particular, in\nthe context of meta-learning,",
    "start": "1531350",
    "end": "1538669"
  },
  {
    "text": "we are going to have\nour observed variable.",
    "start": "1538670",
    "end": "1543880"
  },
  {
    "text": " In this case, the\nobserved variable",
    "start": "1543880",
    "end": "1549280"
  },
  {
    "text": "will now correspond to the\ndata for a particular task.",
    "start": "1549280",
    "end": "1555860"
  },
  {
    "text": "And so, just like when you go\nfrom learning to meta-learning, you're treating these\ndata sets as data points.",
    "start": "1555860",
    "end": "1563149"
  },
  {
    "text": "And so, it the analogy\ncontinues there. And, then, the\nlatent variable will",
    "start": "1563150",
    "end": "1569140"
  },
  {
    "text": "correspond to the task-specific\nparameters phi, i.",
    "start": "1569140",
    "end": "1577270"
  },
  {
    "text": "And once we've defined\nthese two things, then, we can basically\njust reuse everything",
    "start": "1577270",
    "end": "1584920"
  },
  {
    "text": "from variational inference\nthat we learned about before, where we can formulate\na lower bound",
    "start": "1584920",
    "end": "1592450"
  },
  {
    "text": "on the likelihood as\nan expectation under q",
    "start": "1592450",
    "end": "1598500"
  },
  {
    "text": "of phi, of log p of\nDi, given phi, i,",
    "start": "1598500",
    "end": "1608720"
  },
  {
    "text": "minus the KL divergence\nbetween q of phi",
    "start": "1608720",
    "end": "1615230"
  },
  {
    "text": "and our prior over phi. ",
    "start": "1615230",
    "end": "1622320"
  },
  {
    "text": "And so, this is just\nbasically rewriting everything on the-- kind of in our\nevidence lower bound",
    "start": "1622320",
    "end": "1631690"
  },
  {
    "text": "but kind of replacing our\nobserved variable with Di and our latent\nvariable with phi, i.",
    "start": "1631690",
    "end": "1638500"
  },
  {
    "text": "Yeah? Why are we not writing q\nas phi given d [INAUDIBLE]??",
    "start": "1638500",
    "end": "1644370"
  },
  {
    "text": "Yeah, so the question was, why\nare we not writing q as phi,",
    "start": "1644370",
    "end": "1649550"
  },
  {
    "text": "given d? So I wanted to write\nit first as this because q can really be\nconditioned on anything.",
    "start": "1649550",
    "end": "1657680"
  },
  {
    "text": "As we talked about\non Monday, it just needs to give you some\nestimate over phi.",
    "start": "1657680",
    "end": "1663380"
  },
  {
    "text": "And so, we have a choice\nin terms of what we might want to condition q on.",
    "start": "1663380",
    "end": "1669460"
  },
  {
    "text": "And so, we can\ncondition it on Di. But we may also want to\ncondition it on something else.",
    "start": "1669460",
    "end": "1678090"
  },
  {
    "text": "And so, does anyone\nhave thoughts on what",
    "start": "1678090",
    "end": "1685000"
  },
  {
    "text": "we might condition q on? ",
    "start": "1685000",
    "end": "1691340"
  },
  {
    "text": "Yeah. [INAUDIBLE] q on the\ntask representation?",
    "start": "1691340",
    "end": "1698400"
  },
  {
    "text": "So the response\nis we, maybe, want to consider conditioning\nq on the task or the task",
    "start": "1698400",
    "end": "1705030"
  },
  {
    "text": "representation? So what is the task\nrepresentation? ",
    "start": "1705030",
    "end": "1716710"
  },
  {
    "text": "I feel like it makes\nsense to condition it on the training set. But I'm not sure.",
    "start": "1716710",
    "end": "1723054"
  },
  {
    "text": "Yeah, so one thing you\ncan do is condition it on the training data set. ",
    "start": "1723055",
    "end": "1736090"
  },
  {
    "text": "And this would, basically-- it's always mimic\nwhat we saw before",
    "start": "1736090",
    "end": "1741220"
  },
  {
    "text": "and except that now we're\nactually specifically thinking about Di train here.",
    "start": "1741220",
    "end": "1746290"
  },
  {
    "text": "And the cool thing about\nthis particular choice is that you can think of\nthis as a neural network that",
    "start": "1746290",
    "end": "1752980"
  },
  {
    "text": "takes as input the\ntraining data set and outputs a\ndistribution over phi, i.",
    "start": "1752980",
    "end": "1761930"
  },
  {
    "text": "And this starts to\nlook a lot like what we saw in black box\nmeta-learning, where we're",
    "start": "1761930",
    "end": "1768872"
  },
  {
    "text": "training a neural network to\ntake as input a training data set and output a set\nof parameters that",
    "start": "1768873",
    "end": "1774860"
  },
  {
    "text": "solves that training data set. And so, in many\nways, you can think about this kind of\nposterior inference process",
    "start": "1774860",
    "end": "1782480"
  },
  {
    "text": "as kind of the inner loop of\nthe meta-learning algorithm.",
    "start": "1782480",
    "end": "1789210"
  },
  {
    "text": "Now, one other thing\nthat I'll mention here is that we want to output\na distribution over phi, i.",
    "start": "1789210",
    "end": "1796409"
  },
  {
    "text": "And so, what we'll\nactually do is, we can model this as a\nGaussian distribution.",
    "start": "1796410",
    "end": "1801850"
  },
  {
    "text": "And so, this neural\nnetwork will actually output a mu and a\nsigma for phi, i.",
    "start": "1801850",
    "end": "1810360"
  },
  {
    "text": "And this will be a lot like\na Bayesian neural network, where we're going\nto be having a--",
    "start": "1810360",
    "end": "1815978"
  },
  {
    "text": "this will represent a\nGaussian distribution over the weights for task i.",
    "start": "1815978",
    "end": "1821340"
  },
  {
    "text": "And this is going to be twice\nas large as the typical kind",
    "start": "1821340",
    "end": "1826908"
  },
  {
    "text": "of output if we were just\noutputting a single parameter vector because, basically,\nthe size of mu of phi",
    "start": "1826908",
    "end": "1834149"
  },
  {
    "text": "is going to be equal to the\nsize of our original space. And, similarly, our\nsize over sigma of phi",
    "start": "1834150",
    "end": "1841350"
  },
  {
    "text": "will also be the same as the\nsize of the parameter vector. ",
    "start": "1841350",
    "end": "1848910"
  },
  {
    "text": "Cool, and then you can-- I guess, just to catch up\na little bit on the slide,",
    "start": "1848910",
    "end": "1854200"
  },
  {
    "text": "so this is what we\nwrote down before. We thought about what\nyou should condition on. And we can have q condition\non our training data.",
    "start": "1854200",
    "end": "1863340"
  },
  {
    "text": "And then we can view q as\nthe inner loop process.",
    "start": "1863340",
    "end": "1868580"
  },
  {
    "text": "And then, here,\nwhen we actually are optimizing for the likelihood\nunder our data for that--",
    "start": "1868580",
    "end": "1876230"
  },
  {
    "text": "for task i, what we can\ndo is we can specifically pick held out data\nfor this, such",
    "start": "1876230",
    "end": "1883009"
  },
  {
    "text": "that this is equal\nto log p of y test i, given phi, i and xi test.",
    "start": "1883010",
    "end": "1892760"
  },
  {
    "text": "And this will exactly\ncorrespond to what we do in the outer loop of the\nmeta-learning algorithm, where",
    "start": "1892760",
    "end": "1898730"
  },
  {
    "text": "we evaluate how good our\nneural network is, phi, i on making predictions\nfor new data points.",
    "start": "1898730",
    "end": "1905815"
  },
  {
    "text": "And so, this will\nbe-- these will be sampled from the query set. ",
    "start": "1905815",
    "end": "1912530"
  },
  {
    "text": "And so, this is\nwritten right here where, basically, the\ntraining data set is used for the inference process.",
    "start": "1912530",
    "end": "1917870"
  },
  {
    "text": "And the query data set\nis used to evaluate",
    "start": "1917870",
    "end": "1923360"
  },
  {
    "text": "the likelihood of the data\nunder those parameters. Cool, and then the last\nquestion is, where do the meta",
    "start": "1923360",
    "end": "1932240"
  },
  {
    "text": "parameters come into play here? And the natural place for\nthem to come into play,",
    "start": "1932240",
    "end": "1939410"
  },
  {
    "text": "at least insofar as this\ncorresponds to black box meta-learning, is right\nhere, where, basically,",
    "start": "1939410",
    "end": "1945590"
  },
  {
    "text": "the meta parameters-- you can view them as\nparameterizing this network q.",
    "start": "1945590",
    "end": "1954200"
  },
  {
    "text": "So this neural network\nhas parameters theta. You can also use them\nin other ways as well.",
    "start": "1954200",
    "end": "1961980"
  },
  {
    "text": "So you can, for example,\ninstead of having this be just like a standard\nGaussian distribution",
    "start": "1961980",
    "end": "1971240"
  },
  {
    "text": "over parameters, you\ncould actually learn a prior over your parameters. And so, this would correspond,\nthen, to p of phi given theta.",
    "start": "1971240",
    "end": "1982070"
  },
  {
    "text": "And this could be a good\nchoice because regularizing neural network parameters\ntowards a 0 mean unit Gaussian",
    "start": "1982070",
    "end": "1991070"
  },
  {
    "text": "distribution, that\nmay not correspond to something that's a\nvery useful set of weights",
    "start": "1991070",
    "end": "2000160"
  },
  {
    "text": "for the network. ",
    "start": "2000160",
    "end": "2005210"
  },
  {
    "text": "And so, if we introduce\nthe meta parameters",
    "start": "2005210",
    "end": "2010240"
  },
  {
    "text": "in the inference\nnetwork and the prior, then, the corresponding equation\nlooks like something like this.",
    "start": "2010240",
    "end": "2015640"
  },
  {
    "text": "I should also mention that you\ncould also incorporate the meta parameters into\nthe function that's",
    "start": "2015640",
    "end": "2022840"
  },
  {
    "text": "making predictions as well. In many cases, we\nhaven't done this.",
    "start": "2022840",
    "end": "2029290"
  },
  {
    "text": "But if, for example,\nyou're using an RNN and there's KIND OF some\nweight sharing between the meta",
    "start": "2029290",
    "end": "2034330"
  },
  {
    "text": "parameters and the\ntask-specific parameters, then, that would come\ninto play here as well.",
    "start": "2034330",
    "end": "2039340"
  },
  {
    "text": " And so, for completeness,\nthe final objective",
    "start": "2039340",
    "end": "2045409"
  },
  {
    "text": "look something like\nthis, where we are-- we now have-- we some kind\nof sum over your tasks i.",
    "start": "2045410",
    "end": "2056388"
  },
  {
    "text": "You're maximizing\nthis with respect to your meta parameters.",
    "start": "2056389",
    "end": "2061500"
  },
  {
    "text": "And you're basically optimizing\nfor how well your task",
    "start": "2061500",
    "end": "2067429"
  },
  {
    "text": "parameters solve the task\nand, also, optimizing for your inferred\nparameters or your kind",
    "start": "2067429",
    "end": "2076379"
  },
  {
    "text": "of inferred distribution over\nthe task-specific parameters matching some\nprior distribution.",
    "start": "2076380",
    "end": "2083020"
  },
  {
    "text": "Yeah. [INAUDIBLE],, can it choose\nthat the prior over phi",
    "start": "2083020",
    "end": "2088750"
  },
  {
    "text": "as this p of theta because,\nin something like MAML, we initialize the\nparameters with theta? And then we see-- when we\nsee examples, we [INAUDIBLE]..",
    "start": "2088750",
    "end": "2096780"
  },
  {
    "text": "And then you are\nupdating a prior version, like the belief [INAUDIBLE].",
    "start": "2096780",
    "end": "2102460"
  },
  {
    "text": "Or we could think about theta\nas being a prior for phi. So the question was,\ncan we think of--",
    "start": "2102460",
    "end": "2110170"
  },
  {
    "text": "can we just have p\nof phi just be theta?",
    "start": "2110170",
    "end": "2115191"
  },
  {
    "text": "[INAUDIBLE] Yeah, so there's a\nfew different ways",
    "start": "2115191",
    "end": "2120460"
  },
  {
    "text": "that you could\nparameterize this. You could basically\njust learn a--",
    "start": "2120460",
    "end": "2128110"
  },
  {
    "text": "basically have-- learn a\nmu theta and a sigma theta",
    "start": "2128110",
    "end": "2134710"
  },
  {
    "text": "that you're, basically,\ntrying to regularize towards.",
    "start": "2134710",
    "end": "2140410"
  },
  {
    "text": "I wasn't quite sure how\nthis relates to MAML. In this case, we're\npurely looking at-- you can think of this\nas just a pure black box",
    "start": "2140410",
    "end": "2147190"
  },
  {
    "text": "meta-learning approach. And we'll talk about\noptimization-based meta-learning approaches\nin a few slides.",
    "start": "2147190",
    "end": "2152359"
  },
  {
    "text": "But yeah. [INAUDIBLE] make you have\na prior belief of your",
    "start": "2152360",
    "end": "2159400"
  },
  {
    "text": "[INAUDIBLE]. And then you see data points. So I was thinking that\ninitializing the parameter with theta [INAUDIBLE] initial\nview of [INAUDIBLE] data",
    "start": "2159400",
    "end": "2168210"
  },
  {
    "text": "points with the labels. And then you tune based\non the data points. Or [INAUDIBLE]\nreally makes sense",
    "start": "2168210",
    "end": "2173970"
  },
  {
    "text": "to think of theta as a prior\nover phi or in a Bayesian sense? Yeah, so there-- in\nsomething like MAML,",
    "start": "2173970",
    "end": "2180644"
  },
  {
    "text": "it kind of definitely\nintuitively makes sense to actually think\nof theta as a prior, basically, the initial\nparameters as a prior.",
    "start": "2180645",
    "end": "2186660"
  },
  {
    "text": "And we'll cover that\nin a couple of slides. There's actually a way to\nformalize the intuition too,",
    "start": "2186660",
    "end": "2192270"
  },
  {
    "text": "which is pretty cool. ",
    "start": "2192270",
    "end": "2199870"
  },
  {
    "text": "Cool, so once we\nformulate this objective, we can then kind of optimize\nit, just like you would optimize",
    "start": "2199870",
    "end": "2206830"
  },
  {
    "text": "a variational auto-encoder. But instead of having your\ninference network be over",
    "start": "2206830",
    "end": "2213790"
  },
  {
    "text": "some representation space,\nit's actually over weights. ",
    "start": "2213790",
    "end": "2219220"
  },
  {
    "text": "And this allows you to represent\nnon-Gaussian distributions",
    "start": "2219220",
    "end": "2225940"
  },
  {
    "text": "over y test because you now\nhave a-- you're ultimately",
    "start": "2225940",
    "end": "2231190"
  },
  {
    "text": "getting a distribution\nover phi, i and then sampling from\nthat distribution. And so, yeah, it has\na number of benefits.",
    "start": "2231190",
    "end": "2238390"
  },
  {
    "text": "This is one benefit. And it gives you a\ndistribution over functions,",
    "start": "2238390",
    "end": "2243725"
  },
  {
    "text": "rather than only a\ndistribution over your labels because, at the end of this,\nyou get some kind of estimates",
    "start": "2243725",
    "end": "2254390"
  },
  {
    "text": "for y test. But you also are able to\nuse your inference network to get a distribution over\ntask-specific parameters.",
    "start": "2254390",
    "end": "2261029"
  },
  {
    "text": "Now, on this note, one thing\nthat I should mention is that, unlike in variational\nauto-encoders where you might",
    "start": "2261030",
    "end": "2266869"
  },
  {
    "text": "throw away q, in this case,\nyou won't-- you'll actually be using q at test time.",
    "start": "2266870",
    "end": "2273020"
  },
  {
    "text": "If you want to, basically,\ninfer a distribution of your task-specific\nparameters, that's exactly what q\nis doing in this case.",
    "start": "2273020",
    "end": "2279779"
  },
  {
    "text": "And so, the inner\nloop process is-- unlike in variational\nauto-encoders at test time,",
    "start": "2279780",
    "end": "2285980"
  },
  {
    "text": "you'll first use q to get phi. And then you'll use p to get a\ndistribution over your labels. ",
    "start": "2285980",
    "end": "2297450"
  },
  {
    "text": "Now, one of the downsides\nof this approach is that you can only represent\nGaussian distributions",
    "start": "2297450",
    "end": "2303960"
  },
  {
    "text": "over phi. And the reason for\nthis is that the things",
    "start": "2303960",
    "end": "2310480"
  },
  {
    "text": "like the reparameterization\ntrick and KL divergence are primarily applicable\nto Gaussian distributions.",
    "start": "2310480",
    "end": "2317110"
  },
  {
    "text": "And if you want\nsomething that is more expressive than a Gaussian\ndistribution over weights,",
    "start": "2317110",
    "end": "2322360"
  },
  {
    "text": "then, it is difficult to\napply this sort of framework to that setting.",
    "start": "2322360",
    "end": "2328029"
  },
  {
    "text": "That said, if you have a\nlarge enough neural network, especially a deep enough\nneural network, then, the neural network can kind\nof transform Gaussian--",
    "start": "2328030",
    "end": "2335890"
  },
  {
    "text": "samples of Gaussian\nweights into something that ends up looking fairly complex.",
    "start": "2335890",
    "end": "2341620"
  },
  {
    "text": " Cool, so that was kind of\nversion one of a Bayesian",
    "start": "2341620",
    "end": "2350180"
  },
  {
    "text": "meta-learning algorithm. And it was a black\nbox algorithm. Now let's talk a\nlittle bit about",
    "start": "2350180",
    "end": "2355280"
  },
  {
    "text": "optimization-based approaches. And there's-- in this case,\nthere's really kind of one",
    "start": "2355280",
    "end": "2361830"
  },
  {
    "text": "clear way to apply variational\ninference to black box methods. But for optimization-based\napproaches,",
    "start": "2361830",
    "end": "2367110"
  },
  {
    "text": "we're actually going to study\nthree different approaches to Bayesian\nmeta-learning algorithms.",
    "start": "2367110",
    "end": "2374579"
  },
  {
    "text": "And before we actually talk\nabout those approaches, let's talk a little bit about\nsimply just interpreting",
    "start": "2374580",
    "end": "2382453"
  },
  {
    "text": "optimization-based\nmeta-learning as kind of under a variational model.",
    "start": "2382453",
    "end": "2387860"
  },
  {
    "text": "And, in particular, one\nintuition that came up before is that, if you're running\ngradient descent starting",
    "start": "2387860",
    "end": "2395569"
  },
  {
    "text": "from some initial set\nof parameter vectors-- or some initial\nset of parameters",
    "start": "2395570",
    "end": "2402050"
  },
  {
    "text": "doing something like this,\nyou can kind of intuitively",
    "start": "2402050",
    "end": "2407870"
  },
  {
    "text": "think of the initial\nparameters as a form of prior",
    "start": "2407870",
    "end": "2415840"
  },
  {
    "text": "about the function that\nyou're trying to solve. And if you randomly\ninitialize, that",
    "start": "2415840",
    "end": "2421450"
  },
  {
    "text": "means you have no\nprior knowledge. Whereas, if you kind of\ninitialize as something that you think is pretty close\nto where you might want to go,",
    "start": "2421450",
    "end": "2428050"
  },
  {
    "text": "and you only run a few\nsteps of gradient descent, then, that's going to strongly\naffect the set of parameters that you end up with.",
    "start": "2428050",
    "end": "2435597"
  },
  {
    "text": "And it turns out\nthat you can actually formalize that a little bit. And so, here's a\ngraphical model that's",
    "start": "2435597",
    "end": "2442180"
  },
  {
    "text": "basically the same as the\none that we saw before. It doesn't split up the\ntrain set and the test set.",
    "start": "2442180",
    "end": "2447820"
  },
  {
    "text": "And it doesn't separately\nrepresent x and y. But, otherwise, it\ncorresponds to the same thing",
    "start": "2447820",
    "end": "2453790"
  },
  {
    "text": "that we saw before. And if we're interested in\nmaximizing the log probability",
    "start": "2453790",
    "end": "2460040"
  },
  {
    "text": "of the data given\nour meta parameters, you can expand this out\nfollowing the graphical model",
    "start": "2460040",
    "end": "2466960"
  },
  {
    "text": "to incorporate the latent\nvariable phi, where the log likelihood is equal to the log\nproduct of the integral of p",
    "start": "2466960",
    "end": "2476619"
  },
  {
    "text": "of D given phi and p\nof phi given theta. And, then, the last\nstep is one way",
    "start": "2476620",
    "end": "2484990"
  },
  {
    "text": "that you can try to\nestimate that integral. So if you have this pretty\nnasty integral over phi,",
    "start": "2484990",
    "end": "2492370"
  },
  {
    "text": "that means you're integrating\nover all possible values of your task-specific\nparameters.",
    "start": "2492370",
    "end": "2498020"
  },
  {
    "text": "So we have p of Di given\nphi, i and p of phi, i",
    "start": "2498020",
    "end": "2504160"
  },
  {
    "text": "given theta, D phi, i. ",
    "start": "2504160",
    "end": "2510230"
  },
  {
    "text": "One way that you could try to\napproximate this integral is, basically, try to find the phi,\ni that has maximum probability.",
    "start": "2510230",
    "end": "2520250"
  },
  {
    "text": "That's the thing that's\ngoing to have the most weight or, basically, have-- be the\nlargest term in this integral.",
    "start": "2520250",
    "end": "2527960"
  },
  {
    "text": "And you can very crudely\nestimate the integral as just taking\nthat map estimate,",
    "start": "2527960",
    "end": "2533510"
  },
  {
    "text": "the thing that has the\nhighest probability, and saying that this is\nroughly equal to the value",
    "start": "2533510",
    "end": "2544580"
  },
  {
    "text": "under the particular maximum\na posteriori estimate-- ",
    "start": "2544580",
    "end": "2551798"
  },
  {
    "text": "whoops, no d phi. And the reason why this is\ninteresting to think about",
    "start": "2551798",
    "end": "2558520"
  },
  {
    "text": "is that there's a paper that\nshows, in a very simplified",
    "start": "2558520",
    "end": "2564190"
  },
  {
    "text": "setting, that gradient\ndescent with early stopping corresponds to doing map\ninference under a Gaussian",
    "start": "2564190",
    "end": "2574300"
  },
  {
    "text": "prior with a mean at\nthe initial parameters",
    "start": "2574300",
    "end": "2579730"
  },
  {
    "text": "and a variance that depends on\na number of different factors, including the number of\ngradient steps that you run.",
    "start": "2579730",
    "end": "2588040"
  },
  {
    "text": "And so, what this means is\nthat, insofar as that last line the map estimate is\napproximating this integral,",
    "start": "2588040",
    "end": "2595300"
  },
  {
    "text": "you can think of an algorithm\nthat runs gradient descent to get the map estimate as\nsomething that's approximating",
    "start": "2595300",
    "end": "2602590"
  },
  {
    "text": "the log likelihood. And so, if, for example, you\nrun an algorithm like MAML",
    "start": "2602590",
    "end": "2609250"
  },
  {
    "text": "to get-- or run an algorithm\nlike gradient descent to get the map estimate\nand then optimize for the likelihood of the data\nunder that map estimate, which",
    "start": "2609250",
    "end": "2616720"
  },
  {
    "text": "is what MAML does,\nthat corresponds to the last equation here. ",
    "start": "2616720",
    "end": "2623963"
  },
  {
    "text": "And so, the thing\nthat's cool about this is it provides kind of a\nBayesian interpretation of what",
    "start": "2623963",
    "end": "2630029"
  },
  {
    "text": "the MAML algorithm is doing. Although, the thing\nthat's somewhat unsatisfying about\nthis is it doesn't",
    "start": "2630030",
    "end": "2636290"
  },
  {
    "text": "allow us to actually sample\nfrom the distribution over task parameters. ",
    "start": "2636290",
    "end": "2643640"
  },
  {
    "text": "It kind of allows\nus to interpret MAML as sort of a Bayesian approach. But it almost gets rid of\na lot of the Bayesian part",
    "start": "2643640",
    "end": "2651642"
  },
  {
    "text": "of Bayesian\napproaches, because it doesn't allow us\nto actually think about this distribution over\ntask-specific parameters.",
    "start": "2651643",
    "end": "2657744"
  },
  {
    "text": "And so, the next\nthree algorithms that we'll talk\nabout are algorithms that will allow us to actually\nsample from this distribution,",
    "start": "2657745",
    "end": "2663380"
  },
  {
    "text": "rather than using\na map estimate. ",
    "start": "2663380",
    "end": "2669760"
  },
  {
    "text": "Cool, so the first algorithm\nthat we can think about,",
    "start": "2669760",
    "end": "2676660"
  },
  {
    "text": "it will start from the algorithm\nthat we derive in the black box",
    "start": "2676660",
    "end": "2683200"
  },
  {
    "text": "case. And the only thing\nthat will differ",
    "start": "2683200",
    "end": "2689640"
  },
  {
    "text": "is our choice of\ninference network. And so, before,\ninference network",
    "start": "2689640",
    "end": "2694910"
  },
  {
    "text": "was just a neural\nnetwork that took as input the training data\nset and output some parameters",
    "start": "2694910",
    "end": "2701150"
  },
  {
    "text": "over-- a mean and variance over our\ntask-specific parameters.",
    "start": "2701150",
    "end": "2707090"
  },
  {
    "text": "And remember that\nthe inference network q, this variational\ndistribution, it can really be whatever\nyou want it to be.",
    "start": "2707090",
    "end": "2713492"
  },
  {
    "text": "And so, one thing\nthat you could do is, instead of having it be an\ninference network like this,",
    "start": "2713492",
    "end": "2721130"
  },
  {
    "text": "you could actually kind of embed\ngradient descent inside of q.",
    "start": "2721130",
    "end": "2726259"
  },
  {
    "text": "And so, what it could look\nlike is you could take--  start with some set of\nsome mean and variance.",
    "start": "2726260",
    "end": "2735230"
  },
  {
    "text": "I'll call this mean and variance\nmu theta and sigma theta.",
    "start": "2735230",
    "end": "2741820"
  },
  {
    "text": "And then what q could correspond\nto is running gradient descent",
    "start": "2741820",
    "end": "2749290"
  },
  {
    "text": "with respect to mu theta and\ngradient descent with respect",
    "start": "2749290",
    "end": "2755290"
  },
  {
    "text": "to sigma theta in order to get\nmu phi, i and sigma phi, i.",
    "start": "2755290",
    "end": "2762310"
  },
  {
    "text": " And you could have this kind\nof gradient descent process",
    "start": "2762310",
    "end": "2770510"
  },
  {
    "text": "correspond to your\ninference network q. ",
    "start": "2770510",
    "end": "2780470"
  },
  {
    "text": "And, in particular,\nthese gradients will be, with respect\nto mu and sigma,",
    "start": "2780470",
    "end": "2787140"
  },
  {
    "text": "with respect to the loss for\nthe training data D train, i.",
    "start": "2787140",
    "end": "2792180"
  },
  {
    "start": "2792180",
    "end": "2799069"
  },
  {
    "text": "So q can be an\narbitrary function. And instead of having\nq be a neural network, it could include a gradient\noperator inside of it.",
    "start": "2799070",
    "end": "2807540"
  },
  {
    "text": "And so, what you can do is\nhave q correspond to SGD speed on the mean and variance\nof some neural network",
    "start": "2807540",
    "end": "2814340"
  },
  {
    "text": "weights with respect\nto D train, i. ",
    "start": "2814340",
    "end": "2823790"
  },
  {
    "text": "And so, in this case, this will\ngive you a kind of mu and sigma",
    "start": "2823790",
    "end": "2829490"
  },
  {
    "text": "over phi, i. And kind of once you define this\ninference network like this,",
    "start": "2829490",
    "end": "2836970"
  },
  {
    "text": "you can, kind of,\nagain, reuse all of the same kind of training\nprocedure that we saw before.",
    "start": "2836970",
    "end": "2843640"
  },
  {
    "text": "Yeah? [INAUDIBLE] actually\nbeing a distribution",
    "start": "2843640",
    "end": "2849440"
  },
  {
    "text": "or represented in distribution\nbecause, previously, [INAUDIBLE]. Now it's just a process that\ngives you the distribution?",
    "start": "2849440",
    "end": "2857870"
  },
  {
    "text": "Yeah, so instead of being\na neural network that outputs a distribution,\nit will be a process that",
    "start": "2857870",
    "end": "2863480"
  },
  {
    "text": "still yields a distribution. The-- this process does\nstill have some parameters.",
    "start": "2863480",
    "end": "2871670"
  },
  {
    "text": "Specifically, it has the\nkind of initial mu and sigma. And I called these kind\nof mu theta and sigma",
    "start": "2871670",
    "end": "2878060"
  },
  {
    "text": "theta, in that they signify\nthe initial set of parameters that we saw in an\nalgorithm like MAML.",
    "start": "2878060",
    "end": "2884120"
  },
  {
    "start": "2884120",
    "end": "2890530"
  },
  {
    "text": "Any other questions? ",
    "start": "2890530",
    "end": "2906640"
  },
  {
    "text": "Cool, so the only\nthing that changed, we're using the same\nobjective as before.",
    "start": "2906640",
    "end": "2911920"
  },
  {
    "text": "We're just redefining\nthe inference network to have a different form. And this form is analogous\nto the kind of thing",
    "start": "2911920",
    "end": "2918270"
  },
  {
    "text": "that we saw in\noptimization-based meta-learning algorithms. We're basically just stuffing\ngradient descent inside",
    "start": "2918270",
    "end": "2923850"
  },
  {
    "text": "of our inference\nnetwork and actually having gradient\ndescent correspond to what happens inside.",
    "start": "2923850",
    "end": "2930480"
  },
  {
    "text": "The other thing that's\ndifferent about-- a standard MAML algorithm is\nthat our meta parameters now",
    "start": "2930480",
    "end": "2936930"
  },
  {
    "text": "are going to correspond\nto both mu and sigma here. And so, we'll have--",
    "start": "2936930",
    "end": "2942510"
  },
  {
    "text": "we won't just have a\nsingle theta vector. We'll have two of these\ntheta vectors, one",
    "start": "2942510",
    "end": "2948180"
  },
  {
    "text": "that corresponds to\nthe mean and one that corresponds to the variance. ",
    "start": "2948180",
    "end": "2955960"
  },
  {
    "text": "Now, the cool thing about\nthis is that, at test time, once we want to do\ninference to infer",
    "start": "2955960",
    "end": "2961200"
  },
  {
    "text": "our task-specific\nparameters, we're just going to be running\ngradient descent at test time. So instead of doing\ninference by passing it",
    "start": "2961200",
    "end": "2968490"
  },
  {
    "text": "through a neural network to get\nour task-specific parameters or our distribution over the\ntask-specific parameters, we're going to be\nrunning gradient descent.",
    "start": "2968490",
    "end": "2975510"
  },
  {
    "text": "This means that we should\nbe kind of a little bit more robust to tasks that are a\nlittle bit out of distribution",
    "start": "2975510",
    "end": "2983400"
  },
  {
    "text": "at test time. The downside of this is that\nwe are, similar to before,",
    "start": "2983400",
    "end": "2990000"
  },
  {
    "text": "going to end up with a\nGaussian distribution over our task-specific\nparameters.",
    "start": "2990000",
    "end": "2995790"
  },
  {
    "text": "And this means\nthat, if we wanted to represent a more\ncomplex distribution over our task-specific\nparameters,",
    "start": "2995790",
    "end": "3002210"
  },
  {
    "text": "we would be out of\nluck in that case. And it's, again,\nimportant for it",
    "start": "3002210",
    "end": "3008960"
  },
  {
    "text": "to be Gaussian for\ntwo reasons, one, that it allows us\nto evaluate the KL divergence in closed form.",
    "start": "3008960",
    "end": "3014780"
  },
  {
    "text": "And second, it allows us to use\nthe reparameterization trick to back prop into this.",
    "start": "3014780",
    "end": "3020990"
  },
  {
    "text": "So would we-- when\nwe sample from q-- when we sample a\nphi from q, we're",
    "start": "3020990",
    "end": "3026870"
  },
  {
    "text": "going to be sampling a phi\nfrom a Gaussian distribution parameterized by mu\nphi and sigma phi.",
    "start": "3026870",
    "end": "3037640"
  },
  {
    "text": "And we can, again, use the\nsame kind of reparameterization trick and have this be equal\nto mu phi, plus epsilon,",
    "start": "3037640",
    "end": "3045170"
  },
  {
    "text": "times sigma phi, where epsilon\nis sampled from a Gaussian",
    "start": "3045170",
    "end": "3052609"
  },
  {
    "text": "with mean 0 and unit variance. And by making this a\nGaussian distribution, that allows us to use this\nreparameterization trick",
    "start": "3052610",
    "end": "3059569"
  },
  {
    "text": "and back prop into\nmu phi and sigma, i but, also, back\nprop all the way back",
    "start": "3059570",
    "end": "3066110"
  },
  {
    "text": "into mu theta and sigma theta. ",
    "start": "3066110",
    "end": "3071940"
  },
  {
    "text": "Yeah? In general, the meta\nparameters can be more than [INAUDIBLE] et\ncetera, et cetera.",
    "start": "3071940",
    "end": "3079140"
  },
  {
    "text": "So that's still fits into\nthis framework, right? That doesn't-- [INAUDIBLE] I\njust wanted to confirm that",
    "start": "3079140",
    "end": "3084838"
  },
  {
    "text": "for students. Yeah, so the question\nwas, in general, in optimization-based\nmeta-learning, the meta parameters\ncan correspond",
    "start": "3084838",
    "end": "3090420"
  },
  {
    "text": "to not just the initialization\nbut other things, like the learning\nrate and so forth. And, yeah, that also fits\nwell into this framework.",
    "start": "3090420",
    "end": "3096310"
  },
  {
    "text": "So here, I'm writing mu\ntheta and sigma theta as the main meta parameters.",
    "start": "3096310",
    "end": "3102060"
  },
  {
    "text": "But you can also\noptimize other things. And so, for example, you could\noptimize the learning rate here",
    "start": "3102060",
    "end": "3110369"
  },
  {
    "text": "and have that be a part of\nthe meta parameters as well. ",
    "start": "3110370",
    "end": "3120369"
  },
  {
    "text": "Cool, so then there's a\nquestion of whether we can model a non-Gaussian posterior.",
    "start": "3120370",
    "end": "3126210"
  },
  {
    "text": "And we'll look at two different\napproaches for doing this. ",
    "start": "3126210",
    "end": "3131960"
  },
  {
    "text": "The first is-- will\nbe to use ensembles. And, in particular,\nwhat we can do",
    "start": "3131960",
    "end": "3139590"
  },
  {
    "text": "is, if we want to get a\ndistribution over phi, i,",
    "start": "3139590",
    "end": "3146040"
  },
  {
    "text": "we can basically just\ntrain an ensemble of MAMLs and, specifically, just train\nM independent MAML models,",
    "start": "3146040",
    "end": "3157418"
  },
  {
    "text": "train them independently with\ndifferent mini batches of tasks and so forth, to get\nan ensemble of MAMLs.",
    "start": "3157418",
    "end": "3164339"
  },
  {
    "text": "And it's also worth noting\nthat you can use ensembles with kind of black box or\nnon-parametric methods as well.",
    "start": "3164340",
    "end": "3170170"
  },
  {
    "text": "And this will also give you\nsome sense of distribution over meta parameters.",
    "start": "3170170",
    "end": "3176282"
  },
  {
    "text": "And so, this will give\nyou a distribution over meta parameters. And then when you\nrun gradient descent starting from those\ninitializations, you'll also",
    "start": "3176282",
    "end": "3182700"
  },
  {
    "text": "get a distribution over phi, i. ",
    "start": "3182700",
    "end": "3188240"
  },
  {
    "text": "One challenge with ensembles\nis that if you just train independently,\noftentimes, training will result in a set of\nparameters or meta parameters",
    "start": "3188240",
    "end": "3196279"
  },
  {
    "text": "that are very similar\nto one another. And one approach for\ndealing with this is to try to more actively\ndiversify the weights that you",
    "start": "3196280",
    "end": "3204290"
  },
  {
    "text": "get and try to optimize for a\nmore diverse ensemble of MAMLs.",
    "start": "3204290",
    "end": "3211920"
  },
  {
    "text": "And so, the way this can\nwork is, there's actually a-- rather than just crudely trying\nto say, oh, the parameter",
    "start": "3211920",
    "end": "3220050"
  },
  {
    "text": "vector should be\nindependent, there's something called Stein\nVariational Gradient Descent",
    "start": "3220050",
    "end": "3225660"
  },
  {
    "text": "that actually actively\npushes particles away from each other with a\nparticular choice of kernel.",
    "start": "3225660",
    "end": "3233859"
  },
  {
    "text": "And so, the way that this\nmethod is going to work is, when we run gradient\ndescent in the inner loop,",
    "start": "3233860",
    "end": "3240250"
  },
  {
    "text": "we are not just going to run\ngradient descent on our support set.",
    "start": "3240250",
    "end": "3246240"
  },
  {
    "text": "So, typically, we'll do\nsomething like theta,",
    "start": "3246240",
    "end": "3251430"
  },
  {
    "text": "minus alpha grad theta, L of\ntheta with respect to D train.",
    "start": "3251430",
    "end": "3257520"
  },
  {
    "text": "And, then, this will be-- this will correspond to phi, i. And what we're going to do\nthat's a little bit different",
    "start": "3257520",
    "end": "3264750"
  },
  {
    "text": "is we're going to\nsay that we want phi, i to be kind of different\nfrom the other members",
    "start": "3264750",
    "end": "3274039"
  },
  {
    "text": "of our ensemble. And so, we're going to optimize\nfor multiple particles.",
    "start": "3274040",
    "end": "3280880"
  },
  {
    "text": "And so, I'll use m to\ndenote the particle number. And we're going to,\nadditionally, have a term",
    "start": "3280880",
    "end": "3288530"
  },
  {
    "text": "that says that we want\nto kind of push away",
    "start": "3288530",
    "end": "3296070"
  },
  {
    "text": "the value of our\nparameters and make it different from other values.",
    "start": "3296070",
    "end": "3301510"
  },
  {
    "text": "And so, we can measure\nthis-- or the distance between our current parameters\nthat we're optimizing",
    "start": "3301510",
    "end": "3308130"
  },
  {
    "text": "and the values,\nthe other particles",
    "start": "3308130",
    "end": "3316430"
  },
  {
    "text": "that are different for,\nlike, m prime not equal to m for that particular task.",
    "start": "3316430",
    "end": "3323015"
  },
  {
    "text": " And so, this is what the inner\nloop is going to look like.",
    "start": "3323015",
    "end": "3329970"
  },
  {
    "text": "And, then, the outer\nloop will be, basically, just the same as before.",
    "start": "3329970",
    "end": "3335190"
  },
  {
    "text": "The equations here are\njust copied from the paper. And so, they use slightly\ndifferent notation. But the outer loop is\njust going to correspond",
    "start": "3335190",
    "end": "3342270"
  },
  {
    "text": "to optimizing for the likelihood\nof phi, i on the test set",
    "start": "3342270",
    "end": "3354990"
  },
  {
    "text": "for task i. And you're going to\nbe doing this for all of the different parameters. And so, you're going to\nsum over both the tasks i,",
    "start": "3354990",
    "end": "3362280"
  },
  {
    "text": "as well as the ensemble members. ",
    "start": "3362280",
    "end": "3370803"
  },
  {
    "text": "And so, the only thing,\nreally, here that's changing is, first, that\nwe're going to be-- we're going to have multiple\nparticles that we're optimizing",
    "start": "3370803",
    "end": "3376750"
  },
  {
    "text": "for in the inner loop. And we're going\nto push them apart by adding this additional term\nin our inner loop objective.",
    "start": "3376750",
    "end": "3383665"
  },
  {
    "text": "Yeah. What kind of kernels\nare most useful here? Yeah, the question is,\nwhat kind of kernels",
    "start": "3383665",
    "end": "3388869"
  },
  {
    "text": "are most useful here? I can't actually\nremember exactly what they used in the paper here. I think that, typically,\nsomething just like a--",
    "start": "3388870",
    "end": "3398520"
  },
  {
    "text": "looking at the Euclidean\ndistance is reasonable here.",
    "start": "3398520",
    "end": "3404460"
  },
  {
    "text": "I do think that distances in\nparameter space are not always a good function of kind\nof functional similarity",
    "start": "3404460",
    "end": "3413220"
  },
  {
    "text": "because you can-- if there are\nsome parts of the weight vector that are-- does not used by the\nnetwork, then, you",
    "start": "3413220",
    "end": "3419820"
  },
  {
    "text": "can push those parts away a\nlot and just kind of ignore the other parts. And that will lead\nto two functions that",
    "start": "3419820",
    "end": "3426203"
  },
  {
    "text": "are very different\nin weight space but are identically\nfunctionally. And so, you want your kernel\nto try to pay attention",
    "start": "3426203",
    "end": "3434850"
  },
  {
    "text": "to all of the parameters\nin the parameter vector to try to prevent that case. And if you can measure some\nnotion of functionality,",
    "start": "3434850",
    "end": "3444238"
  },
  {
    "text": "for example, looking at\nsomething like the Fisher information matrix or\nsomething like that, then, that may lead\nto better performance.",
    "start": "3444238",
    "end": "3450310"
  },
  {
    "text": "But those measures often end up\nbeing computationally expensive or crude estimates\nof something that's",
    "start": "3450310",
    "end": "3456510"
  },
  {
    "text": "computationally expensive.  Yeah? [INAUDIBLE] because\nwe won't be doing--",
    "start": "3456510",
    "end": "3465370"
  },
  {
    "text": "we won't have [INAUDIBLE]? ",
    "start": "3465370",
    "end": "3472450"
  },
  {
    "text": "So you're saying that,\nwhat happens at meta test time might be different? Or-- [INAUDIBLE]",
    "start": "3472450",
    "end": "3479450"
  },
  {
    "text": "So at meta test\ntime, you actually also run this same\ninner loop as well. And so, you-- basically,\nwhat you want to happen",
    "start": "3479450",
    "end": "3486520"
  },
  {
    "text": "is you'll have a single\nset of initial parameters. And you'll want to\ntry to have this lead",
    "start": "3486520",
    "end": "3493839"
  },
  {
    "text": "to multiple task-specific\nparameters for that task.",
    "start": "3493840",
    "end": "3500690"
  },
  {
    "text": "And this will basically\nrepresent samples from p, i",
    "start": "3500690",
    "end": "3506050"
  },
  {
    "text": "of theta, given-- sorry, p, i-- or p of phi, i\ngiven theta and D train, i.",
    "start": "3506050",
    "end": "3514450"
  },
  {
    "text": "And so, just like\nbefore, we were-- on the whiteboard\nthat's behind it,",
    "start": "3514450",
    "end": "3520381"
  },
  {
    "text": "we were getting this\nsort of distribution with our inference network. In this case, we're\nrepresenting this distribution",
    "start": "3520382",
    "end": "3525450"
  },
  {
    "text": "with these different\nkind of samples or these different\nensemble members. ",
    "start": "3525450",
    "end": "3537990"
  },
  {
    "text": "Cool, so the benefit of this\nsort of approach is it's pretty simple to implement.",
    "start": "3537990",
    "end": "3544440"
  },
  {
    "text": "It tends to work pretty well. Ensembles, especially, are one\nof the most effective methods",
    "start": "3544440",
    "end": "3550319"
  },
  {
    "text": "for model uncertainty\nor epistemic uncertainty and, also, can give you\nnon-Gaussian distributions.",
    "start": "3550320",
    "end": "3558270"
  },
  {
    "text": "The phi, i that you\nend up with, these could be samples from\na distribution that's",
    "start": "3558270",
    "end": "3563360"
  },
  {
    "text": "much more complex than\na Gaussian distribution. ",
    "start": "3563360",
    "end": "3568970"
  },
  {
    "text": "The downside is that you do need\nto maintain m different model instances. And this can get pretty\nexpensive at times.",
    "start": "3568970",
    "end": "3578329"
  },
  {
    "text": "But one way to try to mitigate\nthis is to do gradient-based-- to do gradient descent\nonly on the last layer.",
    "start": "3578330",
    "end": "3584360"
  },
  {
    "text": "And, then, you only have to\nmaintain m different copies of the last layer, rather\nthan m different copies",
    "start": "3584360",
    "end": "3589490"
  },
  {
    "text": "of the entire network. ",
    "start": "3589490",
    "end": "3596420"
  },
  {
    "text": "Cool, now, from\nthere, we'll cover one more Bayesian\nmeta-learning algorithm",
    "start": "3596420",
    "end": "3602210"
  },
  {
    "text": "which tries to give us a\nnon-Gaussian distribution over all of the\nparameters in a way that's",
    "start": "3602210",
    "end": "3607220"
  },
  {
    "text": "a bit cheaper than maintaining\nm different copies. ",
    "start": "3607220",
    "end": "3614400"
  },
  {
    "text": "And some of the intuition\nbehind this last approach is to try to sample\nparameter vectors",
    "start": "3614400",
    "end": "3619650"
  },
  {
    "text": "with a procedure that looks\na little bit like Hamiltonian Monte Carlo. And the way that Hamiltonian\nMonte Carlo works",
    "start": "3619650",
    "end": "3625710"
  },
  {
    "text": "is you typically first add\nnoise to your parameters and then run gradient descent\non your parameters in order to--",
    "start": "3625710",
    "end": "3634257"
  },
  {
    "text": "typically, you actually\niterate that process in order to ultimately draw\nsamples from some distribution.",
    "start": "3634257",
    "end": "3642250"
  },
  {
    "text": "And some of the\nintuition behind this is we're going to try to learn\na prior where, if we randomly",
    "start": "3642250",
    "end": "3652490"
  },
  {
    "text": "kind of kick the\nparameters or randomly add noise to the parameters,\nthat will put us in different modes\nof the distribution.",
    "start": "3652490",
    "end": "3660000"
  },
  {
    "text": "And so. If we think about\nthe kind of example that we talked about before\nwhere different attributes would correspond to\ndifferent classifiers,",
    "start": "3660000",
    "end": "3667252"
  },
  {
    "text": "for example, if we wanted to\nlearn a classifier for smiling or wearing a hat, versus\na classifier for smiling and young, we'd like to\nlearn a prior theta where,",
    "start": "3667252",
    "end": "3677150"
  },
  {
    "text": "if we add noise\nin one direction, it puts us in kind of one basin.",
    "start": "3677150",
    "end": "3683510"
  },
  {
    "text": "And if we add\nnoise in the other, it kind of puts us\nin a different mode. And so, ideally, we'd like to\nbe able to learn a theta such",
    "start": "3683510",
    "end": "3691339"
  },
  {
    "text": "that, if we add noise and\nthen run gradient descent, we'll get different samples from\nthis distribution that end up",
    "start": "3691340",
    "end": "3699440"
  },
  {
    "text": "being classifiers that are-- that correspond to\nthese different modes",
    "start": "3699440",
    "end": "3705590"
  },
  {
    "text": "of the distribution. ",
    "start": "3705590",
    "end": "3711880"
  },
  {
    "text": "So that's the\nhigh-level intuition. In terms of how we\nmight actually do this,",
    "start": "3711880",
    "end": "3717150"
  },
  {
    "text": "first, we're actually going\nto have a distribution over our meta parameters. This is going to be\ndifferent from the things",
    "start": "3717150",
    "end": "3723990"
  },
  {
    "text": "that we saw before. Before, we just had a single\nvector of meta parameters that were basically\nparameterizing",
    "start": "3723990",
    "end": "3731520"
  },
  {
    "text": "our prior and our\ninference network. And here, we're\ngoing to actually also have a distribution\nover these meta parameters.",
    "start": "3731520",
    "end": "3740430"
  },
  {
    "text": "And then we're going to also\nhave a distribution of phi, i given theta.",
    "start": "3740430",
    "end": "3745980"
  },
  {
    "text": "And our goal will be to sample\nfrom the posterior of phi, i given the support set\nand the test example.",
    "start": "3745980",
    "end": "3753585"
  },
  {
    "text": " We'd like to also be able to\nsample from this distribution",
    "start": "3753585",
    "end": "3761690"
  },
  {
    "text": "without the test example. So, in practice, we can\nobserve the test example. And that distribution\nup there corresponds",
    "start": "3761690",
    "end": "3769310"
  },
  {
    "text": "to inferring phi, i from\neverything that we can observe. Although, in\npractice, it'd be nice",
    "start": "3769310",
    "end": "3774830"
  },
  {
    "text": "if we had a single parameter\nvector that worked well for any test example,\nnot just the test example",
    "start": "3774830",
    "end": "3781040"
  },
  {
    "text": "that is observed at any\ngiven point in time. And then from there,\nwe can write down",
    "start": "3781040",
    "end": "3788030"
  },
  {
    "text": "our distribution over\nphi, i as, again, kind of the product of p\nof theta, p of phi, i given",
    "start": "3788030",
    "end": "3796310"
  },
  {
    "text": "theta, and then p\nof y train, given x train and phi, i and, then,\nof course, in this case,",
    "start": "3796310",
    "end": "3803600"
  },
  {
    "text": "integrating out theta. So this is just the product\nof the distributions that",
    "start": "3803600",
    "end": "3810230"
  },
  {
    "text": "underlie this graphical model.  But, of course, this\nintegral, like many",
    "start": "3810230",
    "end": "3816693"
  },
  {
    "text": "of the other integrals that\nwe've seen in the class, is completely\nintractable because it has to integrate out over\nkind of all the parameters",
    "start": "3816693",
    "end": "3825609"
  },
  {
    "text": "in this Gaussian distribution. And so, the last\nway that we're going",
    "start": "3825610",
    "end": "3831250"
  },
  {
    "text": "to try to deal with an\nintractable integral, in this case, is trying\nto crudely estimate",
    "start": "3831250",
    "end": "3838940"
  },
  {
    "text": "this distribution right here\nof phi given theta and x train, y train. And if we did know\nthis distribution,",
    "start": "3838940",
    "end": "3845730"
  },
  {
    "text": "then, sampling would be much-- inferring phi, i given\nx train of y train",
    "start": "3845730",
    "end": "3850880"
  },
  {
    "text": "would be much easier\nbecause what we could do is we could first\nsample theta and then sample from this\ndistribution right here.",
    "start": "3850880",
    "end": "3859793"
  },
  {
    "text": "We can just-- and that's what's\ncalled ancestral sampling, where you sample\none and then sample from the next distribution. And we, basically, transform\nour graphical model",
    "start": "3859793",
    "end": "3866610"
  },
  {
    "text": "into this one, where you\nfirst sample from theta. And then we sample\nfrom the distribution that feeds into phi, i.",
    "start": "3866610",
    "end": "3874060"
  },
  {
    "text": "And that would give us a sample\nfrom the kind of distribution of p phi, i given x\ntrain and y train.",
    "start": "3874060",
    "end": "3882315"
  },
  {
    "text": "Now, of course,\nwe don't actually know this distribution of p of\nphi, i given theta and x train,",
    "start": "3882315",
    "end": "3887920"
  },
  {
    "text": "y train. But what we could do is we could\ntry to estimate this as a map",
    "start": "3887920",
    "end": "3893200"
  },
  {
    "text": "estimate, just like\nwe saw in the kind of Bayesian\ninterpretation of MAML when we first started talking\nabout optimization-based",
    "start": "3893200",
    "end": "3900070"
  },
  {
    "text": "Bayesian meta-learning\nalgorithms. And the map estimate is a crude\nestimate of this distribution.",
    "start": "3900070",
    "end": "3909760"
  },
  {
    "text": "It's only giving you the\nmode of this distribution, rather than a sample\nfrom the distribution.",
    "start": "3909760",
    "end": "3916240"
  },
  {
    "text": "But it's also a very\nconvenient approximation to this distribution\nbecause, once we have this approximation,\nthen we can just--",
    "start": "3916240",
    "end": "3926320"
  },
  {
    "text": "then it's very easy to\nsample from p of phi, i. And, in particular,\nonce we approximate this",
    "start": "3926320",
    "end": "3934680"
  },
  {
    "text": "with map inference\nand specifically with a few steps of\ngradient descent,",
    "start": "3934680",
    "end": "3940320"
  },
  {
    "text": "then, at test time,\nwhat happens is we will basically first\nsample from theta.",
    "start": "3940320",
    "end": "3952980"
  },
  {
    "text": "And then, to sample-- that then next we want a\nsample from p of phi given",
    "start": "3952980",
    "end": "3959970"
  },
  {
    "text": "theta and Di train. And to do this, we'll then\ntake the sample that we took",
    "start": "3959970",
    "end": "3968160"
  },
  {
    "text": "and then very crudely\napproximate this as running gradient descent\nstarting from the sample. Maybe, I'll denote\nthis as theta prime,",
    "start": "3968160",
    "end": "3974615"
  },
  {
    "text": "just to differentiate\nit from p of theta. And then we're going to run\ngradient descent on Di train.",
    "start": "3974615",
    "end": "3984450"
  },
  {
    "text": "And this kind of corresponds\nexactly to the procedure that we saw on the previous\nslide, where we first sample and then run gradient descent.",
    "start": "3984450",
    "end": "3990630"
  },
  {
    "start": "3990630",
    "end": "3997759"
  },
  {
    "text": "And, then, sampling is easy. What about training?",
    "start": "3997760",
    "end": "4004080"
  },
  {
    "text": "You can also actually\njust train this with amortized\nvariational inference. I'm going to skip\nthe exact training",
    "start": "4004080",
    "end": "4011310"
  },
  {
    "text": "procedure for the sake of time. But if you're interested\nin learning more, we can talk about\nit in office hours. Or you can take a\nlook at the paper.",
    "start": "4011310",
    "end": "4017910"
  },
  {
    "text": " And so, it, again--",
    "start": "4017910",
    "end": "4025030"
  },
  {
    "text": "sampling from p of theta and\nthen running gradient descent looks like what we\ntalked about before.",
    "start": "4025030",
    "end": "4030700"
  },
  {
    "text": "In particular, sampling\nfrom p of theta corresponds to,\nbasically, taking mu theta",
    "start": "4030700",
    "end": "4038740"
  },
  {
    "text": "and then adding\nnoise corresponding and multiplying that\nnoise by the variance.",
    "start": "4038740",
    "end": "4045320"
  },
  {
    "text": "And so, that will\ncorrespond to, basically, adding noise to mu theta.",
    "start": "4045320",
    "end": "4050470"
  },
  {
    "text": "And then step two corresponds\nto running gradient descent, which will hopefully\nget us into these two",
    "start": "4050470",
    "end": "4056950"
  },
  {
    "text": "modes of the\ndistribution or, ideally, more than two modes\nof the distribution, if we have more\nambiguity than that.",
    "start": "4056950",
    "end": "4063730"
  },
  {
    "start": "4063730",
    "end": "4069930"
  },
  {
    "text": "Do you have a question? [INAUDIBLE] So what do you\nmean by [INAUDIBLE]",
    "start": "4069930",
    "end": "4076940"
  },
  {
    "text": "into the two [INAUDIBLE]? Does it mean [INAUDIBLE],, or do\nyou just do the process twice?",
    "start": "4076940",
    "end": "4085920"
  },
  {
    "text": "Right, so the question\nis, does this mean that we're keeping two copies? Or are we doing\nthe process twice?",
    "start": "4085920",
    "end": "4092270"
  },
  {
    "text": "So yeah, so if we-- our goal is really to sample\nfrom p of phi, sample from--",
    "start": "4092270",
    "end": "4102429"
  },
  {
    "text": "be able to sample multiple\ndifferent task-specific parameters. And the way that\nwe'll do that is we will just repeat this\nprocess multiple times,",
    "start": "4102430",
    "end": "4109839"
  },
  {
    "text": "depending on the number\nof samples that we want. And so, if we want to see--",
    "start": "4109840",
    "end": "4115930"
  },
  {
    "text": "if we think that\nthere might be-- well, yeah, basically, this\ncorresponds to the number of samples that you want.",
    "start": "4115930",
    "end": "4121240"
  },
  {
    "text": "You might start by collecting\nfive samples, for example, by adding noise, and then\nrunning gradient descent,",
    "start": "4121240",
    "end": "4126399"
  },
  {
    "text": "and repeating that five times to\nget five different classifiers. And if you see that you have a\nlot of variance among your five",
    "start": "4126399",
    "end": "4133756"
  },
  {
    "text": "different classifiers,\nthen, you could continue to sample other\nclassifiers from there.",
    "start": "4133757",
    "end": "4139540"
  },
  {
    "text": " The upside of this is\nthat it will give you",
    "start": "4139540",
    "end": "4145370"
  },
  {
    "text": "a non-Gaussian posterior. It's fairly simple at test time. You just add noise and\nrun gradient descent.",
    "start": "4145370",
    "end": "4151399"
  },
  {
    "text": "You also only need to\ntrain one model instance.",
    "start": "4151399",
    "end": "4158130"
  },
  {
    "text": "The downside is that it leads\nto a more complex training or meta-training procedure.",
    "start": "4158130",
    "end": "4163910"
  },
  {
    "text": " Yeah? So [INAUDIBLE]\nsample [INAUDIBLE]",
    "start": "4163910",
    "end": "4171040"
  },
  {
    "text": "because then [INAUDIBLE],,\nso [INAUDIBLE]..",
    "start": "4171040",
    "end": "4177160"
  },
  {
    "start": "4177160",
    "end": "4183970"
  },
  {
    "text": "Yeah, so to sample multiple-- to generate multiple\nsamples from phi, you'll sample multiple thetas\nand run gradient descent",
    "start": "4183970",
    "end": "4189818"
  },
  {
    "text": "from each of those thetas. [INAUDIBLE] only\none [INAUDIBLE]??",
    "start": "4189819",
    "end": "4197410"
  },
  {
    "text": "Oh, sorry, you only need one\nmeta-training model instance. Whereas, when you train\nan ensemble of MAMLs,",
    "start": "4197410",
    "end": "4202510"
  },
  {
    "text": "you'll need kind of multiple\ncopies of the meta parameters. ",
    "start": "4202510",
    "end": "4210730"
  },
  {
    "text": "Cool, so to summarize\nall the methods that we've talked about,\nV0 is just to output",
    "start": "4210730",
    "end": "4216340"
  },
  {
    "text": "a distribution over y\ntest, which is simple. But it can't reason\nabout uncertainty",
    "start": "4216340",
    "end": "4222460"
  },
  {
    "text": "over function space. And, then, all the methods\nthat we talked about after V0, we're actually giving\nus distributions",
    "start": "4222460",
    "end": "4228460"
  },
  {
    "text": "over classifiers or\ndistribution over predictors. We talked about a\nblack box approach",
    "start": "4228460",
    "end": "4233860"
  },
  {
    "text": "that used a latent\nvariable model over phi with amortized\nvariational inference.",
    "start": "4233860",
    "end": "4238900"
  },
  {
    "text": "And this allowed us to represent\nnon-Gaussian distributions over y but was restricted\nto Gaussian distributions",
    "start": "4238900",
    "end": "4245710"
  },
  {
    "text": "over phi.  And then we also\ntalked about three",
    "start": "4245710",
    "end": "4250750"
  },
  {
    "text": "different optimization-based\nmeta-learning algorithms. The first was just to\nstuff gradient descent",
    "start": "4250750",
    "end": "4259300"
  },
  {
    "text": "into our inference network. And this was pretty simple. It was a very\nsimple modification",
    "start": "4259300",
    "end": "4265210"
  },
  {
    "text": "of the black box approach. But it meant that p\nof phi, i given theta had to be modeled as a Gaussian.",
    "start": "4265210",
    "end": "4271210"
  },
  {
    "text": "We also talked\nabout an ensemble, which is pretty simple,\nmaking model non-Gaussian distributions but requires\nmultiple model instances.",
    "start": "4271210",
    "end": "4278050"
  },
  {
    "text": "And then the more\nhybrid approach that we talked about that was\ncombining this map estimate",
    "start": "4278050",
    "end": "4286060"
  },
  {
    "text": "and variational\ninference can give you a non-Gaussian posterior\nbut involves a more complex",
    "start": "4286060",
    "end": "4292030"
  },
  {
    "text": "training procedure. In the last five\nminutes, I'd like to talk a little bit about\nevaluation of these approaches.",
    "start": "4292030",
    "end": "4302315"
  },
  {
    "text": "One thing that you\ncould consider doing is to try to use\nstandard benchmarks, like MiniImagenet\nset or Omniglot.",
    "start": "4302315",
    "end": "4307690"
  },
  {
    "text": "And these are standardized\nand have real images. And they're a good\ncheck that your Bayesian meta-learning\napproach didn't break",
    "start": "4307690",
    "end": "4313660"
  },
  {
    "text": "the meta-learning algorithm\nthat you had before.  But they aren't really the\nbest metric of how good",
    "start": "4313660",
    "end": "4321430"
  },
  {
    "text": "your Bayesian\nmeta-learning algorithm is. First, metrics\nlike accuracy won't evaluate whether your\nuncertainty estimates",
    "start": "4321430",
    "end": "4328270"
  },
  {
    "text": "are calibrated. And second, the tasks\nmay not actually exhibit that much ambiguity.",
    "start": "4328270",
    "end": "4334610"
  },
  {
    "text": "And so, it may not\nstress test your ability to actually model distributions\nover task parameters.",
    "start": "4334610",
    "end": "4343802"
  },
  {
    "text": "And then, lastly, it may also\nbe the uncertainty just isn't useful on those data sets. And it's good to\nactually evaluate",
    "start": "4343802",
    "end": "4350940"
  },
  {
    "text": "algorithms and\nsettings where they might be practically useful. ",
    "start": "4350940",
    "end": "4356502"
  },
  {
    "text": "So what about better\nproblems in metrics? So it really depends on\nwhat you might care about. So one thing that you\ncould look at that is--",
    "start": "4356502",
    "end": "4364012"
  },
  {
    "text": "that I think is kind of nice\nbecause you can actually just visualize the\nfunctions that it's learning is to look at some ambiguous\nproblems in one or two",
    "start": "4364012",
    "end": "4373660"
  },
  {
    "text": "dimensions and, actually,\nvisualize the functions that it gives you. So this is a few-shot\nregression problem",
    "start": "4373660",
    "end": "4379480"
  },
  {
    "text": "where the purple triangles\ncorrespond to the support examples. And the tasks correspond\nto either sinusoids",
    "start": "4379480",
    "end": "4388420"
  },
  {
    "text": "or linear functions. And some of the tasks,\nthere's very little ambiguity. And other tasks, there's\nactually a lot more ambiguity.",
    "start": "4388420",
    "end": "4395150"
  },
  {
    "text": "So the middle\nfunction, for example, is something where\nit could actually correspond to either a linear\nfunction or a sinusoid.",
    "start": "4395150",
    "end": "4402250"
  },
  {
    "text": "And you see that the process\nthat samples these functions will actually give you--",
    "start": "4402250",
    "end": "4408340"
  },
  {
    "text": "sometimes, give you\nlinear functions and, sometimes, give you\nsinusoidal functions.",
    "start": "4408340",
    "end": "4413790"
  },
  {
    "text": "You could also formulate an\nambiguous classification task. This is a setting where\nall the tasks corresponded",
    "start": "4413790",
    "end": "4419400"
  },
  {
    "text": "to these circular\ndecision boundaries. And the algorithm is\nactually only given one example in the support\nset, just one positive example",
    "start": "4419400",
    "end": "4427320"
  },
  {
    "text": "that's indicated by\nthe green plus sign. And that green plus\nsign may be anywhere",
    "start": "4427320",
    "end": "4433650"
  },
  {
    "text": "within the decision boundary. And you see that these dashed\nlines are showing the decision",
    "start": "4433650",
    "end": "4438870"
  },
  {
    "text": "boundaries corresponding\nto the functions phi, i that you're sampling. And you can see\nvisually that it's",
    "start": "4438870",
    "end": "4445110"
  },
  {
    "text": "giving you a fairly diverse\nsample of these functions. So this is one toy visualization\nthat gives you a lot of--",
    "start": "4445110",
    "end": "4454580"
  },
  {
    "text": "gives you the ability to\ninterpret what's going on. But it's also very toy.",
    "start": "4454580",
    "end": "4460410"
  },
  {
    "text": "Another thing that you could\nlook at is trying to generate-- trying to look at\nambiguous generation tasks.",
    "start": "4460410",
    "end": "4466000"
  },
  {
    "text": "So this is something\nwhere the goal is to learn a generative model\nover different viewpoints",
    "start": "4466000",
    "end": "4471480"
  },
  {
    "text": "of an object. And it's given\nonly one viewpoint in the support set, which\nis shown on the left.",
    "start": "4471480",
    "end": "4478050"
  },
  {
    "text": "And the goal is to generate\nlots of other viewpoints, which is shown in the\nmiddle of the slide. ",
    "start": "4478050",
    "end": "4485710"
  },
  {
    "text": "And here, you can actually\njust look at the samples in comparison to a C-VAE. This Bayesian\nmeta-learning algorithm",
    "start": "4485710",
    "end": "4492127"
  },
  {
    "text": "called VERSA, which is a lot\nlike the black box approach that we talked about is much\nbetter able to kind of generate",
    "start": "4492127",
    "end": "4498930"
  },
  {
    "text": "samples from the distributions. And it also gives you a lower\nmean squared error and a lower",
    "start": "4498930",
    "end": "4507330"
  },
  {
    "text": "SSIM, which is another measure\nof reconstruction error-- or sorry, actually, a\nhigher SSIM, which is-- you",
    "start": "4507330",
    "end": "4514280"
  },
  {
    "text": "want to be higher\non SSIM metrics. ",
    "start": "4514280",
    "end": "4519869"
  },
  {
    "text": "A third thing that\nyou could look at is looking at both accuracy\nas well as mode coverage",
    "start": "4519870",
    "end": "4525300"
  },
  {
    "text": "and likelihood. And so, you can take\nthis celebA task that we saw earlier\nwhere they're",
    "start": "4525300",
    "end": "4532510"
  },
  {
    "text": "kind of purposely ambiguous. Some tasks-- basically,\nkind of the support set",
    "start": "4532510",
    "end": "4538349"
  },
  {
    "text": "is not enough\ninformation to figure out what the positive examples and\nnegative examples should be.",
    "start": "4538350",
    "end": "4543790"
  },
  {
    "text": "And there's a number\nof metrics that you can look at in combination. One is just accuracy on\nclassifying new examples.",
    "start": "4543790",
    "end": "4552300"
  },
  {
    "text": "But you can also look at-- you can also measure-- there's three possible\nclassifiers for it",
    "start": "4552300",
    "end": "4557820"
  },
  {
    "text": "to consider that are, in\nthis case, visualized in B.",
    "start": "4557820",
    "end": "4563429"
  },
  {
    "text": "And you can try to see,\nis it learning all three of those classifiers? And we see, in\nthis example, the--",
    "start": "4563430",
    "end": "4573960"
  },
  {
    "text": "everything with the\npink box is showing things that were classified\nas positive by the classifier.",
    "start": "4573960",
    "end": "4580230"
  },
  {
    "text": "And you can see that\nit does actually give you three classifiers that,\nmore or less, in this case, cover the three ground\ntruth classifiers underlying",
    "start": "4580230",
    "end": "4588929"
  },
  {
    "text": "that data. And then you could also\nlook at average negative log likelihood. Yeah?",
    "start": "4588930",
    "end": "4593940"
  },
  {
    "text": "[INAUDIBLE] generation\ntask, there's maybe more than one\ndimension of uncertainty.",
    "start": "4593940",
    "end": "4601297"
  },
  {
    "text": "There are lots of ways that\nyou could be uncertain about whether your image is right. And are there\ninteresting trade offs",
    "start": "4601297",
    "end": "4607260"
  },
  {
    "text": "there, like, do these\nmodels have different-- are they uncertain in\ndifferent ways, basically?",
    "start": "4607260",
    "end": "4613739"
  },
  {
    "text": "So the question was the-- there's multiple\npossible dimensions of ambiguity in tasks like this.",
    "start": "4613740",
    "end": "4619949"
  },
  {
    "text": "And are there different trade\noffs that models can make? ",
    "start": "4619950",
    "end": "4627111"
  },
  {
    "text": "I guess, I do think that\ndifferent algorithms will have different properties.",
    "start": "4627111",
    "end": "4633620"
  },
  {
    "text": " I certainly think\nthat there are-- things like VERSA are strictly\nbetter than C-VAE in this case.",
    "start": "4633620",
    "end": "4642469"
  },
  {
    "text": "I haven't-- I don't know of any\nexamples off the top of my head of interesting trade\noffs between algorithms. But I can think\nabout it and-- yeah.",
    "start": "4642470",
    "end": "4650595"
  },
  {
    "text": "Just can you summarize\nwith a number if you collapse all\nof it into one thing?",
    "start": "4650595",
    "end": "4656460"
  },
  {
    "text": "But if-- Yeah, absolutely, and one of\nthe things that I actually wanted to provide\nin these slides is that, sometimes,\nthe numbers, they",
    "start": "4656460",
    "end": "4662094"
  },
  {
    "text": "don't actually\ntell you that much about what's actually going on. And so, actually, making\nthese kinds of visualizations,",
    "start": "4662095",
    "end": "4667730"
  },
  {
    "text": "I think, is really helpful\nfor understanding what's beyond the number, basically.",
    "start": "4667730",
    "end": "4674200"
  },
  {
    "text": "And I guess, it's also,\nI think, useful to be kind of creative\nabout the numbers that you measure because,\nwhen you do look at the data,",
    "start": "4674200",
    "end": "4682720"
  },
  {
    "text": "and kind of notice\ndifferent things, you can try to actually come\nup with metrics like coverage. What are the kind of number\nof classifiers that you're",
    "start": "4682720",
    "end": "4688928"
  },
  {
    "text": "representing that do actually\ncapture the kinds of things that you might want to see? And, I guess, in\nthis example, it",
    "start": "4688928",
    "end": "4698400"
  },
  {
    "text": "is actually possible to\nget kind of classifiers that have very low\ncoverage but pretty high accuracy and,\nlikewise, things that",
    "start": "4698400",
    "end": "4705300"
  },
  {
    "text": "have really good coverage\nbut slightly lower accuracy. And that is one\nexample of a trade off that you can make,\ndepending on the hyperparameters",
    "start": "4705300",
    "end": "4712349"
  },
  {
    "text": "of the algorithm. Cool, and in the last--\nor no, second to last one",
    "start": "4712350",
    "end": "4717697"
  },
  {
    "text": "is reliability diagrams,\nwhich we actually already talked about. And then the last\nthing you can look at is active learning\nsettings, which is,",
    "start": "4717697",
    "end": "4724520"
  },
  {
    "text": "if you give it-- if you\nallow it to actively query a few additional data points,\nhow much does the accuracy drop?",
    "start": "4724520",
    "end": "4729620"
  },
  {
    "text": "Or sorry, how much\ndoes the error drop? And how much does the\naccuracy increase? And you can see that Bayesian\nmeta-learning algorithms,",
    "start": "4729620",
    "end": "4739070"
  },
  {
    "text": "like some of the ones\nthat we saw today are able to drop the\nerror rate and increase",
    "start": "4739070",
    "end": "4744139"
  },
  {
    "text": "the accuracy faster than an\nalgorithm that chooses data",
    "start": "4744140",
    "end": "4749600"
  },
  {
    "text": "points at random or an\nalgorithm that doesn't have good estimates of uncertainty. ",
    "start": "4749600",
    "end": "4756369"
  },
  {
    "text": "Cool, so yeah,\nthat's it for today. We talked about Bayesian\nmeta-learning algorithms",
    "start": "4756370",
    "end": "4761650"
  },
  {
    "text": "and kind of techniques for\nrepresenting uncertainty over parameters. Next week, we're going to\ntalk about domain adaptation",
    "start": "4761650",
    "end": "4768922"
  },
  {
    "text": "and domain\ngeneralization, which is a pretty cool special\ncase of the multitask and meta-learning\nproblem setting.",
    "start": "4768922",
    "end": "4775510"
  },
  {
    "text": "The following week, we'll\nhave our last kind of I don't know-- main\ntechnical lecture, I guess,",
    "start": "4775510",
    "end": "4780760"
  },
  {
    "text": "on lifelong learning. And then we'll start to\nhave two guest lectures and a final lecture on open\nproblems and future directions.",
    "start": "4780760",
    "end": "4790090"
  },
  {
    "text": "Before that last week, we're\ngoing to have Thanksgiving. So we can eat some turkey. And yeah, as a\nreminder, homework three",
    "start": "4790090",
    "end": "4797860"
  },
  {
    "text": "is due on Friday. ",
    "start": "4797860",
    "end": "4804000"
  }
]
[
  {
    "start": "0",
    "end": "5350"
  },
  {
    "text": "So what we'll do today is finish\nup the discussion of barrier",
    "start": "5350",
    "end": "12309"
  },
  {
    "text": "methods, maybe start on these L1\nconvex cardinality type thing. So let's take a look at that.",
    "start": "12310",
    "end": "18080"
  },
  {
    "text": "So just to remind\nyou what it was, we are going to look at\nusing a barrier method.",
    "start": "18080",
    "end": "26619"
  },
  {
    "text": "Barrier methods are a\npretty simple thing. Let me go find it. There we go.",
    "start": "26620",
    "end": "31730"
  },
  {
    "text": "So it simply says we find a\npoint on the central path.",
    "start": "31730",
    "end": "37510"
  },
  {
    "text": "You use Newton's\nmethod to do that. Then you increment this\nbarrier parameter T",
    "start": "37510",
    "end": "43420"
  },
  {
    "text": "that controls the gap. And you compute the new point. And you keep doing this. And at some point,\nactually, every time",
    "start": "43420",
    "end": "50890"
  },
  {
    "text": "you center, you end up with\ntwo things, strictly feasible",
    "start": "50890",
    "end": "56140"
  },
  {
    "text": "primal point-- that's x. You also end up with\nstrictly feasible dual point.",
    "start": "56140",
    "end": "61960"
  },
  {
    "text": "And you have a gap, that means. And the gap is\nprecisely m over t. t is that parameter\nthat controls",
    "start": "61960",
    "end": "68210"
  },
  {
    "text": "the level of approximation. So basically, you\nkeep increasing t",
    "start": "68210",
    "end": "73729"
  },
  {
    "text": "until m over t,\nwhich is the gap, is less than whatever\nyour threshold-- whatever",
    "start": "73730",
    "end": "79490"
  },
  {
    "text": "your desired threshold is. So that's the method. I think we talked\nabout that last time. This is a homotopy method.",
    "start": "79490",
    "end": "85580"
  },
  {
    "text": "It's kind of a special one\nbecause general homotopy methods are much more complex\nbecause paths can just stop",
    "start": "85580",
    "end": "92720"
  },
  {
    "text": "or they can bifurcate,\nor they can just start in the middle of nowhere. Here, that's false. And no matter where\nyou are, you can always",
    "start": "92720",
    "end": "100310"
  },
  {
    "text": "get back to the central path. It may cost you a\nbunch of Newton steps, but you can always do it. OK, that's the barrier method.",
    "start": "100310",
    "end": "107729"
  },
  {
    "text": "And what we're going\nto do now is look at-- we're going to look at the\ncomplexity analysis of it.",
    "start": "107730",
    "end": "113869"
  },
  {
    "text": "I think I mentioned\nlast time that according to the classical\nanalysis, the upper bound",
    "start": "113870",
    "end": "120409"
  },
  {
    "text": "on the number of Newton\nsteps grows as the barrier method-- as t increases.",
    "start": "120410",
    "end": "125810"
  },
  {
    "text": "And so if you believed that\nupper bound had any meaning, you might actually shy away\nfrom even attempting this",
    "start": "125810",
    "end": "133250"
  },
  {
    "text": "because you'd say,\nwell, sure, as t gets bigger and\nbigger, the problems we solve by Newton's method\nget harder and harder,",
    "start": "133250",
    "end": "139590"
  },
  {
    "text": "it takes more and more\niterations, and so on and so forth. And then you get into\nsome kind of doom spiral",
    "start": "139590",
    "end": "145520"
  },
  {
    "text": "there or whatever. This actually kind of\nhappened in the '60s, weirdly. I don't know why.",
    "start": "145520",
    "end": "153079"
  },
  {
    "text": "So it turns out that's not true. You could have guessed\nthat because you've already seen empirical results for how\nwell the barrier method works,",
    "start": "153080",
    "end": "159379"
  },
  {
    "text": "which is, by the way,\njust unbelievably well. So basically-- and it's got\na very weird interpretation.",
    "start": "159380",
    "end": "165350"
  },
  {
    "text": "The one interpretation\nof its working so well is that it\ntakes between 20-- you solve between 20 and\n50 least squares problems",
    "start": "165350",
    "end": "173959"
  },
  {
    "text": "to solve a convex\noptimization problem with inequality constraints,\nall that kind of stuff.",
    "start": "173960",
    "end": "180050"
  },
  {
    "text": "It's crazy. Why do I say you\nsolve least squares problems is because you do\nbetween 20 and 50 Newtons",
    "start": "180050",
    "end": "186950"
  },
  {
    "text": "steps total. But a Newton step is actually\nsolving a set of kkt--",
    "start": "186950",
    "end": "193775"
  },
  {
    "text": "a set of linear kkt\nsystems, which is precisely solving a least squares--\nit's exactly the same",
    "start": "193775",
    "end": "198830"
  },
  {
    "text": "as solving a least\nsquares problem with equality constraints. So it's actually kind of cool.",
    "start": "198830",
    "end": "204890"
  },
  {
    "text": "So you can-- says basically you\ncan solve any convex problem",
    "start": "204890",
    "end": "211700"
  },
  {
    "text": "by solving between 20 and 50\nleast squares problems that have the same\nstructure and so on.",
    "start": "211700",
    "end": "217790"
  },
  {
    "text": "So that's actually kind of-- I mean, I find that\nkind of interesting. And by the way, also-- well, let's see.",
    "start": "217790",
    "end": "224970"
  },
  {
    "text": "If people had been\nawake in the '60s, people would have noticed this.",
    "start": "224970",
    "end": "230550"
  },
  {
    "text": "So this wasn't mainstream until\nthe '90s or something like. But before then, this would\nhave been just completely",
    "start": "230550",
    "end": "237090"
  },
  {
    "text": "radical and unheard of. OK, that's the background. Now what we're\ngoing to do is let's see if we can get the theory\nto catch up with the practice.",
    "start": "237090",
    "end": "244318"
  },
  {
    "text": " And that comes via\nself-concordance analysis.",
    "start": "244318",
    "end": "250230"
  },
  {
    "text": "So what we're going\nto do is we're going to simply assume\nthat the problems-- that the centering problem, the\nobjective, is self-concordant.",
    "start": "250230",
    "end": "257607"
  },
  {
    "text": "And that's true for,\nactually, a whole bunch of the things that we actually\ncare about, like logs.",
    "start": "257607",
    "end": "262950"
  },
  {
    "text": "And then this is the entire--\nthis is basically all of it. This is also the densest chain\nof inequalities, I think,",
    "start": "262950",
    "end": "270030"
  },
  {
    "text": "that have appeared in lecture\nslides that I'm aware of. I couldn't follow it,\nso I had to work it",
    "start": "270030",
    "end": "275100"
  },
  {
    "text": "out myself this morning. So we will go through\nthis together now a bit. I mean, eventually\nI followed it.",
    "start": "275100",
    "end": "283990"
  },
  {
    "text": "So let's remember\nwhat we're doing. We're on the central\npath at a point-- I'll draw a central path.",
    "start": "283990",
    "end": "290210"
  },
  {
    "text": "So here's the central path. Here's the optimal point. Here we are.",
    "start": "290210",
    "end": "295990"
  },
  {
    "text": "So we're at x of t.",
    "start": "295990",
    "end": "301300"
  },
  {
    "text": "And then we're going\nto increase t by mu. We're going to have\nt times equals mu. And this is going\nto be x of mu t.",
    "start": "301300",
    "end": "308620"
  },
  {
    "text": "And we're going to call\nthis guy x plus, like that. So we're going to do a step\nof the barrier method, which",
    "start": "308620",
    "end": "316540"
  },
  {
    "text": "is to use Newton's method\nto go from here to here. So that's what we're\ngoing to analyze.",
    "start": "316540",
    "end": "324009"
  },
  {
    "text": "What we're going to\ntry to do is bound the number of steps\nit takes to do that-- number of Newton steps.",
    "start": "324010",
    "end": "331270"
  },
  {
    "text": "OK, so we go back to self\nconcordance analysis, and we ask, well,\nhow many Newton steps",
    "start": "331270",
    "end": "338710"
  },
  {
    "text": "does it take to compute this\nthing starting from here?",
    "start": "338710",
    "end": "343840"
  },
  {
    "text": "And the answer is you look at\nthe function you're minimizing, which is-- it's this.",
    "start": "343840",
    "end": "349090"
  },
  {
    "text": "It's mu t. So we start when\nyou-- let's see. Let me write down what this is.",
    "start": "349090",
    "end": "355120"
  },
  {
    "text": "So x plus is the\nargmin, right, of t mu,",
    "start": "355120",
    "end": "363460"
  },
  {
    "text": "or I'll write it as mu t, f0 of\nx plus sum and this is over i",
    "start": "363460",
    "end": "372250"
  },
  {
    "text": "of this is the barriers, right?",
    "start": "372250",
    "end": "377960"
  },
  {
    "text": "Right.  And then plus the\nindicator function.",
    "start": "377960",
    "end": "384760"
  },
  {
    "text": "I guess we write\nit as Ax equals b. Looks like that. OK? So you're basically minimizing\nthis function subject",
    "start": "384760",
    "end": "394240"
  },
  {
    "text": "to these equality\nconstraints, right? So that's literally\nthe definition of what x plus is, right?",
    "start": "394240",
    "end": "399580"
  },
  {
    "text": "If I remove this, this\nis the definition of x. And, in fact, that's\nthe point, right?",
    "start": "399580",
    "end": "404900"
  },
  {
    "text": "The whole point is we\njust computed this. Now we increase\nt and so the idea",
    "start": "404900",
    "end": "410780"
  },
  {
    "text": "is this problem is very--\nshould be relatively close to the\nprevious one and that hopefully will save\nus some Newton steps",
    "start": "410780",
    "end": "416750"
  },
  {
    "text": "or something like that. That's the hope here. So this is the minimizer. OK. So the general\nself-concordance theory",
    "start": "416750",
    "end": "423890"
  },
  {
    "text": "says that the number of steps,\nthe number of Newton steps, is less than or equal\nto the function value",
    "start": "423890",
    "end": "430760"
  },
  {
    "text": "where you start minus the\nfunction value where you end, which is its optimal value, and\nthen multiplied by a constant.",
    "start": "430760",
    "end": "437240"
  },
  {
    "text": "And you could either\nuse our lazy constant is like you divide by 365\nor something like that. Or maybe you multiply by 360--",
    "start": "437240",
    "end": "443720"
  },
  {
    "text": "I think you multiply by 365. And then you add something\nthat looks like log, log, 1 over epsilon, which we just\ncall 5 or 6 and that's fine.",
    "start": "443720",
    "end": "451460"
  },
  {
    "text": "Everybody got that? So that's the c\nover there, right? So this is the function value\nat x of t, which we're just",
    "start": "451460",
    "end": "462620"
  },
  {
    "text": "going to call x over here. That's this guy here. And then this is going to be the\nfunction value when you finish.",
    "start": "462620",
    "end": "470930"
  },
  {
    "text": "Because x plus minimizes this\nthing subject to the equality",
    "start": "470930",
    "end": "476180"
  },
  {
    "text": "constraints, right? So that's what that is. OK. So that's the number\nof Newton iterations.",
    "start": "476180",
    "end": "481700"
  },
  {
    "text": "And our job is to get an upper\nbound on this big thing here.",
    "start": "481700",
    "end": "486740"
  },
  {
    "text": "Forget the c for\nthe moment and let's just take a look at this thing. And now we go very\nslowly or I'll",
    "start": "486740",
    "end": "494870"
  },
  {
    "text": "expand various things, right? So the first question\nis how on Earth",
    "start": "494870",
    "end": "500240"
  },
  {
    "text": "do you get-- how do you go\nfrom this line to this line? And that's an\nequality constraint. And so I think that\nis written here.",
    "start": "500240",
    "end": "508850"
  },
  {
    "text": "We use the fact that phi\nof x minus phi of x plus. So phi of x is the sum of the--",
    "start": "508850",
    "end": "516229"
  },
  {
    "text": "it's minus the sum of the\nlog of minus fi of x, right?",
    "start": "516230",
    "end": "521539"
  },
  {
    "text": "This is the same thing\nevaluated at x plus. So this difference\nlooks like that.",
    "start": "521540",
    "end": "527360"
  },
  {
    "text": "It doesn't look like it. It's equal to it, right? So this is the\ndifference, right?",
    "start": "527360",
    "end": "532520"
  },
  {
    "text": "It's this rate. The log of this ratio. I'll leave the minus\nsigns there just-- I don't know-- of course,\nyou could get rid of them.",
    "start": "532520",
    "end": "538850"
  },
  {
    "text": "They're both negative. Both fi of x and fi of\nx plus because they're both strictly feasible.",
    "start": "538850",
    "end": "544070"
  },
  {
    "text": "OK. Now, now we're going\nto use the following. Lambda i, these are\nthe dual variables",
    "start": "544070",
    "end": "551990"
  },
  {
    "text": "associated-- the inequality\nconstraints associated with computing a point\non the central path. That's equal to this.",
    "start": "551990",
    "end": "558140"
  },
  {
    "text": "And you realize that, hey,\nthis looks like that, right? So it says minus 1 over fi\nor 1 over minus fi of x--",
    "start": "558140",
    "end": "565355"
  },
  {
    "text": "that's the denominator here-- is equal to t lambda i. So I plug t lambda i in instead\nof that and I get this, OK?",
    "start": "565355",
    "end": "573649"
  },
  {
    "text": "So that I think-- that makes sense.",
    "start": "573650",
    "end": "579290"
  },
  {
    "text": "OK. And I do that. And then what I'm going\nto do very weirdly is I'm going to\ndo the following.",
    "start": "579290",
    "end": "586290"
  },
  {
    "text": "If you don't mind, I'm going\nto put a mu here and then go minus--",
    "start": "586290",
    "end": "591560"
  },
  {
    "text": "let's see, minus-- I'm going to put-- I'm going to put a mu in there. And then I'm going to\nsay maybe plus log mu.",
    "start": "591560",
    "end": "598430"
  },
  {
    "text": "I think I got that right, right? Because here, I multiply\nthis thing by mu.",
    "start": "598430",
    "end": "605960"
  },
  {
    "text": "There's a minus sign and I\nthink I'd go plus log mu. I think that's right. Is that right or did I\ndo that the wrong way? I think I did it--",
    "start": "605960",
    "end": "611510"
  },
  {
    "text": "I did it the wrong way. Let me see. So it looked like that.",
    "start": "611510",
    "end": "617240"
  },
  {
    "text": "I'm going to\nmultiply this by mu. So I have to do this. There we go. And now that didn't change.",
    "start": "617240",
    "end": "624535"
  },
  {
    "text": "So this is going to be\nwhat you see over there. And this is a sum over i of log\nmu, but there's m in that sum.",
    "start": "624535",
    "end": "631620"
  },
  {
    "text": "So that's m log mu. So I think we got to--",
    "start": "631620",
    "end": "636950"
  },
  {
    "text": "we've verified this line here.  So OK.",
    "start": "636950",
    "end": "642279"
  },
  {
    "text": " Next up, we're going to go\nfrom this line to this line. A lot of the terms\nare the same, right?",
    "start": "642280",
    "end": "648900"
  },
  {
    "text": "These are the same. That's the same. And here, I'm only going to\nuse one inequality, which,",
    "start": "648900",
    "end": "656820"
  },
  {
    "text": "again, goes back to\nweek two of the class. Which is just-- I'm going to use\nJensen's inequality",
    "start": "656820",
    "end": "662220"
  },
  {
    "text": "that says that for any\npositive number log a is less than a minus 1, right?",
    "start": "662220",
    "end": "668009"
  },
  {
    "text": "By the way, all these weird\ninequalities that you know, now you'll probably\nremember that--",
    "start": "668010",
    "end": "673770"
  },
  {
    "text": "you'll probably recognize\nthat almost all of them follow directly-- they're\njust Jensen's inequality for something, right?",
    "start": "673770",
    "end": "679145"
  },
  {
    "text": "So this just says-- this just says look at the\nTaylor expansion of log a around a equals 1 and you\nget this inequality, OK?",
    "start": "679145",
    "end": "689310"
  },
  {
    "text": "So that means here, I\ncan take this thing.",
    "start": "689310",
    "end": "695265"
  },
  {
    "text": "If I replace-- if I remove\nthe log and subtract 1, I get a lower bound. So that's this next term here.",
    "start": "695265",
    "end": "700900"
  },
  {
    "text": "So I get this. I get here. I get minus 1. I sum over m of them\nso I get minus m",
    "start": "700900",
    "end": "706390"
  },
  {
    "text": "and I get this thing because\nthat's just that down here. And I pulled out the mu and\nthe t that don't depend on i.",
    "start": "706390",
    "end": "711850"
  },
  {
    "text": "So OK. Now the next one is this.",
    "start": "711850",
    "end": "719596"
  },
  {
    "text": "The next trick is to recognize\na couple of things here. OK, here it is.",
    "start": "719596",
    "end": "725334"
  },
  {
    "text": "We recognize mu t. Forget the mu t on\nthese two terms. This is f0 of x plus and this\nis some lambda i, fi of x plus.",
    "start": "725335",
    "end": "736990"
  },
  {
    "text": "But that basically\nis nothing but-- that is exactly the Lagrangian--\nlet me write that out.",
    "start": "736990",
    "end": "744730"
  },
  {
    "text": "That's actually\nthe Lagrangian at-- let's see that's lambda\nnu and x plus, right?",
    "start": "744730",
    "end": "753290"
  },
  {
    "text": "That's what that is, right? Because that's the-- Oh,\nthere's one more term.",
    "start": "753290",
    "end": "759430"
  },
  {
    "text": "The other term would be to\nhave a nu transpose Ax minus b, but x is feasible. So Ax is equal b and that other\nterm, it doesn't appear there.",
    "start": "759430",
    "end": "767740"
  },
  {
    "text": "So l of lambda nu x plus is\nprecisely f0 plus sum lambda i,",
    "start": "767740",
    "end": "776180"
  },
  {
    "text": "fi, OK? But we know the following.",
    "start": "776180",
    "end": "781400"
  },
  {
    "text": "This thing is for\nsure bigger than or equal to g of lambda nu.",
    "start": "781400",
    "end": "787190"
  },
  {
    "text": "Because the dual\nfunction is what minimizes this over all x's and\nthis is just a particular x.",
    "start": "787190",
    "end": "795279"
  },
  {
    "text": "So this is for sure true. So then what we do, we go\nback over here in the world's",
    "start": "795280",
    "end": "801740"
  },
  {
    "text": "densest one slide derivation. And we replace the f0\nof x plus some lambda i,",
    "start": "801740",
    "end": "808250"
  },
  {
    "text": "fi with a lower bound,\nwhich is the g, OK? And that goes to right-- I think that goes the right way.",
    "start": "808250",
    "end": "814550"
  },
  {
    "text": "It does go the right way, right? OK. Now we look at this thing.",
    "start": "814550",
    "end": "822290"
  },
  {
    "text": "And we say, well, wait a minute. f0 of x minus g of lambda nu\nis the gap at x lambda nu.",
    "start": "822290",
    "end": "832250"
  },
  {
    "text": "But that's precisely m over t. That's the calculation\nwe did before, right?",
    "start": "832250",
    "end": "837965"
  },
  {
    "text": "So this minus g,\nthat's m over t. So I have mu t times m over t\nand I end up with just this.",
    "start": "837965",
    "end": "845880"
  },
  {
    "text": "So I think that was coherent. So OK.",
    "start": "845880",
    "end": "853220"
  },
  {
    "text": "Yeah? Isn't that the i is associated\nwith x instead of x plus? Which one?",
    "start": "853220",
    "end": "859100"
  },
  {
    "text": "Lambda i. Is that, define lambda i-- No, no. The lambda i's are-- the lambda i's are\nwith respect to x here.",
    "start": "859100",
    "end": "865759"
  },
  {
    "text": "Yeah, not x plus. But Langrangian tell you--",
    "start": "865760",
    "end": "874000"
  },
  {
    "text": "equate to g is, in terms\nof x plus, [INAUDIBLE].. No. No, no.",
    "start": "874000",
    "end": "879130"
  },
  {
    "text": "Certainly not. It is up here. This is where-- To get this, I replace the x\nplus with x in the Lagrangian.",
    "start": "879130",
    "end": "886330"
  },
  {
    "text": "So no. This is right. Yeah?",
    "start": "886330",
    "end": "891690"
  },
  {
    "text": "OK. All right. So what does mu minus 1\nminus log mu look like?",
    "start": "891690",
    "end": "897340"
  },
  {
    "text": "So let me draw that. So that's going to look\nsomething like this, right?",
    "start": "897340",
    "end": "904160"
  },
  {
    "text": "So it's mu minus 1 minus log mu.",
    "start": "904160",
    "end": "909959"
  },
  {
    "text": "Now mu is bigger than 1, right? Because mu is the amount\nby which we crank up",
    "start": "909960",
    "end": "915320"
  },
  {
    "text": "t at each step of\nthe barrier method. So this is 1. This thing is 0 here.",
    "start": "915320",
    "end": "920779"
  },
  {
    "text": "Also, its derivative is 0\nhere and its second derivative is 1, right? So this looks like at least\nlocally something like that.",
    "start": "920780",
    "end": "930060"
  },
  {
    "text": "A square. That's what that looks like. And what this says-- I mean, you end up with\na stunning answer, right?",
    "start": "930060",
    "end": "936180"
  },
  {
    "text": "It basically says\nif I divide that, this multiplied by a\nnumber and then you",
    "start": "936180",
    "end": "941340"
  },
  {
    "text": "add 6, that's an upper bound\non the number of Newton steps it takes you to compute the x\nof mu t starting from x of t.",
    "start": "941340",
    "end": "953550"
  },
  {
    "text": "These are two points on\nthe central path, right? And that's the bound. And it's actually cool. What it does is it does say that\nas mu gets bigger and bigger,",
    "start": "953550",
    "end": "962670"
  },
  {
    "text": "the bound goes up. But it does say that if you\ntake like really small steps, it's not going to\ntake much at all.",
    "start": "962670",
    "end": "969030"
  },
  {
    "text": "Actually, at that\npoint, the 5 or the 6, which is our way to say\nlog, log, 1 over epsilon, is going to dominate, right?",
    "start": "969030",
    "end": "975510"
  },
  {
    "text": "So OK. OK. Now you simply assemble things.",
    "start": "975510",
    "end": "982130"
  },
  {
    "text": "You say, well, the number of\nNewton's steps, remember, is-- this is exactly the\nnumber of outer steps",
    "start": "982130",
    "end": "988430"
  },
  {
    "text": "you'll take because you'll\nstart with an initial gap. This is basically\nthe initial gap. And then divided by log mu.",
    "start": "988430",
    "end": "995540"
  },
  {
    "text": "So if mu is really small, you'll\ntake a whole bunch of steps. But you'll make\nsmall-- you'll make a progress, which is\nexactly a factor of mu,",
    "start": "995540",
    "end": "1001813"
  },
  {
    "text": "and duality gap each step. And then this is the\nnumber of-- that's",
    "start": "1001813",
    "end": "1007070"
  },
  {
    "text": "our bound on the number\nof-- the upper bound on the number of Newton\nsteps to compute x at mu",
    "start": "1007070",
    "end": "1014009"
  },
  {
    "text": "t given you've just\ncomputed it at xt, right? And so now when you multiply\nthese two things together,",
    "start": "1014010",
    "end": "1020764"
  },
  {
    "text": "you get something\nthat looks like this. It's actually really cool. And here, I'm using our\nlazy numbers, right?",
    "start": "1020765",
    "end": "1026939"
  },
  {
    "text": "Our lazy numbers in the bound,\nI forget what they were. I think it's 365 times the\ndifference in objective value",
    "start": "1026940",
    "end": "1034020"
  },
  {
    "text": "plus 6 or something. And you get something that\nlooks like this, right? And this is very, very cool.",
    "start": "1034020",
    "end": "1040050"
  },
  {
    "text": "What it does is it says there\nis indeed a trade off of mu. If you take mu too small,\nthen you're going to be--",
    "start": "1040050",
    "end": "1046380"
  },
  {
    "text": "this term is going to\ngive you a lot of-- you're going to have\nto-- you're going to have to do many, many\nouter iterations, right?",
    "start": "1046380",
    "end": "1053370"
  },
  {
    "text": "If you take mu too\nbig, it says this term is going to start dominating\nand it'll look like that.",
    "start": "1053370",
    "end": "1058919"
  },
  {
    "text": "And this says that somewhere,\nfor this particular problem with 100 inequalities and a\nduality gap reduction of 10",
    "start": "1058920",
    "end": "1066090"
  },
  {
    "text": "to the 5, it says that the\noptimal mu is around 1.03 or something, right?",
    "start": "1066090",
    "end": "1072580"
  },
  {
    "text": "Actually, I'm pretty sure this\nis using our lazy bound which has got 365. A more careful Russian\nbound, you know,",
    "start": "1072580",
    "end": "1079900"
  },
  {
    "text": "where you go through\nlots of pages of analysis makes that number\ncloser to 11 or 12. So it's about 30.",
    "start": "1079900",
    "end": "1084970"
  },
  {
    "text": "And then I think actually\nyou get something, you know. It's actually\ninstead of 1.02, it's",
    "start": "1084970",
    "end": "1090820"
  },
  {
    "text": "something like 1.3, which\nis at least less ridiculous. But it doesn't matter. It looks the same, right?",
    "start": "1090820",
    "end": "1097260"
  },
  {
    "text": "Right. So oh, and also you can\nnotice the number of-- you can look at the theory\nhere and it will say--",
    "start": "1097260",
    "end": "1102500"
  },
  {
    "text": "it will say the good news\nis that the total number of iterations is\nless than 8,000.",
    "start": "1102500",
    "end": "1111110"
  },
  {
    "text": "There, there you go. OK. So But we all know that\nas an empirical fact.",
    "start": "1111110",
    "end": "1116700"
  },
  {
    "text": "It takes between 20\nand 80 steps always. There's never been any\nexperience otherwise.",
    "start": "1116700",
    "end": "1122060"
  },
  {
    "text": "Everybody got this? So I guess it's not so bad. If you take 8,000\nand divide it by 36, which is the ratio of the\nlazy bound to the other one,",
    "start": "1122060",
    "end": "1129649"
  },
  {
    "text": "you get something that's\nmuch more reasonable I think. But anyway, OK.",
    "start": "1129650",
    "end": "1136943"
  },
  {
    "text": "So that's pretty cool. So actually, I mean,\nthese two slides would have been completely\nradical in the year,",
    "start": "1136943",
    "end": "1142390"
  },
  {
    "text": "I don't know, 1990 or\nsomething like that. And in fact, something\nnot too dissimilar",
    "start": "1142390",
    "end": "1149650"
  },
  {
    "text": "ended up on the cover\nof The New York-- the front page of The New York\nTimes, which is another story,",
    "start": "1149650",
    "end": "1154840"
  },
  {
    "text": "but it's a weird one. OK. So OK.",
    "start": "1154840",
    "end": "1160250"
  },
  {
    "text": "Now if you want-- if you want\nto go all the way on this, what you do is you say, well, I\ncan take this function here,",
    "start": "1160250",
    "end": "1166360"
  },
  {
    "text": "which is my upper bound on the\ntotal number of Newton steps. And I can minimize it\nover mu, which you can do.",
    "start": "1166360",
    "end": "1171684"
  },
  {
    "text": "I mean, it's not\nthat hard to do. You don't do it exactly\nbecause all of this is sloppy. And it's all silly because\nthis is all upper bounds",
    "start": "1171685",
    "end": "1177020"
  },
  {
    "text": "and all that kind of stuff. But if you do, what\nyou'll find out is that you would\nlike to choose mu to be on the order\nsomething like that.",
    "start": "1177020",
    "end": "1184100"
  },
  {
    "text": "That's very close in order to\nwhat the minimizer would be. If you plug that back in,\nyou get something amazing.",
    "start": "1184100",
    "end": "1189500"
  },
  {
    "text": "It says that the\nnumber of steps is it's on the order of\nthe square root of m",
    "start": "1189500",
    "end": "1195140"
  },
  {
    "text": "and then there's a log m term. I ignore that. I guess if you're a complexity\ntheorist, you don't, right?",
    "start": "1195140",
    "end": "1201830"
  },
  {
    "text": "The log m. So it's square root m,\nlog m is the complexity. I think people just quote\nit as square root m, right?",
    "start": "1201830",
    "end": "1209840"
  },
  {
    "text": "So it's pretty good. So I mean, in fact, most\npeople would choose--",
    "start": "1209840",
    "end": "1216710"
  },
  {
    "text": "choose mu's that\nare much larger. And in fact, people refer to\nmethods that have small mu.",
    "start": "1216710",
    "end": "1224240"
  },
  {
    "text": "They refer to those\nas short step methods. And then ones where\nyou actually are",
    "start": "1224240",
    "end": "1229280"
  },
  {
    "text": "much more aggressive\nin adapting mu are called long step methods. You might see this if you start\nlooking at some of the papers",
    "start": "1229280",
    "end": "1236592"
  },
  {
    "text": "from the '90s and the '00s\nand all that kind of stuff. You would actually see\nthis in titles of papers",
    "start": "1236592",
    "end": "1242210"
  },
  {
    "text": "like a long step primal dual\nmethod, blah, blah, blah. Something like that. OK. ",
    "start": "1242210",
    "end": "1249520"
  },
  {
    "text": "So this is actually like-- I think it's pretty cool. I mean this is--",
    "start": "1249520",
    "end": "1255475"
  },
  {
    "text": "This is how the theory\nand the practice are approximately consistent.",
    "start": "1255475",
    "end": "1263005"
  },
  {
    "text": "But what I should tell you-- I mean, I'll\nexplain this later-- what I should tell you,\nthough, is that there's",
    "start": "1263005",
    "end": "1269800"
  },
  {
    "text": "been a leapfrog thing\nwhere people working on practical implementations\nof interior point methods",
    "start": "1269800",
    "end": "1276790"
  },
  {
    "text": "or barrier methods actually\nwill do something not justified by the theory.",
    "start": "1276790",
    "end": "1281880"
  },
  {
    "text": "And it will work better. And they will run it on test\nsuites of thousands of problems and blah, blah, blah,\nrelease something maybe",
    "start": "1281880",
    "end": "1287275"
  },
  {
    "text": "commercially or whatever. And what will happen then\ntypically is five years later, the theorists will catch up and\nshow that a very-- a simplified",
    "start": "1287275",
    "end": "1295150"
  },
  {
    "text": "variation of that\nmethod actually is like polynomial\ntime or something. And then, by then, the people\nactually working on the methods",
    "start": "1295150",
    "end": "1302650"
  },
  {
    "text": "will come up with\nsomething else, right? And extend it. So there are\nperiods every couple of years when the theory and\nthe practice are in sync,",
    "start": "1302650",
    "end": "1310420"
  },
  {
    "text": "but it doesn't last very\nlong as soon as that happens. So that's actually\nthe story, but OK.",
    "start": "1310420",
    "end": "1316120"
  },
  {
    "text": " Well, first of all, any\nquestions about this?",
    "start": "1316120",
    "end": "1323320"
  },
  {
    "text": "It's cool stuff. But if not, we'll move on.",
    "start": "1323320",
    "end": "1329605"
  },
  {
    "text": "You probably guessed that the\nway everything was set up, the same-- the\nexact same methods",
    "start": "1329605",
    "end": "1334900"
  },
  {
    "text": "are going to work for\ngeneralized inequalities, right? And so-- and you're right. And this is how you solve like\nSOCPs, semidefinite programs,",
    "start": "1334900",
    "end": "1342740"
  },
  {
    "text": "things like that, of\nwhich you've solved a whole bunch already so.",
    "start": "1342740",
    "end": "1349540"
  },
  {
    "text": "Sorry, you didn't. But CVXPY-- You typed in CVXPY,\nCVXPY compiled your problem",
    "start": "1349540",
    "end": "1355330"
  },
  {
    "text": "to some standard\nform and then called one of some number of solvers. So you have solved a bunch\nof SDPs in that spirit.",
    "start": "1355330",
    "end": "1365544"
  },
  {
    "text": "So OK. So here, what we're\ngoing to do is we're going to look at these--",
    "start": "1365545",
    "end": "1370840"
  },
  {
    "text": "we're going to have cone\nconstraints like this, right? So fi is a vector. And the most\ninteresting one is going",
    "start": "1370840",
    "end": "1378110"
  },
  {
    "text": "to be things like\nSOCP and SDPs, right? ",
    "start": "1378110",
    "end": "1385910"
  },
  {
    "text": "So if you think\nabout it, we have to just go back and\ngeneralize everything. Now before, we had fi of x.\nfi of x was a number, right?",
    "start": "1385910",
    "end": "1395299"
  },
  {
    "text": "Minus fi of x we\nthought as a margin. And minus log minus fi of x\nwas this barrier function.",
    "start": "1395300",
    "end": "1401480"
  },
  {
    "text": "It was convex. And as you got to the boundary,\nthe boundary being fi equals 0,",
    "start": "1401480",
    "end": "1406760"
  },
  {
    "text": "this thing would go\nto plus infinity. So that was our barrier. But now, I mean, let's\nsuppose I have some cone.",
    "start": "1406760",
    "end": "1413790"
  },
  {
    "text": "Let's imagine it's like\nthe semidefinite cone or something like that. You need to have\nsomething that's going",
    "start": "1413790",
    "end": "1419240"
  },
  {
    "text": "to be the same as a logarithm. So you need the idea of\na logarithm on a cone.",
    "start": "1419240",
    "end": "1425960"
  },
  {
    "text": "So what you do is\nyou generalize this to have-- you say that\na generalized logarithm,",
    "start": "1425960",
    "end": "1432560"
  },
  {
    "text": "it's a function that is--\nits domain is the interior. So that makes perfect sense.",
    "start": "1432560",
    "end": "1437940"
  },
  {
    "text": "It's concave. It's strictly concave. That's what this\nsecond term mean-- means.",
    "start": "1437940",
    "end": "1443160"
  },
  {
    "text": "And in fact, this is\nactually concave in the--",
    "start": "1443160",
    "end": "1448595"
  },
  {
    "text": "let's just say it's\nconcave, right? And then it has to actually\nagree with a logarithm",
    "start": "1448595",
    "end": "1454400"
  },
  {
    "text": "on any ray, right? And so it's going\nto look like this. If you multiply phi\nwith some scalar s here,",
    "start": "1454400",
    "end": "1461750"
  },
  {
    "text": "phi of sy, that's going\nto be 5y plus theta log s. So it has to look exactly\nlike a log on any ray.",
    "start": "1461750",
    "end": "1469639"
  },
  {
    "text": "OK. So you do get things like this. Oh, and this number,\ntheta, is called the degree",
    "start": "1469640",
    "end": "1476179"
  },
  {
    "text": "of that logarithm, right? So here, if you have\nthe nonnegative orthant, if you use this\nconstraint-- you just",
    "start": "1476180",
    "end": "1482690"
  },
  {
    "text": "end up with the same barrier\nwe had before, right, or this is the log of\nthe nonnegative orthant.",
    "start": "1482690",
    "end": "1491240"
  },
  {
    "text": "The log of a vector\nis this thing, right? Something like it's a\ngeneralized logarithm.",
    "start": "1491240",
    "end": "1496460"
  },
  {
    "text": "What's interesting is\nmuch more interesting is what happens on like\na semidefinite cone. There, surprise,\nsurprise, our friend",
    "start": "1496460",
    "end": "1503120"
  },
  {
    "text": "log determinant, which\ngoes back, whatever, to week two of the class.",
    "start": "1503120",
    "end": "1508650"
  },
  {
    "text": "Not surprisingly, that's\na generalized logarithm on the positive definite cone. OK.",
    "start": "1508650",
    "end": "1514120"
  },
  {
    "text": "So it's got a lot of the things\nyou would like on it, right? It's also correct, right? If you go an array of\nmatrices, we already saw that.",
    "start": "1514120",
    "end": "1520380"
  },
  {
    "text": "That's actually how\nwe proved concavity. Now this thing looks exactly\nlike a logarithm, right? So that's it.",
    "start": "1520380",
    "end": "1525570"
  },
  {
    "text": "And here the so-called\ndegree is n, right?",
    "start": "1525570",
    "end": "1531759"
  },
  {
    "text": "And for a second\norder cone, you get something that looks like this. This is not-- it's not totally\nobvious that that's concave,",
    "start": "1531760",
    "end": "1539789"
  },
  {
    "text": "but it is. Actually, I don't think\nit's that hard to show. The only one that would be\ntricky would be this part.",
    "start": "1539790",
    "end": "1546245"
  },
  {
    "text": "So OK. Sorry the others. All right. So there's a bunch\nof properties.",
    "start": "1546245",
    "end": "1551405"
  },
  {
    "text": "If you have a\ngeneralized logarithm, you can figure out\nwhat happens, right?",
    "start": "1551405",
    "end": "1556679"
  },
  {
    "text": "One is that the gradient is\nnonnegative in the dual cone.",
    "start": "1556680",
    "end": "1562770"
  },
  {
    "text": "If you have y transpose times\nthe gradient of the logarithm, you just get theta.",
    "start": "1562770",
    "end": "1568290"
  },
  {
    "text": "It's just a constant. And so for a\nnonnegative orthant, if you want to check that the\ngradient is going to be this,",
    "start": "1568290",
    "end": "1577470"
  },
  {
    "text": "I guess you've seen that, right? And then if you take y\ntranspose times this gradient,",
    "start": "1577470",
    "end": "1583350"
  },
  {
    "text": "you just get n. Because you just-- you take y\ntimes 1 over y and so on. y1 times 1 over y1 and so on. So you just get this.",
    "start": "1583350",
    "end": "1589379"
  },
  {
    "text": "OK. And for positive\nsemidefinite cone, it's actually super interesting. The gradient of\nthe log determinant",
    "start": "1589380",
    "end": "1595919"
  },
  {
    "text": "is the inverse matrix, right? You have to interpret\nthat super carefully, but that's what it is.",
    "start": "1595920",
    "end": "1601320"
  },
  {
    "text": "That's the inverse. And the inner product between\ntwo symmetric matrices is the trace of\nthe product, right?",
    "start": "1601320",
    "end": "1606660"
  },
  {
    "text": "Because that's actually\nthe inner product. It's the sum of the products\nof the corresponding entries, right?",
    "start": "1606660",
    "end": "1611950"
  },
  {
    "text": "And so that, of course, is\nn because trace of y times y inverse is the trace\nof i, which is n, OK?",
    "start": "1611950",
    "end": "1619130"
  },
  {
    "text": "So these things work. Second order cone, same story\nif you work out what this is.",
    "start": "1619130",
    "end": "1625340"
  },
  {
    "text": "OK. So all right. So that's your-- that's this\nproperty of the logarithmic--",
    "start": "1625340",
    "end": "1632200"
  },
  {
    "text": "of the generalized logarithm. Armed with that, we can actually\ndefine a logarithmic barrier.",
    "start": "1632200",
    "end": "1638390"
  },
  {
    "text": "So the log barrier\nis going to be this. I have a bunch of cone\ninequalities, but they are-- Sorry.",
    "start": "1638390",
    "end": "1643640"
  },
  {
    "text": "I have a bunch of\ninequalities, but they're respect to some cone here. Like here K1 and up\nto K sub m, right?",
    "start": "1643640",
    "end": "1650750"
  },
  {
    "text": "So we form this thing. That's going to be\nthe log barrier. And this is exactly\nlike in the case",
    "start": "1650750",
    "end": "1656480"
  },
  {
    "text": "when the inequalities\nwere scalars. It's identical, right? Or at least the form\nis identical, right?",
    "start": "1656480",
    "end": "1662792"
  },
  {
    "text": "It's a bit more\ncomplicated, right? These are vectors now.",
    "start": "1662792",
    "end": "1667845"
  },
  {
    "text": "And this thing is convex. It's twice continuously\ndifferentiable. And this allows us to\ntalk about a central path.",
    "start": "1667845",
    "end": "1673799"
  },
  {
    "text": "But now we can talk about\nthings like the central path for a semidefinite program or\na second-order cone program. And it's actually\nidentical, right?",
    "start": "1673800",
    "end": "1681990"
  },
  {
    "text": "x star of t is the\nminimum of this thing. And the only difference\nis we have changed-- we've generalized phi to\nhandle generalized inequalities",
    "start": "1681990",
    "end": "1691800"
  },
  {
    "text": "for the constraints. So the barrier has just changed. That's the only thing\nthat ever changed.",
    "start": "1691800",
    "end": "1697080"
  },
  {
    "text": "Makes sense? So OK. Everything else is\ngoing to work, right?",
    "start": "1697080",
    "end": "1703470"
  },
  {
    "text": "If you look at the\noptimal-- if you minimize that the function t times\nthe function plus a barrier,",
    "start": "1703470",
    "end": "1710684"
  },
  {
    "text": "then you will get this\nthing called x star of t. That's the central\npath-- that's a point on the central path associated\nwith the parameter value t.",
    "start": "1710685",
    "end": "1718215"
  },
  {
    "text": "And if you work out the\noptimality condition, it just looks like this. And when you work this\nout, it's identical.",
    "start": "1718215",
    "end": "1725190"
  },
  {
    "text": "It says that if this holds,\nthen it turns out x star of t also minimizes the Lagrangian\nwith this particular choice",
    "start": "1725190",
    "end": "1732550"
  },
  {
    "text": "of lambda i of t and nu of t. And if you look back at what\nit was for the scalar case,",
    "start": "1732550",
    "end": "1738190"
  },
  {
    "text": "it's just exactly the same. It's the same. OK.",
    "start": "1738190",
    "end": "1744764"
  },
  {
    "text": "And we know that this is\ngoing to be non-negative in the dual norm, right?",
    "start": "1744765",
    "end": "1750570"
  },
  {
    "text": "And then it turns out\nthe gap is the same. This used to be--\nif you can think about this for the\ntypes of things",
    "start": "1750570",
    "end": "1756210"
  },
  {
    "text": "if you had-- if the constraints\ndo not involve generalized or vector inequalities,\neach of these is 1, right?",
    "start": "1756210",
    "end": "1763100"
  },
  {
    "text": "And so this term\nis just m over t. That's the term we\nwere just looking at. It's the m over t\nfrom over there.",
    "start": "1763100",
    "end": "1768380"
  },
  {
    "text": "But now instead\nof m, you replace m, not the number\nof constraints, but actually the\nsum of the degree--",
    "start": "1768380",
    "end": "1775220"
  },
  {
    "text": "the total sum of degrees, right? Which is actually\nnot obvious, right? Because if I give you a single\nsemi-definite constraint with",
    "start": "1775220",
    "end": "1783380"
  },
  {
    "text": "a 10 by 10 matrix, how many-- and I ask you how many\nconstraints is that?",
    "start": "1783380",
    "end": "1788810"
  },
  {
    "text": "It's not clear. It's a single vector\nconstraint, right, where it's a positive\nsemidefinite matrix.",
    "start": "1788810",
    "end": "1795320"
  },
  {
    "text": "Or you could say,\nwell, it's like n, n plus 1 over 2 constraints\nbecause that's the number of scalars\nin a symmetric 10 by 10",
    "start": "1795320",
    "end": "1801290"
  },
  {
    "text": "matrix, right? But 55 is not right\neither because I think that's what you'd get. And what this says is for\nthis purposes, it's 10.",
    "start": "1801290",
    "end": "1810400"
  },
  {
    "text": "It acts as if a\nsemidefinite inequality with a 10 by 10 matrix is\nroughly equivalent to 10 scalar",
    "start": "1810400",
    "end": "1818919"
  },
  {
    "text": "inequalities. That's what this is saying here. OK. ",
    "start": "1818920",
    "end": "1824759"
  },
  {
    "text": "So now you get cool stuff. You get semidefinite\nprogramming.",
    "start": "1824760",
    "end": "1830520"
  },
  {
    "text": "You work out what\nthe log barrier is. You work out what it\nis on the central path.",
    "start": "1830520",
    "end": "1836820"
  },
  {
    "text": "It's this. You get dual points. It's this thing. And this is the dual of\nthis semidefinite program.",
    "start": "1836820",
    "end": "1845520"
  },
  {
    "text": "And the duality gap\nis exactly p over t. p is equal to the size of\nthese matrices, right?",
    "start": "1845520",
    "end": "1851670"
  },
  {
    "text": "Because that's the\ndegree of the logarithm on the positive definite cone.",
    "start": "1851670",
    "end": "1858040"
  },
  {
    "text": "OK. Well, now you have\nthe barrier method. Here it is. You look at it for a minute.",
    "start": "1858040",
    "end": "1863920"
  },
  {
    "text": "And here's what you'll find out. Nothing changed\nat least in form.",
    "start": "1863920",
    "end": "1869670"
  },
  {
    "text": "Nothing changed. Oh, the only thing was\nyou had to replace m. This used to be m. And now it's some of the\ntheta i's over t, right?",
    "start": "1869670",
    "end": "1877110"
  },
  {
    "text": "So in something\nlike Julia, it would mean that your code from\nbefore would actually",
    "start": "1877110",
    "end": "1882120"
  },
  {
    "text": "probably just work. Literally just work, right? I mean, you go back and\nyou have to make sure that a logarithm is defined\ncorrectly and all that,",
    "start": "1882120",
    "end": "1889530"
  },
  {
    "text": "but it would just work. And you can see, it's\njust exactly the same. And you get the-- the\ncomplexity analysis just",
    "start": "1889530",
    "end": "1897000"
  },
  {
    "text": "applies just immediately. It just works. Except wherever I\nsaid m over here, you replace it with sum theta i.",
    "start": "1897000",
    "end": "1904800"
  },
  {
    "text": "OK? So this is pretty cool. And, I mean, maybe\nmore important",
    "start": "1904800",
    "end": "1911235"
  },
  {
    "text": "at least certainly\nmore important to me is that it actually--\nit actually works super well in practice.",
    "start": "1911235",
    "end": "1917270"
  },
  {
    "text": "So what's crazy is if\nyou look at these things, they look exactly like\nthe ones we saw before",
    "start": "1917270",
    "end": "1924500"
  },
  {
    "text": "for linear programs, quadratic\nprograms, geometric programs. They look the same, right?",
    "start": "1924500",
    "end": "1930065"
  },
  {
    "text": "That everything's\nover and somewhere between 20 and 50 steps if\nyou choose mu reasonably.",
    "start": "1930065",
    "end": "1936680"
  },
  {
    "text": "You see all sorts of stuff. I mean, you couldn't tell\nany difference between this. This plot looks exact--\nthese look exactly",
    "start": "1936680",
    "end": "1942230"
  },
  {
    "text": "like they did for\nsolving an LP, right?",
    "start": "1942230",
    "end": "1947780"
  },
  {
    "text": "So it's just the same. And the fancier methods,\nI'll talk about them briefly.",
    "start": "1947780",
    "end": "1954965"
  },
  {
    "text": "But they would come in\nbetween 20 and 50 just always. That's how that works, right?",
    "start": "1954965",
    "end": "1960470"
  },
  {
    "text": "So by the way, this is pretty\ncool because I started-- I started using\nsemidefinite programming for problems in control.",
    "start": "1960470",
    "end": "1967050"
  },
  {
    "text": "Actually, before the\nadvent of these methods and we used very fancy--",
    "start": "1967050",
    "end": "1972540"
  },
  {
    "text": "complicated methods that\nwould take 10 minutes to solve a semidefinite\nprogram with a handful",
    "start": "1972540",
    "end": "1979380"
  },
  {
    "text": "of matrix inequalities\nthat were like 10 by 10. And we were happy and\nwe liked the results.",
    "start": "1979380",
    "end": "1985770"
  },
  {
    "text": "We had absolutely no idea\nthat within a couple of years, there would be methods-- there would be methods that\nwould be 20x shorter the code",
    "start": "1985770",
    "end": "1995924"
  },
  {
    "text": "and be 100x or 1,000x faster. Just did not like it was\na-- anyway, people now,",
    "start": "1995925",
    "end": "2001970"
  },
  {
    "text": "they just don't--\nthey don't care. As a matter of fact,\nmost people don't even care how these\nthings are solved. They just call a solver\nor, for that matter,",
    "start": "2001970",
    "end": "2010190"
  },
  {
    "text": "a higher level of ignorance,\nwhich is totally cool and fine is you just use CVXPY and\ncall the solve method.",
    "start": "2010190",
    "end": "2015267"
  },
  {
    "text": "And you have absolutely\nno idea what's being done on your behalf at\nthe far end, which is just fine. That's the way it's\nsupposed to be, right?",
    "start": "2015267",
    "end": "2021270"
  },
  {
    "text": "So OK. So this shows you this works.",
    "start": "2021270",
    "end": "2028370"
  },
  {
    "text": "There's like just a same story. It just takes between\n20 and 50 steps.",
    "start": "2028370",
    "end": "2033890"
  },
  {
    "text": "OK. So I do want to\nmention something which is that the barrier method\nis just a simple first cut.",
    "start": "2033890",
    "end": "2045140"
  },
  {
    "text": "I think yours is probably going\nto come in at around 50 lines order of magnitude. If you put a bunch\nof comments in there, it might be 70 or\nsomething, right?",
    "start": "2045140",
    "end": "2051967"
  },
  {
    "text": "If you were to double that\nlength, you would actually-- you could actually get\nsomething that would be--",
    "start": "2051967",
    "end": "2057138"
  },
  {
    "text": "that would actually\nbe competitive, right? So if you went to 100 lines\nor something like that.",
    "start": "2057139",
    "end": "2063860"
  },
  {
    "text": "People don't really\nuse the barrier method that you've put together,\nbut they put things-- but what are you-- what is used,\nfor example, in Ekos or in any",
    "start": "2063860",
    "end": "2071658"
  },
  {
    "text": "of these things in all\nthese commercial tools as well, what are\nused are what are called primal dual\ninterior point methods.",
    "start": "2071659",
    "end": "2078408"
  },
  {
    "text": "I'll just say a\nlittle bit about them just so you know what they are.",
    "start": "2078409",
    "end": "2083540"
  },
  {
    "text": "So they actually update\nthe primal dual variables at each iteration. And you don't have the\ndistinction between inner",
    "start": "2083540",
    "end": "2089360"
  },
  {
    "text": "and-- you don't have\ninner-- you're not going all the way back to\nthe central path, right?",
    "start": "2089360",
    "end": "2094364"
  },
  {
    "text": "What you'll find out\nis if you actually look at some of these\ncodes, you will find out that you're still solving\na KKT system at every step.",
    "start": "2094364",
    "end": "2101370"
  },
  {
    "text": "So that part is\nexactly the same.  And let's see.",
    "start": "2101370",
    "end": "2106930"
  },
  {
    "text": "I should say that they do use\nsomething like what you're using because your\ncentering method is actually",
    "start": "2106930",
    "end": "2116020"
  },
  {
    "text": "an infeasible start. These also use infeasible start. They use something called\nthe primal-dual homogeneous",
    "start": "2116020",
    "end": "2122410"
  },
  {
    "text": "embedding. We're not going\nto talk about it, but it's actually very cool. It's actually it's a\nStanford development.",
    "start": "2122410",
    "end": "2128260"
  },
  {
    "text": "It's from [? NEA, ?]\nmaybe 20 years ago. It is now used for all solvers.",
    "start": "2128260",
    "end": "2136029"
  },
  {
    "text": "Commercial, noncommercial. Everywhere. That is what's used. And what it does is it\nactually solves the primal",
    "start": "2136030",
    "end": "2141670"
  },
  {
    "text": "and the dual simultaneously. It handles things\nlike infeasibility and it handles\nunbounded-- unboundedness.",
    "start": "2141670",
    "end": "2149830"
  },
  {
    "text": "All of it just by solving\none-- it solves one problem. You look at two\nscalar variables. From them, you figure out if\n1 is 1 or something like that.",
    "start": "2149830",
    "end": "2158049"
  },
  {
    "text": "If 1 is positive, it means you\nfound a primal-dual solution. If the other is\npositive, it means it's either unbounded or--",
    "start": "2158050",
    "end": "2164860"
  },
  {
    "text": "it will actually\nget the certificate. It'll either give you\na ray that establishes that it is unbounded below or\nit'll give you a certificate",
    "start": "2164860",
    "end": "2174050"
  },
  {
    "text": "showing that the original\nproblem is infeasible. So that's what that is. I mean, I'm just saying this is\nif you're interested in this.",
    "start": "2174050",
    "end": "2181020"
  },
  {
    "text": "I mean, it's not-- some small fraction\nof you might actually be if you ended up implementing\nsomething like this.",
    "start": "2181020",
    "end": "2188450"
  },
  {
    "text": "You might not. You might not. But I'm just saying,\nif you want it. But if you were to\nread the papers, everything else would be--",
    "start": "2188450",
    "end": "2194359"
  },
  {
    "text": "you would you'd see everything. You'd see KKT. You'd see log barriers. You'd hear self-concordance.",
    "start": "2194360",
    "end": "2199940"
  },
  {
    "text": "You'd look at the KKT systems\nthat are being solved. You'd see they'd-- we're\ngoing to do it by reduction or we're going to do it by\njust using a primal-dual--",
    "start": "2199940",
    "end": "2209099"
  },
  {
    "text": "sorry, an LDL transpose\nfactorization. So you would be\nhighly familiar--",
    "start": "2209100",
    "end": "2214685"
  },
  {
    "text": "You are now ready\nto start reading-- you could read. I mean I'm not\nrecommending this, right? But, at this point, you could\nlook at any of these things.",
    "start": "2214685",
    "end": "2221660"
  },
  {
    "text": "You could actually\nlook at the codes and everything would\nbe very, very familiar. So OK.",
    "start": "2221660",
    "end": "2228170"
  },
  {
    "text": "So I'll quit here on this.",
    "start": "2228170",
    "end": "2233359"
  },
  {
    "text": "And let me just\nfinish by saying-- well, I don't know\nunless maybe there's some questions\nabout this or not.",
    "start": "2233360",
    "end": "2238940"
  },
  {
    "text": " OK.",
    "start": "2238940",
    "end": "2244250"
  },
  {
    "text": "Yeah. So I guess in the ensuing\n30 years basically, these methods have taken over.",
    "start": "2244250",
    "end": "2249790"
  },
  {
    "text": "They're now the default\ncommercial solvers. So all solvers\nbasically do this. There are some hold overs\nfor linear programming",
    "start": "2249790",
    "end": "2257500"
  },
  {
    "text": "as a little bit special and so\nthere's hold overs for that. But for everything\nelse, it's just this. I mean, it's not--",
    "start": "2257500",
    "end": "2263422"
  },
  {
    "text": "it's these primal-dual\ninterior point methods, right? So OK.",
    "start": "2263422",
    "end": "2268539"
  },
  {
    "text": "Let me finish by just\nsaying one thing. The reason we just did the\nlast two and a half weeks of the class and you\nare doing this homework",
    "start": "2268540",
    "end": "2276580"
  },
  {
    "text": "was purely to demystify\nthese methods. To show they're\nnot as complicated",
    "start": "2276580",
    "end": "2284120"
  },
  {
    "text": "as they might sound if you\njust jump in and start reading the papers or you\nstart looking at codes",
    "start": "2284120",
    "end": "2289490"
  },
  {
    "text": "if they're open source, right? They're just not as\ncomplicated as they sound. And so it seems\nlike a good thing",
    "start": "2289490",
    "end": "2295130"
  },
  {
    "text": "to understand that actually\nan LP solver is not that complicated. Solving a small-- solving\nsemidefinite program",
    "start": "2295130",
    "end": "2302210"
  },
  {
    "text": "is not that complicated, right? I mean, whether or\nnot you would have",
    "start": "2302210",
    "end": "2307850"
  },
  {
    "text": "to actually do any of this,\nit depends what you do. If you're actually\ninvolved in weird real-time",
    "start": "2307850",
    "end": "2315230"
  },
  {
    "text": "or super large scale\nimplementations, real-time would be\nprobably more closer to actually a realistic thing.",
    "start": "2315230",
    "end": "2321982"
  },
  {
    "text": "Well, let's suppose\nyou're flying a drone and it turns out you need to\nsolve a small semidefinite program, I don't know,\n100 times a second.",
    "start": "2321982",
    "end": "2329780"
  },
  {
    "text": "OK. It's actually very difficult\nto take a commercial solver and embed it, right? Because the commercial\nsolver is going",
    "start": "2329780",
    "end": "2336110"
  },
  {
    "text": "to do all crazy stuff like-- Well, for one\nthing, it's actually going to do things\nlike actually ask",
    "start": "2336110",
    "end": "2341310"
  },
  {
    "text": "to allocate memory, which\ndoesn't work super well when you're in the air, right?",
    "start": "2341310",
    "end": "2346680"
  },
  {
    "text": "And you have a 10\nmillisecond deadline, right? So anyway, I'm just saying, if\nyou end up at a high frequency",
    "start": "2346680",
    "end": "2355470"
  },
  {
    "text": "trading firm or\nsomething like that, and you're going to implement\na tiny QP or LP solver that",
    "start": "2355470",
    "end": "2361500"
  },
  {
    "text": "should solve in like\n50 microseconds, now you know that you can do\nit and it's not a big deal. So that was the sole reason\nto do this part of the course,",
    "start": "2361500",
    "end": "2369250"
  },
  {
    "text": "but I think it's\nactually important. So OK. Any questions about it?",
    "start": "2369250",
    "end": "2375130"
  },
  {
    "text": "It's cool. So actually now, the whole\nstack is demystified for you because here's what it does.",
    "start": "2375130",
    "end": "2381010"
  },
  {
    "text": "When you type in CVXPY,\nCVXPY does forms a sequence",
    "start": "2381010",
    "end": "2386650"
  },
  {
    "text": "of equivalent problems. It starts with your problem. It does a reduction, makes it\na completely equivalent problem",
    "start": "2386650",
    "end": "2393609"
  },
  {
    "text": "with a retrieval method, right? Then reduces it again and again. Maybe 12, 15, 20 reductions\nlater, it looks up and it says,",
    "start": "2393610",
    "end": "2401650"
  },
  {
    "text": "I have a form that one\nof my solvers can solve. Everybody following this?",
    "start": "2401650",
    "end": "2408280"
  },
  {
    "text": "Then it passes it\noff to the solver. They are not all\ninterior point methods.",
    "start": "2408280",
    "end": "2414250"
  },
  {
    "text": "SCS, for example, is not. OSQP is not. But many others are.",
    "start": "2414250",
    "end": "2420340"
  },
  {
    "text": "So Ekos, Clarabel, commercial\nones are most almost entirely--",
    "start": "2420340",
    "end": "2426040"
  },
  {
    "text": "I guess almost entirely. They are barrier and interior\npoint methods, right? And now you know at\nleast a little bit",
    "start": "2426040",
    "end": "2432220"
  },
  {
    "text": "of the details of those. If you go down,\ndrill down deeper, what you know is if you\nprofile one of these things,",
    "start": "2432220",
    "end": "2439940"
  },
  {
    "text": "it is only doing the\nfollowing, linear algebra. Absolutely nothing else.",
    "start": "2439940",
    "end": "2446230"
  },
  {
    "text": "Linear algebra it's doing is\nactually mostly just exploiting sparsity and that's it.",
    "start": "2446230",
    "end": "2451430"
  },
  {
    "text": "So now, in a weird way,\nyou know everything at least for the\nfull stack from what",
    "start": "2451430",
    "end": "2456910"
  },
  {
    "text": "happens when you call-- when\nyou type in myprob.solve. And now you know.",
    "start": "2456910",
    "end": "2462730"
  },
  {
    "text": "So yeah? Is there a difference between\nsaying interior point methods or barrier methods?",
    "start": "2462730",
    "end": "2469480"
  },
  {
    "text": "Yeah, let's see. No, not really. So barrier method I\nthink is an older term.",
    "start": "2469480",
    "end": "2475670"
  },
  {
    "text": "I like it because it's\na cool retro term. But it refers to the same-- Yeah, it's usually\npretty much the same.",
    "start": "2475670",
    "end": "2482480"
  },
  {
    "text": "So yeah. So to your point I think is\nwhat most people would call it these days so.",
    "start": "2482480",
    "end": "2489520"
  },
  {
    "text": "I mean, it's still--\nyou have to admit, it's pretty stunning\nthat you can solve an LP with 10,000\nvariables and 5,000 constraints",
    "start": "2489520",
    "end": "2498475"
  },
  {
    "text": "in 20 iterations. And that's too extremely\nhigh precision, right?",
    "start": "2498475",
    "end": "2504040"
  },
  {
    "text": "That's very weird, right? Because basically you want\nto find a particular vertex",
    "start": "2504040",
    "end": "2510880"
  },
  {
    "text": "in this polyhedron\nof which there's a number equal to the number\nof subatomic particles",
    "start": "2510880",
    "end": "2517030"
  },
  {
    "text": "in the universe, including\ndark matter, right? So that's-- and what it does\nis it basically stops and asks",
    "start": "2517030",
    "end": "2523480"
  },
  {
    "text": "for directions 20 times. That's, to me, very weird.",
    "start": "2523480",
    "end": "2529760"
  },
  {
    "text": "I mean, it's cool. We're all very lucky because\nwe're beneficiaries of it. But it's very cool, right?",
    "start": "2529760",
    "end": "2536980"
  },
  {
    "text": "I still don't get it. There are people who claim\nto understand why this works, but I don't believe\nthem so or at least I",
    "start": "2536980",
    "end": "2544292"
  },
  {
    "text": "didn't get [INAUDIBLE]. Yes? Can you give an example of\nhow CVXPY reduces the problem",
    "start": "2544292",
    "end": "2549850"
  },
  {
    "text": "or comes up with [INAUDIBLE]? Sure. It's actually--\nSo we did a lot--",
    "start": "2549850",
    "end": "2555100"
  },
  {
    "text": "we did those very early on. I don't know if you\nremember we did that. What happens is you actually\ndon't do a lot of those",
    "start": "2555100",
    "end": "2561460"
  },
  {
    "text": "now because it's done for you. But the reduction would\nbe like introduction",
    "start": "2561460",
    "end": "2566590"
  },
  {
    "text": "of a slack variable, right? It would be-- I mean, the interesting\nones would be how to handle.",
    "start": "2566590",
    "end": "2575142"
  },
  {
    "text": "I mean, an interesting\none would be how do we handle the\nsum of the 3.5 largest entries of a vector?",
    "start": "2575142",
    "end": "2580859"
  },
  {
    "text": "That's a convex function. Since CVXPY sum\nlargest x comma 3.5.",
    "start": "2580860",
    "end": "2586260"
  },
  {
    "text": "Just you don't have to\nthink about anything. That's a much more\ninteresting reduction. Those things you-- all of those\nyou would know about, right?",
    "start": "2586260",
    "end": "2594720"
  },
  {
    "text": "So there's no-- most\nof the reductions are actually really dumb. They're really boring.",
    "start": "2594720",
    "end": "2600660"
  },
  {
    "text": "Here's one. You want to maximize\nan objective, right? Well, none of our--",
    "start": "2600660",
    "end": "2606119"
  },
  {
    "text": "no solver solves that problem. So here's an equivalent problem. Ready? Minimize minus the objective.",
    "start": "2606120",
    "end": "2613380"
  },
  {
    "text": "There you go. I mean, that's a reduction. It's dumb, right? And then the retrieval\nmethod is simple.",
    "start": "2613380",
    "end": "2619830"
  },
  {
    "text": "The retrieval method is that\nyou just replicate x, right? The solution.",
    "start": "2619830",
    "end": "2624990"
  },
  {
    "text": "But you change the optimal value\nby flipping the sign, right? So they range between-- these\nreductions range between--",
    "start": "2624990",
    "end": "2631800"
  },
  {
    "text": "most of them are deeply boring\nlike the one I just said. And a handful of them\nare actually interesting.",
    "start": "2631800",
    "end": "2638690"
  },
  {
    "text": "So that was a non-answer. But you have seen these in\nmaybe week four of the course.",
    "start": "2638690",
    "end": "2644520"
  },
  {
    "text": "These-- I guess what I was\nasking, like, how do you tell which one\n[? is useful ?] [INAUDIBLE]?? Ah, OK. Well, now that's\nanother story, right?",
    "start": "2644520",
    "end": "2651280"
  },
  {
    "text": "So it actually finds a shortest\npath in the graph, right? So it takes a problem.",
    "start": "2651280",
    "end": "2657730"
  },
  {
    "text": "It estimates what is\nthe most specific. I mean, this just\nbecause you asked, right? It looks at your\nproblem and says,",
    "start": "2657730",
    "end": "2664190"
  },
  {
    "text": "I could compile that to a QP\nand a second-order cone program or something like that.",
    "start": "2664190",
    "end": "2669850"
  },
  {
    "text": "Then it looks among your solvers\nunless you specified one. It looks for the one\nthat's most specific.",
    "start": "2669850",
    "end": "2676280"
  },
  {
    "text": "In that case, it might pick\nthe QP or something like that. So then it actually\nhas a shortest path.",
    "start": "2676280",
    "end": "2681910"
  },
  {
    "text": "It tries to figure out,\nis there a sequence of transformations that will\ntake this problem to a QP?",
    "start": "2681910",
    "end": "2688015"
  },
  {
    "text": "So that's roughly what it does. So cool.",
    "start": "2688015",
    "end": "2693990"
  },
  {
    "text": "OK. So weirdly, I think now\neverything is demystified. I mean maybe not every detail.",
    "start": "2693990",
    "end": "2700260"
  },
  {
    "text": "But if you were to\nstart reading about it, you would-- everything would\nbe completely familiar. OK.",
    "start": "2700260",
    "end": "2705810"
  },
  {
    "text": "So we could do two things. We could either jump\ninto our last topic,",
    "start": "2705810",
    "end": "2711705"
  },
  {
    "text": "which I think is actually-- I think actually that's\nwhat we're going to do. I just made the decision for us. There we go.",
    "start": "2711705",
    "end": "2717275"
  },
  {
    "text": "So here's what\nwe're going to do. ",
    "start": "2717275",
    "end": "2724240"
  },
  {
    "text": "OK. So this is what we\nhold in reserve. So if we finish a bit early,\nwhich is typical like we just",
    "start": "2724240",
    "end": "2733050"
  },
  {
    "text": "did, then we'll be able\nto go back and look at some other cool material.",
    "start": "2733050",
    "end": "2738850"
  },
  {
    "text": "So what we're\ngoing to do is look at L1 norm methods for\nconvex cardinality problems.",
    "start": "2738850",
    "end": "2745840"
  },
  {
    "text": "And I'll explain\nthat in a minute. You already know I think about\nthe connection between L1",
    "start": "2745840",
    "end": "2752910"
  },
  {
    "text": "norms and sparsity, right? And you may also have seen this\nin maybe a statistics class",
    "start": "2752910",
    "end": "2759960"
  },
  {
    "text": "or something like that. So I'm not sure where\nelse it would come up, but that's one place\nwhere it would come up.",
    "start": "2759960",
    "end": "2765160"
  },
  {
    "text": "So we'll just go a bit\nmore into depth here and it'll be-- it's actually\nthere's some interesting stuff and you'll actually see\nsome cool connections that",
    "start": "2765160",
    "end": "2772170"
  },
  {
    "text": "will actually give you that's\nbetter than merely saying",
    "start": "2772170",
    "end": "2777240"
  },
  {
    "text": "you want that sparse? Here. And then you type out a\nproblem with an L1 norm. You'll see that you can\nactually do better than that.",
    "start": "2777240",
    "end": "2785319"
  },
  {
    "text": "OK. So here's the idea. So a cardinality, by the\nway, is simply the number",
    "start": "2785320",
    "end": "2791230"
  },
  {
    "text": "of non-zeros of a vector. And, in fact, it's a\nseparable function, right?",
    "start": "2791230",
    "end": "2796570"
  },
  {
    "text": "So it actually is based on this. It's based on-- so it's\nthe cardinality-- this",
    "start": "2796570",
    "end": "2805390"
  },
  {
    "text": "is for a scalar of let's\nsay a is equal to either 1",
    "start": "2805390",
    "end": "2810769"
  },
  {
    "text": "if a is not 0. And 0, if a equals 0. OK? So that's--",
    "start": "2810770",
    "end": "2816099"
  },
  {
    "text": "And if you sum this function\nover all the coefficients",
    "start": "2816100",
    "end": "2821590"
  },
  {
    "text": "of a vector, you\nget the cardinality, which is the number, right? And this function,\nobviously, is not convex.",
    "start": "2821590",
    "end": "2827710"
  },
  {
    "text": "I guess that's obvious. It looks like this. That's empty. And that, oop.",
    "start": "2827710",
    "end": "2833260"
  },
  {
    "text": "Yeah. Whoops. OK yeah. It looks like this. And then this is looks\nlike it's this point.",
    "start": "2833260",
    "end": "2839319"
  },
  {
    "text": "And wait. No, no, no, no, no, no. Here, it's this and then that. So this is-- or if you\nlike, I'll make it look",
    "start": "2839320",
    "end": "2846280"
  },
  {
    "text": "like that in a very\nweird way, right? So that's the\ncardinality function. OK.",
    "start": "2846280",
    "end": "2852630"
  },
  {
    "text": "Obviously not convex, right? OK. So the history of this\ngoes back in way pre-date--",
    "start": "2852631",
    "end": "2860609"
  },
  {
    "text": "it goes back into\nthe '50s at the least and maybe even earlier. But it's used in all cool things\nlike in sparse design is one.",
    "start": "2860610",
    "end": "2868830"
  },
  {
    "text": "So a very interesting\nexample of that is it",
    "start": "2868830",
    "end": "2874110"
  },
  {
    "text": "was actually used in aerospace\nin design of structures in the 1950s and '60s.",
    "start": "2874110",
    "end": "2879900"
  },
  {
    "text": "So let me explain\nhow that works. You're going to\nbuild a structure and you put in all these bars\nthat connect two nodes, right?",
    "start": "2879900",
    "end": "2887550"
  },
  {
    "text": "So it's a space frame\nor something like that. By the way, how many people\nknow what I'm talking about?",
    "start": "2887550",
    "end": "2892560"
  },
  {
    "text": "Because if-- a couple, OK. That's good enough. And the rest should just pick\nup the flavor of it, right?",
    "start": "2892560",
    "end": "2898155"
  },
  {
    "text": "So I have a whole\nbunch of nodes. And I'm going to\nput in bars, right? And my variables actually\nare the cross sectional areas",
    "start": "2898155",
    "end": "2904390"
  },
  {
    "text": "of the bars, OK? That's the variables. But what you do is the bars--\nyou put in a gazillion bars,",
    "start": "2904390",
    "end": "2911890"
  },
  {
    "text": "you have absolutely no\nintention to use a million-- a million bars in your\nspace frame, right?",
    "start": "2911890",
    "end": "2917740"
  },
  {
    "text": "This could be, for example,\nthe wing of an airplane, right? Or some structure like that, or\nsome structure in a spacecraft,",
    "start": "2917740",
    "end": "2925510"
  },
  {
    "text": "right? OK. So what you do then is you\nactually put an L1 norm",
    "start": "2925510",
    "end": "2932800"
  },
  {
    "text": "on the cross sectional areas. What's the L1 norm of\na non-negative vector?",
    "start": "2932800",
    "end": "2939040"
  },
  {
    "start": "2939040",
    "end": "2944856"
  },
  {
    "text": "[INAUDIBLE] Thank you. Yeah, OK, fine. So you could actually--\nwhat's weird about that",
    "start": "2944856",
    "end": "2949890"
  },
  {
    "text": "is you could look in some\nof those papers for L1 norm. And you're like I don't\nsee any L1 norm here. And the reason is the\nthings that you're computing",
    "start": "2949890",
    "end": "2958260"
  },
  {
    "text": "in L1 norm of are non-negative. So it's just a sum. OK, fine. All right. So what happens\nis you solve this",
    "start": "2958260",
    "end": "2966150"
  },
  {
    "text": "and the constraints are\nyou'd have a limit on weight. You have a limit. What you also have is a\nwhole bunch of constraints",
    "start": "2966150",
    "end": "2972780"
  },
  {
    "text": "which are performance related. And it basically says\nif I take this structure and I put various forces\non various places,",
    "start": "2972780",
    "end": "2978420"
  },
  {
    "text": "can it withstand it, right? I might have a maximum stress\nlimit in each bar or something. Everybody-- so there's a\nwhole bunch of constraints.",
    "start": "2978420",
    "end": "2984960"
  },
  {
    "text": "The comment is strong enough\nto handle boost, takeoff, whatever reentry.",
    "start": "2984960",
    "end": "2990900"
  },
  {
    "text": "I don't care whatever\nthis is, right? Or rough turbulence. All that kind of stuff. Everybody following this?",
    "start": "2990900",
    "end": "2996002"
  },
  {
    "text": "So that's a whole\nbunch of constraints. Anyway, when you\nsolve this problem,",
    "start": "2996002",
    "end": "3001369"
  },
  {
    "text": "you offered it the option\nof using-- they didn't do a million in the '60s, OK? But now they do\na million, right?",
    "start": "3001370",
    "end": "3006579"
  },
  {
    "text": "So you offered it the\nchoice of a million bars. And what happens is 322\nturn out to be positive",
    "start": "3006580",
    "end": "3015040"
  },
  {
    "text": "and the rest are zero. Everybody got this? And then it's cool because\nsomeone said, well, what did you just do?",
    "start": "3015040",
    "end": "3020365"
  },
  {
    "text": "And you say I just designed-- I just designed the structure. It's a cool structure.",
    "start": "3020365",
    "end": "3025930"
  },
  {
    "text": "And you see all these bars\nconnecting various points and stuff like that. And if your specs\nwere right it would be a completely\nreasonable structure.",
    "start": "3025930",
    "end": "3031750"
  },
  {
    "text": "And someone said that sounds\nlike a combinatorial problem, right? Because you did-- Here's what you\ndid not solve, you",
    "start": "3031750",
    "end": "3037980"
  },
  {
    "text": "didn't say I want\n322 bars from my--",
    "start": "3037980",
    "end": "3044609"
  },
  {
    "text": "what I'm offering you which\nis 1.1 million, right? Because 1.1 million choose 322\nis a super big number, right?",
    "start": "3044610",
    "end": "3052320"
  },
  {
    "text": "So you did not\nsolve that problem. So this is a heuristic,\nbut that's what happens. Everybody got that?",
    "start": "3052320",
    "end": "3058600"
  },
  {
    "text": "So that's already in the '60s. People were doing\nthis, which is cool. I know that there was\na great example in--",
    "start": "3058600",
    "end": "3065085"
  },
  {
    "text": "Can they do it in circuits? That's a good one. So, in circuit\ndesign, you're going to build yourself a filter.",
    "start": "3065085",
    "end": "3071799"
  },
  {
    "text": "You're going to build,\nlet's say, an FIR filter. So I'm speaking\ndialect, but it's OK. If people get--",
    "start": "3071800",
    "end": "3076980"
  },
  {
    "text": "So you're going to build\nyourself a finite impulse response filter, which is a set\nof a bunch of sums and stuff",
    "start": "3076980",
    "end": "3082829"
  },
  {
    "text": "like that. And you design the coefficients. Here are the coefficients--\ncan be negative.",
    "start": "3082830",
    "end": "3088270"
  },
  {
    "text": "So there's an L1 norm put in. And you say I want a filter\nthat has the following specs,",
    "start": "3088270",
    "end": "3094050"
  },
  {
    "text": "but I also want the\ncoefficients to be sparse. So you add an L1 term. It's sparse.",
    "start": "3094050",
    "end": "3099579"
  },
  {
    "text": "And it's very cool\nbecause then when you're going to emit\nthe hardware for it. When a coefficient is zero,\nit means that little block",
    "start": "3099580",
    "end": "3106592"
  },
  {
    "text": "in your actual hardware\ncircuit, you don't even need it because I know how to-- I'm not a hardware designer,\nbut I do know how to--",
    "start": "3106592",
    "end": "3113410"
  },
  {
    "text": "I do know how to synthesize\nhardware that multiplies by 0 and adds it to the result.\nThat I can do, right?",
    "start": "3113410",
    "end": "3119830"
  },
  {
    "text": "And the answer is just\nno hardware at all. Everybody following these? And then, of course, I\nthink most-- many of you",
    "start": "3119830",
    "end": "3125380"
  },
  {
    "text": "have seen this in statistics. Actually for two different\npurposes at least two.",
    "start": "3125380",
    "end": "3132609"
  },
  {
    "text": "The first is for sparse features\nis feature selection, right?",
    "start": "3132610",
    "end": "3137650"
  },
  {
    "text": "So you'd say here's\na bunch of data.",
    "start": "3137650",
    "end": "3142690"
  },
  {
    "text": "I have 500 patients. 250 have one type of cancer, 250\ndon't or something like that.",
    "start": "3142690",
    "end": "3149530"
  },
  {
    "text": "Here's gene activation data. So I give you, I don't know,\n80,000 gene expression levels.",
    "start": "3149530",
    "end": "3156610"
  },
  {
    "text": "And then if you put L1-- if you put an L1\nregularizer on, let's say",
    "start": "3156610",
    "end": "3162310"
  },
  {
    "text": "just logistic regression\nto classify the two, then it's going to go in\nand choose 22 genes, right?",
    "start": "3162310",
    "end": "3169810"
  },
  {
    "text": "Everybody? So, by the way, how many people\nhave seen that or something like that in some class?",
    "start": "3169810",
    "end": "3176724"
  },
  {
    "text": "Where was it? Like Stat 315 or something? 206. 206?",
    "start": "3176725",
    "end": "3182680"
  },
  {
    "text": "Good. I was hoping for more people to\nraise their hands on that one. These are super\ncool things, right?",
    "start": "3182680",
    "end": "3189130"
  },
  {
    "text": "So everybody should\nhave seen these things. But anyway, do you\nknow what they do? I have biologist friends.",
    "start": "3189130",
    "end": "3194630"
  },
  {
    "text": "You know what they do with that? So I have a biologist\nfriend who hates math. Doesn't trust. He says it's stupid.",
    "start": "3194630",
    "end": "3199833"
  },
  {
    "text": "It doesn't work. I caught him actually\nrunning one of those things. I was like you're so busted.",
    "start": "3199833",
    "end": "3205869"
  },
  {
    "text": "He said no. I don't trust it. He said what I do\nis I take the 22 genes, I look at the first 10\nand go like duh, of course,",
    "start": "3205870",
    "end": "3212535"
  },
  {
    "text": "they're related to this\npathway because he actually knows biology. He said, of course,\nthat's obviously related to the pathway for x, y, and z.",
    "start": "3212535",
    "end": "3218493"
  },
  {
    "text": "And he looked at\ntwo others and he says that has nothing to do\nwith-- that's ridiculous. And he looks at three others\nand he goes like, hmm.",
    "start": "3218493",
    "end": "3224830"
  },
  {
    "text": "These are people who know\ngenes by name, right? He looks at them and he goes\nlike, hmm, that's interesting.",
    "start": "3224830",
    "end": "3232380"
  },
  {
    "text": "That actually could be related. That could be. And then I said, well,\nwhat do you do then? He said, well, then\nI just call my lab.",
    "start": "3232380",
    "end": "3238609"
  },
  {
    "text": "He said and he makes his\npostdocs go in and knock out those genes and see if\nsomething happens, right? Then the next morning\nmaybe it happens,",
    "start": "3238610",
    "end": "3245150"
  },
  {
    "text": "maybe it doesn't, right? Or whenever the\nexperiment's over so. That's fine, right?",
    "start": "3245150",
    "end": "3250490"
  },
  {
    "text": "But OK. OK. Let's see some other\nexamples of it.",
    "start": "3250490",
    "end": "3255619"
  },
  {
    "text": "Oh, it comes up in-- Oh, in a lot of image\nprocessing-- signal processing, geophysics from the '70s.",
    "start": "3255620",
    "end": "3262220"
  },
  {
    "text": "Oh, there's on total\nvariation reconstruction. We've already seen that. That's actually\nbasically an L1 norm",
    "start": "3262220",
    "end": "3268339"
  },
  {
    "text": "applied to a derivative\neither a first difference or, for example, in an image,\nit might be to a gradient,",
    "start": "3268340",
    "end": "3275990"
  },
  {
    "text": "in a space gradient in an image. OK. So these are-- And yeah, that's a bit old.",
    "start": "3275990",
    "end": "3281972"
  },
  {
    "text": "I mean, yeah, there are some\ntheoretical results that guarantee the methods works. I mean, that's I think\nit's cool, but whatever.",
    "start": "3281972",
    "end": "3288890"
  },
  {
    "text": "It's fine. They work without these\nmethods anyway so. OK.",
    "start": "3288890",
    "end": "3294050"
  },
  {
    "text": "So what we're going to\ndo now is look at this and go through this stuff\na bit more carefully.",
    "start": "3294050",
    "end": "3302000"
  },
  {
    "text": "So the cardinality\nis the function I just plotted over here. It looks like that.",
    "start": "3302000",
    "end": "3307580"
  },
  {
    "text": "It's quasi-concave. But, I mean, who cares? Because that's not something\nthat tells you congratulations.",
    "start": "3307580",
    "end": "3313190"
  },
  {
    "text": "You can maximize the cardinality\nof a vector, which is silly.",
    "start": "3313190",
    "end": "3318319"
  },
  {
    "text": "Otherwise, it has no\nconvexity properties, right? You have lots of interesting\nproblems like a convex",
    "start": "3318320",
    "end": "3325980"
  },
  {
    "text": "cardinality problem. Here's one that looks like this. So this says here's\na set of convex.",
    "start": "3325980",
    "end": "3331859"
  },
  {
    "text": "Here's a convex set, say. And what you're going to do\nis you say please find in this",
    "start": "3331860",
    "end": "3339210"
  },
  {
    "text": "set the point with the\nsmallest number of nonzeros. This is general, but we're going\nto look at specific examples.",
    "start": "3339210",
    "end": "3346380"
  },
  {
    "text": "And you'll see this is a\nsuper interesting problem. Or you could do\nthings like this. I could have a standard\nconvex problem here.",
    "start": "3346380",
    "end": "3353625"
  },
  {
    "text": "Here. But I could add\na constraint that says you can only use\nk nonzeros, right?",
    "start": "3353625",
    "end": "3359579"
  },
  {
    "text": "So I mean in statistics\nor machine learning, this would be maximize\nmy log likelihood",
    "start": "3359580",
    "end": "3368880"
  },
  {
    "text": "subject to some constraints\nthat are required. Then also-- P.S.,\nyou're only allowed",
    "start": "3368880",
    "end": "3374730"
  },
  {
    "text": "to use-- you can't use\nmore than 22 features and I'm giving you\na million, right?",
    "start": "3374730",
    "end": "3380040"
  },
  {
    "text": "So that would be that, right. And there it's called\nlike feature selection. We'll get to that.",
    "start": "3380040",
    "end": "3385650"
  },
  {
    "text": "OK. So just a couple of\nobservations about this. So the first one is if you\nfix the sparsity pattern,",
    "start": "3385650",
    "end": "3394380"
  },
  {
    "text": "then you just get a\nconvex problem, right? So if I tell you fit my\nmodel and you go, OK.",
    "start": "3394380",
    "end": "3401513"
  },
  {
    "text": "You say I have a\nmillion features. You say, oh, but only these\n22 are allowed to be nonzero and all the rest are zero.",
    "start": "3401513",
    "end": "3407130"
  },
  {
    "text": "Then you're like, OK,\nbecause then it's just a problem with 22 variables. Everybody got this? So this is obvious.",
    "start": "3407130",
    "end": "3414059"
  },
  {
    "text": "That means that you could solve\n2 to the n convex problems",
    "start": "3414060",
    "end": "3419270"
  },
  {
    "text": "to solve these, right? If n is 1,000, it's not. I mean, if n-- sorry. n is 100, it's not--",
    "start": "3419270",
    "end": "3424950"
  },
  {
    "text": "n is less than 10,\nthis is not-- this might not be insane, right?",
    "start": "3424950",
    "end": "3430680"
  },
  {
    "text": "So yeah. So that's one.",
    "start": "3430680",
    "end": "3435869"
  },
  {
    "text": "But this brute force\nsearch doesn't work for-- obviously for bigger problems.",
    "start": "3435870",
    "end": "3442996"
  },
  {
    "text": "It's extremely easy to\nshow that the whole thing-- that this general\nproblem is (NP-) hard. I think we'll do\nthat in a minute.",
    "start": "3442997",
    "end": "3448570"
  },
  {
    "text": "And you could solve\nit globally by what are called branch\nand bound methods. And there's also\nbranch and cut methods.",
    "start": "3448570",
    "end": "3454170"
  },
  {
    "text": "There's all sorts\nof names for this. It's a whole area I guess\npeople would call it. Like mixed integer\nconvex programming.",
    "start": "3454170",
    "end": "3461394"
  },
  {
    "text": "They might. These things can work. Some of them can\nwork spectacularly. I'm not going to\ntalk about those.",
    "start": "3461394",
    "end": "3468320"
  },
  {
    "text": "But anyway, just general\nideas about how you would solve these problems, right?",
    "start": "3468320",
    "end": "3474270"
  },
  {
    "text": " So you can actually\nexpress Boolean LP",
    "start": "3474270",
    "end": "3480990"
  },
  {
    "text": "as a cardinality problem\nlike that, right? And I think you've actually\ndone a couple of problems",
    "start": "3480990",
    "end": "3486180"
  },
  {
    "text": "on heuristic-- first\nof all, getting computing bounds for\nBoolean LPs and then also",
    "start": "3486180",
    "end": "3492090"
  },
  {
    "text": "for heuristics for actually\napproximately solving them.",
    "start": "3492090",
    "end": "3497640"
  },
  {
    "text": "I believe you had that\nin some homework, right? So the way that works is you\nwant to solve this problem.",
    "start": "3497640",
    "end": "3504099"
  },
  {
    "text": "Now, by the way, solving a\nset of linear inequalities with Boolean variables\nis basically like all--",
    "start": "3504100",
    "end": "3511146"
  },
  {
    "text": "all of these problems\nin computer science. Like everything is that, right? It's things like 3-SAT.",
    "start": "3511146",
    "end": "3517440"
  },
  {
    "text": "It's the Traveling\nSalesman Problem. I can write down very\nshort descriptions with 0, 1 variables.",
    "start": "3517440",
    "end": "3524217"
  },
  {
    "text": "And you just write it this way\nand it's a cardinality problem. And it just looks like this. It's actually the\ncardinality of x",
    "start": "3524217",
    "end": "3529320"
  },
  {
    "text": "stacked on 1 minus x is less\nthan or equal to n, right? Because this thing\ntells you the number",
    "start": "3529320",
    "end": "3536610"
  },
  {
    "text": "of entries of x and the nonzero. This tells you the\nnumber of entries of x that are not one, right?",
    "start": "3536610",
    "end": "3542609"
  },
  {
    "text": "And so if you add\nthose two together, the smallest that could be is n. And that would be if\nevery x is either 0 or 1.",
    "start": "3542610",
    "end": "3551339"
  },
  {
    "text": "If you throw in an x\nthat's 3.6, then that's going to come out to be\nn plus 1 or something",
    "start": "3551340",
    "end": "3556410"
  },
  {
    "text": "like that, that sum, right? OK. So that immediately establishes\nthat solving convex cardinality",
    "start": "3556410",
    "end": "3563040"
  },
  {
    "text": "problems is like\n(NP-) hard, right? So OK. OK.",
    "start": "3563040",
    "end": "3569720"
  },
  {
    "text": "So now we'll look\nat some examples before we get into the methods\nbecause they're very, very cool.",
    "start": "3569720",
    "end": "3576350"
  },
  {
    "text": "Yeah. So sparse design is C\nis a set of things that give you your specifications.",
    "start": "3576350",
    "end": "3582100"
  },
  {
    "text": "It says, here's what\nx has to satisfy. And then you simply\nwant the sparsest",
    "start": "3582100",
    "end": "3587440"
  },
  {
    "text": "x that satisfies your\nconditions, right? And the idea there is\npresumably a zero value",
    "start": "3587440",
    "end": "3595330"
  },
  {
    "text": "of x simplifies\nthe design, right? Or generally, it can actually\nbe components that don't even--",
    "start": "3595330",
    "end": "3601299"
  },
  {
    "text": "for example, I think we already\ntalked about a Truss design. And a zero\ncoefficient is it says",
    "start": "3601300",
    "end": "3607007"
  },
  {
    "text": "you should attach a bar between\nthis node and that wire. And what's the\ncross sectional area zero and you're like,\nOK, as in no bar, right?",
    "start": "3607007",
    "end": "3614020"
  },
  {
    "text": "For an FIR filter, if\nyou're designing a filter, it says there's whole\nblocks that you just don't",
    "start": "3614020",
    "end": "3619300"
  },
  {
    "text": "need in the hardware, right? So that's what that is. Oh, it's used in wire sizing,\nwhich is actually really cool.",
    "start": "3619300",
    "end": "3626450"
  },
  {
    "text": "So I've seen people use this for\ncircuit design and wire sizing, where they-- they're,\nlet's say, generating--",
    "start": "3626450",
    "end": "3633370"
  },
  {
    "text": "let's say you're synthesizing--\nwhich is their word for optimizing--",
    "start": "3633370",
    "end": "3639980"
  },
  {
    "text": "a power-- a power distribution\nnetwork on a chip, right? So what you do is you put\nin a whole bunch of wires",
    "start": "3639980",
    "end": "3646880"
  },
  {
    "text": "you have no-- it's like you put in fact\nan entire mesh in, right? You have no intention of\nactually implementing a mesh",
    "start": "3646880",
    "end": "3653270"
  },
  {
    "text": "because it's going\nto be too expensive. So you do that. You write down the conditions. It's all pretty\nstraightforward, right?",
    "start": "3653270",
    "end": "3658915"
  },
  {
    "text": "There's total amounts\nof current that have to be go various places. And anyway. So you do that,\nthat's going to be C.",
    "start": "3658915",
    "end": "3665240"
  },
  {
    "text": "And then your\nvariables are the-- actually weirdly that's--\nit's the width of the wires. They have a constant height so\nit's also the cross-- basically",
    "start": "3665240",
    "end": "3673040"
  },
  {
    "text": "the cross sectional area. And then, when you do\nthat, what you'll find? Is it'll synthesize--\nit'll actually",
    "start": "3673040",
    "end": "3679250"
  },
  {
    "text": "choose which wires to use. So you started with\na big mesh and then you'll end up with something. It has to be connected.",
    "start": "3679250",
    "end": "3684830"
  },
  {
    "text": "Because otherwise, you\nprobably wouldn't end up-- you wouldn't meet\nyour specs, right? Because one of your specs\nis that you power up every",
    "start": "3684830",
    "end": "3690320"
  },
  {
    "text": "module on your circuit. So how many people know\nabout that kind of stuff?",
    "start": "3690320",
    "end": "3698508"
  },
  {
    "text": "I ain't getting you. Giving examples that no\none gets, but that's OK. I mean, the basic idea though is\npretty straightforward, right?",
    "start": "3698508",
    "end": "3708220"
  },
  {
    "text": "So OK. So these are examples\nof these things.",
    "start": "3708220",
    "end": "3713920"
  },
  {
    "text": "OK. Now we get to machine\nlearning and statistics. You have sparse modeling and\nregressor selection, right?",
    "start": "3713920",
    "end": "3720100"
  },
  {
    "text": "So here, this is not the-- this is not the\nnotation that someone",
    "start": "3720100",
    "end": "3725287"
  },
  {
    "text": "in statistics or machine\nlearning would use, but too bad. So here x, which someone else\nmight call theta or beta,",
    "start": "3725287",
    "end": "3732860"
  },
  {
    "text": "depends on which what your\nstatistics identity is or machine learning identity is.",
    "start": "3732860",
    "end": "3740109"
  },
  {
    "text": "But here, you're\nsimply saying please-- it says please select k out\nof the number of features.",
    "start": "3740110",
    "end": "3747250"
  },
  {
    "text": "I guess m, is that right? Nope. n. So please choose k features to\nuse to fit the model, right?",
    "start": "3747250",
    "end": "3755980"
  },
  {
    "text": "So by the way, that's a\nvery strong and pretty good regularizer or something\nlike that, right?",
    "start": "3755980",
    "end": "3761350"
  },
  {
    "text": "OK. And I mean, you could do this\nby trying all n choose k choices",
    "start": "3761350",
    "end": "3767230"
  },
  {
    "text": "and lots of examples people have\nthings like you could write it as a penalized form.",
    "start": "3767230",
    "end": "3774310"
  },
  {
    "text": "You could find\nthe sparsest model that gives you a certain-- that gives you a\ncertain performance.",
    "start": "3774310",
    "end": "3782410"
  },
  {
    "text": "I guess this would be\non your training data. Everybody got that? So that'd be find me the\nsparsest thing that actually",
    "start": "3782410",
    "end": "3788320"
  },
  {
    "text": "gives me the following\npre-specified performance on the training data. So OK.",
    "start": "3788320",
    "end": "3794589"
  },
  {
    "text": "So this is the sparse modeling\nand regressor selection. Sparse signal reconstruction.",
    "start": "3794590",
    "end": "3800109"
  },
  {
    "text": "This is a big deal. Maybe fading a\nlittle bit, but maybe",
    "start": "3800110",
    "end": "3805839"
  },
  {
    "text": "'90s through the\nmaybe five years ago was kind of a big deal.",
    "start": "3805840",
    "end": "3811510"
  },
  {
    "text": "And the typical\nthing there was this. As you'd say a measure-- what you want to do\nis estimate something",
    "start": "3811510",
    "end": "3817360"
  },
  {
    "text": "like x, I'll switch to\ntheir dialect, right? So a would be a basis, which\ndrives the columns of a",
    "start": "3817360",
    "end": "3827440"
  },
  {
    "text": "would be a basis for the signals\nexcept that, I don't know,",
    "start": "3827440",
    "end": "3832450"
  },
  {
    "text": "since 1820 everyone\nagreed what a basis was. And people in signal\nprocessing decided",
    "start": "3832450",
    "end": "3837685"
  },
  {
    "text": "that they would use\ntheir own meaning for it. And they just dropped the fact\nthat they were independent.",
    "start": "3837685",
    "end": "3843880"
  },
  {
    "text": "I couldn't make this stuff up. And then people challenged\nthem and they'd say, oh no. You're misunderstanding.",
    "start": "3843880",
    "end": "3849280"
  },
  {
    "text": "This is an overcomplete\nbasis, right? Which, by the way,\nhere's another--",
    "start": "3849280",
    "end": "3854980"
  },
  {
    "text": "you want to know how you\ndescribe an overcomplete basis? It's a set of vectors. That's what it is. It has no other properties.",
    "start": "3854980",
    "end": "3860800"
  },
  {
    "text": "Anyway, don't get\nme started on that. But they would say so the\ncolumns of A would be-- they",
    "start": "3860800",
    "end": "3865930"
  },
  {
    "text": "would call that\ntheir basis, right? Even though if they said\nthat to any normal person",
    "start": "3865930",
    "end": "3871900"
  },
  {
    "text": "not in that particular\nsub, sub, subfield, they would interpret that\nthey'd say oh, that's cool. It's a basis.",
    "start": "3871900",
    "end": "3877700"
  },
  {
    "text": "Great. Meaning, they're linearly\nindependent and span. It doesn't matter.",
    "start": "3877700",
    "end": "3882849"
  },
  {
    "text": "[? You ?] do that. And then they\nwould say the thing I'm looking for is\nsparse in that basis.",
    "start": "3882850",
    "end": "3888050"
  },
  {
    "text": "So you'd hear things like this. You'd say, well, I think that\nthe MRI image I want to recover",
    "start": "3888050",
    "end": "3896150"
  },
  {
    "text": "is sparse in this wavelet basis. That would be the typical kind\nof thing they would say, right?",
    "start": "3896150",
    "end": "3902780"
  },
  {
    "text": "And that's fine. Anyway. So that you'd end up with things\nthat would look like this. And that would be\nthese are generally",
    "start": "3902780",
    "end": "3909020"
  },
  {
    "text": "things like sparse\nsignal reconstruction. So OK. ",
    "start": "3909020",
    "end": "3915569"
  },
  {
    "text": "Another one, which is\nactually very interesting, this is less often spoken of\nI think is handling outliers,",
    "start": "3915570",
    "end": "3925410"
  },
  {
    "text": "right? This actually\nmakes sense, right? What you should have\nin your mind by now--",
    "start": "3925410",
    "end": "3932670"
  },
  {
    "text": "and I imagine already do-- is that when I say\nsomething like L1,",
    "start": "3932670",
    "end": "3938550"
  },
  {
    "text": "different things\nshould come up, right? A picture in your\nmind should come up. As you come up as,\nlet's say, a sparsifier.",
    "start": "3938550",
    "end": "3945390"
  },
  {
    "text": "And what sparsifying about it? That point at the bottom. Because roughly\nspeaking, what happens",
    "start": "3945390",
    "end": "3950490"
  },
  {
    "text": "is the pressure to\nmove something to zero keeps up until\nyou're zero, right?",
    "start": "3950490",
    "end": "3957050"
  },
  {
    "text": "There's another property of L1. You also know that it's a-- when it's a penalty, it's\nsomething that's robust, right?",
    "start": "3957050",
    "end": "3964610"
  },
  {
    "text": "And you might--\nbecause what happens is that means that for large\nvalues, it grows slowly.",
    "start": "3964610",
    "end": "3970400"
  },
  {
    "text": "It grows as slowly as a\nconvex penalty can, right? And that you would use to do\nthings like to do sparse stuff.",
    "start": "3970400",
    "end": "3978920"
  },
  {
    "text": "You could have a\nHuber penalty, right? Where it starts out as--\nit starts out as a square",
    "start": "3978920",
    "end": "3984900"
  },
  {
    "text": "and then transitions\nto linear, right? So it looks like an\nL1 for large things.",
    "start": "3984900",
    "end": "3990650"
  },
  {
    "text": "And then that's\ngoing to play really well when there are really big\noutliers in your data, right? So these-- OK.",
    "start": "3990650",
    "end": "3996440"
  },
  {
    "text": "These are things you should\nhave in your mind by now I hope. So it shouldn't\nbe too surprising",
    "start": "3996440",
    "end": "4002260"
  },
  {
    "text": "that the problem of\nhandling outliers",
    "start": "4002260",
    "end": "4007816"
  },
  {
    "text": "is related to this\ncardinality thing. ",
    "start": "4007816",
    "end": "4013560"
  },
  {
    "text": "So here's the measurement model. It says I'm going to\nmeasure some things. They are linear\nfunctions of the thing I want to guess which\nis x plus a Gaussian.",
    "start": "4013560",
    "end": "4022110"
  },
  {
    "text": "That's fine. And then plus wi. wi is simply assumed\nto be sparse.",
    "start": "4022110",
    "end": "4027780"
  },
  {
    "text": "Now what this means? Otherwise, that we have no-- I say nothing about\nthe size of ai.",
    "start": "4027780",
    "end": "4033255"
  },
  {
    "text": "I have no statistical\nmodel for wi, sorry. I have no statistical model. Nothing. I just say it's sparse.",
    "start": "4033255",
    "end": "4038280"
  },
  {
    "text": "Oh, and it has only k nonzeros. And what this really\nmeans is that k up to k of these measurements\nare completely wrong.",
    "start": "4038280",
    "end": "4047100"
  },
  {
    "text": "Because wi can be anything. We didn't say what wi could be. So it basically says,\nI'm going to give you",
    "start": "4047100",
    "end": "4052500"
  },
  {
    "text": "a bunch of measurements. I'll give you m measurements. I will tell you the\nfollowing. k of them",
    "start": "4052500",
    "end": "4057810"
  },
  {
    "text": "can be completely wrong. And then you'd say\nplease fit a model.",
    "start": "4057810",
    "end": "4063480"
  },
  {
    "text": "Everybody following this? So that's a very strong\noutlier formulation.",
    "start": "4063480",
    "end": "4068490"
  },
  {
    "text": "Handling an outlier-- but it's\na perfectly good one, right? And you could write\nthis lots of ways.",
    "start": "4068490",
    "end": "4074800"
  },
  {
    "text": "One way is you could\nwrite it this way. It says that you are\ngoing to select--",
    "start": "4074800",
    "end": "4079950"
  },
  {
    "text": "you're going to select\nthe measurements. And you will select--",
    "start": "4079950",
    "end": "4085200"
  },
  {
    "text": "you're going to select a set\nof measurements to ignore. So you're going to say thank\nyou for your n measurements.",
    "start": "4085200",
    "end": "4092550"
  },
  {
    "text": "In my opinion, I'm going to-- I think that the 11th, the\n22nd, the 48th, and the 137th,",
    "start": "4092550",
    "end": "4099089"
  },
  {
    "text": "I think they're\ncomplete nonsense. I don't believe them, right? So you take that and\nthen you would solve--",
    "start": "4099090",
    "end": "4104825"
  },
  {
    "text": "you would toss them out\nand solve the least squares problem. And you can rewrite\nthat immediately as just a simple\ncardinality constraint.",
    "start": "4104825",
    "end": "4112170"
  },
  {
    "text": "It looks like this, right? Let's walk through this. ",
    "start": "4112170",
    "end": "4118580"
  },
  {
    "text": "w, other than this, it's\nnot constrained at all. So if a wi is nonzero, this\nwi can be anything you like.",
    "start": "4118580",
    "end": "4125794"
  },
  {
    "text": "And I can actually choose that\nwi to equal this residual here.",
    "start": "4125794",
    "end": "4131060"
  },
  {
    "text": "In which case, that\nmeans y is ax, right? So that's fine. So if you work out what this is,\nit's exactly the same as that.",
    "start": "4131060",
    "end": "4139170"
  },
  {
    "text": "That makes sense? There, so that's the idea there.",
    "start": "4139170",
    "end": "4145229"
  },
  {
    "text": "OK.  Fascinating area\nhas to do with--",
    "start": "4145229",
    "end": "4151089"
  },
  {
    "text": "we talked a little bit about\nthis when we talked about phase one methods is minimum\nnumber of violations.",
    "start": "4151090",
    "end": "4156278"
  },
  {
    "text": "So I give you a set of\nconvex constraints like m specifications or something.",
    "start": "4156279",
    "end": "4163479"
  },
  {
    "text": "If they're all feasible, great. If they're not all\nfeasible, then I might want to say\nsomething like this.",
    "start": "4163479",
    "end": "4170810"
  },
  {
    "text": "Please find an x that\nviolates as few as possible. Make sense?",
    "start": "4170810",
    "end": "4177290"
  },
  {
    "text": "That would be the picture. You could put weights on it. It doesn't matter. But here, just violate them\nas few as few as possible.",
    "start": "4177290",
    "end": "4184170"
  },
  {
    "text": "And so that, you could\nwrite down this way. I introduce a slack variable t.",
    "start": "4184170",
    "end": "4189318"
  },
  {
    "text": "If t is zero, then it\nmeans you've actually satisfied the i-th inequality.",
    "start": "4189319",
    "end": "4194550"
  },
  {
    "text": "But if t is positive, it means\nyou might not have, right?",
    "start": "4194550",
    "end": "4199741"
  },
  {
    "text": "And, of course, if you're\nminimizing the cardinality, if you did satisfy it, you'd\ntake t equals 0 here, right? So this does exactly what\nyou're asked to do, right?",
    "start": "4199742",
    "end": "4209840"
  },
  {
    "text": "This makes sense? So this would be that-- Yeah. And we'll see all sorts\nof cool things happen.",
    "start": "4209840",
    "end": "4216150"
  },
  {
    "text": "Yes? Well, isn't this like the\nfeasibility thing we did. We had like one transpose s--",
    "start": "4216150",
    "end": "4221690"
  },
  {
    "text": "Yes. We could solve that one, right? Yes, you can. Yeah. OK. You have to be very careful.",
    "start": "4221690",
    "end": "4227447"
  },
  {
    "text": "You can quote, \"solve,\" unquote\nit if that's what you mean. But I guess here the\nright way is-- the way",
    "start": "4227447",
    "end": "4232639"
  },
  {
    "text": "to say it that's\nofficial would be to say we have a powerful\nheuristic for approximately",
    "start": "4232640",
    "end": "4238940"
  },
  {
    "text": "solving that problem comma\nbased on convex optimization. That would be the\ntrue statement.",
    "start": "4238940",
    "end": "4245260"
  },
  {
    "text": "You can't solve this problem. OK. Right. Well, you can if there's\n10 inequalities, right?",
    "start": "4245260",
    "end": "4252518"
  },
  {
    "text": "But other than that, you can't. If there's 100 inequalities,\nyou can't solve that problem. [INAUDIBLE] maybe I'm\njust misremembering.",
    "start": "4252518",
    "end": "4258910"
  },
  {
    "text": "I thought that's what\nwe were doing when we had like the 1 transpose s-- Nope. Nope.",
    "start": "4258910",
    "end": "4264010"
  },
  {
    "text": "The 1 transpose s on the\nslack, that was simply a heuristic for approximately\nsolving that problem,",
    "start": "4264010",
    "end": "4272200"
  },
  {
    "text": "but you don't\nsolve that problem. OK. Yeah. I mean, you might\nsolve it, but you won't know you've solved it.",
    "start": "4272200",
    "end": "4278050"
  },
  {
    "text": "That's another way\nto say it, right? Yeah. In fact, in many cases,\nyou probably do, right?",
    "start": "4278050",
    "end": "4286179"
  },
  {
    "text": "Yeah. So and yes, they're going to\nbe related to this, right? ",
    "start": "4286180",
    "end": "4292945"
  },
  {
    "text": "OK. So good example is\na linear classifier. So I give you a whole bunch\nof points with labels, right?",
    "start": "4292945",
    "end": "4302170"
  },
  {
    "text": "Say with a Boolean label, yi. And you know, what you want is\nyou want to find w and v. Yeah.",
    "start": "4302170",
    "end": "4310280"
  },
  {
    "text": "So this says that you want\nthis to look like that. You want all these to be less\nthan or equal to zero or bigger",
    "start": "4310280",
    "end": "4316430"
  },
  {
    "text": "and equal zero. It wouldn't matter whatever\nyour convention is, right? And so then you\ncan rewrite this.",
    "start": "4316430",
    "end": "4322770"
  },
  {
    "text": "If you want the\nclassifier that makes the fewest number\nof mistakes, it's going to be one of these\nconvex cardinalities.",
    "start": "4322770",
    "end": "4330380"
  },
  {
    "text": "It's going to be\nthis one, right? By the way, when we do\nour magic or approximation",
    "start": "4330380",
    "end": "4338659"
  },
  {
    "text": "or whatever it is and we\nmake this into an L1 problem, what do you imagine this is\ngoing to turn into roughly?",
    "start": "4338660",
    "end": "4344905"
  },
  {
    "text": " It's going to turn into a\nsupport vector machine roughly,",
    "start": "4344905",
    "end": "4351170"
  },
  {
    "text": "right? So in fact, if I add\nL2 regularization, that's exactly what it is. So OK. ",
    "start": "4351170",
    "end": "4361510"
  },
  {
    "text": "Here's another weird one,\nwhich is not the same. So the story starts\nthe same way.",
    "start": "4361510",
    "end": "4367870"
  },
  {
    "text": "I have a set of\ninfeasible inequalities. In the previous story, which\nwas a weird positive 1,",
    "start": "4367870",
    "end": "4374110"
  },
  {
    "text": "it would basically say\nignore the fewest number of inequalities to make that\nfeasible and you go cool.",
    "start": "4374110",
    "end": "4381370"
  },
  {
    "text": "Of your 22 inequalities,\nI'm going to-- if I just toss out these\nfive, then the rest",
    "start": "4381370",
    "end": "4387130"
  },
  {
    "text": "I can make feasible. Everybody-- that's\nwhat we're doing? This one says to identify\nwhat is the essence",
    "start": "4387130",
    "end": "4393940"
  },
  {
    "text": "of the mutual infeasibility. So what you're going to do\nis take the original 22. They're mutually infeasible.",
    "start": "4393940",
    "end": "4399490"
  },
  {
    "text": "And I want to get a\nsubset of, let's say, ideal would be like three. I could say the\nfifth, 10th, and 11th.",
    "start": "4399490",
    "end": "4407800"
  },
  {
    "text": "Those three together\nare infeasible. That means, you can forget\nabout the other 19, right?",
    "start": "4407800",
    "end": "4413830"
  },
  {
    "text": "Because it says that's where--\nit's somewhere in these three. And then you negotiate\nand you go back",
    "start": "4413830",
    "end": "4419680"
  },
  {
    "text": "and you find-- you look at\nthese three inequalities that are the bottleneck and you\ntry to figure out some way",
    "start": "4419680",
    "end": "4426845"
  },
  {
    "text": "to either expand or\nwhatever to go and negotiate for a bigger right-hand side\ninequality or something.",
    "start": "4426845",
    "end": "4432320"
  },
  {
    "text": "Bigger budget. OK. So that's it.",
    "start": "4432320",
    "end": "4437429"
  },
  {
    "text": "So this also is going to\nwork that way as well. So if here, if you work out\nthe certificate of infeasible--",
    "start": "4437430",
    "end": "4447080"
  },
  {
    "text": "of infeasibility,\nit basically says that if the inf over x--\nthis is the dual function. If that's bigger\nthan or equal to 1,",
    "start": "4447080",
    "end": "4452960"
  },
  {
    "text": "actually all you need is to be\npositive, but it's homogeneous. So that's good enough. If lambda is positive and this\n[INAUDIBLE] is bigger than 1,",
    "start": "4452960",
    "end": "4461030"
  },
  {
    "text": "then this collection\nhere of inequalities is mutually infeasible. And so now what\nyou're going to do",
    "start": "4461030",
    "end": "4467270"
  },
  {
    "text": "is you simply minimize\nthe cardinality. So you'd put a comment\nnext to these things. You'd put a comment\nhere that said",
    "start": "4467270",
    "end": "4473630"
  },
  {
    "text": "this is a certificate proving\nthat these inequalities are mutually infeasible.",
    "start": "4473630",
    "end": "4480395"
  },
  {
    "text": "And if you put-- if you\nminimize the cardinality, you will get this-- you\nwill get the smallest group",
    "start": "4480395",
    "end": "4487520"
  },
  {
    "text": "subset of mutually infeasible\ninequalities, right?",
    "start": "4487520",
    "end": "4492830"
  },
  {
    "text": "So which is actually\nvery cool, right? I mean, could be quite useful.",
    "start": "4492830",
    "end": "4498110"
  },
  {
    "text": "OK. We'll give one more\nexample and then we'll come back next\ntime and talk about what",
    "start": "4498110",
    "end": "4503990"
  },
  {
    "text": "to do about these, right? You also get things in-- I mean, here's an\nexample from finance.",
    "start": "4503990",
    "end": "4509000"
  },
  {
    "text": "That doesn't apply\nto big hedge funds, but it does apply\nto people, right?",
    "start": "4509000",
    "end": "4515360"
  },
  {
    "text": "This actually comes up in\nactually in crypto trading. It's the same story.",
    "start": "4515360",
    "end": "4520789"
  },
  {
    "text": "What happens is the following. You have a trading\nfee, which might be proportional, first\nof all, to the amount",
    "start": "4520790",
    "end": "4528080"
  },
  {
    "text": "that you buy or sell. That's normal. But you also have one\nthat says that is actually",
    "start": "4528080",
    "end": "4535580"
  },
  {
    "text": "if you buy or sell at all, I'm\ngoing to charge you $3 or $9 or something like that.",
    "start": "4535580",
    "end": "4540875"
  },
  {
    "text": "And I forget what this is\ncalled in crypto trading, but you have to provide\na gas fee or something.",
    "start": "4540875",
    "end": "4548510"
  },
  {
    "text": "Anyway something\nlike that, right? And that's what it would be. If you propose to trade it\nall, you pay a simple fee",
    "start": "4548510",
    "end": "4555650"
  },
  {
    "text": "to request the trade. In that case,\nthere would be no-- this alpha would be 0\nor something like that.",
    "start": "4555650",
    "end": "4561710"
  },
  {
    "text": "OK. And your budget constraint\nmight look like this. That 1 transpose\nx is-- so here, x",
    "start": "4561710",
    "end": "4569410"
  },
  {
    "text": "is either positive\nor negative, right? Or here. I guess we want to-- we're going\nto purchase some dollar amount.",
    "start": "4569410",
    "end": "4574927"
  },
  {
    "text": "So it's all positive. That's the gross cost of\nwhat you're going to buy.",
    "start": "4574927",
    "end": "4580750"
  },
  {
    "text": "This would be the linear-- the\nso-called linear cost here. And then this part\nwould be the charge",
    "start": "4580750",
    "end": "4588160"
  },
  {
    "text": "or simply, if you\nbuy 14 things, you're going to buy 14 times\nwhatever some fixed charges.",
    "start": "4588160",
    "end": "4593680"
  },
  {
    "text": "OK? And then you would end up with\na problem that looks like that, right? So without this, it's convex,\nof course, right, without that.",
    "start": "4593680",
    "end": "4603500"
  },
  {
    "text": "So without that, it's convex. That's an example. OK. So I think well, we're going\nto quit here for today.",
    "start": "4603500",
    "end": "4610150"
  },
  {
    "text": "Next time, we'll finish\nthis up and that'll maybe go until Tuesday. And then I'll reserve\nsome time for us",
    "start": "4610150",
    "end": "4616690"
  },
  {
    "text": "to wrap up the whole\ncourse as well. ",
    "start": "4616690",
    "end": "4624000"
  }
]
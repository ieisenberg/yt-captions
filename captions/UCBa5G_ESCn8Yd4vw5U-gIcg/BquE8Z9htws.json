[
  {
    "start": "0",
    "end": "5600"
  },
  {
    "text": "Good afternoon, CS109. How are you guys doing today? Whoop! Fantastic.",
    "start": "5600",
    "end": "10760"
  },
  {
    "text": "You guys know this, but\nit's our penultimate class. We have class today. We have a fun little\nlecture on Wednesday,",
    "start": "10760",
    "end": "17540"
  },
  {
    "text": "and then that's it\nfor lectures in CS109. I can't believe\nwe're at that part.",
    "start": "17540",
    "end": "23180"
  },
  {
    "text": "It feels like just yesterday. We were starting,\nand we're like, hey, let's talk about probabilities. And we were doing counting.",
    "start": "23180",
    "end": "28595"
  },
  {
    "text": "Oh, what good times. We have a very fun\ncelebratory lecture today.",
    "start": "28595",
    "end": "34525"
  },
  {
    "text": "We're at that part\nof the quarter where these aren't things\nthat will be on the exam. But it's also a really\nfun chance for me",
    "start": "34525",
    "end": "41600"
  },
  {
    "text": "to just talk about what\nI think is interesting and part of the\nfuture of probability.",
    "start": "41600",
    "end": "46700"
  },
  {
    "text": "And I have a novel\nlecture for you guys, one I've not given\nbefore and one that I'm really excited to give.",
    "start": "46700",
    "end": "52280"
  },
  {
    "text": "So I was thinking about\nwhat should we talk about. And there's all these\nfun things to talk about.",
    "start": "52280",
    "end": "58040"
  },
  {
    "text": "I was like, oh, I can\ntalk about KL divergence, or I can talk about bounds. And then something\nhappened last Thursday",
    "start": "58040",
    "end": "65483"
  },
  {
    "text": "that's really worth\ntalking about. As you might have\nheard, there was a new release of this large\nlanguage model called GPT.",
    "start": "65483",
    "end": "73080"
  },
  {
    "text": "Just quickly, has anyone\never heard of this? OK, it seems like something\nworth talking about.",
    "start": "73080",
    "end": "80190"
  },
  {
    "text": "Interestingly, it coincides. This last week was the\nworld's biggest AI conference.",
    "start": "80190",
    "end": "86180"
  },
  {
    "text": "In fact, we had a\ncouple of papers there. I decided to stay\nbecause I wanted to hang out with you guys. I got sick a couple\nof times this quarter,",
    "start": "86180",
    "end": "92040"
  },
  {
    "text": "and I just wanted to\nchill with my CS109 fam. But that's why\nyou're seeing so much happening in the world of AI.",
    "start": "92040",
    "end": "98000"
  },
  {
    "text": "And I thought long\nand hard about it. I just thought it would\nbe so neat for you guys to learn some of the probability\nbehind some of the biggest",
    "start": "98000",
    "end": "105710"
  },
  {
    "text": "movers and shakers of today. So in today's class, we're\ngoing to learn about how",
    "start": "105710",
    "end": "111290"
  },
  {
    "text": "Dall-E works how GPT-3 works. And if we have\ntime, I can tell you a little bit about some of my\nmost recent probability work",
    "start": "111290",
    "end": "118580"
  },
  {
    "text": "If you guys find\nthat interesting. Do you want to do it? So it's also going\nto be on the board.",
    "start": "118580",
    "end": "124399"
  },
  {
    "text": "So I practice and everything. We're going to try and\ndo this on the board. We're going to get rid of\nthe screen in a second,",
    "start": "124400",
    "end": "129412"
  },
  {
    "text": "but not quite yet,\nbecause before we jump into thinking about\nthe wonderful ideas behind these algorithms\nthat maybe are going",
    "start": "129412",
    "end": "136980"
  },
  {
    "text": "to have a rather\nprofound impact, let's just play a little bit. So if you haven't seen GPT,\nit's a pretty simple API.",
    "start": "136980",
    "end": "146040"
  },
  {
    "text": "You can write text, and\nit will produce text. So for example, here I \"write\na thought-provoking poem",
    "start": "146040",
    "end": "151938"
  },
  {
    "text": "that explains the difference\nbetween maximum likelihood parameter estimation and\nMAP parameter estimation, but it should be sung by\na pirate as a sea shanty.\"",
    "start": "151938",
    "end": "159510"
  },
  {
    "text": "So it says, \"Aye,\nye landlubbers, listen to me as I sing\nof parameter estimation of maximum likelihood in MAP.",
    "start": "159510",
    "end": "166050"
  },
  {
    "text": "Ye see two approaches, both\nwith their own reputation. Maximum likelihood it seeks\nto maximize the probability",
    "start": "166050",
    "end": "172689"
  },
  {
    "text": "of data that's seen. MAP adds a prior to\nregularize and balance this trade-off between\nbias and precision.\"",
    "start": "172690",
    "end": "179489"
  },
  {
    "text": "I feel like I got it to be\nmore piratey other times. But you can be like,\nOK, be more piratey.",
    "start": "179490",
    "end": "185250"
  },
  {
    "text": "How do you even spell piratey. Is that it? [LAUGHS] Oh, man.",
    "start": "185250",
    "end": "190800"
  },
  {
    "text": "\"Aye, ye scurvy dogs , lend\nan ear to the tale I spin of--\" and this is\nbehind the scenes,",
    "start": "190800",
    "end": "198620"
  },
  {
    "text": "a machine learning model, a\nlittle bit like we've learned. So that's one of\nthe things we're going to talk about today,\nwhat's going on with this model",
    "start": "198620",
    "end": "204980"
  },
  {
    "text": "and what are the\ngreat ideas behind it. What's the difference\nbetween what we've learned in CS109 and\nthe technology behind GPT?",
    "start": "204980",
    "end": "211430"
  },
  {
    "text": "But we're also going to talk\nabout a different model that might seem pretty separate,\nbut there is similar ideas",
    "start": "211430",
    "end": "218630"
  },
  {
    "text": "that go on behind the scenes. And this one doesn't\nproduce text, but instead, it produces images.",
    "start": "218630",
    "end": "223830"
  },
  {
    "text": "So I said a photo of a\nbeautiful coast live oak. These aren't real photos. They don't exist.",
    "start": "223830",
    "end": "229220"
  },
  {
    "text": "They were just generated. And you guys have\nprobably seen this before. I'm just trying to\ncatch everyone up.",
    "start": "229220",
    "end": "236360"
  },
  {
    "text": "And before we go to the board,\nthere's just one more picture that I want you guys\nto see before we",
    "start": "236360",
    "end": "242420"
  },
  {
    "text": "go in there because I'm\ngoing to, at some point, refer to Gaussian noise, and\nyou need to have a visualization",
    "start": "242420",
    "end": "248810"
  },
  {
    "text": "to go with it. So this is a picture\nwith no noise, and this is a picture\nwith some Gaussian noise.",
    "start": "248810",
    "end": "255180"
  },
  {
    "text": "And when I say some\nGaussian noise, notice how it looks blurred\nor a little bit distorted. Every single pixel has\nits original value,",
    "start": "255180",
    "end": "262510"
  },
  {
    "text": "but we've added some Gaussian\nsamples into the pixels. In this case, it's on both\nthe red or all red, green,",
    "start": "262510",
    "end": "270129"
  },
  {
    "text": "and blue channels. This is with a little\nbit of Gaussian noise. And this is with a\nton of Gaussian noise.",
    "start": "270130",
    "end": "276570"
  },
  {
    "text": "You can't even see\nthe dog anymore. OK, questions,\ncomments, thoughts",
    "start": "276570",
    "end": "281883"
  },
  {
    "text": "before we jump into this?  OK, let's make\nthat screen go up.",
    "start": "281883",
    "end": "287909"
  },
  {
    "text": "Let's get lights\nall on as bright as we can get it in\nthis NVIDIA auditorium. ",
    "start": "287910",
    "end": "298170"
  },
  {
    "text": "OK, so this is our roadmap. We're going to\nstart with thinking",
    "start": "298170",
    "end": "304770"
  },
  {
    "text": "about that second algorithm,\nthe one that can produce trees. And it's a really\ninteresting story.",
    "start": "304770",
    "end": "311310"
  },
  {
    "text": "And did you know it actually\ntook place at Stanford? The great idea behind\nhow you can create images",
    "start": "311310",
    "end": "317639"
  },
  {
    "text": "from neural networks\nwas a simple idea that happened here not too\nlong ago by a fellow called",
    "start": "317640",
    "end": "323700"
  },
  {
    "text": "Jascha Sohl-Dickstein. OK, so where should we start?",
    "start": "323700",
    "end": "329580"
  },
  {
    "text": "Maybe we could start by building\na little bit of a roadmap. And I want to put it\nhere in the center.",
    "start": "329580",
    "end": "335460"
  },
  {
    "text": "I want to talk about\nthe three models we should have in our minds. One model is what you're\ndoing for homework.",
    "start": "335460",
    "end": "341400"
  },
  {
    "text": "The second model is\ngoing to be this Dall-E. And the third model\nis going to be GPT. And on some level, they\nhave a lot in common.",
    "start": "341400",
    "end": "348310"
  },
  {
    "text": "They all have a\nbig neural network. Well, maybe yours has\na logistic regression, but we're going to think\nof them all as black boxes.",
    "start": "348310",
    "end": "355180"
  },
  {
    "text": "So if we start with\nyour algorithm, so this is your P set 6. ",
    "start": "355180",
    "end": "363010"
  },
  {
    "text": "You built a little machine\nlearning algorithm, and the machine learning\nalgorithm takes features which",
    "start": "363010",
    "end": "373280"
  },
  {
    "text": "come as a list, and it\nproduces a prediction y, which is an element of 0, 1,\nwhich is a really fancy way",
    "start": "373280",
    "end": "382550"
  },
  {
    "text": "of saying you built an algorithm\nthat could take some inputs, and it predicts out either\n01 binary prediction.",
    "start": "382550",
    "end": "389300"
  },
  {
    "text": "But we also want to\nadd in Dall-E here. And Dall-E does\nsomething different.",
    "start": "389300",
    "end": "396320"
  },
  {
    "text": "It's also a neural\nnetwork, but we're going to be making Dall-E tree style.",
    "start": "396320",
    "end": "401990"
  },
  {
    "text": "And what Dall-E tree does is\nit doesn't take any inputs. But every single time you\nrun this neural network,",
    "start": "401990",
    "end": "409039"
  },
  {
    "text": "it's going to\nproduce not a 0 or 1, but it's going to\nproduce an image.",
    "start": "409040",
    "end": "414470"
  },
  {
    "text": "And our version is always\ngoing to be an image of a tree. So let's get out\nour blue marker,",
    "start": "414470",
    "end": "421159"
  },
  {
    "text": "and let's draw ourselves\na little bit of a tree. Woohoo! ",
    "start": "421160",
    "end": "428800"
  },
  {
    "text": "What do you guys think? Not quite Dall-E, but\nit's an all-right drawing. And then the final\nneural network",
    "start": "428800",
    "end": "434818"
  },
  {
    "text": "we're going to think\nabout is going to be GPT.  And GPT takes in some text\nlike \"I--\" let's say you wrote,",
    "start": "434818",
    "end": "446390"
  },
  {
    "text": "\"I love,\" and you throw\nit into the model,",
    "start": "446390",
    "end": "453720"
  },
  {
    "text": "and it produces more text. So let's say \"CS109\nand pancakes.\"",
    "start": "453720",
    "end": "460500"
  },
  {
    "start": "460500",
    "end": "466060"
  },
  {
    "text": "OK, so that's our goal. Let's see if we can\nunderstand these three. Now, hopefully,\nyou're understanding",
    "start": "466060",
    "end": "471970"
  },
  {
    "text": "your own problem set 6. So maybe we could start by\njumping into thinking about how",
    "start": "471970",
    "end": "477280"
  },
  {
    "text": "this Dall-E model works. Can I start with just asking\nyou to come up with it,",
    "start": "477280",
    "end": "485020"
  },
  {
    "text": "because there is a history here? In this task of running\na neural network",
    "start": "485020",
    "end": "490990"
  },
  {
    "text": "and having it produce\nan image, there's been a long history of\ncool, creative ideas.",
    "start": "490990",
    "end": "496120"
  },
  {
    "text": "One creative idea\nthat's no longer used is you'd have two\ndifferent neural networks.",
    "start": "496120",
    "end": "501250"
  },
  {
    "text": "One neural network\nwould create images, and the other neural\nnetwork would try and decide was this image\nproduced by a computer",
    "start": "501250",
    "end": "508240"
  },
  {
    "text": "or was it produced-- is it an\nactual image from the internet? And these two competing\nneural networks",
    "start": "508240",
    "end": "513429"
  },
  {
    "text": "would train against each other,\nand eventually, one of them would get really, really\ngood at producing images that would trick the other one.",
    "start": "513429",
    "end": "519729"
  },
  {
    "text": "That was a great idea. But as I said, Stanford,\nnot too long ago, someone had another great\nidea that changed the game.",
    "start": "519730",
    "end": "525328"
  },
  {
    "text": "It's a great idea that you're\ngoing to understand deeply by the end of today's class. But I wanted to just give\nyou guys an idea to play.",
    "start": "525328",
    "end": "531830"
  },
  {
    "text": "Come up with your wild ideas. Just make up way. If I said you had to create\na neural network that's",
    "start": "531830",
    "end": "537680"
  },
  {
    "text": "going to generate a picture of\na tree, how would you do it? And some of the questions\nyou can ask yourself",
    "start": "537680",
    "end": "542700"
  },
  {
    "text": "are, what data would I use? And then what would\nI do with the data?",
    "start": "542700",
    "end": "549030"
  },
  {
    "text": "Imagine somebody gives\nyou a big neural network, how could you set the parameters\nof that neural network with some data?",
    "start": "549030",
    "end": "555260"
  },
  {
    "text": "Have a moment. Just be playful. Make up ideas. Say something silly. Be like, I'll send\nmy neural network to a pirate who knows so\nmuch about maximum likelihood",
    "start": "555260",
    "end": "561890"
  },
  {
    "text": "estimation that they'll\nfigure out all the parameters. Have a good time. Think about it for\na second before we jump into what is the\ngreat idea behind Dall-E.",
    "start": "561890",
    "end": "569300"
  },
  {
    "text": "OK, talk to the person next\nto you, and I'll take a moment and practice my tree drawing. [SIDE CONVERSATIONS]",
    "start": "569300",
    "end": "576260"
  },
  {
    "start": "576260",
    "end": "677120"
  },
  {
    "text": "No expectations. But there's a small chance\nthat we'll just totally revolutionize the world because\nthis is such an open field.",
    "start": "677120",
    "end": "685009"
  },
  {
    "text": "OK, let's hear them. Good ideas, bad ideas, funny\nideas, we'll take them all. OK, what's your thoughts?",
    "start": "685010",
    "end": "690269"
  },
  {
    "text": "So for Dall-E, what\nI would do is-- I was like\n[INAUDIBLE] for trees. I'd scrape Google,\npunch images of trees,",
    "start": "690270",
    "end": "698810"
  },
  {
    "text": "and then have Dall-E\ncreate a bunch of images and then see which\none most closely matches the data set of trees.",
    "start": "698810",
    "end": "705199"
  },
  {
    "text": "OK, scrape Google,\nproduce an image,",
    "start": "705200",
    "end": "712730"
  },
  {
    "text": "and then the loss can be\nsomething like distance to the closest tree. ",
    "start": "712730",
    "end": "722060"
  },
  {
    "text": "Great. Fantastic. OK, yes, an idea. Try and make a network to\nidentify trees and then,",
    "start": "722060",
    "end": "729470"
  },
  {
    "text": "in some sense,\nrun it in reverse. Ooh, OK. So we're going to have a tree\nnetwork like ours over here.",
    "start": "729470",
    "end": "736530"
  },
  {
    "text": "And you put in a picture\nand either say tree or not. But we're going to\nthen run it in reverse, and we're going to say,",
    "start": "736530",
    "end": "741970"
  },
  {
    "text": "OK, you're a tree\nmess with my pixels. Oh, I like it.",
    "start": "741970",
    "end": "747420"
  },
  {
    "text": "Reverse a classification\nimage or a predictor.",
    "start": "747420",
    "end": "756825"
  },
  {
    "text": "Sorry. ",
    "start": "756825",
    "end": "764930"
  },
  {
    "text": "Yes, one more idea. So maybe you produce three\nimages, one of the red pixels,",
    "start": "764930",
    "end": "770000"
  },
  {
    "text": "green pixels, and blue pixels. And so you have multiple\nvariable outputs. And then, for each\nof those outputs,",
    "start": "770000",
    "end": "776300"
  },
  {
    "text": "you have 256 values\nthat it could be. And so you take all of the\npictures in that you've",
    "start": "776300",
    "end": "781610"
  },
  {
    "text": "scraped from Google\nand then evaluate, what's the probability that\nin a picture of a tree, this particular pixel has\nthis particular level?",
    "start": "781610",
    "end": "789260"
  },
  {
    "text": "Oh, OK. So you said a lot\nof good things. One is when we're\nmaking this picture, we're going to have\nto not just output 01,",
    "start": "789260",
    "end": "796279"
  },
  {
    "text": "but we have to output\nthe pixel values. That's going to mean the red,\ngreen, and blue pixel values. So that's going to be our task.",
    "start": "796280",
    "end": "802160"
  },
  {
    "text": "And then you said\nwe could set it up so that we say the most\nlikely pixel, or the Pixel",
    "start": "802160",
    "end": "808760"
  },
  {
    "text": "that's most likely\ngiven what we've seen. OK, great.",
    "start": "808760",
    "end": "814010"
  },
  {
    "text": "So we're going to have\nto predict pixel values.",
    "start": "814010",
    "end": "821350"
  },
  {
    "text": "Awesome. And we want maybe the\nmost likely given tree.",
    "start": "821350",
    "end": "831630"
  },
  {
    "text": "OK, these are all\nvery, very good ideas. ",
    "start": "831630",
    "end": "839610"
  },
  {
    "text": "Shall we go into-- because\nit's the beauty of what goes behind Dall-E is\nthat it's when you see it,",
    "start": "839610",
    "end": "845459"
  },
  {
    "text": "you'll be like, oh, OK, let's\nget behind the probability. But I can appreciate\nthat it works.",
    "start": "845460",
    "end": "852310"
  },
  {
    "text": "Now, one of the things that's\ncomplicated about the world is you've got all these\nimages, but on Google,",
    "start": "852310",
    "end": "860610"
  },
  {
    "text": "say, not all of\nthem have labels. You can get lots and lots\nand lots of pictures. Some of them might have\nlabels that say what they are,",
    "start": "860610",
    "end": "869190"
  },
  {
    "text": "but some of them won't. And there is this\ninteresting idea.",
    "start": "869190",
    "end": "875519"
  },
  {
    "text": "You could take any\nimage, picture of a tree, and here's something\nyou could do to it.",
    "start": "875520",
    "end": "880980"
  },
  {
    "text": "We'll explain why you\nmay want to do that. But here's something you can do. At the moment, it's a\nlittle bit unmotivated.",
    "start": "880980",
    "end": "888480"
  },
  {
    "text": "Take your picture. And one of the\nthings you could do",
    "start": "888480",
    "end": "894070"
  },
  {
    "text": "is you could break your picture. And one of the ways you\ncould break your picture is you could adding\nin some noise.",
    "start": "894070",
    "end": "901420"
  },
  {
    "text": "And let's say you\nchose Gaussian noise. Yeah, that's a pretty\nreasonable thing to do. So I'm going to\nadd in 20% noise.",
    "start": "901420",
    "end": "911410"
  },
  {
    "text": "And my 20% noise may\nbe like 1 in 5 pixels. I can add in some\nGaussian noise.",
    "start": "911410",
    "end": "920042"
  },
  {
    "text": "So to give you an idea\nof what that looks like, if we zoomed into\nsome pixel, pretend",
    "start": "920042",
    "end": "926310"
  },
  {
    "text": "for a moment that\npixel-- all our pictures are black and white. This is the black and white. ",
    "start": "926310",
    "end": "935070"
  },
  {
    "text": "We're like the artsy version. Imagine every pixel\nis black and white.",
    "start": "935070",
    "end": "940113"
  },
  {
    "text": "That makes it a\nlittle bit easier. We don't have to think\nabout red, green, and blue. It's just that if you zoomed\ninto any pixel of a tree--",
    "start": "940113",
    "end": "946889"
  },
  {
    "text": "if you looked at a pixel,\nit would just have a number. And let's say those numbers\nare between 0 and 1. So let's say this is a 0.5.",
    "start": "946890",
    "end": "955340"
  },
  {
    "text": "When we add in Gaussian\nnoise, here's what I mean. For some of these\npixels, we're going",
    "start": "955340",
    "end": "960770"
  },
  {
    "text": "to add in a random\nsample from a Gaussian. And we could choose\nany Gaussian.",
    "start": "960770",
    "end": "966050"
  },
  {
    "text": "But let's say we chose a pretty\nreasonable Gaussian that has a mean of 0 and some variance.",
    "start": "966050",
    "end": "972319"
  },
  {
    "text": "And so maybe when you\nsampled from this Gaussian, you got like a 0.1.",
    "start": "972320",
    "end": "977360"
  },
  {
    "text": "So then the resulting\npixel value is 0.6. So when I say adding\nGaussian noise,",
    "start": "977360",
    "end": "984649"
  },
  {
    "text": "it's something that you\nguys could do right now. You could pull up a computer. And if I gave you\na pixel value, you could do, hey, SciPy,\nsample from a Gaussian",
    "start": "984650",
    "end": "992960"
  },
  {
    "text": "with a particular mean\nand a particular variance, and then add that to\nmy old pixel value.",
    "start": "992960",
    "end": "1000620"
  },
  {
    "text": "And you could do this. You could then take\nthis image, and do you know what you could do?",
    "start": "1000620",
    "end": "1006008"
  },
  {
    "text": "You'd be like, not noisy enough. I'm going to add a\nlittle bit more noise.",
    "start": "1006008",
    "end": "1011720"
  },
  {
    "text": "So you can say I want\nsomething with 40%. And then, eventually,\nyou could keep",
    "start": "1011720",
    "end": "1017760"
  },
  {
    "text": "going until you've just got\nthe world's noisiest image.",
    "start": "1017760",
    "end": "1024015"
  },
  {
    "text": " So we could add 20% noise, and\nwe could add another 20% noise.",
    "start": "1024015",
    "end": "1031540"
  },
  {
    "text": "And now it's just starting\nto look pretty noisy. And eventually, when\nyou get to 100% noise,",
    "start": "1031540",
    "end": "1038699"
  },
  {
    "text": "everything just looks like a\nrandom value from our Gaussian, and you just can't\nsee any tree anymore.",
    "start": "1038700",
    "end": "1046079"
  },
  {
    "text": "I haven't described\nany neural network. There's not a\nneural network here. It's just a way that you can\ntake all these gigantic tons",
    "start": "1046079",
    "end": "1053220"
  },
  {
    "text": "of images from the\ninternet, and you could start to manipulate them. But there's this\ngrowing mystery,",
    "start": "1053220",
    "end": "1060060"
  },
  {
    "text": "which is why would anyone want\nto do that to your poor images. You're making them\nharder to see.",
    "start": "1060060",
    "end": "1065980"
  },
  {
    "text": "Why is that a useful thing? ",
    "start": "1065980",
    "end": "1072640"
  },
  {
    "text": "Do you guys want to\ntry and think about it? I've left this tantalizing clue.",
    "start": "1072640",
    "end": "1078900"
  },
  {
    "text": "Just reflect on it. What could you do with this? Because I say-- when I say this\nis like a $1 million question,",
    "start": "1078900",
    "end": "1086213"
  },
  {
    "text": "I feel like the\nperson who figured this out is now one of the\nlead researchers at Google. So it probably was\nworth like $1 million",
    "start": "1086213",
    "end": "1092520"
  },
  {
    "text": "for the person who\ndid figure it out. It did. Yeah, probably. Jesus, what a time!",
    "start": "1092520",
    "end": "1099300"
  },
  {
    "text": "Well, you could do this\nto a lot of images. And why would that be nice?",
    "start": "1099300",
    "end": "1107180"
  },
  {
    "text": "OK, an idea? I think it is very\nsimilar to what you, Vijay said because you're\nstarting the outcome. ",
    "start": "1107180",
    "end": "1115070"
  },
  {
    "text": "So you know the outcome\nthen you're adding features that separat it. So you're constantly-- so it's\nconditioned on the outcome.",
    "start": "1115070",
    "end": "1122250"
  },
  {
    "text": "So constantly\nyou're adding noise. You're conditioning to\nwhat you [INAUDIBLE]",
    "start": "1122250",
    "end": "1127280"
  },
  {
    "text": "in such a way that it keeps\nlearning how the outcome should",
    "start": "1127280",
    "end": "1132650"
  },
  {
    "text": "look at various scenarios, so\nthat when you're [INAUDIBLE] do work. Yes, you're on to something\nthat is really, really",
    "start": "1132650",
    "end": "1139340"
  },
  {
    "text": "in the right direction. So yes, we're going in\nthe right direction. It has this relationship between\nthe outcome, the cleaner image,",
    "start": "1139340",
    "end": "1147410"
  },
  {
    "text": "and a noisier image.  Yeah.",
    "start": "1147410",
    "end": "1153440"
  },
  {
    "text": "Maybe you could deblur\nthe blurry images to create different trees.",
    "start": "1153440",
    "end": "1159320"
  },
  {
    "text": "Yeah, that's it. This is the first great idea. So the first great\nidea that changed",
    "start": "1159320",
    "end": "1165920"
  },
  {
    "text": "everything about\nimage generation is we",
    "start": "1165920",
    "end": "1171300"
  },
  {
    "text": "could build a little\nneural network. And its job is pretty simple. It doesn't have to do any\ncomplicated predictions.",
    "start": "1171300",
    "end": "1179019"
  },
  {
    "text": "So we're going to call\nthis an idea number one. And idea number\none is we're going",
    "start": "1179020",
    "end": "1184917"
  },
  {
    "text": "to build a neural network. It will take in an\nimage, and that image is going to be of\na tree, and it's",
    "start": "1184917",
    "end": "1196820"
  },
  {
    "text": "going to have some noise in it. Let's try and recreate that\nimage as well as we can.",
    "start": "1196820",
    "end": "1203630"
  },
  {
    "text": "And we're going to build\na little neural network. And this little neural\nnetwork, when it's done,",
    "start": "1203630",
    "end": "1213059"
  },
  {
    "text": "it will produce a picture that\nhas removed 20% of the noise.",
    "start": "1213060",
    "end": "1219040"
  },
  {
    "text": "So could you make this data set? Could you make your\ntraining and test set? ",
    "start": "1219040",
    "end": "1226290"
  },
  {
    "text": "Yeah, you can make\nyourself a big one. Take all of Google. Take all the images you've\ngot, add in noise, and then you",
    "start": "1226290",
    "end": "1232800"
  },
  {
    "text": "can feed it into your\nneural network and say, here's the noisy version,\ncan you predict an image?",
    "start": "1232800",
    "end": "1237870"
  },
  {
    "text": "And then I'll see how\ngood a job you are at removing the Gaussian noise. But that doesn't\ngenerate a whole tree.",
    "start": "1237870",
    "end": "1244559"
  },
  {
    "text": "That just removes some noise. So how could you generate\na tree like this?",
    "start": "1244560",
    "end": "1251030"
  },
  {
    "text": "Well, you start here. Generate random samples from\na Gaussian for every pixel,",
    "start": "1251030",
    "end": "1256759"
  },
  {
    "text": "then run that\ncompletely noisy version through your neural network. You'll end up with\nsomething with 80% noise.",
    "start": "1256760",
    "end": "1262353"
  },
  {
    "text": "Take the result, put it through\nyour neural network again. You'll end up with\nsomething 60% noise. Put it through your\nneural network again.",
    "start": "1262353",
    "end": "1267860"
  },
  {
    "text": "You have 40% noise,\nand you keep going. And eventually, it's got a tree. What if you want\na different tree?",
    "start": "1267860",
    "end": "1272929"
  },
  {
    "text": "You're like, that's\nnot pretty enough. I want a new one. You just start with\ndifferent random noises.",
    "start": "1272930",
    "end": "1278540"
  },
  {
    "text": "If you create\ndifferent random noise, you put in this\ncompletely noisy image through your neural network,\nand it'll try and remove noise",
    "start": "1278540",
    "end": "1285530"
  },
  {
    "text": "in a way that'll make it\nlook more like a tree. And you repeat this\nfive times, and you'll have a picture of a tree.",
    "start": "1285530",
    "end": "1290840"
  },
  {
    "text": "OK, questions, yes. In this example,\ndoes the black box-- is that strictly just removing\n20% percent noise on each step,",
    "start": "1290840",
    "end": "1298270"
  },
  {
    "text": "or do we have five [INAUDIBLE]\nfrom going to 100 to 81 from going from 80 to 61 from--",
    "start": "1298270",
    "end": "1304930"
  },
  {
    "text": "and incrementally like that? Just one box. Now, one of the\nthings that I've--",
    "start": "1304930",
    "end": "1311200"
  },
  {
    "text": "I'm going to try and give\nyou guys the great ideas. There are some small\ndetails that are helpful. I think this black\nbox also takes",
    "start": "1311200",
    "end": "1317800"
  },
  {
    "text": "in which step you're on as one\nof is Xs, one of its features.",
    "start": "1317800",
    "end": "1323280"
  },
  {
    "text": "But as I said, that's\nnot the great idea. And if you got rid of that, it\nwould probably be just fine. Yeah, just one box.",
    "start": "1323280",
    "end": "1329190"
  },
  {
    "text": "And they call that\nbox Dall-E. Yes.",
    "start": "1329190",
    "end": "1336929"
  },
  {
    "text": "Is it removing just\nrandom 20% noise, or is it more\nsophisticated than that? How does the training part work?",
    "start": "1336930",
    "end": "1343620"
  },
  {
    "text": "How is it getting feedback? So we'll talk about it\nin mathematical detail, I promise you, because you guys\ncould-- you guys, actually,",
    "start": "1343620",
    "end": "1351323"
  },
  {
    "text": "you're totally\nready to understand all the mathematical\nsophistication of precisely what it's doing. But let me give you\nthe big picture first.",
    "start": "1351323",
    "end": "1358320"
  },
  {
    "text": "It has both of these images. How? Because it generated them. And so it puts in one.",
    "start": "1358320",
    "end": "1364940"
  },
  {
    "text": "And actually, realistically, you\nend up with your predicted one.",
    "start": "1364940",
    "end": "1370009"
  },
  {
    "text": "And then there's the\ntrue image of the tree, and maybe the true\nimage of the tree is slightly different because\nwhen your neural network tried",
    "start": "1370010",
    "end": "1376940"
  },
  {
    "text": "to make a tree, it\ndidn't get it perfect. Oh, all the colors, you guys. This is such an enjoyable\nmarker experience.",
    "start": "1376940",
    "end": "1386190"
  },
  {
    "text": "So maybe, when you\nmade your prediction, you got it slightly wrong.",
    "start": "1386190",
    "end": "1391290"
  },
  {
    "text": "And when I say slightly\nwrong, what do I mean? Well, we know what the truth is.",
    "start": "1391290",
    "end": "1396830"
  },
  {
    "text": "We had the clean image, and then\nwe added the noise ourselves. So we have the input,\nand we have the truth.",
    "start": "1396830",
    "end": "1403850"
  },
  {
    "text": "And then we can see\nyour prediction. We can be like, how\ngood is that prediction? Now you ask, as I\npromised, not only",
    "start": "1403850",
    "end": "1410655"
  },
  {
    "text": "do I want to explain\nthis to you, guys. I want to give you the\nlevel of sophistication that you are ready for in CS109.",
    "start": "1410655",
    "end": "1416500"
  },
  {
    "text": "We'll talk about that detail,\nbut let's get that big picture first. Also, I want to explain\nmyself pedagogically.",
    "start": "1416500",
    "end": "1421640"
  },
  {
    "text": "I want to draw on the\nboard for lots of reasons. And one of the goals\nis to slow myself down, and so that we can\nkeep it all up on the board,",
    "start": "1421640",
    "end": "1428100"
  },
  {
    "text": "so you can see the big\npicture as it unfolds. Plus, it's fun for me. Yeah, a question. If we wanted to do\nthe full Dall-E,",
    "start": "1428100",
    "end": "1435390"
  },
  {
    "text": "so not just making trees\nbut making whatever would be train it to\ndeblur images in general,",
    "start": "1435390",
    "end": "1442440"
  },
  {
    "text": "and then instead of using\ncompletely random noise blur a tree or something else? So it's actually pretty simple.",
    "start": "1442440",
    "end": "1448773"
  },
  {
    "text": "I'm going to remove that\ndetail so we can just focus on the great idea. But the simple idea is\nyou also insert text.",
    "start": "1448773",
    "end": "1455970"
  },
  {
    "text": "So you say this is an oak tree,\nwhatever the prompt the user gave you, and that text can\nhelp it guide its denoising.",
    "start": "1455970",
    "end": "1465059"
  },
  {
    "text": "Now, when we\nunderstand GPT, we'll have a better sense of\nhow you could do that.",
    "start": "1465060",
    "end": "1470309"
  },
  {
    "text": "And until we talk\nabout GPT, let's just assume that all it does\nis make some trees,",
    "start": "1470310",
    "end": "1475830"
  },
  {
    "text": "but it's actually a\npretty small addition to make it also be guided.",
    "start": "1475830",
    "end": "1481470"
  },
  {
    "text": "OK, question. Could you explain a little bit\nmore of the intuition behind-- the benefits and\ndrawbacks of running",
    "start": "1481470",
    "end": "1487920"
  },
  {
    "text": "at five times versus\njust a neural network with, say, five\ntimes as many layers?",
    "start": "1487920",
    "end": "1493140"
  },
  {
    "text": "Oh, that's such a good one. Well, the question is, why\ndo it five times instead",
    "start": "1493140",
    "end": "1500600"
  },
  {
    "text": "of just going all the way? So I actually used to take-- [INAUDIBLE] and I used to live\nin San Francisco together,",
    "start": "1500600",
    "end": "1506600"
  },
  {
    "text": "and our labs were right next\nto each other at Stanford. You're like, hey, Chris, why\ndidn't you invent diffusion? And I'm like, that's\nnot important right now.",
    "start": "1506600",
    "end": "1513210"
  },
  {
    "text": "[LAUGHS] And I guess I\nwas hanging out with him. We get on the couch. And we were writing a paper\ntogether around the same time.",
    "start": "1513210",
    "end": "1519690"
  },
  {
    "text": "So he was telling me\na little bit about it. And honestly, it didn't\nwork because he just tried to do it all at once,\nand it wasn't successful.",
    "start": "1519690",
    "end": "1527160"
  },
  {
    "text": "But if you did it\nstep by step, it seemed to be a\nlittle bit easier. And there is a little bit of\nart form to some of this stuff.",
    "start": "1527160",
    "end": "1534950"
  },
  {
    "text": "And I don't think there's a\ndeep theoretical reason why putting it through five\ntimes is better than making a five times bigger model.",
    "start": "1534950",
    "end": "1541280"
  },
  {
    "text": "I will say this, though, at the\ntime when he was a researcher,",
    "start": "1541280",
    "end": "1546420"
  },
  {
    "text": "he had access to a\npretty big computer. But we're going to talk\nabout this in a second.",
    "start": "1546420",
    "end": "1551860"
  },
  {
    "text": "One of the other things\nthat's happened is scale. Dall-E is trained on massive\nsupercomputers, which--",
    "start": "1551860",
    "end": "1558540"
  },
  {
    "text": "maybe that means that in\nthe new version of Dall-E, they could go straight. It might have just been the\nconstraint of his computer.",
    "start": "1558540",
    "end": "1565980"
  },
  {
    "text": "Good question. Why do 20%? Yes. This is random, but\nis Dall-E open source?",
    "start": "1565980",
    "end": "1572390"
  },
  {
    "text": "Does it continue\nto train every time people use it and get better? Not open source.",
    "start": "1572390",
    "end": "1577610"
  },
  {
    "text": "And it does get better\nas people use it. So this is such an\ninteresting ethical issue.",
    "start": "1577610",
    "end": "1585030"
  },
  {
    "text": "So these models are expensive. They cost about half a\nbillion dollars to train.",
    "start": "1585030",
    "end": "1590090"
  },
  {
    "text": "And there's only a few\ncompanies in the world who have access to them. And I think they're trying\nto figure out what this",
    "start": "1590090",
    "end": "1596480"
  },
  {
    "text": "means monetarily as part of it. But you know what they said? They said this\nstuff's too powerful.",
    "start": "1596480",
    "end": "1601745"
  },
  {
    "text": "We can't just give it away. And they're not\ncompletely wrong. On some level, there's\nprobably some version of GPT",
    "start": "1601745",
    "end": "1609203"
  },
  {
    "text": "that maybe shouldn't be\nout there in the wild. People could use it in\nreally nefarious ways, but that's what they said.",
    "start": "1609203",
    "end": "1614270"
  },
  {
    "text": "But it's hard to ignore that\nthe value of these things. Even though they cost\n$1 billion to train, they might be worth\ntrillions of dollars",
    "start": "1614270",
    "end": "1620856"
  },
  {
    "text": "to whoever can figure\nout the smartest one. So that's such a good question.",
    "start": "1620857",
    "end": "1626750"
  },
  {
    "text": "OK, yeah. Question. So are we starting with a\nblurred image of another tree",
    "start": "1626750",
    "end": "1635190"
  },
  {
    "text": "or just a blurred image\nthat can become anything? Good question. When you start, you start\nwith just a blurred image.",
    "start": "1635190",
    "end": "1640780"
  },
  {
    "text": "So if I gave you a\nfully trained Dall-E, here's what you would do. You would create the size\nof the tree you want,",
    "start": "1640780",
    "end": "1646770"
  },
  {
    "text": "and for every single pixel, you\njust sample from a Gaussian. Its value would be a\nsample from a Gaussian.",
    "start": "1646770",
    "end": "1651810"
  },
  {
    "text": "Now, if we want to get\na little more detail, there would be red,\ngreen, and blue. But just assuming\nit's black and white, every single pixel will just\nbe sampled from a Gaussian.",
    "start": "1651810",
    "end": "1657610"
  },
  {
    "text": "So you look at it\nat the beginning, and it just looks like\nstatic on your TV. But then you put it\nthrough our model once,",
    "start": "1657610",
    "end": "1663563"
  },
  {
    "text": "and it starts to look a\nlittle bit less like static. The tree, it looks like,\nwill be defined by whatever random noise you started with.",
    "start": "1663563",
    "end": "1669270"
  },
  {
    "text": "That seed is where the--\noh, that's so beautiful. It's the seeds where the\ntree sprouts from-- do you see what I did there?",
    "start": "1669270",
    "end": "1674602"
  },
  {
    "text": "Not important. And then you run it\nfive times, and then you have your fully grown tree. And you're like, oh, we went\nthrough so much together.",
    "start": "1674602",
    "end": "1682140"
  },
  {
    "text": "Yes. Just [INAUDIBLE] Is there\none reference picture that the system is trying to make\nit look like, or is it just--",
    "start": "1682140",
    "end": "1689100"
  },
  {
    "text": "So this is one of\nthe trillion images that found on the internet. One of the secrets\nbehind all of this",
    "start": "1689100",
    "end": "1694595"
  },
  {
    "text": "is that the internet\nhas a lot of data. So they'll do this\nonce for this tree, and then they'll do it for\nthe next tree, and then",
    "start": "1694595",
    "end": "1700060"
  },
  {
    "text": "the next tree and the\nnext tree, and we'll get every tree we get. In fact, there are so many\ntrees on the internet. It often won't look at\nthe same tree twice.",
    "start": "1700060",
    "end": "1706840"
  },
  {
    "text": "Once it's done it, it\ncan just be put it away. Now, there are different\ntraining schemes. I don't have that\nmany tree pictures.",
    "start": "1706840",
    "end": "1712090"
  },
  {
    "text": "I would probably use\ntrees multiple times.  Yes.",
    "start": "1712090",
    "end": "1717430"
  },
  {
    "text": "What's the advantage of\nusing random noise as opposed to just white pixels? Good question.",
    "start": "1717430",
    "end": "1723100"
  },
  {
    "text": "If you start with\nwhite pixels, you would always get the same\ntree every time you run it.",
    "start": "1723100",
    "end": "1728299"
  },
  {
    "text": "And I suppose if you--",
    "start": "1728300",
    "end": "1734140"
  },
  {
    "text": "the idea here of trying to\nfigure out where the noise is, I think one of the-- Well, do you know what?",
    "start": "1734140",
    "end": "1739618"
  },
  {
    "text": "That's a cool idea. I'm just going with that. That's a cool idea. So one of the things\nwe could have done is we could have\ntaken your tree, and you could just white it out\nevery single 20% of the pixels,",
    "start": "1739618",
    "end": "1747100"
  },
  {
    "text": "and then white out\n20% more, and then your job is to fill in the 20%. That sounds really good. But certainly, you have this\nproblem that you'll always",
    "start": "1747100",
    "end": "1753880"
  },
  {
    "text": "produce the same tree. Why would you always-- Well, one of the reasons\nyou get different trees is because the noises\nis different each time.",
    "start": "1753880",
    "end": "1760230"
  },
  {
    "text": "Every time you\ncreate your image, it starts with\ndifferent noise when you're in the generation phase.",
    "start": "1760230",
    "end": "1765250"
  },
  {
    "text": "But if you always start with\nthe exact same seed, it'll-- when it removes this 20%.",
    "start": "1765250",
    "end": "1770429"
  },
  {
    "text": "There's nothing about this\nthat is stochastic in nature. The stochasticity-- the fact\nthat you get different trees,",
    "start": "1770430",
    "end": "1776430"
  },
  {
    "text": "starts with the fact that\nyou created a different seed. But I like that, and we\nshould try that out, an idea.",
    "start": "1776430",
    "end": "1783330"
  },
  {
    "text": "Is the denoising model, is it\njust run on the entire image, or does it only denoise 20%\nof the pixels each time?",
    "start": "1783330",
    "end": "1792059"
  },
  {
    "text": "Well, it's run on\nthe entire image, and it tries to denoise 20%. But we're just at\nthe start of things.",
    "start": "1792060",
    "end": "1799010"
  },
  {
    "text": "People are trying to use\nthis in different ways. You can imagine this is a\nfoundation upon which you guys could build some cool ideas.",
    "start": "1799010",
    "end": "1804910"
  },
  {
    "text": "And one of the\ncool ideas is maybe we want to just fill\nin specific pixels. Maybe we just want to\nremove this branch.",
    "start": "1804910",
    "end": "1810240"
  },
  {
    "text": "There's lots of neat\nthings that you could do on top of this technology. OK, one more question then-- I'm actually going\nto tell you there",
    "start": "1810240",
    "end": "1816530"
  },
  {
    "text": "is an even better\nidea than this. Is the variance of\nthe Gaussian noise",
    "start": "1816530",
    "end": "1822020"
  },
  {
    "text": "chosen to ensure that\nthe training propagates through the network? There's a lot of art form.",
    "start": "1822020",
    "end": "1828110"
  },
  {
    "text": "I'd say that's not\na closed discussion. So people choose variants\nin lots of different ways. Diffusion actually comes\nfrom a physics idea.",
    "start": "1828110",
    "end": "1836450"
  },
  {
    "text": "This idea of removing\nGaussian noise has existed for a long time\nin the world of physics,",
    "start": "1836450",
    "end": "1841610"
  },
  {
    "text": "and they've been very\nthoughtful about how they choose variances. For today's example, we're just\ngoing to use constant variance.",
    "start": "1841610",
    "end": "1847080"
  },
  {
    "text": "But if you read the\noriginal diffusion model 1, you can see that\nthey're changing noise in intentional ways\nthroughout the training",
    "start": "1847080",
    "end": "1854630"
  },
  {
    "text": "process. Though, again, it would have\nworked just fine if they hadn't. ",
    "start": "1854630",
    "end": "1861950"
  },
  {
    "text": "OK, now this turned out to\nstill be a hard problem. What have we talked\nabout so far?",
    "start": "1861950",
    "end": "1867419"
  },
  {
    "text": "We've talked about\nthe architecture. We've talked about\nhow you can get data. So at this moment, if I give\nyou a fully-trained Dall-E,",
    "start": "1867420",
    "end": "1874130"
  },
  {
    "text": "you could use it. You could put in noise,\nand you could get progressively better images. What I haven't told\nyou is if I gave you",
    "start": "1874130",
    "end": "1880250"
  },
  {
    "text": "an untrained Dall-E, how you\ncould do the training yourself. And one of the reasons is\nthat it's a little bit hard",
    "start": "1880250",
    "end": "1886700"
  },
  {
    "text": "to think about the\nlikelihood, like what's the maximum likelihood of an\nimage given another image?",
    "start": "1886700",
    "end": "1895617"
  },
  {
    "text": "I don't know. Some people could have\nfigured things out. There are cool ideas, like\nan elbow lower bound loss.",
    "start": "1895618",
    "end": "1900690"
  },
  {
    "text": "That was fine. But somebody\nrealized, hey, there's a slightly easier problem.",
    "start": "1900690",
    "end": "1907169"
  },
  {
    "text": "And it's very easy to\nthink about the probability and really first\nprinciple ways if we",
    "start": "1907170",
    "end": "1912720"
  },
  {
    "text": "solve this easier problem. Did you guys know there's\nan even easier problem? Want to hear about it?",
    "start": "1912720",
    "end": "1917970"
  },
  {
    "text": "OK, here's how it goes. Same starting point--\nthe starting point",
    "start": "1917970",
    "end": "1924120"
  },
  {
    "text": "is still going to have a picture\nof a tree with some noise, and you want to denoise it.",
    "start": "1924120",
    "end": "1929190"
  },
  {
    "text": " I got to keep the\nnoise consistently red.",
    "start": "1929190",
    "end": "1936783"
  },
  {
    "text": "I like this Christmas\ntheme going on.  And this time, the output\nis not going to be a tree.",
    "start": "1936783",
    "end": "1946740"
  },
  {
    "text": "You're like, what? It's not going to be a tree? I thought we were\nmaking trees here. No, pal, we're no longer in\nthe tree-making business.",
    "start": "1946740",
    "end": "1953040"
  },
  {
    "text": "We're now in the noise\nprediction business. So this time, we're not going\nto predict trees at all.",
    "start": "1953040",
    "end": "1961270"
  },
  {
    "text": "Instead, we're going\nto say, if you gave me this tree, instead of predicting\nthe tree without noise,",
    "start": "1961270",
    "end": "1966809"
  },
  {
    "text": "I'll predict the noise. What would you\nguys do with that?",
    "start": "1966810",
    "end": "1973309"
  },
  {
    "text": "If I said here was my input, I\npredict that this is the noise.",
    "start": "1973310",
    "end": "1978620"
  },
  {
    "text": "Could you turn that into a tree? ",
    "start": "1978620",
    "end": "1983740"
  },
  {
    "text": "I see some nodding,\njust like division.",
    "start": "1983740",
    "end": "1990450"
  },
  {
    "text": "OK, an idea. Somebody has got this. Somebody is thinking it. Yeah, in the back.",
    "start": "1990450",
    "end": "1997120"
  },
  {
    "text": "So taking the input and\nsubtracting the noise? Exactly. If I gave you an image and you\npredicted where the noise was--",
    "start": "1997120",
    "end": "2004365"
  },
  {
    "text": "and this noise could be\npositive or negative. And let's say you predicted\npositive negative values. You could just subtract. You could take this\nimage, subtract out,",
    "start": "2004365",
    "end": "2010950"
  },
  {
    "text": "and then you should be left\nwith the unnoised image. So it turns out that these\ntwo problems-- somebody",
    "start": "2010950",
    "end": "2017100"
  },
  {
    "text": "realized were the same. And this problem was, A, much\neasier and, B, much easier to think about probabilistically\nbecause we still",
    "start": "2017100",
    "end": "2024150"
  },
  {
    "text": "have this task of how\ncould we train this puppy. ",
    "start": "2024150",
    "end": "2030870"
  },
  {
    "text": "So you could have\npredicted your noise, and then I know exactly\nwhere I put the noise.",
    "start": "2030870",
    "end": "2036210"
  },
  {
    "text": "Let's say you forgot that one. ",
    "start": "2036210",
    "end": "2041299"
  },
  {
    "text": "And now, we have to\nthink about what's the likelihood of the true\nimage given what we predicted,",
    "start": "2041300",
    "end": "2051658"
  },
  {
    "text": "so a lot like maximum\nlikelihood estimation. Now, what I'm going\nto tell you is going",
    "start": "2051659",
    "end": "2058280"
  },
  {
    "text": "to extend to the whole image. But can we just jump into\none pixel for a hot second? If we just jumped\ninto one pixel--",
    "start": "2058280",
    "end": "2063815"
  },
  {
    "text": " let's see if we can\nget that up there.",
    "start": "2063815",
    "end": "2070190"
  },
  {
    "text": "If we jumped into\none pixel, you could imagine that if you looked\nat, say, this pixel over",
    "start": "2070190",
    "end": "2077210"
  },
  {
    "text": "here, you could\nhave two numbers.",
    "start": "2077210",
    "end": "2084419"
  },
  {
    "text": "We're going to have a y hat. And I'm going to be a\nlittle clear that y hat is",
    "start": "2084420",
    "end": "2090669"
  },
  {
    "text": "a result of the neural network. So I'm going to say that it was\na function of the parameters, just like the output\nof a neural network",
    "start": "2090670",
    "end": "2096399"
  },
  {
    "text": "was a function of\nits parameters. And let's say y hat was 0.--",
    "start": "2096400",
    "end": "2101620"
  },
  {
    "text": " let's say the true one is 0.6. Let's say y hat is 0.5 and\nthe true y, the true amount--",
    "start": "2101620",
    "end": "2113728"
  },
  {
    "text": "actually, we're\npredicting the noise. Sorry. The true noise is 0.1.",
    "start": "2113728",
    "end": "2118930"
  },
  {
    "text": "And let's say you\npredicted a 0.2. So at this pixel,\nyou made a prediction",
    "start": "2118930",
    "end": "2125900"
  },
  {
    "text": "of the amount of noise. You predicted it as a 0.2,\nbut in truth, it was a 0.1.",
    "start": "2125900",
    "end": "2131510"
  },
  {
    "text": "People said, you know what? Let's think about this\nas a random variable.",
    "start": "2131510",
    "end": "2136550"
  },
  {
    "text": "We can think about y\nas being a Gaussian",
    "start": "2136550",
    "end": "2143920"
  },
  {
    "text": "because we know\nit is a Gaussian. And we're going to assume\nthat the Gaussian takes on the mean that\nwas your prediction.",
    "start": "2143920",
    "end": "2150230"
  },
  {
    "text": "So you can say its mean is\nequal to the prediction you had, y hat of theta.",
    "start": "2150230",
    "end": "2157490"
  },
  {
    "text": "And then we're going to say it\nhas some fixed Gaussian-- fixed variance for now. We can call that K.",
    "start": "2157490",
    "end": "2164290"
  },
  {
    "text": "And then, we can ask\na likelihood question. We can do it for one\npixel, but of course, we could think about\nevery pixel as being",
    "start": "2164290",
    "end": "2170170"
  },
  {
    "text": "independent because our\nGaussian noise was independent. But let's think about\none pixel at a time. We can talk about\nwhat's the likelihood.",
    "start": "2170170",
    "end": "2176560"
  },
  {
    "text": "We'd say, what's the likelihood\nwith respect to our parameters? And as you guys know\nnow, it should just",
    "start": "2176560",
    "end": "2183700"
  },
  {
    "text": "be the probability density\nfunction of a random variable. Probability density\nfunction of a normal.",
    "start": "2183700",
    "end": "2189670"
  },
  {
    "text": "That's something\nwe've seen before. Do you guys remember this\nfrom back in the day? Oh, man, I'm already nostalgic.",
    "start": "2189670",
    "end": "2195433"
  },
  {
    "text": "We're going to have to say-- don't be strangers. You guys should come say\nhi whenever you see me. That's not important right now.",
    "start": "2195433",
    "end": "2200802"
  },
  {
    "text": "It's not goodbye yet. We've got a lot of GPT to\ntalk about before that.",
    "start": "2200802",
    "end": "2206800"
  },
  {
    "text": "But you remember this\nlittle expression? Oh, man. It just makes me sad\nto think that this is one of the last times we'll\nbe talking about normals.",
    "start": "2206800",
    "end": "2216010"
  },
  {
    "text": "But anyways, you have the\nvalue of y you observed. So we observed a 0.1.",
    "start": "2216010",
    "end": "2222730"
  },
  {
    "text": "We know the true mean was 0.2. And remember, this is\ny, and this is y hat.",
    "start": "2222730",
    "end": "2229150"
  },
  {
    "text": "Sorry. This is y hat, and this is y for\nthose people following along. And you have 2 sigma squared.",
    "start": "2229150",
    "end": "2236250"
  },
  {
    "text": "So we can say how\nlikely does the result of our neural network\nlooks or how likely is",
    "start": "2236250",
    "end": "2243170"
  },
  {
    "text": "our random variable assignment? But of course, we don't really\nthink about the likelihood.",
    "start": "2243170",
    "end": "2248269"
  },
  {
    "text": "We like to think\nabout log likelihood because it's easier\nto work with. And if we took the\nlog of this, you'd",
    "start": "2248270",
    "end": "2254780"
  },
  {
    "text": "end up with a log\nof this expression. Do you know what? This thing is going to look\nlike, a big old constant",
    "start": "2254780",
    "end": "2260990"
  },
  {
    "text": "because don't forget\nit's only this thing here that's got parameters.",
    "start": "2260990",
    "end": "2268730"
  },
  {
    "text": "The parameters went into\ngenerating this number, but the parameters didn't\ngo into anything else. So when we think about this as\na function of the parameters,",
    "start": "2268730",
    "end": "2276723"
  },
  {
    "text": "everything that doesn't\nhave a parameter looks like a constant. So this whole thing\nis going to be log--",
    "start": "2276723",
    "end": "2283170"
  },
  {
    "text": "I'm going to draw a smiley\nface for my constant. You're like, is\nthat a Greek symbol? No, it's a smiley face. But it's a smiley face why?",
    "start": "2283170",
    "end": "2288770"
  },
  {
    "text": "Because I'm so happy when I\nhave to deal with constants. What's the log of this? It's going to be\na constant plus.",
    "start": "2288770",
    "end": "2295932"
  },
  {
    "text": "A log of multiplication is\ngoing to be a log of this plus a log of this. Log of e raised to the\npower of something.",
    "start": "2295933",
    "end": "2301640"
  },
  {
    "text": "Remember, exp just means e as\na base raised to the power of.",
    "start": "2301640",
    "end": "2307460"
  },
  {
    "text": "Cancels out. What a good time! Am I missing a negative?",
    "start": "2307460",
    "end": "2312930"
  },
  {
    "text": "No, yeah. ",
    "start": "2312930",
    "end": "2318809"
  },
  {
    "text": "Is there a negative here in the\nGaussian probability density function? There is a negative. There is a negative, yes.",
    "start": "2318810",
    "end": "2325079"
  },
  {
    "text": "What a crazy time to be alive! I forgot. But then I remembered\njust in time. OK, so this is going\nto become negative.",
    "start": "2325080",
    "end": "2332520"
  },
  {
    "text": "And I could write 0.1, or I\ncould write y minus y hat.",
    "start": "2332520",
    "end": "2338550"
  },
  {
    "text": "And remember, Y\nhat was something that came from our parameters. Doo, doo, doo, doo, doo, squared\ndivided by a Smiley face.",
    "start": "2338550",
    "end": "2347192"
  },
  {
    "text": "You're like you can't\ndivide by a Smiley face. Oh, yes, I can because\nthis is a constant.",
    "start": "2347193",
    "end": "2352270"
  },
  {
    "text": "Now, this is all\nlooking well and good, but there's just one other\nthing I want to point us out.",
    "start": "2352270",
    "end": "2357480"
  },
  {
    "text": "We want to choose our thetas to\nbe the argmax of this function.",
    "start": "2357480",
    "end": "2367359"
  },
  {
    "text": "And the argmax of\nthis function doesn't care about this constant. And the argmax of this\nfunction doesn't care",
    "start": "2367360",
    "end": "2373480"
  },
  {
    "text": "about this constant either. So the argmax of\nthis is just going to be the same as the argmax\nof y minus y hat squared.",
    "start": "2373480",
    "end": "2383810"
  },
  {
    "start": "2383810",
    "end": "2391060"
  },
  {
    "text": "That was for one pixel. And because every\npixel is independent, the likelihood should have\nhad a big product here.",
    "start": "2391060",
    "end": "2397970"
  },
  {
    "text": "And the log-likelihood should\nhave had a big sum here. And this thing would just\nhave a sum over here. And if I throw\nthat sum back in--",
    "start": "2397970",
    "end": "2404557"
  },
  {
    "text": "I'm feeling a little bit fancy. So it's going to be pink. ",
    "start": "2404558",
    "end": "2416830"
  },
  {
    "text": "You get an expression\nthat you might have heard people talk about. It's the sum of squared errors.",
    "start": "2416830",
    "end": "2424380"
  },
  {
    "text": "These are all your predictions,\nand these are the true values. You look at the difference\nbetween those two",
    "start": "2424380",
    "end": "2430200"
  },
  {
    "text": "and square it, and you sum\nthat over all of your pixels, and you're going to try and\nchoose the parameters that",
    "start": "2430200",
    "end": "2436770"
  },
  {
    "text": "maximize this. Now, it's maximum of a\nnegative, so it's the minimize of the sum of squared errors.",
    "start": "2436770",
    "end": "2441798"
  },
  {
    "text": "And so you're going\nto try and choose the parameters that minimize\nthe sum of squared errors.",
    "start": "2441798",
    "end": "2447270"
  },
  {
    "text": "It's a beautiful\npiece of probability that leads to a very,\nvery simple algorithm. So going back here,\nwhat you're going to do?",
    "start": "2447270",
    "end": "2454770"
  },
  {
    "text": "You put in your noisy image. It goes through\nyour neural network. You make your predictions. Now you have the\npredictions and the truth.",
    "start": "2454770",
    "end": "2461970"
  },
  {
    "text": "You calculate the sum\nof squared errors, and that tells you how\ngood a job you did. But that doesn't tell you\nhow to change the parameters",
    "start": "2461970",
    "end": "2469093"
  },
  {
    "text": "in the neural network. How are we going to\nchange those parameters in the neural network? Gradient descent.",
    "start": "2469093",
    "end": "2474570"
  },
  {
    "text": "Gradient descent. You can't set that\nderivative equal to 0 and then solve for\nthem because there's",
    "start": "2474570",
    "end": "2480090"
  },
  {
    "text": "going to be a big old set\nof parameters in here. But what you then\ndo is you just say,",
    "start": "2480090",
    "end": "2485900"
  },
  {
    "text": "hey, there's a lot of\nparameters in here. For every single parameter\nI can ask the question, what's the derivative of this\nobjective function with respect",
    "start": "2485900",
    "end": "2494920"
  },
  {
    "text": "to every single parameter? Oh man, it's time to\ntalk about history.",
    "start": "2494920",
    "end": "2501910"
  },
  {
    "text": "I'm going to try and throw\nin some interesting histories because I can't\nbelieve I'm so old. I live through some history.",
    "start": "2501910",
    "end": "2507887"
  },
  {
    "text": "Man, my field is moving fast. So if this is time, and\nthis is AI progress,",
    "start": "2507887",
    "end": "2518130"
  },
  {
    "text": "I would say it has\nfelt to me like this.",
    "start": "2518130",
    "end": "2523890"
  },
  {
    "text": "And there is this\nhuge moment here, and this was, I'd\nsay, about 2013-ish.",
    "start": "2523890",
    "end": "2531980"
  },
  {
    "text": "In 2013, some\namazing programmers came up with this amazing\npiece of technology.",
    "start": "2531980",
    "end": "2538890"
  },
  {
    "text": "It has a name. It was called autograd. ",
    "start": "2538890",
    "end": "2548550"
  },
  {
    "text": "Before that date, when\nI made neural networks, do you know what I would do?",
    "start": "2548550",
    "end": "2553870"
  },
  {
    "text": "I would construct\nmy neural networ, imagine all of the neurons,\nall the logistic regressions",
    "start": "2553870",
    "end": "2560220"
  },
  {
    "text": "connected to each other. And then me and my buddy\nwould go to a cafe, and we'd spend our day\ndoing all the derivatives.",
    "start": "2560220",
    "end": "2567370"
  },
  {
    "text": "And if it was a\ncomplicated neural network, we'd start with the\nlast layer and then we'd get the derivative\nof the next layer, and we'd get the derivative\nof the next layer.",
    "start": "2567370",
    "end": "2573897"
  },
  {
    "text": "We made weird neural\nnetworks, weirder ones than I ever see now. We'd have trees and stuff. And it was great.",
    "start": "2573897",
    "end": "2579120"
  },
  {
    "text": "It was a good time, but we\nwould spend the entire day doing derivatives. And then, there\nis this great idea",
    "start": "2579120",
    "end": "2585930"
  },
  {
    "text": "that started in a program called\nTorch, which was originally written in a\nlanguage called Lua. Does anyone program in Lua?",
    "start": "2585930",
    "end": "2592934"
  },
  {
    "text": "No. One person, a little bit. Yeah, I used to program\nin this thing called Lua. It's like a Brazilian\nprogramming language,",
    "start": "2592934",
    "end": "2599490"
  },
  {
    "text": "and it was the first\none that had autograd. And it was such a big deal. We all learned this Brazilian\nprogramming language",
    "start": "2599490",
    "end": "2604523"
  },
  {
    "text": "named after the moon anyway. And so, what did autograd do?",
    "start": "2604523",
    "end": "2609780"
  },
  {
    "text": "Autograd meant that in\nPython, I would say, here's my neural network. It has this layer,\nthis layer, this layer.",
    "start": "2609780",
    "end": "2617490"
  },
  {
    "text": "Here is my objective function. And then I would\nsay automatically",
    "start": "2617490",
    "end": "2624510"
  },
  {
    "text": "do all the calculus, and\nit would just be one line. And the neural network would\nknow how to do the chain rule.",
    "start": "2624510",
    "end": "2630130"
  },
  {
    "text": "It would know how to do the\nchain rule, the derivative of this with respect to the end\nlayer, the derivative of that",
    "start": "2630130",
    "end": "2635369"
  },
  {
    "text": "with respect to\nthe previous layer. And it did all the chain rule. So no one has to\ndo derivatives now.",
    "start": "2635370",
    "end": "2640945"
  },
  {
    "text": "It's important to\nknow that they exist, and that's the magic\nbehind the scenes. But autograd, you guys\nlive in the future.",
    "start": "2640945",
    "end": "2646535"
  },
  {
    "text": "What a time to be alive!  OK, what that means is that as\nan architect, what you really",
    "start": "2646535",
    "end": "2654750"
  },
  {
    "text": "need is just this function. You have to figure out what\nis the loss function that is probabilistically inspired.",
    "start": "2654750",
    "end": "2661410"
  },
  {
    "text": "So I can talk about how\ngood a job I'm doing, and then I can ask the computer\nto update the gradients.",
    "start": "2661410",
    "end": "2667100"
  },
  {
    "text": "OK, wait a second. That's kind of it.",
    "start": "2667100",
    "end": "2674070"
  },
  {
    "text": "Insane. Now, in terms of the\narchitecture here,",
    "start": "2674070",
    "end": "2679350"
  },
  {
    "text": "there's a lot of\nthings you could do. But there's one\nthing that turned out to be really important.",
    "start": "2679350",
    "end": "2685990"
  },
  {
    "text": "It's got to be big. ",
    "start": "2685990",
    "end": "2691299"
  },
  {
    "text": "And this is going to be\neven more true for GPT. But for GPT.",
    "start": "2691300",
    "end": "2696970"
  },
  {
    "text": "There's two things\nthat people realize not too long after autograd. They're like, since we don't\nhave to do our derivatives,",
    "start": "2696970",
    "end": "2703960"
  },
  {
    "text": "what if we had a\nbigger neural network and we just got more data? And people got better and\nbetter at building special chips",
    "start": "2703960",
    "end": "2711700"
  },
  {
    "text": "for doing automatic\ndifferentiation and doing the actual\ngradient ascent. And people got bigger\nand bigger computers.",
    "start": "2711700",
    "end": "2718720"
  },
  {
    "text": "And they noticed two things. ",
    "start": "2718720",
    "end": "2723980"
  },
  {
    "text": "Number of training time-- I'm going to draw two graphs.",
    "start": "2723980",
    "end": "2732190"
  },
  {
    "text": "And on the X-axis are\ntwo different things. On the X-axis, how\nbig are our models, and on the X-axis over here\nis, how long do they train?",
    "start": "2732190",
    "end": "2739360"
  },
  {
    "text": "And originally,\nwhen I built models, I would try and make\nmore and more parameters,",
    "start": "2739360",
    "end": "2745839"
  },
  {
    "text": "but my models would\nlook like this. ",
    "start": "2745840",
    "end": "2751599"
  },
  {
    "text": "And I never got that big. Let's say this is\nlike 10 to the 10th, and this is like 10 to the 10th.",
    "start": "2751600",
    "end": "2758860"
  },
  {
    "text": "And my model would\neventually look like that. What does that mean? That means as I'm training,\nit gets smarter and smarter",
    "start": "2758860",
    "end": "2765530"
  },
  {
    "text": "and smarter. But eventually, I hit what\nwe would call a plateau. And then I would call it a day.",
    "start": "2765530",
    "end": "2770540"
  },
  {
    "text": "I would go have an\nadventure with my friends. And I just assume that's\nwhat would happen.",
    "start": "2770540",
    "end": "2777190"
  },
  {
    "text": "And for the longest\ntime, I believed that all neural networks\nwould hit the ceiling",
    "start": "2777190",
    "end": "2784040"
  },
  {
    "text": "until one day, somebody\nwas like, do you know what? I'm just going to get\na lot more parameters.",
    "start": "2784040",
    "end": "2789780"
  },
  {
    "text": "And when you got to a certain\nlevel, all of a sudden, people started to\nescape the plateau,",
    "start": "2789780",
    "end": "2794990"
  },
  {
    "text": "and they started to hit\nthese points where it didn't seem to have a plateau. It wasn't maybe getting that\nmuch smarter that quickly.",
    "start": "2794990",
    "end": "2804589"
  },
  {
    "text": "But they hit this point\nwhere if you could just take a network like this one,\nput more and more parameters",
    "start": "2804590",
    "end": "2811940"
  },
  {
    "text": "into it, and give it\nmore and more data, it would just keep\ngetting smarter. And then people did\nthe craziest things.",
    "start": "2811940",
    "end": "2819559"
  },
  {
    "text": "I used to train these things. You guys think about\nyour homework assignment. How long do you train\nyour gradient descent",
    "start": "2819560",
    "end": "2824690"
  },
  {
    "text": "for logistic regression? I don't have five\nminutes at most. It really does plateau\nout pretty fast.",
    "start": "2824690",
    "end": "2830905"
  },
  {
    "text": "[INAUDIBLE] most. What? Do you think people\nwould do longer? It gets big. Yeah, you could do it\nlonger [INAUDIBLE]..",
    "start": "2830905",
    "end": "2837160"
  },
  {
    "text": "Yeah, but we tell them\nhow many steps to do. OK, it depends on your computer. Maybe you can train\nit for 10 minutes.",
    "start": "2837160",
    "end": "2844530"
  },
  {
    "text": "Well, once people\nrealized this, they started doing something that\nwasn't the most ecologically",
    "start": "2844530",
    "end": "2849660"
  },
  {
    "text": "sound. They're like, what if we just\nkeep on all the supercomputers and not turn it off for a year?",
    "start": "2849660",
    "end": "2857190"
  },
  {
    "text": "And every time the programmers\ngo to sleep, they wake up. It was still training, and\npeople just went and went and went. And it started getting better\nand better at denoising.",
    "start": "2857190",
    "end": "2864809"
  },
  {
    "text": "So these are the\nmain narratives that led to Dall-E. I hope you guys\nfeel a little bit like this",
    "start": "2864810",
    "end": "2873180"
  },
  {
    "text": "is demystified. This was a great idea,\nbut it's a great idea you could have had.",
    "start": "2873180",
    "end": "2880682"
  },
  {
    "text": "Think about the\nperson next to you. Think about the person\non the other side. If it's not one\nof them, maybe it would be you who could\nhave come up with this.",
    "start": "2880682",
    "end": "2886877"
  },
  {
    "text": "And there's many more\nideas like that out there. This second idea--\nthat was a nice one.",
    "start": "2886877",
    "end": "2892460"
  },
  {
    "text": "Instead of trying to predict-- removing the noise, just\npredict where the noise is, and we can do the math.",
    "start": "2892460",
    "end": "2898069"
  },
  {
    "text": "And that this leads to a nice\nlittle piece of mathematics where if you think of the noise\nas being Gaussian when you",
    "start": "2898070",
    "end": "2904369"
  },
  {
    "text": "do the log-likelihood\nand the argmax of it, you end up with this negative\nsum of squared errors.",
    "start": "2904370",
    "end": "2910490"
  },
  {
    "text": "Now, I'm not going to-- I'm going to say autograd, man. I'm such as fans. If I ever meet the\npeople who did autograd,",
    "start": "2910490",
    "end": "2916099"
  },
  {
    "text": "I'm going to be\nlike a total fanboy. I'm like, you guys are amazing. And I wouldn't say\nthis is a great idea.",
    "start": "2916100",
    "end": "2922290"
  },
  {
    "text": "I think it's just\nmore like, OK, great. We can do that.",
    "start": "2922290",
    "end": "2927470"
  },
  {
    "text": "But that's the\nbig story picture. So I'm going to go get my blue\nmarker, which is my favorite.",
    "start": "2927470",
    "end": "2937040"
  },
  {
    "text": "I'm going to say that was\npart one of today's adventure.",
    "start": "2937040",
    "end": "2942847"
  },
  {
    "text": "So I'm going to give you guys\nthe pedagogical pause now. Guess what we're\ngoing to do next? I won't tell you.",
    "start": "2942847",
    "end": "2948180"
  },
  {
    "text": "I'll leave it as a mystery. Take your two-minutes\npedagogical pause, and then we'll continue\ntoday's lecture. ",
    "start": "2948180",
    "end": "2956682"
  },
  {
    "text": "I got a little liberal\nin my use of the board. I have to think-- [SIDE CONVERSATIONS]",
    "start": "2956683",
    "end": "2962100"
  },
  {
    "start": "2962100",
    "end": "3145490"
  },
  {
    "text": "So what we've talked\nabout so far is Dall-E.",
    "start": "3145490",
    "end": "3151970"
  },
  {
    "text": "And that was fantastic. And if I had to name\nthat part of a lecture, if I had to give\nit a title, it'd be Denoising because that was\nreally the most beautiful idea",
    "start": "3151970",
    "end": "3159830"
  },
  {
    "text": "in all of this,\nthat we're actually going to be really\ncreative with our data, add noise, then train a neural\nnetwork that can remove--",
    "start": "3159830",
    "end": "3165770"
  },
  {
    "text": "that can predict the noise. And since the noise\nis Gaussian, we've got a really nice likelihood\nfunction we can do MLE.",
    "start": "3165770",
    "end": "3172130"
  },
  {
    "text": "If I had to name the next\npart of this lecture, I would call it Attention\nis All You Need because that",
    "start": "3172130",
    "end": "3177980"
  },
  {
    "text": "was actually the name of\none of the papers that led to the great idea that\nreally transformed this.",
    "start": "3177980",
    "end": "3185009"
  },
  {
    "text": "And the original GPT-- there's a lot of history\nhere at Stanford.",
    "start": "3185010",
    "end": "3192270"
  },
  {
    "text": "The original GPT was\nwritten by a person called Andre Karpathy, who has yet\nagain also a PhD student",
    "start": "3192270",
    "end": "3198450"
  },
  {
    "text": "in Stanford. So a lot of this\nstuff was created by people just like yourselves.",
    "start": "3198450",
    "end": "3205859"
  },
  {
    "text": "So language presents a problem. In our previous model, we\ndealt with generating images.",
    "start": "3205860",
    "end": "3212310"
  },
  {
    "text": "But now we're going to start\nthinking about language. And there's a bunch of\nreasons that language",
    "start": "3212310",
    "end": "3217349"
  },
  {
    "text": "is really difficult. One is we ascribe so much\nmeaning and intelligence",
    "start": "3217350",
    "end": "3222510"
  },
  {
    "text": "to language. We take it very\nseriously as a society, but there's also more\npractical challenges.",
    "start": "3222510",
    "end": "3227530"
  },
  {
    "text": "And if I could point out\none practical challenge about language is that\nit's variable length.",
    "start": "3227530",
    "end": "3233090"
  },
  {
    "text": "If you think about\nyour features, we always had a fixed\nlength number of features that we gave on\nour problem set 6.",
    "start": "3233090",
    "end": "3239580"
  },
  {
    "text": "When we think about GPT, we\ncould control the image size. It would always be\nfixed-size images.",
    "start": "3239580",
    "end": "3244680"
  },
  {
    "text": "And that just made a lot about\nour architecture a lot easier. But one of the things I'm going\nto point out about language that's quite difficult,\nbesides the fact that it's",
    "start": "3244680",
    "end": "3251573"
  },
  {
    "text": "such a complicated\nconcept, is that it's going to be variable length.",
    "start": "3251573",
    "end": "3256690"
  },
  {
    "text": "So first, let me\ntell you a little bit about the bad ideas\nthat didn't work.",
    "start": "3256690",
    "end": "3262220"
  },
  {
    "text": "So one of the bad ideas\nthat didn't work so much was to build this--",
    "start": "3262220",
    "end": "3268340"
  },
  {
    "text": "well, when I say\nit's a bad idea, it will be part of\nour final solution.",
    "start": "3268340",
    "end": "3273430"
  },
  {
    "text": "They build these\nlittle neural networks. And the idea of the\nlittle neural network",
    "start": "3273430",
    "end": "3279550"
  },
  {
    "text": "would be you would\nput your language",
    "start": "3279550",
    "end": "3285760"
  },
  {
    "text": "through the neural network,\nand the neural network can produce two things.",
    "start": "3285760",
    "end": "3291140"
  },
  {
    "text": "It could produce\nboth the next word. So maybe you could\nhopefully predict socks. ",
    "start": "3291140",
    "end": "3298790"
  },
  {
    "text": "And it could also\nproduce a vector. And if you took that vector\nand you put this vector",
    "start": "3298790",
    "end": "3309408"
  },
  {
    "text": "into the neural network,\nit would hopefully produce the next word. And you can have different\nwords coming as inputs.",
    "start": "3309408",
    "end": "3315130"
  },
  {
    "text": "And so they built these\nlittle neural networks that you could use recurrently.",
    "start": "3315130",
    "end": "3320470"
  },
  {
    "text": "You could put in CS109\nthrough this network. It would produce maybe rocks,\nand it would produce a vector.",
    "start": "3320470",
    "end": "3326680"
  },
  {
    "text": "Then you could put rocks\nthrough this network, it would produce socks, and it\nwould create another vector. And this vector would\nthen become the output--",
    "start": "3326680",
    "end": "3333820"
  },
  {
    "text": "or, sorry, would eventually\nbecome input over here. So what you produce as output\nthen becomes this input.",
    "start": "3333820",
    "end": "3339130"
  },
  {
    "text": "And we could call these\nthings state vectors. So you have a state at time 0. And one of the things that\nyour neural network would make",
    "start": "3339130",
    "end": "3346030"
  },
  {
    "text": "is state at time 1. It seemed like a good idea,\nand people made language models",
    "start": "3346030",
    "end": "3352240"
  },
  {
    "text": "like this for a long time. And they were fine. They just couldn't do that much.",
    "start": "3352240",
    "end": "3358905"
  },
  {
    "text": "And they weren't\nthat impressive. You asked for a recipe,\nand it would just start giving you gobbledygook.",
    "start": "3358905",
    "end": "3365770"
  },
  {
    "text": "On some level,\nthough, this wasn't what the really great idea was.",
    "start": "3365770",
    "end": "3370790"
  },
  {
    "text": "The really great\nidea here was, hey, let's borrow some\nof those ideas.",
    "start": "3370790",
    "end": "3377190"
  },
  {
    "text": "So we're still going to\nhave a neural network. It's still going to\ntake in a state vector,",
    "start": "3377190",
    "end": "3385820"
  },
  {
    "text": "and it's still going to\nproduce the next word. But the great idea\nhere is we're going",
    "start": "3385820",
    "end": "3391280"
  },
  {
    "text": "to build a very special\nneural network that we're going to call an\nattention neural network.",
    "start": "3391280",
    "end": "3397190"
  },
  {
    "text": " And this attention\nneural network is going to take in all the\nwords we've seen so far,",
    "start": "3397190",
    "end": "3407180"
  },
  {
    "text": "and it's going to put them\ntogether into a really, really, really special\nformat that we're going",
    "start": "3407180",
    "end": "3412640"
  },
  {
    "text": "to call the context vector.  So we have this neural\nnetwork that I have not",
    "start": "3412640",
    "end": "3421210"
  },
  {
    "text": "described to you\nyet, but what it's going to do is it's going\nto take all the words and compress them into some\nimportant piece of context.",
    "start": "3421210",
    "end": "3428559"
  },
  {
    "text": " Now let me give you a little\nbit more layer of detail",
    "start": "3428560",
    "end": "3435140"
  },
  {
    "text": "about what is going to output. There is a lot of words\nin the English language.",
    "start": "3435140",
    "end": "3441730"
  },
  {
    "text": "This little neural\nnetwork here is not going to just\nproduce a word that's a little bit oversimplified.",
    "start": "3441730",
    "end": "3448000"
  },
  {
    "text": "Instead, it's going to\npredict, for every word in the English language, the\nprobability that word is next.",
    "start": "3448000",
    "end": "3456013"
  },
  {
    "text": "So I'm not going to try\nand draw all the words in the English\nlanguage, but you can imagine it creates a\nbig old dictionary.",
    "start": "3456013",
    "end": "3461920"
  },
  {
    "text": "And it'll say rocks. That's a pretty high\nprobability, is 0.001.",
    "start": "3461920",
    "end": "3467950"
  },
  {
    "text": "And you could say, Stanford. Maybe that's less. Maybe it's 10 to\nthe negative fourth.",
    "start": "3467950",
    "end": "3474490"
  },
  {
    "text": "But for every single word, we're\ngoing to produce a probability. If I gave you this\nneural network,",
    "start": "3474490",
    "end": "3480880"
  },
  {
    "text": "you gave me a set\nof words as input. It would go through\nthe special layer, make context, and start\nwith some random state,",
    "start": "3480880",
    "end": "3487090"
  },
  {
    "text": "and then it produces\nthese probabilities. How could you go from\nthese probabilities",
    "start": "3487090",
    "end": "3492370"
  },
  {
    "text": "to picking a word? I've said a lot of complexity. So I want to take a\nmoment and solidify. And I'm going to give you guys\na minute to think about it.",
    "start": "3492370",
    "end": "3499510"
  },
  {
    "text": "Why don't you talk about it\nwith the person next to you? And the question I want\nyou guys to figure out is if you had a neural\nnetwork and it produced",
    "start": "3499510",
    "end": "3505210"
  },
  {
    "text": "word probability mappings, how\nwould you choose the next word? Talk about it, but also\ntake it as a moment",
    "start": "3505210",
    "end": "3510720"
  },
  {
    "text": "to figure out what's\nconfusing about this. And we'll take some\nquestions afterwards. OK, go for it. Think about it.",
    "start": "3510720",
    "end": "3516430"
  },
  {
    "start": "3516430",
    "end": "3610630"
  },
  {
    "text": "OK, an idea? What would you guys do if I\ngave you a neural network?",
    "start": "3610630",
    "end": "3616410"
  },
  {
    "text": "It took a couple of\nwords, and it gave you back this dictionary where\nwords with the probability that they come next.",
    "start": "3616410",
    "end": "3622010"
  },
  {
    "text": "What would you do? ",
    "start": "3622010",
    "end": "3630660"
  },
  {
    "text": "The most likely word. You could choose the\nmost likely word. That is not a bad idea. And that would be possible.",
    "start": "3630660",
    "end": "3638742"
  },
  {
    "text": "But here, let me\njust tell you what one thing that would happen. Do you remember when\nwe had that great idea? We had the white\npixels, but I said",
    "start": "3638742",
    "end": "3644040"
  },
  {
    "text": "if you did that, then\nevery time you ran this, you would always\nget the same image. If you choose the\nmost likely word,",
    "start": "3644040",
    "end": "3649650"
  },
  {
    "text": "then every time you\nwrite CS109 rocks you'll always get that most\nlikely word because, again,",
    "start": "3649650",
    "end": "3654809"
  },
  {
    "text": "there's no randomness in\nthe neural network itself. So while that would\nbe a good idea, you'd always get\nthe same production.",
    "start": "3654810",
    "end": "3660910"
  },
  {
    "text": "We want it to be a little\nbit different each time. All right. Yes. What if you just pick a\nword that's likely enough",
    "start": "3660910",
    "end": "3667049"
  },
  {
    "text": "and then just sample\nrandomly from all the words? Is it good enough,\nand then put it in?",
    "start": "3667050",
    "end": "3673780"
  },
  {
    "text": "There it is. I don't know if that's\nwhat you're going to say, but sampling randomly\nis what people do. So you get this\nwhole dictionary.",
    "start": "3673780",
    "end": "3679795"
  },
  {
    "text": "And do you know what? They treat it like multinomials. There's all-- it's\nlike this big dice.",
    "start": "3679795",
    "end": "3684908"
  },
  {
    "text": "It's got all these sides. And here's the probability\nof each outcome. And they take this gigantic\nEnglish language side dice,",
    "start": "3684908",
    "end": "3692280"
  },
  {
    "text": "and they roll it. And you imagine they have\nto have their arms like this because it's so big. And they'll get\none word, and it's",
    "start": "3692280",
    "end": "3698508"
  },
  {
    "text": "most likely to be the thing that\nhas the highest probability, but it could be something else. But let's say for now, when you\nsample, you get the word rocks.",
    "start": "3698508",
    "end": "3707030"
  },
  {
    "text": "But if there was\nanother high probability word when you roll\nthat dice, it's very possible you get\nsomething other than rocks.",
    "start": "3707030",
    "end": "3713810"
  },
  {
    "text": "So at this point-- sorry. ",
    "start": "3713810",
    "end": "3719060"
  },
  {
    "text": "It doesn't say rocks. That's what it just had. CS109 rocks.",
    "start": "3719060",
    "end": "3724320"
  },
  {
    "start": "3724320",
    "end": "3731080"
  },
  {
    "text": "Socks. What did you say? It's great. Yeah, CS1-- No, you can't\nsay CS109 rocks is great.",
    "start": "3731080",
    "end": "3738250"
  },
  {
    "text": "It's always rocks socks. What else can you rock and roll?",
    "start": "3738250",
    "end": "3744550"
  },
  {
    "text": "No, it's definitely socks. ",
    "start": "3744550",
    "end": "3750160"
  },
  {
    "text": "OK, so socks is\nthe word we choose. Sorry. Now, at this point, we don't\nwant to just produce one word.",
    "start": "3750160",
    "end": "3757350"
  },
  {
    "text": "We want to keep doing this. So in the same\nway that we-- when we were doing the denoising,\nwe'd reuse our neural network",
    "start": "3757350",
    "end": "3762797"
  },
  {
    "text": "to remove more and\nmore noise, we're going to reuse our\nneural network. So at this point, we\nhave a neural network, it's the word\nsocks, and it's also",
    "start": "3762797",
    "end": "3769590"
  },
  {
    "text": "produced another vector,\nanother set of neurons. You can imagine. You can just take the\nlast layer of activations",
    "start": "3769590",
    "end": "3775980"
  },
  {
    "text": "here and treat that as a vector. And then we're going to reuse\nthat exact same neural network. But now, instead of\nhaving CS109 rocks,",
    "start": "3775980",
    "end": "3782520"
  },
  {
    "text": "we have CS109 rock socks. And we're going to put that\nthrough this special thing we haven't talked about in\ndetail called attention layer.",
    "start": "3782520",
    "end": "3789930"
  },
  {
    "text": "Again, that's going to give us\na set of neuron activations, and then we use the\nsame neural network.",
    "start": "3789930",
    "end": "3795030"
  },
  {
    "text": "That neural network\nwants a state vector, it wants a context\nvector, and it's going to output\nanother dictionary.",
    "start": "3795030",
    "end": "3801553"
  },
  {
    "text": "And I don't know what\ncomes after socks. Can somebody help me out here? What could go after socks? Be the large language model.",
    "start": "3801553",
    "end": "3807390"
  },
  {
    "text": "\"Period.\" \"Period.\" Yes, certainly. That happens with\nhigh probability.",
    "start": "3807390",
    "end": "3815170"
  },
  {
    "text": "So when you sample from this\ndictionary, you get \"period.\" ",
    "start": "3815170",
    "end": "3821450"
  },
  {
    "text": "And it just keeps doing that. Now, this idea had been\naround for a while,",
    "start": "3821450",
    "end": "3827890"
  },
  {
    "text": "and people had tried it. And it just didn't\nwork that well because they hadn't figured\nout the magic that goes",
    "start": "3827890",
    "end": "3833290"
  },
  {
    "text": "into this little mechanism. And what they do with\nthis little mechanism",
    "start": "3833290",
    "end": "3840160"
  },
  {
    "text": "was interesting. They built a neural network\nthat could take in any word.",
    "start": "3840160",
    "end": "3847620"
  },
  {
    "text": "So let's say you had CS109.",
    "start": "3847620",
    "end": "3853590"
  },
  {
    "text": "They built a little\nneural network, and that little neural network\nwould produce a single value",
    "start": "3853590",
    "end": "3863450"
  },
  {
    "text": "called an intention word. Let's say that this would-- doo, doo, doo, doo, doo.",
    "start": "3863450",
    "end": "3868640"
  },
  {
    "text": "Well, actually, I guess it\nwould produce two things.",
    "start": "3868640",
    "end": "3873859"
  },
  {
    "text": "Let's say this is word 0\nbecause it's the first thing. It would produce a little\nembedding of the word,",
    "start": "3873860",
    "end": "3880340"
  },
  {
    "text": "and it would come up with\nan intention value, so a number between 0 and 1.",
    "start": "3880340",
    "end": "3885590"
  },
  {
    "text": " And this was little\nneural network,",
    "start": "3885590",
    "end": "3890800"
  },
  {
    "text": "it also took the state vector. So you could take whatever\nstate vector you had, and it goes into this layer here.",
    "start": "3890800",
    "end": "3896414"
  },
  {
    "text": " So we have state time 0.",
    "start": "3896415",
    "end": "3902710"
  },
  {
    "text": "And any word, you\ncan put it through the second neural network. We'll call this the\nattention neural network. And the big thing is that it\nproduces this attention vector.",
    "start": "3902710",
    "end": "3910269"
  },
  {
    "text": " This context that\ncomes out of attention",
    "start": "3910270",
    "end": "3915910"
  },
  {
    "text": "is really a simple thing. Let's say the context would\nbe equal to the sum over all",
    "start": "3915910",
    "end": "3923620"
  },
  {
    "text": "the words i of the words vector,\nweighted by its attention.",
    "start": "3923620",
    "end": "3932280"
  },
  {
    "text": "And the really simple idea here\nis this little neural network is like a focuser.",
    "start": "3932280",
    "end": "3938250"
  },
  {
    "text": "It would say before we even\nstart to process the sentence, let's have a neural\nnetwork, which says what we should be\npaying attention to.",
    "start": "3938250",
    "end": "3945180"
  },
  {
    "text": "For example, when you're\nproducing the word socks, you probably only need to\nwork at the word rocks.",
    "start": "3945180",
    "end": "3950520"
  },
  {
    "text": "It doesn't matter\nwhat came before. If you put a lot of\nattention on our rocks, you can realize that\nthe next word was socks.",
    "start": "3950520",
    "end": "3955890"
  },
  {
    "text": "But it might be the case\nthat when you put a period, you have to look and realize\nwhat are you saying rocks",
    "start": "3955890",
    "end": "3961859"
  },
  {
    "text": "and be like, oh, let's put\nattention on this word. Since this word,\nCS109, obviously, it",
    "start": "3961860",
    "end": "3967530"
  },
  {
    "text": "rocks socks period. And so it can know\nwhat to focus on. And it seems like a simple idea.",
    "start": "3967530",
    "end": "3973810"
  },
  {
    "text": "But this simple\nidea, we think, was one of the biggest\nchanges in architecture. And then all of a sudden,\npeople were like, OK, this stuff",
    "start": "3973810",
    "end": "3979509"
  },
  {
    "text": "seems to work. And then again, when\nthey start to scale up, they ended up with things\nthat could speak and create",
    "start": "3979510",
    "end": "3986290"
  },
  {
    "text": "things that look like meaning. I'm almost done. I know there's a lot going\non in these two boards,",
    "start": "3986290",
    "end": "3992290"
  },
  {
    "text": "and I should take\na lot of questions. But that's the big idea. We're just missing one thing.",
    "start": "3992290",
    "end": "3999710"
  },
  {
    "text": "You could get in\nPython, and you could define in PyTorch, which is\nthe successor of this Torch",
    "start": "3999710",
    "end": "4006339"
  },
  {
    "text": "that was originally\nwritten in Lua. And you can say,\nI'm going to define all these neural networks.",
    "start": "4006340",
    "end": "4011930"
  },
  {
    "text": "I'm going to just\ndefine my states, and I'll have a neural\nnetwork that takes as input. It's like you're making a\ntree the graphical structure.",
    "start": "4011930",
    "end": "4019010"
  },
  {
    "text": "You make your\ngraphical structure, and then you call autograd. You'd say, I want you to update\nall of these based off words.",
    "start": "4019010",
    "end": "4028500"
  },
  {
    "text": "Where do we get these words? ",
    "start": "4028500",
    "end": "4036210"
  },
  {
    "text": "The dictionary is good. Yes, there's many words\nin the dictionary. But in order to do\nthis, we're going",
    "start": "4036210",
    "end": "4042299"
  },
  {
    "text": "to need a whole bunch\nof not just words. We want to have some words. We're going to\nmake a prediction.",
    "start": "4042300",
    "end": "4048340"
  },
  {
    "text": "And then we wanted to know,\nwas our prediction good? Yeah, an idea? [INAUDIBLE] look at a\nbunch of written stuff.",
    "start": "4048340",
    "end": "4055830"
  },
  {
    "text": "Yeah, they get a lot\nof written stuff. Do you know where do they\nfind all that written stuff? The internet.",
    "start": "4055830",
    "end": "4061260"
  },
  {
    "text": "Yeah, not in a library. The internet's got a\nlot of written stuff. So somewhere on the internet,\nsomebody was writing a passage.",
    "start": "4061260",
    "end": "4067349"
  },
  {
    "text": "And they're like,\n[INAUDIBLE] was cool, but CS109 rocked socks like--",
    "start": "4067350",
    "end": "4075720"
  },
  {
    "start": "4075720",
    "end": "4082099"
  },
  {
    "text": "Box. Box? Like a-- ",
    "start": "4082100",
    "end": "4089102"
  },
  {
    "text": "Fox. --a fox.  And someone wrote this.",
    "start": "4089103",
    "end": "4094530"
  },
  {
    "text": "And then, people would take\nthis word on the internet, and they would create\ntraining examples.",
    "start": "4094530",
    "end": "4099930"
  },
  {
    "text": "They would say, OK,\nI'm going to put this into my neural\nnetwork, and I'm going",
    "start": "4099930",
    "end": "4106460"
  },
  {
    "text": "to see is it able to\npredict this next word. The last thing we\nwould need if we wanted",
    "start": "4106460",
    "end": "4113250"
  },
  {
    "text": "to bring this thing\nfull circle is not just how would you use\nthe neural network but how you would\ntrain it, which means you need to have\nsomething like this.",
    "start": "4113250",
    "end": "4120159"
  },
  {
    "text": "You need to have the\nMLE scoring function that we're trying to optimize.",
    "start": "4120160",
    "end": "4125710"
  },
  {
    "text": "So this says CS109 rocks.",
    "start": "4125710",
    "end": "4130890"
  },
  {
    "text": "We look at the real\nword, and it's a socks. And do you know what? We produced a probability.",
    "start": "4130890",
    "end": "4136109"
  },
  {
    "text": "We'd said how likely it was. And so since we had a\nprobability of socks, we could use the\nmultinomial probability mass",
    "start": "4136109",
    "end": "4143520"
  },
  {
    "text": "function to say, OK, I thought\nsocks had this probability. I could say, what is my\nloss function given that?",
    "start": "4143520",
    "end": "4149399"
  },
  {
    "text": "So very similar to how you\ndid your loss function here. Here, you use the Bernoulli\nloss function because you",
    "start": "4149399",
    "end": "4155880"
  },
  {
    "text": "had a class with two labels. Here, you've got a class\nwith multiple labels. And here, you use your\nprobability of one",
    "start": "4155880",
    "end": "4161969"
  },
  {
    "text": "in your Bernoulli\nprobability mass function. And here, you use the\nmultinomial probability mass function. And then you're done.",
    "start": "4161970",
    "end": "4167250"
  },
  {
    "text": "You've got a\nlikelihood function. And the next big\nidea was just data.",
    "start": "4167250",
    "end": "4172620"
  },
  {
    "text": "Give it lots and lots\nand lots of data. Now, to be clear, what I\ndescribed is probably GPT-3.",
    "start": "4172620",
    "end": "4180330"
  },
  {
    "text": "It's unclear what\nis behind GPT-4. They say it's going to come out\nbetween December and February.",
    "start": "4180330",
    "end": "4185880"
  },
  {
    "text": "They say it's going to be as big\na change from GPT-2 to GPT-3. And I can't tell\nyou what's in GPT-4.",
    "start": "4185880",
    "end": "4191460"
  },
  {
    "text": "Maybe they're like,\nyou know what? If, instead of attention,\nwe do retention structure,",
    "start": "4191460",
    "end": "4196650"
  },
  {
    "text": "then everything works out. Who knows? Maybe they just came up with\na better chip that could do more autograd more quickly.",
    "start": "4196650",
    "end": "4205870"
  },
  {
    "text": "I'm not sure, but that's\nthe future coming.  I know this is probably a lot\nthe first time you see it,",
    "start": "4205870",
    "end": "4213900"
  },
  {
    "text": "but maybe you can appreciate\nthat there's a finite number of things to learn. There's a lot more\nstructure here.",
    "start": "4213900",
    "end": "4220440"
  },
  {
    "text": "You can appreciate for\nlanguage, it's really nice that you don't have to\ndo your derivatives, that all your derivatives can\ncome for free because there's",
    "start": "4220440",
    "end": "4227638"
  },
  {
    "text": "this interesting reusing\nof neural networks that gets really hard\nto do the math around. But a computer can go through\nand do all the chain rules",
    "start": "4227638",
    "end": "4234239"
  },
  {
    "text": "that you want. At the end of the day, you're\nproducing probabilities, so MLE is still a\ntool you can use.",
    "start": "4234240",
    "end": "4241230"
  },
  {
    "text": "And this really simple idea of\nI'm going to take each input and decide how\nmuch I should care",
    "start": "4241230",
    "end": "4246720"
  },
  {
    "text": "about it, that\nsimple idea was kind of the equivalent of denoising. And it seems that\nattention is really good.",
    "start": "4246720",
    "end": "4254260"
  },
  {
    "text": "In fact, this single\nidea was so good you start to see it in\nall other places,",
    "start": "4254260",
    "end": "4260928"
  },
  {
    "text": "like in algorithms\nthat try and learn how to drive instead of\ntrying to do some really complicated network.",
    "start": "4260928",
    "end": "4266369"
  },
  {
    "text": "Now they're trying to use\nattention where they can just say, OK, if I can\nsee out my car,",
    "start": "4266370",
    "end": "4271875"
  },
  {
    "text": "what should I be\npaying attention to when I make my next decision? So this simple\nattention neural network",
    "start": "4271875",
    "end": "4277360"
  },
  {
    "text": "turns out to be very helpful. Again, autograd is a\nbig deal because now you have two different neural\nnetworks with parameters",
    "start": "4277360",
    "end": "4283210"
  },
  {
    "text": "all over the place doing lots\nof different complicated things, and all you would need to do is\nstring up your neural network",
    "start": "4283210",
    "end": "4289060"
  },
  {
    "text": "and then, say, computer,\ndo the optimization for me. OK, questions,\ncomments, concerns?",
    "start": "4289060",
    "end": "4295590"
  },
  {
    "text": "Yes. This is backtracking a little,\nbut I was wondering, instead of doing gradient\nascent or descent,",
    "start": "4295590",
    "end": "4301860"
  },
  {
    "text": "why can't you just\nsolve for the closed form of the gradient,\nthe log-likelihood, and then find your\nparameters that way?",
    "start": "4301860",
    "end": "4308789"
  },
  {
    "text": "It is because just too\nhard of the equation? Yeah, it is too hard\nof the equation.",
    "start": "4308790",
    "end": "4314670"
  },
  {
    "text": "I'm pretty sure there\nis no closed form. So let's talk about\nwhy it's hard. First of all, if you\nhad one parameter,",
    "start": "4314670",
    "end": "4321960"
  },
  {
    "text": "you would take that gradient\nand set it equal to 0 and then solve. If you had two parameters,\nyou have two equations,",
    "start": "4321960",
    "end": "4328210"
  },
  {
    "text": "two unknowns, and then solve. These things have close\nto a trillion parameters.",
    "start": "4328210",
    "end": "4334110"
  },
  {
    "text": "So you could set up a trillion\nequations, a trillion unknowns, and then try and solve. But it gets worse.",
    "start": "4334110",
    "end": "4340110"
  },
  {
    "text": "When we think about\nour neural networks, they're all logistic\nregressions. At some point, you\nhave the activation",
    "start": "4340110",
    "end": "4349170"
  },
  {
    "text": "of one logistic regression\ncell inside this massive neural network, is going to\nbe equal to something",
    "start": "4349170",
    "end": "4356100"
  },
  {
    "text": "like a sigmoid of the\nweighted sum of the inputs",
    "start": "4356100",
    "end": "4363180"
  },
  {
    "text": "times by the weights.  So we're going to say\ninput i, weights i.",
    "start": "4363180",
    "end": "4369540"
  },
  {
    "text": " Did you guys notice how, the\npredictions we were making,",
    "start": "4369540",
    "end": "4376230"
  },
  {
    "text": "if this inner part\nended up being positive, we would just predict a one, if\nthis ended up being negative,",
    "start": "4376230",
    "end": "4381750"
  },
  {
    "text": "we'd predict a 0 in\nyour own homework? But we still have this sigmoid. Originally, the\nsigmoid was helpful",
    "start": "4381750",
    "end": "4389160"
  },
  {
    "text": "because it allowed\nus to interpret the results as a probability. But it turns out the sigmoid\ndid something else that's",
    "start": "4389160",
    "end": "4395470"
  },
  {
    "text": "really important. If you got rid of\nthat sigmoid, and you said every single neuron\nwas just inputs multiplied",
    "start": "4395470",
    "end": "4400828"
  },
  {
    "text": "by weights, and you didn't\nput it through the squashing function, it turns out that you\ncould have trillion parameters,",
    "start": "4400828",
    "end": "4407700"
  },
  {
    "text": "but it would still be\nequivalent to if you just had a linear system.",
    "start": "4407700",
    "end": "4412869"
  },
  {
    "text": "This sigmoid here\nmakes it nonlinear in really complicated ways. It also makes it basically\nimpossible to do closed forms.",
    "start": "4412870",
    "end": "4422040"
  },
  {
    "text": "Oh, I want to tell\nyou guys something, and you guys tell me if\nI did the wrong thing.",
    "start": "4422040",
    "end": "4428260"
  },
  {
    "text": "How's that? You're like, Chris,\nwhat did you do? I know. When I make logistic\nregression, I use a sigmoid.",
    "start": "4428260",
    "end": "4437840"
  },
  {
    "text": "But sigmoid has this\nreally nasty property that if you look\nat it, it has its--",
    "start": "4437840",
    "end": "4446390"
  },
  {
    "text": "doo, doo, doo, doo, doo. All its values are positive. It's always between 0 and 1.",
    "start": "4446390",
    "end": "4451780"
  },
  {
    "text": "That's great if you're\nthinking about an output. But if you're somewhere in the\nmiddle of a neural network, it turns out having\nall of your weights",
    "start": "4451780",
    "end": "4458800"
  },
  {
    "text": "have positive values is really\nannoying and problematic for really subtle reasons.",
    "start": "4458800",
    "end": "4463909"
  },
  {
    "text": "And so people don't want their\ninner neurons to be shifted. So you could do a sigmoid\nand subtract by 0.5.",
    "start": "4463910",
    "end": "4470969"
  },
  {
    "text": "Did you guys want to know\nthere's another function? ",
    "start": "4470970",
    "end": "4478230"
  },
  {
    "text": "Tan. Anyone have seen\nthis before, tanh? Yeah, the hyperbolic tangent.",
    "start": "4478230",
    "end": "4485730"
  },
  {
    "text": "It's not that special. It doesn't have a\nprobabilistic interpretation. You wouldn't use it\nfor the final layer, but you can use it\nin internal layers.",
    "start": "4485730",
    "end": "4491723"
  },
  {
    "text": "It looks a lot like the sigmoid,\nbut it's just centered nicely. And it turns out this\nis a really big deal",
    "start": "4491723",
    "end": "4497519"
  },
  {
    "text": "if you want to have inner\nlayers in a neural network. There's other things you\ncan use rather than a tanh.",
    "start": "4497520",
    "end": "4502680"
  },
  {
    "text": "But no matter what you do--\nsorry, I went on a tangent, but you need this-- [LAUGHTER]",
    "start": "4502680",
    "end": "4509800"
  },
  {
    "text": " You need this nonlinear piece. You need to put through\nsome squashing function to make sure your whole\nthing doesn't end up",
    "start": "4509800",
    "end": "4516450"
  },
  {
    "text": "just being linear. It is important,\nbut it also makes it impossible to do the closed\nform set it equal to zero.",
    "start": "4516450",
    "end": "4524507"
  },
  {
    "text": "You're like, here's my question. I'm like, whoa, tanh,\nand then we're back. But I just-- I needed to\nget this off my chest,",
    "start": "4524507",
    "end": "4530100"
  },
  {
    "text": "that even though we use\nsigmoid for the final layer, in the inner layers,\nwe actually use tanh, which looks very similar,\nbut it's centered around zero.",
    "start": "4530100",
    "end": "4537250"
  },
  {
    "text": "Yes. What is the array of parameters\nfor attention interact",
    "start": "4537250",
    "end": "4543130"
  },
  {
    "text": "with the ones for the next word\nin the relative probabilities for those words?",
    "start": "4543130",
    "end": "4548860"
  },
  {
    "text": "Is it that you first do\none in and then the other? So in the forward pass, you\ncan imagine the forward pass",
    "start": "4548860",
    "end": "4557199"
  },
  {
    "text": "you first do the\nattention on each word, and what you do on\neach word, every word will end up with its\nvector and also its weight.",
    "start": "4557200",
    "end": "4565250"
  },
  {
    "text": "So you do this for every word. That's your first thing. Then, the second thing is\nyou run this little function.",
    "start": "4565250",
    "end": "4570460"
  },
  {
    "text": "You end up with the context. At this point, you have\na vector for context. You always keep a state vector.",
    "start": "4570460",
    "end": "4577060"
  },
  {
    "text": "It's just always-- it's like\na set of neurons that are just holding onto some memory.",
    "start": "4577060",
    "end": "4582328"
  },
  {
    "text": "Do you want to know\nwhat happens here when you have to merge those\ntwo things into this box?",
    "start": "4582328",
    "end": "4587790"
  },
  {
    "text": "OK, wait for it. If you have a neural network\nand it's getting inputs from the top, and it's\ngetting inputs from the side,",
    "start": "4587790",
    "end": "4595469"
  },
  {
    "text": "check out what we do. So these are--\nit's just a vector, a little bit like your Xs, but\nnow you've got two of them.",
    "start": "4595470",
    "end": "4601365"
  },
  {
    "text": " We do this. We stack them.",
    "start": "4601365",
    "end": "4607750"
  },
  {
    "text": "You take your first one,\nyou take your second one. You stick them\ntogether, and now you've got one vector going\ninto your neural network,",
    "start": "4607750",
    "end": "4613750"
  },
  {
    "text": "very similar to how\nyou have your Xs going into your logistic regression. So we use this.",
    "start": "4613750",
    "end": "4619540"
  },
  {
    "text": "This is just a diagram. But really, it's\nthese two are both inputs into the neural network.",
    "start": "4619540",
    "end": "4625190"
  },
  {
    "text": "OK, is that question? Yeah. Can you explain exactly\nwhat the state 1 and state 2",
    "start": "4625190",
    "end": "4632770"
  },
  {
    "text": "actually [INAUDIBLE]? What makes it meaningful? What is it even [INAUDIBLE]?",
    "start": "4632770",
    "end": "4638140"
  },
  {
    "text": "They're just neurons. They're just like\nyou have these-- you have some neurons\nthat produce values,",
    "start": "4638140",
    "end": "4645730"
  },
  {
    "text": "and you have a bunch\nof them, and then you store them in memory. And in theory, it's\nholding on to memory.",
    "start": "4645730",
    "end": "4652430"
  },
  {
    "text": "It's holding onto\nideas that it's constructing as it's going. So maybe it's trying to\nproduce a poem in pirate",
    "start": "4652430",
    "end": "4659620"
  },
  {
    "text": "speak, and it's producing\nit word by word, and it has to keep track of\nwhere it's going in some space,",
    "start": "4659620",
    "end": "4664693"
  },
  {
    "text": "and it stores it\nin these neurons. And I don't even\nunderstand what's going on with those neurons. But it's some sort\nof black magic, and it just keeps it so that\nit can make its prediction",
    "start": "4664693",
    "end": "4672489"
  },
  {
    "text": "for the next word. It's amazing. It's coming earlier. We had that converging\nstructure for the neurons.",
    "start": "4672490",
    "end": "4679610"
  },
  {
    "text": "This is just a different\nway that shape now? Yeah, and you can\nimagine, much like when",
    "start": "4679610",
    "end": "4688471"
  },
  {
    "text": "we were producing\nimages, remember, we were producing images. You could produce one pixel,\nand then another pixel, and the third pixel.",
    "start": "4688472",
    "end": "4694120"
  },
  {
    "text": "It's a lot like that. These are just a\nbunch of neurons. And they're all going to\nbe produced a little bit like they're pixels. It's just we're going\nto store them as a state",
    "start": "4694120",
    "end": "4700450"
  },
  {
    "text": "and use in different ways. We're actually-- wow. I was like two algorithms.",
    "start": "4700450",
    "end": "4705760"
  },
  {
    "text": "How long could it take? But I wanted to draw\nthe board because I wanted to go slow and\ngo to the details. And maybe if I could\nleave it on this--",
    "start": "4705760",
    "end": "4711165"
  },
  {
    "text": " normally, I was\nthe person who was",
    "start": "4711165",
    "end": "4716580"
  },
  {
    "text": "hoping we'd never hit general\nintelligence was hoping we'd stay in like\nthe simple world where we just do our\neducational things.",
    "start": "4716580",
    "end": "4722477"
  },
  {
    "text": "But I must say, until\nThursday, I was like, oh, yeah, people are\nmaking their GPTs,",
    "start": "4722477",
    "end": "4727650"
  },
  {
    "text": "how cute, oh my God, Dall-E, I\ncan make a picture of a tree. This is fantastic. And then I started\nplaying around this a lot",
    "start": "4727650",
    "end": "4733392"
  },
  {
    "text": "over the weekend. And in my heart I feel like\nit is a bit of a change. And it's not such a big change.",
    "start": "4733392",
    "end": "4739897"
  },
  {
    "text": "It's not like the\nwhole world is going to reorient around this stuff. But it is a new technology.",
    "start": "4739897",
    "end": "4745199"
  },
  {
    "text": "And you know what\nit reminds me of? Did I say I was so\nold I remember when mobile phones became a thing? I was a computer science major.",
    "start": "4745200",
    "end": "4751860"
  },
  {
    "text": "And all of a sudden\nwe have mobile phones. You can make apps. And there was a rush. Everyone wanted to make an app. My God, I probably\nshould have made a map.",
    "start": "4751860",
    "end": "4758190"
  },
  {
    "text": "If I made an app, maybe I\ncould have retired young. Note to self. Hey, do you want to\ngo into a business? We're going to do some cool\nGPT-based neural network?",
    "start": "4758190",
    "end": "4765655"
  },
  {
    "text": "No? [INAUDIBLE] put in the\n[INAUDIBLE] set app. Oh, we'll put it in\nthe [INAUDIBLE] app, and then we'll all\ndo it together.",
    "start": "4765655",
    "end": "4772030"
  },
  {
    "text": "And did mobile phones\nchange everything? Yes and no. There was a whole set\nof new ideas that came.",
    "start": "4772030",
    "end": "4778595"
  },
  {
    "text": "Things were possible. It was a very exciting time\nto be a young researcher because all of a sudden I got to\nthe cutting edge a lot faster.",
    "start": "4778595",
    "end": "4786820"
  },
  {
    "text": "When I look at GPT-3,\nI told you a lot of what I know about GPT-3. And soon you guys can\nbe on that cutting edge.",
    "start": "4786820",
    "end": "4794662"
  },
  {
    "text": "And I think that's a\nlittle bit exciting. It's a little bit terrifying\nbecause there's uncertainty. And uncertainty is always\nhard, except for people",
    "start": "4794662",
    "end": "4800470"
  },
  {
    "text": "who study probability. We like to make decisions\nunder uncertainty. I don't know. And I would welcome you\nguys to this conversation.",
    "start": "4800470",
    "end": "4807620"
  },
  {
    "text": "What do you guys think\nit means and where do you want to see it go how\nwould you like to shape it? What role would\nyou like to play?",
    "start": "4807620",
    "end": "4814550"
  },
  {
    "text": "And then come back on Wednesday. It's our very final class. We're going to say goodbye. I'll miss you.",
    "start": "4814550",
    "end": "4819880"
  },
  {
    "text": "Don't be strangers. Have a fantastic day. You guys rock. See you on Wednesday.",
    "start": "4819880",
    "end": "4825540"
  },
  {
    "start": "4825540",
    "end": "4830000"
  }
]
[
  {
    "start": "0",
    "end": "6770"
  },
  {
    "text": "OK, great. So the first sort of paper that\nI'm going to be talking about is called emergent abilities\nof large language models.",
    "start": "6770",
    "end": "13490"
  },
  {
    "text": "And this paper was\nespecially cool, I think, because we got people\nfrom Google and DeepMind,",
    "start": "13490",
    "end": "19130"
  },
  {
    "text": "and also Stanford\nyou might recognize Percy, or Tatsuya, or Rishi.",
    "start": "19130",
    "end": "24380"
  },
  {
    "text": "I mean, we got people\nto agree on what's a nice framework of looking\nat why we want to scale",
    "start": "24380",
    "end": "30710"
  },
  {
    "text": "and emerging abilities. So one of the things that we've\nseen throughout language models",
    "start": "30710",
    "end": "38810"
  },
  {
    "text": "is that you get these\npredictable gains as a result of scaling. So here's the canonical\nKaplan et al paper,",
    "start": "38810",
    "end": "46820"
  },
  {
    "text": "where you can see\nthat, if you scale up the size of the language\nmodel, measured either in compute, in data set\nsize, or in parameters.",
    "start": "46820",
    "end": "55940"
  },
  {
    "text": "You see that the loss\non the test set actually goes down predictably.",
    "start": "55940",
    "end": "62098"
  },
  {
    "text": "With your screen sharing. So people in Zoom, I don't\nthink, can see the slides. Yeah, yeah, yeah. Sorry. ",
    "start": "62098",
    "end": "69830"
  },
  {
    "text": "OK. I guess I'll say this\nfor the third time. As we've seen in\nlanguage models,",
    "start": "69830",
    "end": "77600"
  },
  {
    "text": "if you scale up the\nsize of language model, measured either in\ncompute, in data set size,",
    "start": "77600",
    "end": "83270"
  },
  {
    "text": "or a number of\nparameters, you can see that there's a sort of\nthis predictable improvement in the test loss.",
    "start": "83270",
    "end": "88955"
  },
  {
    "text": " Now, what I'm going to\nbe talking about in terms",
    "start": "88955",
    "end": "94380"
  },
  {
    "text": "of emergence, is something\nthat's actually unpredictable, if you only look at\nsmaller language models.",
    "start": "94380",
    "end": "100530"
  },
  {
    "text": "So one way that emergence has\nbeen described in the broader science literature\nis, it's basically",
    "start": "100530",
    "end": "106530"
  },
  {
    "text": "seen as a qualitative\nchange that arises from quantitative changes. It sort of started with\nthis article in science",
    "start": "106530",
    "end": "114240"
  },
  {
    "text": "by a Nobel Prize\nwinning physicist called \"More is Different.\"",
    "start": "114240",
    "end": "119300"
  },
  {
    "text": "And I really like this post\nfrom Jacob Steinhardt that sort of describes emergence.",
    "start": "119300",
    "end": "125420"
  },
  {
    "text": "He gives a couple of\ngood examples here. For example, he\nsays, with uranium.",
    "start": "125420",
    "end": "130610"
  },
  {
    "text": "With a bit of uranium,\nnothing special happens. With the large amount of\nuranium packed densely enough,",
    "start": "130610",
    "end": "136019"
  },
  {
    "text": "you get a nuclear reaction. And then also, with\nDNA, for example. Given only small\nmolecules such as calcium,",
    "start": "136020",
    "end": "142760"
  },
  {
    "text": "you can't meaningfully\nencode useful information. But given larger models such as\nDNA, you can encode a genome.",
    "start": "142760",
    "end": "148190"
  },
  {
    "text": " So for this particular\nwork, we use this definition",
    "start": "148190",
    "end": "155430"
  },
  {
    "text": "of emergent abilities of large\nlanguage models in particular. So we say that\nability is emergent",
    "start": "155430",
    "end": "162150"
  },
  {
    "text": "if it is not present\nin smaller models, but it is present\nin larger models.",
    "start": "162150",
    "end": "167849"
  },
  {
    "text": "And the sort of\nnatural question here is, how do you measure the size\nor the scale of the language",
    "start": "167850",
    "end": "173190"
  },
  {
    "text": "model? And they're traditionally\nthree axes of scale. So the training FLOPS\nor the amount of compute",
    "start": "173190",
    "end": "179700"
  },
  {
    "text": "that you use to train\nthe language model. The number of model\nparameters or the size of the language model.",
    "start": "179700",
    "end": "185460"
  },
  {
    "text": "And also the size\nof the training data set that the model\nis trained on. And a lot of the plots here\nwill use either training FLOPS",
    "start": "185460",
    "end": "193300"
  },
  {
    "text": "or the number of\nmodel parameters. The reason is that the\ntraining of the asset size is usually fixed for\ndifferent sized models.",
    "start": "193300",
    "end": "200800"
  },
  {
    "text": "And because training\nFLOPS is just the data set size times\nmodel of parameters, you can get a similar plot\nfrom either training FLOPS",
    "start": "200800",
    "end": "208390"
  },
  {
    "text": "or a number of model parameters\nfor most language models. ",
    "start": "208390",
    "end": "214550"
  },
  {
    "text": "Great. And so the first\ntype of emergence-- yeah, sorry, go ahead.",
    "start": "214550",
    "end": "221000"
  },
  {
    "text": "Yeah. For, me it seems like it\nwould be relatively easier to measure the size.",
    "start": "221000",
    "end": "226010"
  },
  {
    "text": "First it's like what\nqualifies as natural. I need to find chances of\nnatural ability versus not.",
    "start": "226010",
    "end": "234110"
  },
  {
    "text": "Yeah, sure-- So yeah, for example,\nI'll just give an example",
    "start": "234110",
    "end": "241190"
  },
  {
    "text": "here, which is actually\nin the next slide. So basically, we have\nthis way of interacting",
    "start": "241190",
    "end": "246200"
  },
  {
    "text": "with language models,\ncalled few short prompting. And the way it works is, the\nlanguage model is a really good",
    "start": "246200",
    "end": "252049"
  },
  {
    "text": "next word predictor. And when you give the\nmodel an example, and then",
    "start": "252050",
    "end": "258169"
  },
  {
    "text": "you ask it for an unseen like\nmovie review for example.",
    "start": "258170",
    "end": "264060"
  },
  {
    "text": "And then you say,\nwhat's the output? And then here,\nthe language model can say positive,\nbecause it understands to use the context from the\nreview to give the next token.",
    "start": "264060",
    "end": "274039"
  },
  {
    "text": "And the definition that we\nuse for having ability or not, is that basically, a\nfew shot prompted task,",
    "start": "274040",
    "end": "281840"
  },
  {
    "text": "for example, sentiment\nanalysis, is emergent if it has random accuracy\nfor small models,",
    "start": "281840",
    "end": "287840"
  },
  {
    "text": "but above random accuracy\nfor large models. Does that make sense? So basically, if the model isn't\ndoing any better than random,",
    "start": "287840",
    "end": "294585"
  },
  {
    "text": "then we say it doesn't\nhave the ability to do this particular task. ",
    "start": "294585",
    "end": "302050"
  },
  {
    "text": "I'll give you a\nfew examples here. So here's the canonical way that\nwe look at plots for emergence.",
    "start": "302050",
    "end": "309730"
  },
  {
    "text": "So basically, what we have,\neach of these different plots is a different task, and I'll\ngo over some examples soon.",
    "start": "309730",
    "end": "318040"
  },
  {
    "text": "But the way you\nread the plot is, the x-axis is the number\nof training FLOPS, or the model scale.",
    "start": "318040",
    "end": "324520"
  },
  {
    "text": "And then, the y-axis\nis like the accuracy, or how good the model\nis doing the task.",
    "start": "324520",
    "end": "330280"
  },
  {
    "text": "And then, we have different\nlanguage models from OpenAI, from Google, and from DeepMind.",
    "start": "330280",
    "end": "336280"
  },
  {
    "text": "And then, each of the points\nis a different language model. It's not a language model\nover the course of training.",
    "start": "336280",
    "end": "342280"
  },
  {
    "text": "Each point is a\ndifferent language model. And what you see is that, for\nthe very small language models,",
    "start": "342280",
    "end": "349510"
  },
  {
    "text": "you basically get a performance\nthat's close to random, or not being any\nbetter than random.",
    "start": "349510",
    "end": "355990"
  },
  {
    "text": "And then once you pass\na certain threshold, you can see that the performance\nsuddenly gets above random.",
    "start": "355990",
    "end": "365602"
  },
  {
    "text": "And this is what\nwe call emergence. So basically, if you were\nto extrapolate the lines",
    "start": "365602",
    "end": "371230"
  },
  {
    "text": "from the small\nlanguage models, you might predict that it would\nnever do better than random because it's just a flat line.",
    "start": "371230",
    "end": "377668"
  },
  {
    "text": "But the interesting phenomena\nis that when you scale up past a certain\nthreshold, you actually do see this emergent\nphenomenon where the model does",
    "start": "377668",
    "end": "384340"
  },
  {
    "text": "a lot better than random.  So let me go over some\nconcrete examples.",
    "start": "384340",
    "end": "392330"
  },
  {
    "text": "So here's one task. It's basically a benchmark\ncalled multitask NLU or MMLU.",
    "start": "392330",
    "end": "400090"
  },
  {
    "text": "And basically, what\nit is, it's a bunch of test questions\nranging from high school",
    "start": "400090",
    "end": "406180"
  },
  {
    "text": "all the way to\nprofessional level exams. And how it works is,\nthe language model",
    "start": "406180",
    "end": "411900"
  },
  {
    "text": "is sort of given-- for example, here is a\nhigh school math example.",
    "start": "411900",
    "end": "417210"
  },
  {
    "text": "And the language model\nis given a few examples, and then for an unseen question,\nit has to give the answer.",
    "start": "417210",
    "end": "424080"
  },
  {
    "text": "And then you can see in\nthe plot on the right. So for the model scale,\nif you go up to 10",
    "start": "424080",
    "end": "430199"
  },
  {
    "text": "to the power of\n22 training slots, you don't actually get any\nbetter than random accuracy on this task.",
    "start": "430200",
    "end": "435509"
  },
  {
    "text": "But if you scale up to 10\nto the 24 training FLOPS, then you see that all the three\nmodels there do much better",
    "start": "435510",
    "end": "442770"
  },
  {
    "text": "than random accuracy.  Yeah, go ahead.",
    "start": "442770",
    "end": "448330"
  },
  {
    "text": "The scale of the data\nused to train this, is it roughly similar,\nor because these are different models\ntrained by different ports?",
    "start": "448330",
    "end": "456069"
  },
  {
    "text": "Yeah, the scale is, I think,\nwithin an order of magnitude for these models here, yeah.",
    "start": "456070",
    "end": "462370"
  },
  {
    "text": "And plus, every single dot\non each individual tracks is the same data?",
    "start": "462370",
    "end": "467680"
  },
  {
    "text": "Yes, the data is fixed\nexcept for a chinchilla. Chinchilla it uses more\ndata for larger models,",
    "start": "467680",
    "end": "473020"
  },
  {
    "text": "but I believe, for all the other\nmodels here, the amount of data stays the same. ",
    "start": "473020",
    "end": "481100"
  },
  {
    "text": "Yeah, here's just\nanother example to show it more concretely. So this is a task from\nthe BIG-bench benchmark.",
    "start": "481100",
    "end": "490550"
  },
  {
    "text": "Just as an aside, the BIG-bench\nbenchmark is 200 benchmarks, and basically it's like a\ncrowdsource set of benchmarks,",
    "start": "490550",
    "end": "498140"
  },
  {
    "text": "so I'd recommend looking at if\nyou're doing [INAUDIBLE] work. And basically, the task\nis, the language model",
    "start": "498140",
    "end": "503930"
  },
  {
    "text": "has to take an English\nsentence, and then give the International Phonetic\nAlphabet transliteration,",
    "start": "503930",
    "end": "510590"
  },
  {
    "text": "the IPA transliteration,\nwhich is basically, how to pronounce it.",
    "start": "510590",
    "end": "515959"
  },
  {
    "text": "And for this task,\nthe evaluation metric is actually blue or like\nan N-gram overlap metric.",
    "start": "515960",
    "end": "523190"
  },
  {
    "text": "And you got a similar\nphenomenon where, as you increase the size\nof the language model,",
    "start": "523190",
    "end": "529910"
  },
  {
    "text": "it's flat for a while, and\nthen suddenly the improvement is above random. ",
    "start": "529910",
    "end": "537690"
  },
  {
    "text": "Great. So I'll talk about another\ninteresting result here",
    "start": "537690",
    "end": "543217"
  },
  {
    "text": "that, that's why it's emergence. So this was a technical\nreport that we put out a couple of months ago.",
    "start": "543217",
    "end": "549170"
  },
  {
    "text": "And basically, there's this\nreally interesting prize in-- or it's like a one time\nprize in language models",
    "start": "549170",
    "end": "557660"
  },
  {
    "text": "where, Anthropic, which\nis like a startup, basically had this prize\nwhere, if people could come up",
    "start": "557660",
    "end": "563720"
  },
  {
    "text": "with a task where the\nperformance on the task would actually decrease\nas you increase",
    "start": "563720",
    "end": "571009"
  },
  {
    "text": "the size of the\nlanguage model, then you would get a bunch of money. So basically, there are a\nlot of submissions to this,",
    "start": "571010",
    "end": "577590"
  },
  {
    "text": "and here's one example\nof a task where they found that the\nperformance would actually decrease if you increase the\nsize of the language model.",
    "start": "577590",
    "end": "585110"
  },
  {
    "text": "So the tasks is-- here it's like, repeat\nmy sense is back to me, and then the input is, all\nthat glisters is not glue.",
    "start": "585110",
    "end": "593030"
  },
  {
    "text": "And the output is-- the model has to\naccurately say a glue.",
    "start": "593030",
    "end": "601339"
  },
  {
    "text": "And so what happened is, for\nthe small language model, it doesn't know the phrase\nall that glisters is not gold.",
    "start": "601340",
    "end": "609350"
  },
  {
    "text": "So it just copies the input\nand actually does good. It's like 100% on that.",
    "start": "609350",
    "end": "614740"
  },
  {
    "text": "But then, for the\nmedium size language model, what you would see is\nthat the performance actually",
    "start": "614740",
    "end": "620080"
  },
  {
    "text": "decreased. Because the medium size\nlanguage model knows the phrase all that glisters is\nnot gold, and then it",
    "start": "620080",
    "end": "625389"
  },
  {
    "text": "says gold, which actually is\nnot what the task asks it to do. Yeah, go ahead. Someone on Zoom asked, can\nyou get a physical estimate",
    "start": "625390",
    "end": "632050"
  },
  {
    "text": "of 10 to 24 FLOPS? Possibly in terms of training\ntime or number of years.",
    "start": "632050",
    "end": "638470"
  },
  {
    "text": "Yeah, so I think 10 to\nthe 24 FLOPS is around--",
    "start": "638470",
    "end": "645790"
  },
  {
    "text": "so at Google, we use TPUs. And one part of TPUs, I believe,\nis equal to 4,000 a 110s.",
    "start": "645790",
    "end": "655740"
  },
  {
    "text": "And 10 to the 24 FLOPS is like\ntwo pods for around six weeks or something like that.",
    "start": "655740",
    "end": "662480"
  },
  {
    "text": "So it's a lot of compute\nto do the pretraining. ",
    "start": "662480",
    "end": "667613"
  },
  {
    "text": "I don't know, but do you guys\nremember in chemistry class, when you'd have moles.",
    "start": "667613",
    "end": "672730"
  },
  {
    "text": "And it would be\nlike 10 to the 23, and then you're like--\nteacher would be like, oh, don't even think about\nhow big this number is.",
    "start": "672730",
    "end": "678940"
  },
  {
    "text": "That's like the number of\nfloating point operations that goes into the pretraining\nof some of these models.",
    "start": "678940",
    "end": "686350"
  },
  {
    "text": "OK, great. Anyways so basically, the\nmedium size language model",
    "start": "686350",
    "end": "692300"
  },
  {
    "text": "will actually do worse. Oh, yeah. Did you have another question? Yeah.",
    "start": "692300",
    "end": "697752"
  },
  {
    "text": "Does this one the price or not? This one is one of the--",
    "start": "697752",
    "end": "703649"
  },
  {
    "text": "I think it's the third\nplace winner or something. [INAUDIBLE]",
    "start": "703650",
    "end": "708660"
  },
  {
    "text": " Because I would think-- my initial opinion\nwould be, oh, you",
    "start": "708660",
    "end": "713740"
  },
  {
    "text": "can just put a negative sign\non how you evaluate your tests [INAUDIBLE] What do you mean\nflip a negative sign?",
    "start": "713740",
    "end": "720420"
  },
  {
    "text": "Well, because all of\nthis depends on which evaluation scheme you use to\nmeasure and you do your test.",
    "start": "720420",
    "end": "727770"
  },
  {
    "text": "So it's like the\nmeasurement is very sparse, you only get credit if you\ndo it perfectly or something.",
    "start": "727770",
    "end": "735000"
  },
  {
    "text": "So a lot of things emerge. Because you just won't\nget it perfectly.",
    "start": "735000",
    "end": "740760"
  },
  {
    "text": "Really optimize it\nfor a long time. Or if you take a test,\nand then like evaluate,",
    "start": "740760",
    "end": "746610"
  },
  {
    "text": "it's like it's minus sing. Wouldn't it get worse?",
    "start": "746610",
    "end": "751900"
  },
  {
    "text": "Like something\nthat's [INAUDIBLE].. Yeah. So for this thing, they\nlike to count it for all.",
    "start": "751900",
    "end": "757170"
  },
  {
    "text": "You can't just say\nthe task should be able to do badly on something. It has to be a\nmeaningful sort of task.",
    "start": "757170",
    "end": "763390"
  },
  {
    "text": "And then, I guess\nyour point about how [INAUDIBLE] or the\nvaluation metric works is actually a really good one.",
    "start": "763390",
    "end": "771090"
  },
  {
    "text": "So I guess it still\nkind of counts if-- I guess the argument is,\nthe performance might not",
    "start": "771090",
    "end": "780420"
  },
  {
    "text": "look emergent if you\nassign partial credit. But we have a bunch of-- I can show example later, but\neven if you use partial credit",
    "start": "780420",
    "end": "788580"
  },
  {
    "text": "metrics, you'll often still\nsee the same type of emergence. So it's not purely a phenomenon\nof not assigning partial credit",
    "start": "788580",
    "end": "795230"
  },
  {
    "text": "based on the valuation metric. ",
    "start": "795230",
    "end": "802139"
  },
  {
    "text": "And then-- great. So what we argued in this\npaper is that, yeah, there",
    "start": "802140",
    "end": "808240"
  },
  {
    "text": "might be some tasks where\nthe performance starts to decrease if you use a\nmedium size language model.",
    "start": "808240",
    "end": "813660"
  },
  {
    "text": "But if you keep scaling all\nthe way to the largest model that we have at Google\nthat's known publicly.",
    "start": "813660",
    "end": "822150"
  },
  {
    "text": "PaLM. You'll see that the\nlanguage model can actually go back and do the\ntask correctly.",
    "start": "822150",
    "end": "827759"
  },
  {
    "text": "Because the large language\nmodel also knows the phrase all that glisters is not\ngold, but it also understands",
    "start": "827760",
    "end": "836250"
  },
  {
    "text": "repeat my senses back to me. So it's able to get\n100% on this task. So this is a different\ntype of emergence also.",
    "start": "836250",
    "end": "844020"
  },
  {
    "text": " And another class of emergence\nthat we talk about in the paper",
    "start": "844020",
    "end": "853420"
  },
  {
    "text": "is an emergent\nprompting technique. So basically, other than\n[INAUDIBLE] prompting,",
    "start": "853420",
    "end": "859270"
  },
  {
    "text": "there's other ways\nof interacting with the language models, that\ncan be considered emergent.",
    "start": "859270",
    "end": "866230"
  },
  {
    "text": "Yeah? Sorry, somebody\nelse had a question on the previous slides. The question is, did all\nmodels undergo instruction fine",
    "start": "866230",
    "end": "873790"
  },
  {
    "text": "tuning? None of these models\nunderwent instruction fine tuning for this plot.",
    "start": "873790",
    "end": "880190"
  },
  {
    "text": "Yeah.  Great.",
    "start": "880190",
    "end": "886863"
  },
  {
    "text": "Yeah, so one way of interacting\nwith language models is by basically\nfinding the model using",
    "start": "886863",
    "end": "893710"
  },
  {
    "text": "a technique called RLHF. And basically the\nway it works is, you have this data, and humans\nrate preferences for what",
    "start": "893710",
    "end": "900670"
  },
  {
    "text": "type of outputs they prefer. And then the model is\ntrained on how to optimize for human preferences.",
    "start": "900670",
    "end": "908800"
  },
  {
    "text": "And what this plot\nis showing here, is that, if you do\nthis RLHF on the model,",
    "start": "908800",
    "end": "914260"
  },
  {
    "text": "the model performance on\na different zero-shot task actually gets worse\nfor small models.",
    "start": "914260",
    "end": "919600"
  },
  {
    "text": "You can see the blue line\nis above the orange line. Blue line is the baseline,\nthe orange line is RLHF.",
    "start": "919600",
    "end": "926880"
  },
  {
    "text": "And then, if you do\nit for large models, though, then you can see\nthat the performance actually",
    "start": "926880",
    "end": "932100"
  },
  {
    "text": "has a positive delta\nfrom doing RLHF.  And so this is sort of an\ninteresting thing, where",
    "start": "932100",
    "end": "939110"
  },
  {
    "text": "a certain technique\nmight only help if you try on a large\nenough language model. So if you only try to on\nthe small language models,",
    "start": "939110",
    "end": "946220"
  },
  {
    "text": "it'd be tough to draw\nthe conclusion that it wouldn't help performance.",
    "start": "946220",
    "end": "951303"
  },
  {
    "text": "And then later, I'll talk about\nchain of thought prompting as another emergent problem. ",
    "start": "951303",
    "end": "958660"
  },
  {
    "text": "So here's sort of the\nhand-waving diagram that I used, to think about\nemergence as a framework.",
    "start": "958660",
    "end": "965260"
  },
  {
    "text": "So on the x-axis here, there's\na scale of the language model. And on the y-axis,\nthere's a sort",
    "start": "965260",
    "end": "971190"
  },
  {
    "text": "of imaginary range of things\nthat a language model can do.",
    "start": "971190",
    "end": "978550"
  },
  {
    "text": "And then basically, you\ncan pick some random point, like say, 100 billion parameters\nin the language model. And there will be\ncertain abilities.",
    "start": "978550",
    "end": "986140"
  },
  {
    "text": "OK, so first you can\nsee, as you increase the size of the language model,\nthe number of tasks or things",
    "start": "986140",
    "end": "991830"
  },
  {
    "text": "the language model\ncan do increases. And then you can see,\nthere are some tasks where",
    "start": "991830",
    "end": "998140"
  },
  {
    "text": "model's above 100 billion\nparameters, for example, can do them, but models below\n100 parameters can't do them,",
    "start": "998140",
    "end": "1003510"
  },
  {
    "text": "and we call these\nemerging abilities Sorry, quick question\nabout the slide. What are the colors?",
    "start": "1003510",
    "end": "1010480"
  },
  {
    "text": "Oh, it's just highlighting-- the dark blue is tasks\nthat a smaller language",
    "start": "1010480",
    "end": "1016900"
  },
  {
    "text": "model wouldn't be able to do. Does that make sense? Yeah. And then, to the right\nof the dotted line, the white region of top?",
    "start": "1016900",
    "end": "1024780"
  },
  {
    "text": "Oh, that just\nmeans tasks that we haven't been able to solve yet\nwith language models, yeah.",
    "start": "1024780",
    "end": "1031959"
  },
  {
    "text": "And I'm curious to\nknow, do you think that those tasks in the\nwhite region are unsolvable, like 100 billion scale.",
    "start": "1031960",
    "end": "1039280"
  },
  {
    "text": "Or do you think that better\nmodels, specific training data",
    "start": "1039280",
    "end": "1044290"
  },
  {
    "text": "would allow us to have\n100 billion scale get into that white region. Yeah, I definitely think\nthat it's not a fixed--",
    "start": "1044290",
    "end": "1054520"
  },
  {
    "text": "I'll give an example\nshortly, but it's not a rule that you have to have\n100 billion parameters",
    "start": "1054520",
    "end": "1061330"
  },
  {
    "text": "to do a certain task. It's just that that happens\nto be the threshold that we've observed in models so far.",
    "start": "1061330",
    "end": "1066940"
  },
  {
    "text": "And I do think, with better\ntraining data and architecture and algorithms, we can\nprobably beat that.",
    "start": "1066940",
    "end": "1072640"
  },
  {
    "text": " Cool. Yeah, so as [INAUDIBLE]\njust mentioned,",
    "start": "1072640",
    "end": "1080000"
  },
  {
    "text": "one example of getting emergence\ncan be with better data, so it's not all about scale.",
    "start": "1080000",
    "end": "1085370"
  },
  {
    "text": "I'll give some [INAUDIBLE] here. So for this task--\nthis is just one of the tasks in the\nBIG-bench benchmark.",
    "start": "1085370",
    "end": "1092300"
  },
  {
    "text": "You can see that for LaMDA,\nwhich is a Google model, and GPT-3, you actually don't\nget emergence from scaling",
    "start": "1092300",
    "end": "1098960"
  },
  {
    "text": "to 137 or 175\nbillion parameters.",
    "start": "1098960",
    "end": "1105770"
  },
  {
    "text": "But when you come in with a\ndifferent language model, PaLM, which is trained on better\ndata than LaMDA and GPT-3,",
    "start": "1105770",
    "end": "1112940"
  },
  {
    "text": "you actually can get\nthis emergent ability even with the smaller\nlanguage model, so in here at 62 billion parameters.",
    "start": "1112940",
    "end": "1120240"
  },
  {
    "text": "[INAUDIBLE] better model has\nbetter data, or also better architectural [INAUDIBLE]?",
    "start": "1120240",
    "end": "1127130"
  },
  {
    "text": " Yeah, so the challenging thing\nis-- that's a great question.",
    "start": "1127130",
    "end": "1135110"
  },
  {
    "text": "There's a lot of differences\nbetween PaLM and LaMDA, for example. And we can't really ablate them\nin any controlled way because",
    "start": "1135110",
    "end": "1141710"
  },
  {
    "text": "of the cost of pretraining. But our running\nhypothesis is that PaLM",
    "start": "1141710",
    "end": "1146882"
  },
  {
    "text": "is trained on better\ndata, and that accounts for a lot of the\ndifference between PaLM and LaMDA.",
    "start": "1146882",
    "end": "1152030"
  },
  {
    "text": "I seen the smaller scales where\nit is possible to ablate stuff? Really architecture wise.",
    "start": "1152030",
    "end": "1157580"
  },
  {
    "text": "[INAUDIBLE] Yeah, that's a good question. So I guess, even\nhere, you can look at,",
    "start": "1157580",
    "end": "1163025"
  },
  {
    "text": "for example, the\nPaLM 8-billion model. Like that. That point there.",
    "start": "1163025",
    "end": "1168680"
  },
  {
    "text": "You can ablate it, and\nit's a little bit higher, but it's not really an\nemergent yet at that point. So it's hard to tell, for\nexample, this particular task,",
    "start": "1168680",
    "end": "1177200"
  },
  {
    "text": "what the effect is. There's a question on Zoom. Are there two different\nversions of PaLM?",
    "start": "1177200",
    "end": "1183080"
  },
  {
    "text": "If not, why are there\ntwo lines for it? Oh, so I think the\ntwo lines here. One is maybe three shot,\nand then one is zero shot.",
    "start": "1183080",
    "end": "1194186"
  },
  {
    "text": "Something like that. So it just refers to\nthe way that we're using the language model.",
    "start": "1194187",
    "end": "1199340"
  },
  {
    "text": "Either with or\nwithout exemplars. ",
    "start": "1199340",
    "end": "1204810"
  },
  {
    "text": "Great. I'll talk about a small\nablation here that shows this.",
    "start": "1204810",
    "end": "1211220"
  },
  {
    "text": "So this is an ablation\non a toy task, where basically, the language\nmodel has to know that.",
    "start": "1211220",
    "end": "1218890"
  },
  {
    "text": "In English, you have to use\nplural verbs with plural subjects, and singular verbs\nwith singular subjects.",
    "start": "1218890",
    "end": "1224784"
  },
  {
    "text": " What we're doing\nhere is basically,",
    "start": "1224785",
    "end": "1230470"
  },
  {
    "text": "we train these small\nverb models from scratch, and then we held out--",
    "start": "1230470",
    "end": "1236289"
  },
  {
    "text": "we fixed the frequency\nof certain verbs in a training data set. Which basically says,\nOK, what's the effect",
    "start": "1236290",
    "end": "1242620"
  },
  {
    "text": "of seeing a certain verb\nin the data more often? In this plot, the x-axis is\nlike the frequency of the verb,",
    "start": "1242620",
    "end": "1250799"
  },
  {
    "text": "and the y-axis is\nthe error rate. And what you basically\nsee is that, if you",
    "start": "1250800",
    "end": "1256200"
  },
  {
    "text": "have more in-domain data. So if the model sees\nthe verb more times, it does the task a lot better.",
    "start": "1256200",
    "end": "1262140"
  },
  {
    "text": "This is an example of having\nhigh-quality data, or data that's more in-domain for\nthe task evaluating on,",
    "start": "1262140",
    "end": "1268826"
  },
  {
    "text": "can make a big difference. Even if you're fixing the\ncompute, the size of the model, and the rest of the data.",
    "start": "1268827",
    "end": "1276230"
  },
  {
    "text": "Question on Zoom. Someone asks, could\nthere be a way to distill convergent\nabilities down to smaller models from\nlarger teacher models?",
    "start": "1276230",
    "end": "1284470"
  },
  {
    "text": "Yeah, I think so. So larger teacher\nmodels can basically--",
    "start": "1284470",
    "end": "1291240"
  },
  {
    "text": "you can use them, for\nexample, to generate data. And then if you fine tune\nthe smaller model on data,",
    "start": "1291240",
    "end": "1298740"
  },
  {
    "text": "it's pretty likely that you'll\nbe able to get the ability to emerge in the smaller model.",
    "start": "1298740",
    "end": "1303778"
  },
  {
    "text": "I'll talk about\nexample of this, too. Let me see. Oh actually that's\nnext slide, so--",
    "start": "1303778",
    "end": "1309740"
  },
  {
    "text": "Desired behaviors can be\ninduced in smaller models once you know what\nbehavior you want.",
    "start": "1309740",
    "end": "1315210"
  },
  {
    "text": "So for example, here's a\nfigure from this ChatGPT paper.",
    "start": "1315210",
    "end": "1322760"
  },
  {
    "text": "And basically, the\ndesired behavior here is instruction following.",
    "start": "1322760",
    "end": "1327860"
  },
  {
    "text": "And you can see that\nthere's multiple models. So on the left you\nhave these small models",
    "start": "1327860",
    "end": "1333050"
  },
  {
    "text": "that are trained with\nRLHF, and they actually have better performance\nthan larger models",
    "start": "1333050",
    "end": "1338630"
  },
  {
    "text": "trained on weaker techniques. So basically the\npoint is, if you know that you want a\ncertain behavior that you",
    "start": "1338630",
    "end": "1346040"
  },
  {
    "text": "saw previously in an emergent\nway in a larger model, you can find a way to\nfine tune on that behavior",
    "start": "1346040",
    "end": "1352700"
  },
  {
    "text": "specifically, and induce that\nbehavior in a smaller model.",
    "start": "1352700",
    "end": "1358070"
  },
  {
    "text": "But I guess, one\nof the limitations is that, unless you know all\nthe behaviors that you want,",
    "start": "1358070",
    "end": "1363260"
  },
  {
    "text": "you can't really get this\nnatural emergent behavior. ",
    "start": "1363260",
    "end": "1370700"
  },
  {
    "text": "Yeah, another discussion\npoint here is that-- there's this question of, what's\nthe right x-axis for emergence?",
    "start": "1370700",
    "end": "1377810"
  },
  {
    "text": "So right now, we mostly\ntalk about model parameters and training FLOPS. But I guess, if you ask DeepMind\npeople how they look at it,",
    "start": "1377810",
    "end": "1386150"
  },
  {
    "text": "you'll get this argument that\nmodel parameters and training FLOPS are really just a proxy\nfor how good the model is.",
    "start": "1386150",
    "end": "1393770"
  },
  {
    "text": "And how good the\nmodel is can really be measured by perplexity or\nhow well it's doing on some dev",
    "start": "1393770",
    "end": "1400430"
  },
  {
    "text": "sets, which is Wiki-text 103. So basically, you can\nalso measure emergence",
    "start": "1400430",
    "end": "1407180"
  },
  {
    "text": "in terms of perplexity. So here is Wiki-text perplexity.",
    "start": "1407180",
    "end": "1413600"
  },
  {
    "text": "And then you can see,\non a downstream task that, as the\nperplexity gets better, there's this threshold where\nare you able to do a lot better",
    "start": "1413600",
    "end": "1421370"
  },
  {
    "text": "on the downstream task. And there's a\nstrong correlation,",
    "start": "1421370",
    "end": "1427400"
  },
  {
    "text": "at least right now, between\nperplexity and training compute. So you can see these two\nlines are pretty similar.",
    "start": "1427400",
    "end": "1432950"
  },
  {
    "text": " Basically, I think,\nin the future if we have much\nbetter models that",
    "start": "1432950",
    "end": "1439735"
  },
  {
    "text": "are a lot smaller, churn\nout much better data and better algorithms, then\nmaybe Wiki-text perplexity can",
    "start": "1439735",
    "end": "1444970"
  },
  {
    "text": "show a different type of plot\nthan using other metrics. ",
    "start": "1444970",
    "end": "1451970"
  },
  {
    "text": "So Wiki-text is basically a-- I think it's a\nsubset of Wikipedia.",
    "start": "1451970",
    "end": "1459650"
  },
  {
    "text": "And then perplexity is a measure\nof how well you can predict the next word in a data set.",
    "start": "1459650",
    "end": "1465730"
  },
  {
    "text": "So basically, if you're really\ngood at modeling the next word on this particular\nevaluation set,",
    "start": "1465730",
    "end": "1472600"
  },
  {
    "text": "that's a measure of how well\nyou understand language. That make sense?",
    "start": "1472600",
    "end": "1478230"
  },
  {
    "text": "[INAUDIBLE]  Oh, this is like a\nheld out test set.",
    "start": "1478230",
    "end": "1483290"
  },
  {
    "start": "1483290",
    "end": "1490370"
  },
  {
    "text": "And then, a final\nthing that I think is pretty exciting\nabout emergence, is that they're sort of not\njust technical emergence",
    "start": "1490370",
    "end": "1498080"
  },
  {
    "text": "that we've talked\nabout, but there's sociological changes in how\nthe AI community views scaling",
    "start": "1498080",
    "end": "1504679"
  },
  {
    "text": "and how to use language models. So here are some\nexamples of where",
    "start": "1504680",
    "end": "1511810"
  },
  {
    "text": "scaling up the size of the\nlanguage model enables you to-- the sort of few-shot scenario.",
    "start": "1511810",
    "end": "1517900"
  },
  {
    "text": "Beat a task-specific,\nfine-tuned language model that's usually fine tuned on\nsay, thousands of examples.",
    "start": "1517900",
    "end": "1525200"
  },
  {
    "text": "So basically, the green line\nis the prior state-of-the-art achieved by fine tuning.",
    "start": "1525200",
    "end": "1532420"
  },
  {
    "text": "And then the blue\ndots basically show, if you take a pretrained\nlanguage model and you do few-shot prompting, which\nmeans the language model",
    "start": "1532420",
    "end": "1538420"
  },
  {
    "text": "isn't intentionally\ntrained to do the task, you can often get\nstate-of-the-art results just by continuing to scale up the\nsize of the language model.",
    "start": "1538420",
    "end": "1545950"
  },
  {
    "text": "And obviously, there's\nlimitations here, you don't want to just keep\nscaling up in order to get state-of-the-art.",
    "start": "1545950",
    "end": "1551620"
  },
  {
    "text": "But I think it's a pretty\nbig change in people's minds, that you could actually get\nsome of the best results",
    "start": "1551620",
    "end": "1556838"
  },
  {
    "text": "just by scaling up the\nsize of the language model and doing prompting.",
    "start": "1556838",
    "end": "1562430"
  },
  {
    "text": "Question from Zoom. Someone asks, is that\nnot a contradiction graph from two or three slides ago?",
    "start": "1562430",
    "end": "1568100"
  },
  {
    "text": " Which one? This one?",
    "start": "1568100",
    "end": "1574130"
  },
  {
    "text": "Shouldn't we, in general,\nassume-- oh, he said yes. OK.",
    "start": "1574130",
    "end": "1579380"
  },
  {
    "text": "We said, should we,\nin general, assume that scale trumps fine tune.",
    "start": "1579380",
    "end": "1584480"
  },
  {
    "text": "Yeah, so that's\na great question. So this plot is saying that\nyou fine tune and you can do--",
    "start": "1584480",
    "end": "1593240"
  },
  {
    "text": "so it depends on\nyour particular task.",
    "start": "1593240",
    "end": "1599420"
  },
  {
    "text": "But what this plot is saying is\nthat fine-tuned smaller models",
    "start": "1599420",
    "end": "1610520"
  },
  {
    "text": "can do well on some tasks\nif you target it well. But for like tasks\nare more complicated,",
    "start": "1610520",
    "end": "1616140"
  },
  {
    "text": "often you can do\nbetter just by scaling. So there's sort\nof tasks that fall",
    "start": "1616140",
    "end": "1621230"
  },
  {
    "text": "into both of these categories. And I wouldn't say that\nit's contradictory.",
    "start": "1621230",
    "end": "1626520"
  },
  {
    "text": "I guess some tasks, you would do\na lot better just by scaling up",
    "start": "1626520",
    "end": "1633270"
  },
  {
    "text": "the size of the model. And then other tasks, if\nit's a very narrow domain or the large language\nmodel might not",
    "start": "1633270",
    "end": "1640100"
  },
  {
    "text": "be trained on that\nkind of data, then you would do better by fine tuning. ",
    "start": "1640100",
    "end": "1647070"
  },
  {
    "text": "OK, great. So here's a little\nsummary slide. So basically, emergent\nabilities can only",
    "start": "1647070",
    "end": "1653010"
  },
  {
    "text": "be observed in large models. And if you try to predict\ntheir emergence just by looking",
    "start": "1653010",
    "end": "1658225"
  },
  {
    "text": "at the plots for\nsmall models, then you wouldn't be able to do it. And of had a little reflection\non how to look at this.",
    "start": "1658225",
    "end": "1666870"
  },
  {
    "text": "So emergence is\nreally this framing of how to view new abilities\nthat are not intentionally",
    "start": "1666870",
    "end": "1672960"
  },
  {
    "text": "built in to the pretraining. And I think the subtext for\nthis is super important, which is, you can see it as\nimplicit argument for why",
    "start": "1672960",
    "end": "1680549"
  },
  {
    "text": "we should keep scaling\nup language models because you get these\nabilities that are really hard to find otherwise.",
    "start": "1680550",
    "end": "1687342"
  },
  {
    "text": "And the context around\nthis is pretty important because it's really\nexpensive to continue scaling",
    "start": "1687342",
    "end": "1693320"
  },
  {
    "text": "up these models. And even one year\nago, a lot of people didn't believe that you could\ndo better on certain tasks",
    "start": "1693320",
    "end": "1700370"
  },
  {
    "text": "just by scaling up the\nsize of the language model.  If you work in industry\nat all, there's",
    "start": "1700370",
    "end": "1706310"
  },
  {
    "text": "this interesting tension\nbetween emergence and also like many production tasks. So emergence is\nsort of this task",
    "start": "1706310",
    "end": "1713480"
  },
  {
    "text": "general phenomena where\nyou scale up the model and it's really expensive,\nbut the single model",
    "start": "1713480",
    "end": "1718670"
  },
  {
    "text": "can do a lot of tasks. In the direction of AGI.",
    "start": "1718670",
    "end": "1724100"
  },
  {
    "text": "And then, for many\nproduction tasks, you have the opposite where\nyou know what task it is.",
    "start": "1724100",
    "end": "1730220"
  },
  {
    "text": "For example, translating\ninto Spanish. And then you have these\nconstraints on compute. Because when you build Google\nTranslate, for example,",
    "start": "1730220",
    "end": "1737267"
  },
  {
    "text": "you don't want people to have\nto wait a couple of seconds just to get the translation. And then, you also happen to\nhave a lot of in-domain data.",
    "start": "1737267",
    "end": "1745160"
  },
  {
    "text": "So you have, for\nexample, a million pairs of English Spanish\nsentences to turn on.",
    "start": "1745160",
    "end": "1752150"
  },
  {
    "text": "And this is the\nopposite setting, where you don't really care\nabout the model's emergence.",
    "start": "1752150",
    "end": "1758720"
  },
  {
    "text": "You can just train a very\nsmall model on the data, and do all of the task without\nhaving to use a lot of compute.",
    "start": "1758720",
    "end": "1765840"
  },
  {
    "text": "And the final point\nis that, I think, a really promising\nresearch direction, if anyone is interested\nin doing research,",
    "start": "1765840",
    "end": "1772590"
  },
  {
    "text": "is to work on predicting\nfuture emergent abilities. And I haven't seen\na lot of work on it",
    "start": "1772590",
    "end": "1778380"
  },
  {
    "text": "recently just because, I\nthink, maybe it's too hard, for example. You can only predict\nemergence for a specific task.",
    "start": "1778380",
    "end": "1786360"
  },
  {
    "text": "Or one way of\npredicting emergence might not be super\ngeneral, and-- so I haven't seen\nmuch work on that,",
    "start": "1786360",
    "end": "1792220"
  },
  {
    "text": "but I think this is a pretty\npromising direction to work on. And maybe [INAUDIBLE] is\nworking on it, I don't know.",
    "start": "1792220",
    "end": "1797368"
  },
  {
    "text": " OK, great. Any questions on\nthat before I move on to chain-of-thought prompting?",
    "start": "1797368",
    "end": "1804505"
  },
  {
    "text": "Yeah, go ahead.  Do we have any theoretical\nbasis to predicting",
    "start": "1804505",
    "end": "1810200"
  },
  {
    "text": "which parameters are best\nscaled to get [INAUDIBLE]?? So obviously, there are many\ndifferent options for where",
    "start": "1810200",
    "end": "1816710"
  },
  {
    "text": "you [INAUDIBLE]. Like GPT, for example, you\ncan [INAUDIBLE] event there.",
    "start": "1816710",
    "end": "1822680"
  },
  {
    "text": "You had more of\n[INAUDIBLE] or whatever. Is that mostly\nsomething we just test,",
    "start": "1822680",
    "end": "1827870"
  },
  {
    "text": "and then we find out\nwhich ones scale better to get better results-- Yeah.",
    "start": "1827870",
    "end": "1833810"
  },
  {
    "text": "I would say that we don't have\nvery principled methods for how to scale up these architectures.",
    "start": "1833810",
    "end": "1841702"
  },
  {
    "text": "I'm not an expert on\nthis, but some of it has to do with how\nmany parameters you can fit onto a particular TPU.",
    "start": "1841702",
    "end": "1850280"
  },
  {
    "text": "But in general, I\nthink, you scale up the number of intentions\nheads and embeddings",
    "start": "1850280",
    "end": "1855740"
  },
  {
    "text": "somewhat proportionally. But yeah, I think this is like\nan open research question.",
    "start": "1855740",
    "end": "1861740"
  },
  {
    "text": "You can't really do ablations\nover these pretraining. You can't really do\nablations over pretraining.",
    "start": "1861740",
    "end": "1867860"
  },
  {
    "text": "It's hard to have any\nprincipled way of doing it, other than some engineers who\nare in charge of doing it.",
    "start": "1867860",
    "end": "1875152"
  },
  {
    "text": "Say, OK, I think this is\nthe right thing to do, and then it kind of\nworks, and you go with it.",
    "start": "1875152",
    "end": "1880280"
  },
  {
    "text": "Yeah? Do you have any indication\nof [INAUDIBLE] behavior of the [INAUDIBLE]? Do you expect that\neventually it would reach",
    "start": "1880280",
    "end": "1888230"
  },
  {
    "text": "a plateau of [INAUDIBLE] loss? Or would it just go all\nthe way down to zero?",
    "start": "1888230",
    "end": "1894920"
  },
  {
    "text": "Yeah, that's a great question. ",
    "start": "1894920",
    "end": "1900080"
  },
  {
    "text": "You mean on perplexity or some-- on a particular task,\nor just in general,",
    "start": "1900080",
    "end": "1906080"
  },
  {
    "text": "like next word prediction? Well, seems like these results\nare pretty general, pretty task independent, right? It's like emergent scaling.",
    "start": "1906080",
    "end": "1912440"
  },
  {
    "text": "Yeah. But if you take the limit\nof infinite parameters, then even analytically,\nis there any sense",
    "start": "1912440",
    "end": "1918200"
  },
  {
    "text": "of how that converges? Yeah, I have no clue.",
    "start": "1918200",
    "end": "1923900"
  },
  {
    "text": "For most of these tasks, there's\na limit to accuracy, like 100%, for example. So there's some sort\nof asymptote there.",
    "start": "1923900",
    "end": "1930440"
  },
  {
    "text": "But I guess, the deeper question\nthat you might be asking is, can a language\nmodel perfectly know",
    "start": "1930440",
    "end": "1936500"
  },
  {
    "text": "how to predict the next\nword for any given input?",
    "start": "1936500",
    "end": "1941970"
  },
  {
    "text": "And maybe, I guess\nthere's some limit to--",
    "start": "1941970",
    "end": "1948090"
  },
  {
    "text": "if I say a sentence, there\nare two possible next words or something, and\nyou might not be able to guess that perfectly.",
    "start": "1948090",
    "end": "1955775"
  },
  {
    "text": "I think there's\nsome limit, but I think we're far from\nreaching that limit, and there's still a\nlot of unsolved tasks that sort of indicate that\nthere's a lot of headroom.",
    "start": "1955775",
    "end": "1965110"
  },
  {
    "text": "Yeah? If researchers are interested\nin studying divergence, what family of\ndifferent-sized models",
    "start": "1965110",
    "end": "1971530"
  },
  {
    "text": "is publicly available,\nor best for study units? Yeah, good question.",
    "start": "1971530",
    "end": "1978470"
  },
  {
    "text": "So I think the OpenAI API\nhas a lot of language models,",
    "start": "1978470",
    "end": "1983648"
  },
  {
    "text": "and we actually use that a lot. Even at Google, it's\nused to study emergence. And that's one way of doing it.",
    "start": "1983648",
    "end": "1990190"
  },
  {
    "text": "And actually, a lot of these\nmodels are currently free. They're rate limited,\nbut they're free,",
    "start": "1990190",
    "end": "1995650"
  },
  {
    "text": "so we also use that. I think there's also\nsmaller language models.",
    "start": "1995650",
    "end": "2002850"
  },
  {
    "text": "Like, for example, there's\nthe UL2 model, that's like 20 billion parameters. But I guess--\nyou're right, there",
    "start": "2002850",
    "end": "2008670"
  },
  {
    "text": "is this challenge where\nsmall language models, you won't see a lot of\nthese emergent behaviors. So you kind of have\nto either train--",
    "start": "2008670",
    "end": "2017100"
  },
  {
    "text": "yeah, so you have to either\nuse OpenAI API for now, or wait until people\ntrain larger models.",
    "start": "2017100",
    "end": "2024180"
  },
  {
    "text": "I guess, there's also the BLOOM\nand like-- you guys probably know of that. The OPT models that\nare publicly available,",
    "start": "2024180",
    "end": "2030880"
  },
  {
    "text": "but I haven't seen a lot\nof experiments on them. Yeah. Yeah?",
    "start": "2030880",
    "end": "2036090"
  },
  {
    "text": "So my question is, are there\nemergent abilities that are",
    "start": "2036090",
    "end": "2041130"
  },
  {
    "text": "accessible and lower parameter\n[INAUDIBLE] maybe there might",
    "start": "2041130",
    "end": "2050610"
  },
  {
    "text": "be some that are-- maybe\nnot like chain of thought, but I heard some that are like-- Yeah, definitely, I\nthink, in the paper",
    "start": "2050610",
    "end": "2057060"
  },
  {
    "text": "we had a list couple\nof dozen abilities that would be emerging on\nlike 8 billion parameters, or like $60 billion parameters\nor something like that.",
    "start": "2057060",
    "end": "2063629"
  },
  {
    "text": " I have two questions from Zoom. The first question is, do\nyou see strategy tactics",
    "start": "2063630",
    "end": "2070050"
  },
  {
    "text": "between the larger tech firms\ndiffering systematically in studying these models?",
    "start": "2070050",
    "end": "2075150"
  },
  {
    "text": "Or is basically everyone\ntaking the same approach? ",
    "start": "2075151",
    "end": "2084750"
  },
  {
    "text": "I wouldn't say that everyone\nis taking the same approach. I think, as one\nexample, Anthropic",
    "start": "2084750",
    "end": "2092360"
  },
  {
    "text": "takes a very\nsafety-centric approach. And they're super interested\nin emergent abilities",
    "start": "2092360",
    "end": "2099080"
  },
  {
    "text": "because there could be emergent\nabilities that are undesirable, and they want to predict\nthose types of things.",
    "start": "2099080",
    "end": "2106700"
  },
  {
    "text": "also don't know what\nhappens at other companies other than at Google, so I can't\nreally speak too much to that.",
    "start": "2106700",
    "end": "2113680"
  },
  {
    "text": "Yeah? The second question. What are some examples of tasks\nor abilities that have not yet emerged even models like\nLaMDA, ChatGPT, et cetera?",
    "start": "2113680",
    "end": "2123030"
  },
  {
    "text": "Oh, yeah, I have-- maybe I'll just show\nthis real quick. ",
    "start": "2123030",
    "end": "2133680"
  },
  {
    "text": "There's a nice list somewhere. ",
    "start": "2133680",
    "end": "2145780"
  },
  {
    "text": "Yeah, so basically,\nwhat we did is, there's 200 tasks in BIG bench.",
    "start": "2145780",
    "end": "2151030"
  },
  {
    "text": "And then we basically\nclassified them into smoothly increasing,\nemergent with GPT-3 or LaMDA,",
    "start": "2151030",
    "end": "2158349"
  },
  {
    "text": "emergent with PaLM,\nand then flat, which is no model\nbetter than random. So I think, if you look at\nany of these tasks here,",
    "start": "2158350",
    "end": "2166000"
  },
  {
    "text": "they should still\nnot have emerged yet. And if you can get them to\nemerge, that'd be interesting.",
    "start": "2166000",
    "end": "2172450"
  },
  {
    "text": " Sorry? I think ChatGPT could\nbe 20 questions.",
    "start": "2172450",
    "end": "2178675"
  },
  {
    "text": "Oh, OK, yeah, this\nis not a super-- I think this is a couple\nof months old, so-- Oh, sorry. Yeah, yeah.",
    "start": "2178675",
    "end": "2184830"
  },
  {
    "text": "Oh, 20 questions? OK, yeah. [INAUDIBLE] Yeah, I think--\nthe cool thing is,",
    "start": "2184830",
    "end": "2192580"
  },
  {
    "text": "you can see over time, right? Originally, maybe only\nthese were emerging. And then when PaLM\ncame out, you'd",
    "start": "2192580",
    "end": "2198580"
  },
  {
    "text": "see a couple of dozen more\nabilities emerging and then-- I suspect, in a year\nor two, most of these",
    "start": "2198580",
    "end": "2205600"
  },
  {
    "text": "will become emergent, and\nwe'll need harder benchmarks. Yeah? There's another\nquestion on Zoom.",
    "start": "2205600",
    "end": "2210905"
  },
  {
    "text": "Why doesn't Google take as much\nof a safety-centric approach, like you said in Anthropic does? Are there reasons to believe\nharmful capabilities wouldn't",
    "start": "2210905",
    "end": "2218680"
  },
  {
    "text": "be emergent?  Yeah, I don't want to answer the\nquestion on behalf of Google,",
    "start": "2218680",
    "end": "2225560"
  },
  {
    "text": "I just can only talk\nabout my own opinions. But I think the\nreality is that Google,",
    "start": "2225560",
    "end": "2232900"
  },
  {
    "text": "even if you look at the amount\nof research that Google does, it might not be in the\nlarge language model space",
    "start": "2232900",
    "end": "2238640"
  },
  {
    "text": "specifically. But the amount of safety\nresearch that we do, I think, is more than Anthropic,\nif you actually",
    "start": "2238640",
    "end": "2244519"
  },
  {
    "text": "look at the number\nof papers published. Don't quote me on this,\nbut I think that's correct.",
    "start": "2244520",
    "end": "2251300"
  },
  {
    "text": "OK.  Great. ",
    "start": "2251300",
    "end": "2257799"
  },
  {
    "text": "So yeah, I'll talk about\nchain-of-thought prompting. So basically,\nchain-of-thought prompting",
    "start": "2257800",
    "end": "2264040"
  },
  {
    "text": "is this way of doing\nreasoning, multi-step reasoning with large language models.",
    "start": "2264040",
    "end": "2269890"
  },
  {
    "text": "And yeah, I wanted\nto say that I get super exciting to\nsee a lot of people",
    "start": "2269890",
    "end": "2276310"
  },
  {
    "text": "at Google working on this, and\nalso to see Sundar, our CEO, present this at our last\nyear's Google I/O press event.",
    "start": "2276310",
    "end": "2284320"
  },
  {
    "text": " And basically, the\nmotivation for this",
    "start": "2284320",
    "end": "2290380"
  },
  {
    "text": "is that we want language models\nto do more complicated tasks that-- for example, we\nknow language models",
    "start": "2290380",
    "end": "2297819"
  },
  {
    "text": "can do easy tasks like\n[INAUDIBLE] analysis or translation. But what about more\ncomplicated tasks",
    "start": "2297820",
    "end": "2303160"
  },
  {
    "text": "that might even take a human\na minute or more to do?",
    "start": "2303160",
    "end": "2308359"
  },
  {
    "text": "And the goal here is\nto basically guide them with metadata. So for example, instead of just\ngiving an input-output pair,",
    "start": "2308360",
    "end": "2315220"
  },
  {
    "text": "we want to give them the\nentire reasoning process, and have them mimic that.",
    "start": "2315220",
    "end": "2320930"
  },
  {
    "text": "And basically, you can see\nhere, in a standard prompt, you have the question\nand then the answer,",
    "start": "2320930",
    "end": "2326968"
  },
  {
    "text": "and then you have a\nquestion, and the model gives a new answer. Unfortunately it's wrong.",
    "start": "2326968",
    "end": "2332900"
  },
  {
    "text": "And then, with\nchain-of-thought prompting, you give the model\na question, and then",
    "start": "2332900",
    "end": "2338690"
  },
  {
    "text": "like how your teacher would\nask you to show your work, you give the chain\nof thought, is",
    "start": "2338690",
    "end": "2344330"
  },
  {
    "text": "what we call it, or\nbasically, a reasoning path. And then you give\nthe final answer. And then when the model\nsees this unseen question,",
    "start": "2344330",
    "end": "2350900"
  },
  {
    "text": "now it's able to give\nthe reasoning path, and then give the\ncorrect final answer. And the way that we add these\nprompts into the prompt,",
    "start": "2350900",
    "end": "2358610"
  },
  {
    "text": "is basically, we just\nmanually write a couple, and then add it into the prompt.",
    "start": "2358610",
    "end": "2363890"
  },
  {
    "text": "So let me just show\nhow that works. ",
    "start": "2363890",
    "end": "2369920"
  },
  {
    "text": "So this is the OpenAI API. And basically, here's the\nnon-chain-of-thought way",
    "start": "2369920",
    "end": "2378490"
  },
  {
    "text": "of doing it. So basically, you would have\na question, answer, question, answer, question, answer.",
    "start": "2378490",
    "end": "2384730"
  },
  {
    "text": "And then a new question about-- cafeteria has 23\napples, they use 20 to make lunch and\nabout six more.",
    "start": "2384730",
    "end": "2390000"
  },
  {
    "text": "How many apples they have? And the model gets it wrong.",
    "start": "2390000",
    "end": "2396260"
  },
  {
    "text": "And the only difference\nwith chain of thought is that you give these\nintermediate reasoning paths",
    "start": "2396260",
    "end": "2403850"
  },
  {
    "text": "before giving the final answer. So here's a path. There's a reasoning chain. There's another reasoning chain.",
    "start": "2403850",
    "end": "2410569"
  },
  {
    "text": "And then, now the model\nfor this unseen question",
    "start": "2410570",
    "end": "2415850"
  },
  {
    "text": "gives the entire\nreasoning process. And then this actually enables\nthe models to get it correct.",
    "start": "2415850",
    "end": "2423210"
  },
  {
    "text": "I'll give another quick example. This one.",
    "start": "2423210",
    "end": "2428370"
  },
  {
    "text": "So here the task is, just\ntake the last letters of the words of Bill Gates. So L from Bill and S from gates.",
    "start": "2428370",
    "end": "2435270"
  },
  {
    "text": "And then concatenate them. And the answer should be LS. And then here, the\nmodel gets it wrong.",
    "start": "2435270",
    "end": "2442140"
  },
  {
    "text": "The answer should be NK. It says SK. And then, if you do\nchain of thought,",
    "start": "2442140",
    "end": "2450110"
  },
  {
    "text": "obviously it becomes\nvery easy for the model. So it says the last third\nof Bill L, the last letter",
    "start": "2450110",
    "end": "2456390"
  },
  {
    "text": "of Gates is S. Answer is LS. And then here, it's able to do,\nthe last letter of Elon is N,",
    "start": "2456390",
    "end": "2463960"
  },
  {
    "text": "and the last letter of\nMusk is K, and answers NK. ",
    "start": "2463960",
    "end": "2470750"
  },
  {
    "text": "Is this clear? Any questions about\nwhat's going on here? OK.",
    "start": "2470750",
    "end": "2475800"
  },
  {
    "text": " So basically, we can have\nthese similar plots where",
    "start": "2475800",
    "end": "2481720"
  },
  {
    "text": "the x-axis is the model scale,\nthe y-axis is the performance. So on the left, we have this\nmath word question benchmark",
    "start": "2481720",
    "end": "2489430"
  },
  {
    "text": "called GSMAK. It's basically\nquestions that you'd see in an elementary\nschool math test.",
    "start": "2489430",
    "end": "2495250"
  },
  {
    "text": "And you can see, the\nblue dot is standard, and the purple star\nis chain of thought.",
    "start": "2495250",
    "end": "2501115"
  },
  {
    "text": "Basically, you see that\nthe chain of thought, if you use a large enough\nmodel, does a lot better",
    "start": "2501115",
    "end": "2506200"
  },
  {
    "text": "than standard prompting. And actually, it beats\nthe fine-tuned state of the art at the time.",
    "start": "2506200",
    "end": "2513640"
  },
  {
    "text": "A similar example is on this\nbenchmark called StrategyQA. And what StrategyQA\nis it's basically",
    "start": "2513640",
    "end": "2520240"
  },
  {
    "text": "like this world knowledge\nplus common-sense reasoning benchmark. So the question would\nbe like, can you",
    "start": "2520240",
    "end": "2525760"
  },
  {
    "text": "hide a basketball in\nthe sand cats ear? And then the model would say, a\nbasketball is about this size,",
    "start": "2525760",
    "end": "2532180"
  },
  {
    "text": "a sand cat's ear is that,\nso it would not fit. And on this benchmark,\nyou can also see that we can beat the\nfine-tuned state of the art",
    "start": "2532180",
    "end": "2539349"
  },
  {
    "text": "from before, just by\nusing chain of thought with a large enough\nlanguage model. ",
    "start": "2539350",
    "end": "2548089"
  },
  {
    "text": "So one way we use this is that\nwe evaluate a chain of thought on a certain subset\nof BIG-bench tasks.",
    "start": "2548090",
    "end": "2555560"
  },
  {
    "text": "So we created the subset\ncalled BIG-bench hard. And basically, it's like\n23 challenging tasks",
    "start": "2555560",
    "end": "2561760"
  },
  {
    "text": "from BIG-bench, where\nno model had done better than the average human writer.",
    "start": "2561760",
    "end": "2568600"
  },
  {
    "text": "So the way that you\nprompt the model is that you'd have a task\ndescription, question, options,",
    "start": "2568600",
    "end": "2574119"
  },
  {
    "text": "chain of thought. And then the test\n[AUDIO OUT] question. And so I'll give a couple\nof examples of tasks here.",
    "start": "2574120",
    "end": "2582800"
  },
  {
    "text": "So one example is navigate. Basically, what\nthe language model",
    "start": "2582800",
    "end": "2588170"
  },
  {
    "text": "has to do in this task is it\nhas to basically follow these-- so the question is, if you\nfollow these instructions,",
    "start": "2588170",
    "end": "2594559"
  },
  {
    "text": "do you return to\nthe starting point? Turn left, turn right, take\nfive steps, take four steps, turn around and take nine steps.",
    "start": "2594560",
    "end": "2601040"
  },
  {
    "text": "And then, the model following\nthe [INAUDIBLE] exemplars is able to basically track\nstate after all of the actions.",
    "start": "2601040",
    "end": "2610250"
  },
  {
    "text": "And then at the end it says,\nOK, are we at the final answer-- are we at the original location?",
    "start": "2610250",
    "end": "2616457"
  },
  {
    "text": "If it is zero, zero,\nthen the answer is yes.  Just to give an example\nof another task.",
    "start": "2616457",
    "end": "2624720"
  },
  {
    "text": "Here's a task that's\nvery easy for humans, basically word sorting. So there's a list of words.",
    "start": "2624720",
    "end": "2630420"
  },
  {
    "text": "Early, bela, I'm not\ngoing to read them. And basically, the\nmodel has to sort them",
    "start": "2630420",
    "end": "2635520"
  },
  {
    "text": "in alphabetical order. And here, the model can follow\nthe [INAUDIBLE] exemplar. So you have this pretty\ncomplicated chain of thought,",
    "start": "2635520",
    "end": "2645270"
  },
  {
    "text": "where the model has to\nsort each of the subparts, and then finally, it gets to the\nfinal answer, which is correct.",
    "start": "2645270",
    "end": "2651869"
  },
  {
    "text": " So here's this result summary\non this subset of BIG-bench.",
    "start": "2651870",
    "end": "2660030"
  },
  {
    "text": "So you can see, OK,\nwe have two metrics. One is just the average\nperformance on all these tasks,",
    "start": "2660030",
    "end": "2667530"
  },
  {
    "text": "and the second is\npercent of tasks that are above the average human writer.",
    "start": "2667530",
    "end": "2674820"
  },
  {
    "text": "So average human writer is\n67, max human writer is 94.",
    "start": "2674820",
    "end": "2680160"
  },
  {
    "text": "And then prior results, the\nmodel was doing way worse. It was like 50. And this is sort of by\nconstruction of the subset.",
    "start": "2680160",
    "end": "2689850"
  },
  {
    "text": "And then we use\nDaVinci 0.2, which is like one of the open AI models. And actually you can use this\none for free with OpenAI API.",
    "start": "2689850",
    "end": "2698190"
  },
  {
    "text": "And basically, if you\ndo answer only prompting without chain of\nthought, then you sort of",
    "start": "2698190",
    "end": "2703560"
  },
  {
    "text": "are being the average\nhuman writer on 5 of 27. But if you use\nchain-of-thought prompting,",
    "start": "2703560",
    "end": "2709470"
  },
  {
    "text": "then the performance increases\nby this pretty decent amount, and you're able to pass\nthe average human--",
    "start": "2709470",
    "end": "2715560"
  },
  {
    "text": "on the majority of tasks. And then below is just\nthis visualization of the tasks that are doing\nworse than humans, in red,",
    "start": "2715560",
    "end": "2723210"
  },
  {
    "text": "and then better\nthan humans in blue. Yeah? Two questions. One is, isn't this\nsimilar to [INAUDIBLE],,",
    "start": "2723210",
    "end": "2729510"
  },
  {
    "text": "in spirit at least? Is what similar? I think chain-of-thought prompt,\nI'm not sure what [INAUDIBLE]",
    "start": "2729510",
    "end": "2736930"
  },
  {
    "text": "in chain of thought. Yeah, I think it's--",
    "start": "2736930",
    "end": "2744440"
  },
  {
    "text": "I wouldn't call it similar. So train of thought\nis basically, you take a pretrained\nlanguage model, and you use a prompting\ntechnique that includes",
    "start": "2744440",
    "end": "2751790"
  },
  {
    "text": "intermediate reasoning path. The way that RLHF works is that\nyou have this additional data",
    "start": "2751790",
    "end": "2758180"
  },
  {
    "text": "that you want to fine\ntune the model on, and you have a\npreference model that predicts how well does\na certain output--",
    "start": "2758180",
    "end": "2765454"
  },
  {
    "text": " how likely is that to\nbe preferred by humans?",
    "start": "2765455",
    "end": "2772250"
  },
  {
    "text": "And then RLHF, what that\ndoes is it fine tunes",
    "start": "2772250",
    "end": "2777320"
  },
  {
    "text": "the language model to do\nwell on the preference models prediction. So basically, it's sort\nof aligning the model",
    "start": "2777320",
    "end": "2784130"
  },
  {
    "text": "with what humans would prefer. Is there a second question? Yeah, I'm sorry, it's here.",
    "start": "2784130",
    "end": "2789840"
  },
  {
    "text": "Grace asks, can chain of thought\nbe encoded in fine tuning, rather than having to\nbe in the [INAUDIBLE]??",
    "start": "2789840",
    "end": "2796570"
  },
  {
    "text": "Yes. The short answer is yes. The sort of complicated\nthing about that is that you have to have\nchain-of-thought intermediate",
    "start": "2796570",
    "end": "2804990"
  },
  {
    "text": "steps. And those are pretty-- it can be costly to gather that\ndata and to do the fine tuning.",
    "start": "2804990",
    "end": "2814569"
  },
  {
    "text": "One last question. Sorry for everybody. Another student\nasks, do you think that chain-of-thought and\nprompt engineering in general",
    "start": "2814570",
    "end": "2820960"
  },
  {
    "text": "is just an artifact\nthat won't be necessary for\nlarger-scale models that are able to understand\nthe [INAUDIBLE]..",
    "start": "2820960",
    "end": "2828130"
  },
  {
    "text": "Yeah, so that's\na great question. Basically, the question is, how\nephemeral is prompt engineering",
    "start": "2828130",
    "end": "2835060"
  },
  {
    "text": "going to be? I think we'll find out,\nbut some initial intuitions are, for easy tasks that\nare easy to describe,",
    "start": "2835060",
    "end": "2844420"
  },
  {
    "text": "and maybe they're\nmultiple choice, larger models will\nprobably be more robust to prompt\nengineering, and there's",
    "start": "2844420",
    "end": "2850299"
  },
  {
    "text": "less you can do with that. But I think, as language\nmodels get more powerful,",
    "start": "2850300",
    "end": "2855520"
  },
  {
    "text": "it'll sort of be more\nnormal to use them on a lot more challenging tasks. And in those tasks, you'll have\nto specify exactly what you",
    "start": "2855520",
    "end": "2862990"
  },
  {
    "text": "want them all to do et cetera. So I think there will\nstill be some room for prompt engineering there,\nat least in the near future.",
    "start": "2862990",
    "end": "2869430"
  },
  {
    "text": "Yeah, go ahead. Do you know how well does\nchain-of-thought prompting [INAUDIBLE]. And so for example, if you\nshow these two tasks write",
    "start": "2869430",
    "end": "2875370"
  },
  {
    "text": "a simple [INAUDIBLE],, and\nthen the other one basically sorting the words\nalphabetically.",
    "start": "2875370",
    "end": "2882030"
  },
  {
    "text": "So I mean, I see\nthat [INAUDIBLE]",
    "start": "2882030",
    "end": "2893280"
  },
  {
    "text": "if you have to give the\nchain of thought or something worse or better? Yeah, that's a great question.",
    "start": "2893280",
    "end": "2899290"
  },
  {
    "text": "So for some tasks where\nyou've seen similar data",
    "start": "2899290",
    "end": "2904410"
  },
  {
    "text": "in pretraining, the\nmodel can do really well, even if the chain of thought\nis from another task.",
    "start": "2904410",
    "end": "2909713"
  },
  {
    "text": "So for example, like\nmath word problems. You actually don't really\nneed a math chain of thought. Because the model already\nknows how to do that.",
    "start": "2909713",
    "end": "2915450"
  },
  {
    "text": "But for a task like\nthis, you probably haven't seen any data that's\nlike the chain of thought here.",
    "start": "2915450",
    "end": "2921250"
  },
  {
    "text": "So without\ntask-specific exemplars, you probably wouldn't do\nsuper well on tasks like this without manually writing\nthem for other examples.",
    "start": "2921250",
    "end": "2931670"
  },
  {
    "text": "Yeah? I'm wondering, as the\nresearcher behind this. What mental model would we use?",
    "start": "2931670",
    "end": "2938089"
  },
  {
    "text": "Like you can try,\nand it's like, do you perceive the model as\nlike-- if I was in person, how would I do this better? Or is it like trying to give\nit more compute in order to--",
    "start": "2938090",
    "end": "2947660"
  },
  {
    "text": "people are guessing the answer? Yeah, great question. I think my motivation\nwas just thinking",
    "start": "2947660",
    "end": "2953900"
  },
  {
    "text": "about it, just as you said. What's going on\nin a human's mind while they try to solve\nthis math question?",
    "start": "2953900",
    "end": "2961490"
  },
  {
    "text": "And well, if you notice,\nat least some humans will think actually\nin natural language.",
    "start": "2961490",
    "end": "2968400"
  },
  {
    "text": "So if you just think about it. If you pay attention a lot to\nwhat's going on in your mind, you actually notice\nthat sometimes you",
    "start": "2968400",
    "end": "2974810"
  },
  {
    "text": "think in language. And so while the language model\ncan think of language, too. So that was kind of the\nmotivation behind asking",
    "start": "2974810",
    "end": "2981125"
  },
  {
    "text": "the language model to do that. And I think, one\nthing that went well",
    "start": "2981125",
    "end": "2987680"
  },
  {
    "text": "is that the development\nof this technique actually coincided with\nthe development of PaLM.",
    "start": "2987680",
    "end": "2993559"
  },
  {
    "text": "And so-- yeah, basically,\nhaving the model PaLM sort of allowed us to\ndo a lot better task--",
    "start": "2993560",
    "end": "3001810"
  },
  {
    "text": "or a lot more challenging\ntasks using chain of thought. Yeah?",
    "start": "3001810",
    "end": "3007030"
  },
  {
    "text": "So when talking about\nthe [INAUDIBLE].. We're saying that it matters\nthat the absolute number",
    "start": "3007030",
    "end": "3012279"
  },
  {
    "text": "of examples of this\nchain-of-thought process or whatever, in the data set. Or in [INAUDIBLE].",
    "start": "3012280",
    "end": "3019210"
  },
  {
    "text": "Is that the main\nsignificant thing, or is it relative\nnumber of frequency of those examples, or\njust negative examples,",
    "start": "3019210",
    "end": "3026410"
  },
  {
    "text": "which are not good\nexamples of how to do those as much as\njust the absolute number",
    "start": "3026410",
    "end": "3031990"
  },
  {
    "text": "of good examples? Yeah good question.",
    "start": "3031990",
    "end": "3038343"
  },
  {
    "text": "So I guess the challenging\nthing is, we can't really measure how many similar\nexamples are in the training set.",
    "start": "3038343",
    "end": "3045030"
  },
  {
    "text": "It's hard to do that\nwell, and I don't think anyone has done that before.",
    "start": "3045030",
    "end": "3050230"
  },
  {
    "text": "So it's this open question\nof why a chain of thought even works. Because you actually\ndon't see similar data",
    "start": "3050230",
    "end": "3057070"
  },
  {
    "text": "like that in the training set. Yeah, I think it's open\nquestion like why it works.",
    "start": "3057070",
    "end": "3063539"
  },
  {
    "text": "[INAUDIBLE] chain of thought. I want to see [INAUDIBLE]\nthinking about how [INAUDIBLE]",
    "start": "3063540",
    "end": "3073790"
  },
  {
    "text": "things. That sometimes you\nthink in language, and that model\nshould do that, too. But like how do you\nactually think in--",
    "start": "3073790",
    "end": "3078930"
  },
  {
    "text": "like what a [INAUDIBLE]\nmodel like-- I mean, is that like a shift\nin very a specific task,",
    "start": "3078930",
    "end": "3084530"
  },
  {
    "text": "like some way to get more\nfocus from [INAUDIBLE]?? How do you think about it?",
    "start": "3084530",
    "end": "3090640"
  },
  {
    "text": "Yeah, I don't really\nthink about it in terms of what's going\non in the weights, I guess, the way that I think\nabout it is that like--",
    "start": "3090640",
    "end": "3097315"
  },
  {
    "text": "it'd be unfair for me to\ngive you a math question, and ask you to give me the\nanswer within like half",
    "start": "3097315",
    "end": "3103060"
  },
  {
    "text": "a second. Which is basically what\nyou're doing with the model, and when you do a chain\nof thought, right? You're basically asking\nthis challenging question,",
    "start": "3103060",
    "end": "3109840"
  },
  {
    "text": "and the model\ndoesn't have enough compute to solve it in\none pass to give you the next answer immediately.",
    "start": "3109840",
    "end": "3116680"
  },
  {
    "text": "I think the second\nthing that I think about is that the\nmodel has learned",
    "start": "3116680",
    "end": "3123370"
  },
  {
    "text": "a compositional set of\nskills during pretraining, so maybe it hasn't\nreally learned",
    "start": "3123370",
    "end": "3130329"
  },
  {
    "text": "this particular navigate\ntask during pretraining. But certain other things, right? OK, if you take five steps and\nyou're facing this, maybe yeah,",
    "start": "3130330",
    "end": "3138760"
  },
  {
    "text": "you should add five here or\nsomething like that, right? And it's learned how\nto do pattern matching. So maybe in the\n[INAUDIBLE] exemplars,",
    "start": "3138760",
    "end": "3145690"
  },
  {
    "text": "it can match sort of what\nthe reasoning path is with what the question was. And there's these little skills\nthat the model might know.",
    "start": "3145690",
    "end": "3153572"
  },
  {
    "text": "And then maybe if you\ncan combine them together in some clever way, then\nyou can get them all to solve a more\nchallenging problems.",
    "start": "3153572",
    "end": "3158845"
  },
  {
    "start": "3158845",
    "end": "3165710"
  },
  {
    "text": "How much time do we have? We have a half hour. [INTERPOSING VOICES]",
    "start": "3165710",
    "end": "3170869"
  },
  {
    "text": "OK, 50. OK OK. ",
    "start": "3170870",
    "end": "3179240"
  },
  {
    "text": "OK, great. That's a good example of\nhow we judge these tasks.",
    "start": "3179240",
    "end": "3184310"
  },
  {
    "text": "Same way. A bunch of different answers,\nall of them [INAUDIBLE]..",
    "start": "3184310",
    "end": "3189920"
  },
  {
    "text": "Yeah. OK, great. Yeah, feel free to keep asking\nquestions if you have any.",
    "start": "3189920",
    "end": "3195970"
  },
  {
    "text": "So yeah, here's another\nexample of emergence. So basically, you can see,\nthere's three models here",
    "start": "3195970",
    "end": "3203030"
  },
  {
    "text": "in GPT, Codex and PaLM. Chain of though in blue non\nchain of thought is in gray.",
    "start": "3203030",
    "end": "3210420"
  },
  {
    "text": "And then you can\nsee, you actually have to have sufficient model\nscale to chain of thought to work well.",
    "start": "3210420",
    "end": "3216560"
  },
  {
    "text": "And I guess, the\nintuition here is that, if you have a\nreally small model,",
    "start": "3216560",
    "end": "3222619"
  },
  {
    "text": "the model will keep\nrepeating itself or not saying anything\ncoherent, and never give you a final answer, which\nis why using chain of thought",
    "start": "3222620",
    "end": "3229309"
  },
  {
    "text": "for the small models\ndoesn't really work well. And then for the large models,\nobviously, for multi problems,",
    "start": "3229310",
    "end": "3236630"
  },
  {
    "text": "the model is going\nto be able to solve the task at a lot higher\naccuracy with chain of thought. ",
    "start": "3236630",
    "end": "3244799"
  },
  {
    "text": "And another cool thing\nabout chain of thought is, there are some tasks\nwhere you sort of wouldn't",
    "start": "3244800",
    "end": "3251910"
  },
  {
    "text": "get emergent behavior at all. So emergence hasn't\nbeen unlocked yet.",
    "start": "3251910",
    "end": "3258600"
  },
  {
    "text": "But you can see that if\nyou use chain of thought, you can unlock this emergent\nperformance in smaller models.",
    "start": "3258600",
    "end": "3266190"
  },
  {
    "text": "So one example here is\nmulti-step arithmetic, where-- I don't know if you'll ever--",
    "start": "3266190",
    "end": "3273337"
  },
  {
    "text": "I don't want to say never. But it's hard to imagine\na model getting this. Here's a question and then\nthe next token is correct.",
    "start": "3273337",
    "end": "3280350"
  },
  {
    "text": "That's pretty hard\nto solve in one step. But with chain of thought you\ncan get 50% accuracy on this",
    "start": "3280350",
    "end": "3285900"
  },
  {
    "text": "just by having the model output\nthese intermediate reasoning",
    "start": "3285900",
    "end": "3291900"
  },
  {
    "text": "steps. So I have a question. Oh, yeah. Is this something that needs\na rehab intuition about what's",
    "start": "3291900",
    "end": "3299970"
  },
  {
    "text": "going on? Abstractly, I know that a\ntransformer can definitely do addition.",
    "start": "3299970",
    "end": "3306119"
  },
  {
    "text": "[INAUDIBLE] right? In one step. But it can take in the\nnumbers and do the carries--",
    "start": "3306120",
    "end": "3311470"
  },
  {
    "text": "Definitely, yeah, yeah. But then there's this question\nof what happens empirically,",
    "start": "3311470",
    "end": "3318010"
  },
  {
    "text": "right? And I understand that it isn't\nnecessarily a lot of space to do arithmetic.",
    "start": "3318010",
    "end": "3324040"
  },
  {
    "text": "So my question is, how-- can you really tell\nthe difference?",
    "start": "3324040",
    "end": "3331030"
  },
  {
    "text": "Maybe [INAUDIBLE] ways to tell\nthe difference between things that have an emerge because\nthere's just no space.",
    "start": "3331030",
    "end": "3337710"
  },
  {
    "text": "Or there's so many\ntasks that you're",
    "start": "3337710",
    "end": "3342869"
  },
  {
    "text": "allotted, any space specifically\ndo that one, versus the task",
    "start": "3342870",
    "end": "3348510"
  },
  {
    "text": "is so hard that it just\ncan't, even if you like--",
    "start": "3348510",
    "end": "3354100"
  },
  {
    "text": "Yeah. [INAUDIBLE] they're\ntrying to do it. Yeah, that's a good question. I think-- there seems to be some\nsubset of tasks where it just",
    "start": "3354100",
    "end": "3364890"
  },
  {
    "text": "doesn't fit well with the way\nthat we train language models. So for example, in language\nmodels, we use tokens, right?",
    "start": "3364890",
    "end": "3371309"
  },
  {
    "text": "And so if you give\nit the token four, it actually doesn't\ntake the number four,",
    "start": "3371310",
    "end": "3378210"
  },
  {
    "text": "it takes this embedding\nthat's like 1,000 dimensions or something. Or if you give it a word and ask\nit to reverse like the letters.",
    "start": "3378210",
    "end": "3386560"
  },
  {
    "text": "This is a super easy task,\nbut the way we train the model doesn't actually look at\nthe letters and stuff.",
    "start": "3386560",
    "end": "3391780"
  },
  {
    "text": "So I think there's a certain\nsubset of tasks where it doesn't really just\nfit well with the way",
    "start": "3391780",
    "end": "3397320"
  },
  {
    "text": "that we train transformers,\nand you can actually-- I mean, if you really\ncare about these tasks,",
    "start": "3397320",
    "end": "3403950"
  },
  {
    "text": "you can just solve them using\ncode or something like that. But yeah, I don't think\nthis is really an inherent--",
    "start": "3403950",
    "end": "3413140"
  },
  {
    "text": "something that would never\nemerge, because it's too hard. Yeah. Yeah? We have a question on Zoom.",
    "start": "3413140",
    "end": "3419325"
  },
  {
    "text": "Also, by the way, sorry,\nI forgot to mention. Somebody's asking, can\nyou repeat the questions? Because they can't always hear-- Oh, OK.",
    "start": "3419325",
    "end": "3424910"
  },
  {
    "text": "Yeah. That's my bad. It's my bad. So the question someone\nasked is, do you think chain of thought would\nbe a viable interpretability",
    "start": "3424910",
    "end": "3430710"
  },
  {
    "text": "technique for very\nadvanced AI systems? And they mentioned that there\nis some research by Anthropic",
    "start": "3430710",
    "end": "3436230"
  },
  {
    "text": "called externalized reasoning\noversight by Tamera Lanham.",
    "start": "3436230",
    "end": "3441570"
  },
  {
    "text": "Will it be a viable\ninterpretability technique for advanced AI? Yeah, am I supposed\nto repeat this?",
    "start": "3441570",
    "end": "3447570"
  },
  {
    "text": "Yeah, yeah, yeah, sorry. Oh, so the question is,\ncan chain of thought be a viable interpretability\ntechnique for AI?",
    "start": "3447570",
    "end": "3456100"
  },
  {
    "text": "I think there's no guarantee\nthat the chain of thought is how the model actually\narrives at the final answer.",
    "start": "3456100",
    "end": "3463410"
  },
  {
    "text": "But often, you can\nuse it to debug like, why isn't the model getting\nthis question correct. Or what can we do better\nin the chain of thought",
    "start": "3463410",
    "end": "3471300"
  },
  {
    "text": "to help them all\nget this correct? I haven't read the Anthropic\npaper that was mentioned,",
    "start": "3471300",
    "end": "3476349"
  },
  {
    "text": "so I actually don't\nknow the answer to that. OK. ",
    "start": "3476350",
    "end": "3484060"
  },
  {
    "text": "Another interesting\nresult that we had here was that you can actually\ndo like multi-lingual",
    "start": "3484060",
    "end": "3490570"
  },
  {
    "text": "chain-of-thought prompting. And so basically\nwhat we had is, we translated this benchmark\nof math word problems",
    "start": "3490570",
    "end": "3498099"
  },
  {
    "text": "to 10 languages. And then we prompt the model\nto do it in, say, Bengali.",
    "start": "3498100",
    "end": "3503859"
  },
  {
    "text": "And then the model\nhas to basically do the math problem in Bengali\nand give the final answer.",
    "start": "3503860",
    "end": "3509655"
  },
  {
    "text": "I think the cool\nthing about this is, this input is like\nhighly improbable, right? So Bengali is 0.1% of\nthe pretraining data,",
    "start": "3509655",
    "end": "3517000"
  },
  {
    "text": "and math word\nproblems are probably even smaller subset of that.",
    "start": "3517000",
    "end": "3522993"
  },
  {
    "text": "And basically, the\ninteresting thing is, the model can actually do these\ntypes of questions pretty well.",
    "start": "3522993",
    "end": "3528890"
  },
  {
    "text": "To probably a surprising degree. So if you ask people before, I\nshow them this result. How well can the model do like these\nmath questions in Swahili?",
    "start": "3528890",
    "end": "3536240"
  },
  {
    "text": "Probably like 10%. But actually, even very\nunderrepresented languages",
    "start": "3536240",
    "end": "3541820"
  },
  {
    "text": "like Swahili, or Bengali, or\nTelugu, and Thai, the model",
    "start": "3541820",
    "end": "3547370"
  },
  {
    "text": "can do surprisingly well,\ndespite the fact that they only occupy a very small subset\nof the pretrained data.",
    "start": "3547370",
    "end": "3555990"
  },
  {
    "text": "Yeah? Actually speaking to this, and\nmost of my experience with this is ChatGPT. But if you ask things\nin different languages,",
    "start": "3555990",
    "end": "3562820"
  },
  {
    "text": "despite not being explicitly\ntrained in these languages, right? It seems have derived\nreasoning, independent",
    "start": "3562820",
    "end": "3568369"
  },
  {
    "text": "of language to some extent. Do the reasoning--\nit's kind of funny, sometimes it always\nlooks like it",
    "start": "3568370",
    "end": "3574100"
  },
  {
    "text": "does the reasoning in English,\nand then translates back to the other language. The answers it gives\nyou a sort of--",
    "start": "3574100",
    "end": "3580190"
  },
  {
    "text": "if you reason to\nEnglish, and then translate to the other thing. So do you think that learning\nthe structure of a language",
    "start": "3580190",
    "end": "3586430"
  },
  {
    "text": "and learning reasoning\nabilities are somewhat separate in\nlarge language models? Or that it inherently will\nlearn creative thought reasoning",
    "start": "3586430",
    "end": "3593780"
  },
  {
    "text": "within that language within\nthe structure of the language, like the way thought\nworks in that language?",
    "start": "3593780",
    "end": "3599347"
  },
  {
    "text": "Did that make sense? Yeah, that's a great question. I'm not sure how\nto measure that, but I've definitely\nthought about it. I think the language--",
    "start": "3599347",
    "end": "3605720"
  },
  {
    "text": "I mean based on these\nresults, you probably didn't have any math questions\nin Swahili for the model",
    "start": "3605720",
    "end": "3612230"
  },
  {
    "text": "to learn from. And I think definitely there's\nsomething language agnostic going on, where the model\nlearns reasoning independently",
    "start": "3612230",
    "end": "3618980"
  },
  {
    "text": "of language, and then\nit can express it in different languages\nif it needs to. Yeah, but I don't think anyone--",
    "start": "3618980",
    "end": "3624803"
  },
  {
    "text": "I don't think we know\nthe answers to that yet. ",
    "start": "3624803",
    "end": "3631750"
  },
  {
    "text": "Yeah, so basically, one question\nthat comes up frequently is, why does scaling up\nimprove chain-of-thought?",
    "start": "3631750",
    "end": "3639550"
  },
  {
    "text": "And one way of\nlooking at this is, we can take a smaller\nmodel like PaLM-62B and see what types of errors\nare fixed from scaling",
    "start": "3639550",
    "end": "3646299"
  },
  {
    "text": "up to 540 parameters. And you see that for these\nthree categories that we came up",
    "start": "3646300",
    "end": "3651670"
  },
  {
    "text": "with, some of all\nof them get fixed. So scaling seems to have\nthis universal effect",
    "start": "3651670",
    "end": "3657099"
  },
  {
    "text": "on improving different types\nof errors from smaller models. ",
    "start": "3657100",
    "end": "3663700"
  },
  {
    "text": "And then here's\nthis the [INAUDIBLE] diagram that express\nin different ways. So basically, you\nhave some tasks",
    "start": "3663700",
    "end": "3669833"
  },
  {
    "text": "that are doable with\nstandard prompting. So in blue. And then the goal of\nchain-of-though prompting",
    "start": "3669833",
    "end": "3675710"
  },
  {
    "text": "is to increase the set\nof tasks that we can do. So for example, now\nthe ones shown in pink",
    "start": "3675710",
    "end": "3682780"
  },
  {
    "text": "include math word problems,\nsymbolic reasoning, and challenging common\nsense reasoning, yeah.",
    "start": "3682780",
    "end": "3688200"
  },
  {
    "text": "One more question. Have you done any calculations\nto figure out how much--",
    "start": "3688200",
    "end": "3695170"
  },
  {
    "text": "is any of this contribution\njust because of the fact that you do more computations\nwhen you put in longer prompts.",
    "start": "3695170",
    "end": "3702339"
  },
  {
    "text": "Like you put multiple\npasses through the model, you create multiple\nembeddings to adjust",
    "start": "3702340",
    "end": "3709210"
  },
  {
    "text": "the things the model's\nlooking at in a way. How much of that-- have you tried\nnon-chain-of-thought prompts",
    "start": "3709210",
    "end": "3714670"
  },
  {
    "text": "with like same token lengths? Yeah, yeah, we tried with\nx, x, x, x, x or something,",
    "start": "3714670",
    "end": "3720400"
  },
  {
    "text": "and it doesn't work. I see. So I think it's not\njust about the compute, I think it's about the language\nguiding the model as part",
    "start": "3720400",
    "end": "3729100"
  },
  {
    "text": "of the reasoning. I see. And have you tried describing\nthe problem in more detail? [INAUDIBLE]",
    "start": "3729100",
    "end": "3736150"
  },
  {
    "text": "I'm just very curious about-- sounds like a very\ninteresting property, and I'm very curious\nexactly how it fits in.",
    "start": "3736150",
    "end": "3744352"
  },
  {
    "text": "Yeah, you mean like describing\nthe question in three different ways and saying-- Yeah, just explaining the\nquestion in more detail, instead of explicitly doing\nthe step-by-step thing,",
    "start": "3744353",
    "end": "3751325"
  },
  {
    "text": "and seeing how that-- Yeah. I haven't tried that,\nbut I would be surprised if that worked.",
    "start": "3751325",
    "end": "3756420"
  },
  {
    "text": "Yeah. Or you could edit the\nquestion you need, Did you try having it-- I'll put the answer and\nthen explain its reasoning,",
    "start": "3756420",
    "end": "3763410"
  },
  {
    "text": "and did that? Yeah, that doesn't work as well. Yeah. But it depends on the task also. So like-- Yeah.",
    "start": "3763410",
    "end": "3769970"
  },
  {
    "text": "[INTERPOSING VOICES] ",
    "start": "3769970",
    "end": "3775540"
  },
  {
    "text": "That seems to be the case, yeah. Yeah? Does there really\nhave to be reasoning?",
    "start": "3775540",
    "end": "3781190"
  },
  {
    "text": "I mean, you like just\n[INAUDIBLE] or that's your calculation. Sort of [INAUDIBLE] the answer.",
    "start": "3781190",
    "end": "3788480"
  },
  {
    "text": "In a way, you can [INAUDIBLE]. Chain of thought is like\na very structured thing.",
    "start": "3788480",
    "end": "3793520"
  },
  {
    "text": "What if the same\nstructures [INAUDIBLE] we use them for random things",
    "start": "3793520",
    "end": "3799640"
  },
  {
    "text": "Yeah. You could try it. I'd be surprised if it works. I think like\noutputting tokens is",
    "start": "3799640",
    "end": "3806960"
  },
  {
    "text": "pretty important for the model. ",
    "start": "3806960",
    "end": "3812260"
  },
  {
    "text": "OK.  So we're doing on time. OK, great. So the last part I think\nis a pretty cool trick",
    "start": "3812260",
    "end": "3820413"
  },
  {
    "text": "with chain of thought. So basically, what\npeople usually do is, they'll just generate\none chain of thought,",
    "start": "3820413",
    "end": "3827840"
  },
  {
    "text": "and then they'll take\nthe final answer. But there's this nice trick\ncalled self consistency, where you can use temperature\nsampling with the model",
    "start": "3827840",
    "end": "3834980"
  },
  {
    "text": "to generate a bunch\nof different reasoning paths and final answers. And then if you just\ntake a majority vote",
    "start": "3834980",
    "end": "3840890"
  },
  {
    "text": "over the final answers, this\nends up improving performance by a pretty big margin, so--",
    "start": "3840890",
    "end": "3846470"
  },
  {
    "text": "for example, here,\nyou can see on GSMAK, which is like the math\nword problem data set.",
    "start": "3846470",
    "end": "3852140"
  },
  {
    "text": "The improvement goes from-- the performance is 56. And then if you do\nself consistency,",
    "start": "3852140",
    "end": "3858160"
  },
  {
    "text": "that becomes 74, which is\na pretty big improvement. [INAUDIBLE]",
    "start": "3858160",
    "end": "3863270"
  },
  {
    "text": "Yeah. Here how many are the averaging\nnumber for self consistency? I think 40. So it increases the cost of\nthe inference type compute,",
    "start": "3863270",
    "end": "3871910"
  },
  {
    "text": "but improves\nperformance by a lot. You might be about to answer\nthis, but I'm curious to know.",
    "start": "3871910",
    "end": "3877280"
  },
  {
    "text": "How many samples\nor how many chains does one need to draw\nto get a significant-- what is the trade off\nif the number of chains",
    "start": "3877280",
    "end": "3883100"
  },
  {
    "text": "averaged over performance gain. I think it depends on the--",
    "start": "3883100",
    "end": "3889010"
  },
  {
    "text": "sorry, the question\nis, how many chains do you need to get\nperformance gain? I think the answer really\ndepends on the data set.",
    "start": "3889010",
    "end": "3898070"
  },
  {
    "text": "But usually, you can get\nsomething good with 16 I think. Yeah.",
    "start": "3898070",
    "end": "3903360"
  },
  {
    "text": "I'm sorry we have a question. How does the temperature\nchange the way a model works.",
    "start": "3903360",
    "end": "3908520"
  },
  {
    "text": "OK. The question is, how\ndoes the temperature change the way the model works. Basically, when you use\ntemperature decoding,",
    "start": "3908520",
    "end": "3916020"
  },
  {
    "text": "the language model\ncan stochastically pick one of the outputs, instead\nof always picking the highest",
    "start": "3916020",
    "end": "3921870"
  },
  {
    "text": "probability next word. So basically, you get these\nmore stochastic outputs",
    "start": "3921870",
    "end": "3927480"
  },
  {
    "text": "that are still based on what\nthe language model has learned, but it's just a little\nbit more random.",
    "start": "3927480",
    "end": "3933839"
  },
  {
    "text": " And then, finally,\nself consistency also",
    "start": "3933840",
    "end": "3941069"
  },
  {
    "text": "seems to be emergent ability. I guess part of it is\nbecause chain of thought is emerging because\nyou wouldn't get",
    "start": "3941070",
    "end": "3946920"
  },
  {
    "text": "any better than random\nperformance without doing train",
    "start": "3946920",
    "end": "3952900"
  },
  {
    "text": "of thought. But yeah, you kind\nof see this big delta from self consistency\nfor larger models.",
    "start": "3952900",
    "end": "3958425"
  },
  {
    "text": " Great.",
    "start": "3958425",
    "end": "3963660"
  },
  {
    "text": "So I'm going to run out of time. Let me just go to--",
    "start": "3963660",
    "end": "3969155"
  },
  {
    "text": "I'll just talk about\nthis a little bit. So I think, in addition\nto just purely scaling",
    "start": "3969155",
    "end": "3975360"
  },
  {
    "text": "up the language model, which\nis only available to people in the industry. I think there's a couple\nof interesting directions",
    "start": "3975360",
    "end": "3981480"
  },
  {
    "text": "to work on. One is better prompting\nand characterization",
    "start": "3981480",
    "end": "3986550"
  },
  {
    "text": "of language model abilities. I think right now,\nwe're sort of just at the edge of knowing what\nthe best way to prompt language",
    "start": "3986550",
    "end": "3994110"
  },
  {
    "text": "models is. There's also pretty\ngood applied work. So you can use\nlanguage models, I've",
    "start": "3994110",
    "end": "4000440"
  },
  {
    "text": "heard, to train therapists. To help with creative\nwriting, to help with science. I think ChatGPT has really\nshown what language models can",
    "start": "4000440",
    "end": "4008150"
  },
  {
    "text": "do in this regard. I think benchmarks\nare also something that's pretty lacking.",
    "start": "4008150",
    "end": "4014060"
  },
  {
    "text": "Because I think we solve\nbenchmarks pretty quickly. For example PaLM beat the\naverage human on BIG-bench",
    "start": "4014060",
    "end": "4021290"
  },
  {
    "text": "within a year or something\nof a BIG-bench coming out. So I think we need\nmore benchmarks,",
    "start": "4021290",
    "end": "4026750"
  },
  {
    "text": "I think that's going to be\nan important contribution. And then the final\none is, how can we",
    "start": "4026750",
    "end": "4032990"
  },
  {
    "text": "have computer-efficient methods\nto make language models better, so that it's less\nexpensive to use them,",
    "start": "4032990",
    "end": "4041300"
  },
  {
    "text": "and more people get to use them. Great. So I'll end here.",
    "start": "4041300",
    "end": "4049280"
  },
  {
    "text": "And feel free to email me\nif you have any feedback, and if you're\ninterested in Google,",
    "start": "4049280",
    "end": "4054320"
  },
  {
    "text": "feel free to\n[INAUDIBLE] as well. Thanks. Thank you. ",
    "start": "4054320",
    "end": "4068000"
  }
]
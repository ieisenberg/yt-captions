[
  {
    "start": "0",
    "end": "5690"
  },
  {
    "text": "So to start to get\ninto today's content, so far, we've been talking a\nlot about few-shot learning",
    "start": "5690",
    "end": "11870"
  },
  {
    "text": "by using meta learning. And the problem\nsetup for this was we were given data from some\nnumber of training tasks.",
    "start": "11870",
    "end": "19789"
  },
  {
    "text": "And we wanted to quickly solve\na new task more quickly, more proficiently, or more stably.",
    "start": "19790",
    "end": "25340"
  },
  {
    "text": "And we reviewed a\nfew different methods for doing that-- black\nbox meta learning methods, optimization-based\nmeta learning methods,",
    "start": "25340",
    "end": "31550"
  },
  {
    "text": "and nonparametric methods. And one big assumption\nthat these algorithms make",
    "start": "31550",
    "end": "38030"
  },
  {
    "text": "is that you have access to\na set of training tasks. And there may be\nscenarios where you",
    "start": "38030",
    "end": "43970"
  },
  {
    "text": "don't have a large\nnumber of training tasks. And so that's really the\nmotivation for the lectures",
    "start": "43970",
    "end": "49497"
  },
  {
    "text": "that we're going to\nbe talking about-- the topics we're going to\nbe talking about this week. And in particular, we're going\nto be considering scenarios",
    "start": "49497",
    "end": "56000"
  },
  {
    "text": "where you only have one large\nbatch of unlabeled examples. And we want to kind\npretrain models",
    "start": "56000",
    "end": "62660"
  },
  {
    "text": "that allow us to perform well\nwith small amounts of data, perform well on new tasks\nwith small amounts of data",
    "start": "62660",
    "end": "68450"
  },
  {
    "text": "by pretraining on\nthis unlabeled data. ",
    "start": "68450",
    "end": "74730"
  },
  {
    "text": "And so in particular,\nthis week is all about unsupervised\nrepresentation learning.",
    "start": "74730",
    "end": "80510"
  },
  {
    "text": "And the lecture today\nwill be one class of methods for doing that, which\nis called contrastive learning.",
    "start": "80510",
    "end": "86210"
  },
  {
    "text": "And the lecture\non Wednesday will be another class of methods for\ndoing that which are methods based off of reconstruction.",
    "start": "86210",
    "end": "94950"
  },
  {
    "text": "And at the end of this\nlecture, I'll talk about-- it should be apparent as we\nkind of go through the lecture",
    "start": "94950",
    "end": "101310"
  },
  {
    "text": "but also talk about how\nthese methods relate to meta learning methods. It actually turns out\nthat there actually",
    "start": "101310",
    "end": "106830"
  },
  {
    "text": "is a pretty close relationship\nbetween the methods that we'll talk about\ntoday and the methods that we've actually already been\ntalking about for the past two",
    "start": "106830",
    "end": "113610"
  },
  {
    "text": "weeks.  Cool. So the goals for the\nlecture are to understand",
    "start": "113610",
    "end": "118790"
  },
  {
    "text": "contrastive learning, including\nthe intuition, design choices, and how to implement them, and\nhow these algorithms relate",
    "start": "118790",
    "end": "124010"
  },
  {
    "text": "to meta learning.  Cool. So unlike meta\nlearning, the main data",
    "start": "124010",
    "end": "131870"
  },
  {
    "text": "that we'll have access to\nan unsupervised pretraining is a large unlabeled data set.",
    "start": "131870",
    "end": "137280"
  },
  {
    "text": "And so that will\nhave a large set of examples denoted as xi\nwithout their corresponding",
    "start": "137280",
    "end": "142879"
  },
  {
    "text": "labels. And the goal of this\nunsupervised pretraining",
    "start": "142880",
    "end": "148800"
  },
  {
    "text": "process is to take\nthis unlabeled data and produce a\npretrained model such",
    "start": "148800",
    "end": "154110"
  },
  {
    "text": "that when we take\nthat pretrained model and fine-tune it on a much\nsmaller label data set, we can do well on our new task.",
    "start": "154110",
    "end": "163218"
  },
  {
    "text": "So you can in many ways think\nof this as the same setup as the meta learning\nalgorithms you've seen before,",
    "start": "163218",
    "end": "168269"
  },
  {
    "text": "except instead of having access\nto a large number of tasks, we have access to this\ndiverse unlabeled data set.",
    "start": "168270",
    "end": "176050"
  },
  {
    "text": "And then what we'll be\ntalking about this week is this first arrow\non the slide here where, how do we basically go\nfrom that diverse unlabeled",
    "start": "176050",
    "end": "183850"
  },
  {
    "text": "data set to a pretrained model? The unlabeled data set\ncould be a bunch of images",
    "start": "183850",
    "end": "189967"
  },
  {
    "text": "that you found on the internet. It could be a bunch\nof sentences or text. It could also be something\nmore domain specific.",
    "start": "189968",
    "end": "198120"
  },
  {
    "text": "Like if you're in\nan education domain, maybe it's a lot of student\nsolutions to a problem. But you don't have\nfeedback or labels",
    "start": "198120",
    "end": "204780"
  },
  {
    "text": "on those solutions,\nthings along those lines. ",
    "start": "204780",
    "end": "210360"
  },
  {
    "text": "Cool. And so today, we'll be talking\nabout contrastive learning for unsupervised pretraining.",
    "start": "210360",
    "end": "215900"
  },
  {
    "text": "And really, the key idea\nbehind contrastive learning is that we want to learn our\nrepresentation and specifically",
    "start": "215900",
    "end": "224270"
  },
  {
    "text": "a mapping from inputs to\na vector representation such that similar examples\nhave similar representations.",
    "start": "224270",
    "end": "234660"
  },
  {
    "text": "So examples that are\nsemantically related to one another should map to a-- map to points in space that\nare closer than examples",
    "start": "234660",
    "end": "242180"
  },
  {
    "text": "that are semantically\ndifferent from each other. ",
    "start": "242180",
    "end": "247870"
  },
  {
    "text": "And so, for example, maybe\nyou have two examples with the same class label. We want to learn the\nrepresentation space such",
    "start": "247870",
    "end": "254519"
  },
  {
    "text": "that these examples have a\nvery similar representation. Of course, if we did something\nlike this with examples",
    "start": "254520",
    "end": "261540"
  },
  {
    "text": "with class labels, we\nactually would need labels for those examples in order to\ntrain those examples to have",
    "start": "261540",
    "end": "268290"
  },
  {
    "text": "similar representations. And this is very closely\nrelated to things like Siamese networks\nand prototypical networks",
    "start": "268290",
    "end": "274230"
  },
  {
    "text": "where we are training a network\nto predict whether or not two examples had\nthe same class label or whether they had\ndifferent class labels.",
    "start": "274230",
    "end": "282389"
  },
  {
    "text": "And so yeah, the stuff that\nwe talked about on Wednesday last week in some\nways can be viewed",
    "start": "282390",
    "end": "287940"
  },
  {
    "text": "as a form of\ncontrastive learning. But it requires labels. And so what we\nwant to do is think about how we might do\nsomething like that",
    "start": "287940",
    "end": "295169"
  },
  {
    "text": "without access to labels. And so there's a\nfew different things that we could imagine doing, in\nparticular a few different ways",
    "start": "295170",
    "end": "302310"
  },
  {
    "text": "that we could imagine\ncreating examples that might be semantically\nsimilar to one another.",
    "start": "302310",
    "end": "308183"
  },
  {
    "text": "One thing that we could do\nis we could take an image and say that patches of\nthat image that are nearby",
    "start": "308183",
    "end": "314010"
  },
  {
    "text": "to one another probably should\nhave a similar representation. Because if they're\nnearby to each other,",
    "start": "314010",
    "end": "320371"
  },
  {
    "text": "that means that they're probably\nmaybe from the same object or from a similar part\nof the same object.",
    "start": "320372",
    "end": "326110"
  },
  {
    "text": "And so that's what was\ndone in the CPC paper. They tried to encourage\nthose patches to have a similar representation.",
    "start": "326110",
    "end": "333997"
  },
  {
    "text": "Instead of taking\npatches of an input, we could also\naugment an example.",
    "start": "333997",
    "end": "339675"
  },
  {
    "text": "And so in this case, we\ncould take our image. And then we could flip\nit and also crop it and say that the\naugmented example should",
    "start": "339675",
    "end": "346620"
  },
  {
    "text": "have a similar representation\nas the original example. And if your augmentations--",
    "start": "346620",
    "end": "353039"
  },
  {
    "text": "if your augmentations preserve\nthe class of the image, then they should\nproduce representations",
    "start": "353040",
    "end": "358800"
  },
  {
    "text": "that correspond to these\nkinds of semantic categories that you may want\nit to correspond to.",
    "start": "358800",
    "end": "366830"
  },
  {
    "text": "So something like this was\ndone in the SimCLR paper. There's also a\nversion of this where we could take videos and say\nthat images that are nearby",
    "start": "366830",
    "end": "375190"
  },
  {
    "text": "in time from the\nsame video should have a similar representation.",
    "start": "375190",
    "end": "381115"
  },
  {
    "text": "So really, the key idea\nbehind contrastive learning is to take things\nthat we intuitively think should have\nsimilar representations,",
    "start": "381115",
    "end": "386990"
  },
  {
    "text": "encourage them to have\nsimilar representations such that we can then use that\nrepresentation space in order",
    "start": "386990",
    "end": "393560"
  },
  {
    "text": "to do transfer to\ndifferent downstream tasks. ",
    "start": "393560",
    "end": "401170"
  },
  {
    "text": "Cool. So then there's the\nquestion of, how do we actually implement\nthis intuition in practice?",
    "start": "401170",
    "end": "406800"
  },
  {
    "text": "So we can use a running\nexample of trying to say that the two\nimages at the top",
    "start": "406800",
    "end": "411860"
  },
  {
    "text": "have similar representation and\nthe two images at the bottom have similar representations. Now, one thing you\ncould do is you",
    "start": "411860",
    "end": "418139"
  },
  {
    "text": "can say that maybe\nthe first image is x, the second image is x prime. And you could\ntrain for a model f",
    "start": "418140",
    "end": "425340"
  },
  {
    "text": "that encourages\nthe representation of the first image\nand the representation",
    "start": "425340",
    "end": "430620"
  },
  {
    "text": "of the second image. We could basically\nencourage this to have to be very close,\nmaybe in Euclidean space",
    "start": "430620",
    "end": "438510"
  },
  {
    "text": "or in some other space. And we could basically\noptimize for our representation",
    "start": "438510",
    "end": "445200"
  },
  {
    "text": "functions such that\nthese are close together. Now, does anyone see\nkind of a problem",
    "start": "445200",
    "end": "450330"
  },
  {
    "text": "with an objective like this? Yeah. Yeah, [INAUDIBLE] presentation,\nregardless of the input.",
    "start": "450330",
    "end": "459150"
  },
  {
    "text": "Yeah, exactly. Yeah, so there's a\ndegenerative solution to this loss function, which\nis to basically just map",
    "start": "459150",
    "end": "465259"
  },
  {
    "text": "everything, all of the images\nto a single constant vector. And then you would\nminimize this loss function",
    "start": "465260",
    "end": "471590"
  },
  {
    "text": "very nicely because you\nwould achieve 0 loss here. But it means that you don't\nget a very good representation",
    "start": "471590",
    "end": "479000"
  },
  {
    "text": "space. And so we can't simply\nminimize the difference",
    "start": "479000",
    "end": "484160"
  },
  {
    "text": "between these representations\nbecause of that collapse. And instead of only\ncomparing examples and saying",
    "start": "484160",
    "end": "490237"
  },
  {
    "text": "that examples should have\nsimilar representations, we also need to say what\nneeds to be different. We need to also contrast\nthe images as well.",
    "start": "490237",
    "end": "497823"
  },
  {
    "text": "And so that's one\nof the key ideas behind contrastive learning. ",
    "start": "497823",
    "end": "503569"
  },
  {
    "text": "And so in particular, if we\ntake these three examples here, we have our embedding space.",
    "start": "503570",
    "end": "508746"
  },
  {
    "text": "Then we could try to\ntrain for our embedding space in a way that first\nembeds these examples",
    "start": "508747",
    "end": "514779"
  },
  {
    "text": "and then brings together\nthe representations of similar examples\nwhile also pushing apart",
    "start": "514780",
    "end": "520900"
  },
  {
    "text": "the representations\nof different examples. ",
    "start": "520900",
    "end": "527470"
  },
  {
    "text": "And so this is\nbasically the key idea behind contrastive learning. And from here, there's really\njust only two key design",
    "start": "527470",
    "end": "534779"
  },
  {
    "text": "choices behind these algorithms. The first is how do you actually\nimplement the loss function.",
    "start": "534780",
    "end": "540990"
  },
  {
    "text": "We'll go over two different\nloss functions in this lecture. But there's actually a\nnumber of loss functions",
    "start": "540990",
    "end": "546269"
  },
  {
    "text": "that people have\nused in practice. And then also choosing what\nto compare and contrast.",
    "start": "546270",
    "end": "551670"
  },
  {
    "text": "We talked about some options\nat the very beginning with the pictures of the dogs. But there's other\nconsiderations there as well.",
    "start": "551670",
    "end": "558750"
  },
  {
    "text": " Cool. So let's first get\ninto the implementation",
    "start": "558750",
    "end": "565000"
  },
  {
    "text": "of the loss function for\ncontrastive learning. So the first--",
    "start": "565000",
    "end": "573000"
  },
  {
    "text": "I guess in terms of--\nfor some terminology, if we want to bring two\nexamples together and push apart",
    "start": "573000",
    "end": "578790"
  },
  {
    "text": "two examples,\ntypically, we will refer to the first example\nas the anchor because that's what we're going\nto be comparing and contrasting",
    "start": "578790",
    "end": "585990"
  },
  {
    "text": "to. And then we'll refer to the next\nexample as a positive example.",
    "start": "585990",
    "end": "591850"
  },
  {
    "text": "And the third example\nis the negative. So we're trying to bring the\npositive towards the anchor and push the negative\naway from the anchor.",
    "start": "591850",
    "end": "599600"
  },
  {
    "text": "And really, the simplest\nform of loss function is referred to a triplet loss.",
    "start": "599600",
    "end": "605790"
  },
  {
    "text": "And we can start by just\ntaking the loss function that we wrote down before.",
    "start": "605790",
    "end": "611040"
  },
  {
    "text": "And instead of only\nminimizing the distance between the embedded\nx and x prime,",
    "start": "611040",
    "end": "616640"
  },
  {
    "text": "we can also add a term\nthat basically maximizes the distance between--",
    "start": "616640",
    "end": "622820"
  },
  {
    "text": "actually, using the notation\nhere, we'll call this x plus. That will also maximize the\ndistance between the embedded x",
    "start": "622820",
    "end": "628220"
  },
  {
    "text": "and the negative. So this would correspond to\nf theta of x minus f theta",
    "start": "628220",
    "end": "638090"
  },
  {
    "text": "of x minus squared. ",
    "start": "638090",
    "end": "643620"
  },
  {
    "text": "And because we have\na negative here, we're going to be maximizing\nthis distance when we minimize this overall\nobjective function.",
    "start": "643620",
    "end": "651269"
  },
  {
    "text": "Yeah. If there were a\nbunch of case losses that you want to\ncontrast against,",
    "start": "651270",
    "end": "657305"
  },
  {
    "text": "you just extend\nthis loss function for all the different\nclasses or just [INAUDIBLE]??",
    "start": "657305",
    "end": "662660"
  },
  {
    "text": "Yeah, so the question is,\nwhat happens if you actually have a lot of\ndifferent negatives that you want to\ncontrast against?",
    "start": "662660",
    "end": "667880"
  },
  {
    "text": "And we'll get into that\nactually after this slide. Yeah. Is there a way so that you can\ncontrol how much you push away",
    "start": "667880",
    "end": "677960"
  },
  {
    "text": "the contrasting examples? Yeah, so the\nquestion is, is there a way to control how\nmuch you push away",
    "start": "677960",
    "end": "684079"
  },
  {
    "text": "from the contrasting examples? And there's actually\ntwo different aspects of that question.",
    "start": "684080",
    "end": "689850"
  },
  {
    "text": "One is that maybe\nfor some examples, you want to push away\nmore than others. And in practice, contrastive\nlearning algorithms",
    "start": "689850",
    "end": "697220"
  },
  {
    "text": "will push away the same amount\nfor all of the negatives. But that doesn't\nmean that all of them",
    "start": "697220",
    "end": "702470"
  },
  {
    "text": "will end up at the same\ndistance because some of them will naturally be harder\nto push away than others.",
    "start": "702470",
    "end": "707579"
  },
  {
    "text": "And so oftentimes,\neven if you push apart all of them the\nsame amount, they'll",
    "start": "707580",
    "end": "713690"
  },
  {
    "text": "still give you a meaningfully--\nthe distances in the space will be meaningful.",
    "start": "713690",
    "end": "719060"
  },
  {
    "text": "But the second part\nof that question is, there's actually\nan issue with this loss function to some degree, which\nis that this term of the loss",
    "start": "719060",
    "end": "728000"
  },
  {
    "text": "function is somewhat\nunbounded, which",
    "start": "728000",
    "end": "733910"
  },
  {
    "text": "is that you can kind of\nbasically put this to infinity. You can make them\nmaximally far apart.",
    "start": "733910",
    "end": "739910"
  },
  {
    "text": "And so when designing either\nyour embedding function or your loss function,\nyou need to make sure",
    "start": "739910",
    "end": "746512"
  },
  {
    "text": "that you don't have an\nunbounded loss function. Otherwise, it will go\nto negative infinity. And there's a few different\nways to accomplish this.",
    "start": "746512",
    "end": "752870"
  },
  {
    "text": "One thing that you could\ndo is you could make sure that your embedding space\nis normalized in some way, it's bounded itself.",
    "start": "752870",
    "end": "759300"
  },
  {
    "text": "But one thing that's common\nto do with a triplet loss is to actually use\na hinge loss here,",
    "start": "759300",
    "end": "767090"
  },
  {
    "text": "which is that instead of\nrewarding it more and more, the more that it pushes\naway, it says that once it's",
    "start": "767090",
    "end": "773420"
  },
  {
    "text": "a certain distance away, then\nit no longer gets rewarded for pushing it any further.",
    "start": "773420",
    "end": "779565"
  },
  {
    "text": "And so you probably\nhave seen something like a hinge loss in a\nmachine learning class before.",
    "start": "779565",
    "end": "787020"
  },
  {
    "text": "The way it looks like is,\nif we look at the distance,",
    "start": "787020",
    "end": "795070"
  },
  {
    "text": "we want to, in this\ncase-- or the difference",
    "start": "795070",
    "end": "800890"
  },
  {
    "text": "of these distances,\nbasically, as this increases, we want it to get a lower loss.",
    "start": "800890",
    "end": "806230"
  },
  {
    "text": "So the y-axis here is\ngoing to be the loss value. So as it increases, we want\nit to get a lower loss.",
    "start": "806230",
    "end": "812149"
  },
  {
    "text": "But at some point,\nwe want it to not continue getting\nrewarded because it doesn't need to push it all\nthe way to negative infinity.",
    "start": "812150",
    "end": "818630"
  },
  {
    "text": "And so what a\nhinge loss would do is basically give\nyou a shape that looks like this, where\nup until some point,",
    "start": "818630",
    "end": "827160"
  },
  {
    "text": "it's going to be rewarded\nfor increasing the distance. And after that, it will be-- it will just sit at 0 loss.",
    "start": "827160",
    "end": "836199"
  },
  {
    "text": "And this distance right here\nis referred to as your margin.",
    "start": "836200",
    "end": "844248"
  },
  {
    "text": "And this is something\nthat you can control. This is like a hyperparameter. And this controls how much\nyou are-- how far apart you",
    "start": "844248",
    "end": "850209"
  },
  {
    "text": "want your examples to be. And so the way that you\nactually will implement",
    "start": "850210",
    "end": "856330"
  },
  {
    "text": "this is instead of having\nyour loss function be the difference between these\ntwo things, you're going to--",
    "start": "856330",
    "end": "866620"
  },
  {
    "text": "first, you will add your margin. Maybe your margin is\nreferred to as epsilon.",
    "start": "866620",
    "end": "873490"
  },
  {
    "text": "And then you will basically\nbound this below by 0. And so you can take the\nmax between this and 0.",
    "start": "873490",
    "end": "883120"
  },
  {
    "text": "And this will basically\njust apply this function to what we had before.",
    "start": "883120",
    "end": "890210"
  },
  {
    "text": "And then we'll minimize this\nwhole thing with respect to theta. ",
    "start": "890210",
    "end": "897340"
  },
  {
    "text": "And so that loss function\nis written out right here. Yeah.",
    "start": "897340",
    "end": "904030"
  },
  {
    "text": "Does the xx plus x minus come\nfrom the same mini batch?",
    "start": "904030",
    "end": "909260"
  },
  {
    "text": "I mean, I don't\nknow how we, I mean, move over the two x,\nx plus x, x minus eta.",
    "start": "909260",
    "end": "916210"
  },
  {
    "text": "Yeah, so the question is, where\ndo xx plus and x minus come from? Oh, yeah. Yeah, so they can come from--",
    "start": "916210",
    "end": "923589"
  },
  {
    "text": "these triplets can come from\na number of different places. In one case, it could--\nif you have labels,",
    "start": "923590",
    "end": "930250"
  },
  {
    "text": "then it could come from the-- whether or not examples\nhave the same label. So you could sample two examples\nof the same label and one",
    "start": "930250",
    "end": "936129"
  },
  {
    "text": "example with the\ndifferent label. And that would give you\nan anchor, a positive, and a negative. One of the other things\nthat we talked about",
    "start": "936130",
    "end": "942670"
  },
  {
    "text": "is instead of\nusing class labels, you can also use augmentations. And so you could\nsample an example",
    "start": "942670",
    "end": "949329"
  },
  {
    "text": "and sample a different example. That will be the anchor\nand the negative. And then to get\nanother positive,",
    "start": "949330",
    "end": "954460"
  },
  {
    "text": "you can augment and create\nanother view of the anchor by, for example,\napplying a random crop",
    "start": "954460",
    "end": "961570"
  },
  {
    "text": "or flipping the image or\ndoing something like that. [INAUDIBLE] mini batch.",
    "start": "961570",
    "end": "969330"
  },
  {
    "text": "So it means all of them\nfrom the same mini batch. Is my understanding correct? So in practice, you'll sample\na mini batch of these triplets.",
    "start": "969330",
    "end": "979110"
  },
  {
    "text": "So you'll sample-- you'll\nsample not just one triplet. But you'll sample a\nmini batch of them.",
    "start": "979110",
    "end": "984931"
  },
  {
    "text": "OK, how do we choose an anchor? Is it for each of the\nelements in the mini batch,",
    "start": "984932",
    "end": "990740"
  },
  {
    "text": "we choose the anchor then take\na break on the x plus and x minus relatively?",
    "start": "990740",
    "end": "997460"
  },
  {
    "text": "So yeah, the sample and\nanchor, you can basically-- when you sample an image\nfrom your unlabeled data set,",
    "start": "997460",
    "end": "1002770"
  },
  {
    "text": "that can be the anchor. You sample a different image,\nand that could be the negative. And then the positive,\nyou can augment the anchor",
    "start": "1002770",
    "end": "1010540"
  },
  {
    "text": "to get the positive. So we'll also render\nan algorithm too,",
    "start": "1010540",
    "end": "1016410"
  },
  {
    "text": "which should maybe give a little\nbit more intuition for this. Yeah. What if I-- yeah,\nnegative examples",
    "start": "1016410",
    "end": "1022770"
  },
  {
    "text": "are accidentally created in\nthe same class or something or from the same\nclass as the anchor.",
    "start": "1022770",
    "end": "1028049"
  },
  {
    "text": "How bad is that in\nthe training process? Yeah, so the question\nis, what happens",
    "start": "1028050",
    "end": "1033119"
  },
  {
    "text": "if the negative\nexample is accidentally kind of the same\nclass as the anchor? And this is generally\na great question.",
    "start": "1033119",
    "end": "1041069"
  },
  {
    "text": "And in practice, especially\nwhen you have unlabeled examples and you're contrasting\nagainst augmentations,",
    "start": "1041069",
    "end": "1048157"
  },
  {
    "text": "you will sample negatives\nthat may actually be somewhat similar to the\nexample that the anchor",
    "start": "1048158",
    "end": "1053309"
  },
  {
    "text": "that you sampled. This is OK. The most important\nthing is that--",
    "start": "1053310",
    "end": "1061020"
  },
  {
    "text": "well, the most\nimportant thing is that happens somewhat rarely. And so if-- general, if you have\na really huge data set and you",
    "start": "1061020",
    "end": "1070380"
  },
  {
    "text": "just want to-- yeah, if you have\na huge data set, then the number of\nexamples that you",
    "start": "1070380",
    "end": "1077100"
  },
  {
    "text": "have from a particular class\nwill be somewhat small. And the likelihood\nof actually an anchor and a negative being very\nsimilar to each other",
    "start": "1077100",
    "end": "1084809"
  },
  {
    "text": "will also be small.  Yeah. Does the choice of the embedding\nspace in the distance metric",
    "start": "1084810",
    "end": "1092410"
  },
  {
    "text": "make a big difference\nto the results here? You might imagine\nthat if you embed",
    "start": "1092410",
    "end": "1097720"
  },
  {
    "text": "in some non-Euclidean space, you\ncan get different combinations of distances. And I'm wondering\nif that's helpful.",
    "start": "1097720",
    "end": "1103527"
  },
  {
    "text": "So you're asking, does the\ndistance function here, is that important? Or you're asking\nsomething different?",
    "start": "1103527",
    "end": "1108940"
  },
  {
    "text": "Not so much. Like, how helpful\nit is to do that? Yeah, I think that there's\nreally two common choices.",
    "start": "1108940",
    "end": "1115610"
  },
  {
    "text": "One is to use\nEuclidean, and another is to use basically\nnegative cosine similarity.",
    "start": "1115610",
    "end": "1121190"
  },
  {
    "text": " To my knowledge,\nit's not critical.",
    "start": "1121190",
    "end": "1126820"
  },
  {
    "text": "And you probably\nwant to consider both of those two options. But beyond that, I don't think\nthat people get super creative.",
    "start": "1126820",
    "end": "1135110"
  },
  {
    "text": "Yeah. [INAUDIBLE] ",
    "start": "1135110",
    "end": "1143732"
  },
  {
    "text": "Yeah, so one thing\nthat's different here is that these\npositives and negatives, they're actually quite\ndifferent from a class label.",
    "start": "1143732",
    "end": "1150530"
  },
  {
    "text": "And they may not correspond\nexactly to your class labels. They're going to\ninstead correspond",
    "start": "1150530",
    "end": "1157070"
  },
  {
    "text": "to some other kind of notion\nof relatedness and so forth.",
    "start": "1157070",
    "end": "1163340"
  },
  {
    "text": " Sorry, what was your question? So if we're given an\nexample [INAUDIBLE],,",
    "start": "1163340",
    "end": "1169860"
  },
  {
    "text": "how do we know [INAUDIBLE]?  Yeah, so I'll go back to\nthe slide that I had here.",
    "start": "1169860",
    "end": "1177659"
  },
  {
    "text": "So augmented versions\nare the top right. Beyond that, there's-- I have two other examples here.",
    "start": "1177660",
    "end": "1183570"
  },
  {
    "text": "One is to use image patches\nor to use basically-- in this case, they actually\noften use overlapping image",
    "start": "1183570",
    "end": "1188690"
  },
  {
    "text": "patches from the same image. Or if you have a video,\nyou can use nearby frames.",
    "start": "1188690",
    "end": "1194630"
  },
  {
    "text": "And these are also somewhat\npopular choices as well.",
    "start": "1194630",
    "end": "1200600"
  },
  {
    "text": "In computer vision,\naugmented versions is definitely the most\npopular example of this.",
    "start": "1200600",
    "end": "1206270"
  },
  {
    "text": "But using things like basically\nthings that are nearby in some space, either in image\nspace or in time or something",
    "start": "1206270",
    "end": "1212840"
  },
  {
    "text": "else is also very popular. I guess to also provide\nsome intuition for that,",
    "start": "1212840",
    "end": "1218120"
  },
  {
    "text": "for example, with video\nframes, the intuition there is that things that\nco-occur in time",
    "start": "1218120",
    "end": "1223990"
  },
  {
    "text": "will be related to one another. But it does end up being\nfairly data dependent.",
    "start": "1223990",
    "end": "1229620"
  },
  {
    "text": "And if your data-- if your data for whatever\nreason doesn't obey that,",
    "start": "1229620",
    "end": "1236650"
  },
  {
    "text": "like if you have videos that are\nconstantly changing over time and are more random in\nterms of their sequence,",
    "start": "1236650",
    "end": "1243970"
  },
  {
    "text": "then that may yield\nrepresentations that aren't as good as something\nthat has a little bit more temporal coherence.",
    "start": "1243970",
    "end": "1250520"
  },
  {
    "text": "Yeah. [INAUDIBLE] ",
    "start": "1250520",
    "end": "1255930"
  },
  {
    "text": "Is it possible to\nstretch [INAUDIBLE]?? Yeah, so you can view\naugmentations essentially",
    "start": "1255930",
    "end": "1262290"
  },
  {
    "text": "as a form of hyperparameter or\nas a form of domain knowledge that's going into the algorithm. And the choice of augmentation\nis actually really,",
    "start": "1262290",
    "end": "1269769"
  },
  {
    "text": "really important to actually\nhow the performance ends up-- of these algorithms\nends up being. There's actually a\nlot of literature",
    "start": "1269770",
    "end": "1277200"
  },
  {
    "text": "on different forms\nof augmentations that work well often for images.",
    "start": "1277200",
    "end": "1282773"
  },
  {
    "text": "And there's also\nsome work outside of computer vision domains that\nlook at other augmentations as well.",
    "start": "1282773",
    "end": "1287880"
  },
  {
    "text": "But it does end up\nbeing quite important. And so if you look at, for\nexample, the SimCLR paper,",
    "start": "1287880",
    "end": "1293639"
  },
  {
    "text": "I know that they included a\nstudy of different kinds of-- basically, how well different\nkinds of augmentations work. [INAUDIBLE]",
    "start": "1293640",
    "end": "1302222"
  },
  {
    "text": " There is actually a paper\nthat discovers augmentations.",
    "start": "1302222",
    "end": "1307440"
  },
  {
    "text": "And I'll cover it\nlater in the lecture. ",
    "start": "1307440",
    "end": "1313890"
  },
  {
    "text": "Cool. So we've talked about\nthe triplet loss.",
    "start": "1313890",
    "end": "1320309"
  },
  {
    "text": "And so that's what we\nwent over on the board. And this is really the simplest\nform of contrastive loss.",
    "start": "1320310",
    "end": "1326810"
  },
  {
    "text": "And it actually\nworks pretty well. And yeah, it's pretty nice,\na good place to start.",
    "start": "1326810",
    "end": "1335120"
  },
  {
    "text": "Compared to something like\nSiamese networks, which we talked about on Wednesday,\nit's actually extremely similar",
    "start": "1335120",
    "end": "1340942"
  },
  {
    "text": "to Siamese networks,\nespecially if you're using class labels as your\npositives and negatives.",
    "start": "1340942",
    "end": "1348050"
  },
  {
    "text": "And you could essentially\nthink of it as Siamese networks from the standpoint\nof if this distance",
    "start": "1348050",
    "end": "1354080"
  },
  {
    "text": "in your embedding\nspace is small, then classify the examples\nas being the same class. Otherwise, classify them as\nbeing in a different class.",
    "start": "1354080",
    "end": "1362309"
  },
  {
    "text": "Really, the key difference\nbetween this triplet loss and Siamese networks is that\nwhen you use this triplet loss",
    "start": "1362310",
    "end": "1370310"
  },
  {
    "text": "to learn a\nrepresentation, you're going to be learning this\nkind of metric space, this representation space\nfrom which you can measure",
    "start": "1370310",
    "end": "1376129"
  },
  {
    "text": "the distance between examples. Whereas the Siamese\nnetworks were only just learning a classifier.",
    "start": "1376130",
    "end": "1382220"
  },
  {
    "text": "And it was just giving\nyou the probability that they were correct\nor not rather than a representation\nwhere you can measure these kinds of distances.",
    "start": "1382220",
    "end": "1388190"
  },
  {
    "start": "1388190",
    "end": "1393970"
  },
  {
    "text": "Cool. Now, one thing that comes\nup with this loss function",
    "start": "1393970",
    "end": "1401590"
  },
  {
    "text": "is that choosing good\nnegatives is difficult.",
    "start": "1401590",
    "end": "1407043"
  },
  {
    "text": "And in particular, if you're\nin your embedding space and you sample a negative\nthat's already very far away,",
    "start": "1407043",
    "end": "1412100"
  },
  {
    "text": "then you're just going to\nhave 0 loss at that space. And you won't actually\nbe learning anything",
    "start": "1412100",
    "end": "1417610"
  },
  {
    "text": "from that negative. And so you really want\nto try to find negatives",
    "start": "1417610",
    "end": "1423280"
  },
  {
    "text": "that are difficult. One\nthing that you could do is what's called\nhard negative mining where you explicitly search\nfor negatives that are closer",
    "start": "1423280",
    "end": "1430720"
  },
  {
    "text": "and use those negatives to\nactually allow it to continue to learn and continue to getting\ngood gradients from this loss",
    "start": "1430720",
    "end": "1437350"
  },
  {
    "text": "function. But we can also just basically--",
    "start": "1437350",
    "end": "1442785"
  },
  {
    "text": "essentially, instead of\njust sampling one negative, we can sample multiple\nnegatives and incorporate that into the loss function as well.",
    "start": "1442785",
    "end": "1448752"
  },
  {
    "text": "And this gets at the question\nthat was asked before, which is, what if I don't want\nto contrast against one thing? What if I want to contrast\nagainst multiple different",
    "start": "1448753",
    "end": "1455200"
  },
  {
    "text": "things?  And so the second version of\nthe loss function that will look",
    "start": "1455200",
    "end": "1462020"
  },
  {
    "text": "like-- the second version\nof the loss function is something that is going to do\nmore of an n-way classification",
    "start": "1462020",
    "end": "1467477"
  },
  {
    "text": "rather than these\nbinary comparisons. And so instead of thinking\nabout just having one negative,",
    "start": "1467477",
    "end": "1473380"
  },
  {
    "text": "we're also going to\nthink about having multiple other negatives. And essentially, what we're\ngoing to want to be able to do",
    "start": "1473380",
    "end": "1480830"
  },
  {
    "text": "is classify among the\nturquoise and pink and yellow",
    "start": "1480830",
    "end": "1486559"
  },
  {
    "text": "and salmon-colored dots which of\nthose is the positive and which one is the negative--",
    "start": "1486560",
    "end": "1492559"
  },
  {
    "text": "or which one is a negative. And so if we want to perform\nthat kind of classification,",
    "start": "1492560",
    "end": "1501559"
  },
  {
    "text": "it's going to look a\nlot like a softmax. So we can measure the\ndistance between the positive",
    "start": "1501560",
    "end": "1509299"
  },
  {
    "text": "and the anchor and the\nnegative and the anchor-- or the negatives and the anchor.",
    "start": "1509300",
    "end": "1515030"
  },
  {
    "text": "And what are the probability\nthat an example will be?",
    "start": "1515030",
    "end": "1521330"
  },
  {
    "text": "The positive will\nbe something like e to the negative distance\nbetween x and x plus divided",
    "start": "1521330",
    "end": "1530150"
  },
  {
    "text": "by basically a softmax. So we're just going to\nexponentiate and normalize",
    "start": "1530150",
    "end": "1535520"
  },
  {
    "text": "these distances\nwhere we are dividing by the distance between\nthe anchor in each",
    "start": "1535520",
    "end": "1541370"
  },
  {
    "text": "of the negatives.  And so this basically\ngives you the probability",
    "start": "1541370",
    "end": "1548929"
  },
  {
    "text": "that x plus is a\npositive example, rather than being a negative example.",
    "start": "1548930",
    "end": "1554950"
  },
  {
    "text": "And when you actually then\ncompute the loss for this--",
    "start": "1554950",
    "end": "1560110"
  },
  {
    "text": "oh, actually, sorry. These should technically,\nI guess, be f of x.",
    "start": "1560110",
    "end": "1565660"
  },
  {
    "text": "Or equivalently, you could\nwrite these as d of z or d of z",
    "start": "1565660",
    "end": "1570970"
  },
  {
    "text": "and d of z plus and d\nof z and d of z minus.",
    "start": "1570970",
    "end": "1576190"
  },
  {
    "text": "So d will just correspond to\neither the Euclidean losses before or something like\nnegative cosine similarity.",
    "start": "1576190",
    "end": "1586940"
  },
  {
    "text": "And then what the loss\nfunction looks like is-- this is a probability. We'll just minimize the\nnegative log probability.",
    "start": "1586940",
    "end": "1594870"
  },
  {
    "text": "So we'll take the log of this\nand minimize this with respect to theta.",
    "start": "1594870",
    "end": "1601179"
  },
  {
    "text": "Yeah. Is there something over\nthe negative examples? [INAUDIBLE]?",
    "start": "1601180",
    "end": "1607450"
  },
  {
    "text": "Oh, yeah, sorry. This is something over\nthe negative examples. And so yeah, great catch. So this is over n.",
    "start": "1607450",
    "end": "1612910"
  },
  {
    "text": "And then this is z minus n. [INAUDIBLE]",
    "start": "1612910",
    "end": "1621970"
  },
  {
    "text": "Yeah, so we need to\nknow-- during training, we need to know what the\npositives and negative examples are. Yeah.",
    "start": "1621970",
    "end": "1627000"
  },
  {
    "text": "[INAUDIBLE] We don't a priori know how\ngood of a negative they are.",
    "start": "1627000",
    "end": "1634870"
  },
  {
    "text": "But this loss function\nwill basically take into account all of them.",
    "start": "1634870",
    "end": "1640070"
  },
  {
    "text": "Yeah. Could we also sum over\nall the negative examples",
    "start": "1640070",
    "end": "1646130"
  },
  {
    "text": "using the triplet loss? Yeah, so the question\nwas, can we also",
    "start": "1646130",
    "end": "1652010"
  },
  {
    "text": "sum over all the negatives\nusing the triplet loss? This actually ends up\nbeing very, very similar to doing that.",
    "start": "1652010",
    "end": "1657720"
  },
  {
    "text": "So if you actually write\nthis out with the log,",
    "start": "1657720",
    "end": "1664470"
  },
  {
    "text": "the numerator will become log\nof e to the negative distance. And so-- or negative log of\ne to the negative distance.",
    "start": "1664470",
    "end": "1669810"
  },
  {
    "text": "And so this actually just\nbecomes d of z and z plus. And then with the\ndenominator, you",
    "start": "1669810",
    "end": "1676490"
  },
  {
    "text": "get something like\nplus log of sum of e",
    "start": "1676490",
    "end": "1682190"
  },
  {
    "text": "to the negative distance\nof z and z minus. And so you have a\nlog sum x up here.",
    "start": "1682190",
    "end": "1689850"
  },
  {
    "text": "But if you basically think of\nthe log and the e canceling out, this is basically just like\nsumming up the distances there.",
    "start": "1689850",
    "end": "1699940"
  },
  {
    "text": "Yeah. So I didn't get that. Can you basically explain what\nyou're trying to achieve here?",
    "start": "1699940",
    "end": "1705610"
  },
  {
    "text": "Yeah, so the question was just-- the question was, can we just\nbasically take the triplet loss",
    "start": "1705610",
    "end": "1712730"
  },
  {
    "text": "and just add up\nall the negatives? And what I was simply saying\nis that this loss function",
    "start": "1712730",
    "end": "1719210"
  },
  {
    "text": "is actually already very\nsimilar to the triplet loss but where you sum over\nthe negatives here.",
    "start": "1719210",
    "end": "1725940"
  },
  {
    "text": "And so the question\nis, why don't we just do something like this?",
    "start": "1725940",
    "end": "1732448"
  },
  {
    "text": "And this loss is actually\nalready doing something a lot like that, except instead\nof something, we're going to do a log sum x.",
    "start": "1732448",
    "end": "1738814"
  },
  {
    "text": "[INAUDIBLE] Oh, sorry, yeah, what is the\nloss function doing itself? So yeah, there's a few\ndifferent intuitive ways",
    "start": "1738814",
    "end": "1747320"
  },
  {
    "text": "to think about\nthis loss function. One is very similar to\nthe triplet loss, which",
    "start": "1747320",
    "end": "1752810"
  },
  {
    "text": "is that it's pulling together\nthe things, the positive and the anchor, and\npushing apart or maximizing",
    "start": "1752810",
    "end": "1758030"
  },
  {
    "text": "the distance between the\nanchor and the negatives. The second intuition that\nyou can think of it as",
    "start": "1758030",
    "end": "1763880"
  },
  {
    "text": "is basically classifying\nwhether or not an example is a positive example\nor a negative example given",
    "start": "1763880",
    "end": "1770809"
  },
  {
    "text": "the anchor. And so this looks a\nlot like a softmax",
    "start": "1770810",
    "end": "1777830"
  },
  {
    "text": "where your logits correspond\nto this negative distance between your example\nand the anchor.",
    "start": "1777830",
    "end": "1786605"
  },
  {
    "start": "1786605",
    "end": "1791730"
  },
  {
    "text": "Yeah. I think I still just\nhave a hard time grasping why the top is\npositive and the bottom",
    "start": "1791730",
    "end": "1798725"
  },
  {
    "text": "is some other negative\nexamples like the-- sorry, for this loss\nfunction on the--",
    "start": "1798725",
    "end": "1806392"
  },
  {
    "text": "yeah, it says that\nz plus on the top. But [INAUDIBLE] negative\nexamples for the bottom part.",
    "start": "1806392",
    "end": "1816690"
  },
  {
    "text": "And I'm not sure\nwhy that's the case. Yeah, so the-- well, so I guess\none other form of this loss",
    "start": "1816690",
    "end": "1823980"
  },
  {
    "text": "function that I\ncan mention is one where you use sum over all\nthe examples on the bottom. And so you also add something\nwhere the positive example also",
    "start": "1823980",
    "end": "1834179"
  },
  {
    "text": "comes on the bottom. I don't know if that\nmakes more sense to you.",
    "start": "1834180",
    "end": "1839980"
  },
  {
    "text": "So yeah, this is also a\nversion that you can do. This, I think-- this\nversion actually, I think, is what is done in\nthis first paper.",
    "start": "1839980",
    "end": "1846860"
  },
  {
    "text": "Whereas in the second\npaper, they actually didn't include this. And I think that the intuition\nperhaps for not including it",
    "start": "1846860",
    "end": "1853620"
  },
  {
    "text": "is that you really only\nwant to push apart the-- you really only\nwant to push apart",
    "start": "1853620",
    "end": "1859950"
  },
  {
    "text": "the anchor and the negatives. You don't really\nwant to push apart the anchor and the positive.",
    "start": "1859950",
    "end": "1865152"
  },
  {
    "text": "And this denominator is\nbasically pushing them apart. Yeah. I'm sorry [INAUDIBLE]. Do we have any knowledge\nabout the class of z?",
    "start": "1865152",
    "end": "1874140"
  },
  {
    "text": "The question was, do we have any\nknowledge about the class of z? In the unlabeled\ncase, you don't have",
    "start": "1874140",
    "end": "1879280"
  },
  {
    "text": "any knowledge about the\nclass of any of the examples. Then why would we want\nit to be closer to z plus",
    "start": "1879280",
    "end": "1886434"
  },
  {
    "text": "rather than z minus? Yeah, so the question\nis, why would we then want the anchor to\nbe closer to z plus versus",
    "start": "1886434",
    "end": "1893139"
  },
  {
    "text": "z minus? This comes down to how we\nsample positives and negatives. And so on the next slide, I'll\ntalk about how we sample it.",
    "start": "1893140",
    "end": "1902070"
  },
  {
    "text": "Yeah. Going back to hard\nnegative mining, could you interpret that\nas adversarial paradigm",
    "start": "1902070",
    "end": "1907280"
  },
  {
    "text": "where you're trying to find the\nhardest examples [INAUDIBLE]?? Yeah, so question is, can we\ninterpret hard negative mining",
    "start": "1907280",
    "end": "1913610"
  },
  {
    "text": "as a form of adversarial loss? And yeah, exactly. So basically, if you're-- the\nway that it would look like",
    "start": "1913610",
    "end": "1920255"
  },
  {
    "text": "in the case of the\ntriplet loss, for example, is you find the negatives that\nmaximize this loss function",
    "start": "1920255",
    "end": "1925520"
  },
  {
    "text": "rather than minimize those\nand specifically pick those. And so in some ways, it is\na form of an adversarial-- or a form of an adversary.",
    "start": "1925520",
    "end": "1932000"
  },
  {
    "text": " Cool. So here's the loss function\njust kind of written out",
    "start": "1932000",
    "end": "1941620"
  },
  {
    "text": "on the board. I talked a little bit about\nhow this is in some ways",
    "start": "1941620",
    "end": "1946870"
  },
  {
    "text": "a generalization of the triplet\nloss to multiple negatives. Now, let's actually walk\nthrough one algorithm",
    "start": "1946870",
    "end": "1955653"
  },
  {
    "text": "that explicitly\nwalks through also how we sample the\npositive and negatives. And I think that that should\nhelp clear up what has been--",
    "start": "1955653",
    "end": "1963490"
  },
  {
    "text": "clear up some of the questions\nthat have been asked. So the input to this algorithm\nis just a set of examples",
    "start": "1963490",
    "end": "1972880"
  },
  {
    "text": "x, just unlabeled examples. And so what the\nSimCLR algorithm does is it samples a mini\nbatch of those examples.",
    "start": "1972880",
    "end": "1980610"
  },
  {
    "text": "So it samples n\nof those examples. And to generate\npositives, it's going",
    "start": "1980610",
    "end": "1986960"
  },
  {
    "text": "to augment those examples with\nsome augmentation function. And so here, we're\nsampling some images, which",
    "start": "1986960",
    "end": "1995660"
  },
  {
    "text": "are our mini batch of examples. And we're going to augment each\nof those examples twice to get",
    "start": "1995660",
    "end": "2003010"
  },
  {
    "text": "x tilde and x tilde prime. And so, for example,\nthe augmentations here correspond to\nchanging the color,",
    "start": "2003010",
    "end": "2010179"
  },
  {
    "text": "cropping in different ways,\nand distorting or flipping",
    "start": "2010180",
    "end": "2016180"
  },
  {
    "text": "and so forth. And so, for example,\nwe take our example. Then we augment it\nin two different ways",
    "start": "2016180",
    "end": "2022270"
  },
  {
    "text": "and do that for every\nexample in our mini batch.",
    "start": "2022270",
    "end": "2027310"
  },
  {
    "text": "Then once we have\nthese augmentations, we're going to embed\nour augmented examples",
    "start": "2027310",
    "end": "2032920"
  },
  {
    "text": "into our embedding space. So this corresponds\nto just running each of these augmented examples\nthrough our encoder f theta.",
    "start": "2032920",
    "end": "2040990"
  },
  {
    "text": " And then from\nthere, the positives",
    "start": "2040990",
    "end": "2047929"
  },
  {
    "text": "are going to correspond to\naugmentations of the same image",
    "start": "2047930",
    "end": "2053940"
  },
  {
    "text": "and the negatives are going\nto correspond to augmentations of different images. And so the things that we're\ngoing to try to bring together",
    "start": "2053940",
    "end": "2061230"
  },
  {
    "text": "are these augmentations\nat the same image. And the things that we're\ngoing to try to push apart are basically everything\nelse in the batch.",
    "start": "2061230",
    "end": "2067664"
  },
  {
    "text": " So this is one way to generate\npositives and negatives.",
    "start": "2067664",
    "end": "2072850"
  },
  {
    "text": "There's also other\nways to generate positives and\nnegatives that we'll talk about on a future slide.",
    "start": "2072850",
    "end": "2079734"
  },
  {
    "text": "And so intuitively,\nwe don't know the classes of these images. But we do know that if we\ndesign good augmentations,",
    "start": "2079735",
    "end": "2086840"
  },
  {
    "text": "then the augmented\nversions-- these are actually very different images. But they have the same\nclass because they're",
    "start": "2086840",
    "end": "2092480"
  },
  {
    "text": "generated from the same image. And likewise, these have\ndifferent classes and so forth.",
    "start": "2092480",
    "end": "2103040"
  },
  {
    "text": "As was mentioned\nbefore, it's possible that you could also sample\na chair in this batch. And you might end up\npushing apart other chairs.",
    "start": "2103040",
    "end": "2112690"
  },
  {
    "text": "That's OK as long as the-- as long as not every\nexample you're pushing apart",
    "start": "2112690",
    "end": "2118420"
  },
  {
    "text": "is also a chair. You could also think of\nthis as doing something",
    "start": "2118420",
    "end": "2123579"
  },
  {
    "text": "a form of more\nfine-grained classification where you're basically trying\nto discriminate different instances rather than\ndifferent classes.",
    "start": "2123580",
    "end": "2129490"
  },
  {
    "text": " Did that answer your question? ",
    "start": "2129490",
    "end": "2136140"
  },
  {
    "text": "Yeah. So eventually,\nthis kind of thing will lead to an\nembedding space where",
    "start": "2136140",
    "end": "2141800"
  },
  {
    "text": "even if there are two in the\nclass that's in the chair and if we had two different\nimages of chairs--",
    "start": "2141800",
    "end": "2148020"
  },
  {
    "text": "so they might be separate. But the relative distance\nwithin two chairs would be lesser than\nthe relative distance",
    "start": "2148020",
    "end": "2154730"
  },
  {
    "text": "between the chair and the dog? Yeah, exactly. So the result of this algorithm\nshould be an embedding space",
    "start": "2154730",
    "end": "2160579"
  },
  {
    "text": "such that chairs are closer\nto each other than chairs and dogs. And part of that also relies\non your augmentation function.",
    "start": "2160580",
    "end": "2168599"
  },
  {
    "text": "And ideally, your\naugmentation function will generate other things\nthat look like chairs. And so by pulling\ntogether those things,",
    "start": "2168600",
    "end": "2175790"
  },
  {
    "text": "it will make it more\ndifficult for the network to push apart an example\nof a different chair",
    "start": "2175790",
    "end": "2182000"
  },
  {
    "text": "because you have--\nbecause you have to have these have a\nsimilar representation.",
    "start": "2182000",
    "end": "2187520"
  },
  {
    "text": "Yeah. Could you explain the choice why\nto augment twice and train only on augmented\nexamples, as opposed",
    "start": "2187520",
    "end": "2193280"
  },
  {
    "text": "to augmenting once and\nusing your original data? Yeah, so you could also just\naugment once, and basically",
    "start": "2193280",
    "end": "2199820"
  },
  {
    "text": "use the unaugmented\nexample as the anchor, and the augmented\nexample as the positive.",
    "start": "2199820",
    "end": "2206839"
  },
  {
    "text": "One thing that\nthis does give you is it gives you more negatives\nand more anchors and more",
    "start": "2206840",
    "end": "2212730"
  },
  {
    "text": "positives. And so if you have a good\naugmentation function, I think that augmenting twice\nand using augmented examples,",
    "start": "2212730",
    "end": "2220520"
  },
  {
    "text": "both as anchors and\npositives and negatives, should work well. I would also expect\nthat if they include",
    "start": "2220520",
    "end": "2226099"
  },
  {
    "text": "some of the original examples\nas positives, anchors, and so forth, or basically\nhave the identity function",
    "start": "2226100",
    "end": "2231950"
  },
  {
    "text": "be part of your augmentation\nclass, that would also be a very reasonable choice. ",
    "start": "2231950",
    "end": "2239660"
  },
  {
    "text": "Yeah. if it is not part of\naugmentation, you could say,",
    "start": "2239660",
    "end": "2244750"
  },
  {
    "text": "isn't the natural\n[INAUDIBLE] distribution for the [INAUDIBLE],, kind\nof, because it's only been [INAUDIBLE]? Because it's something quite\ndifferent from the natural.",
    "start": "2244750",
    "end": "2252390"
  },
  {
    "text": "Yeah. So the question was if the\nidentity function isn't in your augmentation class,\nthen will these images",
    "start": "2252390",
    "end": "2257750"
  },
  {
    "text": "be out of distribution in\ncomparison to these images? In general, these\naugmentation classes are designed such that\nthey are exhaustive",
    "start": "2257750",
    "end": "2265550"
  },
  {
    "text": "and that they cover a much wider\nspace than the original space. And such that they\naren't completely",
    "start": "2265550",
    "end": "2271430"
  },
  {
    "text": "disjoint from the\noriginal space. And so, in practice, that\nends up not being an issue",
    "start": "2271430",
    "end": "2276799"
  },
  {
    "text": "if you design your\naugmentations well. But it does mean that when\nyou design your augmentations, you shouldn't design it\nto basically be disjoint",
    "start": "2276800",
    "end": "2283580"
  },
  {
    "text": "from your original space. Yeah. So we're not embedding the\noriginal examples at all?",
    "start": "2283580",
    "end": "2291430"
  },
  {
    "text": "Yeah, in this case, we're not\nactually-- well, if identity is included in your augmentation\nclass, then we are.",
    "start": "2291430",
    "end": "2296690"
  },
  {
    "text": "But if it's not, then we're\nnot actually doing that. Yeah. So if this is\ncompletely unsupervised,",
    "start": "2296690",
    "end": "2303030"
  },
  {
    "text": "then can't we accidentally\nsample two dogs instead of a dog and a chair?",
    "start": "2303030",
    "end": "2308760"
  },
  {
    "text": "Yeah, so if this was\ncompletely unsupervised, can't we accidentally sample\ntwo dogs rather than a dog",
    "start": "2308760",
    "end": "2314710"
  },
  {
    "text": "in a chair? And yes. This relies on the fact that\nkind of sampling to dogs",
    "start": "2314710",
    "end": "2322320"
  },
  {
    "text": "is less likely than sampling\na dog and something else. It also relies on the fact\nthat when you augment,",
    "start": "2322320",
    "end": "2328943"
  },
  {
    "text": "you'll create things that\nyou have to push together. And that will make it harder\nto push apart two dogs",
    "start": "2328943",
    "end": "2334260"
  },
  {
    "text": "than it is to push\napart a chair and a dog. ",
    "start": "2334260",
    "end": "2340970"
  },
  {
    "text": "Cool. And so just to finish\nout the algorithm, we talked about\nattracting and repelling. Attracting things of the\nsame image, orientations",
    "start": "2340970",
    "end": "2347320"
  },
  {
    "text": "of the same image, and\nrepelling augmentations of different images. What this ends up looking\nlike is once you embed",
    "start": "2347320",
    "end": "2353980"
  },
  {
    "text": "into your z-space then-- in this case, they're\nusing cosine similarity to compute the distances between\nall of the different pairs",
    "start": "2353980",
    "end": "2361539"
  },
  {
    "text": "of augmented examples. And what the loss function\nends up looking like",
    "start": "2361540",
    "end": "2366849"
  },
  {
    "text": "is basically exactly what we\nhave written on the board here. Where we take the\ndistance between the two",
    "start": "2366850",
    "end": "2376990"
  },
  {
    "text": "augmented versions\nof the same image. So that's going to\nbe z and z plus, here it's written as z\ntilde and z prime tilde.",
    "start": "2376990",
    "end": "2384865"
  },
  {
    "text": "So the i is the same,\nthat means that they're from the same original image. And then the denominator\nis over examples",
    "start": "2384865",
    "end": "2392530"
  },
  {
    "text": "that are of different\ninitial images.",
    "start": "2392530",
    "end": "2400950"
  },
  {
    "text": "And so those are an\naugmentation of one image versus an augmentation\nof another image. ",
    "start": "2400950",
    "end": "2408280"
  },
  {
    "text": "Yeah. Isn't this loss\nfunction algorithm kind of assumes a sort of\nbalance between classes?",
    "start": "2408280",
    "end": "2414819"
  },
  {
    "text": "Because if there's a huge\nimbalance this might not work.",
    "start": "2414820",
    "end": "2420190"
  },
  {
    "text": "Yeah, so the question\nis does this algorithm assume that your unlabeled\ndata is unbalanced? And in particular,\nif it's unbalanced",
    "start": "2420190",
    "end": "2426430"
  },
  {
    "text": "and you have a ton of dogs and\nonly a small number of chairs then maybe it\nwouldn't work well.",
    "start": "2426430",
    "end": "2432339"
  },
  {
    "text": "That's a great question. I don't know of any-- I don't know of any works\noff the top of my head",
    "start": "2432340",
    "end": "2437410"
  },
  {
    "text": "that have analyzed that. Although I vaguely remember some\nworks showing that in general",
    "start": "2437410",
    "end": "2442840"
  },
  {
    "text": "these algorithms can\nwork much less well if your data is not balanced. And this is actually a\nreally important thing",
    "start": "2442840",
    "end": "2451150"
  },
  {
    "text": "to keep in mind. Because data sets\nlike images that are balanced because we\nknow the labels of the data",
    "start": "2451150",
    "end": "2457780"
  },
  {
    "text": "set, or they're more balanced\nbecause we know the labels. But in cases where we\ndon't know the labels, we have no way of telling\nif they're balanced",
    "start": "2457780",
    "end": "2464300"
  },
  {
    "text": "or not because we\ndon't know the labels. And so in general, in practice\nwhen putting these algorithms",
    "start": "2464300",
    "end": "2474820"
  },
  {
    "text": "into practice, it's important\nto keep that in mind. If you also want to add,\nI can also potentially try",
    "start": "2474820",
    "end": "2480500"
  },
  {
    "text": "to point you to things\nthat have specifically looked at unsupervised\nlearning within balanced data. ",
    "start": "2480500",
    "end": "2489609"
  },
  {
    "text": "Cool. And so you apply this\nprocess iteratively to update your encoder. And once you have\nyour encoder, you",
    "start": "2489610",
    "end": "2495940"
  },
  {
    "text": "can then either\ntrain a classifier on top of that\nrepresentation, or fine tune the entire network.",
    "start": "2495940",
    "end": "2502690"
  },
  {
    "text": "One other design\nchoice I'll mention, it's not kind of written\nin the equations. But the SimCLR paper\nfound it pretty helpful",
    "start": "2502690",
    "end": "2510040"
  },
  {
    "text": "to actually use the\nrepresentation right here as your pre-trained\nrepresentation, rather",
    "start": "2510040",
    "end": "2515800"
  },
  {
    "text": "than the one right here. And that means that there's this\nkind of additional projection head that's taking\nthe representation",
    "start": "2515800",
    "end": "2521428"
  },
  {
    "text": "and projecting it\ninto another space. And then doing the compare and\ncontrast in that other space.",
    "start": "2521428",
    "end": "2529000"
  },
  {
    "text": "And they found that this made\nperformance somewhat better. And you could imagine that\nit gives a little bit more flexibility to the network.",
    "start": "2529000",
    "end": "2535900"
  },
  {
    "text": "Although, it also introduces\nadditional hyper-parameters in determining where\nshould this representation",
    "start": "2535900",
    "end": "2541690"
  },
  {
    "text": "be in the network. Yeah. On the loss function, I see\na similar, the two samples.",
    "start": "2541690",
    "end": "2549530"
  },
  {
    "text": "And if [INAUDIBLE] come from\na different class of group",
    "start": "2549530",
    "end": "2558010"
  },
  {
    "text": "because, I'm thinking,\nfor example, for example, an instance, suppose [INAUDIBLE]\nmaybe in the first and second,",
    "start": "2558010",
    "end": "2567100"
  },
  {
    "text": "both are for a\nsimilar cat, right. But in this formula, they\nsay once you, I mean,",
    "start": "2567100",
    "end": "2573910"
  },
  {
    "text": "make the distance larger\nbetween these two. So the denominator here is\nalways examples that have--",
    "start": "2573910",
    "end": "2581860"
  },
  {
    "text": "always augmentations\nof different examples. Although they may be examples\nof the same class, which",
    "start": "2581860",
    "end": "2588100"
  },
  {
    "text": "we had mentioned before. And ideally, that happens with\nlower probability than examples",
    "start": "2588100",
    "end": "2595630"
  },
  {
    "text": "of different classes. Yeah. [INAUDIBLE] before\nthe final, they're",
    "start": "2595630",
    "end": "2600829"
  },
  {
    "text": "actually going to make\nan adequate performance for this algorithm.",
    "start": "2600830",
    "end": "2606299"
  },
  {
    "text": "So this Unet, can\nUNet perform better for this contrastive algorithm?",
    "start": "2606300",
    "end": "2612510"
  },
  {
    "text": "So the question is,\ncan UNet perform better for these contrastive\nalgorithms? [INAUDIBLE]",
    "start": "2612510",
    "end": "2619920"
  },
  {
    "text": "So we'll talk more\nabout architectures that reconstruct the input\nin the Wednesday lecture.",
    "start": "2619920",
    "end": "2626150"
  },
  {
    "text": "I don't think you necessarily\nneed something like a UNet here, because this\nrepresentation doesn't need to be this very large image.",
    "start": "2626150",
    "end": "2633740"
  },
  {
    "text": "It can still be much\nlower dimensional or lower dimensional-- You could try [INAUDIBLE].",
    "start": "2633740",
    "end": "2641588"
  },
  {
    "text": "Yeah, you can also imagine\nhaving like skip connections here for example. Yeah, I think that you could\nimagine doing something",
    "start": "2641588",
    "end": "2647960"
  },
  {
    "text": "like that, I guess. I don't know of any\npapers that do that. But my intuition\nwould say that that",
    "start": "2647960",
    "end": "2655340"
  },
  {
    "text": "could be bad from the standpoint\nof like, it could just completely ignore\nthis part and just use the representation--\nuse the information do",
    "start": "2655340",
    "end": "2662000"
  },
  {
    "text": "those skip connections to\ndo the contrastive learning. But that's somewhat speculative.",
    "start": "2662000",
    "end": "2668087"
  },
  {
    "text": "And I don't know of any\npapers that do that. ",
    "start": "2668087",
    "end": "2675970"
  },
  {
    "text": "Cool, so how will these\nalgorithms actually work for learning\nrepresentations?",
    "start": "2675970",
    "end": "2683140"
  },
  {
    "text": "So here are some results from\nthe paper from the algorithm that we just went over.",
    "start": "2683140",
    "end": "2688360"
  },
  {
    "text": "And here they're comparing\nto ImageNet classification,",
    "start": "2688360",
    "end": "2694240"
  },
  {
    "text": "the top five accuracy. And they're looking\nat if you only use 1% of the ImageNet labels\nor 10% of the ImageNet labels.",
    "start": "2694240",
    "end": "2702569"
  },
  {
    "text": "And here, 1% corresponds to\nabout 12.8 images per class. And 10% corresponds to\nabout 128 images per class.",
    "start": "2702570",
    "end": "2711460"
  },
  {
    "text": "And so once you get down to\n1%, you're almost in few-shot learning regime,\nor possibly, you",
    "start": "2711460",
    "end": "2717197"
  },
  {
    "text": "can consider that in the\nfew-shot learning regime, if you kind of have 10\nto 15 examples per class. ",
    "start": "2717197",
    "end": "2724050"
  },
  {
    "text": "And we're comparing\nto a baseline that only trains with\nsupervised learning on those",
    "start": "2724050",
    "end": "2729089"
  },
  {
    "text": "labeled examples. As well as some\nsemi-supervised learning methods and some\nother representational learning methods.",
    "start": "2729090",
    "end": "2735570"
  },
  {
    "text": "And the results\nshow that first you get really substantial\nimprovements over just supervised\ntraining from scratch.",
    "start": "2735570",
    "end": "2741930"
  },
  {
    "text": "You go from-- in the 1%\ncase, from 48% accuracy to 85% accuracy.",
    "start": "2741930",
    "end": "2747460"
  },
  {
    "text": "Which is pretty significant. And you also see pretty\nsignificant improvements over other semi-supervised\nand unsupervised methods.",
    "start": "2747460",
    "end": "2756060"
  },
  {
    "text": " We see this kind of\nespecially as being the case",
    "start": "2756060",
    "end": "2761860"
  },
  {
    "text": "in the 1% label setting. So for example, in\ncomparison to, well,",
    "start": "2761860",
    "end": "2767410"
  },
  {
    "text": "CPC, which is another\ncontrastive method, we see about a 7%\nperformance improvement.",
    "start": "2767410",
    "end": "2773560"
  },
  {
    "text": "Compared to BigBiGAN, you see a\n30% improvement, and so forth.",
    "start": "2773560",
    "end": "2779488"
  },
  {
    "text": "These methods work pretty well. And overall, 85%\naccuracy on ImageNet is, I feel like, not too shabby.",
    "start": "2779488",
    "end": "2785420"
  },
  {
    "text": "And it's nice that we can\nget that while using only 1% of the labels in the data set.",
    "start": "2785420",
    "end": "2790970"
  },
  {
    "text": " Yeah.",
    "start": "2790970",
    "end": "2796060"
  },
  {
    "text": "[INAUDIBLE] Oh, yeah, what does\nthe 2x and 4x mean? So ResNet-50 is the standard\nResNet-50 architecture.",
    "start": "2796060",
    "end": "2803200"
  },
  {
    "text": "2x means that the width of the\nhidden layers is 2x larger. And 4x means it's 4x larger.",
    "start": "2803200",
    "end": "2810130"
  },
  {
    "text": "So it's just a larger network. And we see that it does\nbetter with larger networks.",
    "start": "2810130",
    "end": "2815410"
  },
  {
    "text": "But what about when\nusing 10% of the labels? What about when using\n10% of the labels?",
    "start": "2815410",
    "end": "2821316"
  },
  {
    "text": "[INAUDIBLE] Yeah, so we see that\nthe performance, it also does quite well\nin the 10% setting.",
    "start": "2821316",
    "end": "2826680"
  },
  {
    "text": "The performance improvements\nare somewhat smaller. And there's a semi supervised\nmethod that gets 91.2,",
    "start": "2826680",
    "end": "2832920"
  },
  {
    "text": "whereas this gets 92.6. But it is still kind of the best\nmethod compared to the methods",
    "start": "2832920",
    "end": "2839910"
  },
  {
    "text": "that were\nstate-of-the-art in 2020. You're saying that you only\nget 12.8 labeled images,",
    "start": "2839910",
    "end": "2847450"
  },
  {
    "text": "but you also get other\nimages that are unlabeled. Or this is only 12.8 images? Sorry, yeah.",
    "start": "2847450",
    "end": "2852790"
  },
  {
    "text": "We're using the entire\nImageNet data set as unlabeled. And then they're only\nusing 1% of the labels.",
    "start": "2852790",
    "end": "2859180"
  },
  {
    "text": "Yeah. [INAUDIBLE] ",
    "start": "2859180",
    "end": "2865005"
  },
  {
    "text": "So now we're trying to\npre train the network, and we're also training to the\nsame images that we pre-trained",
    "start": "2865005",
    "end": "2872730"
  },
  {
    "text": "here, so-- Yeah, so the question is\nare the representations useful beyond just\nImageNet classification?",
    "start": "2872730",
    "end": "2879370"
  },
  {
    "text": "Do the representations\ngeneralize well? The short answer is they do\ngeneralize to some degree,",
    "start": "2879370",
    "end": "2884800"
  },
  {
    "text": "and we'll see some\nresults towards the end of the lecture on that. ",
    "start": "2884800",
    "end": "2892760"
  },
  {
    "text": "Cool. And then there's\none other experiment that I think is actually\nquite important in the SimCLR",
    "start": "2892760",
    "end": "2898310"
  },
  {
    "text": "paper that was looking\nat not just performance, but how performance varied\nwith the number of training",
    "start": "2898310",
    "end": "2903620"
  },
  {
    "text": "epochs and the batch size. And the results are here. So the x-axis is the\nnumber of training epochs,",
    "start": "2903620",
    "end": "2910840"
  },
  {
    "text": "or how long you're training for. And the different bars\nwithin each of those correspond to the batch size.",
    "start": "2910840",
    "end": "2916240"
  },
  {
    "text": "With the blue on the left being\nthe smallest batch size of 256, which is still a\ndecently large batch.",
    "start": "2916240",
    "end": "2923110"
  },
  {
    "text": "And the bar on the far right\nbeing a batch size of 8,192.",
    "start": "2923110",
    "end": "2929360"
  },
  {
    "text": "And it's important to\ntrain for 600 plus epochs. I think this isn't\ntoo surprising",
    "start": "2929360",
    "end": "2935875"
  },
  {
    "text": "in unsupervised\nlearning settings because you need to learn\na lot about the data.",
    "start": "2935875",
    "end": "2941850"
  },
  {
    "text": "One thing that I\nthink is perhaps more important to note here is\nthat it requires a large batch size.",
    "start": "2941850",
    "end": "2947000"
  },
  {
    "text": "So if you train with\na batch size of 256, that does a lot worse than\nif you train on a batch",
    "start": "2947000",
    "end": "2953850"
  },
  {
    "text": "size of 1,000, for example. And the differences can be-- if you train for a\nreally long time,",
    "start": "2953850",
    "end": "2959310"
  },
  {
    "text": "that difference is only 2%. If you train for a\nshort amount of time that difference can\nbe more than 5%.",
    "start": "2959310",
    "end": "2964905"
  },
  {
    "text": " Yeah. Any intuition on why does\nit need a large batch size?",
    "start": "2964905",
    "end": "2971140"
  },
  {
    "text": "Yeah, so why does it\nneed a large batch size? So we'll talk about this\nboth intuitively and more",
    "start": "2971140",
    "end": "2980080"
  },
  {
    "text": "mathematically. So one way to interpret the\ncontrastive loss function",
    "start": "2980080",
    "end": "2986590"
  },
  {
    "text": "is basically you're trying\nto classify between-- classify, kind of, one image\nfrom all the other images",
    "start": "2986590",
    "end": "2996030"
  },
  {
    "text": "in the data set. And you can sort of\nthink of this, kind of,",
    "start": "2996030",
    "end": "3004380"
  },
  {
    "text": "the denominator of\nthis loss function is trying to sum over all the\nother examples in the data set. You're trying to\nclassify between one",
    "start": "3004380",
    "end": "3010230"
  },
  {
    "text": "example and everything else. And in the summation right here,\nthe examples, the negatives,",
    "start": "3010230",
    "end": "3021760"
  },
  {
    "text": "that have the smallest\ndistance are really going to dominate this sum. Because we're exponentiating\nhere, and so something",
    "start": "3021760",
    "end": "3028420"
  },
  {
    "text": "that has a distance\nof, say, like 0.01 versus a distance of 10.",
    "start": "3028420",
    "end": "3033610"
  },
  {
    "text": "Because we're\nexponentiating this, this is going to play a much\nlike e to the -0.01 versus",
    "start": "3033610",
    "end": "3039430"
  },
  {
    "text": "e to the negative 10. This is a much,\nmuch larger number. And so this is going to\nplay a much larger role",
    "start": "3039430",
    "end": "3045759"
  },
  {
    "text": "in the summation right here. And this means that because\nthese examples with a really",
    "start": "3045760",
    "end": "3052970"
  },
  {
    "text": "small distance are dominating,\nif you're subsampling and having a much\nsmaller batch size,",
    "start": "3052970",
    "end": "3057980"
  },
  {
    "text": "then you might miss the\nexamples that actually dominate that loss function.",
    "start": "3057980",
    "end": "3063280"
  },
  {
    "text": "And so you're not actually going\nto get a very good estimate of your loss function if you're\nmissing the examples that actually have played the\nlargest role in the summation.",
    "start": "3063280",
    "end": "3073080"
  },
  {
    "text": "So that's part of the intuition. And then more mathematically,\nif we want to think about this,",
    "start": "3073080",
    "end": "3088422"
  },
  {
    "text": "let's think about\nwhiteboard space. So I guess this is--",
    "start": "3088422",
    "end": "3095779"
  },
  {
    "text": "OK.  So this is our loss\nfunction right here.",
    "start": "3095780",
    "end": "3101599"
  },
  {
    "text": "I'm going to also remove this\njust because this is what-- or this is what SimCLR does.",
    "start": "3101600",
    "end": "3107382"
  },
  {
    "text": "So this is our loss function.  You can essentially\nthink of what",
    "start": "3107382",
    "end": "3114800"
  },
  {
    "text": "we do when we subsample as\nsort of bringing the summation",
    "start": "3114800",
    "end": "3121200"
  },
  {
    "text": "outside of the log. And I guess specifically,\nmaybe one thing to first note",
    "start": "3121200",
    "end": "3128650"
  },
  {
    "text": "is that in normal\nsupervised learning, we subsample all the time. It's not a problem.",
    "start": "3128650",
    "end": "3135960"
  },
  {
    "text": "And it's totally fine\nto have small batches. And the reason for that is our\nkind of typical loss function",
    "start": "3135960",
    "end": "3141420"
  },
  {
    "text": "might be something like log\nprobability of y given x. Or this is kind of a\nsummation over x comma y.",
    "start": "3141420",
    "end": "3150490"
  },
  {
    "text": "And when this is\nour loss function, if we subsample and sample\na smaller batch of x and y,",
    "start": "3150490",
    "end": "3159220"
  },
  {
    "text": "we'll still, in expectation,\nget the correct gradient. Now things are a\nlittle bit different",
    "start": "3159220",
    "end": "3167420"
  },
  {
    "text": "when we actually try to\nsubsample from this summation right here.",
    "start": "3167420",
    "end": "3172760"
  },
  {
    "text": "And in particular, if we\nwrite out this loss function, it ends up looking like\nfirst the distance between z",
    "start": "3172760",
    "end": "3184580"
  },
  {
    "text": "and z plus. This is all fine.  Plus the log of the sum over\nn of e to the negative d of z,",
    "start": "3184580",
    "end": "3200510"
  },
  {
    "text": "and z at minus. And the challenge\nhere is right now",
    "start": "3200510",
    "end": "3206310"
  },
  {
    "text": "this summation is\ninside of the log. ",
    "start": "3206310",
    "end": "3211869"
  },
  {
    "text": "And essentially when we sample\nmini batches, what we're doing is we are saying\nthat, well, maybe this",
    "start": "3211870",
    "end": "3218650"
  },
  {
    "text": "is approximately equal\n2 d of z of z plus.",
    "start": "3218650",
    "end": "3224140"
  },
  {
    "text": "Plus a sum over our mini\nbatch, times log of some over n",
    "start": "3224140",
    "end": "3234760"
  },
  {
    "text": "in our mini batch of e to\nthe negative d of z, zn.",
    "start": "3234760",
    "end": "3240970"
  },
  {
    "text": "So this is really\nwhat we're optimizing when we do mini batch sampling. Because instead of sampling\nall of the negatives",
    "start": "3240970",
    "end": "3248140"
  },
  {
    "text": "in our entire training\ndata set, we're sampling a mini batch of them. And now there's a question\nof what actually happens--",
    "start": "3248140",
    "end": "3257710"
  },
  {
    "text": "what's the relationship\nbetween these two equations? And there's something\ncalled Jensen's Inequality,",
    "start": "3257710",
    "end": "3262900"
  },
  {
    "text": "that's actually super useful. And one of the things that\nJensen's Inequality can",
    "start": "3262900",
    "end": "3268660"
  },
  {
    "text": "tell us is it tells\nus that log sum of x--",
    "start": "3268660",
    "end": "3274130"
  },
  {
    "text": "I always forget\nwhich way it goes-- is greater than or equal\nto the summation of log x.",
    "start": "3274130",
    "end": "3283390"
  },
  {
    "text": "We write this. And so what this means is\nthat it means that when we take the summation\non the outside,",
    "start": "3283390",
    "end": "3290820"
  },
  {
    "text": "that gives us a\nlower bound compared to when it's on the inside.",
    "start": "3290820",
    "end": "3295990"
  },
  {
    "text": "And so that means that this\napproximation right here, when we actually are doing this\nsort of mini batch sampling,",
    "start": "3295990",
    "end": "3302790"
  },
  {
    "text": "we're getting a lower bound\non our original objective.",
    "start": "3302790",
    "end": "3308680"
  },
  {
    "text": "And that means that\nwhen we actually minimize this objective\nwe're actually minimizing a lower bound\non our original objective.",
    "start": "3308680",
    "end": "3318480"
  },
  {
    "text": "And it's not good to minimize\nlower bounds on things because then you\nmay not actually be minimizing your\noriginal objective.",
    "start": "3318480",
    "end": "3328330"
  },
  {
    "text": "And so that's, I guess,\nsome additional intuition for why having a larger\nbatch size is helpful.",
    "start": "3328330",
    "end": "3334470"
  },
  {
    "text": "Because, basically,\nwe're not actually getting a bound\non our objective. And so if we sample something\ncloser to our original data",
    "start": "3334470",
    "end": "3340859"
  },
  {
    "text": "set, then we're actually going\nto come closer to optimizing our original objective. ",
    "start": "3340860",
    "end": "3349059"
  },
  {
    "text": "Any questions on that? ",
    "start": "3349060",
    "end": "3354880"
  },
  {
    "text": "Yeah. Could we also control\nsomehow how close is-- how tight is the bound?",
    "start": "3354880",
    "end": "3362770"
  },
  {
    "text": "The question is, is\nthere a way to control how tight the bound is? I mean, you can--",
    "start": "3362770",
    "end": "3372089"
  },
  {
    "text": "one thing that you could do is\njust sample your whole data set rather than sample mini\nbatches, although that's",
    "start": "3372090",
    "end": "3377100"
  },
  {
    "text": "sort of what we were\ntrying to get away from. Or to sample larger batches. So, I mean, that's kind of\nwhy larger batches make sense.",
    "start": "3377100",
    "end": "3386200"
  },
  {
    "text": "I don't know of any\nway to make it tighter.",
    "start": "3386200",
    "end": "3391300"
  },
  {
    "text": "But if you do, let me know. ",
    "start": "3391300",
    "end": "3399300"
  },
  {
    "text": "Cool. So yeah. The kind of summary is\nthat in normal mini batch,",
    "start": "3399300",
    "end": "3405270"
  },
  {
    "text": "or normal mini batch\nsupervised learning, the summation is\nalready on the outside. And we're all good\nand so we can estimate",
    "start": "3405270",
    "end": "3413130"
  },
  {
    "text": "this with mini batching. When the summation is\non the inside of a log,",
    "start": "3413130",
    "end": "3418840"
  },
  {
    "text": "then mini batching that is not\nreally the correct thing to do.",
    "start": "3418840",
    "end": "3425070"
  },
  {
    "text": "But we do it anyway\nbecause that's what deep learning is like. And then I also wanted to go\nthrough solutions to requiring",
    "start": "3425070",
    "end": "3432589"
  },
  {
    "text": "a large batch size. So one thing that\nyou could do is",
    "start": "3432590",
    "end": "3439660"
  },
  {
    "text": "instead of trying to\nsample your entire data set at every single iteration,\nyou can basically",
    "start": "3439660",
    "end": "3447309"
  },
  {
    "text": "store the representations\nfrom the previous batches with something that looks\na lot like momentum.",
    "start": "3447310",
    "end": "3454440"
  },
  {
    "text": "This is not exactly correct\nbecause your encoder is going to be changing\nover the course of training.",
    "start": "3454440",
    "end": "3461030"
  },
  {
    "text": "And so if you store those\nprevious representations, they're going to be\na little bit stale. But it allows you to somewhat\ndecouple the batch size",
    "start": "3461030",
    "end": "3469700"
  },
  {
    "text": "from this estimate. It allows you to get away\nwith smaller batch sizes because you're basically\naccumulating batches",
    "start": "3469700",
    "end": "3476900"
  },
  {
    "text": "over multiple iterations. This is called momentum\ncontrast, or MoCo.",
    "start": "3476900",
    "end": "3482160"
  },
  {
    "text": "And they were able to get\ngood results with a mini batch size of 256.",
    "start": "3482160",
    "end": "3488579"
  },
  {
    "text": "Another thing that you\ncan do that was proposed in the literature,\nis instead of having",
    "start": "3488580",
    "end": "3493829"
  },
  {
    "text": "any negatives\nwhatsoever, simply try to predict the\nrepresentation of your image",
    "start": "3493830",
    "end": "3499470"
  },
  {
    "text": "under a different augmentation. And so it's kind of more\nof a predictive method. It's called Bootstrap\nYour Own Latent.",
    "start": "3499470",
    "end": "3505730"
  },
  {
    "text": "It actually doesn't\nrequire any negatives. It just requires\nexamples of positives. And when they plotted\nperformance with respect",
    "start": "3505730",
    "end": "3513210"
  },
  {
    "text": "to batch size, they\nfound that it dropped off much less especially up\nuntil 256 in comparison",
    "start": "3513210",
    "end": "3520170"
  },
  {
    "text": "to the SimCLR method. And so it's more\nresilient to batch size, although it's\nsomething that's also--",
    "start": "3520170",
    "end": "3528490"
  },
  {
    "text": "doesn't have some of the kind of\nnice contrast of interpretation",
    "start": "3528490",
    "end": "3533770"
  },
  {
    "text": "that we've talked about so far. ",
    "start": "3533770",
    "end": "3540130"
  },
  {
    "text": "And then overall, in\nterms of the performance of these methods,\nif you actually look at how good\nthey are in terms",
    "start": "3540130",
    "end": "3545500"
  },
  {
    "text": "of self-supervised learning\nfor ImageNet accuracy, we see that some of the\npapers that we covered",
    "start": "3545500",
    "end": "3551140"
  },
  {
    "text": "were from a couple of years ago. But they really remained\nnear state-of-the-art for self-supervised\npre-training.",
    "start": "3551140",
    "end": "3557440"
  },
  {
    "text": "And in particular, you can\nsee MoCo V3 is very close to the state-of-the-art.",
    "start": "3557440",
    "end": "3563320"
  },
  {
    "text": "I haven't actually\nlooked at what is exactly the state-of-the-art. So I'm sure if it may also be\na contrastive method or maybe",
    "start": "3563320",
    "end": "3568758"
  },
  {
    "text": "something that's a\nlittle bit different. Yeah.",
    "start": "3568758",
    "end": "3573930"
  },
  {
    "text": "[INAUDIBLE]  So can't we just try to\nget some of [INAUDIBLE]??",
    "start": "3573930",
    "end": "3581119"
  },
  {
    "start": "3581120",
    "end": "3590700"
  },
  {
    "text": "Can we just take the\nlogs on these [INAUDIBLE]",
    "start": "3590700",
    "end": "3599070"
  },
  {
    "text": "say that it is\nunder expectation? Wouldn't that mean much\nof the same thing?? So you're saying that\nwhy do we have this loss",
    "start": "3599070",
    "end": "3605849"
  },
  {
    "text": "function in the first place? Why not have this on\noutside of the log or-- [INAUDIBLE],, then\nit could be for one",
    "start": "3605850",
    "end": "3612079"
  },
  {
    "text": "of these loss functions. That is correct. If you move the sum\noutside of the log then",
    "start": "3612080",
    "end": "3617580"
  },
  {
    "text": "it becomes a lower\nbound, according to Jensen's Inequality. So if the sum is on\nthe outside, it's",
    "start": "3617580",
    "end": "3623502"
  },
  {
    "text": "a lower bound in comparison\nto if it's on the inside. [INAUDIBLE] Yeah. And unfortunately, sometimes\nI wish Jensen's Inequality",
    "start": "3623502",
    "end": "3630040"
  },
  {
    "text": "went the other way. But, yeah. ",
    "start": "3630040",
    "end": "3636590"
  },
  {
    "text": "Yeah. [INAUDIBLE] ",
    "start": "3636590",
    "end": "3643744"
  },
  {
    "text": "But would this\n[INAUDIBLE] approach be applicable when we\napply multiple objects in the image [INAUDIBLE]?",
    "start": "3643744",
    "end": "3651230"
  },
  {
    "text": "Yeah, so the question was a\nlot of ImageNet images just have one example or one\nobject in the image.",
    "start": "3651230",
    "end": "3657710"
  },
  {
    "text": "And would this work if you have\nmultiple objects in an image?",
    "start": "3657710",
    "end": "3662990"
  },
  {
    "text": "I guess I don't know of any\nspecific detailed experimental studies on that. But I'll show a\ncouple of instances",
    "start": "3662990",
    "end": "3668770"
  },
  {
    "text": "where contrastive learning has\nbeen used in settings outside of ImageNet and\nthat might provide some answer to your question.",
    "start": "3668770",
    "end": "3675619"
  },
  {
    "text": " Cool.",
    "start": "3675620",
    "end": "3681210"
  },
  {
    "text": "And so I guess moving\ntowards that to some degree, these methods have\nbeen really good",
    "start": "3681210",
    "end": "3687600"
  },
  {
    "text": "for visual categorization,\nthings like ImageNet. And one challenge that comes\nup is that we've mostly",
    "start": "3687600",
    "end": "3697270"
  },
  {
    "text": "been focusing on augmentations. And there's a lot\nof scenarios where we don't have a good\nhand-engineered augmentation",
    "start": "3697270",
    "end": "3704140"
  },
  {
    "text": "function that we can\nuse for these methods. And even in those cases,\nthe general framework",
    "start": "3704140",
    "end": "3710349"
  },
  {
    "text": "of contrastive learning\ncan still be very useful. And so kind of alluding to\nsomething that came up earlier,",
    "start": "3710350",
    "end": "3717190"
  },
  {
    "text": "you can actually try to learn\nthe augmentation function. And this is a really cool\npaper that actually basically",
    "start": "3717190",
    "end": "3723700"
  },
  {
    "text": "formulated an adversarial\noptimization where for your augmentation\nfunction, you",
    "start": "3723700",
    "end": "3730060"
  },
  {
    "text": "tried to optimize\nit in a way that maximized the contrastive loss.",
    "start": "3730060",
    "end": "3735395"
  },
  {
    "text": "Of course if you do this in\na completely unbounded space, then it will just give\nyou arbitrary images out. But what you can\ndo is you can say",
    "start": "3735395",
    "end": "3741700"
  },
  {
    "text": "that that augmentation\nfunction, it can only change the\nimage by a small amount, within some L1 sphere.",
    "start": "3741700",
    "end": "3749230"
  },
  {
    "text": "And this paper was actually\ncompetitive with SimCLR on image data,\nwhich means that it",
    "start": "3749230",
    "end": "3755260"
  },
  {
    "text": "was able to find\naugmentations that were as good as the\nhand-engineered augmentations.",
    "start": "3755260",
    "end": "3760900"
  },
  {
    "text": "And it was also able\nto get good results on domains that aren't images. So domains like speech\ndata and sensor data.",
    "start": "3760900",
    "end": "3767650"
  },
  {
    "text": " Cool. And then one other thing\nthat we had mentioned earlier",
    "start": "3767650",
    "end": "3774580"
  },
  {
    "text": "is instead of using\naugmentations, we could use, basically, our\npositives could be",
    "start": "3774580",
    "end": "3780040"
  },
  {
    "text": "frames in a video that\nare nearby in time. And the negatives\ncould be things that are further away in\ntime, or from other videos.",
    "start": "3780040",
    "end": "3787315"
  },
  {
    "text": "And there have been a number of\npapers that have done something like this and they've been able\nto get good results on tasks",
    "start": "3787315",
    "end": "3793089"
  },
  {
    "text": "like robotics tasks. And so in this paper can\ntake, basically, a data",
    "start": "3793090",
    "end": "3801250"
  },
  {
    "text": "set with a ton of\ndiverse videos of humans. Do this sort of time\ncontrastive learning, where",
    "start": "3801250",
    "end": "3806260"
  },
  {
    "text": "you pull together frames that\nhave similar representations and push apart frames that\nhave different representations.",
    "start": "3806260",
    "end": "3811960"
  },
  {
    "text": "And there was also\nan additional loss that sort of did a form\nof contrastive learning between videos and language.",
    "start": "3811960",
    "end": "3818210"
  },
  {
    "text": "And it found that\nif you use this to pre-train or\nrepresentation, you can give a robot 20\ndemonstrations or less",
    "start": "3818210",
    "end": "3824750"
  },
  {
    "text": "than 10 minutes of supervision. And get a policy that\nlooks something like this,",
    "start": "3824750",
    "end": "3831349"
  },
  {
    "text": "gets around 60% success rate\non putting lettuce in a pan. And 40% success rate\non folding a towel.",
    "start": "3831350",
    "end": "3837860"
  },
  {
    "text": " And then the last\nthing I will highlight is this isn't really\nfully self-supervised,",
    "start": "3837860",
    "end": "3846020"
  },
  {
    "text": "but you can also apply\ncontrastive learning between images and text.",
    "start": "3846020",
    "end": "3851160"
  },
  {
    "text": "And what this looks\nlike is you learn a representation\nof the images, you learn a representation\nof the text.",
    "start": "3851160",
    "end": "3856260"
  },
  {
    "text": "If you have data that tells you\nwhether or not-- that basically kind of captions an image. Then you can tell it that\ncaptions and images should",
    "start": "3856260",
    "end": "3864680"
  },
  {
    "text": "go together and images\nand other captions or images and other captions\nshould be pushed apart.",
    "start": "3864680",
    "end": "3872310"
  },
  {
    "text": "And so this is the key idea\nbehind a model called CLIP. And it's actually a\nreally performant model",
    "start": "3872310",
    "end": "3879050"
  },
  {
    "text": "and it gives you very\nuseful representations. It also can give you very\ngood zero-shot classification",
    "start": "3879050",
    "end": "3885770"
  },
  {
    "text": "performance. So on ImageNet, it was able to\ngive you ImageNet accuracy that",
    "start": "3885770",
    "end": "3891470"
  },
  {
    "text": "matches a supervised resonant. But even more interestingly,\nif you give it",
    "start": "3891470",
    "end": "3897380"
  },
  {
    "text": "images that don't look anything\nlike ImageNet-like sketches or it's more adversarial,\nImageNet data",
    "start": "3897380",
    "end": "3904530"
  },
  {
    "text": "set is able to get\nperformance that's much higher than\nsomething that is trained in a supervised\nfashion on ImageNet.",
    "start": "3904530",
    "end": "3910910"
  },
  {
    "text": " Yeah. Could this be because they\nhad massive amounts of data?",
    "start": "3910910",
    "end": "3919640"
  },
  {
    "text": "Yeah, so are these\nresults because of the magic of\ncontrastive learning, or is it because\nof the data set?",
    "start": "3919640",
    "end": "3926510"
  },
  {
    "text": "Certainly the data set\nplays a huge role here. And the diversity of the\ndata set that is given",
    "start": "3926510",
    "end": "3933080"
  },
  {
    "text": "will help it be able to do\nwell on these kinds of things. That said, there are\na number of works",
    "start": "3933080",
    "end": "3939619"
  },
  {
    "text": "that I've kind of\ntried to ablate the role of self-supervised\nlearning versus the data set. And it found that things\nthat are more self-supervised",
    "start": "3939620",
    "end": "3947210"
  },
  {
    "text": "are more similar to\nsomething like CLIP, do better than\nsomething that's trained in a purely supervised fashion.",
    "start": "3947210",
    "end": "3953359"
  },
  {
    "start": "3953360",
    "end": "3958650"
  },
  {
    "text": "Cool. So to summarize\ncontrastive learning, it's a very general and\neffective framework.",
    "start": "3958650",
    "end": "3964140"
  },
  {
    "text": "And we've seen how it can be\nused to compare and contrast lots of different things.",
    "start": "3964140",
    "end": "3970090"
  },
  {
    "text": "One thing that's nice\nabout it is that you only need an encoder, f theta of x. You don't need a generative\nmodel of your data.",
    "start": "3970090",
    "end": "3976870"
  },
  {
    "text": "And this means that\nyou can probably get away with a smaller\nmodel than if you had used a generative model.",
    "start": "3976870",
    "end": "3982470"
  },
  {
    "text": " The other thing that\ncan be viewed as a pro",
    "start": "3982470",
    "end": "3987895"
  },
  {
    "text": "is if you have some\ndomain information, like augmentations, that can be\nincorporated into the algorithm to generate other positives.",
    "start": "3987895",
    "end": "3996809"
  },
  {
    "text": "The challenges is that\nnegatives can be hard to select. And as a result, it often\nrequires a large batch size.",
    "start": "3996810",
    "end": "4004010"
  },
  {
    "text": "And so this is a little bit the\nkind of other side of the coin,",
    "start": "4004010",
    "end": "4009700"
  },
  {
    "text": "with respect to the generative\nmodeling not being required. You can usually get away\nwith a smaller model, but you need a larger\nbatch size oftentimes.",
    "start": "4009700",
    "end": "4016670"
  },
  {
    "text": "And so you might still need\na large amount of GPU memory, for example, to train\nthese kinds of models. ",
    "start": "4016670",
    "end": "4023700"
  },
  {
    "text": "And then the other\nchallenge is that it has been most successful\nwith augmentations, like we talked about.",
    "start": "4023700",
    "end": "4028770"
  },
  {
    "text": "And there might be\ndomains where you don't have\naugmentations available, and there are a couple\nsolutions for that. But it's something that is\nstill an open area of research.",
    "start": "4028770",
    "end": "4037119"
  },
  {
    "text": "Yeah. So if you don't need\nthe modelling part, is contrasted learning sort\nof a good pre-training regime",
    "start": "4037120",
    "end": "4044260"
  },
  {
    "text": "for generative modelling? The question is, is\ncontrastive learning a good pre-training scheme\nfor generative modeling?",
    "start": "4044260",
    "end": "4053350"
  },
  {
    "text": "I guess I often view generative\nmodeling as something that you do with data that's unlabeled. And so if you're--",
    "start": "4053350",
    "end": "4060807"
  },
  {
    "text": "one of the nice things\nabout unsupervised training is you can get a lot of\njuice out of unlabeled data. And so if your task\nis already something",
    "start": "4060807",
    "end": "4067090"
  },
  {
    "text": "that can be done with unlabeled\ndata, like generative modeling, then it may be that you don't\nneed a good pre-training method",
    "start": "4067090",
    "end": "4075250"
  },
  {
    "text": "because, maybe, you already have\na lot of data that you can use. ",
    "start": "4075250",
    "end": "4081050"
  },
  {
    "text": "I guess more specifically,\nI don't know of any works that pre-trained with\ncontrastive learning and then fine tune on a\ngenerative modeling task.",
    "start": "4081050",
    "end": "4088032"
  },
  {
    "text": "But it's possible that there\nare some works out there.",
    "start": "4088032",
    "end": "4093670"
  },
  {
    "text": "Yeah. Can this be combined with what\nfine tuning if, for example,",
    "start": "4093670",
    "end": "4099290"
  },
  {
    "text": "you have a multi label problem. So different examples can either\nbe in the same class or not",
    "start": "4099290",
    "end": "4105459"
  },
  {
    "text": "depending on the label\nthat you're interested in. Can this be combined\nwith fine tuning? ",
    "start": "4105459",
    "end": "4115017"
  },
  {
    "text": "So we talked about\nlearning representations. And then you do often fine\ntune the representation. You often put it like\nsome sort of classifier",
    "start": "4115017",
    "end": "4120810"
  },
  {
    "text": "on top of the representation. And then you can\nfine tune end-to-end. Are you thinking about\nsomething other than that?",
    "start": "4120810",
    "end": "4127560"
  },
  {
    "text": "I guess I'm thinking\nabout the way that you would\ngenerate the embedding. And whether you want to\nchange that, you know.",
    "start": "4127560",
    "end": "4136318"
  },
  {
    "text": "Yeah. So you could also\nimagine fine tuning with the contrastive loss.",
    "start": "4136319",
    "end": "4141599"
  },
  {
    "text": "Similar to how things\nlike prototypical networks are doing classification\nwith this kind of--",
    "start": "4141600",
    "end": "4148799"
  },
  {
    "text": "looks very similar to\na classification loss. And so you could fine tune\nwith something like that.",
    "start": "4148800",
    "end": "4154568"
  },
  {
    "text": "Yeah. So you could certainly\ndo something like that. Definitely the default that I've\nseen the vast majority of work",
    "start": "4154569",
    "end": "4160649"
  },
  {
    "text": "do is to either freeze\nthe representation and put something\non top of that. Or additionally fine\ntune end-to-end.",
    "start": "4160649",
    "end": "4166356"
  },
  {
    "text": "But I could certainly\nimagine that you could fine tune with the\ncontrastive loss as well. And if you can fit\nyour loss function",
    "start": "4166356",
    "end": "4171658"
  },
  {
    "text": "in the form of something\nlike a contrastive loss, you may actually do better\nthan that other approach. ",
    "start": "4171658",
    "end": "4180390"
  },
  {
    "text": "Cool. Then the last thing I'd like\nto talk about in the last 7 minutes is how this\nrelates to some of the meta-learning\nalgorithms that we",
    "start": "4180390",
    "end": "4187120"
  },
  {
    "text": "have talked about in class.  And as you might have guessed,\nsome of these equations",
    "start": "4187120",
    "end": "4196389"
  },
  {
    "text": "look a lot like the\nequations that we saw in the non-parametric\nfew-shot learning lecture.",
    "start": "4196390",
    "end": "4202210"
  },
  {
    "text": "And you can, in many ways,\nformulate an algorithm, a meta-learning\napproach, that looks",
    "start": "4202210",
    "end": "4208570"
  },
  {
    "text": "a lot like the\ncontrast of approaches we've talked about today. And so if you're given\nan unlabeled data set,",
    "start": "4208570",
    "end": "4215665"
  },
  {
    "text": "say you're doing something\nlike SimCLR, where you generate positives and\nnegatives by augmenting, then you can basically\ncreate a labeled data set",
    "start": "4215665",
    "end": "4224770"
  },
  {
    "text": "where you create an image class\nby augmenting your example.",
    "start": "4224770",
    "end": "4230140"
  },
  {
    "text": "And you create multiple\nexamples from that class by augmenting it multiple times.",
    "start": "4230140",
    "end": "4236560"
  },
  {
    "text": "That will give you a data\nset for that image class. And then to create a\ntask, what you'll do",
    "start": "4236560",
    "end": "4242218"
  },
  {
    "text": "is you'll want to\nbe able to classify between different image classes. Now once you have this\nlabelled data set,",
    "start": "4242218",
    "end": "4252365"
  },
  {
    "text": "you can create tasks that\nactually just run your favorite meta-learning\nalgorithm on this data.",
    "start": "4252365",
    "end": "4257590"
  },
  {
    "text": " And it turns out\nthat there's actually a very kind of close\nmathematical relationship",
    "start": "4257590",
    "end": "4265060"
  },
  {
    "text": "between doing\nsomething like this with an algorithm like\nprototypical networks, and the SimCLR algorithm that\nwe talked about in lecture.",
    "start": "4265060",
    "end": "4274750"
  },
  {
    "text": "This paper in the bottom\nright goes in depth on that. But there are really\ntwo key differences.",
    "start": "4274750",
    "end": "4280480"
  },
  {
    "text": "And they're relatively small\ndifferences in my mind. The first is that SimCLR sample\nis only one classification",
    "start": "4280480",
    "end": "4286270"
  },
  {
    "text": "task per mini batch, and\nusually meta learning algorithms will sample a mini\nbatch of tasks.",
    "start": "4286270",
    "end": "4292330"
  },
  {
    "text": "And the second difference\nis that SimCLR is really a look at all pairs\nof negative examples,",
    "start": "4292330",
    "end": "4298929"
  },
  {
    "text": "or all pairs of\nexamples in your batch.",
    "start": "4298930",
    "end": "4304120"
  },
  {
    "text": "Whereas meta-learning only\ncompares the query examples to the support examples. And never compares\nand contrasts,",
    "start": "4304120",
    "end": "4310929"
  },
  {
    "text": "query examples with\nother query examples. So in this way,\nyou could perhaps view the SimCLR class\nas being a little bit--",
    "start": "4310930",
    "end": "4316480"
  },
  {
    "text": "the SimCLR loss as\nbeing a little bit more efficient with its\nbatch because it's going to compare and contrast\neverything in the batch.",
    "start": "4316480",
    "end": "4322960"
  },
  {
    "text": "But otherwise, these algorithms\nend up being extremely similar. ",
    "start": "4322960",
    "end": "4329060"
  },
  {
    "text": "And they also end up\ndoing something extremely similar in practice as well. So if you-- here's just one\nexperiment in that paper.",
    "start": "4329060",
    "end": "4337190"
  },
  {
    "text": "You take an unlabeled data set. I think they took the\nImageNet unlabeled data set.",
    "start": "4337190",
    "end": "4342560"
  },
  {
    "text": "They augmented with the\nSimCLR augmentations,",
    "start": "4342560",
    "end": "4348440"
  },
  {
    "text": "and compared using\nSimCLR versus using this approach with prototypical\nnetworks and R2-D2.",
    "start": "4348440",
    "end": "4354620"
  },
  {
    "text": "Where R2-D2 is an\noptimization-based meta-learner that has a number of kind\nof bells and whistles to it.",
    "start": "4354620",
    "end": "4362030"
  },
  {
    "text": "And you see that\nwhen you then kind of pre-train these\nrepresentations on ImageNet, and then fine tune them on\nthese other image classification",
    "start": "4362030",
    "end": "4369410"
  },
  {
    "text": "problems, you see extremely\nsimilar performance between SimCLR and\nprototypical networks. You also see very\nsimilar performance",
    "start": "4369410",
    "end": "4375662"
  },
  {
    "text": "between SimCLR and R2-D2. And in some cases, R2-D2 is\nable to do a little bit better",
    "start": "4375662",
    "end": "4381320"
  },
  {
    "text": "as well. Yeah. So far meta-learning method\nyou see is mostly few-shot.",
    "start": "4381320",
    "end": "4390409"
  },
  {
    "text": "But this problem is a zero-shot\nproblem, how does that- Yeah, so this is actually\nnot a zero-shot problem.",
    "start": "4390410",
    "end": "4396510"
  },
  {
    "text": "So it's pre-training\nrepresentations with this approach, and then fine tuning\non the entire data set from--",
    "start": "4396510",
    "end": "4405197"
  },
  {
    "text": "the entire training data\nset from these data sets. And so the other\ndifference that I sort of didn't mention on this slide\nis-- on the previous slide--",
    "start": "4405197",
    "end": "4411980"
  },
  {
    "text": "is that meta-training and the\ntraining time is very similar. But what happens at\ntest time is actually a little bit different.",
    "start": "4411980",
    "end": "4417630"
  },
  {
    "text": "So typically in\nfew-shot learning, we'll give it a few\nexamples, embed them,",
    "start": "4417630",
    "end": "4423770"
  },
  {
    "text": "and make a classification. And actually, in this case, at\ntest time what they're doing is they're learning\nthe representation",
    "start": "4423770",
    "end": "4429440"
  },
  {
    "text": "with meta-learning. And then they're just fine\ntuning the whole network. And that's a little bit\ndifferent from what we've been doing in the previous lectures.",
    "start": "4429440",
    "end": "4437153"
  },
  {
    "text": "Yeah, so they're really just\ncomparing the representations that were learned. Rather than the specific\nfew-shot learning approach",
    "start": "4437153",
    "end": "4442235"
  },
  {
    "text": "that happens at test time. Yeah. If I imagine the path sampling,\nI think the meta-learning one,",
    "start": "4442235",
    "end": "4448870"
  },
  {
    "text": "they would have probably more\nsamples instead of one sample. [INAUDIBLE] smaller number\nof samples per anchor.",
    "start": "4448870",
    "end": "4455690"
  },
  {
    "text": "So how does the optimization\ncompare in terms of [INAUDIBLE]? Yeah, so the question\nwas how do we--",
    "start": "4455690",
    "end": "4464380"
  },
  {
    "text": "in meta-learning like n and\nk, you choose n an k, usually, you choose an n\nthat's maybe smaller",
    "start": "4464380",
    "end": "4470290"
  },
  {
    "text": "than 256, at least that's\ncertainly what a lot of papers have done.",
    "start": "4470290",
    "end": "4476350"
  },
  {
    "text": "I can't remember exactly\nwhat they did in this paper. Happy to follow up on it. or you\ncould take a look at the paper.",
    "start": "4476350",
    "end": "4482290"
  },
  {
    "text": "And I'm guessing that they\nprobably used something similar to 256 and so maybe the values\nof those hyperparameters do actually affect performance.",
    "start": "4482290",
    "end": "4489580"
  },
  {
    "text": "Yeah. So [INAUDIBLE] they do\naugmentation, right?",
    "start": "4489580",
    "end": "4495190"
  },
  {
    "text": "So if you assume that each class\nhas you augment that same four or five samples for\neach class, it's",
    "start": "4495190",
    "end": "4502525"
  },
  {
    "text": "like four or five shot training\nfor that class, in a way. So I wanted to ask\nthis mixing these two,",
    "start": "4502525",
    "end": "4510310"
  },
  {
    "text": "so like when you're\nsupervised a few-shot model, can we include\ncontrast to rhythm",
    "start": "4510310",
    "end": "4516460"
  },
  {
    "text": "into training model\napproaches [INAUDIBLE]?? Yeah, so I guess,\nfirst, I do think",
    "start": "4516460",
    "end": "4522397"
  },
  {
    "text": "that it's very similar\nto one-shot learning, because there's one\npositive [AUDIO OUT] anchor. And generally,\none-shot learning is",
    "start": "4522397",
    "end": "4527980"
  },
  {
    "text": "harder than five-shot learning. And so I would suspect that\nyou get better representations from one-shot learning\nthan five-shot learning.",
    "start": "4527980",
    "end": "4534910"
  },
  {
    "text": "The other question is, can\nyou use contrastive learning-- [INAUDIBLE] do the training,\nbut we don't specifically",
    "start": "4534910",
    "end": "4541870"
  },
  {
    "text": "do anything with support\nsamples or query samples. Like, we just compare\nthe stuff [INAUDIBLE]..",
    "start": "4541870",
    "end": "4547120"
  },
  {
    "text": "But we don't do anything in\ntrial, in the support space or query space.",
    "start": "4547120",
    "end": "4552730"
  },
  {
    "text": "Just doing an\nunsupervised learner in introducing\ncontextual learning there",
    "start": "4552730",
    "end": "4558190"
  },
  {
    "text": "that would help in\nthe performance. Yeah, so prototypical\nnet works, it does this sort of like\naggregation in the case where",
    "start": "4558190",
    "end": "4564310"
  },
  {
    "text": "you have more than one shot. And the question is, if\nyou do something like that and additionally include\nelements of this--",
    "start": "4564310",
    "end": "4572337"
  },
  {
    "text": "which I think would sort\nof be similar to training like both one-shot and\nfive-shot in a way. Because one-shot is\nvery similar to this.",
    "start": "4572337",
    "end": "4579340"
  },
  {
    "text": "Does that help? And I could see that\nimproving performance. And I think that the\n\"Prototypical Networks\" paper showed that, actually, sometimes\none-shot training can actually",
    "start": "4579340",
    "end": "4586735"
  },
  {
    "text": "be better than\nfive-shot training when you test on\nfive-shot, because you're training on something harder. ",
    "start": "4586735",
    "end": "4595820"
  },
  {
    "text": "You never actually\nget the information out of the support templates. Like, we don't train\nthem in between, like in an unsupervised manner,\nand we also don't do anything",
    "start": "4595820",
    "end": "4603230"
  },
  {
    "text": "with the query samples. Yeah. So if we could use\nthat [INAUDIBLE] information [INAUDIBLE].",
    "start": "4603230",
    "end": "4608610"
  },
  {
    "text": "Right. Right. Yeah. So you could also use these\naugmentations in addition to the labels that we have in\nthe meta-training data set.",
    "start": "4608610",
    "end": "4616610"
  },
  {
    "text": "And that would be kind of\nlike a semi-supervised model learning thing as well. And we'll probably talk\nabout that a little bit",
    "start": "4616610",
    "end": "4622639"
  },
  {
    "text": "on Monday next week.  Cool.",
    "start": "4622640",
    "end": "4628530"
  },
  {
    "text": "So to wrap up. We talked about\ncontrastive learning. On Wednesday this\nweek, we're going to be talking about another form\nof unsupervised pre-training",
    "start": "4628530",
    "end": "4636000"
  },
  {
    "text": "which are\nreconstruction-based methods. Yeah, so that's the rest\nof contrastive learning.",
    "start": "4636000",
    "end": "4642030"
  },
  {
    "text": "As a couple of reminders,\nyour project proposal is due on Wednesday. And the homework\nis due next Monday.",
    "start": "4642030",
    "end": "4647960"
  },
  {
    "start": "4647960",
    "end": "4652000"
  }
]
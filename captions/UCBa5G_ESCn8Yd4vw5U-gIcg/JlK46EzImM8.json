[
  {
    "start": "0",
    "end": "5160"
  },
  {
    "text": "So this is lecture\n15, and today we'll be talking about\ncode generation.",
    "start": "5160",
    "end": "10960"
  },
  {
    "text": "So a little bit\nunusual since we'll be generating unnatural\nlanguages this time,",
    "start": "10960",
    "end": "17070"
  },
  {
    "text": "but it will connect\nin a number of ways to natural language generation. So before we start, just\na few announcements.",
    "start": "17070",
    "end": "23820"
  },
  {
    "text": "The project milestone\nis due this Thursday. You are certainly\nall aware of that.",
    "start": "23820",
    "end": "30689"
  },
  {
    "text": "And also, when\ndoing the projects, it's always good to keep\ntrack of how much you're",
    "start": "30690",
    "end": "37110"
  },
  {
    "text": "spending on Azure and AWS. And one thing to notice\nis that disk costs money.",
    "start": "37110",
    "end": "42840"
  },
  {
    "text": "It doesn't cost that\nmuch compared to GPUs, but it still costs something.",
    "start": "42840",
    "end": "47879"
  },
  {
    "text": "Be sure to not be spending\nall your money on disk.",
    "start": "47880",
    "end": "54030"
  },
  {
    "text": "So tomorrow, John will\nbe running a discussion on training large\nlanguage models.",
    "start": "54030",
    "end": "59430"
  },
  {
    "text": "It'll be really cool. So it'll be at 3:30 in\nthe Skilling Auditorium.",
    "start": "59430",
    "end": "64559"
  },
  {
    "text": "There's more details on that. And this Thursday, we have\nour first invited talk",
    "start": "64560",
    "end": "70630"
  },
  {
    "text": "in our regular lecture time,\nand attendance is expected. So please everyone show up.",
    "start": "70630",
    "end": "76850"
  },
  {
    "text": "It'll be really cool.  All right.",
    "start": "76850",
    "end": "82179"
  },
  {
    "text": "So let's get started. So when we're talking\nabout a problem",
    "start": "82180",
    "end": "88060"
  },
  {
    "text": "that, in the literature, is\ncalled program synthesis. And let's see what that means.",
    "start": "88060",
    "end": "94070"
  },
  {
    "text": "So program synthesis is\nactually a pretty old challenge of artificial\nintelligence, and the goal",
    "start": "94070",
    "end": "101260"
  },
  {
    "text": "is to create programs that can\ntake some sort of specification and write a program that\nsatisfies that specification.",
    "start": "101260",
    "end": "107329"
  },
  {
    "text": "So it's a program\nthat writes a program. So that's what a program\nsynthesizer is, right?",
    "start": "107330",
    "end": "112480"
  },
  {
    "text": "It's a program that\ntakes your specification, and is able to\ngenerate some program.",
    "start": "112480",
    "end": "118990"
  },
  {
    "text": "And then you can ask, \"what\nkind of specification\"? So one possible\nspecification, for example,",
    "start": "118990",
    "end": "125515"
  },
  {
    "text": "could be a logical formula. It could be like a\nmathematical formula that specifies what behavior\nwe want from the program.",
    "start": "125515",
    "end": "132440"
  },
  {
    "text": "It could be an\nequivalence program. So I could say, OK, here\nis a slow implementation of a sorting algorithm--\nbubble sort for example--",
    "start": "132440",
    "end": "139810"
  },
  {
    "text": "and it runs in o\nof n squared, and I want to synthesize another\nprogram that's equivalent, so it generates all the same\noutputs given the same inputs,",
    "start": "139810",
    "end": "147670"
  },
  {
    "text": "but it's maybe faster. So that could be a\nform of specification. I could give examples, right?",
    "start": "147670",
    "end": "153555"
  },
  {
    "text": "I could say, OK,\nI want a program that if I give it this input,\nit should generate this output,",
    "start": "153555",
    "end": "158620"
  },
  {
    "text": "if I give this string, it\nshould give me back this string. Or, as more popular\nthese days, we",
    "start": "158620",
    "end": "166030"
  },
  {
    "text": "could also maybe in\naddition to or instead of these other kinds\nof specifications, also",
    "start": "166030",
    "end": "171730"
  },
  {
    "text": "give a natural language\ndescription, right? I could just write,\nI want a program that performs a certain operation.",
    "start": "171730",
    "end": "178780"
  },
  {
    "text": " So just to warm\nup, let's see how",
    "start": "178780",
    "end": "184420"
  },
  {
    "text": "this synthesis from logical\nspecifications could look like. So when would it make sense\nto use the program synthesizer",
    "start": "184420",
    "end": "192670"
  },
  {
    "text": "at all? So it would only make\nsense to use a program to write a program\nfor us if that's",
    "start": "192670",
    "end": "199060"
  },
  {
    "text": "in some way easier than writing\nthe program ourselves, right? It should be easier\nto specify what",
    "start": "199060",
    "end": "206050"
  },
  {
    "text": "the program does compared to\nexactly how it should do that.",
    "start": "206050",
    "end": "211690"
  },
  {
    "text": "And this is different than\nnatural language generation in an important way\nin that we usually",
    "start": "211690",
    "end": "217120"
  },
  {
    "text": "have ways to test our\noutput automatically, right? So if I give the\nsynthesizer, OK,",
    "start": "217120",
    "end": "222790"
  },
  {
    "text": "I want a program that\ngiven these inputs, generates these outputs,\nand the synthesizer gives me back a program.",
    "start": "222790",
    "end": "227890"
  },
  {
    "text": "I can go there and execute\nthe program on the inputs that I gave and verify that it\ngenerates the correct outputs.",
    "start": "227890",
    "end": "235520"
  },
  {
    "text": "And this is different than\na natural language task. For example, if I\nask it to summarize",
    "start": "235520",
    "end": "242920"
  },
  {
    "text": "an article or a paragraph and\nit gives me back a response, and I can evaluate\nit in some ways.",
    "start": "242920",
    "end": "247960"
  },
  {
    "text": "I can compare it to\nhuman reference summaries or I can use a language\nmodel to evaluate",
    "start": "247960",
    "end": "255718"
  },
  {
    "text": "the output of another\nlanguage model, but I can't execute\nthe summary and verify that it's a good summary.",
    "start": "255718",
    "end": "262900"
  },
  {
    "text": "So-- Yes. How can you make certain that\nthe output is always correct",
    "start": "262900",
    "end": "269280"
  },
  {
    "text": "considering like-- I mean without\nformal verification, how can you just make sure that\nthe output program is correct,",
    "start": "269280",
    "end": "277320"
  },
  {
    "text": "since you'll be pushing to the\nBIOS on the test cases on the-- Yeah. That's a good question. So the question was,\nhow can we make sure",
    "start": "277320",
    "end": "283478"
  },
  {
    "text": "that the output is\ncorrect in general? Well, it depends on what\nspecification we have, right?",
    "start": "283478",
    "end": "288780"
  },
  {
    "text": "If the specification is\ninput/output examples, all we can do is verify that\nit satisfies those examples. We'll talk about the problem\nof that in a little bit.",
    "start": "288780",
    "end": "295800"
  },
  {
    "text": " Any other questions\nabout this set up?",
    "start": "295800",
    "end": "301020"
  },
  {
    "text": "I'll give you an example,\nso it will be very concrete starting now.",
    "start": "301020",
    "end": "306070"
  },
  {
    "text": "OK. So let's see how\nthis could work. Let's try to specify a\nprogram using this sort",
    "start": "306070",
    "end": "312210"
  },
  {
    "text": "of logical specification. So our first attempt\nwill be to specify",
    "start": "312210",
    "end": "317640"
  },
  {
    "text": "how do I sort an array, right? I want a program that\nreceives an array as input and returns a sorted array.",
    "start": "317640",
    "end": "324400"
  },
  {
    "text": "So how would I write\nthat mathematically? Our first attempt\ncould be, well, let's say that this\nprogram takes an array A",
    "start": "324400",
    "end": "331140"
  },
  {
    "text": "and outputs an array\nB. I can specify that I want the array B to be sorted.",
    "start": "331140",
    "end": "337720"
  },
  {
    "text": "So, mathematically,\nI could write that as for all of the\nindices i of the output, I want the element at that index\nto be at most the next element,",
    "start": "337720",
    "end": "347950"
  },
  {
    "text": "right? So sorted in increasing order. So I can look at this\nstatement and say, oh yes,",
    "start": "347950",
    "end": "354629"
  },
  {
    "text": "if the output satisfies that,\nthen it's a sorted array.",
    "start": "354630",
    "end": "360120"
  },
  {
    "text": "Does this look good? ",
    "start": "360120",
    "end": "365270"
  },
  {
    "text": "Maybe, right? So I can give that\nspecification to a synthesizer, and then it will go and search\nfor programs that satisfy this,",
    "start": "365270",
    "end": "372620"
  },
  {
    "text": "and then it returns this\nprogram, which is called sort, takes an array A and\nreturns the array 1, 2.",
    "start": "372620",
    "end": "380150"
  },
  {
    "text": "So if you look at the\nmathematical formula, it'd say, well, for all of\nthe indices of the output,",
    "start": "380150",
    "end": "385430"
  },
  {
    "text": "that element is smaller than\nor equal to the next element. So it satisfies the\nspecification that we gave,",
    "start": "385430",
    "end": "391110"
  },
  {
    "text": "but of course not the\nprogram we wanted. ",
    "start": "391110",
    "end": "397020"
  },
  {
    "text": "OK. So maybe we missed something. We missed that the output\nnot only should be sorted,",
    "start": "397020",
    "end": "403490"
  },
  {
    "text": "but also should have the\nsame elements as the input. So I can specify that\nas I want the array",
    "start": "403490",
    "end": "410389"
  },
  {
    "text": "B have the same\nlength as array A and has to be a permutation\nfor each element of the output. It has to be somewhere\nthere in the input.",
    "start": "410390",
    "end": "418669"
  },
  {
    "text": "And then writing\na little bit more formally in first order logic\nit would look like that.",
    "start": "418670",
    "end": "425039"
  },
  {
    "text": "Don't have to try to parse it. And then, if I give that\nto the synthesizer, maybe it will go and search\nfor some programs",
    "start": "425040",
    "end": "431610"
  },
  {
    "text": "and return like QuickSort\nor some function that actually sorts the array.",
    "start": "431610",
    "end": "439090"
  },
  {
    "text": "So note that the problem\nhere is quite non-trivial because the formula, as ugly\nas it is, it doesn't tell us",
    "start": "439090",
    "end": "446610"
  },
  {
    "text": "how to sort the array. It just says that the array\nshould be sorted in some way. So it's not just a syntactical\ntranslation between the formula",
    "start": "446610",
    "end": "456420"
  },
  {
    "text": "that we gave and the programming\nlanguage that we're targeting.",
    "start": "456420",
    "end": "462210"
  },
  {
    "text": "But the thing\nthat's obvious here is that these logical\nspecifications are quite hard to read, they're\nquite hard to write, of course,",
    "start": "462210",
    "end": "469110"
  },
  {
    "text": "and also to check, right? If I just gave you\nthe formula that says an array's sorted,\nmaybe at first.",
    "start": "469110",
    "end": "475510"
  },
  {
    "text": "It's not easy to see the corner\ncase that just being sorted is not enough. And I mean if I tell you that\nwe are making a synthesizer that",
    "start": "475510",
    "end": "486760"
  },
  {
    "text": "takes this formula and\nreturns like a function that sorts an array, you could\nreasonably say that maybe it's",
    "start": "486760",
    "end": "492550"
  },
  {
    "text": "just easier to write\nthe function yourself, but it is quite a challenge\nto do so even then.",
    "start": "492550",
    "end": "501820"
  },
  {
    "text": "Any questions about\nthe setup here? ",
    "start": "501820",
    "end": "508130"
  },
  {
    "text": "OK. So maybe logical formulas\nare too much, right? We don't want to be specifying\neven simple programs",
    "start": "508130",
    "end": "516650"
  },
  {
    "text": "like sorting with those\nugly first order formulas. We could try something simpler. We could try examples.",
    "start": "516650",
    "end": "523219"
  },
  {
    "text": "So input output examples\nis a very natural kind of specification. And in fact, when\nwriting programs,",
    "start": "523220",
    "end": "529399"
  },
  {
    "text": "software engineers\nusually already write tests, which are kind of like\ninput output examples, right?",
    "start": "529400",
    "end": "534680"
  },
  {
    "text": "Like if I call the\nfunction with this input, it should return this. I assert that it does that.",
    "start": "534680",
    "end": "540260"
  },
  {
    "text": "So how could I specify\nsorting in that case? I could say, well, if I\ngive the array 3, 2, 1, 0,",
    "start": "540260",
    "end": "547459"
  },
  {
    "text": "it should return 0, 1, 2, 3. For 1, 4, 2, it\nshould return 1, 2, 4.",
    "start": "547460",
    "end": "552740"
  },
  {
    "text": "And for 9, it should return 9. Right? Any human looking at\nthese inputs and outputs",
    "start": "552740",
    "end": "558860"
  },
  {
    "text": "could reasonably guess,\nthat oh, it's just sorting the input array, right?",
    "start": "558860",
    "end": "565910"
  },
  {
    "text": "But as we just saw with\nthe logical synthesizer, we could also get a program\nthat looks like this.",
    "start": "565910",
    "end": "574040"
  },
  {
    "text": "Well, if the array has exactly\nfour elements returned, 0, 1, 2, 3, and if it has\n3 returns this exact array",
    "start": "574040",
    "end": "581440"
  },
  {
    "text": "and otherwise always\nreturn 9, right? It satisfies the\ninput output examples, but somehow it's still\nnot what we want.",
    "start": "581440",
    "end": "588235"
  },
  {
    "text": " Of course this is a kind\nof an adversarial output,",
    "start": "588235",
    "end": "596230"
  },
  {
    "text": "and synthesis by example\nwas actually massively used",
    "start": "596230",
    "end": "601360"
  },
  {
    "text": "in the last decade\nbecause of this feature in Excel called \"FlashFill,\"\nwhich was released in 2013,",
    "start": "601360",
    "end": "609940"
  },
  {
    "text": "and it was for a while\none of the hottest things to have happened\nto Microsoft Excel.",
    "start": "609940",
    "end": "615730"
  },
  {
    "text": "So FlashFill is this\nreally cool feature where the goal is for\nExcel to guess what string",
    "start": "615730",
    "end": "622240"
  },
  {
    "text": "transformation you're applying. So you can write-- for example, if\nyou have a column that has people's\nfirst and last names,",
    "start": "622240",
    "end": "629920"
  },
  {
    "text": "and you want to just get\nthe first name, for example, of everyone. And you create a\nsecond column and you",
    "start": "629920",
    "end": "635529"
  },
  {
    "text": "type, like in this\nexample, Ned, then Excel, if you click on\nthe FlashFill button,",
    "start": "635530",
    "end": "643093"
  },
  {
    "text": "it will magically guess\nthat what you're doing is you're splitting on\nthe space and maybe taking the first of those strings\nand suggest you complete",
    "start": "643093",
    "end": "650230"
  },
  {
    "text": "that as the second column. And it can actually do quite\ncomplex transformations and usually from one or two\nexamples, and it's quite cool.",
    "start": "650230",
    "end": "658149"
  },
  {
    "text": " But as is clear at this\npoint, synthesis from examples",
    "start": "658150",
    "end": "667490"
  },
  {
    "text": "has this inherent problem\nof ambiguity, right? For any set of examples--\ninput/output examples--",
    "start": "667490",
    "end": "673640"
  },
  {
    "text": "that I give, there\nwill be usually an infinite number\nof programs that have exactly that behavior\non those examples, right?",
    "start": "673640",
    "end": "682730"
  },
  {
    "text": "But somehow that's\nvery non-human because humans for\nsome reason have",
    "start": "682730",
    "end": "689510"
  },
  {
    "text": "a very specific preference\nover this infinite space of programs.",
    "start": "689510",
    "end": "694820"
  },
  {
    "text": "Like if I look at this\nprogram that does this, even if I don't tell\nyou what kind of program",
    "start": "694820",
    "end": "702440"
  },
  {
    "text": "was I looking at\nin the first place, it's very obvious that this\nprogram probably not useful for anything.",
    "start": "702440",
    "end": "708710"
  },
  {
    "text": "But it's obvious for you, not\nto a synthesizer, necessarily, that's trying to find a program.",
    "start": "708710",
    "end": "716250"
  },
  {
    "text": "So, for example, what\nprogram I'm specifying here with these two examples? Jan transforms to January and\nFeb transforms to February.",
    "start": "716250",
    "end": "726960"
  },
  {
    "text": "Any human guesses about\nwhat this should do? It takes a short\nname for a month",
    "start": "726960",
    "end": "734019"
  },
  {
    "text": "and expands it to [INAUDIBLE]. Yeah. Exactly. It should obviously do\nthat, but for a while--",
    "start": "734020",
    "end": "739949"
  },
  {
    "text": "I think maybe not-- I'm not sure if this\nfix was released or is going to be\nreleased, but for a while,",
    "start": "739950",
    "end": "745983"
  },
  {
    "text": "this is what FlashFill would do. It would complete\nFeb with February, March with Maruary, April,\nApruary, and so on, right?",
    "start": "745983",
    "end": "755580"
  },
  {
    "text": "So it guessed from\none example what you're doing is just\nconcatenating \"uary\" on the string that you had.",
    "start": "755580",
    "end": "761370"
  },
  {
    "text": "So clearly extrapolates from\nany other possible string that you might want.",
    "start": "761370",
    "end": "767230"
  },
  {
    "text": "So how do we do we deal\nwith this ambiguity?",
    "start": "767230",
    "end": "774011"
  },
  {
    "text": "We'll talk a little\nbit about that. But just to summarize\nwhat we've seen so far, a synthesizer is\nthis program that",
    "start": "774012",
    "end": "780180"
  },
  {
    "text": "takes some form of specification\nof what a program should do, and then generates a program.",
    "start": "780180",
    "end": "785620"
  },
  {
    "text": "And if we get this to\nwork, this would actually have massive impact\nin a number of ways.",
    "start": "785620",
    "end": "791170"
  },
  {
    "text": "It can lower the barrier\nto access programming to a lot of people that\nmaybe don't want to spend",
    "start": "791170",
    "end": "798509"
  },
  {
    "text": "four years taking CS classes. So for example, people can\nautomate a lot of things",
    "start": "798510",
    "end": "804250"
  },
  {
    "text": "just by using FlashFill\nin Excel things-- things that would take a lot more time. And even programmers\nourselves can",
    "start": "804250",
    "end": "811608"
  },
  {
    "text": "benefit from much\nhigher productivity if we can program at\nhigher level ways. So this is quite an\ninteresting goal,",
    "start": "811608",
    "end": "818903"
  },
  {
    "text": "but it, of course, has\nmany challenges, right? It has this infinite\nspace of programs. A lot of them are unreasonable\nin this human way.",
    "start": "818903",
    "end": "826980"
  },
  {
    "text": "And here we're talking about-- at least for now,\nright-- searching in the space of programs in a\nvery specific language where",
    "start": "826980",
    "end": "833760"
  },
  {
    "text": "we can do search, but it's of\ncourse impractical to do search in any real-word\nlanguage like Python,",
    "start": "833760",
    "end": "840450"
  },
  {
    "text": "and we have this\nambiguity problem, right? Like how do you capture\nhuman preferences? ",
    "start": "840450",
    "end": "847980"
  },
  {
    "text": "So we'll talk here about the\nconnection between this problem of ambiguity in\nprogram synthesis",
    "start": "847980",
    "end": "853270"
  },
  {
    "text": "and ambiguity in\nnatural language, which is extremely common.",
    "start": "853270",
    "end": "858850"
  },
  {
    "text": "So human languages are\nextremely ambiguous, and if you stop to look\nat it more closely,",
    "start": "858850",
    "end": "864520"
  },
  {
    "text": "it's actually quite\nsurprising that we manage to communicate\nso well and so easily",
    "start": "864520",
    "end": "869790"
  },
  {
    "text": "even though if\nyou look up almost any word in the\ndictionary, it will have a large number of\nmeanings that it might have.",
    "start": "869790",
    "end": "876900"
  },
  {
    "text": "Even sentences out of\ncontext can usually have multiple interpretations,\nbut we somehow",
    "start": "876900",
    "end": "882540"
  },
  {
    "text": "do just fine talking in English,\nin this very ambiguous medium. And in fact, ambiguity is not\neven a bug of human languages.",
    "start": "882540",
    "end": "893279"
  },
  {
    "text": "It's a feature, and it's\na feature for efficiency. So, actually, there's\nthis paper here",
    "start": "893280",
    "end": "898779"
  },
  {
    "text": "that's pretty cool that\nprovides true arguments based on information theory that any\ncommunication channel where,",
    "start": "898780",
    "end": "906899"
  },
  {
    "text": "basically, the meaning of\nwords can be disambiguated in context, we'll make\nthose words at some point",
    "start": "906900",
    "end": "913020"
  },
  {
    "text": "collide to make them both short. So, for example, if I\nhave \"bear\" the animal",
    "start": "913020",
    "end": "919269"
  },
  {
    "text": "and \"bear\" the\nverb, they usually appear in very different\ncontexts, right? So it would actually be very\ninefficient to create a word",
    "start": "919270",
    "end": "926769"
  },
  {
    "text": "to separate those\nbecause, at some point, I would be adding both more and\nlonger words in my vocabulary,",
    "start": "926770",
    "end": "933889"
  },
  {
    "text": "right? So if they can be\ndisambiguated to be optimal from a\ncommunication perspective,",
    "start": "933890",
    "end": "940449"
  },
  {
    "text": "I'll actually get\nambiguity at some point. And there's one very\ninteresting challenge",
    "start": "940450",
    "end": "948310"
  },
  {
    "text": "for computers to resolve\nthis kind of ambiguity called the Winograd Schema Challenge.",
    "start": "948310",
    "end": "954129"
  },
  {
    "text": "And if you read the\nexamples, they're quite entertaining\nbecause you read them and it's very\nobvious what's going on, but it's also obvious\nwhat's the challenge.",
    "start": "954130",
    "end": "962230"
  },
  {
    "text": "So here we have\nthese two sentences. \"The city councilmen\nrefused the demonstrators a permit because they\nfeared violence.\"",
    "start": "962230",
    "end": "968800"
  },
  {
    "text": "And the obvious\nambiguity here is that \"they\" could refer\nto the city councilmen or the demonstrators, right?",
    "start": "968800",
    "end": "975190"
  },
  {
    "text": "But when you hear\n\"they feared violence,\" what's the obvious candidate\nhere for what \"they\" refers to?",
    "start": "975190",
    "end": "982580"
  },
  {
    "text": "Yeah. Exactly. And when you say \"they\nadvocated violence,\" then you suddenly process the\nsentence in a different way.",
    "start": "982580",
    "end": "990010"
  },
  {
    "text": "And syntactically, the\nsentences are exactly the same, but just because of\nyour prior knowledge",
    "start": "990010",
    "end": "995170"
  },
  {
    "text": "about how these actors\nbehave in the world. You use that to disambiguate\nthe your different meanings.",
    "start": "995170",
    "end": "1002325"
  },
  {
    "text": " Yeah. So this is very easy\nfor us, handling",
    "start": "1002325",
    "end": "1008930"
  },
  {
    "text": "this kind of ambiguity. How do we do it? It's an interesting question. How do humans do this?",
    "start": "1008930",
    "end": "1015850"
  },
  {
    "text": "And the linguistic term\nfor the kind of reasoning",
    "start": "1015850",
    "end": "1021310"
  },
  {
    "text": "that we do in this setting is\ncalled \"pragmatic reasoning.\" So in linguistics, we\nhave this distinction",
    "start": "1021310",
    "end": "1026709"
  },
  {
    "text": "between semantics and\npragmatics of how do we attribute meaning to things. Like semantics talks about\nthe intrinsic meaning",
    "start": "1026710",
    "end": "1034209"
  },
  {
    "text": "of words in a certain sense. And pragmatics, how does\nthat change in context.",
    "start": "1034210",
    "end": "1039579"
  },
  {
    "text": "And to do this kind of\nresolution of ambiguity, we have to operate with\nsome sort of assumption that",
    "start": "1039579",
    "end": "1048250"
  },
  {
    "text": "helps us get off the ground. And one important\nassumption here is this assumption\nof cooperativity.",
    "start": "1048250",
    "end": "1054130"
  },
  {
    "text": "So when we're\ntalking to someone, we assume that they're\ntrying to help us understand what they're saying.",
    "start": "1054130",
    "end": "1059690"
  },
  {
    "text": "So they won't be adversarial\nas the program synthesizer was in those examples.",
    "start": "1059690",
    "end": "1066920"
  },
  {
    "text": "And we can use that assumption\nto do reasoning context and perform pragmatic reasoning.",
    "start": "1066920",
    "end": "1073590"
  },
  {
    "text": "So I'll show here one model\nof pragmatic reasoning called",
    "start": "1073590",
    "end": "1079159"
  },
  {
    "text": "the \"RSA\" or \"Rational\nSpeech Acts,\" which is a Bayesian model of how this\ncould work in simple scenarios.",
    "start": "1079160",
    "end": "1084720"
  },
  {
    "text": "So here we assume that\nwe have two people like a speaker and a listener. The speaker wants to refer\nto a certain object or person",
    "start": "1084720",
    "end": "1095750"
  },
  {
    "text": "and is going to choose\nan utterance for that like a word or a sentence to\nrefer to that object, right?",
    "start": "1095750",
    "end": "1101040"
  },
  {
    "text": "And then, the listener\non the other side is receiving this utterance\nand trying to infer, OK, what does this speaker mean?",
    "start": "1101040",
    "end": "1108740"
  },
  {
    "text": "What are they referring to? What object or what person? So one really cool\nexample here on the right",
    "start": "1108740",
    "end": "1115309"
  },
  {
    "text": "is this where you\nhave these two people. And then, the\nperson on the right has, \"my friend has glasses,\"\nand there are three people",
    "start": "1115310",
    "end": "1121880"
  },
  {
    "text": "here. There is one person wearing\nno glasses and no hat, there's a person\njust wearing glasses,",
    "start": "1121880",
    "end": "1128070"
  },
  {
    "text": "and a person wearing\na glasses and a hat. When you hear that this\nperson's saying, \"my friend has",
    "start": "1128070",
    "end": "1136409"
  },
  {
    "text": "glasses,\" well it's of\ncourse ambiguous in this case because there are two\npeople wearing glasses, but does anyone\nhave an intuition",
    "start": "1136410",
    "end": "1144409"
  },
  {
    "text": "of who would you guess\nthey're talking about? Yeah. Maybe just the middle\none because that's",
    "start": "1144410",
    "end": "1150260"
  },
  {
    "text": "the most distinguished or the\nonly distinguishing factor that they have. Yeah. The middle one is\nthe one you go to.",
    "start": "1150260",
    "end": "1157040"
  },
  {
    "text": "[INAUDIBLE] Oh, yeah, because if\nyou wanted to refer to the one on the\nright, you would have said, \"my friend in the hat.\" Yeah. Exactly.",
    "start": "1157040",
    "end": "1162380"
  },
  {
    "text": "So you just described\nRSA basically. So we do this kind of\nrecursive reasoning",
    "start": "1162380",
    "end": "1168200"
  },
  {
    "text": "apparently, right,\nwhere we think, OK, so if they wanted to refer\nto the person with a hat, they could have said hat\nand that would have not",
    "start": "1168200",
    "end": "1174380"
  },
  {
    "text": "been ambiguous, but\nthey did not say hat, which probably means\nsomething about what",
    "start": "1174380",
    "end": "1180920"
  },
  {
    "text": "they intended to refer to. So RSA is a very simple Bayesian\nmodel of exactly this process.",
    "start": "1180920",
    "end": "1187950"
  },
  {
    "text": "So just to work\nthrough an example, let's say that we have\nthese three objects. A blue square, a circle,\nwhich is also blue,",
    "start": "1187950",
    "end": "1196760"
  },
  {
    "text": "and then a green square, and\nwe have these four utterances that we can use. A very small vocabulary.",
    "start": "1196760",
    "end": "1202820"
  },
  {
    "text": "Blue, green, circle, and square. So in RSA we will\nbootstrap this process",
    "start": "1202820",
    "end": "1209020"
  },
  {
    "text": "from a literal listener, which\nis a listener that can only understand literal meaning.",
    "start": "1209020",
    "end": "1214220"
  },
  {
    "text": "So if you give this\nlistener some utterance u,",
    "start": "1214220",
    "end": "1222130"
  },
  {
    "text": "the literal listener,\nwhich we'll call L0, will put uniform probability on\nall the objects that satisfy u.",
    "start": "1222130",
    "end": "1229570"
  },
  {
    "text": "So if you say blue\nit will put uniform over all the blue objects. If you say square, it'll\nput uniform probability",
    "start": "1229570",
    "end": "1237040"
  },
  {
    "text": "over the squares. And that's the\ndistribution of beliefs",
    "start": "1237040",
    "end": "1242890"
  },
  {
    "text": "that the literal listener puts. So assuming that you're talking\nto that literal listener,",
    "start": "1242890",
    "end": "1249340"
  },
  {
    "text": "now you can create\na pragmatic speaker which will choose some utterance\nto refer to an object based",
    "start": "1249340",
    "end": "1256478"
  },
  {
    "text": "on the probability that\nthe literal listener will understand what they're saying. So, basically, for each\nof the words in our--",
    "start": "1256478",
    "end": "1263100"
  },
  {
    "text": "or utterances that I\ncould say, maybe it could be extremely specific. Like I could write a text\nexactly describing that object,",
    "start": "1263100",
    "end": "1269348"
  },
  {
    "text": "but that would be\nvery costly, right? So I want to be concise,\nbut at the same time I can't be too concise\nbecause otherwise I might not",
    "start": "1269348",
    "end": "1276169"
  },
  {
    "text": "specify what I want to say. Like I will not be\nunderstood, right? So I can imagine this\npragmatic speaker",
    "start": "1276170",
    "end": "1284299"
  },
  {
    "text": "S1, which is trying to\nmaximize this balance between the probability that\nthe literal listener will guess",
    "start": "1284300",
    "end": "1292160"
  },
  {
    "text": "the intended object minus some\ncost, which, in this case, could be uniform probability.",
    "start": "1292160",
    "end": "1299420"
  },
  {
    "text": "And then, from that\npragmatic listener, now I can create a\npragmatic speaker that will choose an utterance\nbased on the probability",
    "start": "1299420",
    "end": "1308930"
  },
  {
    "text": "that the pragmatic speaker\nwould have chosen that utterance to refer to that object.",
    "start": "1308930",
    "end": "1315830"
  },
  {
    "text": "Sorry, the listener L1\nwill choose an object, will guess a belief over the\nobject based on the probability",
    "start": "1315830",
    "end": "1325190"
  },
  {
    "text": "that the speaker S1 would have\nchosen that utterance to refer to each of the objects.",
    "start": "1325190",
    "end": "1330645"
  },
  {
    "text": "And here I could\nrecourse, right? I could create a\nlistener L2 which reasons about the speaker.",
    "start": "1330645",
    "end": "1338620"
  },
  {
    "text": "Sorry, I could\nchoose a speaker S2 which is talking\nwith the listener L1",
    "start": "1338620",
    "end": "1343929"
  },
  {
    "text": "in their head and then\na listener L2 and so on. But usually this\nlistener-speaker pair,",
    "start": "1343930",
    "end": "1350740"
  },
  {
    "text": "S1 and L1, is often enough\nto model human judgments",
    "start": "1350740",
    "end": "1356050"
  },
  {
    "text": "in these settings. Does this make sense? How this recursive\nprocess is happening?",
    "start": "1356050",
    "end": "1362555"
  },
  {
    "text": "OK.  Yeah. So assuming these three\nobjects and a speaker",
    "start": "1362555",
    "end": "1370990"
  },
  {
    "text": "says blue, again following\nthe same example, the glasses and hats, what would\nyou guess or what's",
    "start": "1370990",
    "end": "1379510"
  },
  {
    "text": "your first intuition about what\nobject they would refer to? The square. Yeah.",
    "start": "1379510",
    "end": "1385840"
  },
  {
    "text": "The square is typically\nwhat people do. So a literal listener would say,\nOK, it's completely ambiguous,",
    "start": "1385840",
    "end": "1391810"
  },
  {
    "text": "right? Like 50% on the square\nand on the circle. But if you set up\na human experiment where people are\nreceiving these utterances",
    "start": "1391810",
    "end": "1398380"
  },
  {
    "text": "and saying how much they\nbelieve each of the objects is the intended object, they\nwill put around 40% probability",
    "start": "1398380",
    "end": "1405310"
  },
  {
    "text": "on the circle and 60% on\nthe square, which is very close to what RSA predicts.",
    "start": "1405310",
    "end": "1410635"
  },
  {
    "text": " OK. So this gives a mechanism\nfor resolving ambiguity",
    "start": "1410635",
    "end": "1418210"
  },
  {
    "text": "in this listener-speaker\nsetting. And one way to see\nprogram synthesis",
    "start": "1418210",
    "end": "1426309"
  },
  {
    "text": "is as a setting where\nwe are the speakers, we're talking to\nthe synthesizer,",
    "start": "1426310",
    "end": "1432820"
  },
  {
    "text": "and we are speaking, for\nexample, input/output examples. ",
    "start": "1432820",
    "end": "1438040"
  },
  {
    "text": "And we want to refer\nto a certain program from a set of programs and\nwe're speaking examples",
    "start": "1438040",
    "end": "1444130"
  },
  {
    "text": "and the synthesizer\nis our listener. We're just trying to infer what\nprogram are we referring to.",
    "start": "1444130",
    "end": "1451420"
  },
  {
    "text": "And the examples\nthat we were seeing,",
    "start": "1451420",
    "end": "1457040"
  },
  {
    "text": "the synthesizer was being\nextremely literal, right? So like, oh, if you say that\ngiven A, it should return B,",
    "start": "1457040",
    "end": "1464810"
  },
  {
    "text": "it could be any of the programs\nthat exist that return B,",
    "start": "1464810",
    "end": "1470210"
  },
  {
    "text": "but now we have a\nprocess that can maybe refine this reasoning\na little bit, right?",
    "start": "1470210",
    "end": "1475430"
  },
  {
    "text": "We have RSA and we\ncan almost directly apply it in the setting where\nwe can build this meaning",
    "start": "1475430",
    "end": "1484070"
  },
  {
    "text": "matrix where in one dimension\nwe have all the programs. So let's assume for\nsimplicity that we",
    "start": "1484070",
    "end": "1491030"
  },
  {
    "text": "have a finite set\nof programs and also a finite set of\nexamples that can be given to the synthesizer.",
    "start": "1491030",
    "end": "1497930"
  },
  {
    "text": "So in that setting we\ncan make this matrix where each entry corresponds\nto a program being",
    "start": "1497930",
    "end": "1505100"
  },
  {
    "text": "ran on one example. And we have 1 if the program\nsatisfies that example, like it returns 2 or an other\nexample for example and 0",
    "start": "1505100",
    "end": "1512730"
  },
  {
    "text": "otherwise. So this matrix directly\ngives us a literal listener for this setting.",
    "start": "1512730",
    "end": "1519840"
  },
  {
    "text": "If I give an example,\na literal synthesizer could just look at this\ntable and say, OK, these",
    "start": "1519840",
    "end": "1525245"
  },
  {
    "text": "are all the programs that\nset aside those examples. Maybe I'll sample one\nof those at random.",
    "start": "1525245",
    "end": "1530670"
  },
  {
    "text": "But I could use the RSA\nrecursion to derive L1 and L2, and those would be like\npragmatic synthesizers.",
    "start": "1530670",
    "end": "1540240"
  },
  {
    "text": "And in a human experiment\nran in this paper, which I won't get into a lot of\ndetail in their setting,",
    "start": "1540240",
    "end": "1545670"
  },
  {
    "text": "but they ran this\nexperiment where people were trying to\nspecify a program that",
    "start": "1545670",
    "end": "1552330"
  },
  {
    "text": "draws a pattern on a grid. And the specification\nwas through examples",
    "start": "1552330",
    "end": "1559440"
  },
  {
    "text": "by basically saying, OK, like,\nthe pattern contains the square or does not contain\nthis square, and people",
    "start": "1559440",
    "end": "1566160"
  },
  {
    "text": "had a much easier time\ncommunicating the pattern that they wanted with the\npragmatic synthesizer, which",
    "start": "1566160",
    "end": "1573990"
  },
  {
    "text": "is just a quite cool\nresult, I think. Yeah. So, of course, the\nassumptions here",
    "start": "1573990",
    "end": "1579630"
  },
  {
    "text": "are that the set of\nprograms and of examples is finite, which is\nquite restrictive.",
    "start": "1579630",
    "end": "1585280"
  },
  {
    "text": "It's not true of real\nprogramming languages, but it does present an\ninteresting challenge right?",
    "start": "1585280",
    "end": "1592525"
  },
  {
    "text": "Like can we extend\nthis kind of approach to an infinite set of\nprograms like real programming",
    "start": "1592525",
    "end": "1599220"
  },
  {
    "text": "languages, and\nmaybe also we want richer kinds of specifications. Instead of just saying,\nthe behavior of the program",
    "start": "1599220",
    "end": "1607890"
  },
  {
    "text": "specific examples, we could\ntry to handle natural language. Any questions about this\nconnection between--",
    "start": "1607890",
    "end": "1615390"
  },
  {
    "text": "yes. Have you ever considered in\nthis whole program synthesis",
    "start": "1615390",
    "end": "1620580"
  },
  {
    "text": "just generally how we would\ntypically want like a simple-- with this sort of example,\nlike how we had different edge",
    "start": "1620580",
    "end": "1628950"
  },
  {
    "text": "cases on like if, if, if. Do we do we account\nfor the fact that-- would we penalize a longer\nprogram or more complicated",
    "start": "1628950",
    "end": "1637450"
  },
  {
    "text": "program when trying to\nconsider something like that? Yeah. So the question was,\nin program synthesis",
    "start": "1637450",
    "end": "1645640"
  },
  {
    "text": "do people use biases\nlike, \"find the shortest program\" for example, or\nthe simplest program that",
    "start": "1645640",
    "end": "1651250"
  },
  {
    "text": "satisfies the specification. And the question\nis both yes and no.",
    "start": "1651250",
    "end": "1658990"
  },
  {
    "text": "It's \"yes\" in the sense\nthat most search based",
    "start": "1658990",
    "end": "1664179"
  },
  {
    "text": "synthesizers will usually\nfind very short programs,",
    "start": "1664180",
    "end": "1670140"
  },
  {
    "text": "but not because people\nuse that as a bias necessarily for\ndisambiguating, but just",
    "start": "1670140",
    "end": "1676830"
  },
  {
    "text": "because it's much easier\nto find threaded programs. So like if you're doing\nsearch on a space of programs,",
    "start": "1676830",
    "end": "1683835"
  },
  {
    "text": "the chance that you find like a\n100 line program that satisfies the specification is naturally\nmuch smaller than you finding",
    "start": "1683835",
    "end": "1689370"
  },
  {
    "text": "a short one. Now, to be able to do search\nin the first time-- a lot",
    "start": "1689370",
    "end": "1694440"
  },
  {
    "text": "of research in this\narea in the last decades has been exactly how to design\nspecific languages and search",
    "start": "1694440",
    "end": "1701700"
  },
  {
    "text": "spaces so that this can be done. Does that make sense? ",
    "start": "1701700",
    "end": "1709300"
  },
  {
    "text": "Any other questions?  OK.",
    "start": "1709300",
    "end": "1714415"
  },
  {
    "text": " So we've been talking a\nlot about language models",
    "start": "1714415",
    "end": "1722570"
  },
  {
    "text": "in the class, and as you know,\nif I give a prefix of anything",
    "start": "1722570",
    "end": "1729320"
  },
  {
    "text": "that can show up\nin the internet, that language model\ngives me a distribution of what can come next. So, for example, if I\nsay, \"Stanford University",
    "start": "1729320",
    "end": "1736640"
  },
  {
    "text": "is located in the\nstate of,\" the model having been trained on\nWikipedia and other sources",
    "start": "1736640",
    "end": "1742620"
  },
  {
    "text": "would put much\nhigher probability on the sentence continuing\nwith \"California\" rather",
    "start": "1742620",
    "end": "1747690"
  },
  {
    "text": "than another US State. Language modeling is quite hard.",
    "start": "1747690",
    "end": "1754000"
  },
  {
    "text": "It's like a really,\nreally hard problem because, as John talked about\nin his lecture, a lot of things",
    "start": "1754000",
    "end": "1760140"
  },
  {
    "text": "can be reduced through\nlanguage modeling. So if I say, \"Theodore Landon\nStreleski a former grad student",
    "start": "1760140",
    "end": "1768300"
  },
  {
    "text": "in mathematics at\nStanford,\" for example, and I ask GPT-3 to give\nplausible completions, it gives",
    "start": "1768300",
    "end": "1774629"
  },
  {
    "text": "\"became known for his\nadvocacy of the use of psychedelic drugs\" or\n\"a homeless advocate.\"",
    "start": "1774630",
    "end": "1781710"
  },
  {
    "text": "And I mean this sounds\nplausible, maybe. The ground truth in\nthis case from Wikipedia",
    "start": "1781710",
    "end": "1786870"
  },
  {
    "text": "is he murdered his\nformer advisor, which might be quite hard to\npredict, given this prefix.",
    "start": "1786870",
    "end": "1792525"
  },
  {
    "text": " And it turns out\nthat if I give GPT-3",
    "start": "1792525",
    "end": "1800110"
  },
  {
    "text": "a prefix such as \"the following\nis a Python function that when given the list 1, 3,\n2 returns 1, 2, 3,\"",
    "start": "1800110",
    "end": "1806260"
  },
  {
    "text": "it will complete exactly\nwith this program. \"def sort_list, lst.sort,\nreturn lst\", which,",
    "start": "1806260",
    "end": "1817740"
  },
  {
    "text": "depending on what year you\nwere born, is quite surprising. It's quite amazing that a model\nthat can predict California",
    "start": "1817740",
    "end": "1826529"
  },
  {
    "text": "from Stanford\nUniversity is located in with the exact same mechanism\ncan generate valid Python code.",
    "start": "1826530",
    "end": "1833370"
  },
  {
    "text": "So this was a realization\nthat people made very quickly after GPT-3 came out, right?",
    "start": "1833370",
    "end": "1841020"
  },
  {
    "text": "Given simple Python\ndocstrings, it was able to generate Python\nfunctions that implemented",
    "start": "1841020",
    "end": "1847210"
  },
  {
    "text": "those docstrings even without\nhaving been trained explicitly for that or even code was\nnot a large part of GPT-3's",
    "start": "1847210",
    "end": "1856240"
  },
  {
    "text": "training set anyway. So the natural\nquestion was, how far",
    "start": "1856240",
    "end": "1863000"
  },
  {
    "text": "can we push that capability? So code is massively\navailable on the internet.",
    "start": "1863000",
    "end": "1868490"
  },
  {
    "text": "GitHub has tens of millions\nof open source repositories.",
    "start": "1868490",
    "end": "1875210"
  },
  {
    "text": "Actually over 120 million as\nof, I think, end of last year.",
    "start": "1875210",
    "end": "1881700"
  },
  {
    "text": "So what happens if you\njust train a language model on a lot of code? So that was basically the idea\nbehind OpenAI Codex, which",
    "start": "1881700",
    "end": "1891049"
  },
  {
    "text": "is the name of\nthe language model that backs GitHub Copilot. Just out of curiosity, how\nmany of you have used Copilot?",
    "start": "1891050",
    "end": "1898265"
  },
  {
    "text": " OK. Less than I would have thought.",
    "start": "1898265",
    "end": "1904610"
  },
  {
    "text": "Maybe 30%? Yeah. So Copilot is basically\nautocomplete on steroids",
    "start": "1904610",
    "end": "1915830"
  },
  {
    "text": "that runs this language model\ncalled \"Codex\" in the back end.",
    "start": "1915830",
    "end": "1921510"
  },
  {
    "text": "And as a lot of papers\nin this age we live in,",
    "start": "1921510",
    "end": "1927920"
  },
  {
    "text": "the technical description\nof what was done was, we took the\narchitecture of GPT-3, maybe changed the\nnumber of parameters,",
    "start": "1927920",
    "end": "1934430"
  },
  {
    "text": "and trained on this data. Yes? [INAUDIBLE] these\ntypes of models. Would you just be looking\nkind of for similarity",
    "start": "1934430",
    "end": "1944450"
  },
  {
    "text": "to gold standard\ncode or are you also checking for\ncorrectness of the code,",
    "start": "1944450",
    "end": "1949700"
  },
  {
    "text": "will compile just like\nthe original one does? Yeah. That's a great question. We'll talk a lot about\nhow these models are",
    "start": "1949700",
    "end": "1957140"
  },
  {
    "text": "evaluated in some settings. ",
    "start": "1957140",
    "end": "1963336"
  },
  {
    "text": "The answer just-- jumping\nahead a little bit-- will be that we'll\nmostly execute the code and see what it does\nrather than just comparing",
    "start": "1963336",
    "end": "1969480"
  },
  {
    "text": "to reference solutions. There is a literature\non how to evaluate",
    "start": "1969480",
    "end": "1976410"
  },
  {
    "text": "when you can't do that, but as\nhappens with natural language, people realize that BLEU\nscores and adaptations are not",
    "start": "1976410",
    "end": "1983519"
  },
  {
    "text": "actually very good for\nfunctional correctness especially in code where\nyou can change one token",
    "start": "1983520",
    "end": "1989370"
  },
  {
    "text": "and not change the\nBLEU score by much but completely change the\nsemantics of the program.",
    "start": "1989370",
    "end": "1997529"
  },
  {
    "text": "Yes? In the training data did\nwe include natural language",
    "start": "1997530",
    "end": "2003889"
  },
  {
    "text": "for if we have a\nfunction in Python-- just like natural language like\ndescribing the function does",
    "start": "2003890",
    "end": "2009500"
  },
  {
    "text": "like in a comment or something? Yeah. So the question was, did\nthey include natural language",
    "start": "2009500",
    "end": "2014510"
  },
  {
    "text": "in the training data? And yes, in two forms. So code already has a lot of\nnatural language like comments",
    "start": "2014510",
    "end": "2021500"
  },
  {
    "text": "and strings, and\nthis was all kept. None of it was stripped.",
    "start": "2021500",
    "end": "2027267"
  },
  {
    "text": "So that's one form\nof natural language that Codex got, and\nthe other one was just a subset of the\ntraining set of GPT-3.",
    "start": "2027267",
    "end": "2034559"
  },
  {
    "text": "So it was not trained on 100%\njust code, it also had like-- So in the training\ndata were there",
    "start": "2034560",
    "end": "2041260"
  },
  {
    "text": "examples of a natural\nlanguage description of a function and then\nthe corresponding Python?",
    "start": "2041260",
    "end": "2048219"
  },
  {
    "text": "So the question was, was\nthere a description-- were there examples in the\ntraining data of a description",
    "start": "2048219",
    "end": "2053469"
  },
  {
    "text": "and then the function? Yeah.  Yes.",
    "start": "2053469",
    "end": "2059020"
  },
  {
    "text": "So there are some\nexamples of that form that naturally appear on GitHub.",
    "start": "2059020",
    "end": "2064510"
  },
  {
    "text": "They're not a lot compared\nto all code that exists.",
    "start": "2064510",
    "end": "2069820"
  },
  {
    "text": "We'll talk a little bit about-- [INAUDIBLE] on Stack Overflow-- [INTERPOSING VOICES] Yes. Yes.",
    "start": "2069820",
    "end": "2075739"
  },
  {
    "text": "Yeah. So the web has a lot\nof that kind of thing in general, right?",
    "start": "2075739",
    "end": "2081888"
  },
  {
    "text": "We'll be talking\nabout one experiment that they did on fine\ntuning exactly that format, and has an impact because\nmost code is not written",
    "start": "2081889",
    "end": "2090190"
  },
  {
    "text": "like that on the internet. Although some fraction\ndefinitely is. ",
    "start": "2090190",
    "end": "2096710"
  },
  {
    "text": "The answer is-- [INAUDIBLE] Yes. So the version one of\nCodex was essentially",
    "start": "2096710",
    "end": "2105380"
  },
  {
    "text": "the same architecture\nas GPT-3, which is a decoder only transformed\nmodel, but with 12",
    "start": "2105380",
    "end": "2112670"
  },
  {
    "text": "billion parameters and then\ntrained on a training set that was constructed mostly\nfrom GitHub but also",
    "start": "2112670",
    "end": "2118422"
  },
  {
    "text": "natural language sources. ",
    "start": "2118423",
    "end": "2124130"
  },
  {
    "text": "Yeah. So how do we evaluate\na model, right? We train it and we can\nprompt it with a few examples",
    "start": "2124130",
    "end": "2130390"
  },
  {
    "text": "and see that it does\ninteresting things, but how do we get a better\nsense of its capability?",
    "start": "2130390",
    "end": "2137230"
  },
  {
    "text": "So the authors in the\npaper in the Codex paper, they set up this challenge\nof given a Python docstring,",
    "start": "2137230",
    "end": "2144443"
  },
  {
    "text": "just generate a\nfunction that implements that docstring where\nthe doc string always",
    "start": "2144443",
    "end": "2149980"
  },
  {
    "text": "had input/output examples\nin the form of assertions. So in this example\nhere on the right,",
    "start": "2149980",
    "end": "2157520"
  },
  {
    "text": "which is one from\nthe paper, right? So the first one, the goal\nis to return a list with all",
    "start": "2157520",
    "end": "2164830"
  },
  {
    "text": "the elements increased by one. So you would infer that\nthe elements are numbers. And then, they\ngive two examples,",
    "start": "2164830",
    "end": "2171339"
  },
  {
    "text": "which are like pydoc tests. You can actually run\nthese tests automatically.",
    "start": "2171340",
    "end": "2177590"
  },
  {
    "text": "So if I call it with 1, 2,\n3, it should return 2, 3, 4, and they give one more example.",
    "start": "2177590",
    "end": "2183250"
  },
  {
    "text": "And besides those\nexamples because-- as machine learning\npeople, you should",
    "start": "2183250",
    "end": "2190300"
  },
  {
    "text": "know if you just give all the\nexamples that are evaluating on, your subject to the program\njust working on those examples",
    "start": "2190300",
    "end": "2196900"
  },
  {
    "text": "but not on held out examples. So for each of these\nproblems they of course also had held out inputs that\nthe model was evaluated on.",
    "start": "2196900",
    "end": "2203650"
  },
  {
    "text": "But since this model\nhas seen a lot more code than any person has any\nchance of ever looking at",
    "start": "2203650",
    "end": "2211450"
  },
  {
    "text": "in their lifespan,\nhow do you even know that the problems\nthat you're giving have not been seen before?",
    "start": "2211450",
    "end": "2218030"
  },
  {
    "text": "So this becomes an increasingly\ndifficult challenge with these large models. So they did a best\nattempt, which",
    "start": "2218030",
    "end": "2226030"
  },
  {
    "text": "was to create a data\nset of their own. Since the goal here is not\nto train on that data set,",
    "start": "2226030",
    "end": "2233260"
  },
  {
    "text": "you don't need\nthat many examples as you would need to train\na model from scratch.",
    "start": "2233260",
    "end": "2238339"
  },
  {
    "text": "So they came up with these\n164 problems of this form",
    "start": "2238340",
    "end": "2244570"
  },
  {
    "text": "that they basically\nmanually authored. So that's a way of saying that,\nOK, the model at least hasn't",
    "start": "2244570",
    "end": "2253160"
  },
  {
    "text": "seen these problems in\nthis exact form, right? And for each one, they\nhad a set of hidden tests.",
    "start": "2253160",
    "end": "2259859"
  },
  {
    "text": "So here the evaluation will\nbe the generated program run correctly on all the tests.",
    "start": "2259860",
    "end": "2265099"
  },
  {
    "text": "The seen and unseen ones. And the main metric\nthat we'll be looking at is what they call\n\"pass@k,\" which",
    "start": "2265100",
    "end": "2271460"
  },
  {
    "text": "is the probability that out of k\nsamples of programs that I take from the model, at least one of\nthem passes all of the tests.",
    "start": "2271460",
    "end": "2280130"
  },
  {
    "text": "And the main result\nhere is that GPT-3,",
    "start": "2280130",
    "end": "2285740"
  },
  {
    "text": "which is also a quite\nlarge model trained on a lot of code\nrelatively speaking",
    "start": "2285740",
    "end": "2292820"
  },
  {
    "text": "does exactly at 0 in this\nbaseline, in this benchmark",
    "start": "2292820",
    "end": "2299462"
  },
  {
    "text": "that they came up with. So it doesn't solve any of\nthe problems, which is good. They're at least not\ntrivial problems, right?",
    "start": "2299462",
    "end": "2306800"
  },
  {
    "text": "And all of the Codex models have\nsome non-trivial performance. So Codex alone,\nlooking at pass@1,",
    "start": "2306800",
    "end": "2314270"
  },
  {
    "text": "which is just sample one program\nfrom the model, does above 20%.",
    "start": "2314270",
    "end": "2320070"
  },
  {
    "text": "And of course, we have to take\nall these numbers relative. 20% in general\ndoesn't mean much,",
    "start": "2320070",
    "end": "2326210"
  },
  {
    "text": "but it solve some\nproblems that GPT-3 alone doesn't solve, right? ",
    "start": "2326210",
    "end": "2333829"
  },
  {
    "text": "And if they generated\na set of problems",
    "start": "2333830",
    "end": "2340520"
  },
  {
    "text": "with this exact format\nof Python docstring and the other function to\nevaluate if this format was",
    "start": "2340520",
    "end": "2346940"
  },
  {
    "text": "kind of unusual for the model. so they kind of\nsynthetically generated",
    "start": "2346940",
    "end": "2353450"
  },
  {
    "text": "a training set to fine tune\nand call the resulting model Codex-S, and yes, Codex-S\ndoes a little bit better.",
    "start": "2353450",
    "end": "2361109"
  },
  {
    "text": "So it seems like\nthere's a little bit",
    "start": "2361110",
    "end": "2368600"
  },
  {
    "text": "of benefit of designing training\ndata exactly with this format. And besides just\nsampling one program",
    "start": "2368600",
    "end": "2379780"
  },
  {
    "text": "and returning that\nas your answer, one thing that we'll see\nhere is that it's usually",
    "start": "2379780",
    "end": "2384910"
  },
  {
    "text": "worth to sample a\nlot more programs and somehow choose which\none is your best bet.",
    "start": "2384910",
    "end": "2390460"
  },
  {
    "text": "One simple way to\ndo that is just by taking the model's log\nprobability over the sample rate. So this is the red\nline here, which",
    "start": "2390460",
    "end": "2399369"
  },
  {
    "text": "improves on top of the others. And if you look at the\nexamples that-- sorry.",
    "start": "2399370",
    "end": "2405118"
  },
  {
    "text": "Can you speak to\nthe purple line? Oh, yes. So the purple line is\nthe Oracle reranking,",
    "start": "2405118",
    "end": "2410547"
  },
  {
    "text": "which is basically like if\nI take all the programs that are generated and actually\nrun them on the hidden tests",
    "start": "2410548",
    "end": "2416770"
  },
  {
    "text": "and take the ones that pass\nthe hidden tests then-- so what the purple\nline is saying is that it's often the\ncase that Codex generates",
    "start": "2416770",
    "end": "2423970"
  },
  {
    "text": "some program that\nsatisfies all the tests, but it might be hard to identify\nwithout actually running",
    "start": "2423970",
    "end": "2429432"
  },
  {
    "text": "the program which one is it.  Yeah.",
    "start": "2429433",
    "end": "2434820"
  },
  {
    "text": "So if you look at the examples\nof samples from the model, it's quite non-trivial, right?",
    "start": "2434820",
    "end": "2440550"
  },
  {
    "text": "So if I describe a\nfunction like def is_prime, returns true if a\nnumber is prime,",
    "start": "2440550",
    "end": "2445960"
  },
  {
    "text": "which is, of course, a\nproblem that the model has seen before in some form.",
    "start": "2445960",
    "end": "2453190"
  },
  {
    "text": "It will fail a lot of\ntimes but most of the times it will do something reasonable.",
    "start": "2453190",
    "end": "2458800"
  },
  {
    "text": "So here you see that\nit's trying to test for divisors of the number.",
    "start": "2458800",
    "end": "2464310"
  },
  {
    "text": "In this case, it's just missing\nthe corner case that's true, I think-- or, no, that one is\nreturning as a prime number.",
    "start": "2464310",
    "end": "2471990"
  },
  {
    "text": "It often returns\nthe same program. So by resampling it, you\ndon't have any guarantees.",
    "start": "2471990",
    "end": "2479250"
  },
  {
    "text": "It was trained on\nGitHub, so it's also seen a lot of incomplete code. So it might say, to do, pass.",
    "start": "2479250",
    "end": "2486060"
  },
  {
    "text": "Do it later. But, yeah, sometimes it works. Sometimes it will do\nexactly the primary test",
    "start": "2486060",
    "end": "2493290"
  },
  {
    "text": "with all the corner\ncases and all. And if you specify a\nmore complicated function",
    "start": "2493290",
    "end": "2500130"
  },
  {
    "text": "with maybe some more\ncorner cases it will again. In this case, it will\nnot solve it completely",
    "start": "2500130",
    "end": "2506160"
  },
  {
    "text": "with any of the samples,\nbut a lot of the samples are surprisingly reasonable.",
    "start": "2506160",
    "end": "2511920"
  },
  {
    "text": "It will often at least\npartially do what the specification is asking.",
    "start": "2511920",
    "end": "2517380"
  },
  {
    "text": "Yes. So just to clarify. How difficult are those tasks? Is there like the\nscore made by humans",
    "start": "2517380",
    "end": "2525150"
  },
  {
    "text": "to specify whether some tasks\nare more difficult than others for humans?",
    "start": "2525150",
    "end": "2530520"
  },
  {
    "text": "Yeah. So the question was, how hard\nare the tasks in general? And these problems are not\nhard for human programmers",
    "start": "2530520",
    "end": "2541980"
  },
  {
    "text": "in general. So they test, basically,\nbasic capabilities",
    "start": "2541980",
    "end": "2547619"
  },
  {
    "text": "of coding in Python. ",
    "start": "2547620",
    "end": "2553350"
  },
  {
    "text": "So this is maybe a problem\nof like medium difficulty in the training set in\nthe data set, right?",
    "start": "2553350",
    "end": "2560070"
  },
  {
    "text": "Like a function that like\ncounts vowels, but has a special case for\ny. y Should only be a vowel if it's at\nthe end, for example.",
    "start": "2560070",
    "end": "2567610"
  },
  {
    "text": "So this is the general flavor\nof these problems in the Codex paper. We'll talk about\ndifferent data sets later.",
    "start": "2567610",
    "end": "2575310"
  },
  {
    "text": "That makes sense? Yeah. So the finding here-- Oh, yes.",
    "start": "2575310",
    "end": "2581320"
  },
  {
    "text": "So it fails in a lot\nof cases but many times produces reasonable guesses of\nwhat the function should do.",
    "start": "2581320",
    "end": "2590990"
  },
  {
    "text": "And one thing that\nthey noticed, which",
    "start": "2590990",
    "end": "2599310"
  },
  {
    "text": "was an important observation\nfor many of the works that came after,\nis that there seems",
    "start": "2599310",
    "end": "2605490"
  },
  {
    "text": "to be quite a large benefit\nin just sampling more programs and trying more.",
    "start": "2605490",
    "end": "2610860"
  },
  {
    "text": "So the space of programs that\nthe model can generate usually contains some correct programs.",
    "start": "2610860",
    "end": "2617730"
  },
  {
    "text": "And when sampling more,\nthere is a trade off between the sampling\ntemperature and how likely it",
    "start": "2617730",
    "end": "2624900"
  },
  {
    "text": "is that the program is correct. So if I sample with\ntemperature 0, then",
    "start": "2624900",
    "end": "2629905"
  },
  {
    "text": "I basically get\ndeterministic behavior. I don't get any\nbenefit from sampling.",
    "start": "2629905",
    "end": "2635040"
  },
  {
    "text": "But if I sample with too\nhigh of a temperature, then I get more and more\nrandom outputs, right? ",
    "start": "2635040",
    "end": "2647829"
  },
  {
    "text": "But, of course, just\nsampling more programs is maybe fine for this kind of\nevaluation with a benchmark,",
    "start": "2647830",
    "end": "2654940"
  },
  {
    "text": "but when interacting\nwith a user, I of course don't want to give the user\n100 options to choose from.",
    "start": "2654940",
    "end": "2662223"
  },
  {
    "text": "Right? there is a\nhigh probability that one of these many programs\nsatisfies what you want, but I don't know which one,\nit would not be very usable.",
    "start": "2662223",
    "end": "2670928"
  },
  {
    "text": "So, of course, I could\njust sample a small number of programs, but knowing\nthat it's usually the case",
    "start": "2670928",
    "end": "2676119"
  },
  {
    "text": "that in a large number\nof samples, one of them will be correct.",
    "start": "2676120",
    "end": "2681400"
  },
  {
    "text": "It, a lot of times,\nmakes sense to sample a large number of\nprograms and then try to rerank them in some way\nand then only show maybe",
    "start": "2681400",
    "end": "2688810"
  },
  {
    "text": "my top guesses. So the Oracle here would be, I\nrun all the programs in a test,",
    "start": "2688810",
    "end": "2696579"
  },
  {
    "text": "but a lot of times\nI don't have that. If I'm in the middle\nof writing a function then I want some\nguess for how to write",
    "start": "2696580",
    "end": "2704170"
  },
  {
    "text": "a certain line of the\nfunction, I might not have tests for\nthat specific line,",
    "start": "2704170",
    "end": "2709760"
  },
  {
    "text": "but I can, for example, use the\nmodel's own log probabilities to rank. And yeah, what they found\nwas that basically taking",
    "start": "2709760",
    "end": "2718980"
  },
  {
    "text": "the average token\nlog probability among a number of slightly more\nfancy ways of trying to rank",
    "start": "2718980",
    "end": "2727490"
  },
  {
    "text": "was the best and\nthat they could get. And here we were trying to\nsample code given docstring,",
    "start": "2727490",
    "end": "2736440"
  },
  {
    "text": "but one of the magics\nof language models is that I can just\ncondition on anything",
    "start": "2736440",
    "end": "2742529"
  },
  {
    "text": "to try to get anything. I'm not guaranteed to get good\nthings, but I can always try.",
    "start": "2742530",
    "end": "2749310"
  },
  {
    "text": "So what if we try to\nuse a model to give me a docstring given the code?",
    "start": "2749310",
    "end": "2754740"
  },
  {
    "text": "So basically describe\nwhat a function does. So that's a very natural\ninversion of the problem that we had before.",
    "start": "2754740",
    "end": "2761190"
  },
  {
    "text": "And that kind of\ndata is certainly way less frequent in\nthe training set,",
    "start": "2761190",
    "end": "2767640"
  },
  {
    "text": "although it certainly\nexists in some cases because naturally in\nPython, docstrings comes before the code, but this\nis also a very common thing",
    "start": "2767640",
    "end": "2778300"
  },
  {
    "text": "with code data. I can usually manufacture\nsynthetic data sets that change the structure in some ways.",
    "start": "2778300",
    "end": "2785119"
  },
  {
    "text": "So I can basically write\ndeterministic program that takes Python\nfunctions and inverts the code in the\ndocstring and make",
    "start": "2785120",
    "end": "2791740"
  },
  {
    "text": "a training set for this task. And in this case\nI lose the ability to automatically evaluate\nif a doc string actually",
    "start": "2791740",
    "end": "2798910"
  },
  {
    "text": "describes the code that well. I get a problem with natural\nlanguage generation where--",
    "start": "2798910",
    "end": "2804130"
  },
  {
    "text": "Lisa talked about--\nevaluation is quite hard. In the Codex, paper they\nevaluated this by hand.",
    "start": "2804130",
    "end": "2809570"
  },
  {
    "text": "So basically pass@k\nwhere pass is a human said that the docstring\ndescribes the function.",
    "start": "2809570",
    "end": "2815770"
  },
  {
    "text": "And surprisingly,\nthis task seems to be harder than generating\ncode from docstrings itself.",
    "start": "2815770",
    "end": "2823400"
  },
  {
    "text": "So even a fine\ntuned model like-- so here Codex-S is\nthe Codex that we",
    "start": "2823400",
    "end": "2832660"
  },
  {
    "text": "saw that was fine\ntuned solve the tasks and Codex-D was fine tuned on\nthis data set of generating",
    "start": "2832660",
    "end": "2839260"
  },
  {
    "text": "docstrings given code. And in this case, they\ndidn't get any benefit from fine tuning or any\nimprovement from the base model",
    "start": "2839260",
    "end": "2847300"
  },
  {
    "text": "that they started with. So it seems like\nmaybe describing code is not that easy\ncompared to writing the code.",
    "start": "2847300",
    "end": "2854920"
  },
  {
    "text": " So-- sorry.",
    "start": "2854920",
    "end": "2861430"
  },
  {
    "text": "You have a question. I was wondering, how do we\nensure that the programs that are generated compile?",
    "start": "2861430",
    "end": "2867760"
  },
  {
    "text": "Do we take advantage of like\nparsing trees and stuff? Yeah. So the question is, how do\nwe know that they compile?",
    "start": "2867760",
    "end": "2874450"
  },
  {
    "text": "In this case, they\njust literally save the code and randomly\nthe Python [INAUDIBLE]..",
    "start": "2874450",
    "end": "2879610"
  },
  {
    "text": "So if it threw an exception,\nit failed basically. If it ran and produced the\nexact output, then it succeeded.",
    "start": "2879610",
    "end": "2886539"
  },
  {
    "start": "2886540",
    "end": "2892102"
  },
  {
    "text": "I'm just curious. For the second task,\nto what degree do we just think of it as like\na reading comprehension task",
    "start": "2892102",
    "end": "2899860"
  },
  {
    "text": "because I couldn't actually\nthink of a measurement there, but is there any similarity\nbetween that task and the way",
    "start": "2899860",
    "end": "2907570"
  },
  {
    "text": "to evaluate that task and the\nspecific task to describe it?",
    "start": "2907570",
    "end": "2913480"
  },
  {
    "text": "Yeah. So so the question\nwas, can we see it as like a reading comprehension\ntask of sorts for code?",
    "start": "2913480",
    "end": "2919930"
  },
  {
    "text": "And yes, basically\nit's a way to probe how well can the model\nunderstand quote unquote, \"what",
    "start": "2919930",
    "end": "2926829"
  },
  {
    "text": "the code does.\" That is one task that is\nlike code understanding,",
    "start": "2926830",
    "end": "2934120"
  },
  {
    "text": "so to speak. Another one is code execution. Like given this\ncode and this input,",
    "start": "2934120",
    "end": "2939290"
  },
  {
    "text": "what output does it produce. Which I'll talk a\nlittle bit about, but it's also quite a hard\ntask for these models.",
    "start": "2939290",
    "end": "2947210"
  },
  {
    "text": "So they're often able to\nproduce code that works, but if you give it\nthe code, then it's",
    "start": "2947210",
    "end": "2954170"
  },
  {
    "text": "hard to predict what the\ncode does from the model. That makes sense?",
    "start": "2954170",
    "end": "2960383"
  },
  {
    "text": "So, just to clarify, it's more\ndifficult than a normal reading comprehension task. [INAUDIBLE]?",
    "start": "2960383",
    "end": "2967850"
  },
  {
    "text": "Just why is code specifically\ndifferent from this",
    "start": "2967850",
    "end": "2973120"
  },
  {
    "text": "than just a normal-- Yeah. So how is code a\ndifferent corpus?",
    "start": "2973120",
    "end": "2978309"
  },
  {
    "text": "Is it more difficult? Yeah. I think, more or less, difficult\ndepends to whom, right?",
    "start": "2978310",
    "end": "2985210"
  },
  {
    "text": "An average human certainly can't\ndescribe what a Python function does, but not\nnecessarily because it's",
    "start": "2985210",
    "end": "2991180"
  },
  {
    "text": "inherently more complex task. So I guess it depends\non who you ask.",
    "start": "2991180",
    "end": "2996220"
  },
  {
    "text": " Yeah.",
    "start": "2996220",
    "end": "3002420"
  },
  {
    "text": "So in the examples that\nthe model got wrong, is there a way to do an analysis\nof the source of the error",
    "start": "3002420",
    "end": "3008220"
  },
  {
    "text": "like if there was an error\nwith the algorithm versus just a syntax error? Yeah. So the question is, what kind\nof errors does the model make",
    "start": "3008220",
    "end": "3017670"
  },
  {
    "text": "and can we evaluate\nit automatically? Yes. I didn't include\nthis here, but one of the papers that I'll\ntalk a little bit about",
    "start": "3017670",
    "end": "3025080"
  },
  {
    "text": "did this analysis of\nwhat kind of error does the model make\nat different scales,",
    "start": "3025080",
    "end": "3032730"
  },
  {
    "text": "and the result there was that\nas the models grow in number",
    "start": "3032730",
    "end": "3038880"
  },
  {
    "text": "of parameters, they tend to make\nless syntactic errors and less compilation errors and\nhave more semantic errors",
    "start": "3038880",
    "end": "3044760"
  },
  {
    "text": "like the program still runs\nbut fails on some tests. And at the smaller\nsizes, it's way more",
    "start": "3044760",
    "end": "3053670"
  },
  {
    "text": "common to get like\nsyntax errors like didn't close the parentheses\nor something like that. ",
    "start": "3053670",
    "end": "3061150"
  },
  {
    "text": "OK. So as you've noticed,\nthe base technology here",
    "start": "3061150",
    "end": "3068100"
  },
  {
    "text": "was still just transformers. We're sampling\nfrom a transformer and running the code,\nand maybe sampling more",
    "start": "3068100",
    "end": "3074789"
  },
  {
    "text": "and reranking using log\nprobabilities, but not nothing extremely specific to\ncode besides the fact",
    "start": "3074790",
    "end": "3080520"
  },
  {
    "text": "that we can execute the output. DeepMind came up with AlphaCode,\nwhich was very talked about--",
    "start": "3080520",
    "end": "3089070"
  },
  {
    "text": "I'm sure at least some\nof you have heard of it-- which was basically\na system that expanded on these ideas of\ntraining language models",
    "start": "3089070",
    "end": "3097140"
  },
  {
    "text": "to generate code. And in this case,\ntheir target was to solve programming competition\nproblems, which some of you",
    "start": "3097140",
    "end": "3105360"
  },
  {
    "text": "might heard about. These are competitions just\nlike math competitions, but where the challenge is\nto come up with algorithms",
    "start": "3105360",
    "end": "3112080"
  },
  {
    "text": "and then write code that\nsolve a computational problem.",
    "start": "3112080",
    "end": "3117150"
  },
  {
    "text": "And the foundation of\nAlphaCode was still",
    "start": "3117150",
    "end": "3123059"
  },
  {
    "text": "sampling from Transformers. A lot of their\ntechnical design choices were basically targeted at\nallowing faster sampling.",
    "start": "3123060",
    "end": "3131010"
  },
  {
    "text": "So they came up with a\ncheaper version of attention",
    "start": "3131010",
    "end": "3136440"
  },
  {
    "text": "where you share the key value\nheads but have multiple query",
    "start": "3136440",
    "end": "3143099"
  },
  {
    "text": "heads because that\nwas an engineering bottleneck in their sampling.",
    "start": "3143100",
    "end": "3148329"
  },
  {
    "text": "And they use an\nencoder-decoder Transformer because it was faster to\njust encode the problem once,",
    "start": "3148330",
    "end": "3156850"
  },
  {
    "text": "but aside from that,\nvery similar ideas. So they pre-trained their\ntransformer on basically,",
    "start": "3156850",
    "end": "3167050"
  },
  {
    "text": "in this case, mostly code. I think from their\ndescription, it",
    "start": "3167050",
    "end": "3172210"
  },
  {
    "text": "was basically just a data\nset composed of GitHub code where the encoder\nwas additionally",
    "start": "3172210",
    "end": "3177790"
  },
  {
    "text": "trained with masked\nlanguage modeling laws. And they fine tuned the model\nthen on a much smaller data",
    "start": "3177790",
    "end": "3186610"
  },
  {
    "text": "set of human solutions to\nprogramming competition problems, which are much sparser\nthan like arbitrary GitHub",
    "start": "3186610",
    "end": "3192549"
  },
  {
    "text": "code. They used one variant\nof reinforcement learning fine tuning\ncalled \"GOLD,\"",
    "start": "3192550",
    "end": "3198220"
  },
  {
    "text": "not RLHF but kind\nof similar idea. Just in this period\nthat you don't",
    "start": "3198220",
    "end": "3206536"
  },
  {
    "text": "want to penalize the model\nfor not being able to produce all valid solutions. You just want it to be able\nto output some solution.",
    "start": "3206537",
    "end": "3212319"
  },
  {
    "text": "So if sampling from the model\nis giving you some solution then it should be\ngetting the reward.",
    "start": "3212320",
    "end": "3218570"
  },
  {
    "text": "And one interesting\ntrick that they did was value conditioning.",
    "start": "3218570",
    "end": "3223820"
  },
  {
    "text": "So basically, since we don't\nhave that many submissions to these competitive\nprogramming problems,",
    "start": "3223820",
    "end": "3230480"
  },
  {
    "text": "it's a little bit\nbad to simply discard all of the wrong\nsolutions, which-- we have a lot more\nwrong solutions",
    "start": "3230480",
    "end": "3236450"
  },
  {
    "text": "than correct solutions. So we want to train\non them somehow but, we don't want to make them\nautogenerate wrong solutions,",
    "start": "3236450",
    "end": "3245135"
  },
  {
    "text": "but there's still some\ninteresting statistics to be learned there. So to train on those\nsolutions, they basically",
    "start": "3245135",
    "end": "3253730"
  },
  {
    "text": "designed their training\nset so that the code starts with a comment that says whether\nit's correct or incorrect.",
    "start": "3253730",
    "end": "3259710"
  },
  {
    "text": "So I can make training examples\nwhere the correct solution start with, this correct\nsolution, and the incorrect one",
    "start": "3259710",
    "end": "3266630"
  },
  {
    "text": "say, this is an\nincorrect solution. And then at test\ntime, of course, when generating a\nprogram that I want",
    "start": "3266630",
    "end": "3273109"
  },
  {
    "text": "to be correct I'll\nstart with the comment, this is the correct solution. That lets the model\nin some way benefit",
    "start": "3273110",
    "end": "3279559"
  },
  {
    "text": "from seeing correct\nsolutions as well. And the thing that they\nreally pushed in this paper",
    "start": "3279560",
    "end": "3285810"
  },
  {
    "text": "was sampling.  So in the Codex\npaper we were talking",
    "start": "3285810",
    "end": "3291300"
  },
  {
    "text": "of up to 100\nsamples per problem, which is already a lot.",
    "start": "3291300",
    "end": "3296430"
  },
  {
    "text": "Like it's something that\njust using the Codex API you would have a lot\nof trouble doing. In AlphaCode, they\nmassively parallelized this",
    "start": "3296430",
    "end": "3303690"
  },
  {
    "text": "and did 100,000\nsamples per problem. And as we're talking, if you are\nto participate in a programming",
    "start": "3303690",
    "end": "3312440"
  },
  {
    "text": "competition and they\nactually did run off a code on a real one,\nyou can't afford at all",
    "start": "3312440",
    "end": "3318920"
  },
  {
    "text": "to submit 100,000 attempts\nof solving a problem. So in some way, you\nhave to narrow that down",
    "start": "3318920",
    "end": "3324799"
  },
  {
    "text": "to a very small set. And in this case,\nthey set the limit of making up to 10 submissions,\nwhich is the range of what",
    "start": "3324800",
    "end": "3333440"
  },
  {
    "text": "a human participant would do. So how do we do that?",
    "start": "3333440",
    "end": "3338829"
  },
  {
    "text": "Well, the first obvious\nstep is filtering. So each of these problems\ncomes with some examples",
    "start": "3338830",
    "end": "3343860"
  },
  {
    "text": "of inputs and outputs. So I can immediately\ndiscard all the programs that don't satisfy even\nthose example inputs.",
    "start": "3343860",
    "end": "3352680"
  },
  {
    "text": "That's already removed like\n90% of these 100K samples.",
    "start": "3352680",
    "end": "3359700"
  },
  {
    "text": "Then we still have a\nquite significant number of programs that work at\nleast on the basic tests.",
    "start": "3359700",
    "end": "3366240"
  },
  {
    "text": "So what do we do? So what they did was they\ntrained a separate model that generates inputs for a program.",
    "start": "3366240",
    "end": "3373940"
  },
  {
    "text": "And for these\ngenerated inputs, we don't really what's\nthe expected output",
    "start": "3373940",
    "end": "3382280"
  },
  {
    "text": "unless we are really good\nat interpreting the problem statement. But even without knowing\nwhat's the expected output,",
    "start": "3382280",
    "end": "3388310"
  },
  {
    "text": "I can use those generated inputs\nto basically group the programs that I have by behavior, right? So if I generate a string\nand I run all the programs",
    "start": "3388310",
    "end": "3397250"
  },
  {
    "text": "on that input\nstring, some of them produce this result and some\nof that produce that result. Then I can infer that maybe\nthese programs are semantically",
    "start": "3397250",
    "end": "3407390"
  },
  {
    "text": "the same, right? So if I had two\nsubmissions to make, maybe I would do one\nof each instead of two",
    "start": "3407390",
    "end": "3412700"
  },
  {
    "text": "in the same cluster. So this is basically\nwhat they did. They generated a lot of inputs,\nclustered the programs based",
    "start": "3412700",
    "end": "3419000"
  },
  {
    "text": "on their behavior\non those inputs, and then picked one submission\nfrom each of the largest",
    "start": "3419000",
    "end": "3424470"
  },
  {
    "text": "clusters, All right. What is the point of using\nincorrect submissions to augment training?",
    "start": "3424470",
    "end": "3430770"
  },
  {
    "text": "How does that help the\nmodel to do better? Yeah. So the question is, how\ndo the wrong solutions",
    "start": "3430770",
    "end": "3438600"
  },
  {
    "text": "help the model in any way? So they didn't\nreally do an ablation of not training the model\non the incorrect solutions",
    "start": "3438600",
    "end": "3445589"
  },
  {
    "text": "to measure the benefit\nof that specifically, but the intuition is that\neven the incorrect solutions",
    "start": "3445590",
    "end": "3452760"
  },
  {
    "text": "have some interesting\ninformation for you to learn from, right? So you might learn that they\nare incorrect, for example.",
    "start": "3452760",
    "end": "3458783"
  },
  {
    "text": "You might learn bug patterns. So you might learn that\nif somewhere in the code",
    "start": "3458783",
    "end": "3464310"
  },
  {
    "text": "I forget to close the\nparentheses, for example, it is probably incorrect.",
    "start": "3464310",
    "end": "3470599"
  },
  {
    "text": "And since in this case, we don't\nreally have that much training data, anyway that you can get to\nuse the training data that you",
    "start": "3470600",
    "end": "3478670"
  },
  {
    "text": "have probably helps. That makes sense? Yeah, but that's\na good question.",
    "start": "3478670",
    "end": "3485750"
  },
  {
    "text": "It's not exactly\nclear what the model learns from the wrong solution.",
    "start": "3485750",
    "end": "3491380"
  },
  {
    "text": "In the competitive programming\ncontext, I was exposed to, you do usually get\na grade at least.",
    "start": "3491380",
    "end": "3497790"
  },
  {
    "text": "You don't see the\nspecific test, but get a grade for your submissions\nbefore the time is up.",
    "start": "3497790",
    "end": "3502980"
  },
  {
    "text": "Was this the best use\nof that information by not looking that at all,\nsince you submit [INAUDIBLE]",
    "start": "3502980",
    "end": "3509340"
  },
  {
    "text": "10 you get like clustering\ninstead of trying to incorporate the feedback\nyou get from the greater?",
    "start": "3509340",
    "end": "3514980"
  },
  {
    "text": "Yeah. So in the competitions\nthat they tried which was basically\nCodeforces, you only get like a binary response.",
    "start": "3514980",
    "end": "3520770"
  },
  {
    "text": "Was it accepted or not. Yes, it's harsher\nthan IOI, for example.",
    "start": "3520770",
    "end": "3529590"
  },
  {
    "text": "Yeah so the result in offline\nexperiments of basically",
    "start": "3529590",
    "end": "3535260"
  },
  {
    "text": "solving this problems from a\nbenchmark that they collected was basically that\nif your sample more,",
    "start": "3535260",
    "end": "3542370"
  },
  {
    "text": "you solve more problems. So they get this log linear\nscaling with how many programs",
    "start": "3542370",
    "end": "3549359"
  },
  {
    "text": "they sample at all of the\nmodel scales that they tried. Which essentially means\nthat if you sample 10 times",
    "start": "3549360",
    "end": "3557970"
  },
  {
    "text": "more programs, your solve rate\nincreases in this linear rate of 6%, approximately.",
    "start": "3557970",
    "end": "3564500"
  },
  {
    "text": "And also with compute. So with how many TPU days\nthey took to train the model,",
    "start": "3564500",
    "end": "3571100"
  },
  {
    "text": "it has also a roughly\nlog linear scale, and also TPU seconds spent\nsampling for each problem.",
    "start": "3571100",
    "end": "3579970"
  },
  {
    "text": "And so that was an offline\nevaluation on a set of problems",
    "start": "3579970",
    "end": "3585119"
  },
  {
    "text": "that they collected,\nbut they also tried this model live on\ncompetition on this website",
    "start": "3585120",
    "end": "3590940"
  },
  {
    "text": "called Codeforces. And their model did get\nnon-trivial performance",
    "start": "3590940",
    "end": "3596369"
  },
  {
    "text": "in a bunch of contests. So they actually ran\nthis in past contexts. They didn't run\nit live, but they",
    "start": "3596370",
    "end": "3605760"
  },
  {
    "text": "tried to simulate as much as\npossible the setting where you would be in the\ncompetition, And yeah.",
    "start": "3605760",
    "end": "3611832"
  },
  {
    "text": "In some of the\ncontests, they would place in the top 30%, top 50%. Like a median coder\nin Division 2,",
    "start": "3611832",
    "end": "3620190"
  },
  {
    "text": "which is important to notice. So as they describe,\nin the paper this is approximately\na few months",
    "start": "3620190",
    "end": "3628230"
  },
  {
    "text": "to a year of training\nprogramming, which is not",
    "start": "3628230",
    "end": "3633910"
  },
  {
    "text": "to say that they're like winning\nthese competitions anytime soon, but at the same\ntime not trivial.",
    "start": "3633910",
    "end": "3639730"
  },
  {
    "text": " And the main component of\ngetting the performance",
    "start": "3639730",
    "end": "3650390"
  },
  {
    "text": "that they did was sampling. Sampling more programs. So they did all this\nengineering to make sure",
    "start": "3650390",
    "end": "3656690"
  },
  {
    "text": "that they could sample\n100k programs per problem,",
    "start": "3656690",
    "end": "3662180"
  },
  {
    "text": "and they had like an\naccumulation of techniques like the MLM pre-training\non the encoder,",
    "start": "3662180",
    "end": "3671090"
  },
  {
    "text": "like sampling with random\nproblem tags, and the GOLD fine tuning and all that,\nand none of them",
    "start": "3671090",
    "end": "3677810"
  },
  {
    "text": "would have helped\nif at test time they were just\ndoing 1,000 samples. So the effects of basically\nall of those techniques",
    "start": "3677810",
    "end": "3684680"
  },
  {
    "text": "only showed up when they\nscaled it up to 100K to a million samples.",
    "start": "3684680",
    "end": "3690349"
  },
  {
    "text": "So on one hand, this\nshows the potential of very simple set of\ntechniques that you've",
    "start": "3690350",
    "end": "3697220"
  },
  {
    "text": "seen in this class\nof just sampling things from Transformers but\ntaken at this extreme scale,",
    "start": "3697220",
    "end": "3704310"
  },
  {
    "text": "but, of course, this also\nshows a limit, right? So at this rate of having to\ntake 10x more samples to get",
    "start": "3704310",
    "end": "3712940"
  },
  {
    "text": "6% more problem solved,\nthis won't get Division I any time soon.",
    "start": "3712940",
    "end": "3718040"
  },
  {
    "text": "So we have to do something\ndifferent if that's the goal. ",
    "start": "3718040",
    "end": "3723780"
  },
  {
    "text": "And one kind of\nproblem that seems to be inherent to these\nmodels, if all you're doing",
    "start": "3723780",
    "end": "3730710"
  },
  {
    "text": "is just like sampling\ncomplete programs, is this challenge that\nhumans don't really have with compositionality.",
    "start": "3730710",
    "end": "3738000"
  },
  {
    "text": "So this is an actual\nresult that was presented in the Codex paper.",
    "start": "3738000",
    "end": "3743710"
  },
  {
    "text": "And if you ask a person that\nknows basic Python programming how to solve problem\nx and they say",
    "start": "3743710",
    "end": "3749670"
  },
  {
    "text": "it's trivial like reverse\na string, for example, and if you separately\nask them how",
    "start": "3749670",
    "end": "3755400"
  },
  {
    "text": "do you compute the\nlength of a string, and they also think\nthat's trivial.",
    "start": "3755400",
    "end": "3760590"
  },
  {
    "text": "If you give them the problem,\ncan you reverse a string and then take the length,\nthey'll say, OK, of course.",
    "start": "3760590",
    "end": "3767250"
  },
  {
    "text": "That's a very simple composition\nof two things that are trivial, but that does not seem to be\nthe case with these language",
    "start": "3767250",
    "end": "3774870"
  },
  {
    "text": "models. So the Codex authors\ndid the experiment",
    "start": "3774870",
    "end": "3781260"
  },
  {
    "text": "where they manufactured tasks\nby basically chaining these very simple tasks, and the result\nwas that as the number",
    "start": "3781260",
    "end": "3788369"
  },
  {
    "text": "of these components\ngrow, the probability that the samples from the model\nsolves the composite problem",
    "start": "3788370",
    "end": "3794640"
  },
  {
    "text": "decays kind of\nexponentially even if the model knows how to\ndo each of the components",
    "start": "3794640",
    "end": "3800890"
  },
  {
    "text": "individually. So this is something which is\na challenge to these models",
    "start": "3800890",
    "end": "3807910"
  },
  {
    "text": "and not to people.  Yeah. So just some quick takeaways.",
    "start": "3807910",
    "end": "3816339"
  },
  {
    "text": "It seems like Transformers\njust trained at scale on code, have non-trivial\nperformance in this task.",
    "start": "3816340",
    "end": "3822280"
  },
  {
    "text": "And these results, maybe for\npeople that download Copilot",
    "start": "3822280",
    "end": "3828940"
  },
  {
    "text": "and just test it and\nit sort of works, don't seem that surprising, but\nfor the program synthesis field",
    "start": "3828940",
    "end": "3835600"
  },
  {
    "text": "that had been for decades\nworking on these very specific, very constrained domain\nspecific languages,",
    "start": "3835600",
    "end": "3841270"
  },
  {
    "text": "these results were just\nunimaginable a few years ago. And it seems like\nsampling and testing",
    "start": "3841270",
    "end": "3847390"
  },
  {
    "text": "and filtering can get\nquite far, but it also gets expensive quite fast. So the AlphaCode, for example.",
    "start": "3847390",
    "end": "3853870"
  },
  {
    "text": "Just training and evaluating\ntheir largest model used the equivalent energy of\nlike 16 American households",
    "start": "3853870",
    "end": "3862980"
  },
  {
    "text": "a year, for example. We can't also have\neveryone using these models at this scale all the time.",
    "start": "3862980",
    "end": "3869300"
  },
  {
    "text": " And the other caveat\nhere, of course,",
    "start": "3869300",
    "end": "3875820"
  },
  {
    "text": "is that this setting\nwhere you get the extremely well specified\nproblem which has tests",
    "start": "3875820",
    "end": "3883400"
  },
  {
    "text": "and you can run the\nprogram and determine exactly when it\npasses all the tests, it's very different from\nreal world programming",
    "start": "3883400",
    "end": "3890029"
  },
  {
    "text": "where most of the time\nis spent understanding what's the problem, deciding\nwhat to do, revising the tests.",
    "start": "3890030",
    "end": "3896660"
  },
  {
    "text": "A lot of time is spent\nediting code, and so on. So there's a lot of progress\nbeing made, but this of course",
    "start": "3896660",
    "end": "3905990"
  },
  {
    "text": "still has a lot to go. Yes. One question is-- it's similar\nto a question that was asked",
    "start": "3905990",
    "end": "3913640"
  },
  {
    "text": "earlier-- if we can do error analysis. Is it possible\nbecause one thing when we're doing this type\nof code generation",
    "start": "3913640",
    "end": "3919910"
  },
  {
    "text": "is if we just assume it to be\nright, it's a lot harder for us to debug our code because we\ndidn't write it ourselves?",
    "start": "3919910",
    "end": "3925970"
  },
  {
    "text": "Are there any kind of like\nideas or things people are considering in the field for\nhow to go about debugging code",
    "start": "3925970",
    "end": "3934430"
  },
  {
    "text": "that was written by an AI? Are there like AI\ndebuggers as well? Yeah. So the question was\nabout debugging.",
    "start": "3934430",
    "end": "3941900"
  },
  {
    "text": "I think there are two things. So one of them is-- Yeah, I had a lot more\nthings that I didn't get to,",
    "start": "3941900",
    "end": "3949220"
  },
  {
    "text": "but one of them was this notion\nof automation bias which people",
    "start": "3949220",
    "end": "3957900"
  },
  {
    "text": "have, which is we have\na general tendency to believe things\nthat are automated, and this is quite a problem.",
    "start": "3957900",
    "end": "3964965"
  },
  {
    "text": "For example, there\nwas this study run here at Stanford,\neven, where--",
    "start": "3964965",
    "end": "3970650"
  },
  {
    "text": "Codex introduces security\nbugs at a non-trivial rate, for example. ",
    "start": "3970650",
    "end": "3978099"
  },
  {
    "text": "Yeah, it's still hard\nto use these models without understanding\nwhat they're doing. And the problem of doing this\nprocess more interactively",
    "start": "3978100",
    "end": "3987410"
  },
  {
    "text": "of writing the program and\nthen looking at what it does and then maybe revising\nthe code is still",
    "start": "3987410",
    "end": "3996440"
  },
  {
    "text": "much harder than just trying to\nwrite the program from scratch exactly because--",
    "start": "3996440",
    "end": "4001540"
  },
  {
    "text": "well, one of the\nreasons is certain that we don't have that much\ndata on that process happening with people.",
    "start": "4001540",
    "end": "4007000"
  },
  {
    "text": "We see GitHub, which is\nkind of the published version of the code,\nbut all the processes",
    "start": "4007000",
    "end": "4012760"
  },
  {
    "text": "to get from an empty file to\nthat is still not recorded. ",
    "start": "4012760",
    "end": "4019880"
  },
  {
    "text": "But, yeah, that's a very active\narea of research as well. Like models to revise\nand edit and debug.",
    "start": "4019880",
    "end": "4028420"
  },
  {
    "text": " Yes, so-- are we at time?",
    "start": "4028420",
    "end": "4033670"
  },
  {
    "text": "You have up to 5:50 actually. 5:50? OK, so we do have time\nto talk about something. OK.",
    "start": "4033670",
    "end": "4039370"
  },
  {
    "text": "Awesome. Yes.",
    "start": "4039370",
    "end": "4044830"
  },
  {
    "text": "So I'll try to go\nover a little bit. So one fun thing connecting\nto what we talked about back",
    "start": "4044830",
    "end": "4055660"
  },
  {
    "text": "is that Codex can do some\nsimple pragmatic reasoning. So for example, if I give\nyou these inputs, list 1, 3,",
    "start": "4055660",
    "end": "4064089"
  },
  {
    "text": "2 returns 1, 2, 3, you'll\nwould probably say sorting. It sorts the list. But what about 1, 2,\n3 returns 1, 2, 3?",
    "start": "4064090",
    "end": "4071800"
  },
  {
    "text": "Probably just identity, but it\ncould also be sorting, right? It's consistent with\nsorting as well.",
    "start": "4071800",
    "end": "4077990"
  },
  {
    "text": "But you would reason\nthat if I wanted to specify the sorting\nfunction, I would probably give a different input.",
    "start": "4077990",
    "end": "4083030"
  },
  {
    "text": "And if I give these\ninputs to Codex, it does predict that\nthe first one is sorting but the second one is identity.",
    "start": "4083030",
    "end": "4090130"
  },
  {
    "text": "Just an interesting\nthing to come out of just regular language\nmodeling training.",
    "start": "4090130",
    "end": "4096729"
  },
  {
    "text": "There are also experiments\nwith using these models in a dialogue style, which\nis a little bit more about--",
    "start": "4096729",
    "end": "4102934"
  },
  {
    "text": "like the question asked. So I can ask it to\nwrite a function, and then model comes up\nwith some implementation,",
    "start": "4102934",
    "end": "4111170"
  },
  {
    "text": "but maybe it has an error. They can sometimes describe\nthe change like, oh, but can you do the\nsort in reverse",
    "start": "4111170",
    "end": "4119028"
  },
  {
    "text": "or only return the\ntop four results, and it can often\nrevise what it did,",
    "start": "4119029",
    "end": "4125670"
  },
  {
    "text": "which is quite interesting. Yes. So last topic here is using\nprograms not as the output",
    "start": "4125670",
    "end": "4137350"
  },
  {
    "text": "that you want from the\nmodel directly, but rather as a representation\nfor other things. So one general\nthing about humans",
    "start": "4137350",
    "end": "4145689"
  },
  {
    "text": "is that our efficacy\nin a lot of tasks depends on using\nexternal tools, right?",
    "start": "4145689",
    "end": "4151600"
  },
  {
    "text": "So if I ask you to multiply\nthese two numbers, 1, 2, 3, 4, 5, 6, you can do it, but\nyou probably won't just",
    "start": "4151600",
    "end": "4159877"
  },
  {
    "text": "do it in your head, right? You use a calculator. Or if I ask you what time is it. Well, you, don't keep track\nof time that precisely, right?",
    "start": "4159877",
    "end": "4166479"
  },
  {
    "text": "So you use a clock. Or what are the five largest\nairports in the world? You'll do some Google search.",
    "start": "4166479",
    "end": "4171490"
  },
  {
    "text": "You figure it out, but you won't\njust take it out of your head. And when we are training a\nlanguage model to just give us",
    "start": "4171490",
    "end": "4179859"
  },
  {
    "text": "answers condition on\nthe question or maybe on some context, we're\nbasically asking it to come up",
    "start": "4179859",
    "end": "4188049"
  },
  {
    "text": "with the answer all by itself. And a lot of these problems\naren't reasonably solved",
    "start": "4188050",
    "end": "4194420"
  },
  {
    "text": "in that manner. The problem with just\ntelling what time is it, for example, is one\nthat you fundamentally",
    "start": "4194420",
    "end": "4199660"
  },
  {
    "text": "can't get out of the model\nthat was trained and frozen and has to produce\nan output now.",
    "start": "4199660",
    "end": "4206220"
  },
  {
    "text": "And for example, there\nwas this language model that came out last\nyear called Minerva",
    "start": "4206220",
    "end": "4212730"
  },
  {
    "text": "which was trained on\nmathematical problems and solutions. And it a lot of times\ngot the strategy right",
    "start": "4212730",
    "end": "4220680"
  },
  {
    "text": "in solving these\nproblems, but still makes a lot of arithmetic errors. So it says, OK,\nthe solution will",
    "start": "4220680",
    "end": "4226470"
  },
  {
    "text": "be this number plus this\nnumber equals something wrong, for example. So it seems limiting that\nwe're asking the model",
    "start": "4226470",
    "end": "4234659"
  },
  {
    "text": "to do all these\nthings by itself. So this OpenAI paper from\n2021 had this very simple idea",
    "start": "4234660",
    "end": "4243239"
  },
  {
    "text": "of solving math word problems\nusing language models but providing them\nwith a calculator.",
    "start": "4243240",
    "end": "4249900"
  },
  {
    "text": "And the way to let the model\nuse a calculator is basically to assign a a special\ntoken in the input such",
    "start": "4249900",
    "end": "4260550"
  },
  {
    "text": "that when the model\ngenerates that token, your decoder, instead of keeping\nconditioning on the model's",
    "start": "4260550",
    "end": "4266670"
  },
  {
    "text": "probabilities, will\nthen deterministically do something with the\ninput like a calculator and paste the output in and\nthe model's output sequence.",
    "start": "4266670",
    "end": "4276570"
  },
  {
    "text": "So they generated this training\nset kind of semi-automatically where solutions to\nmath word problems",
    "start": "4276570",
    "end": "4283139"
  },
  {
    "text": "would have these annotations\nin angle brackets. And by seeing those annotations\nat in the training set--",
    "start": "4283140",
    "end": "4291930"
  },
  {
    "text": "and for training\nyou don't really need to do anything special-- at test time you can give\nthe model a calculator",
    "start": "4291930",
    "end": "4298110"
  },
  {
    "text": "by basically watching\nuntil the moment where it outputs an equal sign. And then, once it does, instead\nof generating from the model,",
    "start": "4298110",
    "end": "4306480"
  },
  {
    "text": "you can take the numbers that\ncome before \"call calculator,\" and then just paste the\nexact output after, right?",
    "start": "4306480",
    "end": "4315220"
  },
  {
    "text": "And this, as you can imagine,\ngives a quite significant boost",
    "start": "4315220",
    "end": "4320500"
  },
  {
    "text": "in solving these problems\nbecause you kind of isolate one kind of error. The model won't make\narithmetic errors anymore.",
    "start": "4320500",
    "end": "4329860"
  },
  {
    "text": "This same idea but\ntaken a little bit farther was used to\nsolve word problems",
    "start": "4329860",
    "end": "4335920"
  },
  {
    "text": "but instead of the\nmodel outputting the solution in\nnatural language,",
    "start": "4335920",
    "end": "4341170"
  },
  {
    "text": "it kind of interspersed natural\nlanguage with Python code, and the final answer was\nnot given by the model,",
    "start": "4341170",
    "end": "4347650"
  },
  {
    "text": "but by running the Python\ncode that it provided. So here's an example. You can look at it\nin more detail later.",
    "start": "4347650",
    "end": "4354860"
  },
  {
    "text": "And this also\ngives a big benefit over just having the\nmodel try to figure out",
    "start": "4354860",
    "end": "4360610"
  },
  {
    "text": "what's the answer on its own. And more generally,\nthere was this paper",
    "start": "4360610",
    "end": "4367369"
  },
  {
    "text": "that came out on arXive called\n\"Toolformer,\" where they basically extended\nthis idea little",
    "start": "4367370",
    "end": "4373400"
  },
  {
    "text": "bit further with a\nself-supervised approach of-- let's say, you come\nup with a list of tools",
    "start": "4373400",
    "end": "4380540"
  },
  {
    "text": "and you want to kind\nof teach your model how to use those tools. And in this case they\ntried quite a few tools.",
    "start": "4380540",
    "end": "4390647"
  },
  {
    "text": "So one of them was a calculator. Another was a machine\ntranslation system. So when the model\noutputs in its--",
    "start": "4390647",
    "end": "4397275"
  },
  {
    "text": "when decoding from\nthe model it outputs like empty and a\nstring, you go and call another neural network,\nwhich is a translation",
    "start": "4397275",
    "end": "4403820"
  },
  {
    "text": "and do the translation\nthat pays that back. Another one was doing search\non Wikipedia, for example,",
    "start": "4403820",
    "end": "4410530"
  },
  {
    "text": "or calling a question\nanswering system. And with the right\nset of techniques",
    "start": "4410530",
    "end": "4417560"
  },
  {
    "text": "to teach them how to\noutput these sequences, you can get very interesting\nbehavior of the model",
    "start": "4417560",
    "end": "4423410"
  },
  {
    "text": "and of deciding on the\nfly which tool to use. And yeah, so this is\nbasically-- the program",
    "start": "4423410",
    "end": "4431120"
  },
  {
    "text": "here is not the final\nresult that you want, but it's rather just\na way for to represent",
    "start": "4431120",
    "end": "4437090"
  },
  {
    "text": "this usage of external tools. ",
    "start": "4437090",
    "end": "4442150"
  },
  {
    "text": "Yes. So we talked a little\nbit about this before. So I guess one natural\nquestion for people graduating",
    "start": "4442150",
    "end": "4449290"
  },
  {
    "text": "in computer science is, will\nI have a job after I graduate or will Codex replace me? And as it turns out, in software\nengineering, a lot of time",
    "start": "4449290",
    "end": "4458920"
  },
  {
    "text": "is not spent writing\ncode in the real world. So there's one study,\nbut there are a lot more",
    "start": "4458920",
    "end": "4465219"
  },
  {
    "text": "that show that when you\ntrack developers time, they spent a lot of time just\nreading code, a lot of time",
    "start": "4465220",
    "end": "4474130"
  },
  {
    "text": "outside of the IDE. This is just IDE\ntime, navigating. And 5% is actually editing code.",
    "start": "4474130",
    "end": "4479440"
  },
  {
    "text": "And even editing code a lot of\ntime is not writing new code, but rather like fixing\nbugs and maintaining.",
    "start": "4479440",
    "end": "4487390"
  },
  {
    "text": "So there's quite a\nlot of time that's not spent writing\ncode for people that are paid to write code.",
    "start": "4487390",
    "end": "4492430"
  },
  {
    "text": " Yeah. And there's this whole process\nof deciding what to build,",
    "start": "4492430",
    "end": "4499020"
  },
  {
    "text": "which is usually more\nimportant than just writing, just building the\nthing right then.",
    "start": "4499020",
    "end": "4505820"
  },
  {
    "text": "Yeah, this is still quite\nfar from what Codex can do. And Yeah there's\nthis notion we talked",
    "start": "4505820",
    "end": "4514190"
  },
  {
    "text": "a little bit about that\ndebugging is very interactive. We run, go back,\nrevise, and this process",
    "start": "4514190",
    "end": "4519950"
  },
  {
    "text": "is mostly lost by just\nsampling more from the model and trying again\nbasically from scratch.",
    "start": "4519950",
    "end": "4525700"
  },
  {
    "text": "And there's active\nresearch even here at Stanford on using models also\ntrue to fix bugs automatically.",
    "start": "4525700",
    "end": "4532520"
  },
  {
    "text": "When you write a program\nhas some syntax error, how to go back and maybe\nchange, but it's still",
    "start": "4532520",
    "end": "4539325"
  },
  {
    "text": "very different from the more\nopen ended kind of debugging that people can do.",
    "start": "4539325",
    "end": "4544800"
  },
  {
    "text": "Yeah. Of course, even all\nthe code on GitHub is still not all the code\nthat you can imagine, right?",
    "start": "4544800",
    "end": "4549920"
  },
  {
    "text": "There are new\nlibraries all the time there's internal libraries for\ncompanies that will just not",
    "start": "4549920",
    "end": "4555170"
  },
  {
    "text": "be on GitHub at any point. So there are challenges\nin teaching models to use those as well.",
    "start": "4555170",
    "end": "4562469"
  },
  {
    "text": "And as we mentioned even,\nif models can generate code, they still fail a lot of\ncode understanding challenges",
    "start": "4562470",
    "end": "4570619"
  },
  {
    "text": "like just executing\ncode, for example. Like asking what\nthis code outputs.",
    "start": "4570620",
    "end": "4576690"
  },
  {
    "text": "And even fine\ntuning doesn't seem true to solve that problem. And yeah.",
    "start": "4576690",
    "end": "4582327"
  },
  {
    "text": "And the other thing is\nthat public code also has a lot of bugs,\nas you can imagine. And they're being fixed all the\ntime, so training on buggy code",
    "start": "4582327",
    "end": "4590580"
  },
  {
    "text": "will also mean that sometimes\nyou generate buggy code. And so you still\nhave to understand",
    "start": "4590580",
    "end": "4595679"
  },
  {
    "text": "what the model outputs. And there are security\nbugs that can be introduced",
    "start": "4595680",
    "end": "4601560"
  },
  {
    "text": "by language models as well. And yes, so just to conclude--\na little bit past time--",
    "start": "4601560",
    "end": "4611070"
  },
  {
    "text": "a lot of these capabilities\nwere completely out of reach even a few years ago. So this is a really\nexciting time",
    "start": "4611070",
    "end": "4617400"
  },
  {
    "text": "to be watching this happen. And I think there's a\nfascinating intersection here",
    "start": "4617400",
    "end": "4623220"
  },
  {
    "text": "between natural language,\nwhich is extremely ambiguous and flexible\nand contextual and we do it so easily,\nand programming languages",
    "start": "4623220",
    "end": "4630900"
  },
  {
    "text": "are these extremely\nrigid languages. You forget a\nparentheses and compiler",
    "start": "4630900",
    "end": "4636510"
  },
  {
    "text": "has no idea what you're\ntrying to do anymore. And we can bridge between\nthese two worlds very easily.",
    "start": "4636510",
    "end": "4642570"
  },
  {
    "text": "Now language models\nare also starting to-- and besides models\nthat write programs,",
    "start": "4642570",
    "end": "4648240"
  },
  {
    "text": "programs are also just a general\ninteresting representation for reasoning. You can represent\nmathematics, legal contracts.",
    "start": "4648240",
    "end": "4655710"
  },
  {
    "text": "This notion of calling and\ncombining different tools. Yeah, so all of these are very\nactive topics of research.",
    "start": "4655710",
    "end": "4663650"
  },
  {
    "text": "And so hope you guys enjoy.",
    "start": "4663650",
    "end": "4669580"
  },
  {
    "text": "Yes. ",
    "start": "4669580",
    "end": "4676000"
  }
]
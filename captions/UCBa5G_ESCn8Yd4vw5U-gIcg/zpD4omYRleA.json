[
  {
    "text": "Welcome to Introduction to Machine Learning. This lecture is an- an example and the idea is that we will go through",
    "start": "4460",
    "end": "14790"
  },
  {
    "text": "a very simple example using all of the topics that we've discussed so far and,",
    "start": "14790",
    "end": "21629"
  },
  {
    "text": "uh, take a little bit of look at sort of results one can expect, and also the, uh,",
    "start": "21629",
    "end": "28525"
  },
  {
    "text": "code that's necessary to get it to work.",
    "start": "28525",
    "end": "32910"
  },
  {
    "text": "So this is, uh, a data set that comes from Kaggle.",
    "start": "34300",
    "end": "39830"
  },
  {
    "text": "Kaggle is, uh, a- a Google owned company that, uh, organizes machine learning competitions.",
    "start": "39830",
    "end": "46460"
  },
  {
    "text": "You can go to Kaggle and download, uh, data for a range of different, uh, uh, domains.",
    "start": "46460",
    "end": "56220"
  },
  {
    "text": "In this case, this is, uh, house prices. Uh, Kaggle also keeps, uh,",
    "start": "56220",
    "end": "62355"
  },
  {
    "text": "data sets in Escrow so that one can compare the results of your own machine learning algorithm against,",
    "start": "62355",
    "end": "72159"
  },
  {
    "text": "uh, uh, uh, validation set, which you've not seen before and a lot people haven't seen before.",
    "start": "72160",
    "end": "79610"
  },
  {
    "text": "And it also keeps track of all the people's performance on particular data sets.",
    "start": "79610",
    "end": "84710"
  },
  {
    "text": "So it's a worthwhile place to go to get experience with, uh, trying machine learning in a variety of domains.",
    "start": "84710",
    "end": "91515"
  },
  {
    "text": "Uh, this is a- a data set that consists of, um,",
    "start": "91515",
    "end": "97725"
  },
  {
    "text": "prices and features for 1,456 homes in Ames,",
    "start": "97725",
    "end": "105390"
  },
  {
    "text": "Iowa, and those were homes that were sold between 2006 and 2010.",
    "start": "105390",
    "end": "111860"
  },
  {
    "text": "And, uh, here, our goal is going to be to",
    "start": "111860",
    "end": "118580"
  },
  {
    "text": "try to use the features of the houses in order to predict the price.",
    "start": "118580",
    "end": "124820"
  },
  {
    "text": "And we're gonna focus on predicting the log of the price because the price is- relative price is,",
    "start": "124820",
    "end": "132480"
  },
  {
    "text": "uh, much more important than absolute price and house prices typically vary over a significant range.",
    "start": "132480",
    "end": "139220"
  },
  {
    "text": "Uh, so our performance metric is going to be the RMS error on the test set of the log of the house price.",
    "start": "139220",
    "end": "147750"
  },
  {
    "text": "And in particular, if you have, uh, an RMS error of say, 0.1,",
    "start": "148050",
    "end": "153620"
  },
  {
    "text": "then it means that you can predict hash prices within a factor of e_0.1,",
    "start": "153620",
    "end": "158985"
  },
  {
    "text": "which is about 10.5%. Here's the sort of thing one sees in this data.",
    "start": "158985",
    "end": "165480"
  },
  {
    "text": "Here we have a plot of the target variable, which is the log of the price against one of the,",
    "start": "165480",
    "end": "170629"
  },
  {
    "text": "uh, independent variables, the, uh, living area of the house in this case.",
    "start": "170630",
    "end": "176380"
  },
  {
    "text": "And you can see, well, first of all, there's, uh, uh, uh, a quite a lot of variation.",
    "start": "176380",
    "end": "181500"
  },
  {
    "text": "Just knowing that living area doesn't narrow down the price very much. Um, uh, here we've got, uh,",
    "start": "181500",
    "end": "188910"
  },
  {
    "text": "house prices varying between e_10.5 and e_13 or e_14,",
    "start": "188910",
    "end": "196725"
  },
  {
    "text": "um, which is, uh- must be less than 100,000 to more than 500,000.",
    "start": "196725",
    "end": "205890"
  },
  {
    "text": "And, uh, so we're seeing quite a- quite a variation here.",
    "start": "205890",
    "end": "210730"
  },
  {
    "text": "Now, the data set actually contains some 80 features. We're gonna to use, uh,",
    "start": "214430",
    "end": "221325"
  },
  {
    "text": "maybe, uh, the first, uh, 20 features and, uh,",
    "start": "221325",
    "end": "229379"
  },
  {
    "text": "focus on, uh, those. So for our embedding, uh,",
    "start": "229380",
    "end": "234420"
  },
  {
    "text": "for embedding the, uh, target variable, we're going to let v be the price and y be the log of v,",
    "start": "234420",
    "end": "242055"
  },
  {
    "text": "it-s the log of the price. And then for the independent variables x,",
    "start": "242055",
    "end": "248075"
  },
  {
    "text": "we're going to, uh, embed them as follows. We have, uh, some of those fields of a house record are numerical.",
    "start": "248075",
    "end": "258325"
  },
  {
    "text": "And we- those we can just embed unchanged. So in particular, we have the year the house was built,",
    "start": "258325",
    "end": "264634"
  },
  {
    "text": "the area of the living space, the area of the first floor, the area of the second floor,",
    "start": "264635",
    "end": "270170"
  },
  {
    "text": "the area of the garage, the area of the wooden deck, area of the basement, the year and the last remodel,",
    "start": "270170",
    "end": "276710"
  },
  {
    "text": "and the area of the lot. So all of the areas are in square feet, they're just numbers, and the years are simply years, they're just integers.",
    "start": "276710",
    "end": "285794"
  },
  {
    "text": "And we will just embed those as numbers as they are.",
    "start": "285795",
    "end": "290100"
  },
  {
    "text": "There are also ordinal fields in our features, and, uh, we will embed those as integers.",
    "start": "291300",
    "end": "298945"
  },
  {
    "text": "So we have, uh, number of bedrooms, number of kitchens, number of fireplaces,",
    "start": "298945",
    "end": "304160"
  },
  {
    "text": "number of half bathrooms, number of rooms, condition.",
    "start": "304160",
    "end": "309870"
  },
  {
    "text": "Condition is a number that's scored between 1 and 10 that's assigned by- by an expert,",
    "start": "309870",
    "end": "314889"
  },
  {
    "text": "uh, presumably an appraiser or- or a real- realtor.",
    "start": "314890",
    "end": "320640"
  },
  {
    "text": "We have the quality of the materials and the finish, again, assigned by an expert, with a score between 1 and 10,",
    "start": "320640",
    "end": "326560"
  },
  {
    "text": "and the number of cars that the garage can hold. So these are all small integers,",
    "start": "326560",
    "end": "332125"
  },
  {
    "text": "typically between 0 and 10 and we just embed them as- as they are.",
    "start": "332125",
    "end": "338180"
  },
  {
    "text": "The kitchen quality is, uh, a field which is stored on our Likert scale.",
    "start": "342390",
    "end": "350645"
  },
  {
    "text": "The kitchen is rated excellent, good, typical, fair, or poor, though I don't think there are actually",
    "start": "350645",
    "end": "357050"
  },
  {
    "text": "any entries in the data set that receive the poor rating. And this is encoded as an integer between 1 and 5 after we embed it.",
    "start": "357050",
    "end": "366690"
  },
  {
    "text": "Uh, the building type is a categorical field.",
    "start": "366690",
    "end": "374055"
  },
  {
    "text": "This is embedded one-hot and so it's embedded as a five-dimensional vector,",
    "start": "374055",
    "end": "381550"
  },
  {
    "text": "one of the canonical unit vectors with a 1 in one position and 0 in all the other positions. Uh, the five different categories are single-family,",
    "start": "381550",
    "end": "390900"
  },
  {
    "text": "townhouse end unit, two-family-conversion, townhouse inside unit, and duplex.",
    "start": "390900",
    "end": "398180"
  },
  {
    "text": "Um, there's also a neighborhood field.",
    "start": "398180",
    "end": "403320"
  },
  {
    "text": "There were 25 different neighborhoods. So it's a categorical data field and this is also one-hot embedded.",
    "start": "403320",
    "end": "412445"
  },
  {
    "text": "As a result, we have, looking back at our, uh, fields here,",
    "start": "412445",
    "end": "418300"
  },
  {
    "text": "we have 17 numerical fields.",
    "start": "418300",
    "end": "424229"
  },
  {
    "text": "And we have, uh, uh, the kitchen quality, which is 18,",
    "start": "424230",
    "end": "430770"
  },
  {
    "text": "and then we have, uh, 30 components which are one-hot.",
    "start": "430770",
    "end": "439020"
  },
  {
    "text": "So the total dimension of our X data variable is 48.",
    "start": "439020",
    "end": "448289"
  },
  {
    "text": "And we're gonna add one more, which will be the constant.",
    "start": "448290",
    "end": "451920"
  },
  {
    "text": "Now, when we do the standardization and the data splitting, we do this in a particular way.",
    "start": "455600",
    "end": "461615"
  },
  {
    "text": "So we split the data randomly, 80/20, 80 percent for training and 20 percent for test.",
    "start": "461615",
    "end": "469050"
  },
  {
    "text": "And that gives us, uh, an X_0 training set and a corresponding Y_training,",
    "start": "469050",
    "end": "475409"
  },
  {
    "text": "and an X_0 test set and a corresponding Y_test. Uh, now, the way we do standardization is we use the training",
    "start": "475410",
    "end": "484130"
  },
  {
    "text": "set to compute the means and the standard deviations of each of the features.",
    "start": "484130",
    "end": "489245"
  },
  {
    "text": "So that means we'll get 48 numbers correspond to the means of each column of",
    "start": "489245",
    "end": "495020"
  },
  {
    "text": "X_0 train and 48 numbers correspond to the standard deviations of each column of X_0_train.",
    "start": "495020",
    "end": "502645"
  },
  {
    "text": "And now we can use the means and standard deviations to standardize X_0_train,",
    "start": "502645",
    "end": "508910"
  },
  {
    "text": "um, simply by, uh, subtracting off the means and dividing by the standard deviations.",
    "start": "508910",
    "end": "515945"
  },
  {
    "text": "And we use the same means and standard deviations to standardize the test set.",
    "start": "515945",
    "end": "521485"
  },
  {
    "text": "Now, in particular, here we don't want to use the test set to compute the means and",
    "start": "521485",
    "end": "526790"
  },
  {
    "text": "the standard deviations because that would be including information from our test set into our predictor.",
    "start": "526790",
    "end": "533645"
  },
  {
    "text": "Uh, there's also a particular, uh, caveat that you should be aware of and that is",
    "start": "533645",
    "end": "539579"
  },
  {
    "text": "because th- many of our variables are categorical. It- it often happens that particular columns of X_train are actually all zeros.",
    "start": "539580",
    "end": "551025"
  },
  {
    "text": "There's no data record, for example, that corresponds to a house in a particular neighborhood.",
    "start": "551025",
    "end": "559820"
  },
  {
    "text": "Um, and that will give you a standard deviation of zero. And so if you try to apply the straightforward standardization, uh,",
    "start": "559820",
    "end": "567620"
  },
  {
    "text": "then of course, that will fail because we'll be trying to divide by 0. But that's very simple.",
    "start": "567620",
    "end": "572715"
  },
  {
    "text": "We do it if we simply include that as a column of zeros in the data set.",
    "start": "572715",
    "end": "578070"
  },
  {
    "text": "So after we've standardized both the- the training and the test set using this- these means and standard deviations,",
    "start": "578590",
    "end": "585813"
  },
  {
    "text": "we can then apply- append a constant feature to both of them and then we'll have X_train and X_test,",
    "start": "585814",
    "end": "593753"
  },
  {
    "text": "and X_train will be 1165 by 49 and X_test will be 291 by 49.",
    "start": "593754",
    "end": "603009"
  },
  {
    "text": "So now we're going to do Ridge regression. So we're going to, uh,",
    "start": "607830",
    "end": "613720"
  },
  {
    "text": "use the- remember the RMS Log Price as our performance metric.",
    "start": "613720",
    "end": "620980"
  },
  {
    "text": "And so our loss will be the quadratic loss, we'll be minimizing",
    "start": "620980",
    "end": "627295"
  },
  {
    "text": "the empirical mean square error in the log price.",
    "start": "627295",
    "end": "636760"
  },
  {
    "text": "And, uh, uh, regularization,",
    "start": "636760",
    "end": "642055"
  },
  {
    "text": "we'll use Ridge regression, so we will use the quadratic regularizer.",
    "start": "642055",
    "end": "647000"
  },
  {
    "text": "So remember how we do regularized empirical risk minimization?",
    "start": "647670",
    "end": "653170"
  },
  {
    "text": "We choose a range of lambda values logarithmically spaced. Here we choose them between 10 to the minus 3 and 10 to the 3.",
    "start": "653170",
    "end": "660625"
  },
  {
    "text": "And for each one of those lambdas, we solve the regularized empirical risk minimization problem to find the theta.",
    "start": "660625",
    "end": "667735"
  },
  {
    "text": "We choose a theta, we find the theta that minimizes this quadratic function of the vector theta.",
    "start": "667735",
    "end": "676850"
  },
  {
    "text": "Notice that we've used a capital Y here, even though capital Y here is actually just a vector not a matrix because m is 1,",
    "start": "676850",
    "end": "685785"
  },
  {
    "text": "we've got only a single target variable. Um, and notice also that we're not regularizing the constant term in theta.",
    "start": "685785",
    "end": "696680"
  },
  {
    "text": "Once we've got these, uh, uh, theta values,",
    "start": "697620",
    "end": "704050"
  },
  {
    "text": "I think we have 50 different lambda values and so we get 50 corresponding theta values.",
    "start": "704050",
    "end": "710785"
  },
  {
    "text": "Then, uh, for each one of those theta values,",
    "start": "710785",
    "end": "716829"
  },
  {
    "text": "we can compute the training error simply by computing the RMS of x train times theta minus y train.",
    "start": "716830",
    "end": "725845"
  },
  {
    "text": "That's just a vector. So, uh, we take, uh, the one on",
    "start": "725845",
    "end": "733660"
  },
  {
    "text": "n times the sum of the squares of that vector and then square root that quantity. And similarly, the test error,",
    "start": "733660",
    "end": "740335"
  },
  {
    "text": "X test theta minus y test.",
    "start": "740335",
    "end": "743480"
  },
  {
    "text": "And for this dataset, this is what we see. Here on the left,",
    "start": "746460",
    "end": "751915"
  },
  {
    "text": "we have, uh, two curves,",
    "start": "751915",
    "end": "757149"
  },
  {
    "text": "uh, plotted against theta. We have the empirical risk of the different thetas.",
    "start": "757150",
    "end": "764860"
  },
  {
    "text": "So at any given lambda value, we have a corresponding theta, we have a corresponding test error and a corresponding train error.",
    "start": "764860",
    "end": "772045"
  },
  {
    "text": "We can see that at all thetas the test error is a little- does a little bit worse than the training.",
    "start": "772045",
    "end": "781390"
  },
  {
    "text": "And, in fact, regularization appears to offer no benefit here,",
    "start": "781390",
    "end": "789070"
  },
  {
    "text": "the data is sufficiently- we have a sufficiently large amount of data compared to",
    "start": "789070",
    "end": "794290"
  },
  {
    "text": "the number of features that we have that there's no danger of over fitting.",
    "start": "794290",
    "end": "799584"
  },
  {
    "text": "And as a result, the regularization does little for us.",
    "start": "799585",
    "end": "805525"
  },
  {
    "text": "Um, the minimum RMS error is about 0.12,",
    "start": "805525",
    "end": "813080"
  },
  {
    "text": "which corresponds to about a 13% error in house price.",
    "start": "813180",
    "end": "818425"
  },
  {
    "text": "Over here on the right, we have the plot of theta verses lambda as a regularization path.",
    "start": "818425",
    "end": "825760"
  },
  {
    "text": "We can see that even with lambda about,",
    "start": "825760",
    "end": "830965"
  },
  {
    "text": "uh, 0.1, we're starting to see some shrinkage.",
    "start": "830965",
    "end": "838539"
  },
  {
    "text": "The components of theta are getting smaller without any loss in performance.",
    "start": "838539",
    "end": "843655"
  },
  {
    "text": "So a reasonable choice of lambda would be something of that order,",
    "start": "843655",
    "end": "848815"
  },
  {
    "text": "somewhere between 0.1 and 1.",
    "start": "848815",
    "end": "852680"
  },
  {
    "text": "Here we have the test data and each point on this plot shows two values.",
    "start": "859080",
    "end": "866170"
  },
  {
    "text": "The true price, Y. This is of course the true Log Price and the predicted lower price Y-hat.",
    "start": "866170",
    "end": "877780"
  },
  {
    "text": "And ideally we would expect- we would want to have all points on the diagonal indicating that we've predicted perfectly.",
    "start": "877780",
    "end": "886630"
  },
  {
    "text": "And the points are clustered reasonably well about the diagonal.",
    "start": "886630",
    "end": "892210"
  },
  {
    "text": "We're not doing badly. We have some outliers here and here,",
    "start": "892210",
    "end": "899515"
  },
  {
    "text": "where we are vastly overestimating the price.",
    "start": "899515",
    "end": "906445"
  },
  {
    "text": "Also here. Well, otherwise we're doing okay.",
    "start": "906445",
    "end": "912030"
  },
  {
    "text": "And perhaps one thing one might do after making these kind of predictions is to go back and look at those data",
    "start": "912030",
    "end": "917579"
  },
  {
    "text": "records and figure out why their true price for those is so much less than the predicted price.",
    "start": "917580",
    "end": "925640"
  },
  {
    "text": "We can also look at the theta. The entries of theta tells us something about the importance of the different features.",
    "start": "929120",
    "end": "936825"
  },
  {
    "text": "And we can see that this one, this one,",
    "start": "936825",
    "end": "942505"
  },
  {
    "text": "this one and this one are important features as is this one, this one and this one.",
    "start": "942505",
    "end": "950110"
  },
  {
    "text": "Those are the theta entries that have the largest magnitudes.",
    "start": "950110",
    "end": "955735"
  },
  {
    "text": "They correspond to these seven features.",
    "start": "955735",
    "end": "966325"
  },
  {
    "text": "Four of those are about the size of the house, area of living space, area of first floor,",
    "start": "966325",
    "end": "972250"
  },
  {
    "text": "area of second floor, area of basement. Very reasonable things that would drive the price of a house.",
    "start": "972250",
    "end": "978940"
  },
  {
    "text": "Um, one of them is the year in which it was built. So how new is the house?",
    "start": "978940",
    "end": "984279"
  },
  {
    "text": "And the other two are the experts assessments of the condition and quality.",
    "start": "984280",
    "end": "991045"
  },
  {
    "text": "And so it's quite reasonable to see that these things are as the most important determinants of the,",
    "start": "991045",
    "end": "999774"
  },
  {
    "text": "uh, price of a house. You can also notice that there are interesting points here.",
    "start": "999775",
    "end": "1006945"
  },
  {
    "text": "Um, the last 25 features in x,",
    "start": "1006945",
    "end": "1014655"
  },
  {
    "text": "are one-hot encoding of the neighborhood. And if we look, for example,",
    "start": "1014655",
    "end": "1021884"
  },
  {
    "text": "at this point and this point, this one's about 0.02 and this one is about minus 0.02.",
    "start": "1021885",
    "end": "1031380"
  },
  {
    "text": "And that means that, if I",
    "start": "1031380",
    "end": "1036555"
  },
  {
    "text": "move from this neighborhood over here to this neighborhood over here,",
    "start": "1036555",
    "end": "1042900"
  },
  {
    "text": "well then this first component here, the 30, first 32nd,",
    "start": "1042900",
    "end": "1050580"
  },
  {
    "text": "33rd component of x switches from a 1 to a 0.",
    "start": "1050580",
    "end": "1057630"
  },
  {
    "text": "And the 30th component of x switches from a 0 to a 1.",
    "start": "1057630",
    "end": "1064200"
  },
  {
    "text": "And so my contribution of theta transpose times",
    "start": "1064200",
    "end": "1071070"
  },
  {
    "text": "x from those two components changes from minus 0.02 to plus 0.02,",
    "start": "1071070",
    "end": "1078884"
  },
  {
    "text": "which means that the house price changed by about 4%.",
    "start": "1078885",
    "end": "1085005"
  },
  {
    "text": "So just by moving from one neighborhood to another, we can see that much change in house price.",
    "start": "1085005",
    "end": "1092370"
  },
  {
    "text": "And these- these last few entries of theta tells us which are",
    "start": "1092370",
    "end": "1098850"
  },
  {
    "text": "the desirable neighborhoods and which are the undesirable neighborhoods.",
    "start": "1098850",
    "end": "1103059"
  },
  {
    "text": "Okay. Let's take a look at the code. Um, first of all,",
    "start": "1106400",
    "end": "1112710"
  },
  {
    "text": "we can just run it and see, uh, if it does what we think it should do.",
    "start": "1112710",
    "end": "1118210"
  },
  {
    "text": "Let's include, the file is called house.jl.",
    "start": "1118550",
    "end": "1126070"
  },
  {
    "text": "And, uh- The main function here is what we're going to run,",
    "start": "1128690",
    "end": "1136269"
  },
  {
    "text": "and that should do the computation, uh, produce the plots.",
    "start": "1138470",
    "end": "1147495"
  },
  {
    "text": "Every time you run it it will produce slightly different plots because remember the test and train split is chosen randomly.",
    "start": "1147495",
    "end": "1154830"
  },
  {
    "text": "Uh, we can see here, this is just the raw data file.",
    "start": "1154830",
    "end": "1161370"
  },
  {
    "text": "Uh, this is another piece of raw data.",
    "start": "1161370",
    "end": "1165850"
  },
  {
    "text": "Here we can see, I think, these features we can see what we- what we've plotted here.",
    "start": "1166430",
    "end": "1172995"
  },
  {
    "text": "Uh, no.",
    "start": "1172995",
    "end": "1178380"
  },
  {
    "text": "So this code will be available on the website. Uh, there are two files in particular; house.jl,",
    "start": "1178380",
    "end": "1185085"
  },
  {
    "text": "which does all the computation, and then there's another file called houseplots.jl.",
    "start": "1185085",
    "end": "1192370"
  },
  {
    "text": "And houseplots.jl does the plotting. That one requires PyPlot",
    "start": "1192500",
    "end": "1203235"
  },
  {
    "text": "where you'll have to modify it to use whatever plotting package you are using.",
    "start": "1203235",
    "end": "1209565"
  },
  {
    "text": "Uh, so here we are plotting two things; we're plo- plotting the lot area and the living area.",
    "start": "1209565",
    "end": "1215945"
  },
  {
    "text": "And so, uh, versus price, and so here are our two features. This is, uh, living area,",
    "start": "1215945",
    "end": "1223510"
  },
  {
    "text": "um, and this is lot area. And we can see that there's quite a few, uh,",
    "start": "1223510",
    "end": "1228915"
  },
  {
    "text": "really extremely large, uh, houses which shift, which are already outliers in our data set.",
    "start": "1228915",
    "end": "1237480"
  },
  {
    "text": "Uh, and so if we were to go through and, uh, remove those or adjust for those in some way,",
    "start": "1237480",
    "end": "1245054"
  },
  {
    "text": "we might find ourselves doing slightly better in our fits.",
    "start": "1245055",
    "end": "1249940"
  },
  {
    "text": "One can open the data file in a spreadsheet,",
    "start": "1254030",
    "end": "1259470"
  },
  {
    "text": "and one can see the 1,500 or so different records and the corresponding 80 or so different fields.",
    "start": "1259470",
    "end": "1269160"
  },
  {
    "text": "[NOISE] Now, if we look at the plots that were generated,",
    "start": "1269160",
    "end": "1274775"
  },
  {
    "text": "this is our regularization path. That's a- now I don't need the plotting file anymore.",
    "start": "1274775",
    "end": "1287070"
  },
  {
    "text": "This is our test and train errors as a function of Lambda,",
    "start": "1287070",
    "end": "1293889"
  },
  {
    "text": "and what's back there is our prediction versus true value.",
    "start": "1294620",
    "end": "1301360"
  },
  {
    "text": "Let's take a look at how this works.",
    "start": "1302780",
    "end": "1306190"
  },
  {
    "text": "Uh, so I have two windows on the screen;",
    "start": "1307820",
    "end": "1315750"
  },
  {
    "text": "one is my Julia terminal, and the other is my editor containing the Julia code.",
    "start": "1315750",
    "end": "1321585"
  },
  {
    "text": "This Julia code is about 150 lines long to do everything that we did today.",
    "start": "1321585",
    "end": "1327885"
  },
  {
    "text": "Um, uh, the first thing it does is it loads the data.",
    "start": "1327885",
    "end": "1334500"
  },
  {
    "text": "We can just take that and paste it into here. Uh, that gives us two things; it gives us D,",
    "start": "1334500",
    "end": "1342585"
  },
  {
    "text": "which is a matrix, which is an array of strings, 1,456 rows by 81 columns.",
    "start": "1342585",
    "end": "1350924"
  },
  {
    "text": "The 81 different fields, I guess the first field there is the identify- an identifier,",
    "start": "1350925",
    "end": "1356760"
  },
  {
    "text": "this was 80 different fields. And every entry in this matrix is a string,",
    "start": "1356760",
    "end": "1363900"
  },
  {
    "text": "and that's loaded by a function at the top of this file called load data,",
    "start": "1363900",
    "end": "1370350"
  },
  {
    "text": "which doesn't do anything very interesting, it just calls the CSV library to load it. It does one thing here,",
    "start": "1370350",
    "end": "1377070"
  },
  {
    "text": "which is it removes, uh, what turns out to be a couple of outliers. There were four of them,",
    "start": "1377070",
    "end": "1382755"
  },
  {
    "text": "which have, um, uh, living area greater than 4,000 square feet, and those are, uh,",
    "start": "1382755",
    "end": "1389940"
  },
  {
    "text": "uh, really quite extraordinary, uh, houses in this data set.",
    "start": "1389940",
    "end": "1396240"
  },
  {
    "text": "So we'll remove those, and then it just returns for us the data D and the header,",
    "start": "1396240",
    "end": "1402690"
  },
  {
    "text": "which is a list of the field names.",
    "start": "1402690",
    "end": "1406990"
  },
  {
    "text": "Now we can take n as the number of records we're going to have.",
    "start": "1410990",
    "end": "1417090"
  },
  {
    "text": "It's the- now we do two embeddings; one is Y, so embedy.",
    "start": "1417090",
    "end": "1423840"
  },
  {
    "text": "Let's take a look at that. What that does? This is the function definition here, it's a one line function definition.",
    "start": "1423840",
    "end": "1432495"
  },
  {
    "text": "Um, uh, some things to notice. Uh, let's, uh, let's take a look at this.",
    "start": "1432495",
    "end": "1437700"
  },
  {
    "text": "Uh, so getdatafield si- simply pulls out, uh, that column of the data.",
    "start": "1437700",
    "end": "1446485"
  },
  {
    "text": "So there's the prices. Um, let's just call that something u. Oops.",
    "start": "1446485",
    "end": "1456100"
  },
  {
    "text": "There we go. And in a stringtonumber- these are all strings just from the way the CSV format is stored.",
    "start": "1458030",
    "end": "1466065"
  },
  {
    "text": "So we can stringtonumber it. Let's just call that u1, and now we've got an array of floating-point numbers.",
    "start": "1466065",
    "end": "1474795"
  },
  {
    "text": "Now, one thing to notice about this, this is a feature of Julia that's worth being aware of, is the dot notation.",
    "start": "1474795",
    "end": "1481245"
  },
  {
    "text": "So, uh, stringtonumber will",
    "start": "1481245",
    "end": "1487260"
  },
  {
    "text": "happily take a string and return you back a number.",
    "start": "1487260",
    "end": "1493200"
  },
  {
    "text": "But actually what u is, it's not a string, it's- it's an array of strings or a list of strings,",
    "start": "1493200",
    "end": "1498465"
  },
  {
    "text": "and so by using the dot notation,",
    "start": "1498465",
    "end": "1502029"
  },
  {
    "text": "so if we were to call stringtonumber on just u, it would say error.",
    "start": "1504890",
    "end": "1510840"
  },
  {
    "text": "This u can't call the function that stringtonumber calls,",
    "start": "1510840",
    "end": "1516570"
  },
  {
    "text": "which is the parse function on an array. But you can, um, do this,",
    "start": "1516570",
    "end": "1523170"
  },
  {
    "text": "and what that does is it cause- causes stringtonumber to be applied to each entry of the array u,",
    "start": "1523170",
    "end": "1529904"
  },
  {
    "text": "and it constructs an array of the results. So if I give it an, uh,",
    "start": "1529905",
    "end": "1535140"
  },
  {
    "text": "an array of strings,",
    "start": "1535140",
    "end": "1541890"
  },
  {
    "text": "it will happily give me back an array of numbers if I call it with the dot.",
    "start": "1541890",
    "end": "1552885"
  },
  {
    "text": "And so we're just applying stringtonumber to each of the entries of that data record.",
    "start": "1552885",
    "end": "1559470"
  },
  {
    "text": "Um, that's what u_1 is, and then we're applying the log to each of the entries of that to get Y.",
    "start": "1559470",
    "end": "1566655"
  },
  {
    "text": "And so if I call embedy D header,",
    "start": "1566655",
    "end": "1573060"
  },
  {
    "text": "it returns me back a vector which is the log of all the prices. That's what Y is.",
    "start": "1573060",
    "end": "1579820"
  },
  {
    "text": "Now, we can, uh, embedx. This is substantially more complicated because we got a bunch of different fields.",
    "start": "1585230",
    "end": "1594690"
  },
  {
    "text": "Uh, let's take a look at that. First of all, let's see what it does.",
    "start": "1594690",
    "end": "1599350"
  },
  {
    "text": "That returns for us x, which is our 1,456 by 48 array of the different fields that we have,",
    "start": "1601010",
    "end": "1613169"
  },
  {
    "text": "20 fields, some of which are encoded as one-hot, and so they correspond to more than one column of this matrix,",
    "start": "1613170",
    "end": "1620009"
  },
  {
    "text": "and all of our data records, all 1,456 different houses.",
    "start": "1620009",
    "end": "1625210"
  },
  {
    "text": "Now the way this works is that, um, uh, in the embedx function here,",
    "start": "1627080",
    "end": "1633330"
  },
  {
    "text": "this is the function definition. Uh, we can see these two convenient functions defined at the top.",
    "start": "1633330",
    "end": "1640830"
  },
  {
    "text": "These are just for convenience. What they do is they're closures, they store the value of D and header so that whenever I call",
    "start": "1640830",
    "end": "1650505"
  },
  {
    "text": "field name inside this function embedx,",
    "start": "1650505",
    "end": "1655785"
  },
  {
    "text": "I don't need to supply D and header. And so when I call real fname,",
    "start": "1655785",
    "end": "1661320"
  },
  {
    "text": "that's just the same as calling stringtonumber dot of getdatafield of D header name.",
    "start": "1661320",
    "end": "1668835"
  },
  {
    "text": "So realf here stands for real field, and so what we're doing is we are, uh,",
    "start": "1668835",
    "end": "1675570"
  },
  {
    "text": "we can define these functions in the Julia loop here on the left.",
    "start": "1675570",
    "end": "1683264"
  },
  {
    "text": "And now if I do realf of YearBuilt,",
    "start": "1683265",
    "end": "1688545"
  },
  {
    "text": "we can see what it's gonna do. It's gonna stringtonumber the data field corresponding to YearBuilt,",
    "start": "1688545",
    "end": "1695080"
  },
  {
    "text": "which is just a list of those numbers. And we can do- we do this for each one of these.",
    "start": "1695080",
    "end": "1702690"
  },
  {
    "text": "Let me get simply a list of the corresponding field numbers.",
    "start": "1704840",
    "end": "1712390"
  },
  {
    "text": "Now we can also look at, um, uh, some of the more complicated ones.",
    "start": "1712880",
    "end": "1719655"
  },
  {
    "text": "One here that's more complicated is the, uh, kitchen quality field.",
    "start": "1719655",
    "end": "1725684"
  },
  {
    "text": "If we look at the- the kitchen quality field, that's a likert scale, the entries in it.",
    "start": "1725685",
    "end": "1734640"
  },
  {
    "text": "Uh, Gd for good, TA, for typical, excellent and, uh, uh,",
    "start": "1734640",
    "end": "1743610"
  },
  {
    "text": "there may be- uh, there are others, we can, uh, unique that and see all of the unique entries in it.",
    "start": "1743610",
    "end": "1749325"
  },
  {
    "text": "Good, typical, excellent or fair. The unlikert function, um,",
    "start": "1749325",
    "end": "1758625"
  },
  {
    "text": "what that does is it maps these particular strings to numbers.",
    "start": "1758625",
    "end": "1766725"
  },
  {
    "text": "Here it is. So unlikert sets up a dictionary which maps Ex to 5,",
    "start": "1766725",
    "end": "1774390"
  },
  {
    "text": "good to 4, TA to 3, fair to 2 and poor to 1, and returns the corresponding number.",
    "start": "1774390",
    "end": "1782610"
  },
  {
    "text": "And so if I apply unlikert to that,",
    "start": "1782610",
    "end": "1792645"
  },
  {
    "text": "I get a list of numbers. Notice the dot again, because I'm applying the unlikert function to each entry",
    "start": "1792645",
    "end": "1800370"
  },
  {
    "text": "of the array separately and returning back an array of the results. Uh, there's one more little piece",
    "start": "1800370",
    "end": "1808200"
  },
  {
    "text": "of conversion that goes on and that's the one-hot conversion. If I look at, say the field building type,",
    "start": "1808200",
    "end": "1814650"
  },
  {
    "text": "let's look at the smaller of the two. And that again is a list of strings.",
    "start": "1814650",
    "end": "1820785"
  },
  {
    "text": "It's categories, five different possible categories. We can look at what they are by doing unique.",
    "start": "1820785",
    "end": "1826815"
  },
  {
    "text": "There are the five categories. And the one-hot here,",
    "start": "1826815",
    "end": "1833505"
  },
  {
    "text": "one-hot does not apply work entry-wise, one-hot works on the entire list of 1456 strings.",
    "start": "1833505",
    "end": "1841665"
  },
  {
    "text": "And it simply finds the categories which are here, uh, unique. u, so we have u is equal to that.",
    "start": "1841665",
    "end": "1852885"
  },
  {
    "text": "Unique of u is gonna be the categories, and then it constructs a matrix which is- each row is a canonical unit vector,",
    "start": "1852885",
    "end": "1862350"
  },
  {
    "text": "which is five dimensional, which is five is the number of categories. So we can see what it does if we do one-hot of u,",
    "start": "1862350",
    "end": "1871065"
  },
  {
    "text": "there's our one-hot encoded building types.",
    "start": "1871065",
    "end": "1876850"
  },
  {
    "text": "Here we have hcat, which joins all of these columns together into one large matrix.",
    "start": "1877700",
    "end": "1885570"
  },
  {
    "text": "And so that if I call embedx, I get the large matrix of all of our data.",
    "start": "1885570",
    "end": "1898270"
  },
  {
    "text": "Now, test- trainrows and testrows are just lists of rows which are randomly selected.",
    "start": "1899120",
    "end": "1905040"
  },
  {
    "text": "Split there is 80-20, when we call it, we'll get a new split. Let's see what that looks like.",
    "start": "1905040",
    "end": "1912000"
  },
  {
    "text": "Yeah, so train rows just says, \"Well, you should use these particular rows as your training set.\"",
    "start": "1912000",
    "end": "1918945"
  },
  {
    "text": "and these particular rows is your test set and their- that's all of the rows together and that's a- there's a disjoint.",
    "start": "1918945",
    "end": "1928360"
  },
  {
    "text": "Now what we do is we split up the feet, the- the data set. Applysplits does the- um,",
    "start": "1929480",
    "end": "1940049"
  },
  {
    "text": "does the- the thing you might expect. Let's look at what applysplit does, applysplit simply splits the data,",
    "start": "1940050",
    "end": "1949154"
  },
  {
    "text": "picks out the corresponding rows for the train and the test set.",
    "start": "1949155",
    "end": "1953770"
  },
  {
    "text": "Let me just run that, and now I've got an Xtrain0, and an Xtest0.",
    "start": "1960680",
    "end": "1972580"
  },
  {
    "text": "My sets of features corresponding to the training and the test sets, and the corresponding Y's.",
    "start": "1973160",
    "end": "1981010"
  },
  {
    "text": "Now the getstatistics function gets the means and the standard deviations of each column very simply.",
    "start": "1981740",
    "end": "1990700"
  },
  {
    "text": "So let's look at what that does.",
    "start": "1993050",
    "end": "1996490"
  },
  {
    "text": "So now how many means have I got? I've got 48 means because Xtrain0, remember,",
    "start": "2000430",
    "end": "2006710"
  },
  {
    "text": "had 48 columns and certainly I've got, uh, 48 standard deviations. You can see there's quite a variation,",
    "start": "2006710",
    "end": "2012950"
  },
  {
    "text": "um, in their, uh, means and in their standard deviations,",
    "start": "2012950",
    "end": "2018155"
  },
  {
    "text": "which is why it's important to, uh, standardize. Uh, standardizeplusone, convenience function that goes through and,",
    "start": "2018155",
    "end": "2031640"
  },
  {
    "text": "uh, does the standardization transformation along each column. Divides, subtracts the mean and divides by the standard deviation.",
    "start": "2031640",
    "end": "2038000"
  },
  {
    "text": "Except in the case when the standard deviation is 0, which can happen. In which case, we simply subtract the mean.",
    "start": "2038000",
    "end": "2045360"
  },
  {
    "text": "And then does one more thing after doing the standardization, which is it appends a column of 1s.",
    "start": "2047050",
    "end": "2054649"
  },
  {
    "text": "Of course we can't do that before standardizing because that will just have its mean subtracted off.",
    "start": "2054650",
    "end": "2061310"
  },
  {
    "text": "So if we do that to Xtrain and Xtest, well that gives us our true Xtrain and Xtest from Xtrain0 and Xtest0.",
    "start": "2061310",
    "end": "2069810"
  },
  {
    "text": "Now we're constructing lambdas, this is our list of lambdas. Note, what we're doing here is dot to the power of, which means, again,",
    "start": "2072040",
    "end": "2081500"
  },
  {
    "text": "it's a broadcasting call of the function, call to the function power this time, so it applies 10 to the power of each of the elements of the range.",
    "start": "2081500",
    "end": "2091010"
  },
  {
    "text": "So we have the range here which is between, uh, uh, minus 3 and 3, that's a- has",
    "start": "2091010",
    "end": "2098060"
  },
  {
    "text": "a particular datatype which is a code on in, it's a range. If you want to see it as a list, you can by doing collect,",
    "start": "2098060",
    "end": "2104795"
  },
  {
    "text": "and then you'll see it as a list. I do lambdas to it,",
    "start": "2104795",
    "end": "2111599"
  },
  {
    "text": "then I'll get my list of logarithmically spaced between 10 to the minus 3,",
    "start": "2112540",
    "end": "2118100"
  },
  {
    "text": "and 10 to the 3 lambdas. Then we do- we do the ridge regression.",
    "start": "2118100",
    "end": "2124339"
  },
  {
    "text": "We've seen that function before, this is applying it one by one to each of the lambdas.",
    "start": "2124340",
    "end": "2129664"
  },
  {
    "text": "For each lambda in lambdas, call ridge regression to give me a, which returns a Theta and make a list of the Thetas.",
    "start": "2129665",
    "end": "2137869"
  },
  {
    "text": "That's what this notation means, this is called a list comprehension. If we run it, there we go.",
    "start": "2137870",
    "end": "2149000"
  },
  {
    "text": "We've got a list of Thetas, we can look at the size of the Thetas variable. And it's just a 50 dimensional list.",
    "start": "2149000",
    "end": "2156110"
  },
  {
    "text": "Theta's one, the first entry is a 49 dimensional vector and same for the other.",
    "start": "2156110",
    "end": "2163775"
  },
  {
    "text": "Each one of those is the Theta corresponding to a lambda.",
    "start": "2163775",
    "end": "2169589"
  },
  {
    "text": "Now for each one of those, we do another little for loop here, another list comprehension for each Theta,",
    "start": "2172930",
    "end": "2180394"
  },
  {
    "text": "we compute Xtrain times Theta, which is, remember, the prediction of Y on the training set elements.",
    "start": "2180394",
    "end": "2188299"
  },
  {
    "text": "And we compute the RMS error of all of the training elements, and the same for the test errors.",
    "start": "2188300",
    "end": "2195869"
  },
  {
    "text": "So now we can do one more thing, which is find the minimum of the test errors.",
    "start": "2196750",
    "end": "2202590"
  },
  {
    "text": "Here, this tells us that the 16th element of test errors was the smallest and the corresponding test error is 0.122.",
    "start": "2202930",
    "end": "2212390"
  },
  {
    "text": "We can also see what the corresponding Theta is, by looking at the corresponding entry of Theta,",
    "start": "2212390",
    "end": "2218780"
  },
  {
    "text": "we can see what the corresponding lambda is. There's the corresponding lambda.",
    "start": "2218780",
    "end": "2226710"
  },
  {
    "text": "And we can just work out what those are, right there. And everything else, and now it's printing.",
    "start": "2226930",
    "end": "2233450"
  },
  {
    "text": "We print our results.",
    "start": "2233450",
    "end": "2238829"
  },
  {
    "text": "Printing optimal train, optimal test, optimal lambda, and optimal Theta.",
    "start": "2243100",
    "end": "2250205"
  },
  {
    "text": "Uh, and then there's a plotting which we'll go through and make the plots that you saw,",
    "start": "2250205",
    "end": "2255245"
  },
  {
    "text": "it needs all of these data elements to do that. And this is really how one would",
    "start": "2255245",
    "end": "2263060"
  },
  {
    "text": "do everything that we've seen so far in the class to do with regression. We can create more complicated features for X,",
    "start": "2263060",
    "end": "2271055"
  },
  {
    "text": "we can create, for example, uh, more one-hot features for- instead of our, uh,",
    "start": "2271055",
    "end": "2280550"
  },
  {
    "text": "simple real number embedding of our ordinals, we could create product features and,",
    "start": "2280550",
    "end": "2288155"
  },
  {
    "text": "uh, we could pick out the outliers. Uh, and there's a few things we could do.",
    "start": "2288155",
    "end": "2293390"
  },
  {
    "text": "Now in fact, for this dataset, none of those things seems to make a great deal of difference,",
    "start": "2293390",
    "end": "2298700"
  },
  {
    "text": "um, which is why we haven't done them. Now, we'll see other examples where we can do some of the more fancy things that,",
    "start": "2298700",
    "end": "2308270"
  },
  {
    "text": "uh, involve more fancy embeddings and more fancy regularizations.",
    "start": "2308270",
    "end": "2313830"
  }
]
[
  {
    "start": "0",
    "end": "67000"
  },
  {
    "text": "[Music]",
    "start": "1130",
    "end": "14690"
  },
  {
    "text": "all right thanks for coming out",
    "start": "16320",
    "end": "17359"
  },
  {
    "text": "everybody",
    "start": "17359",
    "end": "18640"
  },
  {
    "text": "really excited to present some work i've",
    "start": "18640",
    "end": "20320"
  },
  {
    "text": "been working on over the last few months",
    "start": "20320",
    "end": "22080"
  },
  {
    "text": "that has to do with training",
    "start": "22080",
    "end": "23359"
  },
  {
    "text": "interpretable machine learning models",
    "start": "23359",
    "end": "24960"
  },
  {
    "text": "and coming up with ways to turn those",
    "start": "24960",
    "end": "27119"
  },
  {
    "text": "machine learning models into yara rules",
    "start": "27119",
    "end": "31439"
  },
  {
    "text": "it's really quick just to introduce",
    "start": "31439",
    "end": "32719"
  },
  {
    "text": "myself my name is andrew davis i'm a",
    "start": "32719",
    "end": "34480"
  },
  {
    "text": "principal data scientist at elastic i've",
    "start": "34480",
    "end": "36239"
  },
  {
    "text": "been there for about nine months now",
    "start": "36239",
    "end": "38320"
  },
  {
    "text": "and generally speaking i've been",
    "start": "38320",
    "end": "39520"
  },
  {
    "text": "teaching computers how to detect malware",
    "start": "39520",
    "end": "41360"
  },
  {
    "text": "since about 2014. so i've trained a",
    "start": "41360",
    "end": "43040"
  },
  {
    "text": "variety of malware classifiers such as",
    "start": "43040",
    "end": "44879"
  },
  {
    "text": "malware classifiers to target windows",
    "start": "44879",
    "end": "47280"
  },
  {
    "text": "pes",
    "start": "47280",
    "end": "48719"
  },
  {
    "text": "osx macos linux elfs uptrend models that",
    "start": "48719",
    "end": "52000"
  },
  {
    "text": "detect things detect malware inside of",
    "start": "52000",
    "end": "54160"
  },
  {
    "text": "pdfs inside of rtfs inside of docs and",
    "start": "54160",
    "end": "57199"
  },
  {
    "text": "things like that so training machine",
    "start": "57199",
    "end": "59280"
  },
  {
    "text": "learning models on mower is kind of my",
    "start": "59280",
    "end": "61280"
  },
  {
    "text": "bread and butter",
    "start": "61280",
    "end": "63600"
  },
  {
    "text": "so really quick intro and motivation",
    "start": "63600",
    "end": "66560"
  },
  {
    "text": "um",
    "start": "66560",
    "end": "67360"
  },
  {
    "start": "67000",
    "end": "67000"
  },
  {
    "text": "first of all yar is a really great line",
    "start": "67360",
    "end": "69600"
  },
  {
    "text": "first defense against malware if you can",
    "start": "69600",
    "end": "72159"
  },
  {
    "text": "extract a sequence of bytes from a piece",
    "start": "72159",
    "end": "74000"
  },
  {
    "text": "of malware and if it can slam dunk 100",
    "start": "74000",
    "end": "76080"
  },
  {
    "text": "of the time detect that piece of malware",
    "start": "76080",
    "end": "77920"
  },
  {
    "text": "it's really quick to sort of roll all",
    "start": "77920",
    "end": "79280"
  },
  {
    "text": "these ur rules to be able to detect new",
    "start": "79280",
    "end": "81360"
  },
  {
    "text": "particular kinds of variants",
    "start": "81360",
    "end": "83520"
  },
  {
    "text": "deep learning on the other hand has been",
    "start": "83520",
    "end": "85600"
  },
  {
    "text": "used as a very effective way of",
    "start": "85600",
    "end": "87360"
  },
  {
    "text": "detecting malware but unfortunately its",
    "start": "87360",
    "end": "89439"
  },
  {
    "text": "decisions are usually incomprehensible",
    "start": "89439",
    "end": "91040"
  },
  {
    "text": "in the way that the models are usually",
    "start": "91040",
    "end": "92400"
  },
  {
    "text": "sell",
    "start": "92400",
    "end": "93280"
  },
  {
    "text": "so the typical deep learning model is",
    "start": "93280",
    "end": "94960"
  },
  {
    "text": "set up in such a way that you have an",
    "start": "94960",
    "end": "97439"
  },
  {
    "text": "input of a malware sample coming in and",
    "start": "97439",
    "end": "99840"
  },
  {
    "text": "then you have a score for the malware",
    "start": "99840",
    "end": "101119"
  },
  {
    "text": "sample at the end but it's really hard",
    "start": "101119",
    "end": "102640"
  },
  {
    "text": "to trace back and figure out what the",
    "start": "102640",
    "end": "104079"
  },
  {
    "text": "model was thinking to come up with a",
    "start": "104079",
    "end": "105920"
  },
  {
    "text": "decision to call something malicious or",
    "start": "105920",
    "end": "107520"
  },
  {
    "text": "benign",
    "start": "107520",
    "end": "109439"
  },
  {
    "text": "on the other hand deep learning models",
    "start": "109439",
    "end": "111040"
  },
  {
    "text": "are very very very flexible in the sense",
    "start": "111040",
    "end": "113600"
  },
  {
    "text": "that you can",
    "start": "113600",
    "end": "115119"
  },
  {
    "text": "set up a deep learning model to do",
    "start": "115119",
    "end": "116719"
  },
  {
    "text": "something really simple like you know",
    "start": "116719",
    "end": "118560"
  },
  {
    "text": "just a fully connected deep neural",
    "start": "118560",
    "end": "120000"
  },
  {
    "text": "network or you can do something really",
    "start": "120000",
    "end": "121600"
  },
  {
    "text": "complicated like a transformer model or",
    "start": "121600",
    "end": "124159"
  },
  {
    "text": "an attention model",
    "start": "124159",
    "end": "125680"
  },
  {
    "text": "and in this way you can come up with",
    "start": "125680",
    "end": "127600"
  },
  {
    "text": "ways to make the model interpretable",
    "start": "127600",
    "end": "130319"
  },
  {
    "text": "from the get-go in other words structure",
    "start": "130319",
    "end": "132720"
  },
  {
    "text": "your model in such a way that when you",
    "start": "132720",
    "end": "134959"
  },
  {
    "text": "look at",
    "start": "134959",
    "end": "136000"
  },
  {
    "text": "the model's decision-making you can come",
    "start": "136000",
    "end": "138160"
  },
  {
    "text": "up with ways to figure out why the model",
    "start": "138160",
    "end": "140160"
  },
  {
    "text": "made that decision",
    "start": "140160",
    "end": "141599"
  },
  {
    "text": "so what we're going to do in this talk",
    "start": "141599",
    "end": "142959"
  },
  {
    "text": "is i'm going to show you a way to set up",
    "start": "142959",
    "end": "144640"
  },
  {
    "text": "a deep learning model that's",
    "start": "144640",
    "end": "145599"
  },
  {
    "text": "interpretable from the get-go and you",
    "start": "145599",
    "end": "147680"
  },
  {
    "text": "can take that interpretability and turn",
    "start": "147680",
    "end": "150080"
  },
  {
    "text": "that into your rules",
    "start": "150080",
    "end": "153360"
  },
  {
    "text": "so there's a lot of related work on the",
    "start": "153360",
    "end": "154800"
  },
  {
    "text": "subject",
    "start": "154800",
    "end": "156640"
  },
  {
    "text": "there's one particular paper by a",
    "start": "156640",
    "end": "158720"
  },
  {
    "text": "giraffe and a bunch of other authors",
    "start": "158720",
    "end": "160480"
  },
  {
    "text": "called automatic ur role generation",
    "start": "160480",
    "end": "162080"
  },
  {
    "text": "using by clustering",
    "start": "162080",
    "end": "163760"
  },
  {
    "text": "and in this talk they",
    "start": "163760",
    "end": "165440"
  },
  {
    "text": "work on this previous idea of kilo",
    "start": "165440",
    "end": "167519"
  },
  {
    "text": "engrams where they take these long byte",
    "start": "167519",
    "end": "169280"
  },
  {
    "text": "sequences",
    "start": "169280",
    "end": "170560"
  },
  {
    "text": "and they take this idea and come up with",
    "start": "170560",
    "end": "173040"
  },
  {
    "text": "a way to cluster them together and come",
    "start": "173040",
    "end": "175120"
  },
  {
    "text": "up with complex ands and ors and other",
    "start": "175120",
    "end": "177519"
  },
  {
    "text": "things of strings and be able to make",
    "start": "177519",
    "end": "179280"
  },
  {
    "text": "workable yar rules based on small",
    "start": "179280",
    "end": "180879"
  },
  {
    "text": "purposes",
    "start": "180879",
    "end": "182080"
  },
  {
    "text": "so you can feed in a single sample or a",
    "start": "182080",
    "end": "183920"
  },
  {
    "text": "number of samples and it'll generate you",
    "start": "183920",
    "end": "185760"
  },
  {
    "text": "a rule that has a high true positive",
    "start": "185760",
    "end": "187680"
  },
  {
    "text": "rate and a low false positive rate for",
    "start": "187680",
    "end": "189120"
  },
  {
    "text": "the samples you're sending in",
    "start": "189120",
    "end": "190959"
  },
  {
    "text": "there's another",
    "start": "190959",
    "end": "192239"
  },
  {
    "text": "similar one called yayajan what it does",
    "start": "192239",
    "end": "194720"
  },
  {
    "text": "is it looks at",
    "start": "194720",
    "end": "196640"
  },
  {
    "text": "kooky logs for android apks so you send",
    "start": "196640",
    "end": "199680"
  },
  {
    "text": "in an android apk to this particular",
    "start": "199680",
    "end": "201599"
  },
  {
    "text": "android sandbox you detonate the sample",
    "start": "201599",
    "end": "204239"
  },
  {
    "text": "and then this thing is able to look at",
    "start": "204239",
    "end": "205920"
  },
  {
    "text": "the detonation report and come up with",
    "start": "205920",
    "end": "207519"
  },
  {
    "text": "yara rules to detect new variants of",
    "start": "207519",
    "end": "209760"
  },
  {
    "text": "malware based on the",
    "start": "209760",
    "end": "211599"
  },
  {
    "text": "ur rules that it outputs from the um",
    "start": "211599",
    "end": "214560"
  },
  {
    "text": "from the sandbox detonation",
    "start": "214560",
    "end": "217680"
  },
  {
    "text": "and finally there's a really cool",
    "start": "217680",
    "end": "218959"
  },
  {
    "text": "project by joshua sachs called erml the",
    "start": "218959",
    "end": "221920"
  },
  {
    "text": "way it works is you",
    "start": "221920",
    "end": "224640"
  },
  {
    "text": "take a logistic regression or random",
    "start": "224640",
    "end": "227040"
  },
  {
    "text": "forest model and then use some clever",
    "start": "227040",
    "end": "229519"
  },
  {
    "text": "sort of hacks to figure out how to turn",
    "start": "229519",
    "end": "231599"
  },
  {
    "text": "that logistic regression model into the",
    "start": "231599",
    "end": "233439"
  },
  {
    "text": "r rule or change that random forest",
    "start": "233439",
    "end": "235760"
  },
  {
    "text": "model into the url rule",
    "start": "235760",
    "end": "239959"
  },
  {
    "start": "240000",
    "end": "240000"
  },
  {
    "text": "so how do we make an interpretable model",
    "start": "240400",
    "end": "242879"
  },
  {
    "text": "so as i was saying before deep learning",
    "start": "242879",
    "end": "244560"
  },
  {
    "text": "models look at sort of the whole of the",
    "start": "244560",
    "end": "246239"
  },
  {
    "text": "sample to get a score so you feed in",
    "start": "246239",
    "end": "248480"
  },
  {
    "text": "some bytes you feed in an image whatever",
    "start": "248480",
    "end": "250720"
  },
  {
    "text": "you're doing with the deep learning",
    "start": "250720",
    "end": "251760"
  },
  {
    "text": "model and then at the output you get a",
    "start": "251760",
    "end": "253599"
  },
  {
    "text": "funnel score like this is malicious or",
    "start": "253599",
    "end": "255680"
  },
  {
    "text": "this is a bird this is a plane whatever",
    "start": "255680",
    "end": "257440"
  },
  {
    "text": "the model is trying to classify",
    "start": "257440",
    "end": "259840"
  },
  {
    "text": "so in that typical way of setting things",
    "start": "259840",
    "end": "261680"
  },
  {
    "text": "up you don't have a lot of",
    "start": "261680",
    "end": "262479"
  },
  {
    "text": "interpretability there are sort of bolts",
    "start": "262479",
    "end": "264800"
  },
  {
    "text": "on methods that you can use to try and",
    "start": "264800",
    "end": "267040"
  },
  {
    "text": "go back and get interpretability like",
    "start": "267040",
    "end": "268800"
  },
  {
    "text": "one really good one is called lime where",
    "start": "268800",
    "end": "270880"
  },
  {
    "text": "you perturb the input pixels and see if",
    "start": "270880",
    "end": "272800"
  },
  {
    "text": "perturbations change the output much and",
    "start": "272800",
    "end": "275120"
  },
  {
    "text": "then you say the things that",
    "start": "275120",
    "end": "277280"
  },
  {
    "text": "modified the input much were important",
    "start": "277280",
    "end": "279120"
  },
  {
    "text": "so you say that these regions were",
    "start": "279120",
    "end": "280479"
  },
  {
    "text": "important for the classification",
    "start": "280479",
    "end": "282400"
  },
  {
    "text": "but generally speaking in my experience",
    "start": "282400",
    "end": "284160"
  },
  {
    "text": "getting interpretability for deep",
    "start": "284160",
    "end": "285600"
  },
  {
    "text": "learning models for malware recognition",
    "start": "285600",
    "end": "287840"
  },
  {
    "text": "it's sort of a crapshoot as to whether",
    "start": "287840",
    "end": "289600"
  },
  {
    "text": "or not you're going to get something",
    "start": "289600",
    "end": "290800"
  },
  {
    "text": "useful from the interpretability from",
    "start": "290800",
    "end": "292560"
  },
  {
    "text": "something like lime",
    "start": "292560",
    "end": "294240"
  },
  {
    "text": "so in this work what we do is we set up",
    "start": "294240",
    "end": "296400"
  },
  {
    "text": "the model in such a way that when we",
    "start": "296400",
    "end": "298800"
  },
  {
    "text": "feed in any contiguous series of bytes",
    "start": "298800",
    "end": "301280"
  },
  {
    "text": "we can get an upward score so we can",
    "start": "301280",
    "end": "303759"
  },
  {
    "text": "feed in a sequence like you have been",
    "start": "303759",
    "end": "306720"
  },
  {
    "text": "pwned and we should get something really",
    "start": "306720",
    "end": "308560"
  },
  {
    "text": "high like 0.99 or if we feed in",
    "start": "308560",
    "end": "311680"
  },
  {
    "text": "something like please send five bitcoins",
    "start": "311680",
    "end": "313840"
  },
  {
    "text": "to this bitcoin wallet then we get a",
    "start": "313840",
    "end": "315840"
  },
  {
    "text": "high score",
    "start": "315840",
    "end": "317120"
  },
  {
    "text": "whereas if we feed in a different benign",
    "start": "317120",
    "end": "319440"
  },
  {
    "text": "string or if we feed an advanced string",
    "start": "319440",
    "end": "321840"
  },
  {
    "text": "like this program cannot be run in dos",
    "start": "321840",
    "end": "323520"
  },
  {
    "text": "mode we should get a really low score",
    "start": "323520",
    "end": "325360"
  },
  {
    "text": "from the model",
    "start": "325360",
    "end": "326400"
  },
  {
    "text": "so we structure in such a way that we",
    "start": "326400",
    "end": "328639"
  },
  {
    "text": "feed in the entire bytes of the sample",
    "start": "328639",
    "end": "330800"
  },
  {
    "text": "and then for each byte we feed in that",
    "start": "330800",
    "end": "332960"
  },
  {
    "text": "represents some range of bytes we should",
    "start": "332960",
    "end": "334639"
  },
  {
    "text": "be able to get a score back out",
    "start": "334639",
    "end": "336560"
  },
  {
    "text": "in this way the model is interpretable",
    "start": "336560",
    "end": "338160"
  },
  {
    "text": "in the sense that we can look at the",
    "start": "338160",
    "end": "340639"
  },
  {
    "text": "upward score and if the output score is",
    "start": "340639",
    "end": "342639"
  },
  {
    "text": "high then we have a direct way to look",
    "start": "342639",
    "end": "344400"
  },
  {
    "text": "back through the model to see which byte",
    "start": "344400",
    "end": "346560"
  },
  {
    "text": "sequences the model found benign or",
    "start": "346560",
    "end": "348800"
  },
  {
    "text": "malicious",
    "start": "348800",
    "end": "350000"
  },
  {
    "text": "and then what we can do is we can look",
    "start": "350000",
    "end": "352400"
  },
  {
    "text": "at the particular offsets for byte",
    "start": "352400",
    "end": "353919"
  },
  {
    "text": "sequences model thought was bad and then",
    "start": "353919",
    "end": "356240"
  },
  {
    "text": "rip those out and create url rules based",
    "start": "356240",
    "end": "358080"
  },
  {
    "text": "on these",
    "start": "358080",
    "end": "360560"
  },
  {
    "text": "so before i go much further into the",
    "start": "360800",
    "end": "362240"
  },
  {
    "text": "model architecture i'd like to do a",
    "start": "362240",
    "end": "363680"
  },
  {
    "text": "quick primer on convolutional neural",
    "start": "363680",
    "end": "365199"
  },
  {
    "text": "networks to get a better idea of how",
    "start": "365199",
    "end": "367440"
  },
  {
    "text": "this model works",
    "start": "367440",
    "end": "368720"
  },
  {
    "text": "it's not going to be very in-depth it's",
    "start": "368720",
    "end": "370080"
  },
  {
    "text": "going to be very simple",
    "start": "370080",
    "end": "372080"
  },
  {
    "text": "everything that's less important has",
    "start": "372080",
    "end": "374080"
  },
  {
    "text": "been kind of abstracted away but",
    "start": "374080",
    "end": "376000"
  },
  {
    "text": "basically what convolution is doing is",
    "start": "376000",
    "end": "378160"
  },
  {
    "text": "it's going to take some function in this",
    "start": "378160",
    "end": "379919"
  },
  {
    "text": "case the function is represented by",
    "start": "379919",
    "end": "381280"
  },
  {
    "text": "these three squiggly lines here and it's",
    "start": "381280",
    "end": "383520"
  },
  {
    "text": "going to take three bytes on the input",
    "start": "383520",
    "end": "385360"
  },
  {
    "text": "and then it's going to apply a function",
    "start": "385360",
    "end": "387039"
  },
  {
    "text": "to those bytes it doesn't really matter",
    "start": "387039",
    "end": "388560"
  },
  {
    "text": "what the function is so much in the case",
    "start": "388560",
    "end": "390319"
  },
  {
    "text": "of deep neural networks it's just",
    "start": "390319",
    "end": "391520"
  },
  {
    "text": "multiplications and additions but that's",
    "start": "391520",
    "end": "393759"
  },
  {
    "text": "not super important to know",
    "start": "393759",
    "end": "395520"
  },
  {
    "text": "it's going to take those three bytes and",
    "start": "395520",
    "end": "397199"
  },
  {
    "text": "it's going to do something to them then",
    "start": "397199",
    "end": "398880"
  },
  {
    "text": "it's going to output a score or some",
    "start": "398880",
    "end": "400560"
  },
  {
    "text": "representation",
    "start": "400560",
    "end": "402080"
  },
  {
    "text": "basically what we can say is the output",
    "start": "402080",
    "end": "404160"
  },
  {
    "text": "of that function is going to be directly",
    "start": "404160",
    "end": "406240"
  },
  {
    "text": "representative of those three bytes that",
    "start": "406240",
    "end": "407759"
  },
  {
    "text": "we see",
    "start": "407759",
    "end": "409039"
  },
  {
    "text": "so we can take this function and we just",
    "start": "409039",
    "end": "411199"
  },
  {
    "text": "kind of take it and we slide it down all",
    "start": "411199",
    "end": "413280"
  },
  {
    "text": "the bytes that we have on a sample so",
    "start": "413280",
    "end": "416160"
  },
  {
    "text": "this time we're outputting a score or a",
    "start": "416160",
    "end": "417919"
  },
  {
    "text": "representation of bytes one through",
    "start": "417919",
    "end": "419360"
  },
  {
    "text": "three and this time we're outputting a",
    "start": "419360",
    "end": "421120"
  },
  {
    "text": "representation of bytes two through four",
    "start": "421120",
    "end": "423440"
  },
  {
    "text": "so basically you take a function you",
    "start": "423440",
    "end": "425759"
  },
  {
    "text": "apply the function each time identically",
    "start": "425759",
    "end": "427759"
  },
  {
    "text": "to each",
    "start": "427759",
    "end": "428880"
  },
  {
    "text": "set of bytes that you see and then on",
    "start": "428880",
    "end": "430639"
  },
  {
    "text": "the output you have outputs that",
    "start": "430639",
    "end": "432560"
  },
  {
    "text": "correspond to certain ranges of the",
    "start": "432560",
    "end": "434800"
  },
  {
    "text": "input",
    "start": "434800",
    "end": "437800"
  },
  {
    "start": "438000",
    "end": "438000"
  },
  {
    "text": "so further we can sort of stack these",
    "start": "438800",
    "end": "440479"
  },
  {
    "text": "convolutions together in a way that",
    "start": "440479",
    "end": "442639"
  },
  {
    "text": "instead of having an output score we",
    "start": "442639",
    "end": "444240"
  },
  {
    "text": "have an output representation then we",
    "start": "444240",
    "end": "446160"
  },
  {
    "text": "just do a whole bunch of stacks of",
    "start": "446160",
    "end": "447440"
  },
  {
    "text": "convolutions until we get to some output",
    "start": "447440",
    "end": "451039"
  },
  {
    "text": "in this case each time we do another",
    "start": "451039",
    "end": "453039"
  },
  {
    "text": "stack we basically get a larger",
    "start": "453039",
    "end": "454960"
  },
  {
    "text": "receptive field in other words the",
    "start": "454960",
    "end": "457360"
  },
  {
    "text": "output byte",
    "start": "457360",
    "end": "458720"
  },
  {
    "text": "representation that we see is going to",
    "start": "458720",
    "end": "460800"
  },
  {
    "text": "go back further and represent a wider",
    "start": "460800",
    "end": "462479"
  },
  {
    "text": "series of bytes so if we want longer ur",
    "start": "462479",
    "end": "465120"
  },
  {
    "text": "rules then we can add more steps in the",
    "start": "465120",
    "end": "467280"
  },
  {
    "text": "convolution or add more layers of",
    "start": "467280",
    "end": "468800"
  },
  {
    "text": "convolution",
    "start": "468800",
    "end": "470560"
  },
  {
    "text": "so we can see that on the output we're",
    "start": "470560",
    "end": "472240"
  },
  {
    "text": "representing bytes 0 through 6 and we do",
    "start": "472240",
    "end": "474240"
  },
  {
    "text": "the step of the convolution and then the",
    "start": "474240",
    "end": "476160"
  },
  {
    "text": "second output there is going to",
    "start": "476160",
    "end": "477759"
  },
  {
    "text": "represent bytes one through seven",
    "start": "477759",
    "end": "479680"
  },
  {
    "text": "so we can see that the interpretability",
    "start": "479680",
    "end": "481520"
  },
  {
    "text": "here is basically the ability to look at",
    "start": "481520",
    "end": "483919"
  },
  {
    "text": "an output of the model and be able to",
    "start": "483919",
    "end": "486000"
  },
  {
    "text": "tie it directly back to the sequence of",
    "start": "486000",
    "end": "487840"
  },
  {
    "text": "bytes that affected that score",
    "start": "487840",
    "end": "492479"
  },
  {
    "start": "492000",
    "end": "492000"
  },
  {
    "text": "so how the model works the slide is",
    "start": "492479",
    "end": "494160"
  },
  {
    "text": "meant a little bit for the machine",
    "start": "494160",
    "end": "495360"
  },
  {
    "text": "learning people who",
    "start": "495360",
    "end": "497120"
  },
  {
    "text": "want to understand a little bit better",
    "start": "497120",
    "end": "498800"
  },
  {
    "text": "what exactly the architecture of the",
    "start": "498800",
    "end": "500080"
  },
  {
    "text": "model looks like",
    "start": "500080",
    "end": "501280"
  },
  {
    "text": "so we're going to take a whole bunch of",
    "start": "501280",
    "end": "502639"
  },
  {
    "text": "bytes from a binary",
    "start": "502639",
    "end": "504400"
  },
  {
    "text": "in the context of the talk i'll show you",
    "start": "504400",
    "end": "505919"
  },
  {
    "text": "some results later on elf and maco and",
    "start": "505919",
    "end": "507680"
  },
  {
    "text": "pe but generally speaking we can feed",
    "start": "507680",
    "end": "510160"
  },
  {
    "text": "whatever bytes we want into this model",
    "start": "510160",
    "end": "512399"
  },
  {
    "text": "so we'll feed in some bytes and then",
    "start": "512399",
    "end": "514159"
  },
  {
    "text": "each byte is going to be sent through an",
    "start": "514159",
    "end": "515599"
  },
  {
    "text": "embedding layer for the folks who aren't",
    "start": "515599",
    "end": "517760"
  },
  {
    "text": "super familiar with what an embedding",
    "start": "517760",
    "end": "519440"
  },
  {
    "text": "layer might be",
    "start": "519440",
    "end": "520640"
  },
  {
    "text": "it's more or less a way to take",
    "start": "520640",
    "end": "522399"
  },
  {
    "text": "something from a byte into a whole bunch",
    "start": "522399",
    "end": "524720"
  },
  {
    "text": "of floating point numbers that the",
    "start": "524720",
    "end": "526000"
  },
  {
    "text": "neural network can then understand and",
    "start": "526000",
    "end": "527760"
  },
  {
    "text": "work with so we're going to take each",
    "start": "527760",
    "end": "529760"
  },
  {
    "text": "byte put it through an embedding layer",
    "start": "529760",
    "end": "531279"
  },
  {
    "text": "and then we put it through a whole bunch",
    "start": "531279",
    "end": "532480"
  },
  {
    "text": "of convolution layers and each",
    "start": "532480",
    "end": "534800"
  },
  {
    "text": "convolution in this case is going to be",
    "start": "534800",
    "end": "536240"
  },
  {
    "text": "followed up with a rectified linear",
    "start": "536240",
    "end": "538160"
  },
  {
    "text": "layer i think in the most recent set of",
    "start": "538160",
    "end": "539760"
  },
  {
    "text": "experiments i was actually using a",
    "start": "539760",
    "end": "541760"
  },
  {
    "text": "p-relu layer for the ml folks",
    "start": "541760",
    "end": "544480"
  },
  {
    "text": "and we do a whole bunch of these layers",
    "start": "544480",
    "end": "546000"
  },
  {
    "text": "and then at the end we have a sigmoid",
    "start": "546000",
    "end": "547600"
  },
  {
    "text": "layer",
    "start": "547600",
    "end": "548959"
  },
  {
    "text": "what the sigmoid layer does is it sort",
    "start": "548959",
    "end": "550880"
  },
  {
    "text": "of crushes the values model's able to",
    "start": "550880",
    "end": "553519"
  },
  {
    "text": "output between zero and one so this",
    "start": "553519",
    "end": "555680"
  },
  {
    "text": "makes it so that if the score is zero",
    "start": "555680",
    "end": "557600"
  },
  {
    "text": "then we interpret it as benign and if",
    "start": "557600",
    "end": "560000"
  },
  {
    "text": "the score is close to one we interpret",
    "start": "560000",
    "end": "561680"
  },
  {
    "text": "it as malicious",
    "start": "561680",
    "end": "563519"
  },
  {
    "text": "so one thing to point out is that there",
    "start": "563519",
    "end": "565360"
  },
  {
    "text": "are no max pooling layers in this",
    "start": "565360",
    "end": "566880"
  },
  {
    "text": "architecture and this is because if we",
    "start": "566880",
    "end": "568800"
  },
  {
    "text": "were to include things like max pulling",
    "start": "568800",
    "end": "570399"
  },
  {
    "text": "layers we would start to",
    "start": "570399",
    "end": "572720"
  },
  {
    "text": "drastically increase the size of our",
    "start": "572720",
    "end": "574560"
  },
  {
    "text": "receptive field of the input bytes so",
    "start": "574560",
    "end": "576720"
  },
  {
    "text": "max pooling layer is basically going to",
    "start": "576720",
    "end": "578480"
  },
  {
    "text": "down sample stuff by a factor of two or",
    "start": "578480",
    "end": "580560"
  },
  {
    "text": "three or four or whatever you choose so",
    "start": "580560",
    "end": "582640"
  },
  {
    "text": "if we started putting max pooling layers",
    "start": "582640",
    "end": "584240"
  },
  {
    "text": "in here instead of creating signatures",
    "start": "584240",
    "end": "586320"
  },
  {
    "text": "based on 16 or 32 contiguous bytes we",
    "start": "586320",
    "end": "589760"
  },
  {
    "text": "would be creating signatures on things",
    "start": "589760",
    "end": "591440"
  },
  {
    "text": "that are 256 bytes 512 bytes long and",
    "start": "591440",
    "end": "594000"
  },
  {
    "text": "that wouldn't be as useful in the",
    "start": "594000",
    "end": "595279"
  },
  {
    "text": "signature it would be a much less",
    "start": "595279",
    "end": "597120"
  },
  {
    "text": "general signature",
    "start": "597120",
    "end": "599620"
  },
  {
    "text": "[Music]",
    "start": "599620",
    "end": "602809"
  },
  {
    "text": "so basically the more convolutional",
    "start": "603120",
    "end": "604959"
  },
  {
    "text": "layers we apply",
    "start": "604959",
    "end": "606399"
  },
  {
    "text": "the deeper this thing goes the larger",
    "start": "606399",
    "end": "608160"
  },
  {
    "text": "the receptive field that we get and",
    "start": "608160",
    "end": "609839"
  },
  {
    "text": "practically speaking i think i used five",
    "start": "609839",
    "end": "611760"
  },
  {
    "text": "or six layers to give us something like",
    "start": "611760",
    "end": "613839"
  },
  {
    "text": "24 or 30 long url signatures",
    "start": "613839",
    "end": "617600"
  },
  {
    "text": "so basically this architecture is going",
    "start": "617600",
    "end": "620000"
  },
  {
    "text": "to work like you feed in a thousand",
    "start": "620000",
    "end": "621440"
  },
  {
    "text": "bytes and you're going to feed in about",
    "start": "621440",
    "end": "623279"
  },
  {
    "text": "a or you're going to receive about a",
    "start": "623279",
    "end": "624800"
  },
  {
    "text": "thousand scores back",
    "start": "624800",
    "end": "627680"
  },
  {
    "text": "so in terms of training model there's",
    "start": "628240",
    "end": "629600"
  },
  {
    "text": "some practical things to talk about here",
    "start": "629600",
    "end": "632560"
  },
  {
    "start": "631000",
    "end": "631000"
  },
  {
    "text": "so for model training",
    "start": "632560",
    "end": "634320"
  },
  {
    "text": "i sort of refer to this as finding",
    "start": "634320",
    "end": "635760"
  },
  {
    "text": "needles in a haystack we're going to",
    "start": "635760",
    "end": "637440"
  },
  {
    "text": "have these malicious strings which are",
    "start": "637440",
    "end": "639040"
  },
  {
    "text": "strings provide sequences that occur",
    "start": "639040",
    "end": "641040"
  },
  {
    "text": "only in malicious samples and then we",
    "start": "641040",
    "end": "643360"
  },
  {
    "text": "have benign strings which are strings",
    "start": "643360",
    "end": "644959"
  },
  {
    "text": "that are seen either in malicious or",
    "start": "644959",
    "end": "646560"
  },
  {
    "text": "benign samples so we want to train the",
    "start": "646560",
    "end": "649120"
  },
  {
    "text": "model in such a way that if we see a",
    "start": "649120",
    "end": "651680"
  },
  {
    "text": "zero that really says nothing",
    "start": "651680",
    "end": "653920"
  },
  {
    "text": "informative about the string or the byte",
    "start": "653920",
    "end": "655760"
  },
  {
    "text": "sequence it just means that there's",
    "start": "655760",
    "end": "657040"
  },
  {
    "text": "nothing specifically malicious about it",
    "start": "657040",
    "end": "659279"
  },
  {
    "text": "whereas if we get an output of one we",
    "start": "659279",
    "end": "661519"
  },
  {
    "text": "want that to mean this is a rare and",
    "start": "661519",
    "end": "664560"
  },
  {
    "text": "informative string that says that this",
    "start": "664560",
    "end": "667200"
  },
  {
    "text": "thing is indeed malicious",
    "start": "667200",
    "end": "669360"
  },
  {
    "text": "so this means that the model is going to",
    "start": "669360",
    "end": "672000"
  },
  {
    "text": "have to output very sparse outputs it's",
    "start": "672000",
    "end": "674399"
  },
  {
    "text": "going to have to be zeros for most of",
    "start": "674399",
    "end": "676959"
  },
  {
    "text": "the output bytes that it sees except for",
    "start": "676959",
    "end": "679120"
  },
  {
    "text": "the occasional very malicious thing like",
    "start": "679120",
    "end": "680959"
  },
  {
    "text": "a particular op code sequence associated",
    "start": "680959",
    "end": "683120"
  },
  {
    "text": "with i don't know a particular kind of",
    "start": "683120",
    "end": "685040"
  },
  {
    "text": "crypter or something like that",
    "start": "685040",
    "end": "687680"
  },
  {
    "text": "and",
    "start": "687680",
    "end": "688399"
  },
  {
    "text": "yeah we basically want the model to",
    "start": "688399",
    "end": "689680"
  },
  {
    "text": "output zeros for almost everything",
    "start": "689680",
    "end": "691600"
  },
  {
    "text": "except for strings associated with",
    "start": "691600",
    "end": "693040"
  },
  {
    "text": "maliciousness",
    "start": "693040",
    "end": "695839"
  },
  {
    "start": "696000",
    "end": "696000"
  },
  {
    "text": "so the way we do this is we use a thing",
    "start": "696399",
    "end": "698560"
  },
  {
    "text": "called top case selection so",
    "start": "698560",
    "end": "701200"
  },
  {
    "text": "really quick when you're talking about",
    "start": "701200",
    "end": "702480"
  },
  {
    "text": "back propagating or training neural",
    "start": "702480",
    "end": "704160"
  },
  {
    "text": "networks",
    "start": "704160",
    "end": "705440"
  },
  {
    "text": "you're going to look at an output and",
    "start": "705440",
    "end": "707519"
  },
  {
    "text": "then you're going to feed the error of",
    "start": "707519",
    "end": "709120"
  },
  {
    "text": "the output back through the model to be",
    "start": "709120",
    "end": "711040"
  },
  {
    "text": "able to get away to update your model in",
    "start": "711040",
    "end": "713120"
  },
  {
    "text": "such a way that it better classifies",
    "start": "713120",
    "end": "714839"
  },
  {
    "text": "something in this case we're going to",
    "start": "714839",
    "end": "716959"
  },
  {
    "text": "have",
    "start": "716959",
    "end": "717839"
  },
  {
    "text": "sort of this needle in a haystack thing",
    "start": "717839",
    "end": "719440"
  },
  {
    "text": "so it doesn't really make sense to",
    "start": "719440",
    "end": "721279"
  },
  {
    "text": "update every single output in the model",
    "start": "721279",
    "end": "723519"
  },
  {
    "text": "so we do this top case selection which",
    "start": "723519",
    "end": "725279"
  },
  {
    "text": "basically means look at all the scores",
    "start": "725279",
    "end": "727279"
  },
  {
    "text": "we see on the output and sort them based",
    "start": "727279",
    "end": "729680"
  },
  {
    "text": "on their magnitude so you know we'll",
    "start": "729680",
    "end": "731600"
  },
  {
    "text": "sort it descending from one to zero",
    "start": "731600",
    "end": "734480"
  },
  {
    "text": "then we're going to select the top k",
    "start": "734480",
    "end": "736000"
  },
  {
    "text": "valued scores to back propagate through",
    "start": "736000",
    "end": "737680"
  },
  {
    "text": "or to update with respect to",
    "start": "737680",
    "end": "739920"
  },
  {
    "text": "what this does is it heavily promotes",
    "start": "739920",
    "end": "742560"
  },
  {
    "text": "malicious stuff while very quickly",
    "start": "742560",
    "end": "744160"
  },
  {
    "text": "squashing down benign stuff",
    "start": "744160",
    "end": "746160"
  },
  {
    "text": "and practically speaking for top k i",
    "start": "746160",
    "end": "748240"
  },
  {
    "text": "would select let's say the top 10",
    "start": "748240",
    "end": "751040"
  },
  {
    "text": "strongest outputs from the model",
    "start": "751040",
    "end": "753440"
  },
  {
    "text": "this also has the side benefit of",
    "start": "753440",
    "end": "754880"
  },
  {
    "text": "specifying the outputs so we get exactly",
    "start": "754880",
    "end": "757120"
  },
  {
    "text": "what we want we get a model that's",
    "start": "757120",
    "end": "758639"
  },
  {
    "text": "looking for needles in a haystack that's",
    "start": "758639",
    "end": "760880"
  },
  {
    "text": "quickly able to pick out malicious",
    "start": "760880",
    "end": "762560"
  },
  {
    "text": "strings and ignore uninformative ones",
    "start": "762560",
    "end": "766480"
  },
  {
    "text": "and again this has the side effect of",
    "start": "769680",
    "end": "772079"
  },
  {
    "text": "very quickly pushing",
    "start": "772079",
    "end": "774320"
  },
  {
    "text": "benign or uninformed strings down to",
    "start": "774320",
    "end": "777120"
  },
  {
    "text": "zero because we are selecting the most",
    "start": "777120",
    "end": "780079"
  },
  {
    "text": "malicious things that the model sees for",
    "start": "780079",
    "end": "781680"
  },
  {
    "text": "that point in model training and we're",
    "start": "781680",
    "end": "783120"
  },
  {
    "text": "actively squashing those things down",
    "start": "783120",
    "end": "785200"
  },
  {
    "text": "and we're ignoring everything else",
    "start": "785200",
    "end": "788399"
  },
  {
    "start": "788000",
    "end": "788000"
  },
  {
    "text": "another practical consideration to talk",
    "start": "788959",
    "end": "790720"
  },
  {
    "text": "about is how do we fit this onto a gpu",
    "start": "790720",
    "end": "793040"
  },
  {
    "text": "so the",
    "start": "793040",
    "end": "794639"
  },
  {
    "text": "executables that i was training on could",
    "start": "794639",
    "end": "796399"
  },
  {
    "text": "range in size anywhere from a few",
    "start": "796399",
    "end": "798000"
  },
  {
    "text": "kilobytes up to tens of megabytes if",
    "start": "798000",
    "end": "799839"
  },
  {
    "text": "they were an installer or something like",
    "start": "799839",
    "end": "801680"
  },
  {
    "text": "that",
    "start": "801680",
    "end": "802560"
  },
  {
    "text": "and gpus only have so much memory",
    "start": "802560",
    "end": "805360"
  },
  {
    "text": "and another thing to point out is that",
    "start": "805360",
    "end": "807519"
  },
  {
    "text": "when we feed these bytes through the",
    "start": "807519",
    "end": "808880"
  },
  {
    "text": "embedding layer and when we feed these",
    "start": "808880",
    "end": "810800"
  },
  {
    "text": "representations of bytes through all",
    "start": "810800",
    "end": "812240"
  },
  {
    "text": "these deep convolutional activations",
    "start": "812240",
    "end": "816000"
  },
  {
    "text": "we're going to increase the amount of",
    "start": "816000",
    "end": "817440"
  },
  {
    "text": "memory that we need by a factor of",
    "start": "817440",
    "end": "819440"
  },
  {
    "text": "thousands so this one megabyte sample is",
    "start": "819440",
    "end": "821680"
  },
  {
    "text": "all of a sudden gonna need something",
    "start": "821680",
    "end": "822959"
  },
  {
    "text": "like",
    "start": "822959",
    "end": "823680"
  },
  {
    "text": "eight gigabytes of gpu memory to be able",
    "start": "823680",
    "end": "825600"
  },
  {
    "text": "to process",
    "start": "825600",
    "end": "827040"
  },
  {
    "text": "so to deal with this what i did was i",
    "start": "827040",
    "end": "829040"
  },
  {
    "text": "took each sample and i broke it up into",
    "start": "829040",
    "end": "831120"
  },
  {
    "text": "64 kilobyte chunks so i take a sample",
    "start": "831120",
    "end": "834320"
  },
  {
    "text": "break it into a whole bunch of 64",
    "start": "834320",
    "end": "835760"
  },
  {
    "text": "kilobyte chunks and then i feed all",
    "start": "835760",
    "end": "837120"
  },
  {
    "text": "those chunks through the model step by",
    "start": "837120",
    "end": "838560"
  },
  {
    "text": "step so i don't have to use a whole lot",
    "start": "838560",
    "end": "840320"
  },
  {
    "text": "of memory and then i keep track of the",
    "start": "840320",
    "end": "842480"
  },
  {
    "text": "score that's associated with the most",
    "start": "842480",
    "end": "845760"
  },
  {
    "text": "rather i keep track of the bytes",
    "start": "845760",
    "end": "848320"
  },
  {
    "text": "of the score that was most positive so i",
    "start": "848320",
    "end": "851120"
  },
  {
    "text": "might feed in let's say 128 chunks and",
    "start": "851120",
    "end": "854639"
  },
  {
    "text": "then i'll keep track of the chunk that",
    "start": "854639",
    "end": "855760"
  },
  {
    "text": "had the highest score and only update",
    "start": "855760",
    "end": "857760"
  },
  {
    "text": "the model with respect to that chunk",
    "start": "857760",
    "end": "859839"
  },
  {
    "text": "and this is really nice because we're",
    "start": "859839",
    "end": "861199"
  },
  {
    "text": "doing this top k selection thing",
    "start": "861199",
    "end": "863360"
  },
  {
    "text": "because the model is only going to care",
    "start": "863360",
    "end": "865600"
  },
  {
    "text": "about the top valued things anyways so",
    "start": "865600",
    "end": "867920"
  },
  {
    "text": "we can get away with this clever speed",
    "start": "867920",
    "end": "869360"
  },
  {
    "text": "hack by just updating with respect to",
    "start": "869360",
    "end": "871440"
  },
  {
    "text": "the most malicious looking chunk that we",
    "start": "871440",
    "end": "873600"
  },
  {
    "text": "saw",
    "start": "873600",
    "end": "874399"
  },
  {
    "text": "and this has a huge decrease on the",
    "start": "874399",
    "end": "876720"
  },
  {
    "text": "required gpu memory to train a workable",
    "start": "876720",
    "end": "878639"
  },
  {
    "text": "model",
    "start": "878639",
    "end": "880880"
  },
  {
    "start": "881000",
    "end": "881000"
  },
  {
    "text": "so another issue that i ran into was",
    "start": "883680",
    "end": "886399"
  },
  {
    "text": "reducing false positives so what i found",
    "start": "886399",
    "end": "888800"
  },
  {
    "text": "was that the neural network that i was",
    "start": "888800",
    "end": "890240"
  },
  {
    "text": "training was trying very very hard to",
    "start": "890240",
    "end": "892000"
  },
  {
    "text": "find these shortcuts to kind of solve",
    "start": "892000",
    "end": "893680"
  },
  {
    "text": "the problem in unexpected ways",
    "start": "893680",
    "end": "895680"
  },
  {
    "text": "and it would do this by doing things",
    "start": "895680",
    "end": "897199"
  },
  {
    "text": "like i don't know on the off corpus i",
    "start": "897199",
    "end": "899519"
  },
  {
    "text": "found a whole bunch of samples that the",
    "start": "899519",
    "end": "901760"
  },
  {
    "text": "model was consistently calling bad based",
    "start": "901760",
    "end": "904079"
  },
  {
    "text": "on some specific gcc compiler strings",
    "start": "904079",
    "end": "906639"
  },
  {
    "text": "and",
    "start": "906639",
    "end": "907440"
  },
  {
    "text": "lip c versions that just happened to be",
    "start": "907440",
    "end": "909839"
  },
  {
    "text": "near the end of the sample",
    "start": "909839",
    "end": "911600"
  },
  {
    "text": "so this was a case where 99 of the time",
    "start": "911600",
    "end": "914560"
  },
  {
    "text": "where the model would see these strings",
    "start": "914560",
    "end": "916079"
  },
  {
    "text": "would be correct because they were just",
    "start": "916079",
    "end": "918000"
  },
  {
    "text": "uploaded and masked to vt",
    "start": "918000",
    "end": "920959"
  },
  {
    "text": "and they were fairly infrequent in the",
    "start": "920959",
    "end": "922720"
  },
  {
    "text": "benign set so 99 of the time you see",
    "start": "922720",
    "end": "925199"
  },
  {
    "text": "it's malicious one percent of the time",
    "start": "925199",
    "end": "926639"
  },
  {
    "text": "you see it's benign the model thinks",
    "start": "926639",
    "end": "928320"
  },
  {
    "text": "that's a fair trade-off so it says",
    "start": "928320",
    "end": "930160"
  },
  {
    "text": "whenever i see a gcc of this version and",
    "start": "930160",
    "end": "932320"
  },
  {
    "text": "ellipses of this version then i'll call",
    "start": "932320",
    "end": "933759"
  },
  {
    "text": "it that",
    "start": "933759",
    "end": "934639"
  },
  {
    "text": "that's clearly not a very good string",
    "start": "934639",
    "end": "936720"
  },
  {
    "text": "so what i did to counteract this is i",
    "start": "936720",
    "end": "938720"
  },
  {
    "text": "kept track of a rolling buck for false",
    "start": "938720",
    "end": "940639"
  },
  {
    "text": "positives so i would feed in a bunch of",
    "start": "940639",
    "end": "943120"
  },
  {
    "text": "samples and if there were any benign",
    "start": "943120",
    "end": "945040"
  },
  {
    "text": "samples that came back as malicious then",
    "start": "945040",
    "end": "947920"
  },
  {
    "text": "i would throw this thing into a rolling",
    "start": "947920",
    "end": "949360"
  },
  {
    "text": "buffer of false positives and keep them",
    "start": "949360",
    "end": "951120"
  },
  {
    "text": "around for like 10 or 15 minutes",
    "start": "951120",
    "end": "953360"
  },
  {
    "text": "and then for each training mini batch",
    "start": "953360",
    "end": "954880"
  },
  {
    "text": "where we select a small number of",
    "start": "954880",
    "end": "956240"
  },
  {
    "text": "samples to update the model i would",
    "start": "956240",
    "end": "958079"
  },
  {
    "text": "sample from the data set and i would",
    "start": "958079",
    "end": "959600"
  },
  {
    "text": "also sample from this false positive",
    "start": "959600",
    "end": "961120"
  },
  {
    "text": "buffer and then feed that back into the",
    "start": "961120",
    "end": "963199"
  },
  {
    "text": "model to basically overtrain the model",
    "start": "963199",
    "end": "965360"
  },
  {
    "text": "on these things it was pulsing on",
    "start": "965360",
    "end": "967279"
  },
  {
    "text": "and try and bring this 99 versus one",
    "start": "967279",
    "end": "969600"
  },
  {
    "text": "percent thing up closer to 50 50.",
    "start": "969600",
    "end": "973360"
  },
  {
    "text": "and another thing to point out is that",
    "start": "973360",
    "end": "976000"
  },
  {
    "text": "in this",
    "start": "976000",
    "end": "976959"
  },
  {
    "text": "rolling buffer false positive setup that",
    "start": "976959",
    "end": "978639"
  },
  {
    "text": "i have i sample",
    "start": "978639",
    "end": "980959"
  },
  {
    "text": "things that have a higher score more",
    "start": "980959",
    "end": "982880"
  },
  {
    "text": "frequently than things that have a lower",
    "start": "982880",
    "end": "984240"
  },
  {
    "text": "score so the things that are more wrong",
    "start": "984240",
    "end": "986240"
  },
  {
    "text": "get seen more frequently and that helps",
    "start": "986240",
    "end": "988320"
  },
  {
    "text": "to fix those problems more quickly",
    "start": "988320",
    "end": "992240"
  },
  {
    "text": "so signature generation we have an",
    "start": "993120",
    "end": "994880"
  },
  {
    "text": "interpretable model how do we extract ur",
    "start": "994880",
    "end": "997199"
  },
  {
    "text": "signatures from these models",
    "start": "997199",
    "end": "1000000"
  },
  {
    "text": "so there are two ways we can do it we",
    "start": "1000000",
    "end": "1001600"
  },
  {
    "text": "can do it per sample or we can do it in",
    "start": "1001600",
    "end": "1003519"
  },
  {
    "text": "bulk per sample i imagine would be",
    "start": "1003519",
    "end": "1005759"
  },
  {
    "text": "useful to reverse engineers and analysts",
    "start": "1005759",
    "end": "1008720"
  },
  {
    "text": "and people like this so that you can",
    "start": "1008720",
    "end": "1011040"
  },
  {
    "text": "take a small number of samples let's say",
    "start": "1011040",
    "end": "1012800"
  },
  {
    "text": "10 or 15 samples that belong to the same",
    "start": "1012800",
    "end": "1014720"
  },
  {
    "text": "family let's say",
    "start": "1014720",
    "end": "1016160"
  },
  {
    "text": "and be able to generate a yar rule or",
    "start": "1016160",
    "end": "1019040"
  },
  {
    "text": "two or three around samples",
    "start": "1019040",
    "end": "1021440"
  },
  {
    "text": "then there's a second regime in bulk",
    "start": "1021440",
    "end": "1023440"
  },
  {
    "text": "where we want to take let's say ten",
    "start": "1023440",
    "end": "1025678"
  },
  {
    "text": "thousand fifty thousand one hundred",
    "start": "1025679",
    "end": "1027360"
  },
  {
    "text": "thousand samples",
    "start": "1027360",
    "end": "1028798"
  },
  {
    "text": "and generate a few hundred rules that",
    "start": "1028799",
    "end": "1031038"
  },
  {
    "text": "mostly capture",
    "start": "1031039",
    "end": "1032558"
  },
  {
    "text": "the corpus of malware that you're",
    "start": "1032559",
    "end": "1034160"
  },
  {
    "text": "feeding in",
    "start": "1034160",
    "end": "1036640"
  },
  {
    "text": "so sample by sample",
    "start": "1037280",
    "end": "1041039"
  },
  {
    "text": "i have a live demo here",
    "start": "1048720",
    "end": "1051440"
  },
  {
    "text": "i'm calling this python script that i",
    "start": "1051440",
    "end": "1052960"
  },
  {
    "text": "wrote called bump sigs and what dump",
    "start": "1052960",
    "end": "1054960"
  },
  {
    "text": "sigs is going to do is it's going to",
    "start": "1054960",
    "end": "1056559"
  },
  {
    "text": "load in a model that i've trained and",
    "start": "1056559",
    "end": "1058559"
  },
  {
    "text": "run that model against a whole bunch of",
    "start": "1058559",
    "end": "1060320"
  },
  {
    "text": "samples that i've specified",
    "start": "1060320",
    "end": "1063960"
  },
  {
    "text": "so what it's going to do is it's going",
    "start": "1067679",
    "end": "1069120"
  },
  {
    "text": "to load up that model and then it's",
    "start": "1069120",
    "end": "1070799"
  },
  {
    "text": "going to attempt to extract signatures",
    "start": "1070799",
    "end": "1072400"
  },
  {
    "text": "for 25 samples these 25 samples i",
    "start": "1072400",
    "end": "1074799"
  },
  {
    "text": "downloaded from virustotal yesterday",
    "start": "1074799",
    "end": "1076640"
  },
  {
    "text": "it's just",
    "start": "1076640",
    "end": "1078000"
  },
  {
    "text": "25 samples for the number of positives",
    "start": "1078000",
    "end": "1079919"
  },
  {
    "text": "was greater than 10 and the file type is",
    "start": "1079919",
    "end": "1081840"
  },
  {
    "text": "als",
    "start": "1081840",
    "end": "1083520"
  },
  {
    "text": "so what it's going to do is it's going",
    "start": "1083520",
    "end": "1084880"
  },
  {
    "text": "to go through each one of these samples",
    "start": "1084880",
    "end": "1086480"
  },
  {
    "text": "run it through the model",
    "start": "1086480",
    "end": "1088000"
  },
  {
    "text": "and then extract out potential",
    "start": "1088000",
    "end": "1090080"
  },
  {
    "text": "signatures or good signatures",
    "start": "1090080",
    "end": "1092400"
  },
  {
    "text": "in this case we can see",
    "start": "1092400",
    "end": "1094960"
  },
  {
    "text": "we're going through this particular shot",
    "start": "1094960",
    "end": "1096799"
  },
  {
    "text": "256 and we see this signature here but",
    "start": "1096799",
    "end": "1100000"
  },
  {
    "text": "we can see the score isn't very high um",
    "start": "1100000",
    "end": "1102240"
  },
  {
    "text": "this here is the score and this here is",
    "start": "1102240",
    "end": "1103919"
  },
  {
    "text": "the offset of the string",
    "start": "1103919",
    "end": "1105600"
  },
  {
    "text": "we can see it's not very high it was the",
    "start": "1105600",
    "end": "1107280"
  },
  {
    "text": "highest valued string that it could find",
    "start": "1107280",
    "end": "1110080"
  },
  {
    "text": "and we're just dumping that out because",
    "start": "1110080",
    "end": "1111600"
  },
  {
    "text": "it might be a useful string",
    "start": "1111600",
    "end": "1113919"
  },
  {
    "text": "for the others it's going to dump out",
    "start": "1113919",
    "end": "1116640"
  },
  {
    "text": "scores and strings associated with",
    "start": "1116640",
    "end": "1119440"
  },
  {
    "text": "sort of what i would like to call slam",
    "start": "1119440",
    "end": "1120960"
  },
  {
    "text": "dunk dunk signatures where the",
    "start": "1120960",
    "end": "1122880"
  },
  {
    "text": "signatures have really high scores",
    "start": "1122880",
    "end": "1125440"
  },
  {
    "text": "and that's going to output those",
    "start": "1125440",
    "end": "1126559"
  },
  {
    "text": "potential scores for each model and then",
    "start": "1126559",
    "end": "1128000"
  },
  {
    "text": "we'll just choose the max that it sees",
    "start": "1128000",
    "end": "1129440"
  },
  {
    "text": "for each one",
    "start": "1129440",
    "end": "1131360"
  },
  {
    "text": "we can see a number of strings here that",
    "start": "1131360",
    "end": "1133919"
  },
  {
    "text": "probably wouldn't make as good",
    "start": "1133919",
    "end": "1135840"
  },
  {
    "text": "signatures this is sort of indicative of",
    "start": "1135840",
    "end": "1137679"
  },
  {
    "text": "that 99 percent one percent problem that",
    "start": "1137679",
    "end": "1140559"
  },
  {
    "text": "i referred to earlier this string here",
    "start": "1140559",
    "end": "1142880"
  },
  {
    "text": "is going to be it looks like a few glib",
    "start": "1142880",
    "end": "1145120"
  },
  {
    "text": "c things like stirring copy and stir",
    "start": "1145120",
    "end": "1147039"
  },
  {
    "text": "case comp and a few things like that",
    "start": "1147039",
    "end": "1149200"
  },
  {
    "text": "so this particular sequence of i'm going",
    "start": "1149200",
    "end": "1151600"
  },
  {
    "text": "to guess imports on elves the model",
    "start": "1151600",
    "end": "1153440"
  },
  {
    "text": "seems to think is malicious it might be",
    "start": "1153440",
    "end": "1155520"
  },
  {
    "text": "right it might be wrong it's up to the",
    "start": "1155520",
    "end": "1157919"
  },
  {
    "text": "analyst to determine if that's a good",
    "start": "1157919",
    "end": "1159520"
  },
  {
    "text": "string to put into the error rule",
    "start": "1159520",
    "end": "1162080"
  },
  {
    "text": "then it's going to run this over again",
    "start": "1162080",
    "end": "1164080"
  },
  {
    "text": "the 25 samples that i've presented it",
    "start": "1164080",
    "end": "1165840"
  },
  {
    "text": "with",
    "start": "1165840",
    "end": "1167600"
  },
  {
    "text": "and then at the very end it's going to",
    "start": "1167600",
    "end": "1169679"
  },
  {
    "text": "give us a yara rule that tries to detect",
    "start": "1169679",
    "end": "1171919"
  },
  {
    "text": "as many samples as it can in those 25",
    "start": "1171919",
    "end": "1174160"
  },
  {
    "text": "samples",
    "start": "1174160",
    "end": "1175520"
  },
  {
    "text": "so you can just take that and copy paste",
    "start": "1175520",
    "end": "1177280"
  },
  {
    "text": "it into the yara rule and put that into",
    "start": "1177280",
    "end": "1179679"
  },
  {
    "text": "production after of course making sure",
    "start": "1179679",
    "end": "1181520"
  },
  {
    "text": "that there no false positive triggered",
    "start": "1181520",
    "end": "1185600"
  },
  {
    "start": "1188000",
    "end": "1188000"
  },
  {
    "text": "so the second regime is generating",
    "start": "1189120",
    "end": "1190559"
  },
  {
    "text": "signatures in bulk what we're doing here",
    "start": "1190559",
    "end": "1193039"
  },
  {
    "text": "is we're feeding in again tens of",
    "start": "1193039",
    "end": "1194799"
  },
  {
    "text": "thousands of samples through the model",
    "start": "1194799",
    "end": "1196720"
  },
  {
    "text": "to come up with a good set of i don't",
    "start": "1196720",
    "end": "1198799"
  },
  {
    "text": "know 100 200 500 signatures that roughly",
    "start": "1198799",
    "end": "1202240"
  },
  {
    "text": "capture as many malicious samples as it",
    "start": "1202240",
    "end": "1203919"
  },
  {
    "text": "can",
    "start": "1203919",
    "end": "1205520"
  },
  {
    "text": "what we're going to do is we're going to",
    "start": "1205520",
    "end": "1207039"
  },
  {
    "text": "take a pre-trained model we're going to",
    "start": "1207039",
    "end": "1209039"
  },
  {
    "text": "run it over",
    "start": "1209039",
    "end": "1210240"
  },
  {
    "text": "as many samples in our malicious and",
    "start": "1210240",
    "end": "1212320"
  },
  {
    "text": "benign corpuses as we can get",
    "start": "1212320",
    "end": "1214960"
  },
  {
    "text": "and then for malicious samples it'll",
    "start": "1214960",
    "end": "1217039"
  },
  {
    "text": "grab the max score that it sees in the",
    "start": "1217039",
    "end": "1218480"
  },
  {
    "text": "sample and the associated string",
    "start": "1218480",
    "end": "1220080"
  },
  {
    "text": "associated with that score it's also",
    "start": "1220080",
    "end": "1222320"
  },
  {
    "text": "going to do the same for benign strings",
    "start": "1222320",
    "end": "1224480"
  },
  {
    "text": "so if it sees a benign string with a",
    "start": "1224480",
    "end": "1226159"
  },
  {
    "text": "relatively high score it's going to take",
    "start": "1226159",
    "end": "1228720"
  },
  {
    "text": "that string and add it to a list of",
    "start": "1228720",
    "end": "1231200"
  },
  {
    "text": "banished strings in other words it's",
    "start": "1231200",
    "end": "1233039"
  },
  {
    "text": "going to say don't ever use these",
    "start": "1233039",
    "end": "1235039"
  },
  {
    "text": "strings because we saw it as a false",
    "start": "1235039",
    "end": "1236559"
  },
  {
    "text": "positive and we don't want this leaking",
    "start": "1236559",
    "end": "1238159"
  },
  {
    "text": "into our set of production strings",
    "start": "1238159",
    "end": "1241440"
  },
  {
    "text": "so we're going to go through we're going",
    "start": "1241440",
    "end": "1242880"
  },
  {
    "text": "to remove out all the benign false",
    "start": "1242880",
    "end": "1244640"
  },
  {
    "text": "positives and we're going to be left",
    "start": "1244640",
    "end": "1245919"
  },
  {
    "text": "behind with a set of strings that",
    "start": "1245919",
    "end": "1247840"
  },
  {
    "text": "captures as much malicious stuff as",
    "start": "1247840",
    "end": "1249440"
  },
  {
    "text": "possible",
    "start": "1249440",
    "end": "1250799"
  },
  {
    "text": "then we're going to sort things by",
    "start": "1250799",
    "end": "1252000"
  },
  {
    "text": "prevalence",
    "start": "1252000",
    "end": "1253280"
  },
  {
    "text": "so if we have a string or a byte",
    "start": "1253280",
    "end": "1255200"
  },
  {
    "text": "sequence that matches let's say 10",
    "start": "1255200",
    "end": "1257360"
  },
  {
    "text": "percent of our data set that's really",
    "start": "1257360",
    "end": "1259120"
  },
  {
    "text": "useful and we want to promote this",
    "start": "1259120",
    "end": "1260960"
  },
  {
    "text": "string so that it definitely gets",
    "start": "1260960",
    "end": "1262400"
  },
  {
    "text": "selected in our final list of strings",
    "start": "1262400",
    "end": "1264240"
  },
  {
    "text": "that we put out",
    "start": "1264240",
    "end": "1265919"
  },
  {
    "text": "then what we're also going to do is",
    "start": "1265919",
    "end": "1267200"
  },
  {
    "text": "we're going to cluster strings together",
    "start": "1267200",
    "end": "1268559"
  },
  {
    "text": "based on this thing called hamming",
    "start": "1268559",
    "end": "1269679"
  },
  {
    "text": "distance hamming distance is a pretty",
    "start": "1269679",
    "end": "1271360"
  },
  {
    "text": "simple operation where you just look at",
    "start": "1271360",
    "end": "1273360"
  },
  {
    "text": "two byte sequences of the same length",
    "start": "1273360",
    "end": "1275600"
  },
  {
    "text": "and then you compare their bytes and if",
    "start": "1275600",
    "end": "1277360"
  },
  {
    "text": "any of the bytes are different then you",
    "start": "1277360",
    "end": "1278720"
  },
  {
    "text": "increment the hamming distance by one so",
    "start": "1278720",
    "end": "1281360"
  },
  {
    "text": "if you have",
    "start": "1281360",
    "end": "1282480"
  },
  {
    "text": "two byte sequences that differ by two",
    "start": "1282480",
    "end": "1284640"
  },
  {
    "text": "bytes then you're going to have a",
    "start": "1284640",
    "end": "1285520"
  },
  {
    "text": "hamming distance of two",
    "start": "1285520",
    "end": "1288080"
  },
  {
    "text": "we're going to go through all the",
    "start": "1288080",
    "end": "1289360"
  },
  {
    "text": "signatures that we found we're going to",
    "start": "1289360",
    "end": "1290880"
  },
  {
    "text": "cluster them together based on hamming",
    "start": "1290880",
    "end": "1292159"
  },
  {
    "text": "distance",
    "start": "1292159",
    "end": "1293200"
  },
  {
    "text": "and then every single string in a",
    "start": "1293200",
    "end": "1295360"
  },
  {
    "text": "particular cluster we're going to look",
    "start": "1295360",
    "end": "1297120"
  },
  {
    "text": "at their differences and then we're",
    "start": "1297120",
    "end": "1298880"
  },
  {
    "text": "going to use that as a mask",
    "start": "1298880",
    "end": "1300720"
  },
  {
    "text": "and then replace all the differences",
    "start": "1300720",
    "end": "1302320"
  },
  {
    "text": "with a wild card so an example of this",
    "start": "1302320",
    "end": "1304720"
  },
  {
    "text": "we can see off to the right we can see a",
    "start": "1304720",
    "end": "1307039"
  },
  {
    "text": "bunch of byte sequences i think there",
    "start": "1307039",
    "end": "1308720"
  },
  {
    "text": "are 16 or so",
    "start": "1308720",
    "end": "1310080"
  },
  {
    "text": "that are all mostly the same except for",
    "start": "1310080",
    "end": "1311840"
  },
  {
    "text": "the middle byte where the middle byte",
    "start": "1311840",
    "end": "1313440"
  },
  {
    "text": "appears to be a random value so to get",
    "start": "1313440",
    "end": "1316240"
  },
  {
    "text": "more bang for your buck for the",
    "start": "1316240",
    "end": "1317440"
  },
  {
    "text": "signature what we can do is we can",
    "start": "1317440",
    "end": "1319280"
  },
  {
    "text": "replace that middle byte with just a",
    "start": "1319280",
    "end": "1321679"
  },
  {
    "text": "wild card and be able to collapse those",
    "start": "1321679",
    "end": "1323200"
  },
  {
    "text": "16 signatures that the model dumped out",
    "start": "1323200",
    "end": "1325280"
  },
  {
    "text": "into just a single signature",
    "start": "1325280",
    "end": "1328640"
  },
  {
    "start": "1330000",
    "end": "1330000"
  },
  {
    "text": "so in terms of signature efficacy i",
    "start": "1330240",
    "end": "1332000"
  },
  {
    "text": "trained three models i trained an elf",
    "start": "1332000",
    "end": "1333679"
  },
  {
    "text": "model i trained a mocko model and i",
    "start": "1333679",
    "end": "1335360"
  },
  {
    "text": "trained a pe model alpha's the linux",
    "start": "1335360",
    "end": "1337200"
  },
  {
    "text": "executable format maco runs in osx and",
    "start": "1337200",
    "end": "1339600"
  },
  {
    "text": "pe is the windows executable file format",
    "start": "1339600",
    "end": "1342880"
  },
  {
    "text": "for lf i collected data from 2017 to 21",
    "start": "1342880",
    "end": "1345679"
  },
  {
    "text": "for maco i just collected everything and",
    "start": "1345679",
    "end": "1347679"
  },
  {
    "text": "for pe i selected a small set from 2020",
    "start": "1347679",
    "end": "1350559"
  },
  {
    "text": "to 2021.",
    "start": "1350559",
    "end": "1352640"
  },
  {
    "text": "for elf i had 84 000 bad samples that i",
    "start": "1352640",
    "end": "1355280"
  },
  {
    "text": "was able to scrape from virustotal i had",
    "start": "1355280",
    "end": "1357600"
  },
  {
    "text": "five and a half million good and that",
    "start": "1357600",
    "end": "1359120"
  },
  {
    "text": "breaks down as four and a half million",
    "start": "1359120",
    "end": "1360880"
  },
  {
    "text": "ubuntu samples i basically just set up a",
    "start": "1360880",
    "end": "1362880"
  },
  {
    "text": "job to",
    "start": "1362880",
    "end": "1364159"
  },
  {
    "text": "rip through an ubuntu package repository",
    "start": "1364159",
    "end": "1366320"
  },
  {
    "text": "and extract all the dubs and grab all",
    "start": "1366320",
    "end": "1368480"
  },
  {
    "text": "the elves from those dabs and then put",
    "start": "1368480",
    "end": "1370320"
  },
  {
    "text": "them up to s3 for storage",
    "start": "1370320",
    "end": "1372880"
  },
  {
    "text": "then i grabbed one million samples from",
    "start": "1372880",
    "end": "1374720"
  },
  {
    "text": "virustotal for maco we have about a 10",
    "start": "1374720",
    "end": "1378000"
  },
  {
    "text": "90",
    "start": "1378000",
    "end": "1379039"
  },
  {
    "text": "uh breakdown of bad and good and for pe",
    "start": "1379039",
    "end": "1381600"
  },
  {
    "text": "we have about a 50 50 breakdown between",
    "start": "1381600",
    "end": "1383440"
  },
  {
    "text": "bad and good",
    "start": "1383440",
    "end": "1384960"
  },
  {
    "text": "in terms of true positive rates and",
    "start": "1384960",
    "end": "1386240"
  },
  {
    "text": "false positive rates for elf we got",
    "start": "1386240",
    "end": "1388080"
  },
  {
    "text": "about an 81 true positive rate with 950",
    "start": "1388080",
    "end": "1391039"
  },
  {
    "text": "rules",
    "start": "1391039",
    "end": "1392080"
  },
  {
    "text": "um that's at a zero percent false",
    "start": "1392080",
    "end": "1394240"
  },
  {
    "text": "positive rate for ubuntu samples um when",
    "start": "1394240",
    "end": "1397520"
  },
  {
    "text": "i ran the bulk collection job or the",
    "start": "1397520",
    "end": "1399679"
  },
  {
    "text": "bulk signature generation job i made",
    "start": "1399679",
    "end": "1402480"
  },
  {
    "text": "sure that the ubuntu sequences were",
    "start": "1402480",
    "end": "1404720"
  },
  {
    "text": "weighted more highly than the virus",
    "start": "1404720",
    "end": "1406640"
  },
  {
    "text": "total samples because virus total",
    "start": "1406640",
    "end": "1408080"
  },
  {
    "text": "samples can still be kind of falsy even",
    "start": "1408080",
    "end": "1410400"
  },
  {
    "text": "if there are zero vendor deductions",
    "start": "1410400",
    "end": "1413360"
  },
  {
    "text": "we got about a point one five percent",
    "start": "1413360",
    "end": "1414880"
  },
  {
    "text": "false positive rate on various total",
    "start": "1414880",
    "end": "1416480"
  },
  {
    "text": "samples",
    "start": "1416480",
    "end": "1417919"
  },
  {
    "text": "for maco we got a 90 true positive rate",
    "start": "1417919",
    "end": "1420320"
  },
  {
    "text": "at a 0.01 false positive rate with just",
    "start": "1420320",
    "end": "1422240"
  },
  {
    "text": "11 rules this was a very surprising",
    "start": "1422240",
    "end": "1425200"
  },
  {
    "text": "result and i think this is mostly",
    "start": "1425200",
    "end": "1427120"
  },
  {
    "text": "because there are a lot of",
    "start": "1427120",
    "end": "1428840"
  },
  {
    "text": "mostly mostly identical samples in the",
    "start": "1428840",
    "end": "1431600"
  },
  {
    "text": "maco data set that i collected there's",
    "start": "1431600",
    "end": "1433760"
  },
  {
    "text": "this one particular kind of malware",
    "start": "1433760",
    "end": "1435200"
  },
  {
    "text": "family called eagle quest that just",
    "start": "1435200",
    "end": "1436559"
  },
  {
    "text": "dominates the set of malicious samples i",
    "start": "1436559",
    "end": "1439279"
  },
  {
    "text": "think it's like 30",
    "start": "1439279",
    "end": "1441279"
  },
  {
    "text": "and in the end the model just learned to",
    "start": "1441279",
    "end": "1442799"
  },
  {
    "text": "cue in on those very simple things to",
    "start": "1442799",
    "end": "1444400"
  },
  {
    "text": "come up with an accurate but not",
    "start": "1444400",
    "end": "1446400"
  },
  {
    "text": "all-encompassing classifier",
    "start": "1446400",
    "end": "1448799"
  },
  {
    "text": "and then for pe we got about an 80 true",
    "start": "1448799",
    "end": "1451039"
  },
  {
    "text": "positive rate at a 0.07 false positive",
    "start": "1451039",
    "end": "1453360"
  },
  {
    "text": "rate with 700 rules",
    "start": "1453360",
    "end": "1456720"
  },
  {
    "start": "1456000",
    "end": "1456000"
  },
  {
    "text": "so in terms of future work i'd really",
    "start": "1457039",
    "end": "1458559"
  },
  {
    "text": "like to utilize more yar functionality",
    "start": "1458559",
    "end": "1460640"
  },
  {
    "text": "er is a very expressive language and i'm",
    "start": "1460640",
    "end": "1462400"
  },
  {
    "text": "only using a very very small subset of",
    "start": "1462400",
    "end": "1464159"
  },
  {
    "text": "it there are things like string offset",
    "start": "1464159",
    "end": "1465919"
  },
  {
    "text": "that we could put into the model we can",
    "start": "1465919",
    "end": "1467600"
  },
  {
    "text": "make the model aware of where a string",
    "start": "1467600",
    "end": "1469279"
  },
  {
    "text": "is in the sample to provide more context",
    "start": "1469279",
    "end": "1472000"
  },
  {
    "text": "so if you see something like this",
    "start": "1472000",
    "end": "1473279"
  },
  {
    "text": "program can't be run in dos mode in the",
    "start": "1473279",
    "end": "1475360"
  },
  {
    "text": "middle of the sample that might be kind",
    "start": "1475360",
    "end": "1476799"
  },
  {
    "text": "of weird and the model would help things",
    "start": "1476799",
    "end": "1478880"
  },
  {
    "text": "like that",
    "start": "1478880",
    "end": "1480000"
  },
  {
    "text": "we could also add string counts so the",
    "start": "1480000",
    "end": "1481679"
  },
  {
    "text": "model might be",
    "start": "1481679",
    "end": "1484080"
  },
  {
    "text": "able to look at how often a string",
    "start": "1484080",
    "end": "1486480"
  },
  {
    "text": "occurs in a sample",
    "start": "1486480",
    "end": "1488240"
  },
  {
    "text": "there's also a very expressive boolean",
    "start": "1488240",
    "end": "1490640"
  },
  {
    "text": "operation logic thing that we can use in",
    "start": "1490640",
    "end": "1492559"
  },
  {
    "text": "yara so it can have different sets of",
    "start": "1492559",
    "end": "1494799"
  },
  {
    "text": "strings and we can end and order these",
    "start": "1494799",
    "end": "1496400"
  },
  {
    "text": "things together",
    "start": "1496400",
    "end": "1497679"
  },
  {
    "text": "and then have string count thresholds",
    "start": "1497679",
    "end": "1499919"
  },
  {
    "text": "and things like this",
    "start": "1499919",
    "end": "1501360"
  },
  {
    "text": "and extending the model's ability to",
    "start": "1501360",
    "end": "1503840"
  },
  {
    "text": "account for things like this would be",
    "start": "1503840",
    "end": "1505039"
  },
  {
    "text": "really useful in terms of increasing",
    "start": "1505039",
    "end": "1506480"
  },
  {
    "text": "true positive rates and decreasing false",
    "start": "1506480",
    "end": "1508000"
  },
  {
    "text": "positive rates",
    "start": "1508000",
    "end": "1509679"
  },
  {
    "text": "i'd also like to introduce model driven",
    "start": "1509679",
    "end": "1511520"
  },
  {
    "text": "string wild carding into the setup so",
    "start": "1511520",
    "end": "1513760"
  },
  {
    "text": "replace this hamming distance thing with",
    "start": "1513760",
    "end": "1515760"
  },
  {
    "text": "a model driven string wild carding",
    "start": "1515760",
    "end": "1517840"
  },
  {
    "text": "where we use the model's input",
    "start": "1517840",
    "end": "1519039"
  },
  {
    "text": "sensitivity and we feed in a byte",
    "start": "1519039",
    "end": "1521520"
  },
  {
    "text": "sequence we get it score",
    "start": "1521520",
    "end": "1523279"
  },
  {
    "text": "and then we look at a byte we start",
    "start": "1523279",
    "end": "1525760"
  },
  {
    "text": "moving that bot around we replace it",
    "start": "1525760",
    "end": "1527600"
  },
  {
    "text": "with random values and if the model",
    "start": "1527600",
    "end": "1529360"
  },
  {
    "text": "score doesn't change much we can say",
    "start": "1529360",
    "end": "1531120"
  },
  {
    "text": "well the model doesn't care much about",
    "start": "1531120",
    "end": "1532559"
  },
  {
    "text": "the spite so we can just wild card and",
    "start": "1532559",
    "end": "1536000"
  },
  {
    "text": "yeah this would be much less hacky and a",
    "start": "1536000",
    "end": "1538480"
  },
  {
    "text": "much more model-driven way of doing wild",
    "start": "1538480",
    "end": "1540880"
  },
  {
    "text": "carding",
    "start": "1540880",
    "end": "1542480"
  },
  {
    "text": "i'd also like to integrate this tool",
    "start": "1542480",
    "end": "1543840"
  },
  {
    "text": "with parsing libraries so have better",
    "start": "1543840",
    "end": "1546240"
  },
  {
    "text": "context in terms of what exactly this",
    "start": "1546240",
    "end": "1549039"
  },
  {
    "text": "byte sequence is if the byte sequence is",
    "start": "1549039",
    "end": "1551120"
  },
  {
    "text": "in",
    "start": "1551120",
    "end": "1551760"
  },
  {
    "text": "let's say an executable section or",
    "start": "1551760",
    "end": "1553679"
  },
  {
    "text": "something like that maybe we can do some",
    "start": "1553679",
    "end": "1555200"
  },
  {
    "text": "disassembly",
    "start": "1555200",
    "end": "1556400"
  },
  {
    "text": "and then get an idea of what kind of op",
    "start": "1556400",
    "end": "1557919"
  },
  {
    "text": "codes are on this around the signature",
    "start": "1557919",
    "end": "1560159"
  },
  {
    "text": "that we grabbed out",
    "start": "1560159",
    "end": "1561360"
  },
  {
    "text": "see if the",
    "start": "1561360",
    "end": "1563120"
  },
  {
    "text": "see if the bytes that we're grabbing out",
    "start": "1563120",
    "end": "1564400"
  },
  {
    "text": "are in the overlay section see if they",
    "start": "1564400",
    "end": "1566080"
  },
  {
    "text": "correspond to data see if they",
    "start": "1566080",
    "end": "1567200"
  },
  {
    "text": "correspond to code see if they",
    "start": "1567200",
    "end": "1568960"
  },
  {
    "text": "correspond to interesting things and",
    "start": "1568960",
    "end": "1570320"
  },
  {
    "text": "headers things like this i feel like",
    "start": "1570320",
    "end": "1572080"
  },
  {
    "text": "that would be really useful for malware",
    "start": "1572080",
    "end": "1573679"
  },
  {
    "text": "analysts to be able to",
    "start": "1573679",
    "end": "1575200"
  },
  {
    "text": "quickly be able to look at a string or a",
    "start": "1575200",
    "end": "1577520"
  },
  {
    "text": "sequence of bytes and be able to see",
    "start": "1577520",
    "end": "1579279"
  },
  {
    "text": "where those bytes came from and see if",
    "start": "1579279",
    "end": "1580640"
  },
  {
    "text": "that would be a workable rule",
    "start": "1580640",
    "end": "1584159"
  },
  {
    "text": "so with that i'd like to thank you a lot",
    "start": "1584159",
    "end": "1585440"
  },
  {
    "text": "for showing up to this talk again very",
    "start": "1585440",
    "end": "1586960"
  },
  {
    "text": "excited about this work and yeah i'll",
    "start": "1586960",
    "end": "1589120"
  },
  {
    "text": "open up the floor for questions thanks",
    "start": "1589120",
    "end": "1590880"
  },
  {
    "text": "again",
    "start": "1590880",
    "end": "1593880"
  }
]
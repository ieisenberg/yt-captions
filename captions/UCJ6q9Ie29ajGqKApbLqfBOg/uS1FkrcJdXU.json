[
  {
    "start": "0",
    "end": "215000"
  },
  {
    "text": "so without further ado join me in welcoming the Esper thank you maybe we",
    "start": "30",
    "end": "8099"
  },
  {
    "text": "should start easy because this is a quite a complex dog who here knows what it feels like to be about 30 feet away",
    "start": "8099",
    "end": "16740"
  },
  {
    "text": "from a type 1 supernova I can actually",
    "start": "16740",
    "end": "21869"
  },
  {
    "text": "can't see how many hands are being raised right now cuz I am anyway yeah",
    "start": "21869",
    "end": "28470"
  },
  {
    "text": "I'm pretty excited to be here I'm gonna be talking about applying deep learning to side-channel problems and I'm",
    "start": "28470",
    "end": "37170"
  },
  {
    "text": "particularly interested in this topic because I've been doing security professionally since about 2001",
    "start": "37170",
    "end": "42989"
  },
  {
    "text": "and machine learning as a hobby since about 1999 so this was season before all",
    "start": "42989",
    "end": "48000"
  },
  {
    "text": "the deep learning stuff but even beyond that I think more importantly what we're",
    "start": "48000",
    "end": "55170"
  },
  {
    "text": "facing right now in the world is is just you two miles of security issues and really the only way that we're going to",
    "start": "55170",
    "end": "61680"
  },
  {
    "text": "overcome this is to scale up our our testing capabilities our problem-solving",
    "start": "61680",
    "end": "67530"
  },
  {
    "text": "capabilities I think machine learning is one way of doing that so I'm pretty excited to to",
    "start": "67530",
    "end": "73500"
  },
  {
    "text": "show that to you also this work wouldn't have been possible with my two colleagues Yemm and bearish as well",
    "start": "73500",
    "end": "80159"
  },
  {
    "text": "we'll hopefully are fast asleep right now in a in a different continent so",
    "start": "80159",
    "end": "85500"
  },
  {
    "text": "let's get start oh wait I have a clicker thing that's on it's not on and it's",
    "start": "85500",
    "end": "94979"
  },
  {
    "text": "working so before when we were doing side channel analysis the main steps are",
    "start": "94979",
    "end": "101130"
  },
  {
    "text": "we take a chip we measure its power consumption we do some fancy signal",
    "start": "101130",
    "end": "107729"
  },
  {
    "text": "processing we do some leakage modeling and then out comes the cryptographic key if we're successful if you look at",
    "start": "107729",
    "end": "117180"
  },
  {
    "text": "academic literature that studied a lot this leakage modeling and the key a retrieval part which is kind of the",
    "start": "117180",
    "end": "123090"
  },
  {
    "text": "science in inside channel analysis there's also really an art kind of human skill involved in getting",
    "start": "123090",
    "end": "129690"
  },
  {
    "text": "your signals acquired in the right way and transforming them in such a way that",
    "start": "129690",
    "end": "134910"
  },
  {
    "text": "you actually can do the linkage modeling and the key extraction so this is an obvious bottleneck and scaling up these",
    "start": "134910",
    "end": "141360"
  },
  {
    "text": "kind of tests so what we've been researching is what",
    "start": "141360",
    "end": "147090"
  },
  {
    "text": "happens if we replace those two yellow boxes there with a neural network",
    "start": "147090",
    "end": "153000"
  },
  {
    "text": "specifically a deep neural network so that's what I'm going to be talking",
    "start": "153000",
    "end": "158910"
  },
  {
    "text": "about and for that I'll first normally I would now take a survey of like who",
    "start": "158910",
    "end": "164280"
  },
  {
    "text": "knows DPA and who knows deep learning but I can't see you anyway so all them I'll just dive into the basics of both",
    "start": "164280",
    "end": "170549"
  },
  {
    "text": "and then I'll explain the experiments that we did and the results that we got",
    "start": "170549",
    "end": "176900"
  },
  {
    "text": "so let's first do power and e/m side channel analysis and for a sake of time",
    "start": "176900",
    "end": "183269"
  },
  {
    "text": "I'm going to stay pretty abstract which also means that I'm not a hundred percent correct but you can ask me",
    "start": "183269",
    "end": "189329"
  },
  {
    "text": "questions there so the first stage of site analysis is very sexy obviously we",
    "start": "189329",
    "end": "195870"
  },
  {
    "text": "have oscilloscopes we have devices we acquire all these cool traces and this",
    "start": "195870",
    "end": "203220"
  },
  {
    "text": "is still a manual part even with what we're doing the deep learning now we don't have our robots trained yet to connect these these little boards but",
    "start": "203220",
    "end": "211230"
  },
  {
    "text": "after this stage we're gonna do something else but traditionally you would start there and you get these kind",
    "start": "211230",
    "end": "217230"
  },
  {
    "start": "215000",
    "end": "215000"
  },
  {
    "text": "of traces so this is a power profile from some Cryptologic algorithm that's that's executing bonus points if you",
    "start": "217230",
    "end": "225239"
  },
  {
    "text": "come after me and after to talk to me and tell me what it is and the whole goal is just to extract this",
    "start": "225239",
    "end": "230880"
  },
  {
    "text": "cryptographic key from the from the power consumption now this is just step",
    "start": "230880",
    "end": "237989"
  },
  {
    "text": "one after you've taken these traces I'll",
    "start": "237989",
    "end": "243209"
  },
  {
    "start": "238000",
    "end": "238000"
  },
  {
    "text": "actually show you kind of what what you can see this is one example of a trace then this one actually has huge leakage",
    "start": "243209",
    "end": "249989"
  },
  {
    "text": "you can't see that yet because you have to zoom in a little bit if you zoom in here you see the execution of almost to",
    "start": "249989",
    "end": "257579"
  },
  {
    "text": "full quark cycles of a other device and if you take a number of these traces",
    "start": "257579",
    "end": "264410"
  },
  {
    "text": "in and overlap them you can start seeing where the traces start to diverge",
    "start": "264410",
    "end": "270370"
  },
  {
    "text": "and that can actually mean two things it can be really huge data leakage or it",
    "start": "270370",
    "end": "275690"
  },
  {
    "text": "can be some noise now I'm saying really you today the leakage because here you can visually see that the traces are",
    "start": "275690",
    "end": "282169"
  },
  {
    "text": "actually diverging which normally if you have a fairly well protective device the",
    "start": "282169",
    "end": "288380"
  },
  {
    "text": "leakage is below the noise threshold so you're not going to be able to see it with the naked eye you need some kind of",
    "start": "288380",
    "end": "293590"
  },
  {
    "text": "Statistics and filtering to get to that point so let me just take one sip of",
    "start": "293590",
    "end": "301819"
  },
  {
    "text": "water and then just dive right in I prefer to show things live there's",
    "start": "301819",
    "end": "307460"
  },
  {
    "text": "always a bit of risk associated obviously but let's do it anyway Oh or",
    "start": "307460",
    "end": "315830"
  },
  {
    "text": "the beautiful trace no worry I also see just a blue band here there's nothing to",
    "start": "315830",
    "end": "321470"
  },
  {
    "text": "see here and it's not until you start zooming in that there's some stuff happening this is actually quite ugly I",
    "start": "321470",
    "end": "329630"
  },
  {
    "text": "can blow it up a bit for if you're interested I don't see a whole lot of",
    "start": "329630",
    "end": "335330"
  },
  {
    "text": "pattern here it's big blogs etc so here there comes out first phase that I need to do something with this this signal to",
    "start": "335330",
    "end": "341630"
  },
  {
    "text": "make it pretty so with this one that happened to know what buttons to press so let's just do data so I'm actually",
    "start": "341630",
    "end": "348680"
  },
  {
    "text": "taking an absolute value in a low-pass which kind of calculates an envelope over to signal so I get again this trace",
    "start": "348680",
    "end": "355990"
  },
  {
    "text": "nice and blue and a new night low-pass filter ah now it's starting to look like",
    "start": "355990",
    "end": "363110"
  },
  {
    "text": "something that's assumed in now you can start seeing a nice like repetitive",
    "start": "363110",
    "end": "369050"
  },
  {
    "text": "pattern there this is actually nice to see implementation if you're interested but normally this takes a little bit of",
    "start": "369050",
    "end": "377090"
  },
  {
    "text": "fiddling with the signal right I've now done the happy flow but normally you don't know what to do in this filtering",
    "start": "377090",
    "end": "383270"
  },
  {
    "text": "process so there's a similar problem you need to overcome show you the written",
    "start": "383270",
    "end": "390830"
  },
  {
    "text": "here which was I gonna do you know this one are not",
    "start": "390830",
    "end": "412720"
  },
  {
    "text": "a beautiful signal what you see if I scroll through the signals here you can",
    "start": "412720",
    "end": "419830"
  },
  {
    "text": "kind of see it's jumping back and forth so we call this misalignment so the traces aren't really like properly",
    "start": "419830",
    "end": "426550"
  },
  {
    "text": "aligned which is a problem for the algorithms further down the road so obviously we have solutions to this so",
    "start": "426550",
    "end": "433270"
  },
  {
    "text": "we take an area like this here and we perform an alignment of it ignore for",
    "start": "433270",
    "end": "440710"
  },
  {
    "text": "now without typing in and press the",
    "start": "440710",
    "end": "450370"
  },
  {
    "text": "wrong here I'm only going to do it on the hundred traces though it takes too long and the problem is I'm not really",
    "start": "450370",
    "end": "460060"
  },
  {
    "text": "getting any results there's not a problem of the demo but it's the problem that I put in the wrong parameters and",
    "start": "460060",
    "end": "467319"
  },
  {
    "text": "this is the problem with humans you have to try a lot of things and sometimes you screw I have things up I can actually",
    "start": "467319",
    "end": "472810"
  },
  {
    "text": "make this one work if I it so you see that I'm not kidding if I take this",
    "start": "472810",
    "end": "481509"
  },
  {
    "text": "ignore I do in alignment I would take on their traces and instead of the matching",
    "start": "481509",
    "end": "492159"
  },
  {
    "text": "threshold is basically what the correlation needs to be for it to say okay this is a nice overlap I put that a",
    "start": "492159",
    "end": "497440"
  },
  {
    "text": "little bit lower so I fiddle with the parameters and now I get 100 trade",
    "start": "497440",
    "end": "502870"
  },
  {
    "text": "actually 84 traces are dropped a few that are supposedly aligned and if I scroll down it's not much better all",
    "start": "502870",
    "end": "511719"
  },
  {
    "text": "right it's still jumping a bit what you do see is that this area that I selected before I'll zoom in on it a little bit",
    "start": "511719",
    "end": "517560"
  },
  {
    "text": "now actually it does seem to overlap so something has happened but I'm still not",
    "start": "517560",
    "end": "524020"
  },
  {
    "text": "there this is still part of kind of the art of doing exciting amounts you have all",
    "start": "524020",
    "end": "529759"
  },
  {
    "text": "these tools alignment filtering etc but you need experience and knowledge of",
    "start": "529759",
    "end": "534949"
  },
  {
    "text": "these tools to figure out how to put them together before you can really prepare your signal into into something",
    "start": "534949",
    "end": "540170"
  },
  {
    "text": "useful so let's move to the science part",
    "start": "540170",
    "end": "546970"
  },
  {
    "text": "so we talked about signatures misalignments so what's really going on",
    "start": "546970",
    "end": "554240"
  },
  {
    "start": "551000",
    "end": "551000"
  },
  {
    "text": "here I just want to give you a gist of what am i doing what I'm gonna do with all these signals so let's say we have",
    "start": "554240",
    "end": "560120"
  },
  {
    "text": "an aes 128 implementation and if you look at the first part of the first round it gets a 16 byte input vector if",
    "start": "560120",
    "end": "570110"
  },
  {
    "text": "xor is the key in keys well where we're interested in that's what we want to know but we don't know it then out comes",
    "start": "570110",
    "end": "578300"
  },
  {
    "text": "some data which goes through an sbox and after the S box you get some more intermediate data and there's a whole",
    "start": "578300",
    "end": "584329"
  },
  {
    "text": "lot more a as having after that but what we're interested in is modeling the",
    "start": "584329",
    "end": "589699"
  },
  {
    "text": "power consumption of this device just after it's executed the S box there",
    "start": "589699",
    "end": "595120"
  },
  {
    "text": "excuse me the reason for that is that if we let's say let's say we take s 0 there",
    "start": "595120",
    "end": "601279"
  },
  {
    "text": "that intermediate if we can predict maybe not exactly but maybe",
    "start": "601279",
    "end": "607240"
  },
  {
    "text": "probabilistically what the value for s 0 is that means we can actually work back",
    "start": "607240",
    "end": "612559"
  },
  {
    "text": "for the S box to say what X 0 is which means that if we know the input which is",
    "start": "612559",
    "end": "617870"
  },
  {
    "text": "an assumption in DPA we can calculate what the key bite is so it's really",
    "start": "617870",
    "end": "623660"
  },
  {
    "text": "important to understand that there's this relation between the power consumption of intermediate values and",
    "start": "623660",
    "end": "630009"
  },
  {
    "text": "the actual key values I might not be predicting exactly the key value but something that allows me to calculate it",
    "start": "630009",
    "end": "637269"
  },
  {
    "text": "also this is always probabilistically so instead of learning exactly what s0 is",
    "start": "637269",
    "end": "645920"
  },
  {
    "text": "we get a probability distribution over all the values for s 0 which we can calculate back to a probability",
    "start": "645920",
    "end": "652279"
  },
  {
    "text": "distribution over all the values of K 0 so it gives us just some statistics on",
    "start": "652279",
    "end": "657439"
  },
  {
    "text": "what this key and if we do this over and over and over again for multiple traces those",
    "start": "657439",
    "end": "662820"
  },
  {
    "text": "statistics will start to accumulate and I can cancel out noise and eventually there's this one key bite which sort of",
    "start": "662820",
    "end": "669029"
  },
  {
    "text": "has the highest probability and that's the one we use once you have one key bite if you just repeat the whole",
    "start": "669029",
    "end": "674579"
  },
  {
    "text": "process for all the other ones and then you get full a s key",
    "start": "674579",
    "end": "679880"
  },
  {
    "start": "682000",
    "end": "682000"
  },
  {
    "text": "now another step in doing cycle analysis for this is what we call point of",
    "start": "683839",
    "end": "689670"
  },
  {
    "text": "interest selection which basically is what we just talked about so we want to predict what the sbox",
    "start": "689670",
    "end": "696149"
  },
  {
    "text": "output is ideally we don't analyze the entire trace we only analyze the part where this S box out value is present",
    "start": "696149",
    "end": "704510"
  },
  {
    "text": "this is particularly important for the template attacks which we'll talk about",
    "start": "704510",
    "end": "711029"
  },
  {
    "text": "in the next slide because they're very sensitive to putting in samples or parts",
    "start": "711029",
    "end": "717329"
  },
  {
    "text": "of the trace that actually have nothing to do with the key it adds so much noise that's the number of training traces",
    "start": "717329",
    "end": "722490"
  },
  {
    "text": "that you need is too much to actually do some decent key extraction so when we do",
    "start": "722490",
    "end": "731279"
  },
  {
    "start": "729000",
    "end": "729000"
  },
  {
    "text": "when I say template analysis and the basic process is that I want to take a",
    "start": "731279",
    "end": "737250"
  },
  {
    "text": "device for which I can program the key build these templates for the basically",
    "start": "737250",
    "end": "744269"
  },
  {
    "text": "models that relates these intermediate values to the power usage and then once",
    "start": "744269",
    "end": "751199"
  },
  {
    "text": "I get either the same device but maybe a different app or another device with the same chip I can apply my learn templates",
    "start": "751199",
    "end": "759480"
  },
  {
    "text": "and learned there learn what the actual key is so in the one hand I'm building",
    "start": "759480",
    "end": "765149"
  },
  {
    "text": "templates from power traces in the bottom have been taking these templates and I'm matching them to power trace in",
    "start": "765149",
    "end": "771149"
  },
  {
    "text": "order to get keys out again and again these are probabilistic methods so I",
    "start": "771149",
    "end": "778380"
  },
  {
    "text": "don't I need a bunch of traces in order for my templates to output the correct",
    "start": "778380",
    "end": "783630"
  },
  {
    "text": "key bite with some confidence",
    "start": "783630",
    "end": "787820"
  },
  {
    "text": "after we've done this we do something which is called the key recovery phase",
    "start": "791250",
    "end": "797250"
  },
  {
    "text": "and what you see on this slide is on the on the x-axis the number of traces that",
    "start": "797250",
    "end": "802930"
  },
  {
    "text": "we're using to attack a device on the y-axis you see the rank of the correct",
    "start": "802930",
    "end": "809950"
  },
  {
    "text": "key bytes so let's say we this is in a test scenario right so we know what the",
    "start": "809950",
    "end": "815649"
  },
  {
    "text": "actual key is but now we're gonna try to see how close we are to actually extracting that key so a plot like this",
    "start": "815649",
    "end": "821800"
  },
  {
    "text": "shows that so this ranking comes from the probabilities that you're building up over all the keys so you can see in",
    "start": "821800",
    "end": "828970"
  },
  {
    "text": "the beginning on average that rank will be about 1028 right in the middle between 0 and 255 and the more",
    "start": "828970",
    "end": "836130"
  },
  {
    "text": "statistics you accumulate the lower that actual key byte will drop in the ranking",
    "start": "836130",
    "end": "841870"
  },
  {
    "text": "and as soon as all 16 key bites are at rank zero we've actually found the key so that's what happens at the back there",
    "start": "841870",
    "end": "849190"
  },
  {
    "text": "and an often used metric for this is just a number of traces that you need to extract the key so as soon as you see",
    "start": "849190",
    "end": "857260"
  },
  {
    "text": "these plots all the lines kind of converge to zero that's the point where you can extract the key so for this",
    "start": "857260",
    "end": "862570"
  },
  {
    "text": "device we would say we can extract the key in like 50 thousand no sorry five",
    "start": "862570",
    "end": "868690"
  },
  {
    "text": "thousand traces so that's not very strong advice now obviously I've been",
    "start": "868690",
    "end": "876040"
  },
  {
    "start": "874000",
    "end": "874000"
  },
  {
    "text": "just lying to you because this all looks like a waterfall process you do some",
    "start": "876040",
    "end": "881709"
  },
  {
    "text": "filtering some leak its modeling and then out comes the key this is not",
    "start": "881709",
    "end": "887380"
  },
  {
    "text": "reality in reality you make an acquisition you do some filtering the",
    "start": "887380",
    "end": "892480"
  },
  {
    "text": "filtering doesn't work you go back to the drawing board you make its modeling still the key",
    "start": "892480",
    "end": "898839"
  },
  {
    "text": "doesn't come out you find out you didn't connect the wire during acquisition so you go back to that and this is really",
    "start": "898839",
    "end": "904690"
  },
  {
    "text": "an ongoing process that's yeah which humans are involved it's basically using",
    "start": "904690",
    "end": "911380"
  },
  {
    "text": "tools and getting feedback and trying to get basically all the all the stars",
    "start": "911380",
    "end": "916420"
  },
  {
    "text": "aligned in order to get a key out so part of this and specifically",
    "start": "916420",
    "end": "921740"
  },
  {
    "text": "processing an analyst F that's where we're going to tackle with with deep learning so let me talk about that for a",
    "start": "921740",
    "end": "929270"
  },
  {
    "text": "moment so just in general when when",
    "start": "929270",
    "end": "938660"
  },
  {
    "start": "933000",
    "end": "933000"
  },
  {
    "text": "you're applying or when you're doing deep learning really what you're interested is separating dogs from cats",
    "start": "938660",
    "end": "944170"
  },
  {
    "text": "at least when you have classification problems so we have some labeled images of cats we have some labeled images of",
    "start": "944170",
    "end": "950630"
  },
  {
    "text": "dogs and we're going to try to build a machine that's once you give it a new",
    "start": "950630",
    "end": "955970"
  },
  {
    "text": "picture it will say this is a cat with X percent probability and a dog with one",
    "start": "955970",
    "end": "962000"
  },
  {
    "text": "minus X precise probability so in order",
    "start": "962000",
    "end": "967490"
  },
  {
    "text": "to do that we feed it with all these examples and we're training the machine",
    "start": "967490",
    "end": "973400"
  },
  {
    "text": "or a network in this case and in your initial step your machine is that a bit",
    "start": "973400",
    "end": "979820"
  },
  {
    "text": "be pretty poor at doing this kind of classification so outcome some raw some",
    "start": "979820",
    "end": "985130"
  },
  {
    "text": "probabilities that really don't represent what what the input is what you run there is so called back",
    "start": "985130",
    "end": "991550"
  },
  {
    "text": "propagation algorithm and there's a lot of literature and deep learning on how to run this and different variants and",
    "start": "991550",
    "end": "997760"
  },
  {
    "text": "everything but basically you're tweaking the machine to do just a little bit better and if you keep on doing this over and",
    "start": "997760",
    "end": "1004960"
  },
  {
    "text": "over and over again ideally your machine just gets better and better and better at the classification so once you have a",
    "start": "1004960",
    "end": "1013420"
  },
  {
    "text": "candidate where you think like this now works quite well in classification you",
    "start": "1013420",
    "end": "1019870"
  },
  {
    "text": "test the machine on new data that it hasn't seen yet so this is called validation data if the accuracy is good",
    "start": "1019870",
    "end": "1028209"
  },
  {
    "text": "enough on this validation data then good you're happy otherwise you're gonna have to tweak your machine a little bit and",
    "start": "1028210",
    "end": "1034390"
  },
  {
    "text": "obviously you're gonna be in that no cycle for a couple times before you hit it yes and I'll show you that as well so",
    "start": "1034390",
    "end": "1043420"
  },
  {
    "start": "1042000",
    "end": "1042000"
  },
  {
    "text": "just to speak a little bit under the hood here we're going to be using one specific type of network which is called",
    "start": "1043420",
    "end": "1050080"
  },
  {
    "text": "a convolutional neural network and it was actually designed for image",
    "start": "1050080",
    "end": "1057060"
  },
  {
    "text": "processing but it has some parallels with side channel analysis that actually",
    "start": "1057060",
    "end": "1063250"
  },
  {
    "text": "made it interesting enough for us to take a look at to see if it applies there as well what it really does is it",
    "start": "1063250",
    "end": "1070300"
  },
  {
    "text": "has an input layer which is just a representation of your input in the case",
    "start": "1070300",
    "end": "1075490"
  },
  {
    "text": "of cat pictures is just one neuron per pixel 3 I guess if you do in color they",
    "start": "1075490",
    "end": "1083080"
  },
  {
    "text": "have a number of convolutional layers and these convolutional layers they're trained to extract certain features so",
    "start": "1083080",
    "end": "1091420"
  },
  {
    "text": "for instance in the first layer it might be just extracting edges in the next layer it might use this information of",
    "start": "1091420",
    "end": "1098050"
  },
  {
    "text": "edges to constructs an eye and a nose some cute fluffy ears and then in the",
    "start": "1098050",
    "end": "1103720"
  },
  {
    "text": "next layer it will combine this to recognize cat face for instance after",
    "start": "1103720",
    "end": "1109690"
  },
  {
    "text": "that is a number of layers which we call the dense layers and these are used for",
    "start": "1109690",
    "end": "1115570"
  },
  {
    "text": "classification so they take this kind of feature extract that encoded information",
    "start": "1115570",
    "end": "1121150"
  },
  {
    "text": "and turn it into the probability for a certain class cat or dog and the cool",
    "start": "1121150",
    "end": "1127090"
  },
  {
    "text": "thing about the convolutional part is that it's actually able to detect",
    "start": "1127090",
    "end": "1132130"
  },
  {
    "text": "features independent of their position and also scale so you can see I can",
    "start": "1132130",
    "end": "1137680"
  },
  {
    "text": "rotate this cat up don't do this in real life it's really cruel to the kitties but on the pictures you can turn them",
    "start": "1137680",
    "end": "1142960"
  },
  {
    "text": "upside down and left and right and it will still detect them and if you",
    "start": "1142960",
    "end": "1148150"
  },
  {
    "text": "remember our misalignment example that's kind of a similar thing that's happening there",
    "start": "1148150",
    "end": "1153760"
  },
  {
    "text": "like there's this traces that are dancing around they're not exactly in the same place so we're hoping that",
    "start": "1153760",
    "end": "1159040"
  },
  {
    "text": "these convolutional Dannette the properties of this conclusion that will help us in recovering information anyway",
    "start": "1159040",
    "end": "1167010"
  },
  {
    "start": "1166000",
    "end": "1166000"
  },
  {
    "text": "so once we apply this to our type of data really what we're doing is we're taking these traces and we're turning",
    "start": "1167010",
    "end": "1174430"
  },
  {
    "text": "them into one input vector basically one one neuron per sample that we have in",
    "start": "1174430",
    "end": "1181960"
  },
  {
    "text": "the trace and we don't label them as cats and dogs but we label them by the Hemingway - for instance the outputs of",
    "start": "1181960",
    "end": "1189549"
  },
  {
    "text": "the sbox you can ask me later why Hemingway and this is called the the",
    "start": "1189549",
    "end": "1197140"
  },
  {
    "text": "leakage model that we're using that's a term from side channel analysis but basically this is again in a",
    "start": "1197140",
    "end": "1202299"
  },
  {
    "text": "classification problem we take in a trace and we want to figure out what the",
    "start": "1202299",
    "end": "1207970"
  },
  {
    "text": "Hamming weight of that as zero values now once we get once we've trained this",
    "start": "1207970",
    "end": "1214419"
  },
  {
    "start": "1211000",
    "end": "1211000"
  },
  {
    "text": "we actually can do the classification so we again input a trace that it's never seen before it runs through the deep",
    "start": "1214419",
    "end": "1220990"
  },
  {
    "text": "Learning Network and the outputs again just like with the template attack is a probability distribution over the",
    "start": "1220990",
    "end": "1227200"
  },
  {
    "text": "different Hemingway's and this allows me to calculate a probability distribution over key values",
    "start": "1227200",
    "end": "1233130"
  },
  {
    "text": "so it's a very compatible problem so we pulled this out and plugged it into our",
    "start": "1233130",
    "end": "1239710"
  },
  {
    "text": "sights on engine yeah obviously you can actually use the same key an enumeration",
    "start": "1239710",
    "end": "1245260"
  },
  {
    "text": "after this so that was that in theory let's look at the practice for a second",
    "start": "1245260",
    "end": "1252900"
  },
  {
    "text": "um let's first go and do this so I'll",
    "start": "1252900",
    "end": "1261370"
  },
  {
    "text": "open up a trace here blow it up for the people in the back and or with Pat eyes",
    "start": "1261370",
    "end": "1269940"
  },
  {
    "text": "and I wish I had time to go into all",
    "start": "1269940",
    "end": "1276010"
  },
  {
    "text": "these parameters but I don't um but basically what I'm doing is I'm configuring here the neural network that",
    "start": "1276010",
    "end": "1281530"
  },
  {
    "text": "I want to do to attack this particular trace set in this case and purpose I'm",
    "start": "1281530",
    "end": "1291250"
  },
  {
    "text": "making a way to small network so it actually won't be able to learn from this but let's see so it's just one",
    "start": "1291250",
    "end": "1296950"
  },
  {
    "text": "dense layer with ten neurons and I threw out the convolutional part run this now",
    "start": "1296950",
    "end": "1305980"
  },
  {
    "text": "normally you would take a farm of GPUs and crunch",
    "start": "1305980",
    "end": "1311400"
  },
  {
    "text": "it over it now my poor laptop for some technical reason it doesn't support the",
    "start": "1311400",
    "end": "1316860"
  },
  {
    "text": "the GPU and in this particular application but there's one advantage we have and that's we're actually doing",
    "start": "1316860",
    "end": "1323220"
  },
  {
    "text": "this not on big data we're doing this on fairly small data it's almost done it's computation it's",
    "start": "1323220",
    "end": "1331920"
  },
  {
    "text": "back and for everybody who cannot read this but it's saying here is the the",
    "start": "1331920",
    "end": "1341550"
  },
  {
    "text": "correct key was x value 6e and it found key 8a in other words it failed to",
    "start": "1341550",
    "end": "1348030"
  },
  {
    "text": "recover the correct key so this is what happens obviously when you start doing deep learning because nothing works out",
    "start": "1348030",
    "end": "1354660"
  },
  {
    "text": "of the box ever I guess that's more of a life thing than a deep learning thing so we need to do",
    "start": "1354660",
    "end": "1363540"
  },
  {
    "start": "1359000",
    "end": "1359000"
  },
  {
    "text": "it a little bit more work so we need to actually think a little bit about the structure of this network so obviously",
    "start": "1363540",
    "end": "1369030"
  },
  {
    "text": "the network that I just selected with one layer ten neurons it's not working",
    "start": "1369030",
    "end": "1374640"
  },
  {
    "text": "on this particular example so there's a few things it can give you like numbers",
    "start": "1374640",
    "end": "1380670"
  },
  {
    "text": "right now that work because it depends on the trace trace epoch you have in them the noise characteristics leakage",
    "start": "1380670",
    "end": "1386280"
  },
  {
    "text": "characteristics but basically if you have a tray set the input neuron size is",
    "start": "1386280",
    "end": "1394110"
  },
  {
    "text": "the length the number of samples that one's easy the number of convolutional steps we",
    "start": "1394110",
    "end": "1401820"
  },
  {
    "text": "find basically depends on how much misalignment you have if you have almost no misalignment then you almost don't",
    "start": "1401820",
    "end": "1408030"
  },
  {
    "text": "need that layer the more you have the more of these layers you'll need",
    "start": "1408030",
    "end": "1413510"
  },
  {
    "text": "similarly playing with the the size of the dense the dense layers also allows",
    "start": "1413510",
    "end": "1421500"
  },
  {
    "text": "you to classify some targets or some not but I'll give you a general strategy on how to figure out how this how you get",
    "start": "1421500",
    "end": "1429300"
  },
  {
    "text": "to the right parameters so the first thing we try to do is make sure that the",
    "start": "1429300",
    "end": "1436650"
  },
  {
    "start": "1433000",
    "end": "1433000"
  },
  {
    "text": "whole network is actually capable of learning that's kind of a good base case to check so what you need to do it",
    "start": "1436650",
    "end": "1443270"
  },
  {
    "text": "you you you need to make a network that's complex enough to be able to capture all these classes and get a",
    "start": "1443270",
    "end": "1448760"
  },
  {
    "text": "really high so we call accuracy or recall and you see that on the on the",
    "start": "1448760",
    "end": "1454460"
  },
  {
    "text": "left-hand side of this screen so as the network is training throughout time the",
    "start": "1454460",
    "end": "1459500"
  },
  {
    "text": "recall go for them in this case its accuracy goes up which means that I'm learning from my data I'm getting better",
    "start": "1459500",
    "end": "1466130"
  },
  {
    "text": "and better at representing it on the right hand side to see the lost function which is another representation of",
    "start": "1466130",
    "end": "1472720"
  },
  {
    "text": "seeing how well your network is which is great ok now we have a network that's",
    "start": "1472720",
    "end": "1478850"
  },
  {
    "text": "actually capable of learning the problem is that if you make a network too",
    "start": "1478850",
    "end": "1485300"
  },
  {
    "text": "complex it suffers from what's called the memorization effect so if you make a",
    "start": "1485300",
    "end": "1490670"
  },
  {
    "text": "really complex network it can actually start memorizing every input you get given it and get a perfect",
    "start": "1490670",
    "end": "1496400"
  },
  {
    "text": "classification but you give it some modern inputs which it's never seen before",
    "start": "1496400",
    "end": "1501610"
  },
  {
    "text": "terrible terrible classification rates so what do you do next so I make my",
    "start": "1501610",
    "end": "1508340"
  },
  {
    "text": "network bigger and bigger until I get a good training accuracy now I'm going to",
    "start": "1508340",
    "end": "1513920"
  },
  {
    "text": "make sure that my validation accuracy goes up so this is the picture that you want to see so I'm the gray you see the",
    "start": "1513920",
    "end": "1521360"
  },
  {
    "start": "1516000",
    "end": "1516000"
  },
  {
    "text": "the Train sense it needs to go up and up and up and that work needs to be learning but you need to see that the",
    "start": "1521360",
    "end": "1527500"
  },
  {
    "text": "validation recall or accuracy also goes up if you don't have that then your",
    "start": "1527500",
    "end": "1533060"
  },
  {
    "text": "network is not generalizing you're actually not learning you're just memorizing what you do if you look for",
    "start": "1533060",
    "end": "1543020"
  },
  {
    "text": "this special threshold here so in the case of the Hamming weight of a byte they're actually nine classes if you",
    "start": "1543020",
    "end": "1549620"
  },
  {
    "text": "have Hamming weight zero to eight which means that if I flip a coin and I say",
    "start": "1549620",
    "end": "1555080"
  },
  {
    "text": "the Hamming weight of this trace is blah I'm right one out of nine times so",
    "start": "1555080",
    "end": "1560690"
  },
  {
    "text": "that's actually the the minimum accuracy that you want to see recall that you want to see that's not so as soon as it",
    "start": "1560690",
    "end": "1568940"
  },
  {
    "text": "goes above that that means you're generalizing so you're actually seeing in your in your validation set that",
    "start": "1568940",
    "end": "1574370"
  },
  {
    "text": "you're you're better than corn flip accuracy there's other techniques for",
    "start": "1574370",
    "end": "1584270"
  },
  {
    "text": "making the network or there's techniques for making the network generalize I mentioned a couple of here but I'll just",
    "start": "1584270",
    "end": "1590480"
  },
  {
    "text": "highlight the data augmentation part so if you have there a few examples you can",
    "start": "1590480",
    "end": "1597470"
  },
  {
    "text": "actually artificially create new examples and the way you do that for instance let's say I've I'm at the trace",
    "start": "1597470",
    "end": "1604070"
  },
  {
    "text": "that that's somewhat misaligned I can actually take the first trace and",
    "start": "1604070",
    "end": "1609429"
  },
  {
    "text": "generate ten examples with that with different misalignments and this will actually help the network understand",
    "start": "1609429",
    "end": "1616070"
  },
  {
    "text": "misalignment better because it's just getting more traces that are misaligned and it will learn how to cover for that",
    "start": "1616070",
    "end": "1624790"
  },
  {
    "text": "there's other techniques like l1 l2 regularization drop out early stopping",
    "start": "1624790",
    "end": "1630400"
  },
  {
    "text": "deep learning literature we'll talk about that in the in detail I'm really",
    "start": "1630400",
    "end": "1637520"
  },
  {
    "start": "1635000",
    "end": "1635000"
  },
  {
    "text": "in the end we get again these Hemingway distributions over key byte values and we can just run the key recovery as",
    "start": "1637520",
    "end": "1644600"
  },
  {
    "text": "we've done before now I already hinted earlier at the fact",
    "start": "1644600",
    "end": "1649820"
  },
  {
    "text": "that I don't need big data and the reason is that we the the classification",
    "start": "1649820",
    "end": "1657500"
  },
  {
    "text": "we're doing here is actually slightly different from cat pictures and this is",
    "start": "1657500",
    "end": "1662809"
  },
  {
    "text": "an insight that our team only had after starting this is in the beginning you're like hey we have like 100 gazillion",
    "start": "1662809",
    "end": "1670220"
  },
  {
    "text": "trillion cat pictures that we need to train this hugely deep network and then it will get good generalization but what",
    "start": "1670220",
    "end": "1679130"
  },
  {
    "text": "you're trying to achieve there is to classify each individual picture very well and that's how what we're trying to",
    "start": "1679130",
    "end": "1685220"
  },
  {
    "text": "do here we're trying to accumulate statistics about one single key byte and",
    "start": "1685220",
    "end": "1691910"
  },
  {
    "text": "that's different all we need to do is be just slightly above coin flip accuracy",
    "start": "1691910",
    "end": "1697130"
  },
  {
    "text": "in our classification and over time our statistics will accumulate and will point to the right key anyway",
    "start": "1697130",
    "end": "1703809"
  },
  {
    "text": "so this is why we also what you see here actually a copy base of this picture so",
    "start": "1703809",
    "end": "1711200"
  },
  {
    "text": "I don't look at this but I'll show you later in examples that we did we need a",
    "start": "1711200",
    "end": "1717679"
  },
  {
    "text": "ballpark about the same number of traces that we did for tea or other analysis as well so we don't need big data in this",
    "start": "1717679",
    "end": "1725450"
  },
  {
    "text": "case which is great so let's move to the actual meet here so let's get keys from",
    "start": "1725450",
    "end": "1733460"
  },
  {
    "text": "things let me just show you this trace it's another trace that's we start",
    "start": "1733460",
    "end": "1740720"
  },
  {
    "text": "obviously with two examples I love this",
    "start": "1740720",
    "end": "1745940"
  },
  {
    "text": "guy oops so here you can see a nicely",
    "start": "1745940",
    "end": "1759730"
  },
  {
    "text": "misaligned trace actually when you what",
    "start": "1759730",
    "end": "1765679"
  },
  {
    "text": "I do when I'm looking at this kind of stuff especially when it gets later at night you just run some techno music and",
    "start": "1765679",
    "end": "1772220"
  },
  {
    "text": "you pretend to your PJ kidding aside so",
    "start": "1772220",
    "end": "1780919"
  },
  {
    "text": "this is obviously just trays that you need to realign first before you do the do the analysis but we're not going to",
    "start": "1780919",
    "end": "1787159"
  },
  {
    "text": "do that we're just going to see what happens one when we want to run deep",
    "start": "1787159",
    "end": "1795710"
  },
  {
    "start": "1791000",
    "end": "1791000"
  },
  {
    "text": "deep learning on this and just for your information this is coming off of cortex m4 cpu running at 168 megahertz or so so",
    "start": "1795710",
    "end": "1805850"
  },
  {
    "text": "it's not super fast but it works for this is example so what we do is we",
    "start": "1805850",
    "end": "1813860"
  },
  {
    "start": "1806000",
    "end": "1806000"
  },
  {
    "text": "build a neural network using the trial and error and the process that I shown you before and we end up with something",
    "start": "1813860",
    "end": "1821450"
  },
  {
    "text": "with this case three convolutional layers three dense layers and output",
    "start": "1821450",
    "end": "1826610"
  },
  {
    "text": "layer and what we haven't astray is this set is ninety thousand training traces",
    "start": "1826610",
    "end": "1833149"
  },
  {
    "text": "which takes you I don't know half hour hour to acquire so then we use five thousands raises for",
    "start": "1833149",
    "end": "1839539"
  },
  {
    "text": "validation at five thousand for the test and we're using that hemming weight of",
    "start": "1839539",
    "end": "1844730"
  },
  {
    "text": "the s-boat at all so in this case we use the data argumentation that I just",
    "start": "1844730",
    "end": "1849919"
  },
  {
    "text": "talked about to train the network to also recognize misalignment what we're",
    "start": "1849919",
    "end": "1856279"
  },
  {
    "text": "seeing is the pictures that we like to see so that the recall goes up for both the training and validation set the loss",
    "start": "1856279",
    "end": "1864049"
  },
  {
    "text": "function goes down and if we compare",
    "start": "1864049",
    "end": "1869630"
  },
  {
    "text": "this method to vanilla template a text which is not an entirely fair comparison",
    "start": "1869630",
    "end": "1874909"
  },
  {
    "text": "but if we compare it against the vanilla template text you see that it almost doesn't recover the key whereas the the",
    "start": "1874909",
    "end": "1882080"
  },
  {
    "text": "neural network after about five thousand traces there actually recovers the key the reason I'm",
    "start": "1882080",
    "end": "1888710"
  },
  {
    "text": "saying it's not entirely fair is we just run template attacks also on the raw data normally you would also do that",
    "start": "1888710",
    "end": "1895220"
  },
  {
    "text": "alignment the filtering yourself and get to that point but we kind of want to take the human out of the equation here",
    "start": "1895220",
    "end": "1900470"
  },
  {
    "text": "so you can compare them side to side so",
    "start": "1900470",
    "end": "1906049"
  },
  {
    "start": "1904000",
    "end": "1904000"
  },
  {
    "text": "okay we've done a yes let's do a cc I'm completely different algorithm of course in this case we're looking at curve two",
    "start": "1906049",
    "end": "1913130"
  },
  {
    "text": "four five on nine and it's implemented using a Montgomery ladder and scaler blinding for those of you who don't know",
    "start": "1913130",
    "end": "1922340"
  },
  {
    "text": "what scaler blinding is I'm not going to explain it right now but you can't use",
    "start": "1922340",
    "end": "1928730"
  },
  {
    "text": "the nice trick of accumulating more and more traces you actually take one trace and you need to be you can only be off",
    "start": "1928730",
    "end": "1936500"
  },
  {
    "text": "by a couple of bits in your key recovery so here you need to be very precise that's at the modeling and then",
    "start": "1936500",
    "end": "1942860"
  },
  {
    "text": "extracting the rights the right key bits there's obviously quite a messy signal",
    "start": "1942860",
    "end": "1949750"
  },
  {
    "text": "and let's see how it did so in fairness",
    "start": "1949750",
    "end": "1957440"
  },
  {
    "text": "there there was one pre-processing step that we still did which is actually cutting up the trace",
    "start": "1957440",
    "end": "1964040"
  },
  {
    "text": "so we take this long trace which is one ECC computation and we cut it up into the individual loops of the Montgomery",
    "start": "1964040",
    "end": "1971360"
  },
  {
    "text": "ladder but after that that's what we fed into the deep learning algorithm and we",
    "start": "1971360",
    "end": "1978800"
  },
  {
    "text": "use our normal attacks from supervised and supervised horizontal attacks which",
    "start": "1978800",
    "end": "1985700"
  },
  {
    "text": "gives us about a sixty percent success rate which is actually not that great if you do a random query flick you get the",
    "start": "1985700",
    "end": "1992660"
  },
  {
    "text": "50% in this case deep learning",
    "start": "1992660",
    "end": "1997820"
  },
  {
    "text": "after fiddling with the network we actually got the 90% and after we did",
    "start": "1997820",
    "end": "2003220"
  },
  {
    "text": "data augmentation we got the ninety-nine point four percent success rate and those for you who are fast math that 0.6",
    "start": "2003220",
    "end": "2010870"
  },
  {
    "text": "percent of a 256 bit key is just a few bits it's like one or two bits on average so those you just brute force",
    "start": "2010870",
    "end": "2017950"
  },
  {
    "text": "and then the full exponent comes out and then you're done again we used the data",
    "start": "2017950",
    "end": "2024670"
  },
  {
    "text": "augmentation here to artificially create misalignment order to Train and network to recover for that so this was a this",
    "start": "2024670",
    "end": "2032230"
  },
  {
    "text": "was quite a cool result because we've now done on a yes with ECC and it's also we have to be more accurate here so",
    "start": "2032230",
    "end": "2038590"
  },
  {
    "text": "that's that's also cool in this case the network was bigger than we've used",
    "start": "2038590",
    "end": "2044830"
  },
  {
    "text": "before so we have three convolutional layers we actually for dense layers of",
    "start": "2044830",
    "end": "2050500"
  },
  {
    "text": "100 neurons but really if you look at classifying cat pictures versus this",
    "start": "2050500",
    "end": "2056679"
  },
  {
    "text": "this is this is not a very big Network so I can still do this from my poor CPU",
    "start": "2056679",
    "end": "2064200"
  },
  {
    "start": "2063000",
    "end": "2063000"
  },
  {
    "text": "this is where it gets interesting at least in my opinion here we take an",
    "start": "2065040",
    "end": "2071919"
  },
  {
    "text": "example of a so called mast implementation of AES it's actually part",
    "start": "2071919",
    "end": "2078398"
  },
  {
    "text": "of a competition called the DPA contest and here they invite more basically",
    "start": "2078399",
    "end": "2084310"
  },
  {
    "text": "anybody you can download the trace sets to try to break them so its attracts a",
    "start": "2084310",
    "end": "2089590"
  },
  {
    "text": "lot of scholars and academics and hobbyists to try to get the key out in",
    "start": "2089590",
    "end": "2094960"
  },
  {
    "text": "the in the fewest number of traces but really our goal here is not to",
    "start": "2094960",
    "end": "2100060"
  },
  {
    "text": "extract the key in a huge number of traces we're trying to just replace the human the countermeasure that they use",
    "start": "2100060",
    "end": "2106900"
  },
  {
    "text": "here is something called a rotating s belt as box masking I won't go into all the details but I'm going to give you a",
    "start": "2106900",
    "end": "2112990"
  },
  {
    "text": "bit of an idea what what masking means the idea is that you break or you try to",
    "start": "2112990",
    "end": "2120010"
  },
  {
    "text": "break the relation between that's value at zero that's being processed and the",
    "start": "2120010",
    "end": "2125470"
  },
  {
    "text": "power consumption and you do this by before you do an Aes yeah in this case",
    "start": "2125470",
    "end": "2130930"
  },
  {
    "text": "in a yes you flip around the mask you modify your S box just a little bit and",
    "start": "2130930",
    "end": "2136570"
  },
  {
    "text": "you XOR that mask on to your data it then goes through the key addition the",
    "start": "2136570",
    "end": "2142630"
  },
  {
    "text": "master survives it goes through the S box and out comes again another mask",
    "start": "2142630",
    "end": "2147880"
  },
  {
    "text": "value and before you get to the end of the algorithm you basically unmask it again and your regular AES result comes",
    "start": "2147880",
    "end": "2155590"
  },
  {
    "text": "out so because this mask is he's supposed to be random every time you",
    "start": "2155590",
    "end": "2161140"
  },
  {
    "text": "invoke as an attacker you cannot predict anymore what's a zero is because it's it's just massed it's by this random",
    "start": "2161140",
    "end": "2169660"
  },
  {
    "text": "thing that you will never see now there's a tax on this which are cults at the second order attacks and they",
    "start": "2169660",
    "end": "2175960"
  },
  {
    "text": "basically rely on the idea that if you have two points in time that are masked",
    "start": "2175960",
    "end": "2182020"
  },
  {
    "text": "and you cannot really predict what the",
    "start": "2182020",
    "end": "2188440"
  },
  {
    "text": "masks value is going to be but you can predict the unmasked values now what you can actually do if the mask is being",
    "start": "2188440",
    "end": "2195010"
  },
  {
    "text": "used for both values you take X XOR M and you XOR that what Y XOR M and it",
    "start": "2195010",
    "end": "2201970"
  },
  {
    "text": "basically is the same as X X or Y so this is a value that you can calculate",
    "start": "2201970",
    "end": "2207190"
  },
  {
    "text": "without knowing the mask and you can combine the two power measurements at",
    "start": "2207190",
    "end": "2212950"
  },
  {
    "text": "which this masked value is present by multiplying and that actually will give",
    "start": "2212950",
    "end": "2218200"
  },
  {
    "text": "you a correlation between X X or Y and these be samples the problem with this",
    "start": "2218200",
    "end": "2225340"
  },
  {
    "text": "is that if I don't know where I and J are we're just two points in the trace are I basically into brute",
    "start": "2225340",
    "end": "2231130"
  },
  {
    "text": "course through that race which is it's",
    "start": "2231130",
    "end": "2237040"
  },
  {
    "text": "actually squared complexity I'll fix that later so it's N squared over two or she'll",
    "start": "2237040",
    "end": "2244630"
  },
  {
    "text": "within the number of samples in your trace so it's quite costly it's also costly to implement by the way to do",
    "start": "2244630",
    "end": "2250720"
  },
  {
    "text": "this stuff it slows things down if you're doing in hardware your area blows up etc etc if you don't see this a lot a",
    "start": "2250720",
    "end": "2256990"
  },
  {
    "text": "lot we had actually one tricky thing to overcome when we were doing this",
    "start": "2256990",
    "end": "2262240"
  },
  {
    "text": "analysis and that is that normally you want your validation key to be different",
    "start": "2262240",
    "end": "2267430"
  },
  {
    "text": "from your training key because it's kind of unfair if your training on one key and you're validating the same key you",
    "start": "2267430",
    "end": "2273370"
  },
  {
    "text": "might be overfitting without knowing it so you actually develop the simple test",
    "start": "2273370",
    "end": "2278800"
  },
  {
    "text": "to figure out whether you're doing the right training or not which is to terrain on completely the wrong key and",
    "start": "2278800",
    "end": "2285840"
  },
  {
    "text": "if you then see that your network is still training then it's actually not",
    "start": "2285840",
    "end": "2291130"
  },
  {
    "text": "learning anything it's just learning random data so that's one good way to",
    "start": "2291130",
    "end": "2297160"
  },
  {
    "text": "find out whether your network is properly training in this case or not the other thing and we'll be publishing",
    "start": "2297160",
    "end": "2303850"
  },
  {
    "text": "more results about this in the paper soon to be released is to kind of reverse the network so once you've",
    "start": "2303850",
    "end": "2310330"
  },
  {
    "text": "trained on the network you can actually query it to see which input neurons were",
    "start": "2310330",
    "end": "2316360"
  },
  {
    "text": "firing really strongly for a particular output and that gives you an idea of what's in the input is actually causing",
    "start": "2316360",
    "end": "2323500"
  },
  {
    "text": "this leakage so if you look on the left hand side here you see a picture where there's a couple of really distinct",
    "start": "2323500",
    "end": "2328750"
  },
  {
    "text": "spikes and it's sort of what you want to see and on the right hand side you see kind of spikes all over the place and",
    "start": "2328750",
    "end": "2335650"
  },
  {
    "text": "that's usually not how leakage works so then you also know that you're you're doing something wrong so going going",
    "start": "2335650",
    "end": "2346300"
  },
  {
    "text": "into the results and actually I can show this one as well open DBA contests run a",
    "start": "2346300",
    "end": "2360700"
  },
  {
    "text": "deep learning this time I will use the correct Network",
    "start": "2360700",
    "end": "2366560"
  },
  {
    "text": "so I'm using a conditional neural network only one convolutional layer and",
    "start": "2368210",
    "end": "2374820"
  },
  {
    "text": "three dense layers and I'm gonna let my poor CPU run for a little while but we",
    "start": "2374820",
    "end": "2383550"
  },
  {
    "text": "if my sacrifices to the demo gods have paid off we'll see is that we will",
    "start": "2383550",
    "end": "2391320"
  },
  {
    "text": "recover the key in extremely few traces actually in this case a trace is was",
    "start": "2391320",
    "end": "2396450"
  },
  {
    "text": "sufficient to get the full payout and this is this is mind blowing for reasons other than your thinking right now I",
    "start": "2396450",
    "end": "2402720"
  },
  {
    "text": "think if there's there's two reasons why this is mind blowing the first thing is",
    "start": "2402720",
    "end": "2410940"
  },
  {
    "start": "2409000",
    "end": "2409000"
  },
  {
    "text": "this actually shouldn't work we have a masking scheme where we have to predict",
    "start": "2410940",
    "end": "2418650"
  },
  {
    "text": "X X or Y right we didn't feed it X X or Y we just fed it X so we were just doing",
    "start": "2418650",
    "end": "2425070"
  },
  {
    "text": "a first order attack or just being stupid and really if you think about it",
    "start": "2425070",
    "end": "2430609"
  },
  {
    "text": "we're still kind of hypothesizing why it did work but what seems to be happening",
    "start": "2431330",
    "end": "2438000"
  },
  {
    "text": "also if you look at the other contestants in the DPI contest is that there is actually some hidden",
    "start": "2438000",
    "end": "2443700"
  },
  {
    "text": "first-order leakage in in this in these traces you don't find them by just",
    "start": "2443700",
    "end": "2449550"
  },
  {
    "text": "running normal template attacks we can I think the numbers were about 45,000",
    "start": "2449550",
    "end": "2456180"
  },
  {
    "text": "traces for training and then about 5,000 traces for the test set then with",
    "start": "2456180",
    "end": "2461340"
  },
  {
    "text": "template attacks we could get the key down the rank 5 or so 5,000 versus 8 so",
    "start": "2461340",
    "end": "2468480"
  },
  {
    "text": "there is some first-order leakage in there but templates can't find it this",
    "start": "2468480",
    "end": "2473580"
  },
  {
    "text": "did which was really cool the second thing that I think is really cool is",
    "start": "2473580",
    "end": "2478860"
  },
  {
    "text": "that our really stupid network in which the human interaction was this fiddling",
    "start": "2478860",
    "end": "2485460"
  },
  {
    "text": "until the accuracy and the recall looked good is actually up there with dozens of side channel",
    "start": "2485460",
    "end": "2491589"
  },
  {
    "text": "you know world-class teams so just by being stupid and putting in this deep",
    "start": "2491589",
    "end": "2497200"
  },
  {
    "text": "learning network we were ranking there as well so yeah I find those really really fascinating that wasn't even what",
    "start": "2497200",
    "end": "2504009"
  },
  {
    "text": "we're aiming for right we're trying to get people a little bit out of the loop of the Machine of the signal processing",
    "start": "2504009",
    "end": "2510339"
  },
  {
    "text": "but this thing actually found an attack rat so getting more to the last part of",
    "start": "2510339",
    "end": "2516219"
  },
  {
    "text": "that what just happened here getting more into the leakage modeling part of",
    "start": "2516219",
    "end": "2523089"
  },
  {
    "start": "2520000",
    "end": "2520000"
  },
  {
    "text": "everything so this was really cool so just to to wrap up now is a good time",
    "start": "2523089",
    "end": "2530109"
  },
  {
    "start": "2529000",
    "end": "2529000"
  },
  {
    "text": "to start thinking about those excellent questions anyway if you want to learn",
    "start": "2530109",
    "end": "2535450"
  },
  {
    "text": "more so there's a few resources that I can I can recommend so first of all",
    "start": "2535450",
    "end": "2540519"
  },
  {
    "text": "there's a deep learning book which you can read online there's also an entry",
    "start": "2540519",
    "end": "2546249"
  },
  {
    "text": "aleix illan MIT course that kind of teaches you all the basics these are videos that you can watch online intro",
    "start": "2546249",
    "end": "2553420"
  },
  {
    "text": "to deep learning com there's a book on DPA called power",
    "start": "2553420",
    "end": "2560140"
  },
  {
    "text": "analysis attacks by a Stefan Hmong guard which is kind of the yeah historically",
    "start": "2560140",
    "end": "2566200"
  },
  {
    "text": "the book to go for and then Collin am I",
    "start": "2566200",
    "end": "2571799"
  },
  {
    "text": "still working on it we're doing our best but it will be there at some point we're writing a book",
    "start": "2571799",
    "end": "2577809"
  },
  {
    "text": "on these kind of topics as well with a more practical side to it so really if",
    "start": "2577809",
    "end": "2586479"
  },
  {
    "start": "2583000",
    "end": "2583000"
  },
  {
    "text": "you're gonna walk away with with three things deep learning really takes side",
    "start": "2586479",
    "end": "2592539"
  },
  {
    "text": "channel analysis and it performs both the art part and the science part of it which was more than we were hoping for",
    "start": "2592539",
    "end": "2598769"
  },
  {
    "text": "and importantly it also scales right if I can do it on my laptop here then GPU",
    "start": "2598769",
    "end": "2605829"
  },
  {
    "text": "clusters can do much more the bar is definitely not at zero yet this is not",
    "start": "2605829",
    "end": "2610989"
  },
  {
    "text": "fully automated you still need to fiddle with the network but you don't quite need the",
    "start": "2610989",
    "end": "2616450"
  },
  {
    "text": "same kind of expertise for that a couple of guidelines and fiddling and getting a sense for this network might work is",
    "start": "2616450",
    "end": "2622719"
  },
  {
    "text": "already getting you up there with world-class teams and really the AB this",
    "start": "2622719",
    "end": "2628690"
  },
  {
    "text": "kind of automation is needed to put the bent in and all the embedded insecurities that we're seeing so I'm",
    "start": "2628690",
    "end": "2634480"
  },
  {
    "text": "really excited about where this is heading so use some references for the",
    "start": "2634480",
    "end": "2641559"
  },
  {
    "text": "further slides later so I'll be posting these slides online as well if you",
    "start": "2641559",
    "end": "2646569"
  },
  {
    "text": "follow me on twitter i'll post a link there probably probably within a week if",
    "start": "2646569",
    "end": "2654730"
  },
  {
    "text": "you any questions you can either email me or we can take a couple of questions right now live once we're out of time",
    "start": "2654730",
    "end": "2661809"
  },
  {
    "text": "we'll head out to the rap room which is we're just on the hall so time for those",
    "start": "2661809",
    "end": "2670299"
  },
  {
    "text": "excellent questions thanks for the",
    "start": "2670299",
    "end": "2684579"
  },
  {
    "text": "excellent talk Jasper thank you I have a question about this threshold of 1/9",
    "start": "2684579",
    "end": "2689769"
  },
  {
    "text": "yeah you're saying if you're testing accuracy isn't any better than this then",
    "start": "2689769",
    "end": "2695109"
  },
  {
    "text": "your machine learning hasn't learned anything yeah but you can do a lot better than 1/9 because Hamming weights",
    "start": "2695109",
    "end": "2701109"
  },
  {
    "text": "aren't randomly spread over all 9 classes so I think you can do better just by always predicting Hamming weight",
    "start": "2701109",
    "end": "2707739"
  },
  {
    "text": "of 4 so that threshold of 1/9 should be a lot higher can you comment on that it's a good question so that the",
    "start": "2707739",
    "end": "2714880"
  },
  {
    "text": "question is shouldn't you be able to do better than 1/9 because hemming weights aren't uniformly distributed I'm not",
    "start": "2714880",
    "end": "2723759"
  },
  {
    "text": "sure if I can give you exactly the right answer right now but intuitively I'm thinking that the network actually",
    "start": "2723759",
    "end": "2728859"
  },
  {
    "text": "doesn't know that this distribution exists so I think it I think it is",
    "start": "2728859",
    "end": "2735400"
  },
  {
    "text": "assumes thereby implicitly a uniform distribution you might be able to tweak",
    "start": "2735400",
    "end": "2741099"
  },
  {
    "text": "the network not to have this and maybe the training data will do this for you",
    "start": "2741099",
    "end": "2746380"
  },
  {
    "text": "but it's too complex of a question for me to give you a close answer right now",
    "start": "2746380",
    "end": "2752249"
  },
  {
    "text": "thank you yep so just curious did this save you time I",
    "start": "2752249",
    "end": "2758869"
  },
  {
    "text": "mean in between a human having to do all this or the the training of the AI",
    "start": "2758869",
    "end": "2766039"
  },
  {
    "text": "everything else which one was quicker yeah good question well the question is is does this save you time I'm gonna have",
    "start": "2766039",
    "end": "2772670"
  },
  {
    "text": "to ask you a question so maybe stay close to the mic are you talking about wall clock time CPU time human time all",
    "start": "2772670",
    "end": "2779599"
  },
  {
    "text": "of it actually okay a good question in that case so",
    "start": "2779599",
    "end": "2785859"
  },
  {
    "text": "definitely this is more CPU intensive that's the easy one to answer so this is",
    "start": "2787660",
    "end": "2793369"
  },
  {
    "text": "like when we're doing traditional side channel analysis yeah you're doing a bit",
    "start": "2793369",
    "end": "2799130"
  },
  {
    "text": "of filtering you're doing a bit of correlation attacks but this is this is doable deep blue training and deep",
    "start": "2799130",
    "end": "2805789"
  },
  {
    "text": "learning network will take longer like the traces that I just showed you can take up to a few hours to to fully go",
    "start": "2805789",
    "end": "2814369"
  },
  {
    "text": "through all them that's through all the keys and let's just I'm just reminded",
    "start": "2814369",
    "end": "2821839"
  },
  {
    "text": "now that I had one session running and for those who's stuck around 60 60 so it",
    "start": "2821839",
    "end": "2827450"
  },
  {
    "text": "found the key but thank you thanks to my",
    "start": "2827450",
    "end": "2833420"
  },
  {
    "text": "colleagues human time in our experience",
    "start": "2833420",
    "end": "2838759"
  },
  {
    "text": "there's a bit of a learning curve to figure out like how to tune in networks but after that it's definitely not as",
    "start": "2838759",
    "end": "2845630"
  },
  {
    "text": "long as the filtering and that has to do with that with filtering or sorry the",
    "start": "2845630",
    "end": "2850759"
  },
  {
    "text": "traditional approach if it's a multiple of these loops where you kind of wait for you wait for your filtering to end",
    "start": "2850759",
    "end": "2856819"
  },
  {
    "text": "then you see how it is then you do your miss lime you have to go back here there's fewer of these interrelated loops so once you've kind of twiddled",
    "start": "2856819",
    "end": "2863930"
  },
  {
    "text": "your network then yeah then it turns into CPU time so wall clock time I find",
    "start": "2863930",
    "end": "2873769"
  },
  {
    "text": "that one hard to answer I would I would guess that it will save you a bit of time wall clock but for a single",
    "start": "2873769",
    "end": "2882190"
  },
  {
    "text": "execution but you can paralyze this much better right you can run many more deep learning",
    "start": "2882190",
    "end": "2887210"
  },
  {
    "text": "algorithms in parallel than humans fiddling and killing knobs I think we're",
    "start": "2887210",
    "end": "2894230"
  },
  {
    "text": "almost out of time so if there's more questions I'll be heading out to the break room thank you very much for for",
    "start": "2894230",
    "end": "2899599"
  },
  {
    "text": "listening",
    "start": "2899599",
    "end": "2901900"
  }
]
[
  {
    "text": "um this is the Enterprise Intrigue track we are in Palace one uh we are here to",
    "start": "240",
    "end": "5879"
  },
  {
    "text": "hear about clone wise automated package clone detection from Sylvio shazar did I",
    "start": "5879",
    "end": "11880"
  },
  {
    "text": "get it right close enough [Applause]",
    "start": "11880",
    "end": "18000"
  },
  {
    "text": "okay uh thanks for attending uh my talk uh there's not many of you here but I think um there'll be some interesting",
    "start": "18000",
    "end": "23560"
  },
  {
    "text": "things that I'll say um and the title of my talk today is automatically uh detecting packaged clones and infering",
    "start": "23560",
    "end": "29359"
  },
  {
    "text": "security vulner ities from a tool that I've developed called clone wise that is uh plan to be integrated into Debian",
    "start": "29359",
    "end": "35840"
  },
  {
    "text": "infrastructure and hopefully help improve security uh for Linux so just a little bit about who I",
    "start": "35840",
    "end": "42120"
  },
  {
    "text": "am and and where this talk actually comes from um I'm a PhD candidate at Deacon University in Melbourne Australia",
    "start": "42120",
    "end": "49120"
  },
  {
    "text": "my research interests uh cover things like malware detection and automated vulnerability detection uh the talk that",
    "start": "49120",
    "end": "56960"
  },
  {
    "text": "I'm giving today covers automative vulnerability detection but also research other aspects of that looking",
    "start": "56960",
    "end": "62280"
  },
  {
    "text": "at static analysis of binaries using decompilation data flow analysis and so forth um I'm also a book author uh",
    "start": "62280",
    "end": "69960"
  },
  {
    "text": "software similarity and classification was uh published by Springer earlier in the year and that covers and overlaps",
    "start": "69960",
    "end": "75799"
  },
  {
    "text": "the malware detection research that I'm doing I'm looking at malware variant detection and so forth um I'm a black",
    "start": "75799",
    "end": "82680"
  },
  {
    "text": "hat speaker uh from the past was last year in 2003 um but I've also spoken at",
    "start": "82680",
    "end": "88000"
  },
  {
    "text": "other conferences as well including academic conferences and I published in academic journals and so forth I've got",
    "start": "88000",
    "end": "93560"
  },
  {
    "text": "a website through cod.com uh has some free web services that do malware",
    "start": "93560",
    "end": "98840"
  },
  {
    "text": "detection and software similarity uh it also has some content on it um and a Wiki on software similarity and",
    "start": "98840",
    "end": "106920"
  },
  {
    "text": "classification so this talk is about embedded or clone code uh the word clone",
    "start": "106920",
    "end": "112479"
  },
  {
    "text": "code clone comes from Academia where they do code clone detection and code clone detection is detecting duplicated",
    "start": "112479",
    "end": "119240"
  },
  {
    "text": "fragments of code uh which has problems because it causes M maintainability",
    "start": "119240",
    "end": "124360"
  },
  {
    "text": "problems um in this particular talk I'm talking about embedded or cloned",
    "start": "124360",
    "end": "130360"
  },
  {
    "text": "packages um and what happens is that developers sometimes embed code from third party sources so they might",
    "start": "130360",
    "end": "137000"
  },
  {
    "text": "statically link a library for example statically linking lib PNG um they might",
    "start": "137000",
    "end": "142680"
  },
  {
    "text": "maintain an internal copy of the library for example Li PNG uh is copied in the Firefox Source um or sometimes",
    "start": "142680",
    "end": "149920"
  },
  {
    "text": "developers Fork a library they make significant changes to the library so they can't really use the systemwide",
    "start": "149920",
    "end": "156160"
  },
  {
    "text": "shared Library there are lots of examples uh of embedded or cloned code",
    "start": "156160",
    "end": "161840"
  },
  {
    "text": "um XML passing for instance lib XML the xat XML passer embedded in lots of stuff",
    "start": "161840",
    "end": "168280"
  },
  {
    "text": "um image processing has lots of libraries that are used and embedded elsewhere uh we have lip PNG embedded in",
    "start": "168280",
    "end": "173720"
  },
  {
    "text": "Firefox there are also libraries like lib Tiff um there are JPEG and GIF",
    "start": "173720",
    "end": "178879"
  },
  {
    "text": "libraries as well networking is a classic example is open SSL which is embedded in lots of stuff",
    "start": "178879",
    "end": "185200"
  },
  {
    "text": "um and compression again a classic example is Ed Li which is embedded pretty much",
    "start": "185200",
    "end": "192159"
  },
  {
    "text": "everywhere uh embedding code is generally a bad practice um and Linux",
    "start": "192159",
    "end": "197760"
  },
  {
    "text": "policies generally uh disallow this um Debian for instance I don't know if you can read that but it's a um it's part of",
    "start": "197760",
    "end": "204879"
  },
  {
    "text": "their policy to to say that uh embedding code from from third parties is not a",
    "start": "204879",
    "end": "210080"
  },
  {
    "text": "good idea and that you should use a system systemwide shared Library um the",
    "start": "210080",
    "end": "215680"
  },
  {
    "text": "reality is uh people still embed and bundle code um and what the problem uh",
    "start": "215680",
    "end": "222400"
  },
  {
    "text": "eventuates into is that you have multiple versions of that package now existing so Li PNG exists in at least",
    "start": "222400",
    "end": "228599"
  },
  {
    "text": "two places now it exists in the original package and in the Firefox sources where it replicates that lip PNG source so",
    "start": "228599",
    "end": "235920"
  },
  {
    "text": "each individual copy uh needs uh patches and manual patches every time there's a",
    "start": "235920",
    "end": "241519"
  },
  {
    "text": "li PNG bug or vulnerability um and what tends to happen in real life is that these",
    "start": "241519",
    "end": "247760"
  },
  {
    "text": "embedded code copies become out of date um and therefore fall insecure as more vulnerabilities are found against",
    "start": "247760",
    "end": "255040"
  },
  {
    "text": "them the manual approach to find embedded code uh is to use uh signatures",
    "start": "255040",
    "end": "261320"
  },
  {
    "text": "uh typically based on version strings uh so um for example in 2005 this was done",
    "start": "261320",
    "end": "267199"
  },
  {
    "text": "on a mass scale uh uh zlib uh there was a vulnerability that appeared in zlib a",
    "start": "267199",
    "end": "273440"
  },
  {
    "text": "remote code execution uh vulnerability and zlib is pretty much embedded in so many places that that no one in Debian",
    "start": "273440",
    "end": "280280"
  },
  {
    "text": "really had an idea of the extent of where zlib was embedded so Debian",
    "start": "280280",
    "end": "286120"
  },
  {
    "text": "created uh an antivirus signature based on the version string that identified",
    "start": "286120",
    "end": "291199"
  },
  {
    "text": "Zed lib embedded in executable binaries um they they did this against",
    "start": "291199",
    "end": "296840"
  },
  {
    "text": "the entire debban repository and found lots of CAS where Z lib was embedded um and had those outstanding",
    "start": "296840",
    "end": "302880"
  },
  {
    "text": "vulnerabilities I've shown some other examples of version strings from things like bzip 2 um lib Tiff um and lib PNG",
    "start": "302880",
    "end": "310960"
  },
  {
    "text": "most libraries will include a version string so so it is a good idea if you want to create a manual",
    "start": "310960",
    "end": "318400"
  },
  {
    "text": "signature the problem is there's so many packages in Linux we're looking at 10 to 20,000 packages in a major drro so it's",
    "start": "318520",
    "end": "326199"
  },
  {
    "text": "really not practical that you can create a signature every single package um and",
    "start": "326199",
    "end": "332319"
  },
  {
    "text": "it's not like we're talking about just lib PNG or lib Tiff as the only embedded libraries that are used uh Debian",
    "start": "332319",
    "end": "339240"
  },
  {
    "text": "manually track 420 libraries so you know it's quite significant um and Debian is",
    "start": "339240",
    "end": "345440"
  },
  {
    "text": "one of the better distributions because most dis Ros don't track uh this problem at all um it was only after uh we",
    "start": "345440",
    "end": "354120"
  },
  {
    "text": "submitted uh uh information to Red Hat did they actually start creating a Wiki",
    "start": "354120",
    "end": "359360"
  },
  {
    "text": "to track embedded code copies like Debian so we think that most vendors should do this um but at the moment",
    "start": "359360",
    "end": "366039"
  },
  {
    "text": "Debian is really taking the um is really doing the best out of this",
    "start": "366039",
    "end": "372240"
  },
  {
    "text": "and that raises the question of course is that you know if people AR tracking these things how many vulnerabilities are there you know Debian track them and",
    "start": "372240",
    "end": "379240"
  },
  {
    "text": "there's still lots of vulnerability so all the diss that don't track them we're looking at lots of outstanding",
    "start": "379240",
    "end": "384440"
  },
  {
    "text": "vulnerabilities and how do we automate this process and that is is is the focus of this",
    "start": "384440",
    "end": "390479"
  },
  {
    "text": "work the example I've shown in that image is from debian's manual created",
    "start": "390479",
    "end": "395800"
  },
  {
    "text": "database which tracks embedded code copies so we look in the example I don't know if you can read it um but pcast in",
    "start": "395800",
    "end": "403360"
  },
  {
    "text": "the bottom section is embedded um in two packages known pcast um and in two",
    "start": "403360",
    "end": "409280"
  },
  {
    "text": "different uh versions of that of that software as well so the outline of this talk is that",
    "start": "409280",
    "end": "416520"
  },
  {
    "text": "I'm going to give a problem definition Define exactly what I'm to try to solve um and then describe the approach that",
    "start": "416520",
    "end": "422360"
  },
  {
    "text": "I'm taking um the approach is based on machine learning and using statistical",
    "start": "422360",
    "end": "427639"
  },
  {
    "text": "classification uh so I'll be using using that to to classify um packages as",
    "start": "427639",
    "end": "433319"
  },
  {
    "text": "sharing or not sharing code um it's a good approach I think but it's quite slow so we need to scale the analysis",
    "start": "433319",
    "end": "440199"
  },
  {
    "text": "and to do that I've used an Amazon cluster and Ed multi-core and cluster Computing to do that then once we built",
    "start": "440199",
    "end": "446960"
  },
  {
    "text": "a database of of Clines which I have done um automatically or semi-automatically",
    "start": "446960",
    "end": "452960"
  },
  {
    "text": "try to infer vulnerabilities and discover real vulnerabilities in software I'll talk about the implementation and how to evaluate such",
    "start": "452960",
    "end": "459800"
  },
  {
    "text": "a system using uh comparing our results that are automatically generated with debian's manually track database I'll",
    "start": "459800",
    "end": "466960"
  },
  {
    "text": "discuss some general points talk about related work talk about some things that I intend to do in the future and then",
    "start": "466960",
    "end": "472840"
  },
  {
    "text": "conclude the presentation so the problem definition is basically to find package code reuse",
    "start": "472840",
    "end": "480440"
  },
  {
    "text": "in sources Source packages this is a source level analysis so I'm not looking at binaries I'm not looking at static",
    "start": "480440",
    "end": "486800"
  },
  {
    "text": "linking as well uh there has to be replication of the code in the source Street um and then based on that infer",
    "start": "486800",
    "end": "494479"
  },
  {
    "text": "vulnerabilities that are caused by out ofd code so in the example that I've shown here we have the Firefox Source",
    "start": "494479",
    "end": "501319"
  },
  {
    "text": "lip PNG is roughly a subset of that the sources but it's not a perfect subset because some code in Li PNG isn't",
    "start": "501319",
    "end": "508280"
  },
  {
    "text": "embedded in fire Fox but roughly uh it's a good",
    "start": "508280",
    "end": "514479"
  },
  {
    "text": "subset the approach that that that I'm taking that we're taking at Deon University is to consider the problem uh",
    "start": "514839",
    "end": "521518"
  },
  {
    "text": "the code reuse detection problem as a binary classification problem and that just means that we're asking the",
    "start": "521519",
    "end": "527399"
  },
  {
    "text": "question do packages a and b share code yes or no so it's two classes of binary",
    "start": "527399",
    "end": "534040"
  },
  {
    "text": "problem uh to do that classification problem to solve it we need features to",
    "start": "534040",
    "end": "539600"
  },
  {
    "text": "pass to our classifier so the features that we're using are the number of common file names between two Source",
    "start": "539600",
    "end": "546040"
  },
  {
    "text": "packages the number of identical hashes between two Source packages and the",
    "start": "546040",
    "end": "551120"
  },
  {
    "text": "number of similar hashes between two Source packages based on fuzzy hashing and fuzzy",
    "start": "551120",
    "end": "557240"
  },
  {
    "text": "content so the binary classification is comparing two packages but what in fact we want is to know every package in the",
    "start": "557240",
    "end": "564000"
  },
  {
    "text": "repository uh that embeds a particular Library so we take that Library package a and we ask you know doesn't share code",
    "start": "564000",
    "end": "571079"
  },
  {
    "text": "with any other package in the repository so we apply that binary classification problem to every package in the",
    "start": "571079",
    "end": "577040"
  },
  {
    "text": "repository and that gives us our answers where that library or package is",
    "start": "577040",
    "end": "583279"
  },
  {
    "text": "embedded so the solution is based on machine learning and statistical classification",
    "start": "584640",
    "end": "591120"
  },
  {
    "text": "but what exactly is the classification problem um classification assigns",
    "start": "591120",
    "end": "596240"
  },
  {
    "text": "classes to objects so a good example is the spam detection problem you have an object which is an email you have two",
    "start": "596240",
    "end": "604040"
  },
  {
    "text": "classes one of those classes being the email is Spam the other class being the email is not spam and then you simply",
    "start": "604040",
    "end": "610959"
  },
  {
    "text": "assign one of those classes to that to that object so is is the email spam or not spam the major approaches to you to",
    "start": "610959",
    "end": "618760"
  },
  {
    "text": "do classification are supervised learning and unsupervised learning there are also other approaches such as",
    "start": "618760",
    "end": "624839"
  },
  {
    "text": "semi-supervised learning and reinforcement learning but the main approaches are super vised and",
    "start": "624839",
    "end": "630160"
  },
  {
    "text": "unsupervised in supervised learning you train a classification model so you give",
    "start": "630160",
    "end": "635360"
  },
  {
    "text": "it labeled data where you have a set of objects with their known classes and",
    "start": "635360",
    "end": "640480"
  },
  {
    "text": "then you train that model and then once it's fully trained you're able to ask it give it unknown objects and it will tell",
    "start": "640480",
    "end": "647160"
  },
  {
    "text": "you what class they belong to in unsupervised learning you don't have any labeled data so the general approach to",
    "start": "647160",
    "end": "654320"
  },
  {
    "text": "solve this is by using clustering clustering groups together similar it or",
    "start": "654320",
    "end": "659600"
  },
  {
    "text": "similar objects and these clusters identify classes different classes so in",
    "start": "659600",
    "end": "665680"
  },
  {
    "text": "the spam problem cluster analysis might identify that there's a class that roughly matches this email is a spam",
    "start": "665680",
    "end": "673040"
  },
  {
    "text": "class and another class which represents the email is not",
    "start": "673040",
    "end": "678480"
  },
  {
    "text": "spam to perform classification you typically need features um in a feature",
    "start": "679000",
    "end": "684920"
  },
  {
    "text": "Vector uh so a feature Vector is simply an array ordered list an ordered list of",
    "start": "684920",
    "end": "691839"
  },
  {
    "text": "elements uh and in Clone wise we've used 26 different types of features some of",
    "start": "691839",
    "end": "697839"
  },
  {
    "text": "the features include the number of common file names between two packages um the number of file names in a package",
    "start": "697839",
    "end": "704680"
  },
  {
    "text": "and so forth I'll talk a little bit more detail about each each type of feature",
    "start": "704680",
    "end": "709959"
  },
  {
    "text": "that we've used in the next slides in the next set of slides so the first major class of",
    "start": "709959",
    "end": "716240"
  },
  {
    "text": "features that we're using is the number of common file names between two packages um so the example I've shown in",
    "start": "716240",
    "end": "723040"
  },
  {
    "text": "that in that large table um has some has some directory contents um from the xat",
    "start": "723040",
    "end": "729079"
  },
  {
    "text": "library the xat package and the TLA package and what we can see is there are a lot of common file names between them",
    "start": "729079",
    "end": "736399"
  },
  {
    "text": "so we might have something like XML talk.c which is quite unique uh as a",
    "start": "736399",
    "end": "741720"
  },
  {
    "text": "file name uh also it's important to recognize the difference between source",
    "start": "741720",
    "end": "747079"
  },
  {
    "text": "and data file names we recognize source file names by the extension that they're using so I've got a list of extensions",
    "start": "747079",
    "end": "752639"
  },
  {
    "text": "that we recognize because sometimes it's more it's probably more important to know um that Li PNG Doc is shared",
    "start": "752639",
    "end": "759920"
  },
  {
    "text": "between two packages as opposed to a file name called read me we also normalize the file name so we",
    "start": "759920",
    "end": "767240"
  },
  {
    "text": "convert the file names to lowercase we remove punctuation characters from them um and so",
    "start": "767240",
    "end": "774759"
  },
  {
    "text": "forth another type of feature that we're using um is the number of similar file names the previous slide talks about",
    "start": "775440",
    "end": "782120"
  },
  {
    "text": "identical file names after normalization but in this feature we're using the number of similar file names again",
    "start": "782120",
    "end": "787720"
  },
  {
    "text": "applied to source and data file names one way we can determine similarity between file names is using the string",
    "start": "787720",
    "end": "794839"
  },
  {
    "text": "edit distance also known as the lebenstein distance um using the edit distance we can construct a similarity",
    "start": "794839",
    "end": "801800"
  },
  {
    "text": "score and if the similarity is greater than equal to 85% then we say that those two file",
    "start": "801800",
    "end": "808199"
  },
  {
    "text": "names are Sim similar to each",
    "start": "808199",
    "end": "811759"
  },
  {
    "text": "other we also look at uh the hashes and fuzzy hashes of the fuzzy hashes we look",
    "start": "813639",
    "end": "820120"
  },
  {
    "text": "we look at the content and determine their similarity using fuzzy hashing so we use the program SSD to do this which",
    "start": "820120",
    "end": "826639"
  },
  {
    "text": "is based on piecewise uh context triggered piece-wise hashing um uh we",
    "start": "826639",
    "end": "833079"
  },
  {
    "text": "use three types of features the number of identical hashes which represents the content is equivalent the same we use",
    "start": "833079",
    "end": "839240"
  },
  {
    "text": "the number of of hashes where the similarity is greater than 80% and the number of hashes that are greater than",
    "start": "839240",
    "end": "845920"
  },
  {
    "text": "0% so basically are looking for similar content um SSD or context tried peace",
    "start": "845920",
    "end": "852160"
  },
  {
    "text": "wise hatching is good at identifying near duplicate uh Blobs of data it's not",
    "start": "852160",
    "end": "857199"
  },
  {
    "text": "so good at detecting similarity between quite different types of data but for near duplicate data it's quite",
    "start": "857199",
    "end": "863959"
  },
  {
    "text": "good and I've shown some an SS deep hash below uh the steep hashes are compared",
    "start": "863959",
    "end": "870600"
  },
  {
    "text": "using the string at a distance again and that identifies the similarity between",
    "start": "870600",
    "end": "876199"
  },
  {
    "text": "them what we notice though is that again some files are more important than",
    "start": "877120",
    "end": "882320"
  },
  {
    "text": "others so libpng Doc is probably more important than files like read me make",
    "start": "882320",
    "end": "889519"
  },
  {
    "text": "file too Etc because Li P.C occurs very infrequently files like read me occur in",
    "start": "889519",
    "end": "897360"
  },
  {
    "text": "almost every package so what we do is we score the file names based on What's called the inverse",
    "start": "897360",
    "end": "903720"
  },
  {
    "text": "document frequency the inverse document frequency uh gives a weight or a score",
    "start": "903720",
    "end": "909360"
  },
  {
    "text": "to a term based on how frequently that term occurs in a corpus so the more",
    "start": "909360",
    "end": "915000"
  },
  {
    "text": "frequent a file name appears the less it's weighted the less frequently it",
    "start": "915000",
    "end": "920199"
  },
  {
    "text": "occurs the more it's weighted and we use a feature based on summing those weights",
    "start": "920199",
    "end": "925920"
  },
  {
    "text": "or scores for the set of common file names or file",
    "start": "925920",
    "end": "931480"
  },
  {
    "text": "names when we look at comparing similar file names to each other an issue occurs",
    "start": "932240",
    "end": "937759"
  },
  {
    "text": "uh one file name might match um in one file name in one package might match",
    "start": "937759",
    "end": "942800"
  },
  {
    "text": "more than one file name in another package so which file name should we match to each other what's what scores",
    "start": "942800",
    "end": "948880"
  },
  {
    "text": "do we use well each matching has a cost and that's the score that I talked about in the previous slide based on the",
    "start": "948880",
    "end": "955279"
  },
  {
    "text": "inverse document frequency there are lots of matchings possible so we choose a",
    "start": "955279",
    "end": "962000"
  },
  {
    "text": "matching that maximizes the sum of those costs now this problem is actually known",
    "start": "962000",
    "end": "969040"
  },
  {
    "text": "quite well in combinatorial optimization as the assignment problem uh the formal definition is is given but it's the",
    "start": "969040",
    "end": "976519"
  },
  {
    "text": "informal definition is is quite okay as well um we can solve this optimally in cubic time uh using the monkres or",
    "start": "976519",
    "end": "983600"
  },
  {
    "text": "Hungarian algorithm um but in practice even cubic time is quite slow when we're",
    "start": "983600",
    "end": "988680"
  },
  {
    "text": "looking looking at a large number of files in a package so so in practice we use this for for files that that that do",
    "start": "988680",
    "end": "995519"
  },
  {
    "text": "contain a lot of files this packages that do contain a lot of files it's also",
    "start": "995519",
    "end": "1001199"
  },
  {
    "text": "solved um the optim optimally solve using a b bipartite graph matching algorithm which is the figure that I've",
    "start": "1001199",
    "end": "1007880"
  },
  {
    "text": "shown there uh classification is all about",
    "start": "1007880",
    "end": "1014800"
  },
  {
    "text": "features but what we know is that some features are more important than others some features are redundant some",
    "start": "1014800",
    "end": "1020800"
  },
  {
    "text": "features are so chaotic uh that if you include them uh in your feature Vector",
    "start": "1020800",
    "end": "1025959"
  },
  {
    "text": "it actually reduces the accuracy of your classification algorithm so there are a number of approaches that are used to to",
    "start": "1025959",
    "end": "1032240"
  },
  {
    "text": "to remedy this problem we can rank features uh based on assigning a score or a rank uh based on a metric to a",
    "start": "1032240",
    "end": "1039678"
  },
  {
    "text": "feature and then we can exclude those features that that rank quite poorly this is a type of subset selection and",
    "start": "1039679",
    "end": "1046798"
  },
  {
    "text": "there are different ways of Performing subset sele ction we can we can choose subsets of our features pass them to a",
    "start": "1046799",
    "end": "1053480"
  },
  {
    "text": "classification algorithm and see if our accuracy improves as well uh we chose",
    "start": "1053480",
    "end": "1058600"
  },
  {
    "text": "not to use feature selection we experimented with it and in some cases it does improve accuracy uh it's",
    "start": "1058600",
    "end": "1064440"
  },
  {
    "text": "certainly possible that in the future we will include a more thorough feature selection algorithm but the trade-off is",
    "start": "1064440",
    "end": "1071559"
  },
  {
    "text": "that it takes quite a lot a long time to run the subset uh",
    "start": "1071559",
    "end": "1077000"
  },
  {
    "text": "selection so we've got we've got our binary classification problem which is do these two packages share code we've",
    "start": "1077840",
    "end": "1084559"
  },
  {
    "text": "extracted features from these packages constructed a feature Vector",
    "start": "1084559",
    "end": "1090360"
  },
  {
    "text": "Now we move on to the classification algorithm if we consider the featur the feature vectors as an nend dimensional",
    "start": "1090360",
    "end": "1096640"
  },
  {
    "text": "point in space uh we can possibly construct a plane or hyperplane that",
    "start": "1096640",
    "end": "1102679"
  },
  {
    "text": "separates two classes or two classes that those feature vectors represent",
    "start": "1102679",
    "end": "1108080"
  },
  {
    "text": "this is what's known as a linear classifier there are also nonlinear classifiers when we uh we relax that",
    "start": "1108080",
    "end": "1114280"
  },
  {
    "text": "that that that hyperplane and make it a nonlinear function such as Parabola or a",
    "start": "1114280",
    "end": "1120520"
  },
  {
    "text": "cubic function and so forth another type of classif classifier which is interesting to not are decision trees",
    "start": "1120520",
    "end": "1127280"
  },
  {
    "text": "and these basically are a set of decisions or rules that enable us to to classify an",
    "start": "1127280",
    "end": "1134840"
  },
  {
    "text": "object okay so that that that that's the basic solution that we've taken to",
    "start": "1136039",
    "end": "1142440"
  },
  {
    "text": "classify whether two packages share code or one is embedded in another uh the problem is it's really quite slow uh we",
    "start": "1142440",
    "end": "1149799"
  },
  {
    "text": "have to perform that classification algorithm uh to every package in our repository and then we have to do that",
    "start": "1149799",
    "end": "1156360"
  },
  {
    "text": "again for every single library that we're looking at so we needed to scale the",
    "start": "1156360",
    "end": "1162760"
  },
  {
    "text": "analysis the first way I've done this is by using a multicore system uh speeding",
    "start": "1162760",
    "end": "1168159"
  },
  {
    "text": "up clone detection on a single package so remember that to identify when a",
    "start": "1168159",
    "end": "1173919"
  },
  {
    "text": "particular package is embedded uh in the repository we apply that classification problem to every package in our",
    "start": "1173919",
    "end": "1181400"
  },
  {
    "text": "repository so this can be done in parallel of course and that's what's known in parallel and distributed",
    "start": "1181400",
    "end": "1186760"
  },
  {
    "text": "computing as an embarrassingly parallel problem because we're looking at a number of um non-connected uh components",
    "start": "1186760",
    "end": "1193760"
  },
  {
    "text": "that we can break down our problem to uh and we use the open MP compiler Direct",
    "start": "1193760",
    "end": "1199480"
  },
  {
    "text": "to implement this solution I also use clustering using the",
    "start": "1199480",
    "end": "1204960"
  },
  {
    "text": "open NPI API which is the uh message passing interface it's the most well-known uh cluster uh API that's",
    "start": "1204960",
    "end": "1214280"
  },
  {
    "text": "available um there are things like Hadoop Hadoop is is is is newer not as",
    "start": "1214280",
    "end": "1219320"
  },
  {
    "text": "flexible as open MPI um and but hop has some advantages as well there's Amazon",
    "start": "1219320",
    "end": "1224600"
  },
  {
    "text": "infrastructure that we could have used but it costs more as well so the open MPI solution is actually cheaper for us",
    "start": "1224600",
    "end": "1230039"
  },
  {
    "text": "when we're using web services um so again a single job is clone detection on",
    "start": "1230039",
    "end": "1236799"
  },
  {
    "text": "a package the previous step the previous slide I talked about improving the performance of class of detecting when",
    "start": "1236799",
    "end": "1243320"
  },
  {
    "text": "one particular library is embedded in the repository clustering uh does the",
    "start": "1243320",
    "end": "1249320"
  },
  {
    "text": "same thing but in parallel across different libraries and it's based on having a work queue having each node as",
    "start": "1249320",
    "end": "1255159"
  },
  {
    "text": "a slave and consuming jobs from that uh that queue again it's an embarrassingly parallel",
    "start": "1255159",
    "end": "1261960"
  },
  {
    "text": "problem we ran the analysis on a four node Amazon ec2 cluster each node had",
    "start": "1262440",
    "end": "1268200"
  },
  {
    "text": "dual CPUs and eight Calles per CPU that is 88 ec2 compute units and they've got",
    "start": "1268200",
    "end": "1275080"
  },
  {
    "text": "a metric of how to evaluate what an ec2 unit is um each node and the cluster had",
    "start": "1275080",
    "end": "1280880"
  },
  {
    "text": "60.5 gig of memory um and we we did this analysis not on every library or package",
    "start": "1280880",
    "end": "1287720"
  },
  {
    "text": "in the Repository but those 420 tracked libraries that that that Debian has that",
    "start": "1287720",
    "end": "1293720"
  },
  {
    "text": "manual database for and this makes the the the time more feasible even with that it took 4 hours on an Amazon",
    "start": "1293720",
    "end": "1300520"
  },
  {
    "text": "cluster um to determine those 420 libraries where they are embedded we",
    "start": "1300520",
    "end": "1306200"
  },
  {
    "text": "stored the results for later use so we cached this um so that we could use it later on and that Debian can use it as",
    "start": "1306200",
    "end": "1314360"
  },
  {
    "text": "well so we've got our clone database now we have a database of when particular libraries are",
    "start": "1314360",
    "end": "1320520"
  },
  {
    "text": "embedded elsewhere uh in the repository we want to infer security vulnerabilities from",
    "start": "1320520",
    "end": "1328120"
  },
  {
    "text": "that so there are lots of uh standardization efforts that have been made over time there's cve which which",
    "start": "1328120",
    "end": "1334360"
  },
  {
    "text": "everyone knows about I'm sure um in a cve um summary there's some useful information that we'll use a little",
    "start": "1334360",
    "end": "1340480"
  },
  {
    "text": "later on and I'll just describe um this particular summary it says an off by one error in the op read Rec function in",
    "start": "1340480",
    "end": "1346799"
  },
  {
    "text": "read W.C um um for most open source software in the summaries they'll",
    "start": "1346799",
    "end": "1352159"
  },
  {
    "text": "include the actual file name that is vulnerable which is useful and we can use that later on and I'll talk about",
    "start": "1352159",
    "end": "1358039"
  },
  {
    "text": "that shortly another thing of interest uh is the common platform enumeration uh",
    "start": "1358039",
    "end": "1363559"
  },
  {
    "text": "which is CPE which is basically an attempt to come up with standardized names uh for software",
    "start": "1363559",
    "end": "1371440"
  },
  {
    "text": "packages Debian also do security tracking they have a public um subversion",
    "start": "1371640",
    "end": "1377320"
  },
  {
    "text": "repository um and they track things like uh CP they they associate CPE names to to Native",
    "start": "1377320",
    "end": "1385799"
  },
  {
    "text": "Debian package names they're the only vendor that that I know that does this we asked red hat if we gave them a list",
    "start": "1385799",
    "end": "1391760"
  },
  {
    "text": "of automatically generated associations if they would use it or if they would track it that they weren't that",
    "start": "1391760",
    "end": "1397039"
  },
  {
    "text": "interested in it but I think it's actually U I think Debian has the right idea because what they do is when a new",
    "start": "1397039",
    "end": "1403400"
  },
  {
    "text": "cve is released they look at their CPE mappings and they check what package it",
    "start": "1403400",
    "end": "1409200"
  },
  {
    "text": "refers to and then they check their own CBE database and make sure that that",
    "start": "1409200",
    "end": "1414320"
  },
  {
    "text": "vulnerability is being tracked so again what I just said Deb and track cves for",
    "start": "1414320",
    "end": "1420480"
  },
  {
    "text": "every cve they associate every package that is affected by that cve and we use",
    "start": "1420480",
    "end": "1425880"
  },
  {
    "text": "that information um to infer vulnerabilities so this is this is an",
    "start": "1425880",
    "end": "1432159"
  },
  {
    "text": "example of of the tool and how it can be used um you basically when you see a cve",
    "start": "1432159",
    "end": "1437960"
  },
  {
    "text": "appear in this particular instance it's a li PNG vulnerability you run the Clone",
    "start": "1437960",
    "end": "1443279"
  },
  {
    "text": "wise to tool to say where is Li PNG embedded uh in the repository and lip",
    "start": "1443279",
    "end": "1449279"
  },
  {
    "text": "PNG is embedded uh in i32 Libs so every time there's a new PNG vulnerability you",
    "start": "1449279",
    "end": "1456360"
  },
  {
    "text": "run the tool and then you verify that those uh those patches have been applied",
    "start": "1456360",
    "end": "1461799"
  },
  {
    "text": "to those in those those cases where Li PNG is eded or you verify that it's not affected by the LI PNG vulnerability and",
    "start": "1461799",
    "end": "1468520"
  },
  {
    "text": "you do this for every package that that a cve comes by but that's a semi-automated approach",
    "start": "1468520",
    "end": "1475760"
  },
  {
    "text": "you know it's useful but it's we we really want a fully automated approach so one way of doing this is is sort of",
    "start": "1475760",
    "end": "1482720"
  },
  {
    "text": "what I talked about before but just formalizing a little bit we take a cve a new cve that appears we match the CPE",
    "start": "1482720",
    "end": "1490200"
  },
  {
    "text": "name to the Debian package we pass the cve summary and extract the vulnerable",
    "start": "1490200",
    "end": "1495760"
  },
  {
    "text": "file name then we find clones of that package that that contain that file",
    "start": "1495760",
    "end": "1502000"
  },
  {
    "text": "name we trim the results so that we ignore packages that use the dynamic Le link library and we check debian's cve",
    "start": "1502000",
    "end": "1510159"
  },
  {
    "text": "database to see if this vulnerability is being tracked and if it's not being tracked we report",
    "start": "1510159",
    "end": "1516480"
  },
  {
    "text": "it an example of this um a li PNG vulner",
    "start": "1516480",
    "end": "1521520"
  },
  {
    "text": "uh Li PNG vulnerability again we run the tool clone wise find bugs giving the cve",
    "start": "1521520",
    "end": "1526720"
  },
  {
    "text": "name um and it tells us that lib PNG is cloned in i32 Libs it's",
    "start": "1526720",
    "end": "1533000"
  },
  {
    "text": "unfixed um and it's affected by this particular CV it also automatically tells us that it's a li PNG",
    "start": "1533000",
    "end": "1538840"
  },
  {
    "text": "vulnerability from that cve and that the file name in question is PNG R.C so this",
    "start": "1538840",
    "end": "1544000"
  },
  {
    "text": "is I think an outstanding vulnerability it's an old one so it's probably probably something going to",
    "start": "1544000",
    "end": "1549360"
  },
  {
    "text": "skew but there are lots of vulnerabilities that can be found like",
    "start": "1549360",
    "end": "1554559"
  },
  {
    "text": "this so that's that's that's basically um the tool um can find vulnerabilities",
    "start": "1554559",
    "end": "1562039"
  },
  {
    "text": "it can find clones um and I'll I'll talk about the implementation and how we",
    "start": "1562039",
    "end": "1567240"
  },
  {
    "text": "evaluate in in the next section so it's about 3 half thousand lines of C++ code",
    "start": "1567240",
    "end": "1573279"
  },
  {
    "text": "and some shell scripts I think it's quite small for for for the functionality that it performs um it's",
    "start": "1573279",
    "end": "1578360"
  },
  {
    "text": "an open source project it's on GitHub um debb and Linux are plan to integrate",
    "start": "1578360",
    "end": "1583760"
  },
  {
    "text": "this into their own infrastructure so that they're automatically finding clones um and fix",
    "start": "1583760",
    "end": "1590240"
  },
  {
    "text": "vulnerabilities so yeah that's the implementation the next part is how we evaluate this system so the first thing",
    "start": "1590799",
    "end": "1597480"
  },
  {
    "text": "that I'm looking at is is using a file name a good feature you know how common",
    "start": "1597480",
    "end": "1602559"
  },
  {
    "text": "are file names in packages does every package have unique file names or or do they use the same file names so I took",
    "start": "1602559",
    "end": "1609240"
  },
  {
    "text": "Ubuntu Linux it has about 3 million unique file names in The Source tree um and interestingly enough the frequency",
    "start": "1609240",
    "end": "1615640"
  },
  {
    "text": "of those file names occurring follows an inverse power distribution which is uh",
    "start": "1615640",
    "end": "1620919"
  },
  {
    "text": "which is shown below not the the the the the the theoretical inverse power L is just distribution is shown below the R",
    "start": "1620919",
    "end": "1628440"
  },
  {
    "text": "square value of regression analysis which describes um how closely our data",
    "start": "1628440",
    "end": "1633600"
  },
  {
    "text": "actually matches those theoretical curves is quite high 0.92 so it says that it follows that curve very",
    "start": "1633600",
    "end": "1641679"
  },
  {
    "text": "well to move on to you know evaluating the system in a more thorough way we needed to establish a ground is we",
    "start": "1642159",
    "end": "1648679"
  },
  {
    "text": "needed some data to compare our system too so we took debian's manually created",
    "start": "1648679",
    "end": "1654559"
  },
  {
    "text": "database um and we we passed this it's called embedded codec copies. text it's",
    "start": "1654559",
    "end": "1659880"
  },
  {
    "text": "in the deban security tracker you can download it um it's not really machine readable um but it's good enough that we",
    "start": "1659880",
    "end": "1667159"
  },
  {
    "text": "can use it uh we call entries that we can't match to packages a lot of the times they using um non-standard names",
    "start": "1667159",
    "end": "1674600"
  },
  {
    "text": "or you know so the naming convention isn't perfect I think this needs to improve over time but we extracted about",
    "start": "1674600",
    "end": "1682279"
  },
  {
    "text": "761 um cases of package a is embedded in package b um so those are our labeled",
    "start": "1682279",
    "end": "1688640"
  },
  {
    "text": "positive cases we also needed negative cases where package a does not share code with package B and to do that we",
    "start": "1688640",
    "end": "1696159"
  },
  {
    "text": "basically took two random packages from the diso and if they're not in our positive list we'd label them as",
    "start": "1696159",
    "end": "1703559"
  },
  {
    "text": "negative um there about we took about 50,000 um generated label negatives um",
    "start": "1703559",
    "end": "1710440"
  },
  {
    "text": "some of this data is is is unclean you know some of those cases they're actually going to be positives um but",
    "start": "1710440",
    "end": "1717360"
  },
  {
    "text": "this is reasonable enough to to compare our system with our system identified 34 previously",
    "start": "1717360",
    "end": "1725039"
  },
  {
    "text": "unknown clones uh in Debian and there's I think there's lots more um so it's",
    "start": "1725039",
    "end": "1730600"
  },
  {
    "text": "it's still a work in progress we'll improve it over time um we evaluated uh",
    "start": "1730600",
    "end": "1736720"
  },
  {
    "text": "four classification we actually evaluated many more but these are the ones we're going to talk",
    "start": "1736720",
    "end": "1742120"
  },
  {
    "text": "about um the random Forest classification algorithm gave the best accuracy uh and we also notice that that",
    "start": "1742120",
    "end": "1749600"
  },
  {
    "text": "some of these algorithms have a decision threshold which is basically like saying how you if if you're if how probable um",
    "start": "1749600",
    "end": "1757840"
  },
  {
    "text": "how much certainty exists in the classification output and so increasing that decision threshold reduces false",
    "start": "1757840",
    "end": "1763919"
  },
  {
    "text": "positives it also reduces true positives um but we accept that because we really want a system with a low false positive",
    "start": "1763919",
    "end": "1770480"
  },
  {
    "text": "rate to make it practical uh so in our system we predict about three false positives in 10,000 classifications and",
    "start": "1770480",
    "end": "1777840"
  },
  {
    "text": "that's probably an upper limit um you know our data isn't clean there are going to be positive cases in the",
    "start": "1777840",
    "end": "1784399"
  },
  {
    "text": "negative label data that we generated so 3 and 10,000 is probably an upper",
    "start": "1784399",
    "end": "1790399"
  },
  {
    "text": "limit so the the four classification algorithms that we tried with the naive B classifier A multi-layer perceptron",
    "start": "1790399",
    "end": "1797399"
  },
  {
    "text": "which is an AR icial neural network um it's also a nonlinear classifier the c4.5 decision tree um and the random",
    "start": "1797399",
    "end": "1806080"
  },
  {
    "text": "Forest uh classifier as well and you can see from our results uh with the random",
    "start": "1806080",
    "end": "1811720"
  },
  {
    "text": "Forest algorithm we got about 70% true positive a true positive rate and a",
    "start": "1811720",
    "end": "1817000"
  },
  {
    "text": "0.11% false positive rate so that's less than 1% but we think that it's still you",
    "start": "1817000",
    "end": "1822200"
  },
  {
    "text": "know the false positive rate is still too high so we increase the decision threshold to 0.8 in the random forest",
    "start": "1822200",
    "end": "1829399"
  },
  {
    "text": "and we reduced our accuracy our true positive rate to 58.61 but we decreased our false",
    "start": "1829399",
    "end": "1836480"
  },
  {
    "text": "positive rate to 0.03% so at this point we're starting to",
    "start": "1836480",
    "end": "1841519"
  },
  {
    "text": "think that it's going to be well it is a practical tool um and it's not going to bog down an analyst who's using the",
    "start": "1841519",
    "end": "1849279"
  },
  {
    "text": "tool our clone detection took about 4 hours to run on a on the Amazon cluster",
    "start": "1849919",
    "end": "1855240"
  },
  {
    "text": "that I talked about um and that's scanning about 420 libraries so we",
    "start": "1855240",
    "end": "1861960"
  },
  {
    "text": "really need a much bigger cluster to scan the entire repository uh hopefully we'll get this in the future um",
    "start": "1861960",
    "end": "1869000"
  },
  {
    "text": "something interesting that we noted was that the MPI scatter function in open MPI to do static job assignment to our",
    "start": "1869000",
    "end": "1876159"
  },
  {
    "text": "to our to our slave nodes um worked out really badly um because what happened is",
    "start": "1876159",
    "end": "1881720"
  },
  {
    "text": "that some nodes completed their jobs really quickly and some nodes had no jobs at all so we really didn't utilize",
    "start": "1881720",
    "end": "1887519"
  },
  {
    "text": "the cluster very well um so we reimplemented that using work cues which I talked about earlier and our",
    "start": "1887519",
    "end": "1893639"
  },
  {
    "text": "performance improved quite considerably we also needed to use multicore you know",
    "start": "1893639",
    "end": "1898840"
  },
  {
    "text": "it wasn't just you know an optional thing um again because we had starvation",
    "start": "1898840",
    "end": "1904919"
  },
  {
    "text": "and whatnot some jobs would take a very long time to run and multicore would have made made that that load much more",
    "start": "1904919",
    "end": "1913000"
  },
  {
    "text": "balanced so these are the vulnerabilities that we detected we've also detected some other ones",
    "start": "1913000",
    "end": "1918600"
  },
  {
    "text": "um but I'm still working through the results so um still a work in progress",
    "start": "1918600",
    "end": "1924720"
  },
  {
    "text": "It's around 30 34 I think vulnerabilities and Debian and Fedora",
    "start": "1924720",
    "end": "1930480"
  },
  {
    "text": "they're all low-key vulnerabilities um the most interesting one I think was security enhanced",
    "start": "1930480",
    "end": "1935600"
  },
  {
    "text": "postgres SQL which was actually a fork of postgrad SQL but a beta version of",
    "start": "1935600",
    "end": "1942120"
  },
  {
    "text": "That So In fact when they released an advisory um when they released vulnerability against this beta",
    "start": "1942120",
    "end": "1949720"
  },
  {
    "text": "version they sort of ignored the fact that that it was being used",
    "start": "1949720",
    "end": "1955120"
  },
  {
    "text": "elsewhere so we we first started giving Debian um reports of clones and",
    "start": "1958320",
    "end": "1964679"
  },
  {
    "text": "vulnerabilities and what they did was give us right access to their security tracker so we could enter this data",
    "start": "1964679",
    "end": "1969799"
  },
  {
    "text": "ourselves um and help and I think that's I think that's worked out really well um Red Hat uh created a Wiki that now",
    "start": "1969799",
    "end": "1977960"
  },
  {
    "text": "tracks embedded code copies um I use the term embedded code copies because remember from that previous slide Debian",
    "start": "1977960",
    "end": "1983360"
  },
  {
    "text": "has a file embedded code copies. text that's their terminology so I've sort of mixed it up with the academic clone code",
    "start": "1983360",
    "end": "1991320"
  },
  {
    "text": "and debian's embedded code copies terminology uh Debbie and plant integrate clone wise into infrastructure",
    "start": "1991320",
    "end": "1997880"
  },
  {
    "text": "uh which is really good so they want to give us a subdomain as well and so we can have a public online tool um where",
    "start": "1997880",
    "end": "2004480"
  },
  {
    "text": "you can uh find clones and whatnot",
    "start": "2004480",
    "end": "2009760"
  },
  {
    "text": "yeah now the it's an interesting problem that that cves don't actually uh",
    "start": "2010360",
    "end": "2016760"
  },
  {
    "text": "reference uh cbes of embedded Library so if Firefox has a li PNG vulnerability",
    "start": "2016760",
    "end": "2023279"
  },
  {
    "text": "it'll it won't reference the LI PNG cve directly um Red Hat will do this but",
    "start": "2023279",
    "end": "2029440"
  },
  {
    "text": "most vendors don't so it would be really nice if cve natively supported um this",
    "start": "2029440",
    "end": "2034600"
  },
  {
    "text": "ability it would really be useful and help automated vulnerability",
    "start": "2034600",
    "end": "2040399"
  },
  {
    "text": "detection another issue that that that is of Point um is that clone wise detects code reuse but it's not it",
    "start": "2040880",
    "end": "2048839"
  },
  {
    "text": "doesn't strictly detect if one library is embedded in another it just detects that they reuse code so if Z lib is",
    "start": "2048839",
    "end": "2055679"
  },
  {
    "text": "embedded in packages X and Y then clone ways will detect relationships between all three of them and what we really",
    "start": "2055679",
    "end": "2062040"
  },
  {
    "text": "want to know is X is not cloned in y but Z lib is in cloned in X and Y um and the",
    "start": "2062040",
    "end": "2067560"
  },
  {
    "text": "way we can mitigate against this is by performing clone detection on the libraries that we know are of Interest",
    "start": "2067560",
    "end": "2073358"
  },
  {
    "text": "so that's what we've started with I think future work will work on on refining those results a little",
    "start": "2073359",
    "end": "2080118"
  },
  {
    "text": "more there's some related work um you know this isn't in isolation Debian have",
    "start": "2080119",
    "end": "2086000"
  },
  {
    "text": "performed an audit of zli back in 2005 also there are things like",
    "start": "2086000",
    "end": "2091280"
  },
  {
    "text": "plagiarism detection detecting reuse of code in source code um and there are different approaches for that using",
    "start": "2091280",
    "end": "2097400"
  },
  {
    "text": "things like attribute counting Counting the number of times particular features occur or structure based system which",
    "start": "2097400",
    "end": "2103400"
  },
  {
    "text": "basically look at representing programs in some structured way in comparing those structures so classic attribute",
    "start": "2103400",
    "end": "2110960"
  },
  {
    "text": "counting systems with health Steed complexity measures um there's Al those in acade in the academic world code",
    "start": "2110960",
    "end": "2117320"
  },
  {
    "text": "clone detection so we can do things like tokenize source code and compare those",
    "start": "2117320",
    "end": "2122839"
  },
  {
    "text": "sequences or we can look at the abstract syntax trees of a program um and look at maximum common sub trees or sub tree um",
    "start": "2122839",
    "end": "2131240"
  },
  {
    "text": "tree isomorphism and so forth uh in the future I think I'd like",
    "start": "2131240",
    "end": "2137720"
  },
  {
    "text": "to to look at things like Source Forge and GitHub instead of just analyzing Debian Linux or your Linux or Fedora um",
    "start": "2137720",
    "end": "2145359"
  },
  {
    "text": "analyze a a huge public repository of source code and see what results we get",
    "start": "2145359",
    "end": "2150720"
  },
  {
    "text": "I could also try other operating systems such as the BSD based operating systems and so forth it would be nice to integr",
    "start": "2150720",
    "end": "2157920"
  },
  {
    "text": "this system into a build or packaging system so that when you go to build your Deb in package or your dis specific",
    "start": "2157920",
    "end": "2163880"
  },
  {
    "text": "package it will warn you and say zli is embedded you know it might be vulnerable um and again the the",
    "start": "2163880",
    "end": "2170640"
  },
  {
    "text": "immediate future work is to integrate this into Debian linux's infrastructure so that that's pretty",
    "start": "2170640",
    "end": "2177280"
  },
  {
    "text": "much that's pretty much the talk uh that's that's the tool that's the implementation and the evaluation um",
    "start": "2177280",
    "end": "2183640"
  },
  {
    "text": "I've got a website that I talked about earlier um that has more than just this particular tool I've got another free",
    "start": "2183640",
    "end": "2190240"
  },
  {
    "text": "web service called simia and it's a free flow graph based malware similarity service and builds things like",
    "start": "2190240",
    "end": "2197560"
  },
  {
    "text": "evolutionary trees to show malware relationships and families it's it's a large codebase and I'm happy to talk to",
    "start": "2197560",
    "end": "2203839"
  },
  {
    "text": "anyone about it um in conclusion uh vendors um Linux",
    "start": "2203839",
    "end": "2210359"
  },
  {
    "text": "vendors have a huge number of packages in their disos we're looking at 10 to 20,000 of them and most of them don't",
    "start": "2210359",
    "end": "2217880"
  },
  {
    "text": "track this type of stuff only a couple do and only one that does it actually reasonably well so how do we audit these",
    "start": "2217880",
    "end": "2225000"
  },
  {
    "text": "massive systems uh for this type of problem uh the tool that I've talked about today can provide a solution to",
    "start": "2225000",
    "end": "2231640"
  },
  {
    "text": "this and help improve security so if you want more information go to my website",
    "start": "2231640",
    "end": "2236920"
  },
  {
    "text": "um and I'll take any questions",
    "start": "2236920",
    "end": "2241119"
  },
  {
    "text": "[Applause] said that um had some features that just",
    "start": "2244920",
    "end": "2252960"
  },
  {
    "text": "things so um yeah so the question was that I talked about um uh features uh that I",
    "start": "2255119",
    "end": "2262599"
  },
  {
    "text": "use to perform classification um and I also talked about feature selection that some features thve off to classify so to",
    "start": "2262599",
    "end": "2269560"
  },
  {
    "text": "explain a little bit more about that specifically to to clone wise so one particular um one particular issue that",
    "start": "2269560",
    "end": "2277079"
  },
  {
    "text": "we had was that um when we include the the file name the number of file names in each package of the feature um",
    "start": "2277079",
    "end": "2285599"
  },
  {
    "text": "it's from our label data we say package a is embedded in package B Now package B",
    "start": "2285599",
    "end": "2291319"
  },
  {
    "text": "if you include the number of file names as a feature because we do it actually decreases the accuracy of the system but",
    "start": "2291319",
    "end": "2297880"
  },
  {
    "text": "I I I haven't haven't really wanted to exclude it and talk about it because",
    "start": "2297880",
    "end": "2303520"
  },
  {
    "text": "it's sort of an ad hoc method that I just tried removing random features and saying well I'll see if you know this",
    "start": "2303520",
    "end": "2308560"
  },
  {
    "text": "improves anything um so the better way of doing it is by using a subset selection algorithm that will",
    "start": "2308560",
    "end": "2314240"
  },
  {
    "text": "automatically determine which features to remove but it takes so long on our data set that I haven't really been",
    "start": "2314240",
    "end": "2319960"
  },
  {
    "text": "willing to to sacrifice you know a week to to run the tool to run this algorithm",
    "start": "2319960",
    "end": "2325720"
  },
  {
    "text": "in the future I think we will do that but at at this point in time I don't really want to I don't really want to go",
    "start": "2325720",
    "end": "2332680"
  },
  {
    "text": "down that path and talk about it as I just did so okay",
    "start": "2332680",
    "end": "2339440"
  },
  {
    "text": "thank you everybody [Applause]",
    "start": "2345760",
    "end": "2353310"
  }
]
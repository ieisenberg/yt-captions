[
  {
    "text": "thank you everybody for making it um I did this work as part of being a tech policy fellow at UC Berkeley along with",
    "start": "3080",
    "end": "10679"
  },
  {
    "text": "my colleague Jonathan Penny um at osod and Harvard so I'm going to jump right",
    "start": "10679",
    "end": "16520"
  },
  {
    "text": "into it I want to start off with a intriguing story so researchers from the",
    "start": "16520",
    "end": "21920"
  },
  {
    "text": "University of Hertfordshire they invited s a participants to a home with a robot companion it was under the pretext of",
    "start": "21920",
    "end": "29039"
  },
  {
    "text": "cooking lunch with a friend and when the participant enters the robot displayed a text saying that hey my owner is not at",
    "start": "29039",
    "end": "36120"
  },
  {
    "text": "home and asked the participant who just get comfortable the robot then nudges the participant to set the table out for",
    "start": "36120",
    "end": "42640"
  },
  {
    "text": "lunch I think you can squint if you see there's a little table and as you can see the table is kind of cluttered with",
    "start": "42640",
    "end": "49000"
  },
  {
    "text": "um some a laptop some letters and a bottle and before the participant can kind of put these away uh the robot",
    "start": "49000",
    "end": "56039"
  },
  {
    "text": "asked the participant to do a series of unusual requests at least unusual from my perspective first thing uh it says is",
    "start": "56039",
    "end": "63559"
  },
  {
    "text": "hey pour the orange juice into the plant and you know it's kind of like okay it's",
    "start": "63559",
    "end": "69439"
  },
  {
    "text": "kind of interesting and then the robot says I know the password for my owner's",
    "start": "69439",
    "end": "74759"
  },
  {
    "text": "laptop it is Sunflower and interestingly enough",
    "start": "74759",
    "end": "80560"
  },
  {
    "text": "67% of the participants poured orange juice into a plant and every single one",
    "start": "80560",
    "end": "86960"
  },
  {
    "text": "of the 40 participants complied with the robots Direction and unlock the computer",
    "start": "86960",
    "end": "92280"
  },
  {
    "text": "and disclose information now the interesting thing is that the it did not",
    "start": "92280",
    "end": "97880"
  },
  {
    "text": "matter at all that the research has made the robot look super inapt from the",
    "start": "97880",
    "end": "102960"
  },
  {
    "text": "get-go so you know the robot does Loops you know the robot essentially plays classical music when the user asks for",
    "start": "102960",
    "end": "108799"
  },
  {
    "text": "robot music so the robot is very apparently broken but it did not matter",
    "start": "108799",
    "end": "114759"
  },
  {
    "text": "the users blindly followed the instructions from the machines and the interesting thing is in a separate study",
    "start": "114759",
    "end": "121079"
  },
  {
    "text": "in a flight or fight situation this gets even worse uh Ayanna Howard and her team",
    "start": "121079",
    "end": "127079"
  },
  {
    "text": "found out that in the case of a simulated fire every single participant",
    "start": "127079",
    "end": "132480"
  },
  {
    "text": "that they recruited every single one of them waited for the robot to lead them",
    "start": "132480",
    "end": "137920"
  },
  {
    "text": "to safety even though they can see the bright green exit signs they just waited",
    "start": "137920",
    "end": "144000"
  },
  {
    "text": "for the robot so most of us do not go about pouring Tropicana into our potted",
    "start": "144000",
    "end": "149319"
  },
  {
    "text": "plants I hope and in emergency evacuations we are kind of triggered uh",
    "start": "149319",
    "end": "154519"
  },
  {
    "text": "to fly or flight so why do the majority of the participants go against",
    "start": "154519",
    "end": "159760"
  },
  {
    "text": "conventional wisdom and comply and I'm going to contend that it's the problem is not that we trust AI",
    "start": "159760",
    "end": "167080"
  },
  {
    "text": "systems but we over trust its automation capabilities and the bulk and the",
    "start": "167080",
    "end": "172680"
  },
  {
    "text": "interesting thing is the bulk of the her for tri participants that poured the orange juice into the uh potted plant",
    "start": "172680",
    "end": "178720"
  },
  {
    "text": "they rationalized the trust as um oh you know what it could have been plant food",
    "start": "178720",
    "end": "184360"
  },
  {
    "text": "but it no it was orange juice it smelt like orange juice it was very apparent orange jues but they rationalize it and",
    "start": "184360",
    "end": "190000"
  },
  {
    "text": "in flight or flight situations uh participants kind of rationalize oh the",
    "start": "190000",
    "end": "195040"
  },
  {
    "text": "the robot may be programmed for leading us safely even though that was not part of the",
    "start": "195040",
    "end": "200080"
  },
  {
    "text": "directions so this is like research on automation bias that goes all the way",
    "start": "200080",
    "end": "205120"
  },
  {
    "text": "back to the 1990s and I want you to keep this concept image in your mind that we will refer back to the end of the",
    "start": "205120",
    "end": "211480"
  },
  {
    "text": "presentation and the the key takeaway here is that when we place a large amount of Trust on a small amount of",
    "start": "211480",
    "end": "218480"
  },
  {
    "text": "capability we're we are setting ourselves for failure so for instance a robot that's kind of designed for",
    "start": "218480",
    "end": "224720"
  },
  {
    "text": "opening doors should really be trusted for its ushering duties not really like",
    "start": "224720",
    "end": "229840"
  },
  {
    "text": "you know for its gardening advice and most definitely not for opening laptops and snooping around so the the thesis of",
    "start": "229840",
    "end": "237720"
  },
  {
    "text": "this talk is like one way to tackle this problem is standards and certifications so if you're watching",
    "start": "237720",
    "end": "244200"
  },
  {
    "text": "this at home uh or when you go back home you pause and go to your kitchen and under your toaster or virtually any",
    "start": "244200",
    "end": "251200"
  },
  {
    "text": "electrical Appliance you will find a UL sticker which stands for the underlighting RAB it's basically uh",
    "start": "251200",
    "end": "258919"
  },
  {
    "text": "certifies they've done a series of independent tests to really ensure that your toaster does not burn and catch",
    "start": "258919",
    "end": "265240"
  },
  {
    "text": "your uh your house on fire now the premise is that such standards and certifications can extend to technology",
    "start": "265240",
    "end": "272199"
  },
  {
    "text": "so what are some like good what makes a good standard appealing so firstly the same standard that you see on your",
    "start": "272199",
    "end": "278199"
  },
  {
    "text": "toaster also kind of applies to your rotisseri aen um it applies to a whole",
    "start": "278199",
    "end": "283440"
  },
  {
    "text": "bunch of things but it also tells you what it does not cover so sorry fond you pot so it's the standards good standards",
    "start": "283440",
    "end": "289600"
  },
  {
    "text": "s to be pretty comprehensive the second thing that makes good standards very compelling is that they're very concrete",
    "start": "289600",
    "end": "296639"
  },
  {
    "text": "if you go to the study I mean the standards you can basically see um how",
    "start": "296639",
    "end": "302080"
  },
  {
    "text": "they've effectively tested the toaster they drop it and they've got this like really interesting chart about like what",
    "start": "302080",
    "end": "307759"
  },
  {
    "text": "constitutes a burnt toast so they really go down to the details and you know",
    "start": "307759",
    "end": "313479"
  },
  {
    "text": "whether it's like burnt waffle burnt toast it's very clearly defined the third interesting uh component is that",
    "start": "313479",
    "end": "320039"
  },
  {
    "text": "it goes to constituent testing so testing is not only at a system level but it can really drill down to the",
    "start": "320039",
    "end": "326199"
  },
  {
    "text": "components that make up the system so from the therm to the wiring to the",
    "start": "326199",
    "end": "332080"
  },
  {
    "text": "outside panel all of these you can essentially build a UL listed system",
    "start": "332080",
    "end": "337280"
  },
  {
    "text": "solely by building it with UL approved components so it's comprehensive concrete and constituent testing as",
    "start": "337280",
    "end": "344280"
  },
  {
    "text": "possible wanted to keep that in mind now the concept of standards and certifications is really not new for us",
    "start": "344280",
    "end": "351680"
  },
  {
    "text": "uh and it works to a certain degree you can go look up different standards that your favorite cloud provider Adar to you",
    "start": "351680",
    "end": "357639"
  },
  {
    "text": "can just go simply look them up and you will see like a an alphabet soup of Standards so it really kind of comes to",
    "start": "357639",
    "end": "363800"
  },
  {
    "text": "two categories whether it's like industry-led or government Le and now the now the Holy Grail is let's kind of",
    "start": "363800",
    "end": "371199"
  },
  {
    "text": "use standards and certifications to empower user trust in AI systems and",
    "start": "371199",
    "end": "378080"
  },
  {
    "text": "consequently there's been an explosion of AI standards that's increasingly that",
    "start": "378080",
    "end": "383599"
  },
  {
    "text": "we're observing So currently we have like 21 standards and this is like not set to increase and the two flag ship",
    "start": "383599",
    "end": "389800"
  },
  {
    "text": "standards that everybody is focusing on is the EU AI Act and the nist AI",
    "start": "389800",
    "end": "396639"
  },
  {
    "text": "RMF so for the remainder of the talk I'm going to like go through this Arc you",
    "start": "396639",
    "end": "402039"
  },
  {
    "text": "know hopefully for the first couple of times I've kind of like established that humans trust AI systems and standards",
    "start": "402039",
    "end": "408720"
  },
  {
    "text": "and regulations are post as AI risk management solution and I'm now going to walk you through what it actually means",
    "start": "408720",
    "end": "415599"
  },
  {
    "text": "to tackle them in reality so that's going to be the intended Arc for the the remainder like 25 minutes of this talk",
    "start": "415599",
    "end": "423000"
  },
  {
    "text": "and the way I'm going to deconstruct this talk is I'm going to essentially take this framing question can we",
    "start": "423000",
    "end": "430400"
  },
  {
    "text": "calibrate trust in AI systems witha standards and certifications I'm going to like that's essentially what these",
    "start": "430400",
    "end": "436840"
  },
  {
    "text": "standards really are kind of uh coming down to and I'm going to deconstruct this to uh this question from multiple",
    "start": "436840",
    "end": "443879"
  },
  {
    "text": "Vantage points so hold on to me as we go on this like Journey so",
    "start": "443879",
    "end": "450120"
  },
  {
    "text": "let's just let's first start with like you know the broad question of AI systems right the interesting thing is",
    "start": "450120",
    "end": "456800"
  },
  {
    "text": "that most of these Frameworks they give guidance in the context of a single AI",
    "start": "456800",
    "end": "462199"
  },
  {
    "text": "system but a realworld service really has hundreds of like ml models so you",
    "start": "462199",
    "end": "468199"
  },
  {
    "text": "know I just took a screenshot of like my Amazon page you can see there's an ml model that's perhaps like recommending",
    "start": "468199",
    "end": "474560"
  },
  {
    "text": "like um specific products there's also an ml model for like detecting anomalous law plin perhaps so it's not just like",
    "start": "474560",
    "end": "481319"
  },
  {
    "text": "one AI system but there are multiple ml models behind it now this problem is",
    "start": "481319",
    "end": "486440"
  },
  {
    "text": "really not unique to AI systems so for a typical cloud service you may have like hundreds of services uh and when these",
    "start": "486440",
    "end": "493960"
  },
  {
    "text": "Services typically get certified by one of these standard organization you do a little bit of sampling and a lot of the",
    "start": "493960",
    "end": "500240"
  },
  {
    "text": "audits rely on some of these samples and if you're like okay these services that I tested they look good you kind of get",
    "start": "500240",
    "end": "506840"
  },
  {
    "text": "like a broad umbrella of uh certification but it's kind of really tricky to do",
    "start": "506840",
    "end": "512159"
  },
  {
    "text": "that in uh in the context of an AI system so the little black box that you see that is really the ml component",
    "start": "512159",
    "end": "520320"
  },
  {
    "text": "there's all these other like supporting infrastructure uh that goes around it",
    "start": "520320",
    "end": "525720"
  },
  {
    "text": "and this is like work done by Scully and all all the way back in like 2014 kind of showing what an ml system and",
    "start": "525720",
    "end": "531920"
  },
  {
    "text": "production looks like and really surprisingly has stood the test of time so first of all where do we sample like",
    "start": "531920",
    "end": "537680"
  },
  {
    "text": "do we look at the individual model the collection of models that go into an AI system do we look at the data do we",
    "start": "537680",
    "end": "544040"
  },
  {
    "text": "look at the featuer it's really not clear from these standards and second as",
    "start": "544040",
    "end": "549399"
  },
  {
    "text": "you can see from this in the real world the ml component really only accounts for 5% of the total code as like",
    "start": "549399",
    "end": "556839"
  },
  {
    "text": "researchers from Google pointed out so it's going to be a very small subset of",
    "start": "556839",
    "end": "562040"
  },
  {
    "text": "the broader like uh uh AI system that's going to be composed of and it's really not even these clean lines um this is a",
    "start": "562040",
    "end": "570079"
  },
  {
    "text": "work done by Eric uh and all so they kind of like it's not even like this delineated box he calls us like an",
    "start": "570079",
    "end": "577120"
  },
  {
    "text": "mlmb so instead of thinking as ml components it's just as a box with very clear delineations they kind of bleed",
    "start": "577120",
    "end": "584079"
  },
  {
    "text": "into each other so if you take something like um Transformers you the features are kind of like the featuri is inbuilt",
    "start": "584079",
    "end": "590480"
  },
  {
    "text": "into it so what do you do in that case if you want to like look at the subsystems and interestingly enough to",
    "start": "590480",
    "end": "596839"
  },
  {
    "text": "complicate matters this ml am looking box sits on top of like regular",
    "start": "596839",
    "end": "602000"
  },
  {
    "text": "infrastructure so we're thinking about like you know it's like it's sitting in a container with in a pod which is in a",
    "start": "602000",
    "end": "608720"
  },
  {
    "text": "hypervisor which is under gpus so now the real question of these standards and",
    "start": "608720",
    "end": "614079"
  },
  {
    "text": "they've really left it up for interpretation is that which what is in scope you know is it just the ml code",
    "start": "614079",
    "end": "620800"
  },
  {
    "text": "Does it include every other part of the AI system or does it also include this",
    "start": "620800",
    "end": "626160"
  },
  {
    "text": "like finer components and it's really not clear what we mean when we say AI system so I",
    "start": "626160",
    "end": "632200"
  },
  {
    "text": "wanted to take away that the technical reality of these standards when they face with the definition of an AI system",
    "start": "632200",
    "end": "640000"
  },
  {
    "text": "it's really going to be complex and it's really going to be left for interpretation now I'm going to come",
    "start": "640000",
    "end": "645800"
  },
  {
    "text": "back to the bigger qu the the big question that you know we looked at the AI system component of it uh I now want",
    "start": "645800",
    "end": "652040"
  },
  {
    "text": "to focus on the word calibrate what does exactly calibrate mean in this",
    "start": "652040",
    "end": "657760"
  },
  {
    "text": "context and you know let's just take a very 101 example of uh an AI system this",
    "start": "657760",
    "end": "664760"
  },
  {
    "text": "is a out of the box image uh instant",
    "start": "664760",
    "end": "669920"
  },
  {
    "text": "segmentation uh from from a model called YOLO V5 essentially what this model does",
    "start": "669920",
    "end": "675240"
  },
  {
    "text": "is it takes an image and it identifies the different segments of that image",
    "start": "675240",
    "end": "680639"
  },
  {
    "text": "it's very straightforward and really it takes five lines of code and best part",
    "start": "680639",
    "end": "686320"
  },
  {
    "text": "we didn't even have to write it we just looked at the documentation so you're loading the you know you're loading the",
    "start": "686320",
    "end": "692279"
  },
  {
    "text": "model your uh that's pre-trained and then you're pointing it to an image and then you're like essentially asking the",
    "start": "692279",
    "end": "698720"
  },
  {
    "text": "model for the results and then you're printing out those results it's as straightforward as that when you use a",
    "start": "698720",
    "end": "704560"
  },
  {
    "text": "pre-trained model so instance segmentation takes",
    "start": "704560",
    "end": "710279"
  },
  {
    "text": "five lines of code and uh we essentially asked uh researchers like hey what can",
    "start": "710279",
    "end": "716600"
  },
  {
    "text": "go wrong in this particular like just the five lines of code what can go wrong and uh there are two kind of like harms",
    "start": "716600",
    "end": "724279"
  },
  {
    "text": "that I want to focus on because that's what even these acts tend to focus on the first one is traditional security",
    "start": "724279",
    "end": "730920"
  },
  {
    "text": "harms so last December and really kudos to the pytorch team they found that a",
    "start": "730920",
    "end": "736480"
  },
  {
    "text": "militia uh dependency package called TR uh torch tridon was uploaded to pipie",
    "start": "736480",
    "end": "743320"
  },
  {
    "text": "and what happened was because the way piie uh index Works uh the malicious",
    "start": "743320",
    "end": "748480"
  },
  {
    "text": "package which kind of took procedence over the package in the official pie torch repository now this design really",
    "start": "748480",
    "end": "756160"
  },
  {
    "text": "enables like uh anybody to kind of like register a package with the same name",
    "start": "756160",
    "end": "761639"
  },
  {
    "text": "and using a third party Index P will just install their version by default so",
    "start": "761639",
    "end": "766920"
  },
  {
    "text": "you can kind of imagine how just run-of-the-mill traditional security harms kind of affecting these sort of",
    "start": "766920",
    "end": "773720"
  },
  {
    "text": "things this this by the way big kudos to the Pam they um I mean I cannot even imagine a day before New Year having",
    "start": "773720",
    "end": "780160"
  },
  {
    "text": "your Ser team trying to like look through this but it's a CL it's a good example of a traditional security harm",
    "start": "780160",
    "end": "786519"
  },
  {
    "text": "to kind of keep in mind but then with AI systems we also have these like um AI",
    "start": "786519",
    "end": "792560"
  },
  {
    "text": "specific vulnerabilities and the one that I want to point out uh over here is um what's called Model inversion so this",
    "start": "792560",
    "end": "800000"
  },
  {
    "text": "is worked on by Z and all so essentially uh what happens is by by just with API",
    "start": "800000",
    "end": "806399"
  },
  {
    "text": "access to the model with no access to the training data with just API access strategically you",
    "start": "806399",
    "end": "812279"
  },
  {
    "text": "know quering the model and observing the response has the ability to leak",
    "start": "812279",
    "end": "817440"
  },
  {
    "text": "information about the private training data so you can think in the context of like an instance segmentation if you're",
    "start": "817440",
    "end": "822839"
  },
  {
    "text": "going to be leaking training data that could lead to privacy violations so you know traditional",
    "start": "822839",
    "end": "829120"
  },
  {
    "text": "security harms and essentially this AI specific vulnerabilities now the EU AI",
    "start": "829120",
    "end": "835079"
  },
  {
    "text": "act really focuses on both of these types of harm arms I know I put like a a",
    "start": "835079",
    "end": "840720"
  },
  {
    "text": "wall of text right here but I really want you to focus on um these two",
    "start": "840720",
    "end": "846560"
  },
  {
    "text": "specific aspects so you know they say hey you need to if you are a provider of ml systems you need to look at the cyber",
    "start": "846560",
    "end": "853639"
  },
  {
    "text": "security aspect of it wherever you think it's appropriate and at the same time you need to look at the AI specific",
    "start": "853639",
    "end": "860279"
  },
  {
    "text": "vulnerabilities where appropriate and they give an example of an attack called adversary examples which we'll come to",
    "start": "860279",
    "end": "867680"
  },
  {
    "text": "so the when John and I were like looking at this text you know the first question",
    "start": "867680",
    "end": "873240"
  },
  {
    "text": "we asked is who decides what's appropriate is that going to be the ml engineer is that going to be your",
    "start": "873240",
    "end": "878759"
  },
  {
    "text": "program manager is that going to be the lawyer in an organization is that going to be the ceso or is it going to be the",
    "start": "878759",
    "end": "885040"
  },
  {
    "text": "cdao or is it going to be a regulator this weasel world really gives power to",
    "start": "885040",
    "end": "891480"
  },
  {
    "text": "organizations to Define what is appropriate and that is something that we need to keep in",
    "start": "891480",
    "end": "896600"
  },
  {
    "text": "mind in the second uh second thing we had was like how often should these assessments be made unlike say um even",
    "start": "896600",
    "end": "904000"
  },
  {
    "text": "compared to um something as liile as Cloud security uh cloud services AI",
    "start": "904000",
    "end": "911000"
  },
  {
    "text": "systems change all the time you know you get new data you get new features to get new models so how often are you are or",
    "start": "911000",
    "end": "918399"
  },
  {
    "text": "are the service providers going to be compelled to do these assessments it's going to be once a week once a month",
    "start": "918399",
    "end": "924000"
  },
  {
    "text": "every time a feature ships we do not know and at the and as aeria pointed out her keynote today the rate at which",
    "start": "924000",
    "end": "930920"
  },
  {
    "text": "these systems move is at a break neck speed and these assessments can very quickly go stale if it if it's not",
    "start": "930920",
    "end": "936920"
  },
  {
    "text": "correctly updated now the question that it seems very obvious what happens if these",
    "start": "936920",
    "end": "944639"
  },
  {
    "text": "Solutions just do not exist and that is a big reality we need to contend with",
    "start": "944639",
    "end": "949680"
  },
  {
    "text": "and again kudos to uh the Google uh research team who really acknowledged",
    "start": "949680",
    "end": "955199"
  },
  {
    "text": "that hey things like adversarial examples this is is not these defenses are not yet ready for production and",
    "start": "955199",
    "end": "962800"
  },
  {
    "text": "really they come up with a growth mindset and they put this out so what happens when these systems do not have",
    "start": "962800",
    "end": "969720"
  },
  {
    "text": "uh Solutions so that's kind of like you know the second lesson I want you to",
    "start": "969720",
    "end": "975319"
  },
  {
    "text": "take away from this talk you know the language and these standards tend to be really vague and that makes calibrating",
    "start": "975319",
    "end": "981839"
  },
  {
    "text": "trust very difficult so I've been like dancing around the word trust for a little bit",
    "start": "981839",
    "end": "988639"
  },
  {
    "text": "now you know we said we spoke about over trust we spoke about like um why it's difficult but I really want to double",
    "start": "988639",
    "end": "995120"
  },
  {
    "text": "click on the word trust it feels it's like good you know nice feeling and for this I'm going to use",
    "start": "995120",
    "end": "1001839"
  },
  {
    "text": "the definition from NST AI risk management framework which really is being touted as the solution uh for for",
    "start": "1001839",
    "end": "1010639"
  },
  {
    "text": "a whole bunch of reasons and again I don't want to take away that people in N or eui act do not know what they do they",
    "start": "1010639",
    "end": "1016279"
  },
  {
    "text": "are extremely brilliant people these are just externalities of analyzing it and",
    "start": "1016279",
    "end": "1021720"
  },
  {
    "text": "you know they really pack a lot of emotions into trust you know you want the system to be accurate explainable",
    "start": "1021720",
    "end": "1028438"
  },
  {
    "text": "interpretable robust you know bias and it be no harmful use so it becomes this",
    "start": "1028439",
    "end": "1034520"
  },
  {
    "text": "suitcase words for a lot of these ideal properties that we want to kind of achieve and I I want to focus on two",
    "start": "1034520",
    "end": "1042438"
  },
  {
    "text": "specific words here I'm I'm going to pull apart some of these words and look at the interactions um and one of the",
    "start": "1042439",
    "end": "1049360"
  },
  {
    "text": "factor I'm going to look at is robustness which really is a fancy way of saying the property of conferring",
    "start": "1049360",
    "end": "1055280"
  },
  {
    "text": "protection from adversarial manipulation that's what robustness is and you know",
    "start": "1055280",
    "end": "1060760"
  },
  {
    "text": "no talk on adversarial machine learning will be complete without being homage to this classic picture from 2014 this is",
    "start": "1060760",
    "end": "1068799"
  },
  {
    "text": "called an adversarial examples essentially the picture of a panda you know you add this like uh imperceptible",
    "start": "1068799",
    "end": "1076880"
  },
  {
    "text": "uh noise to it and the resulting picture looks just as similar as the first one",
    "start": "1076880",
    "end": "1082240"
  },
  {
    "text": "for humans but unfortunately for machine learning systems that one is very",
    "start": "1082240",
    "end": "1087720"
  },
  {
    "text": "confidently classified as a gibbon the running joke in the ml Community is we don't even know what a gibbon looks like",
    "start": "1087720",
    "end": "1093559"
  },
  {
    "text": "we just assume it looks like a panda at this point so it's a you know it's a classic",
    "start": "1093559",
    "end": "1099480"
  },
  {
    "text": "you know people have a lot of fun with it it's even mentioned in the EU AI act and I want to like bring your attention",
    "start": "1099480",
    "end": "1106520"
  },
  {
    "text": "to how this can have real world implication we've had a lot of talks about like is this attack even relevant",
    "start": "1106520",
    "end": "1112080"
  },
  {
    "text": "and um Vidant uh folks from University of Maryland kind of like had this very interesting study and the the takeaway",
    "start": "1112080",
    "end": "1118919"
  },
  {
    "text": "from this picture is that attacks really do not affect all classes of data points",
    "start": "1118919",
    "end": "1124960"
  },
  {
    "text": "equally so what the researchers did was they built this very apocryphal example you know you're given a face and it",
    "start": "1124960",
    "end": "1130720"
  },
  {
    "text": "predicts like the age of the person from the face and what they did was they launched the very an adversarial example",
    "start": "1130720",
    "end": "1137600"
  },
  {
    "text": "attack on on these like on these systems and that they found that for a black female face the the label changed which",
    "start": "1137600",
    "end": "1146440"
  },
  {
    "text": "means it's uh it's more fallible to the attack but ironically for a white male phas the label was very robust to this",
    "start": "1146440",
    "end": "1153559"
  },
  {
    "text": "attack so takeaway here is that the same amount of perturbation flipped the label",
    "start": "1153559",
    "end": "1159880"
  },
  {
    "text": "for a uh for one class but for another class it was very robust so attacks",
    "start": "1159880",
    "end": "1165080"
  },
  {
    "text": "really do not affect all data points equally interestingly enough um the",
    "start": "1165080",
    "end": "1170880"
  },
  {
    "text": "defenses also do not protect all classes equally and setting this which means",
    "start": "1170880",
    "end": "1176280"
  },
  {
    "text": "that setting the same standard for all of these data points may not really make",
    "start": "1176280",
    "end": "1181679"
  },
  {
    "text": "sense so this is work done from University of like uh Michigan State University and they found that when you",
    "start": "1181679",
    "end": "1188120"
  },
  {
    "text": "try to employ the same defense they found one data set had like 67%",
    "start": "1188120",
    "end": "1193960"
  },
  {
    "text": "robustness accuracy and the other half of the same data set only only had 17%",
    "start": "1193960",
    "end": "1199400"
  },
  {
    "text": "robustness accuracy so that's going to be this like problem where okay you can you can choose to implement a defense",
    "start": "1199400",
    "end": "1206559"
  },
  {
    "text": "but you have to make a choice between what part of your data set you want to protect more and again it goes back to",
    "start": "1206559",
    "end": "1213120"
  },
  {
    "text": "this question of who is making those decisions because it's definitely not the regulators and this kind of opens up",
    "start": "1213120",
    "end": "1219039"
  },
  {
    "text": "a lot of more questions I also want to draw your attention um you know to",
    "start": "1219039",
    "end": "1225000"
  },
  {
    "text": "another another thing which also aeria kind of mentioned and explainability in her keynote and we already saw the",
    "start": "1225000",
    "end": "1231480"
  },
  {
    "text": "robustness and bias there's this tension explainability is a very desirable property if I get my credit denied I",
    "start": "1231480",
    "end": "1238600"
  },
  {
    "text": "want to know like why it was denied uh so now I want to show you like how",
    "start": "1238600",
    "end": "1243679"
  },
  {
    "text": "adding a third Factor like explainability really also complicates the picture here so this is my favorite",
    "start": "1243679",
    "end": "1251960"
  },
  {
    "text": "um experiment that Hima laru from Harvard did so she recruits these like",
    "start": "1251960",
    "end": "1257760"
  },
  {
    "text": "um 40 experts from Harvard Law so think of this as our future policy makers um",
    "start": "1257760",
    "end": "1264640"
  },
  {
    "text": "you know and she says hey I'm I've built this classifier and you know the the aim",
    "start": "1264640",
    "end": "1271039"
  },
  {
    "text": "of the classifier is either to say is either to say you know this person gets bail or this person does not get bail so",
    "start": "1271039",
    "end": "1278000"
  },
  {
    "text": "you give them you give this classifier all the details and the the ml model",
    "start": "1278000",
    "end": "1283240"
  },
  {
    "text": "says Bail no bail that's essentially the prediction task and she asks these like",
    "start": "1283240",
    "end": "1288520"
  },
  {
    "text": "law students uh hey what are the features that the ml system should not focus on and the top features came out",
    "start": "1288520",
    "end": "1295360"
  },
  {
    "text": "like okay you know the fact that somebody should get bail or not should not focus on uh race it should not focus",
    "start": "1295360",
    "end": "1301120"
  },
  {
    "text": "on gender what the ml system should really be looking at is did they app you know did they have prior convictions you",
    "start": "1301120",
    "end": "1307840"
  },
  {
    "text": "know if they had convictions and they failed to appear you know that's what the classifier should focus on so no race no gender we want the classifier to",
    "start": "1307840",
    "end": "1315360"
  },
  {
    "text": "be as objective as possible and these are our desired features so hea and her students is very",
    "start": "1315360",
    "end": "1322600"
  },
  {
    "text": "clever experiment they first construct a completely untrustworthy classifier they",
    "start": "1322600",
    "end": "1328960"
  },
  {
    "text": "build a classifier exactly on this uh things that the the the future policy",
    "start": "1328960",
    "end": "1335880"
  },
  {
    "text": "makers are these Harvard Law experts say no they build a classifier that takes",
    "start": "1335880",
    "end": "1340960"
  },
  {
    "text": "race into account and it can see like if race equals African-American you've already lost at that point so they build",
    "start": "1340960",
    "end": "1347720"
  },
  {
    "text": "this classifier behind the scenes and what they do is they build uh",
    "start": "1347720",
    "end": "1354480"
  },
  {
    "text": "explanation systems for these classifiers which I'll get into and this is like the task that they give to the",
    "start": "1354480",
    "end": "1360159"
  },
  {
    "text": "students they don't she doesn't show the classifier to them she only shows the explanations and she says here are the",
    "start": "1360159",
    "end": "1366919"
  },
  {
    "text": "explanations from three systems and you need to tell me which explanation you trust now remember the the classifier",
    "start": "1366919",
    "end": "1375640"
  },
  {
    "text": "behind completely untrustworthy takes race into account so she gives the",
    "start": "1375640",
    "end": "1381000"
  },
  {
    "text": "students three explanations one that comes straight out of a",
    "start": "1381000",
    "end": "1386559"
  },
  {
    "text": "blackbox one explanation the second explanation kind of uses both you know",
    "start": "1386559",
    "end": "1392120"
  },
  {
    "text": "desired features and undesired featur so it mixes like Rays into the thing so this is like you know her kind of",
    "start": "1392120",
    "end": "1398159"
  },
  {
    "text": "fessing up and the third one she gives an explanation that it only uses desired",
    "start": "1398159",
    "end": "1403880"
  },
  {
    "text": "features she completely hides from these future policy makers that you know race was not even into the",
    "start": "1403880",
    "end": "1410919"
  },
  {
    "text": "classifier again CL the students do not know the classifier they only see the",
    "start": "1410919",
    "end": "1417400"
  },
  {
    "text": "explanations so this is unfortunately your intuition because I put the devil",
    "start": "1417400",
    "end": "1422480"
  },
  {
    "text": "Emoji kind of you know uh she's trying to trick the students of whopping",
    "start": "1422480",
    "end": "1428320"
  },
  {
    "text": "70% of these students pick the uh manipulated misleading explanation so",
    "start": "1428320",
    "end": "1435720"
  },
  {
    "text": "this is kind of very interesting right these misleading you know explanations they they take prohibited features into",
    "start": "1435720",
    "end": "1441840"
  },
  {
    "text": "account they take race they take gender and they can be reconstructed using",
    "start": "1441840",
    "end": "1447200"
  },
  {
    "text": "correlated features like zip code and that's essentially what she's leveraging so now I want you to reflect you know",
    "start": "1447200",
    "end": "1453679"
  },
  {
    "text": "you are getting an explanation from an organization you have no clue about",
    "start": "1453679",
    "end": "1459919"
  },
  {
    "text": "their classifier the only thing that he can judge is based on the explanations and now we know that these explanations",
    "start": "1459919",
    "end": "1467600"
  },
  {
    "text": "can be very easily gained and that has serious ramifications as well explanations is",
    "start": "1467600",
    "end": "1474720"
  },
  {
    "text": "not really our goal we need to have trustworthy explanations and the bigger question that I have is that we saw this",
    "start": "1474720",
    "end": "1482799"
  },
  {
    "text": "tension between oh do I make it more robust do I make it more fair turns out",
    "start": "1482799",
    "end": "1488760"
  },
  {
    "text": "that there's a lot of literature out that not only ask if I make it more",
    "start": "1488760",
    "end": "1494080"
  },
  {
    "text": "robust I make it less explainable if I make it less explainable able I'm showing my hand to adversaries who may",
    "start": "1494080",
    "end": "1501360"
  },
  {
    "text": "potentially want to gain the system so there's this like inherent tension and",
    "start": "1501360",
    "end": "1506720"
  },
  {
    "text": "constructing this ideal AI system is no free lunch and this bring us to like",
    "start": "1506720",
    "end": "1512520"
  },
  {
    "text": "really important questions about trade-offs and it goes back to this like original question around who is making",
    "start": "1512520",
    "end": "1519279"
  },
  {
    "text": "these tradeoffs so keep in mind that there are this like broad sus of tension between",
    "start": "1519279",
    "end": "1526440"
  },
  {
    "text": "the security properties and the other desired properties and I'm going to take us back",
    "start": "1526440",
    "end": "1531919"
  },
  {
    "text": "to our final like you know like big question we've been talking a lot we we spoke about how to calibrate we spoke",
    "start": "1531919",
    "end": "1539240"
  },
  {
    "text": "about like trust we spoke about the Kinks and AI systems but I really want to double click on the word we who is",
    "start": "1539240",
    "end": "1547200"
  },
  {
    "text": "the we over here and for this I'm going to take a look at uh John and I looked",
    "start": "1547200",
    "end": "1553000"
  },
  {
    "text": "at who really responded you know to the nist AI risk risk management framework",
    "start": "1553000",
    "end": "1559159"
  },
  {
    "text": "so they have these like requests for information anybody in the public can virtually go submit you know responses",
    "start": "1559159",
    "end": "1565279"
  },
  {
    "text": "to that and uh they were n just very transparent in publishing also who actually you know",
    "start": "1565279",
    "end": "1572799"
  },
  {
    "text": "responded to their RFI alas you know the the the",
    "start": "1572799",
    "end": "1578279"
  },
  {
    "text": "disappointing thing for me is that um the biggest voices in the room were the",
    "start": "1578279",
    "end": "1584520"
  },
  {
    "text": "tech companies and it always hearkens back for me for uh Julie Cohen's book",
    "start": "1584520",
    "end": "1589960"
  },
  {
    "text": "you know between truth and power she talks about how the legal landscape and all these standards is really constantly",
    "start": "1589960",
    "end": "1597279"
  },
  {
    "text": "stretched and pulled by informational capitalism so it's not these standards are like Divine laws that come from",
    "start": "1597279",
    "end": "1604399"
  },
  {
    "text": "these standard organizations there's an active set of folks who are building it to pull it to their interest and the",
    "start": "1604399",
    "end": "1611080"
  },
  {
    "text": "same kind of concept also applies over here when we think of these AI risk management Frameworks when we think of",
    "start": "1611080",
    "end": "1616600"
  },
  {
    "text": "the EU AI Act we like to think of them as independent Authority making decisions but that's hardly ever the",
    "start": "1616600",
    "end": "1622440"
  },
  {
    "text": "case on the one hand the tech companies which we surveyed in 2020 they are",
    "start": "1622440",
    "end": "1628679"
  },
  {
    "text": "completely unaware of the tools and processes to kind of secure AI systems but they were essentially the loudest",
    "start": "1628679",
    "end": "1635120"
  },
  {
    "text": "voices in the room on the other hand Academia that's exploding with this sort",
    "start": "1635120",
    "end": "1640960"
  },
  {
    "text": "of research they publish two papers every day on this topic since 2016 AR as",
    "start": "1640960",
    "end": "1647960"
  },
  {
    "text": "bursting as it seems they were essentially muted and anytime you think of like standards and certifications the",
    "start": "1647960",
    "end": "1655760"
  },
  {
    "text": "one to benefit the most are going to be unfortunately the Consulting companies",
    "start": "1655760",
    "end": "1661080"
  },
  {
    "text": "and the standard setting organizations themselves and you know let's just take let's have an honest conversation about",
    "start": "1661080",
    "end": "1666720"
  },
  {
    "text": "gdpr you know the US companies essentially spent 8 billion most most of",
    "start": "1666720",
    "end": "1673320"
  },
  {
    "text": "which was actually went to consulting firms and vendors and sometimes it even",
    "start": "1673320",
    "end": "1678480"
  },
  {
    "text": "takes money to go access the standard so you know the the the burn toast example",
    "start": "1678480",
    "end": "1684480"
  },
  {
    "text": "that I had it was actually not from the standard because I had to Pony up like $500 to see it so I just like took one",
    "start": "1684480",
    "end": "1690919"
  },
  {
    "text": "from stock photo that's my that's my reveal over here so even if you want to see a standard and if you want to see",
    "start": "1690919",
    "end": "1697039"
  },
  {
    "text": "how it has been updated you pay for every revision of that so the same will",
    "start": "1697039",
    "end": "1702840"
  },
  {
    "text": "also be applied for AI standards especially by for-profit organizations and I want to ask you the question like",
    "start": "1702840",
    "end": "1709440"
  },
  {
    "text": "how are small businesses which really form the backbone of the AI company what are they going to do about it and how",
    "start": "1709440",
    "end": "1716440"
  },
  {
    "text": "are they going to Bear these costs how are independent researchers are how are they going to be looking at this and",
    "start": "1716440",
    "end": "1721720"
  },
  {
    "text": "what happens when you don't have money to Pony up to consulting firms and lawyers to get",
    "start": "1721720",
    "end": "1728159"
  },
  {
    "text": "certified so you know the I want you to kind of like take away that there's",
    "start": "1728159",
    "end": "1734360"
  },
  {
    "text": "competing interest in in making these AI systems achieve this normative good and",
    "start": "1734360",
    "end": "1741080"
  },
  {
    "text": "it's very difficult for us to actually completely agree even what is normative",
    "start": "1741080",
    "end": "1746720"
  },
  {
    "text": "good in this particular space so I want to Bubble Up I want to you know just like zoom out I know we've",
    "start": "1746720",
    "end": "1753080"
  },
  {
    "text": "been in the weeds uh for you know for for a little while we started off with",
    "start": "1753080",
    "end": "1758440"
  },
  {
    "text": "kind of the seal analogy like you know the UL sticker that you may you will find in these electrical",
    "start": "1758440",
    "end": "1764519"
  },
  {
    "text": "appliances the question that um that really struck for me and John is when was the last time that even check the",
    "start": "1764519",
    "end": "1772279"
  },
  {
    "text": "Seal of every electrical appliances that you bought the Stark reality is that for",
    "start": "1772279",
    "end": "1777600"
  },
  {
    "text": "most people who interact with AI systems they either won't know it's an AI system or they may not even have the means to",
    "start": "1777600",
    "end": "1784840"
  },
  {
    "text": "discover that this what standards the AI system is going to comply with and just take a just you know take a take the",
    "start": "1784840",
    "end": "1791799"
  },
  {
    "text": "example of the fire right if there was a fire and if there was a safety robot are you going to stop and verify that you",
    "start": "1791799",
    "end": "1798080"
  },
  {
    "text": "know that emergency robot was nist AI compliant or the EU AI compliant that's going to be afterwards but at that",
    "start": "1798080",
    "end": "1804240"
  },
  {
    "text": "moment it really does not matter the unfortunate reality for us as consumers",
    "start": "1804240",
    "end": "1809720"
  },
  {
    "text": "is that you simply have to trust that the very people who are building these",
    "start": "1809720",
    "end": "1815080"
  },
  {
    "text": "AI systems are adhering to the letter and spirit of these standards",
    "start": "1815080",
    "end": "1820559"
  },
  {
    "text": "and I want to kind of like give you an example of how things can go wrong if you were to just place this blind Trust",
    "start": "1820559",
    "end": "1828519"
  },
  {
    "text": "um this is like work done by the New York Times and I want to kind of like",
    "start": "1828519",
    "end": "1833720"
  },
  {
    "text": "first preface this by saying that there's already a standard for electronic vehicles in the",
    "start": "1833720",
    "end": "1839960"
  },
  {
    "text": "EU and Reporting from The New York Times has shown that Tesla has repeatedly in",
    "start": "1839960",
    "end": "1846679"
  },
  {
    "text": "the reporting words exaggerated the sophistication of the autopilot and for me that's this the",
    "start": "1846679",
    "end": "1853960"
  },
  {
    "text": "quote that really sticks in that reporting is from Jennifer homady uh the",
    "start": "1853960",
    "end": "1859519"
  },
  {
    "text": "chairwoman of NTSB and she says like where I get concerned is a language used",
    "start": "1859519",
    "end": "1864639"
  },
  {
    "text": "to describe the capabilities of the vehicle and now I wanted to like really Zoom back to the the image of the trust",
    "start": "1864639",
    "end": "1872600"
  },
  {
    "text": "resolution right when research goes dating back to the 1990s that's",
    "start": "1872600",
    "end": "1877760"
  },
  {
    "text": "repeatedly shown that there's a pattern of over trust and AI systems and automation organizations are really",
    "start": "1877760",
    "end": "1885039"
  },
  {
    "text": "building these standards um and contributing to them really have not just a heightened moral and ethical but",
    "start": "1885039",
    "end": "1891799"
  },
  {
    "text": "they have a fiduciary obligation to society to communicate the capabilities of these systems so what this really",
    "start": "1891799",
    "end": "1898200"
  },
  {
    "text": "means is that if you are in an organization you know try to get past people who are the Bluster and ensure",
    "start": "1898200",
    "end": "1905600"
  },
  {
    "text": "that you're really empowering your customers with the right tools for trust resolution and when when we don't do",
    "start": "1905600",
    "end": "1911760"
  },
  {
    "text": "that even with a standard you will see a rise in the amount of of failures this",
    "start": "1911760",
    "end": "1918000"
  },
  {
    "text": "is this is like reporting from Washington Post kind of showing the increased risk so I want to really leave with you",
    "start": "1918000",
    "end": "1926440"
  },
  {
    "text": "all I know you're the brightest Minds over here and you have agency within your organizations if you really if you",
    "start": "1926440",
    "end": "1932919"
  },
  {
    "text": "if you want real change you know it's not going to happen until organizations",
    "start": "1932919",
    "end": "1938480"
  },
  {
    "text": "really act with intention and there's a culture of empathy and I feel that is going to be a big win for these um",
    "start": "1938480",
    "end": "1945960"
  },
  {
    "text": "regulatory lead Bel it may not be in the spirit of the law but it's going to start for forcing people to have these",
    "start": "1945960",
    "end": "1953679"
  },
  {
    "text": "conversations um you know as before uh before I conclude I I really want to",
    "start": "1953679",
    "end": "1959039"
  },
  {
    "text": "thank a whole bunch of people Pat Mika over here hyam Anderson for really",
    "start": "1959039",
    "end": "1964080"
  },
  {
    "text": "helping me through this talk and this this would not be possible without my independent fellowship at UC Berkeley so",
    "start": "1964080",
    "end": "1971639"
  },
  {
    "text": "where you know we encourage to kind of ask these bold questions which may otherwise not be possible really grateful for that that as well so uh you",
    "start": "1971639",
    "end": "1980440"
  },
  {
    "text": "know these are the five lessons that I walked through uh ham and I also wrote a",
    "start": "1980440",
    "end": "1986440"
  },
  {
    "text": "full-fledged book kind of like you know looking at this from various different angles um every scent that goes from",
    "start": "1986440",
    "end": "1993399"
  },
  {
    "text": "this book including our royalties in advance goes to supporting two Charities black and Ai and bountiful children so",
    "start": "1993399",
    "end": "2000760"
  },
  {
    "text": "uh we also always plug our Charities towards the end um that's my contact information and I see almost at time so",
    "start": "2000760",
    "end": "2009360"
  },
  {
    "text": "I'm going to like pause here maybe if you have questions we can we have time for one or two questions over here or",
    "start": "2009360",
    "end": "2014559"
  },
  {
    "text": "else we can uh hang out at the WAP room after this thank you very much really",
    "start": "2014559",
    "end": "2019960"
  },
  {
    "text": "appreciate [Applause] it",
    "start": "2019960",
    "end": "2026440"
  }
]
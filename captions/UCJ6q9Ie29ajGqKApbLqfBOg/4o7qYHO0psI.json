[
  {
    "text": "hello it is a pleasure to be here today and tell you how not to train your hackbot uh there's this topic is very",
    "start": "2679",
    "end": "8639"
  },
  {
    "text": "hot this year uh and we're excited to talk to you about our research on this topic so if you've been paying attention",
    "start": "8639",
    "end": "15120"
  },
  {
    "text": "to the news uh you might have noticed uh that either one of these two things is true uh either Chad gbt has enabled uh",
    "start": "15120",
    "end": "21519"
  },
  {
    "text": "low-skilled actors to do bad stuff or it is totally useless um the truth is somewhere in the middle and we're here",
    "start": "21519",
    "end": "26720"
  },
  {
    "text": "to tell you where that is as an introduction uh my name is Ari Herbert Voss um I'm an llm OG in that",
    "start": "26720",
    "end": "34360"
  },
  {
    "text": "I've been working with llms for the past five years uh I was the first security researcher at openai and I worked on gp3",
    "start": "34360",
    "end": "41039"
  },
  {
    "text": "and on codex with me I've got Shane Caldwell who is also a longtime AI for offense guy we're from run sible which",
    "start": "41039",
    "end": "48719"
  },
  {
    "text": "uh is a place where we build and use models to automate hacker intuition and we're excited to share our research uh",
    "start": "48719",
    "end": "54120"
  },
  {
    "text": "with you here today in this talk uh we're going to be talking through how do large language",
    "start": "54120",
    "end": "59519"
  },
  {
    "text": "models work work with a focus on features and limitations that are relevant to the security domain and we'll also be applying language models",
    "start": "59519",
    "end": "65720"
  },
  {
    "text": "to offensive Security in the context of bug Bounty so what is a GPT well it stands",
    "start": "65720",
    "end": "72080"
  },
  {
    "text": "for a generative train pre-trained transformer and Transformers are large",
    "start": "72080",
    "end": "77320"
  },
  {
    "text": "uh models that are deep learning models originally designed to generate text if you're familiar with using a in the",
    "start": "77320",
    "end": "82680"
  },
  {
    "text": "context of uh information security um you'll probably be familiar with uh the",
    "start": "82680",
    "end": "87920"
  },
  {
    "text": "context of um train tring uh training these models for malare classification as a class example of discriminative",
    "start": "87920",
    "end": "94399"
  },
  {
    "text": "models uh Transformers are different because they generate rather than discriminate uh the samples that you generate from a good model for thinking",
    "start": "94399",
    "end": "100920"
  },
  {
    "text": "about them is as an Adaptive lookup table uh or a compressed representation of the training data that you've been",
    "start": "100920",
    "end": "106320"
  },
  {
    "text": "training on the lookup occurs when you ask the model to predict the next word in a sequence um the first context in",
    "start": "106320",
    "end": "112960"
  },
  {
    "text": "which you might have encountered a Transformers is actually in your phone a keyboard where you type out a sentence and then it spits out some word that it",
    "start": "112960",
    "end": "118960"
  },
  {
    "text": "assumes you want to uh type next when we say words uh we actually",
    "start": "118960",
    "end": "124680"
  },
  {
    "text": "referring to tokens uh which are integers that represent parts of words um llms are just fancy lookup tables for",
    "start": "124680",
    "end": "131120"
  },
  {
    "text": "the tokens and during training that's when we're building this this lookup table uh we create this table by",
    "start": "131120",
    "end": "137040"
  },
  {
    "text": "creating Dynamic key value pairs for each input token by generating these key query and value tokens um vectors um for",
    "start": "137040",
    "end": "144120"
  },
  {
    "text": "every position in the input token sequence uh the uh we then compute the similarity between these vectors um and",
    "start": "144120",
    "end": "150519"
  },
  {
    "text": "this is how you get the attention weights so if you've heard people talk about downloading the Llama weights for example these are the weights that we're",
    "start": "150519",
    "end": "156000"
  },
  {
    "text": "talking about you can think about the weights as being a compressed representation of input data that we then sample from in order to complete an",
    "start": "156000",
    "end": "163080"
  },
  {
    "text": "input sequence so how do you get from building a lookup table to solving math equations",
    "start": "163080",
    "end": "170200"
  },
  {
    "text": "and other Advanced reasoning capabilities you might be thinking are surely there's more going on here than simply predicting the next word in a",
    "start": "170200",
    "end": "176200"
  },
  {
    "text": "sequence but no like that's really all it is uh broadly speaking uh this",
    "start": "176200",
    "end": "181360"
  },
  {
    "text": "particular Paradigm is called fuse shot learning and it's called fuse shot because you don't really need a lot of examples uh you start with a base model",
    "start": "181360",
    "end": "188159"
  },
  {
    "text": "you give it a few examples through an input sequence uh and then you asked to predict the next token as an output",
    "start": "188159",
    "end": "193360"
  },
  {
    "text": "sequence so we got an example here of a sentence that says translate from hex to desk to a to what and we're going to",
    "start": "193360",
    "end": "199920"
  },
  {
    "text": "predict what uh so uh it's been colorized because it's been tokenized so you can see these little integer numbers",
    "start": "199920",
    "end": "205799"
  },
  {
    "text": "underneath each one of these things those are the tokens that we're talking about so for humans uh throughout our",
    "start": "205799",
    "end": "211640"
  },
  {
    "text": "lifetime we've seen enough data uh to learn how to read and make connections between Concepts uh so somebody can ask",
    "start": "211640",
    "end": "216879"
  },
  {
    "text": "you a question like perform a mathematical calculation and using what you know about the meaning of translate",
    "start": "216879",
    "end": "222519"
  },
  {
    "text": "hex and Des you can infer that you need to transform one sequence into another sequence um I didn't need to tell you",
    "start": "222519",
    "end": "228519"
  },
  {
    "text": "mathematically which operations to do because you already have enough information implicitly because you've been looking at this kind of stuff for a long time as hackers we've seen enough",
    "start": "228519",
    "end": "235519"
  },
  {
    "text": "examples of hexadecimal and read enough Hitchhikers Guide to the Galaxy to know that 2 a translates to 42 in",
    "start": "235519",
    "end": "243760"
  },
  {
    "text": "decimal if you've heard of prompting in llm uh this is what few shot learning is um it's also called in context learning",
    "start": "244000",
    "end": "250280"
  },
  {
    "text": "you provide the model with a pattern of text that You' like it to complete uh and then you ask it to then generate some",
    "start": "250280",
    "end": "255639"
  },
  {
    "text": "text this uh little red window here is what we call the context window which is where you shove the text uh that you'd",
    "start": "255639",
    "end": "261680"
  },
  {
    "text": "like the model to complete you can put anything in here um and if the model has seen a similar pattern then uh usually",
    "start": "261680",
    "end": "266759"
  },
  {
    "text": "it'll complete something that's very similar a good examp example of this is with the ubiquitous chat uh interfaces",
    "start": "266759",
    "end": "273639"
  },
  {
    "text": "um chat interfaces are built by loading up a script between a user and an assistant uh and then asking the model",
    "start": "273639",
    "end": "279320"
  },
  {
    "text": "to then just compl continue that play generating and completion involves the model mimicking how it has seen similar",
    "start": "279320",
    "end": "285120"
  },
  {
    "text": "scripts play out um and later in the talk we'll talk about how when you craft prompts um that has a significant impact",
    "start": "285120",
    "end": "291039"
  },
  {
    "text": "on what you can get models to do it's worth also talking about context",
    "start": "291039",
    "end": "296840"
  },
  {
    "text": "windows in a little bit more detail so if you're going to be doing some prompt engineering it's also good to know how much you can actually shove into that",
    "start": "296840",
    "end": "302440"
  },
  {
    "text": "context window uh you don't want to be in a position where you've run over the token limit and are expecting the model to use information that it doesn't",
    "start": "302440",
    "end": "308880"
  },
  {
    "text": "actually have so we've seen um over the last like two years or so that context Windows have gotten much bigger so",
    "start": "308880",
    "end": "315240"
  },
  {
    "text": "looking at GP 3.5 and comparing it to gp4 uh you see a context window growth uh from 2K to 32k and then in the case",
    "start": "315240",
    "end": "322280"
  },
  {
    "text": "of CLA anthropics model um you go from 4K to 100K uh and even in the context of some of these open source models that",
    "start": "322280",
    "end": "328520"
  },
  {
    "text": "we're seeing more fre um we're going from 2 to 4K which for an open source model is actually reasonably",
    "start": "328520",
    "end": "335360"
  },
  {
    "text": "significant you might be thinking uh well infinite context window sounds great um like you can just you know put",
    "start": "335360",
    "end": "342759"
  },
  {
    "text": "everything in it and then ask it a bunch of questions and it'll answer everything for you which uh unfortunately there is no free lunch there never is in machine",
    "start": "342759",
    "end": "348840"
  },
  {
    "text": "learning um so in the context of long context uh",
    "start": "348840",
    "end": "354840"
  },
  {
    "text": "there's just more to forget so there are also these Primacy and recency effects that you also see uh in human memory so",
    "start": "354840",
    "end": "361680"
  },
  {
    "text": "I here I've got a screenshot of a paper that came out about two months ago where um they took the GPD 3.5 turbo models",
    "start": "361680",
    "end": "369080"
  },
  {
    "text": "and they shoved a bunch of documents into it and then they ran some experiments to see how easy it was to extract certain things from certain",
    "start": "369080",
    "end": "374800"
  },
  {
    "text": "parts of the context and as you can see at the first part of the context uh it does a reasonably good job of extracting",
    "start": "374800",
    "end": "380520"
  },
  {
    "text": "stuff uh or returning things that are what uh the uh researchers asked for um",
    "start": "380520",
    "end": "386000"
  },
  {
    "text": "and then for the latter part of the context you can see it also kind of does the same thing but in the middle it just it doesn't perform very well at",
    "start": "386000",
    "end": "392560"
  },
  {
    "text": "all so what do you do when uh you have too much data and can't actually fit in",
    "start": "392639",
    "end": "397759"
  },
  {
    "text": "like a prompt context window well there's a couple things so the most obvious thing of course is to use the biggest model but think uh clearly about",
    "start": "397759",
    "end": "405199"
  },
  {
    "text": "um what is it that's going to be in the middle of the context versus like the first and the last part the second thing",
    "start": "405199",
    "end": "410720"
  },
  {
    "text": "um which I'm a big fan of is using Vector databases where you can embed all the documents that you're planning on uh",
    "start": "410720",
    "end": "416520"
  },
  {
    "text": "searching over or or using in some sort of context uh and then you just do a vector search and find the closest entries uh that are",
    "start": "416520",
    "end": "423479"
  },
  {
    "text": "relevant to what your Cy is and then just shove those into the context and then it usually improves your performance um you can also in the same",
    "start": "423479",
    "end": "429520"
  },
  {
    "text": "vein use a search engine for this information retrieval task where you just simply have the model use a search",
    "start": "429520",
    "end": "435000"
  },
  {
    "text": "engine as a tool um call out to that search engine grab the information you need and then just shove it back in the",
    "start": "435000",
    "end": "441720"
  },
  {
    "text": "context over time uh we've seen everything get better uh not just context windows so here we have a handy",
    "start": "442440",
    "end": "448759"
  },
  {
    "text": "guide for the publicly disclosed parameter sizes um llm performance uh improves smoothly as we increase the",
    "start": "448759",
    "end": "454759"
  },
  {
    "text": "model size data set size and compute used uh for training and we call this the scaling laws so they're the",
    "start": "454759",
    "end": "460680"
  },
  {
    "text": "empirical governing principles for performance and for Optimal Performance all these things need to be dialed in I",
    "start": "460680",
    "end": "465800"
  },
  {
    "text": "will also note that parameter count has turned out to be more complicated than simply more equals better and there are some tuning tricks you can do to get uh",
    "start": "465800",
    "end": "472479"
  },
  {
    "text": "similar performance out of uh smaller parameter models um just by doing some crazy training things so those things",
    "start": "472479",
    "end": "479479"
  },
  {
    "text": "being um first off there are three ways in which you can get information into a language model first of course being",
    "start": "479479",
    "end": "484840"
  },
  {
    "text": "pre-training where you're just training your own model from scratch um second being fine-tuning where you take",
    "start": "484840",
    "end": "490120"
  },
  {
    "text": "somebody else's weights and then you take your own proprietary data set You fine-tune by or you you train on that",
    "start": "490120",
    "end": "497360"
  },
  {
    "text": "same data set with the same weights that you've got and then it just injects uh the information from that training set into the model and then the Third Way",
    "start": "497360",
    "end": "504120"
  },
  {
    "text": "which is the sexiest way and the way that um a lot of interesting things have been coming about now is with",
    "start": "504120",
    "end": "509319"
  },
  {
    "text": "reinforcement learning with human feedback uh which is roughly speaking uh you train a second model to recognize",
    "start": "509319",
    "end": "515120"
  },
  {
    "text": "when an answer is good uh or bad and then use that as a learning signal to improve the base model performance so if",
    "start": "515120",
    "end": "521320"
  },
  {
    "text": "you've used chat GPT you'll notice that it feels like you're talking to an agent more so than some of the other models this is because it's what we call an if",
    "start": "521320",
    "end": "527640"
  },
  {
    "text": "model or an instruction following model uh which means that it's been tuned via rhf to have responses that mimic a",
    "start": "527640",
    "end": "533959"
  },
  {
    "text": "conversation script and the model has been given enough examples of what a good conversation script looks like that it uh has has a good sense of like what",
    "start": "533959",
    "end": "540959"
  },
  {
    "text": "the responses should look like when you asking questions so now that we've got a sense",
    "start": "540959",
    "end": "546279"
  },
  {
    "text": "of how llms work uh let's answer this following question and when you see a titilating headline like this you just know the",
    "start": "546279",
    "end": "552040"
  },
  {
    "text": "answer is no so let's go through why not so there are three core roadblocks",
    "start": "552040",
    "end": "559519"
  },
  {
    "text": "in AI development uh that need to be overcome for this to be a real concern so there statefulness hallucination and",
    "start": "559519",
    "end": "566680"
  },
  {
    "text": "contamination statefulness refers to the ability to store and run things on program States so llms use large amounts",
    "start": "566680",
    "end": "572959"
  },
  {
    "text": "of data to predict the next token of sequence it's all they're doing uh there are promising advances with the information retrieval stuff but it's",
    "start": "572959",
    "end": "579320"
  },
  {
    "text": "meant to augment the sequence prediction accuracy rather than to replace the Paradigm entirely uh memory corruption",
    "start": "579320",
    "end": "585279"
  },
  {
    "text": "issues are the root cause for roughly 70% of vulnerabilities and this is stuff like use after freeze buffer overflows",
    "start": "585279",
    "end": "590760"
  },
  {
    "text": "race conditions all things that um in order to exploit you need to know something about the program State uh on",
    "start": "590760",
    "end": "597160"
  },
  {
    "text": "the machine and then and be able to use it but llms don't have memory so they're not really capable of doing that a great",
    "start": "597160",
    "end": "604320"
  },
  {
    "text": "example of llm struggling with this stapl this problem is actually with Mark Dow's crack Adder overflow bug um so I'm",
    "start": "604320",
    "end": "610360"
  },
  {
    "text": "not going to go through this in detail but this is how's reimplementation of the bug uh in this tiny little window here um the high level overview is that",
    "start": "610360",
    "end": "618360"
  },
  {
    "text": "the code contains an implicit State machine with at least eight different possible paths and that requires looping",
    "start": "618360",
    "end": "623760"
  },
  {
    "text": "nine times to get to an invalid State uh this means that in order for an llm to find this problem it would need to be able to model what is happening as",
    "start": "623760",
    "end": "630160"
  },
  {
    "text": "variables update through the program flow but models they don't run code and they're not tracking variables they are",
    "start": "630160",
    "end": "635839"
  },
  {
    "text": "just predicting the next token so the pattern might exist in the training data set but that doesn't mean that it's",
    "start": "635839",
    "end": "641240"
  },
  {
    "text": "going to be able to actually find vulnerabilities around this kind of stuff the second thing being uh for why",
    "start": "641240",
    "end": "649480"
  },
  {
    "text": "gpds suck at being vulnerability Hunters is the hallucination problem which if you're if you've been playing with these",
    "start": "649480",
    "end": "654639"
  },
  {
    "text": "models you're familiar with like sometimes it'll just spit stuff out that's not actually true um hallucinations are predictions that",
    "start": "654639",
    "end": "660279"
  },
  {
    "text": "appear correct at first but are factually incorrect or are entirely incoherent um making up fake logic or",
    "start": "660279",
    "end": "666920"
  },
  {
    "text": "design flaws isn't useful for vulnerability Discovery it could be useful for things like generating fuzz",
    "start": "666920",
    "end": "671959"
  },
  {
    "text": "harnesses and stuff like that but for the actual vulnerability finding step it's a direct hindrance um in many of",
    "start": "671959",
    "end": "677720"
  },
  {
    "text": "our experiments adapting LMS to find vulnerabilities for source code we found it was common for the model to hallucinate variables that just didn't",
    "start": "677720",
    "end": "683279"
  },
  {
    "text": "exist which means you'd have to go through and figure out like which of these things are real which ones are not and so if you're already in in the weeds",
    "start": "683279",
    "end": "689399"
  },
  {
    "text": "with a piece of code trying to find something having to then double check what your tool is telling you to make sure that it's not just lying to you",
    "start": "689399",
    "end": "694800"
  },
  {
    "text": "adds additional cognitive load and it just it becomes a nonstarter the third thing that would",
    "start": "694800",
    "end": "701120"
  },
  {
    "text": "need to be overcome for llms to be good at ADV hunting is this contamination issue so contamination refers to the",
    "start": "701120",
    "end": "707560"
  },
  {
    "text": "training set containing examples of the thing on which we were evaluating uh so somebody had chat TPT take the bar exam",
    "start": "707560",
    "end": "714360"
  },
  {
    "text": "uh fun fact the bar exam questions are in fact in the training data set so no surprise it actually does pretty well",
    "start": "714360",
    "end": "720200"
  },
  {
    "text": "but turns out when you uh adjust the questions just a little bit um it just the performance drops pretty",
    "start": "720200",
    "end": "726279"
  },
  {
    "text": "significantly and guess what most llm training sets include in terms of code like because of",
    "start": "726279",
    "end": "732000"
  },
  {
    "text": "GitHub they contain bug reports they contain poc's it contains tool code um this uh this is actually pretty good for",
    "start": "732000",
    "end": "739160"
  },
  {
    "text": "stuff like pattern matching for existing vulnerabilities like there are actually some pretty cool uses of llms for code analysis and I'm reasonably optimistic",
    "start": "739160",
    "end": "745760"
  },
  {
    "text": "that some parts of the process uh for doing analysis can be automated but it's it's not an end to-end thing um it",
    "start": "745760",
    "end": "751760"
  },
  {
    "text": "doesn't help with finding things that are out of distribution and contamination actually makes it really difficult to evaluate the baselight",
    "start": "751760",
    "end": "757440"
  },
  {
    "text": "capabilities in general um so if you're an mlog you're familiar with the rule that you can't test on training data uh",
    "start": "757440",
    "end": "763720"
  },
  {
    "text": "but this is extremely difficult with Transformers because um as I mentioned with the chunk chart uh more data more",
    "start": "763720",
    "end": "770800"
  },
  {
    "text": "parameters everything uh you get better and better performance when you have more data so there's a direct perverse",
    "start": "770800",
    "end": "775880"
  },
  {
    "text": "incentive here to train on as much as possible which also includes things that you you might want to be evaluating on if you feed the crackout",
    "start": "775880",
    "end": "782800"
  },
  {
    "text": "vulnerability to chat GPT it can parot some issues back at you because there are some writeups in the training set",
    "start": "782800",
    "end": "787880"
  },
  {
    "text": "for like how you would find this vulnerability but when you start probing it it just immediately it almost immediately Falls over um the fact that",
    "start": "787880",
    "end": "794440"
  },
  {
    "text": "there are some um I mean the this behavior is explained by the fact that there are uh some things in in the",
    "start": "794440",
    "end": "800320"
  },
  {
    "text": "training set around that so if you're looking for the ultimate OD finder llms alone aren't it",
    "start": "800320",
    "end": "807600"
  },
  {
    "text": "um the LMS with a little bit extra like a little bit more information retrieval code use some of the other things we're",
    "start": "807600",
    "end": "813519"
  },
  {
    "text": "going to talk about um get a little bit closer to the mark But the research still just isn't mature enough to panic",
    "start": "813519",
    "end": "818720"
  },
  {
    "text": "um we've seen a hit rate of about two out of six on finding some never-before seen vulnerability examples using just",
    "start": "818720",
    "end": "823959"
  },
  {
    "text": "these bog standard llm apis uh which frankly is terrible um but it's",
    "start": "823959",
    "end": "829199"
  },
  {
    "text": "impressive that an LM can do something like that at all uh but it's it's key to keep in mind that LMS are fundamentally",
    "start": "829199",
    "end": "834360"
  },
  {
    "text": "pattern matching and they're just generating text based off of these patterns uh and many vulnerabilities are are themselves just patterns of existing",
    "start": "834360",
    "end": "840600"
  },
  {
    "text": "vulnerabilities so I mean also if anything uh OD I think more OD will be created from GPT than discovered just",
    "start": "840600",
    "end": "847360"
  },
  {
    "text": "given how many developers lead on these code synthesis tools in the first place um and uh just because lm's suck at",
    "start": "847360",
    "end": "853519"
  },
  {
    "text": "finding OD and source code doesn't mean that they're going to suck at everything related to offense like there there are many different things that you can do um",
    "start": "853519",
    "end": "859360"
  },
  {
    "text": "with llms and uh Shane is going to talk about what they're useful for using bug Bounty as a proof Point all right so",
    "start": "859360",
    "end": "865600"
  },
  {
    "text": "your job is safe but you might have a new employee let's talk about uh so if you do this for a living you",
    "start": "865600",
    "end": "873000"
  },
  {
    "text": "look at a lot of text uh particularly if you're in web right Minify JavaScript",
    "start": "873000",
    "end": "878160"
  },
  {
    "text": "that you can't read HTML and HTTP filling up your birth state and scans feeding into scans feeding into yet more",
    "start": "878160",
    "end": "884240"
  },
  {
    "text": "scans and your only tool is the humble regular expression often as much of a",
    "start": "884240",
    "end": "889519"
  },
  {
    "text": "hindrance as a help but the foundation of our detection engineering right so how do you know if you found a vulnerability the regular expression",
    "start": "889519",
    "end": "895560"
  },
  {
    "text": "tells you how do you get one tool to feed into another regular expression tells you but it lacks a certain expressiveness so we're going to talk",
    "start": "895560",
    "end": "901480"
  },
  {
    "text": "about how we can use the capabilities of language models to sort of expand upon uh past what regular Expressions can",
    "start": "901480",
    "end": "907320"
  },
  {
    "text": "sort of provide let's talk about scoping I don't know how to say this guy's at but I wanted to shout him out uh because",
    "start": "907320",
    "end": "913399"
  },
  {
    "text": "he makes machine readable asset scopes for bounties uh which makes hackers happy so he goes through and runs a",
    "start": "913399",
    "end": "919160"
  },
  {
    "text": "crawler he runs it every like hour uh through all the major bug Bounty platforms and spits all of those IPS and",
    "start": "919160",
    "end": "925600"
  },
  {
    "text": "host names out into a nice Json file that I can just push through the rest of my sort of Recon tooling that's great uh",
    "start": "925600",
    "end": "932160"
  },
  {
    "text": "but vulnerability scope not so clear what bug will be taken by what program so let's say I want to hunt for",
    "start": "932160",
    "end": "937600"
  },
  {
    "text": "cross-site request forgery I just listened to a new podcast episode there's some new technique I want to try",
    "start": "937600",
    "end": "942720"
  },
  {
    "text": "who's available right uh I have to read all of this and all the time I'm reading",
    "start": "942720",
    "end": "948440"
  },
  {
    "text": "this stuff I'm not I'm not finding any bugs I'm not doing any hacking not making any money so how would you use a",
    "start": "948440",
    "end": "954959"
  },
  {
    "text": "language model to sort of help you sort of read this stuff and find the answer to the question is this in scope or not",
    "start": "954959",
    "end": "960519"
  },
  {
    "text": "so again Ari was talking about what if the these policy documents that like hacker one rights very long very long",
    "start": "960519",
    "end": "965759"
  },
  {
    "text": "how are we going to fit this into a prompt right uh so we can take that large document and we can break it up into subdocuments so if it's you know",
    "start": "965759",
    "end": "972759"
  },
  {
    "text": "20,000 tokens maybe I break it up into 500 token bits um when I ask you a",
    "start": "972759",
    "end": "977920"
  },
  {
    "text": "question like what's the most recent book you just read and what's the plot you don't fit the whole book into your",
    "start": "977920",
    "end": "983440"
  },
  {
    "text": "working memory right you fit what is relevant to answer my question your answer based on that we want to be able",
    "start": "983440",
    "end": "988959"
  },
  {
    "text": "to put what is relevant in the working memory of the language model so that's what information retrieval is for right",
    "start": "988959",
    "end": "994199"
  },
  {
    "text": "given a query we're interested in find me the most relevant subdocument and give it to the language model let's look",
    "start": "994199",
    "end": "1000639"
  },
  {
    "text": "at an example so we have a prompt here uh you are a helpful boundy triage assistant scope context comes from the",
    "start": "1000639",
    "end": "1006639"
  },
  {
    "text": "Bounty policy scope it's going to be our subdocument determine if testing for the given vulnerability is in scope or not",
    "start": "1006639",
    "end": "1012240"
  },
  {
    "text": "the vulnerability in scope and your answer true if not answer false this is so when we program around what comes out",
    "start": "1012240",
    "end": "1018759"
  },
  {
    "text": "of the language model we can write things in Python like if true in response and sort of have some automation strung up around this uh then",
    "start": "1018759",
    "end": "1025918"
  },
  {
    "text": "we have the scope context that's going to be our information retrieval and the vulnerability that's the thing I want to know if it's in scope or not let's see",
    "start": "1025919",
    "end": "1032839"
  },
  {
    "text": "an example so this is Tesla's policy page here uh again our question was cross site request forgery so this was",
    "start": "1032839",
    "end": "1039438"
  },
  {
    "text": "an interesting case uh the broader subdocument here uh is referring to uh",
    "start": "1039439",
    "end": "1044959"
  },
  {
    "text": "vulnerabilities that are out of scope right but the language model is capable of reading this somewhat carefully it is",
    "start": "1044959",
    "end": "1050480"
  },
  {
    "text": "in scope as long as it impacts Integrity as long as there's an impact so it figures that out and it correctly",
    "start": "1050480",
    "end": "1056200"
  },
  {
    "text": "answers yep you're you're in scope go ahead so it worked how often does it",
    "start": "1056200",
    "end": "1061919"
  },
  {
    "text": "work that's a great question uh if anyone ever tells you with the capabilities of the language modelar but can't tell you how often they work you",
    "start": "1061919",
    "end": "1067440"
  },
  {
    "text": "should talk to somebody else uh so if you write tests for normal software you know you go through all like The Logical",
    "start": "1067440",
    "end": "1073600"
  },
  {
    "text": "cases you might expect to find and if they all work thumbs up you guys don't write tests but if if you did that's",
    "start": "1073600",
    "end": "1078880"
  },
  {
    "text": "what it would look like uh language models and other probabilistic functions are a little different so we like to",
    "start": "1078880",
    "end": "1084080"
  },
  {
    "text": "look at different cases uh as like data points so we try to collect things we expect to see at inference time or in",
    "start": "1084080",
    "end": "1090559"
  },
  {
    "text": "production and we sort of hand label these and be like we'd like to see this if you got a we' like to see this we got",
    "start": "1090559",
    "end": "1096080"
  },
  {
    "text": "B and then we evaluate the language model on this task and say it's like 70% 80% you know these these kinds of things",
    "start": "1096080",
    "end": "1103480"
  },
  {
    "text": "uh so we did the same thing we collected 30 of these Scopes we hand labeled correctness for various tasks",
    "start": "1103480",
    "end": "1108960"
  },
  {
    "text": "and we set several language models sort of against each other to see if they could correctly determine if something was in an onos scope now this looks bad",
    "start": "1108960",
    "end": "1115520"
  },
  {
    "text": "on Claude Claude did just fine uh claude's problem was not answering true or false in the way that we wanted to so",
    "start": "1115520",
    "end": "1121919"
  },
  {
    "text": "he sort of dropped out of the running altogether uh gbt 4 was actually pretty good A little over 70% at parsing the",
    "start": "1121919",
    "end": "1128799"
  },
  {
    "text": "sort of correct intent of the policy document as we read it uh so not 100%",
    "start": "1128799",
    "end": "1134640"
  },
  {
    "text": "but also not bad on to Recon uh so we like to do Recon the more obscure Recon",
    "start": "1134640",
    "end": "1140640"
  },
  {
    "text": "you do the more information you have that your sort of fellow bounty hunters don't the more likely you're to find a",
    "start": "1140640",
    "end": "1145760"
  },
  {
    "text": "strange asset make money uh so as a way to do that a lot of people recommend you",
    "start": "1145760",
    "end": "1150919"
  },
  {
    "text": "should red disclosed Bounty reports in the program there are a lot of reasons that make sense they let you know what",
    "start": "1150919",
    "end": "1156039"
  },
  {
    "text": "the platform sort of values so are they into the kind of bugs you want to hack on what kind of Technology do they use",
    "start": "1156039",
    "end": "1161640"
  },
  {
    "text": "is the kind of Technology know anything about what kind of programming errors do they tend to make that's useful information but it's also a lot of",
    "start": "1161640",
    "end": "1168360"
  },
  {
    "text": "reading and that is work you are doing for free so can you can you get the",
    "start": "1168360",
    "end": "1173799"
  },
  {
    "text": "information without spending all your time becoming a Recon dragon that just collects the stuff and doesn't actually haunt bugs uh so people have done this",
    "start": "1173799",
    "end": "1181400"
  },
  {
    "text": "sort of statistical analysis of uh sort of vulnerability information in the past Jason hadex did with hunt um so let's",
    "start": "1181400",
    "end": "1188280"
  },
  {
    "text": "say we wanted to answer a very simple question I have a bunch of bug Bounty reports I want to extract the vulnerability name from each of them so",
    "start": "1188280",
    "end": "1195400"
  },
  {
    "text": "I know like what shows up the most frequently uh in this program uh information retrieval like we just saw",
    "start": "1195400",
    "end": "1201600"
  },
  {
    "text": "is a way to do it uh but there are some problems with that right how many ways have you seen someone write cql injection uh I've seen a bunch and",
    "start": "1201600",
    "end": "1208600"
  },
  {
    "text": "hackers tend to not be into the standardization thing so if I just extract the answer it's not going to I",
    "start": "1208600",
    "end": "1213919"
  },
  {
    "text": "can't even count them right uh because there'll be all these duplicates so how would I handle that uh",
    "start": "1213919",
    "end": "1220360"
  },
  {
    "text": "we're going to look at a prompt use the following pieces of context to answer the question at the end the context would part of a bug Bounty report your",
    "start": "1220360",
    "end": "1226480"
  },
  {
    "text": "job is based on the context to determine what vulnerability is being discussed in the report that's information reteval",
    "start": "1226480",
    "end": "1231760"
  },
  {
    "text": "section uh based on a list of possible vs if you do not have enough information answer I don't know so for the possible",
    "start": "1231760",
    "end": "1238440"
  },
  {
    "text": "VES you essentially give a multiple choice list of options for the model to select you are not guaranteeing that the",
    "start": "1238440",
    "end": "1244159"
  },
  {
    "text": "model will select one of those options but you're putting a hefty inductive bias that that's going to be its answer which is going to make it easier for you",
    "start": "1244159",
    "end": "1250280"
  },
  {
    "text": "to get the data out in the form you want and do some sort of Downstream analysis you're also providing this I don't know",
    "start": "1250280",
    "end": "1255400"
  },
  {
    "text": "option so you get an offramp as well if the model is maybe not so sure so we tested this similar thing",
    "start": "1255400",
    "end": "1262240"
  },
  {
    "text": "collected 30 sort of uh activity reports and sort of hand labeled them uh gbt 3.5",
    "start": "1262240",
    "end": "1267880"
  },
  {
    "text": "turbo took it away here which is a little surprising uh and it it took it away because it was more willing seemingly to answer I don't know uh now",
    "start": "1267880",
    "end": "1275520"
  },
  {
    "text": "I wouldn't which is good I wouldn't generalize too far based off these results again like 30 30 hand labeled uh",
    "start": "1275520",
    "end": "1282240"
  },
  {
    "text": "I'd like 30,000 but it's a good general idea of how you can actually measure these capabilities when you're like oh a",
    "start": "1282240",
    "end": "1288360"
  },
  {
    "text": "model can do x uh hacker one seems to think this is a good idea so this is uh",
    "start": "1288360",
    "end": "1293880"
  },
  {
    "text": "they sort of released this feature uh in the midst of our research where you can do activity searching off cves and cwes",
    "start": "1293880",
    "end": "1300600"
  },
  {
    "text": "which is great uh but why restrict yourself to those right anything you could extract from these documents you",
    "start": "1300600",
    "end": "1306120"
  },
  {
    "text": "could use for your own search tools and if it's uh an information source that no one else has that's uh that could be",
    "start": "1306120",
    "end": "1311679"
  },
  {
    "text": "useful to you as a bounty hunter on to application analysis so so far you're",
    "start": "1311679",
    "end": "1317000"
  },
  {
    "text": "looking at me and you're like so it's like smart GP huh that's all that's all that is uh it's not really",
    "start": "1317000",
    "end": "1322559"
  },
  {
    "text": "going to help me hack right it it might help me process text better read faster",
    "start": "1322559",
    "end": "1327640"
  },
  {
    "text": "but what else can it do let's do something a little more nuanced and a little more relevant to the hacker workflow so I was watching naham con",
    "start": "1327640",
    "end": "1334760"
  },
  {
    "text": "this year super cool uh Arch Angel D-Day was on great hacker he was talking about his process for finding bugs and he he",
    "start": "1334760",
    "end": "1340960"
  },
  {
    "text": "calls it finding the nose so reading the uh API documentation looking through the",
    "start": "1340960",
    "end": "1346240"
  },
  {
    "text": "the sort of uh asset and figuring out what does this not want me to do and as",
    "start": "1346240",
    "end": "1351400"
  },
  {
    "text": "soon as you know that that's what you go try to do right you sort of reverse engineer your threat model that way so",
    "start": "1351400",
    "end": "1356600"
  },
  {
    "text": "can we use language models to read this documentation the same way we would and get a similar sort of intuitive sense of",
    "start": "1356600",
    "end": "1362720"
  },
  {
    "text": "like oh this is what smells fishy so what we do here is uh we have",
    "start": "1362720",
    "end": "1367840"
  },
  {
    "text": "another prompt you're an AI specialized in providing security QA uh this is trying to get around those uh",
    "start": "1367840",
    "end": "1373320"
  },
  {
    "text": "restrictions uh for open API Json documentation the user interacting with you will provide the string of of the API documentation you will provide the",
    "start": "1373320",
    "end": "1380080"
  },
  {
    "text": "host path and method of any API calls that likely include private data format your response as Json so there are a",
    "start": "1380080",
    "end": "1386600"
  },
  {
    "text": "couple things going on here first there's this uh this inherent for loop we're asking for right go through every",
    "start": "1386600",
    "end": "1391679"
  },
  {
    "text": "part of this data this big Json we put in here and then we're asking for this named entity extraction so I want the",
    "start": "1391679",
    "end": "1397039"
  },
  {
    "text": "host the path and the method of each of these and there's this implicit classification so if you output this it",
    "start": "1397039",
    "end": "1402400"
  },
  {
    "text": "means you've decided that it seems like there's private data behind this route and then finally we ask it for the Json",
    "start": "1402400",
    "end": "1407480"
  },
  {
    "text": "dictionary so we can program again Downstream of this uh language model call then we give it the uh the open API",
    "start": "1407480",
    "end": "1414320"
  },
  {
    "text": "Json so we went on apis. Guru we pulled down like 30 of these this was the most",
    "start": "1414320",
    "end": "1419360"
  },
  {
    "text": "interesting thing to hand label for evaluation because it's like we're just sort of it's our hacker intuition right",
    "start": "1419360",
    "end": "1424720"
  },
  {
    "text": "we're like this seems like a good thing there would be private data behind uh but not all these are uh public apis are",
    "start": "1424720",
    "end": "1432039"
  },
  {
    "text": "in scope for hacking so we certainly didn't do anything malicious um this was an interesting one the language model",
    "start": "1432039",
    "end": "1439200"
  },
  {
    "text": "was actually pretty good at reading these so it it tended to agree with our definition of what seemed to have",
    "start": "1439200",
    "end": "1444559"
  },
  {
    "text": "private data behind it now keep in mind 100% means 100% out of 30 not 100% in",
    "start": "1444559",
    "end": "1449919"
  },
  {
    "text": "your life but it was generally pretty impressive performance no we had to use the large uh context sizes to fit the",
    "start": "1449919",
    "end": "1456159"
  },
  {
    "text": "entire document in at once on to reporting so uh the vast",
    "start": "1456159",
    "end": "1461360"
  },
  {
    "text": "majority of reports I hope this isn't a secret to anyone here are uh heavily templated right you don't write what a",
    "start": "1461360",
    "end": "1468080"
  },
  {
    "text": "cross-site scripting vulnerability is every time you sit down uh not in Consulting certainly not in bounties but",
    "start": "1468080",
    "end": "1474000"
  },
  {
    "text": "there are sections that you can't really template so the sections that count what is the specific context of this bug how",
    "start": "1474000",
    "end": "1480399"
  },
  {
    "text": "do you find it and why does it matter these are the things that decide whether you actually help secure a platform uh",
    "start": "1480399",
    "end": "1486360"
  },
  {
    "text": "they help decide whether you actually get paid and it's a lot of manual work I think it is natural to think about this",
    "start": "1486360",
    "end": "1492559"
  },
  {
    "text": "sort of uh for hackers to be like oh this generates text I generate text surely these things can can join in some",
    "start": "1492559",
    "end": "1498520"
  },
  {
    "text": "way uh so we decided to test it so we have a hosted version of uh je shop uh",
    "start": "1498520",
    "end": "1504200"
  },
  {
    "text": "there's the SQL ey and the login you guys know what I'm talking about uh so we pass in the request and response showing that SQL injection bug crowd's",
    "start": "1504200",
    "end": "1511159"
  },
  {
    "text": "uh template for SQL injection we say hey man rewrite it for me you know anywhere you see a sort of variable please fill",
    "start": "1511159",
    "end": "1517640"
  },
  {
    "text": "it out rewrite as necessary make it all relevant and onto those hallucinations already told us about uh so first of all",
    "start": "1517640",
    "end": "1525440"
  },
  {
    "text": "it followed some instructions it didn't fill out all these variables for me there's this section where you're asked",
    "start": "1525440",
    "end": "1530559"
  },
  {
    "text": "essentially for a uh you know a picture and it hallucinates an ingor link that if it ever existed does not presently",
    "start": "1530559",
    "end": "1537000"
  },
  {
    "text": "and my personal favorite in quite a few it hallucinated a disclosure timeline on a report that I told it it had not sent",
    "start": "1537000",
    "end": "1542159"
  },
  {
    "text": "in yet uh and added new variables that I didn't have before so that that's kind",
    "start": "1542159",
    "end": "1547679"
  },
  {
    "text": "of a bummer right but that's not uh your your end all Beall um and it's not",
    "start": "1547679",
    "end": "1552919"
  },
  {
    "text": "because you as a consultant also don't send things out the first time you write them right you have this iterative process you have a Critic uh usually",
    "start": "1552919",
    "end": "1559279"
  },
  {
    "text": "your boss who reads the report and is like oh no no that's no good uh passes it back and you go through these sort of processes you can imagine setting up a",
    "start": "1559279",
    "end": "1566039"
  },
  {
    "text": "critic that sort of decides discriminatively hey is this uh ready to ship or not and if it's not it provides",
    "start": "1566039",
    "end": "1571559"
  },
  {
    "text": "some more sort of useful tips that you can pass to the writer who's again just going to keep generating this better and better report it sounds good uh but it",
    "start": "1571559",
    "end": "1579799"
  },
  {
    "text": "the language model first has to know what a good Bounty report looks like so we hand labeled again 30 plus reports 15",
    "start": "1579799",
    "end": "1585960"
  },
  {
    "text": "that were pretty good 15 or that were not so good either because they're totally spam or because they're good",
    "start": "1585960",
    "end": "1591600"
  },
  {
    "text": "sort of technical reports but they're not sort of put together in the kind of way that would get your bounties so this",
    "start": "1591600",
    "end": "1597960"
  },
  {
    "text": "Claude Claude came from behind uh Claude did pretty well so Claude was both uh good at deciding whether or Port was",
    "start": "1597960",
    "end": "1603919"
  },
  {
    "text": "ready to ship agreeing with our sort of own assessments but also uh I can say provided pretty pretty good Pros ready",
    "start": "1603919",
    "end": "1609760"
  },
  {
    "text": "advice as well so that was interesting on to Tool use so uh there's a lot of",
    "start": "1609760",
    "end": "1615240"
  },
  {
    "text": "tech stuff here but let's see how it could get more involved in our workflow uh so to test this we wanted to make",
    "start": "1615240",
    "end": "1621279"
  },
  {
    "text": "sure that there was no contamination in our our you know tests uh so we started",
    "start": "1621279",
    "end": "1626840"
  },
  {
    "text": "the to my understanding only short form text based social media company with a bluebird as a logo is that right uh as",
    "start": "1626840",
    "end": "1635399"
  },
  {
    "text": "far as we know so it's Twitter but it's not Twitter um we call them Echo but besides that follows unfollows",
    "start": "1635399",
    "end": "1641080"
  },
  {
    "text": "everything you'd expect just a little fast API application that we know is not in the training Set uh we have we're",
    "start": "1641080",
    "end": "1647080"
  },
  {
    "text": "doing pretty well we have on the platform Elon Musk and Mark Zuckerberg two Titans of Industry truly uh Mark",
    "start": "1647080",
    "end": "1652640"
  },
  {
    "text": "seems happy for us Elon maybe not so much uh this is in public what we're going to be interested in finding out is what he's been saying in private uh to",
    "start": "1652640",
    "end": "1660360"
  },
  {
    "text": "interact with the API we have this API agent based on a gbt 3.5 turbo so this is a model that we can interact with",
    "start": "1660360",
    "end": "1666600"
  },
  {
    "text": "that has access to tools it can send requests by formatting Json that we can send to python uh it has an encoder",
    "start": "1666600",
    "end": "1672840"
  },
  {
    "text": "decoder kind of like burp if it looks like encoded text it'll try to decode it again using python then tell you what",
    "start": "1672840",
    "end": "1678120"
  },
  {
    "text": "what came out and an endpoint reader which is just a given a natural language description of your goal give me the",
    "start": "1678120",
    "end": "1683440"
  },
  {
    "text": "route that is most likely to sort of uh fulfill that goal and it starts by",
    "start": "1683440",
    "end": "1689080"
  },
  {
    "text": "reading in the open api. Json same as in the application analysis so that's where all its knowledge is coming from how",
    "start": "1689080",
    "end": "1694600"
  },
  {
    "text": "does language model use tools uh this there are a lot of different ways to sort of do this uh but in general you're",
    "start": "1694600",
    "end": "1700200"
  },
  {
    "text": "going to provide a few shot examples of like hey if it's this kind of goal you can use this kind of tool here's the Sy",
    "start": "1700200",
    "end": "1706159"
  },
  {
    "text": "Syntax for how you call it and you can make use of sort of special stop tokens to do that so if I show it we do action",
    "start": "1706159",
    "end": "1713519"
  },
  {
    "text": "then action then observation and we learn something from the world we can do something like this where we end our",
    "start": "1713519",
    "end": "1719440"
  },
  {
    "text": "prompt with what the user asked for and then this action token and instead of waiting for it to generate until it's",
    "start": "1719440",
    "end": "1724720"
  },
  {
    "text": "done we say I want you to generate until you hit the token observation like this so I say get me a",
    "start": "1724720",
    "end": "1730519"
  },
  {
    "text": "list of public Echoes it says oh yeah I kind of know how to do that it generates all this text and before it goes off and",
    "start": "1730519",
    "end": "1735679"
  },
  {
    "text": "generates a bunch of request response paays I say stop at observation what does that look like so",
    "start": "1735679",
    "end": "1742480"
  },
  {
    "text": "this is me typing to the agent it's going to go real fast because we're really just interested in showing you",
    "start": "1742480",
    "end": "1747559"
  },
  {
    "text": "hey it has access to tools and it can make calls so I asked what tools it has access to everything I told you about uh",
    "start": "1747559",
    "end": "1755919"
  },
  {
    "text": "then I asked it to grab the Echoes so it's going to parse my goal it's going to go to the endpoint reader to find out what part of the API that's relevant and",
    "start": "1755919",
    "end": "1762519"
  },
  {
    "text": "then it's going to send a request to get me that information great thanks zil",
    "start": "1762519",
    "end": "1768159"
  },
  {
    "text": "okay so that's interesting uh I have this natural language interface that can call tools and you might even think like you can extend that to everything I",
    "start": "1768159",
    "end": "1774320"
  },
  {
    "text": "could have a natural language interface to burp then you might think a little harder and then say why would I want a natural language interface to burp I use",
    "start": "1774320",
    "end": "1780279"
  },
  {
    "text": "burp with my eyes and my hotkeys and my hand I have all these ways to do this so what what's the point of me doing it that way I agree let's say that uh",
    "start": "1780279",
    "end": "1787919"
  },
  {
    "text": "you're not the one using those tools let's say we go totally end to end let's have gb4 use our natural language",
    "start": "1787919",
    "end": "1793440"
  },
  {
    "text": "interface to try to hack so let's talk about the bug it's uh it's not the most advanced bug in the world we uh we",
    "start": "1793440",
    "end": "1799679"
  },
  {
    "text": "rushed echonest a little bit the API keys are the base 64 encoded usernames of the users so uh not a lot of privacy",
    "start": "1799679",
    "end": "1807000"
  },
  {
    "text": "on the platform uh what are you going to do the goal agent our hacker here's gb4 it will",
    "start": "1807000",
    "end": "1813279"
  },
  {
    "text": "be given a goal uh it can sort of talk to itself in natural language anything it says in these sort of square brackets",
    "start": "1813279",
    "end": "1819200"
  },
  {
    "text": "we're going to take and put into the API agent the same way I did when you saw me typing so what does that look like it",
    "start": "1819200",
    "end": "1826320"
  },
  {
    "text": "looks like a wall Loop where uh two agents talk to each other and I wait for something good to happen uh so basically",
    "start": "1826320",
    "end": "1832760"
  },
  {
    "text": "we let for the experiment we let the uh goal agent put out 100 actions so it could C have 100 natural language",
    "start": "1832760",
    "end": "1838760"
  },
  {
    "text": "interactions with the API agent and if we saw the special string we were looking for inside Elon musk's drafts",
    "start": "1838760",
    "end": "1844519"
  },
  {
    "text": "then we were like great good you passed if you didn't get in 100 you're not going to get it this bug's not that hard",
    "start": "1844519",
    "end": "1850120"
  },
  {
    "text": "uh let's see what that looks like when it works so I'm not going to narrate uh the",
    "start": "1850120",
    "end": "1856320"
  },
  {
    "text": "sort of chat logs between these two AIS because that's not that interesting but what I want to talk to you about as you're sort of reading this here is the",
    "start": "1856320",
    "end": "1863200"
  },
  {
    "text": "structure of its testing so the goal agent starts uh I want to get to Elam usdm I should sign up for an account",
    "start": "1863200",
    "end": "1870360"
  },
  {
    "text": "first great first step right I want to interact the application to learn enough about it to to to hack so it tries to",
    "start": "1870360",
    "end": "1876399"
  },
  {
    "text": "log up it does not have the correct name parameter so the API agent explains need more information it does that remember",
    "start": "1876399",
    "end": "1882880"
  },
  {
    "text": "the goal agent has no access to the API documentation it exclusively interacts through the API agent uh so now he gets",
    "start": "1882880",
    "end": "1891720"
  },
  {
    "text": "the API key uh he starts interacting with the",
    "start": "1891720",
    "end": "1897120"
  },
  {
    "text": "public Echoes right so this so now he's got the API key he's got a user account and he's trying out sort of the tool can",
    "start": "1897120",
    "end": "1903679"
  },
  {
    "text": "you log in great he's getting information there so that's the public Echoes now the goal agent moves on to",
    "start": "1903679",
    "end": "1910600"
  },
  {
    "text": "drafts so tries to look at his own drafts and again reasonable for any hacker here before you hack on a feature",
    "start": "1910600",
    "end": "1916279"
  },
  {
    "text": "you should play with a little a little bit first to make sure you know how it works uh so it doesn't have any drafts",
    "start": "1916279",
    "end": "1921559"
  },
  {
    "text": "it's a new account great make me some drafts he gets",
    "start": "1921559",
    "end": "1926158"
  },
  {
    "text": "draft okay so now that he made a draft sends another request to the drafts uh",
    "start": "1927639",
    "end": "1932720"
  },
  {
    "text": "gets some back so now he's gone all the way around there uh now this is kind of interesting",
    "start": "1932720",
    "end": "1940440"
  },
  {
    "text": "wants to get access to Elon mus account does not have doesn't know what the parameters look like so just says like",
    "start": "1940440",
    "end": "1945760"
  },
  {
    "text": "give me elon's account basically the API agent tries to be helpful and just adds an additional parameter it's like you musk do you like that the API does",
    "start": "1945760",
    "end": "1952480"
  },
  {
    "text": "nothing with that continues to give back the draft users uh of of the test user of the goal agent uh and then finally uh",
    "start": "1952480",
    "end": "1960320"
  },
  {
    "text": "sort of out of nowhere the goal agent remembers hey that API k key you gave me at the beginning was my username b64",
    "start": "1960320",
    "end": "1967320"
  },
  {
    "text": "encoded uh what I expected when we set this experiment up was that it would ask the API agent like hey please encode",
    "start": "1967320",
    "end": "1973000"
  },
  {
    "text": "this you have an encoder tool probably because Elon Musk shows up so much on the internet and gbt 4's training data",
    "start": "1973000",
    "end": "1979000"
  },
  {
    "text": "uh it just has the Bas 64 value of Elon Musk and it's just like this is your API key go get my drafts uh so that was",
    "start": "1979000",
    "end": "1985519"
  },
  {
    "text": "amusing and alarming uh so gets the drafts and uh we get them",
    "start": "1985519",
    "end": "1992679"
  },
  {
    "text": "back so uh Elon is not happy with us the lawyers will be in touch uh and he has",
    "start": "1992679",
    "end": "1998200"
  },
  {
    "text": "been pwned at black hat good deal uh so quickly this worked sometimes",
    "start": "1998200",
    "end": "2006279"
  },
  {
    "text": "about 40% of the time the rest of the time it sort of ends up in these Loops where it keeps trying to go to routes",
    "start": "2006279",
    "end": "2011760"
  },
  {
    "text": "that do not exist and sort of loses track of the plot of what draft is trying to get into when it does work",
    "start": "2011760",
    "end": "2017120"
  },
  {
    "text": "however I'll tell you all the episodes look very similar to the one you saw it starts interacting with the application",
    "start": "2017120",
    "end": "2022159"
  },
  {
    "text": "before it starts trying to hack on it makes a user learns the sort of like what can I do with this API key and then",
    "start": "2022159",
    "end": "2028159"
  },
  {
    "text": "finally goes for the actual testing stage so that limits or that sort of mimics these sort of patterns of how we",
    "start": "2028159",
    "end": "2034600"
  },
  {
    "text": "might expect sort of people to test so what what we're hoping for is not like it's not automating the auto",
    "start": "2034600",
    "end": "2040519"
  },
  {
    "text": "distribution creative stuff you do any more than burps automated scanning does the interesting thing is sort of raising",
    "start": "2040519",
    "end": "2046320"
  },
  {
    "text": "the bar on what lwh hanging fruit looks like and saving the out of hacking distribution uh to you guys well with",
    "start": "2046320",
    "end": "2051839"
  },
  {
    "text": "that in mind what's next so there's a lot of questions over where are llms going so obviously",
    "start": "2051839",
    "end": "2058118"
  },
  {
    "text": "there's some upward Trends here uh where these open source LMS are getting bigger uh the data sets are getting more",
    "start": "2058119",
    "end": "2063638"
  },
  {
    "text": "accessible uh the context Windows of course are getting bigger um methods for ensembling them are also getting better",
    "start": "2063639",
    "end": "2069240"
  },
  {
    "text": "different tools Lang chain and all those sort of things um also techniques for prompt engineering are getting better",
    "start": "2069240",
    "end": "2074919"
  },
  {
    "text": "too people starting to get more Savvy about the specific domain knowledge that they bring to the table when they're trying to use an llm and they're sharing",
    "start": "2074919",
    "end": "2081560"
  },
  {
    "text": "that with other people and they're sharing that more broadly which is exciting um there's also uh interesting Trends with regards to Tool use so as",
    "start": "2081560",
    "end": "2088079"
  },
  {
    "text": "you've seen like we're experimenting with tool use we're finding it to be reasonably successful for some things um",
    "start": "2088079",
    "end": "2093638"
  },
  {
    "text": "there's also some interesting things on the horizon when it comes to multimodality you can imagine being able to look at a screenshot and have it",
    "start": "2093639",
    "end": "2099640"
  },
  {
    "text": "parse out uh or have your llm parse out like what's happening on the screen and being able to do something with with",
    "start": "2099640",
    "end": "2106000"
  },
  {
    "text": "that content in context so where where are we going um",
    "start": "2106000",
    "end": "2111960"
  },
  {
    "text": "the key thing uh from all of this is that llms can't replace like they're not going to take all their jobs like that's",
    "start": "2111960",
    "end": "2117680"
  },
  {
    "text": "not a problem uh but they are going to augment so somebody who does know how know how to use llms better than you is",
    "start": "2117680",
    "end": "2123200"
  },
  {
    "text": "going to take your job so you should probably get on it security teams are going to have to",
    "start": "2123200",
    "end": "2128320"
  },
  {
    "text": "adapt to new behaviors at scale uh that weren't economically feasible before and it's really hard to predict what those",
    "start": "2128320",
    "end": "2133640"
  },
  {
    "text": "things are going to be like you still have to know what you're doing to leverage these tools to their maximum uh but we can say that you can expect that",
    "start": "2133640",
    "end": "2140119"
  },
  {
    "text": "things are going to change we anticipate that more offensive workflows are going to integrate llms and we also think the",
    "start": "2140119",
    "end": "2145560"
  },
  {
    "text": "best defense is a good offense nobody's getting off of Mr bones' wild ride I'm",
    "start": "2145560",
    "end": "2151880"
  },
  {
    "text": "sorry thank you for your time here um if you like this stuff and you want to work on it uh hit us on the socials uh we're",
    "start": "2151880",
    "end": "2157839"
  },
  {
    "text": "on Twitter uh or X now um we're also on email and if you like if you use any of",
    "start": "2157839",
    "end": "2163119"
  },
  {
    "text": "these techniques to get bugs we would also love to hear about that too you can track us at run.com thank",
    "start": "2163119",
    "end": "2170280"
  },
  {
    "text": "you",
    "start": "2173760",
    "end": "2176760"
  }
]
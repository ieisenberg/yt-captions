[
  {
    "start": "0",
    "end": "27000"
  },
  {
    "text": "[Music]",
    "start": "860",
    "end": "8559"
  },
  {
    "text": "hi my name is joshua sax i'm chief scientist at sofos and my talk today is entitled no more secret sauce how we can",
    "start": "8559",
    "end": "15280"
  },
  {
    "text": "power real security machine learning progress through open algorithms and benchmarks",
    "start": "15280",
    "end": "21840"
  },
  {
    "text": "so this this talk is all about how we do sound science uh or how we should how we should how we can get to a place in",
    "start": "22880",
    "end": "28320"
  },
  {
    "start": "27000",
    "end": "27000"
  },
  {
    "text": "which we're doing sound science and cyber security ai so i just wanted to talk i just wanted to talk a little bit",
    "start": "28320",
    "end": "33440"
  },
  {
    "text": "about um what some of the contours of sound science look like",
    "start": "33440",
    "end": "39280"
  },
  {
    "text": "as a way of framing this talk we could spend a long time talking about the exact um",
    "start": "39280",
    "end": "46160"
  },
  {
    "text": "definition of science and i'm i'm not an expert in the philosophy of science i'm not going to attempt that but i i will",
    "start": "46160",
    "end": "52879"
  },
  {
    "text": "say that that one dynamic that characterizes science um just really generally",
    "start": "52879",
    "end": "60480"
  },
  {
    "text": "is um is the dynamic of publishing peer-reviewed papers um",
    "start": "60480",
    "end": "66000"
  },
  {
    "text": "and um collaborating with with peers at institutions other than your own",
    "start": "66000",
    "end": "71040"
  },
  {
    "text": "companies other than your own organizations other than your own i think this i think this node length diagram illustrates that so this is a",
    "start": "71040",
    "end": "78080"
  },
  {
    "text": "social network diagram of scientists who work on information retrieval so outside of cyber security but but still inside",
    "start": "78080",
    "end": "84479"
  },
  {
    "text": "data science each one of these circles represents an individual scientist",
    "start": "84479",
    "end": "91040"
  },
  {
    "text": "and they're connected as a function of whether or not they've",
    "start": "91040",
    "end": "96320"
  },
  {
    "text": "cited each other so each of these scientists is publishing papers submitting papers to peer-reviewed for",
    "start": "96320",
    "end": "103119"
  },
  {
    "text": "like academic conferences and academic journals",
    "start": "103119",
    "end": "108240"
  },
  {
    "text": "those papers are getting reviewed by disinterested parties like other academics",
    "start": "108240",
    "end": "114159"
  },
  {
    "text": "who are who are performing a kind of quality assurance check on those papers if the papers are due past past semester they",
    "start": "114159",
    "end": "120719"
  },
  {
    "text": "get published in those papers cite other scientists at other institutions based on the ideas they",
    "start": "120719",
    "end": "126640"
  },
  {
    "text": "draw on and what emerges is a community of scientists who are publishing and",
    "start": "126640",
    "end": "132000"
  },
  {
    "text": "referencing each other's work openly discussing their ideas openly",
    "start": "132000",
    "end": "138560"
  },
  {
    "text": "publishing their results and so you get something like this in a scientific community lots and lots of",
    "start": "138560",
    "end": "143599"
  },
  {
    "text": "different individuals uh who are um in essence collaborating um and they're",
    "start": "143599",
    "end": "149280"
  },
  {
    "text": "also competing um to see who can make the best breakthroughs um but at it's hard scientific science involves this",
    "start": "149280",
    "end": "155280"
  },
  {
    "text": "kind of openness and collaboration now are are we doing this in insecurity i i",
    "start": "155280",
    "end": "162239"
  },
  {
    "start": "158000",
    "end": "158000"
  },
  {
    "text": "think i think anyone who's attending this ritual or in person black out events and has",
    "start": "162239",
    "end": "168319"
  },
  {
    "text": "been around in the cyber security industry for a while knows that the answer is probably no um",
    "start": "168319",
    "end": "174800"
  },
  {
    "text": "and i think we can answer no um [Music] pretty confidently um",
    "start": "174800",
    "end": "180970"
  },
  {
    "text": "[Music] for a couple of reasons so if it did and the first one is is obvious and the",
    "start": "180970",
    "end": "186800"
  },
  {
    "text": "second one is less obvious so let's start with the obvious one i think i think we can say no we're not doing real science partly because",
    "start": "186800",
    "end": "194239"
  },
  {
    "text": "in my anecdotal experience more than half of cyber security",
    "start": "194239",
    "end": "199280"
  },
  {
    "text": "companies that claim to be doing some kind of artificial intelligence publish nothing on on the work that",
    "start": "199280",
    "end": "204560"
  },
  {
    "text": "they're doing and so it's really anybody's guess",
    "start": "204560",
    "end": "209280"
  },
  {
    "text": "how sounds their research and development process really is and i just wouldn't say what they're",
    "start": "209599",
    "end": "215200"
  },
  {
    "text": "doing is is is science um [Music] because they're not um",
    "start": "215200",
    "end": "222239"
  },
  {
    "text": "writing up what they're doing submitting it for peer review um uh so that scientists who are",
    "start": "222239",
    "end": "228319"
  },
  {
    "text": "disinterested um i can evaluate it for its its soundness",
    "start": "228319",
    "end": "233599"
  },
  {
    "text": "um they're working in a silo and that's that that's not what i would call science nobody can and you know you",
    "start": "233599",
    "end": "240000"
  },
  {
    "text": "can't you can't validate the quality of their their work so it's hard to even know um how scientific uh these companies are",
    "start": "240000",
    "end": "246879"
  },
  {
    "text": "being um so i think i mean like i mean many of these companies are are well-meaning uh",
    "start": "246879",
    "end": "252239"
  },
  {
    "text": "some some of them may be producing good products um but i think we need to develop more of a culture uh",
    "start": "252239",
    "end": "258799"
  },
  {
    "text": "like the culture we have around cryptography here and um expected these companies if they claim to be using ai",
    "start": "258799",
    "end": "264160"
  },
  {
    "text": "they need to publish their scientific work um there's a second category of organizations and and i i think um the",
    "start": "264160",
    "end": "272160"
  },
  {
    "text": "organization i manage the sophos ai team um at sophos which is responsible for my",
    "start": "272160",
    "end": "277919"
  },
  {
    "text": "company's um machine learning technology that falls into this category um",
    "start": "277919",
    "end": "283440"
  },
  {
    "text": "this category of organizations uh does publish and does publish in peer-reviewed forum",
    "start": "283440",
    "end": "289759"
  },
  {
    "text": "but still i wouldn't say that what we're doing has quite passed the thresholds um",
    "start": "289759",
    "end": "296960"
  },
  {
    "text": "uh such that we should consider it to be truly scientific and here's why",
    "start": "296960",
    "end": "302080"
  },
  {
    "text": "uh basically the the the state of practice and security and machine learning research",
    "start": "302080",
    "end": "307280"
  },
  {
    "text": "right now is such that let's say my team is working on building a android malware detector which is",
    "start": "307280",
    "end": "313120"
  },
  {
    "text": "something we have in fact done and we have presented presented at conferences on in the past um",
    "start": "313120",
    "end": "318560"
  },
  {
    "text": "uh when we go look at the at the academic literature on building android malware",
    "start": "318560",
    "end": "323680"
  },
  {
    "text": "detectors based on machine learning um there's a bunch of papers that focused on android malware detection but",
    "start": "323680",
    "end": "329759"
  },
  {
    "text": "they're all all the papers give experimental results on different",
    "start": "329759",
    "end": "335759"
  },
  {
    "text": "data sets sometimes dramatically different data sets sometimes slightly different data sets",
    "start": "335759",
    "end": "341680"
  },
  {
    "text": "but each paper references its own data and as a result if i report you",
    "start": "341680",
    "end": "347919"
  },
  {
    "text": "know an accuracy of 99 in my paper and another team reports an accuracy of 97",
    "start": "347919",
    "end": "354160"
  },
  {
    "text": "or vice versa we don't really know which paper is better it's apples and oranges right uh you know i i",
    "start": "354160",
    "end": "360639"
  },
  {
    "text": "my data sets this green apple their data sets this nectarine you know some third papers data sets this orange uh so the",
    "start": "360639",
    "end": "367440"
  },
  {
    "text": "results aren't mutually comparable which means that um i actually don't know which ideas work",
    "start": "367440",
    "end": "373680"
  },
  {
    "text": "best um and that's a big problem i'm gonna be talking a fair bit about that in this talk",
    "start": "373680",
    "end": "381280"
  },
  {
    "text": "um i mean just just uh just to flesh this out a little bit and here's here here are some accuracy plots",
    "start": "381280",
    "end": "387280"
  },
  {
    "text": "from three different papers on windows malware detection uh so in this plot i'm showing accuracy",
    "start": "387280",
    "end": "393680"
  },
  {
    "text": "results from a paper that my colleague constantine and i published a while back on using a feed forward neural network",
    "start": "393680",
    "end": "401120"
  },
  {
    "text": "approach with a given set of features to detect windows malware we we report our results mostly in terms",
    "start": "401120",
    "end": "407919"
  },
  {
    "text": "of area under rock curve which i'm not going to unpack here but is a measure of machine learning accuracy",
    "start": "407919",
    "end": "414319"
  },
  {
    "text": "uh here's another paper um written by um the first authored by this guy this",
    "start": "414319",
    "end": "421280"
  },
  {
    "text": "uh this this researcher ravi um and they report",
    "start": "421280",
    "end": "426880"
  },
  {
    "text": "first of all a different metric which is accuracy and they're using a different data set um and then here's a third paper and",
    "start": "426880",
    "end": "433360"
  },
  {
    "text": "they're they're publishing the results on their own data sets and they're using different accuracy metrics",
    "start": "433360",
    "end": "438560"
  },
  {
    "text": "um so i think it's great that um we have we have an open literature on",
    "start": "438560",
    "end": "444160"
  },
  {
    "text": "how to detect windows malware using machine learning methods and people are trying different things and publishing them um but",
    "start": "444160",
    "end": "451919"
  },
  {
    "text": "it's it's a real problem that we can't compare our results so that's something i'm going to be talking about later in",
    "start": "451919",
    "end": "457199"
  },
  {
    "text": "this talk like how to how to overcome that um but i think i mean just just sort of summing up these last few slides",
    "start": "457199",
    "end": "464720"
  },
  {
    "text": "basically the the point i'm making is that what we're doing in security ai right now is is falling short of",
    "start": "464720",
    "end": "471280"
  },
  {
    "text": "the standards of actual science i mean one because there's a culture of sort of",
    "start": "471280",
    "end": "477039"
  },
  {
    "text": "claims to secret sauce and the security industry unfortunately in which people just aren't open about what they're doing i mean that's a problem that we",
    "start": "477039",
    "end": "482720"
  },
  {
    "text": "need to solve but then even for the folks who are open about the kinds of machine learning algorithms they're they're developing to stop cyber attacks",
    "start": "482720",
    "end": "489520"
  },
  {
    "text": "um we have this problem of incommensurate data sets where different papers are referencing",
    "start": "489520",
    "end": "495199"
  },
  {
    "text": "different private data sets and we actually don't know which papers are proposing the best techniques for detecting and stopping",
    "start": "495199",
    "end": "501280"
  },
  {
    "text": "cyber attacks um and just to be totally clear i mean",
    "start": "501280",
    "end": "507599"
  },
  {
    "text": "my position here is that you know right now companies rarely publish their machine learning methods uh even when",
    "start": "507599",
    "end": "512640"
  },
  {
    "text": "they do we don't have these we don't have public public benchmarks so we can't compare their results um and you know a lot of the technical",
    "start": "512640",
    "end": "518800"
  },
  {
    "text": "collaboration that happens between organizations in the security industry right now around",
    "start": "518800",
    "end": "524240"
  },
  {
    "text": "machine learning really happens through just reading each other's watered-down blogs or",
    "start": "524240",
    "end": "529760"
  },
  {
    "text": "reading each other's papers even though we can't really compare results um and attempting to glean what",
    "start": "529760",
    "end": "535360"
  },
  {
    "text": "others are doing and attempting to learn from it i think we can do far better and i think that we we need to since",
    "start": "535360",
    "end": "542000"
  },
  {
    "text": "we have an important moral mission which is to protect people from from getting compromised",
    "start": "542000",
    "end": "549000"
  },
  {
    "text": "um and then i also wanted i want to set up a contrast to between the way we're doing science in",
    "start": "549519",
    "end": "555120"
  },
  {
    "text": "uh security machine learning and um or lack thereof and the way that uh um",
    "start": "555120",
    "end": "563920"
  },
  {
    "text": "tech industry and tech academics uh are doing science outside of security um so that there are",
    "start": "563920",
    "end": "571120"
  },
  {
    "text": "some fields and i'm gonna be talking about them um down downstream um in this presentation",
    "start": "571120",
    "end": "578000"
  },
  {
    "text": "um in which there really is a culture of openness and open science uh in which um",
    "start": "578000",
    "end": "584720"
  },
  {
    "text": "both academics and researchers inside of um inside of companies",
    "start": "584720",
    "end": "590480"
  },
  {
    "text": "uh are publishing and they're comparing their results based on common benchmarks",
    "start": "590480",
    "end": "595680"
  },
  {
    "text": "um and those those fields um have been much more successful i would",
    "start": "595680",
    "end": "602079"
  },
  {
    "text": "say in applying machine learning than cyber security has um and i'm going to talk about those um in",
    "start": "602079",
    "end": "608000"
  },
  {
    "text": "a couple slides um i really think we just need i think if there's one takeaway from this talk uh",
    "start": "608000",
    "end": "614000"
  },
  {
    "text": "we need to we need to change in in the security ml space we need to start expecting that people publish their",
    "start": "614000",
    "end": "620079"
  },
  {
    "text": "machine learning algorithms just like we expect that companies um are open about what what cryptographic",
    "start": "620079",
    "end": "626800"
  },
  {
    "text": "algorithms are using if for example we don't accept um",
    "start": "626800",
    "end": "632000"
  },
  {
    "text": "uh see security through obscurity in that domain and we shouldn't accept that in machine learning uh",
    "start": "632000",
    "end": "638240"
  },
  {
    "text": "we need to start we need to start expecting companies to report their machine learning performance against these public benchmarks um of course",
    "start": "638240",
    "end": "644399"
  },
  {
    "text": "companies are to compete um in the security ai space but we should also allow for",
    "start": "644399",
    "end": "650880"
  },
  {
    "text": "cross-pollination um so that we can advance as a field and better better protect people",
    "start": "650880",
    "end": "656720"
  },
  {
    "text": "so those are just sort of theses of these of this talk",
    "start": "656720",
    "end": "660959"
  },
  {
    "text": "convinced that that that they're correct um and that you'll join me in in advocating",
    "start": "663200",
    "end": "668880"
  },
  {
    "text": "for this position around how we should be doing ai in the security space",
    "start": "668880",
    "end": "675320"
  },
  {
    "text": "um and i think the stakes are really high i mean i'm gonna i'm gonna gloss over this quickly so i'm gonna get to get to why",
    "start": "675440",
    "end": "682640"
  },
  {
    "text": "in in the slides that i'm about to present but basically you know if we stay closed about the way",
    "start": "682640",
    "end": "688640"
  },
  {
    "text": "we do security ai we're going to make much less progress than if we open up um we're not going to be able to compare",
    "start": "688640",
    "end": "694079"
  },
  {
    "text": "results and know which ideas work i think that i think people will rightly become",
    "start": "694079",
    "end": "700399"
  },
  {
    "text": "cynical about security ai i think they already are um because of all the sort",
    "start": "700399",
    "end": "705600"
  },
  {
    "text": "of substance-less marketing claims that um are getting promulgated in the security industry",
    "start": "705600",
    "end": "711600"
  },
  {
    "text": "um and i think overall we're to protect people less well than we would have",
    "start": "711600",
    "end": "716959"
  },
  {
    "text": "otherwise if we stay if we keep this kind of closed uh culture um in the coming years in",
    "start": "716959",
    "end": "722720"
  },
  {
    "text": "security i think if we open up i think there's a chance for a lot of progress in security ai um we'll be able to track",
    "start": "722720",
    "end": "729680"
  },
  {
    "text": "which machine learning methods work best against a variety of detection problems um i think users will become less",
    "start": "729680",
    "end": "735200"
  },
  {
    "text": "cynical users of security products will become less cynical about ml claims",
    "start": "735200",
    "end": "740240"
  },
  {
    "text": "um and you know i think the stakes are high because",
    "start": "740240",
    "end": "745600"
  },
  {
    "text": "a big big part of security is about looking through data uh to detect signs of cyber attacks and ai clearly has a",
    "start": "745600",
    "end": "752160"
  },
  {
    "text": "big role to play there so we need to we need to um get our act together as a community",
    "start": "752160",
    "end": "757680"
  },
  {
    "text": "around around this question of openness okay so in order to make this argument",
    "start": "757680",
    "end": "764959"
  },
  {
    "text": "i'm going to uh back up and talk about",
    "start": "764959",
    "end": "770800"
  },
  {
    "text": "the role that openness and open benchmarks have played as a catalyst for progress in",
    "start": "770800",
    "end": "777519"
  },
  {
    "text": "non-security machine learning fields um so i just want to i just want to",
    "start": "777519",
    "end": "784639"
  },
  {
    "start": "781000",
    "end": "781000"
  },
  {
    "text": "start this part of the talk by um really dramatizing um",
    "start": "784639",
    "end": "790959"
  },
  {
    "text": "uh how helpful it can be to have open benchmarks in a field so what i'm",
    "start": "790959",
    "end": "796079"
  },
  {
    "text": "showing here is uh is a plot from the site papers with code.com",
    "start": "796079",
    "end": "801760"
  },
  {
    "text": "this is a very helpful site for folks who are actively involved in building machine learning systems",
    "start": "801760",
    "end": "807440"
  },
  {
    "text": "basically this site collects data on",
    "start": "807440",
    "end": "812800"
  },
  {
    "text": "published machine learning papers and um how well the experiments reported in",
    "start": "812839",
    "end": "819440"
  },
  {
    "text": "those papers um stack up against against um i guess what you could call competing",
    "start": "819440",
    "end": "824480"
  },
  {
    "text": "papers or papers that propose to solve the same problem so so here for example um is a plot of",
    "start": "824480",
    "end": "831920"
  },
  {
    "text": "what looks like a few hundred papers each one of these dots is a machine learning paper that contains",
    "start": "831920",
    "end": "837760"
  },
  {
    "text": "experiments um all of these papers are focused on uh classifying images of objects um i",
    "start": "837760",
    "end": "845920"
  },
  {
    "text": "believe they i believe is that they're working these papers um uh use the imagenet benchmark dataset",
    "start": "845920",
    "end": "852240"
  },
  {
    "text": "which is a very well known benchmark dataset computer vision and i believe they attempt to categorize",
    "start": "852240",
    "end": "858800"
  },
  {
    "text": "objects into into one of a thousand categories um and here we're seeing how well they do",
    "start": "858800",
    "end": "867120"
  },
  {
    "text": "in picking the right category when they look at an image and",
    "start": "867120",
    "end": "872560"
  },
  {
    "text": "uh you know this plot really dramatizes what you can do when you have an open benchmark",
    "start": "872560",
    "end": "878800"
  },
  {
    "text": "so here basically what we can see is progress and accuracy against this",
    "start": "878800",
    "end": "883839"
  },
  {
    "text": "immigrant image classification task over the last decade um so if you go back to",
    "start": "883839",
    "end": "889680"
  },
  {
    "text": "um a decade ago this looks like it's 2010 this is back before the neural network revolution where people anybody",
    "start": "889680",
    "end": "895279"
  },
  {
    "text": "if anybody in the audience works in computer vision you probably remember sift features um when people are using these these sift",
    "start": "895279",
    "end": "901360"
  },
  {
    "text": "features um you know we were able to get as a scientific community 50 accuracy at this task",
    "start": "901360",
    "end": "908639"
  },
  {
    "text": "uh since then we've improved up to 90 accuracy which is i mean it's just",
    "start": "908639",
    "end": "913760"
  },
  {
    "text": "totally dramatic i mean it's it's so dramatic that a whole new class of technologies are now",
    "start": "913760",
    "end": "918880"
  },
  {
    "text": "possible um because of the improvements in computer vision um and the really beautiful thing here is that is that um the computer vision",
    "start": "918880",
    "end": "926320"
  },
  {
    "text": "community was able to track its progress this entire past decade against the common benchmark",
    "start": "926320",
    "end": "931920"
  },
  {
    "text": "when people published a paper uh um and they did better than previously",
    "start": "931920",
    "end": "937839"
  },
  {
    "text": "reported results against this image that benchmark um they would declare that they they got state of the art results",
    "start": "937839",
    "end": "943120"
  },
  {
    "text": "against this image that understand benchmark i mean there's some there's some problems with just focusing on one benchmark um",
    "start": "943120",
    "end": "950320"
  },
  {
    "text": "but it's way better to have a benchmark than not because the issue is in cyber security",
    "start": "950320",
    "end": "956000"
  },
  {
    "text": "we don't we don't have the ability to create a plot like this for um",
    "start": "956000",
    "end": "961839"
  },
  {
    "text": "almost any there's some exceptions um which i'll talk about near the end of the talk but",
    "start": "961839",
    "end": "967759"
  },
  {
    "text": "almost any cyber security problem um uh we just haven't been able to track progress in this way because we don't",
    "start": "967759",
    "end": "973680"
  },
  {
    "text": "have community benchmarks um and i think i think the implications of that are fairly obvious in terms of",
    "start": "973680",
    "end": "979839"
  },
  {
    "text": "our ability to improve as a field we can't if you can't track improvement um it's hard to improve",
    "start": "979839",
    "end": "985519"
  },
  {
    "text": "um now outside of server security there are all sorts of benchmarks available so like on",
    "start": "985519",
    "end": "991040"
  },
  {
    "text": "the papers with code site um there are benchmark data sets for semantic segmentation for image classification",
    "start": "991040",
    "end": "997040"
  },
  {
    "text": "for object detection for image generation for denoising um there are benchmarks for the natural",
    "start": "997040",
    "end": "1003199"
  },
  {
    "text": "language processing category of tasks language modeling machine translation question answering",
    "start": "1003199",
    "end": "1009440"
  },
  {
    "text": "any number of things i mean there are many more tasks here actually but these these are the top tasks um",
    "start": "1009440",
    "end": "1016160"
  },
  {
    "text": "in in the medical domain raids there there are all sorts of benchmarks as well um",
    "start": "1016160",
    "end": "1022160"
  },
  {
    "text": "you know i mean they i think the medical domain benchmarks are instructive just because um",
    "start": "1022160",
    "end": "1028880"
  },
  {
    "text": "there are they remind us that that in some of these domains um really in all of them and some of them",
    "start": "1028880",
    "end": "1034959"
  },
  {
    "text": "more obvious than others there there are real moral stakes to the scientific standards we hold ourselves",
    "start": "1034959",
    "end": "1040319"
  },
  {
    "text": "to as a community um so um where they're not benchmarks for",
    "start": "1040319",
    "end": "1045918"
  },
  {
    "text": "you know cancer detection and medical images and this kind of thing uh those algorithms would perform less well and",
    "start": "1045919",
    "end": "1051360"
  },
  {
    "text": "more people would die right and the fact that we don't have enough benchmarks in cybersecurity machine learning",
    "start": "1051360",
    "end": "1057360"
  },
  {
    "text": "um really does have moral implications the fact that we can't track progress against against you know key",
    "start": "1057360",
    "end": "1063360"
  },
  {
    "text": "cybersecurity detection tasks realistically means that more people will get compromised um as a result of",
    "start": "1063360",
    "end": "1069919"
  },
  {
    "text": "that failure which is part of the reason i'm here giving this talk and advocating for the creation of more open data sets and benchmarks",
    "start": "1069919",
    "end": "1077440"
  },
  {
    "start": "1078000",
    "end": "1078000"
  },
  {
    "text": "um and so so really benchmarks have bo both tell the story of progress in",
    "start": "1079120",
    "end": "1086000"
  },
  {
    "text": "um the security ai uh but they also create the progress because you know there's the there's",
    "start": "1086000",
    "end": "1092240"
  },
  {
    "text": "this sort of trait aphorism uh you can't improve what you don't measure um and i think you know to a",
    "start": "1092240",
    "end": "1099039"
  },
  {
    "text": "large extent that's true um and um because",
    "start": "1099039",
    "end": "1104240"
  },
  {
    "text": "you know many of these many fields outside of cybersecurity ml have set up a community infrastructure",
    "start": "1104240",
    "end": "1110480"
  },
  {
    "text": "for measuring progress they've improved and because we haven't we haven't improved as much as we should",
    "start": "1110480",
    "end": "1115679"
  },
  {
    "text": "have",
    "start": "1115679",
    "end": "1118679"
  },
  {
    "start": "1122000",
    "end": "1122000"
  },
  {
    "text": "um you know so i i just want to i just want to drive this point home by giving a",
    "start": "1123200",
    "end": "1128240"
  },
  {
    "text": "kind of split screen um so at its worst in our fields in security",
    "start": "1128240",
    "end": "1134000"
  },
  {
    "text": "we have marketing schlock a lot of condescending stuff you know marketing literature that shows you know 3d",
    "start": "1134000",
    "end": "1139840"
  },
  {
    "text": "neurons spinning around um uh",
    "start": "1139840",
    "end": "1145200"
  },
  {
    "text": "and you know i mean that is unfortunately sort of average over the way we're doing security ai right now that's probably",
    "start": "1145200",
    "end": "1152320"
  },
  {
    "text": "about average um outside of security at least in some fields we're just in a much better situation in",
    "start": "1152320",
    "end": "1158880"
  },
  {
    "text": "terms of um the expectations that researchers even private companies publish",
    "start": "1158880",
    "end": "1165039"
  },
  {
    "text": "openness and a kind of a kind of game in which researchers at",
    "start": "1165039",
    "end": "1170720"
  },
  {
    "text": "computing institutions are collaborating because they're publishing um and they're also competing",
    "start": "1170720",
    "end": "1176000"
  },
  {
    "text": "because they're trying to publish papers that show better results than their competitors but ideas are",
    "start": "1176000",
    "end": "1182240"
  },
  {
    "text": "getting cross-pollinated and there's an overall technological improvement and and you know what we need to get to is something more like this and less like",
    "start": "1182240",
    "end": "1189200"
  },
  {
    "text": "this on the left okay so there are obviously some",
    "start": "1189200",
    "end": "1195440"
  },
  {
    "text": "challenges to um achieving the the the vision that i'm",
    "start": "1195440",
    "end": "1200559"
  },
  {
    "text": "describing here and i i think they're surmountable but i think they're they're real um so some obvious ones are",
    "start": "1200559",
    "end": "1208880"
  },
  {
    "text": "privacy openness and um perceived risks to companies competitive",
    "start": "1208880",
    "end": "1214720"
  },
  {
    "text": "advantages who are making big investments in security ai",
    "start": "1214720",
    "end": "1220640"
  },
  {
    "start": "1219000",
    "end": "1219000"
  },
  {
    "text": "um so let me let me walk through um why these issues",
    "start": "1220640",
    "end": "1226640"
  },
  {
    "text": "matter and and then i'll talk about um how i think we can address them uh so first so so",
    "start": "1226640",
    "end": "1233760"
  },
  {
    "text": "you know you could so in in in the case where we we may want to",
    "start": "1233760",
    "end": "1238799"
  },
  {
    "text": "release malware as part of benchmark data sets uh you know one could argue that that model",
    "start": "1238799",
    "end": "1245440"
  },
  {
    "text": "could be weaponized by adversaries and one doesn't want to you know make these data sets open um you know in cases where we want to",
    "start": "1245440",
    "end": "1252320"
  },
  {
    "text": "make public benchmarks around detecting phishing emails uh",
    "start": "1252320",
    "end": "1257520"
  },
  {
    "text": "you know one i think one could quite credibly argue that there are big privacy risks there we could potentially",
    "start": "1257520",
    "end": "1262960"
  },
  {
    "text": "be you know um if we were if we were releasing a benchmark that included both the nine emails and phishing emails obviously",
    "start": "1262960",
    "end": "1269840"
  },
  {
    "text": "those benign emails would contain private information we need to figure out how to release",
    "start": "1269840",
    "end": "1274960"
  },
  {
    "text": "benign data in a way that doesn't compromise people's privacy and even phishing emails can sometimes if they're",
    "start": "1274960",
    "end": "1280240"
  },
  {
    "text": "based on background research and such can sometimes contain private information and that's a real problem",
    "start": "1280240",
    "end": "1285600"
  },
  {
    "text": "uh one could argue that if everybody's publishing their security",
    "start": "1285600",
    "end": "1290720"
  },
  {
    "text": "machine learning approaches that adversaries could use that open knowledge",
    "start": "1290720",
    "end": "1296720"
  },
  {
    "text": "uh in order to figure out how to subvert those technologies that's true too and i mean we need to",
    "start": "1296720",
    "end": "1303120"
  },
  {
    "text": "take that seriously or that objection seriously as well um and then finally we have to respect",
    "start": "1303120",
    "end": "1308480"
  },
  {
    "text": "the business um mission of companies uh who may not want to",
    "start": "1308480",
    "end": "1313840"
  },
  {
    "text": "share their you know give up their competitive advantage if they've spent a lot of money to develop um",
    "start": "1313840",
    "end": "1320159"
  },
  {
    "text": "you know high performing machine learning algorithms so i want to walk through and address these these issues",
    "start": "1320159",
    "end": "1326960"
  },
  {
    "start": "1326000",
    "end": "1326000"
  },
  {
    "text": "okay so one so this idea that benchmark malware could be weaponized by",
    "start": "1326960",
    "end": "1332720"
  },
  {
    "text": "adversaries so i i would say that i mean i respect that objection to releasing uh",
    "start": "1332720",
    "end": "1340000"
  },
  {
    "text": "let's say a benchmark data set of malware and spoiler alert like my the organization i i manage at my company",
    "start": "1340000",
    "end": "1347919"
  },
  {
    "text": "sophos um has released um a big data set that includes 10 million dollar binaries",
    "start": "1347919",
    "end": "1353360"
  },
  {
    "text": "um so you know where my position is here but i think it's i think it makes sense to object that adversaries could use",
    "start": "1353360",
    "end": "1358640"
  },
  {
    "text": "this you know my counter to that would be it's not hard to get malware um",
    "start": "1358640",
    "end": "1365039"
  },
  {
    "text": "you know if you have a subscription to virustotal you can just go download millions of malware binaries",
    "start": "1365039",
    "end": "1370080"
  },
  {
    "text": "all by yourself there are big malware repositories where for free on the internet you can just go download lots",
    "start": "1370080",
    "end": "1376240"
  },
  {
    "text": "of malware binaries um you know",
    "start": "1376240",
    "end": "1382000"
  },
  {
    "text": "even with that um it's um it's possible adversaries would",
    "start": "1382559",
    "end": "1388000"
  },
  {
    "text": "go to some benchmark data set and decide that's where they were going to get malware from if they wanted to just get some big dump of malware and somehow use",
    "start": "1388000",
    "end": "1394320"
  },
  {
    "text": "it as part of the campaign um but you know like what we did with our",
    "start": "1394320",
    "end": "1399440"
  },
  {
    "text": "malware dataset and i'll talk about this in a little bit in more detail is we is we changed um some some crucial",
    "start": "1399440",
    "end": "1406720"
  },
  {
    "text": "bits in the malware to make it much harder to actually use even while we didn't strip away the information that",
    "start": "1406720",
    "end": "1413039"
  },
  {
    "text": "machine learning learning researchers tend to use so i think it's possible to make it harder for adversaries to actually use",
    "start": "1413039",
    "end": "1418640"
  },
  {
    "text": "the malware i would also say that you know malware binaries are tend to be part of like",
    "start": "1418640",
    "end": "1423919"
  },
  {
    "text": "big complicated distributed systems and the binaries on their own whether",
    "start": "1423919",
    "end": "1429200"
  },
  {
    "text": "they're osx elf pe or you know whatever binary format they tend to they tend to",
    "start": "1429200",
    "end": "1434880"
  },
  {
    "text": "be to go defunct pretty quickly after they're created um they malware binaries",
    "start": "1434880",
    "end": "1440080"
  },
  {
    "text": "tend to be generated by like polymorphic malware generators and you know have",
    "start": "1440080",
    "end": "1445120"
  },
  {
    "text": "c2 information hard-coded into them and that stuff goes out of date pretty quickly",
    "start": "1445120",
    "end": "1450320"
  },
  {
    "text": "um so i don't think unbalanced this uh",
    "start": "1450320",
    "end": "1455520"
  },
  {
    "text": "this this objection should um shutter the the overall mission of",
    "start": "1455520",
    "end": "1460960"
  },
  {
    "text": "of creating benchmarks that allow us to compare uh results between organizations and i think we need to consider the cost",
    "start": "1460960",
    "end": "1466320"
  },
  {
    "text": "of not releasing benchmarks as well um which are you know what i argued for in the previous",
    "start": "1466320",
    "end": "1472559"
  },
  {
    "text": "section of this talk like an inability to track progress um against important cyber security",
    "start": "1472559",
    "end": "1478320"
  },
  {
    "text": "problems okay so another objection to",
    "start": "1478320",
    "end": "1484880"
  },
  {
    "start": "1480000",
    "end": "1480000"
  },
  {
    "text": "creating benchmark data sets that the security machine learning community can use to track progress is that um there are",
    "start": "1484880",
    "end": "1492480"
  },
  {
    "text": "real privacy risks here so i think this is we need to take this extremely seriously you know a major component of",
    "start": "1492480",
    "end": "1498960"
  },
  {
    "text": "our mission as a field is to protect people's privacy um we definitely don't want to do do harm here um",
    "start": "1498960",
    "end": "1505840"
  },
  {
    "text": "uh so a a couple",
    "start": "1505840",
    "end": "1511440"
  },
  {
    "text": "a couple rebuttals i guess on this point uh one is i we have so few benchmarks in",
    "start": "1511440",
    "end": "1517840"
  },
  {
    "text": "cybersecurity ai that i think we can we can start with the low-hanging fruit that doesn't involve a lot of privacy",
    "start": "1517840",
    "end": "1523279"
  },
  {
    "text": "risk so um i'll talk later about this but like",
    "start": "1523279",
    "end": "1528400"
  },
  {
    "text": "sofos and my team within sofa sofa say i released this data set of of",
    "start": "1528400",
    "end": "1534720"
  },
  {
    "text": "windows malware um and windows benign wear for machine learning researchers and i think there's not much privacy risk to",
    "start": "1534720",
    "end": "1540840"
  },
  {
    "text": "releasing um there's there's minimal privacy risk to releasing portable executable binaries",
    "start": "1540840",
    "end": "1547919"
  },
  {
    "text": "it's not like releasing email or documents um uh you know there's a bunch more",
    "start": "1547919",
    "end": "1554960"
  },
  {
    "text": "candidates benchmark problems that we could solve that that are analogous so like releasing",
    "start": "1554960",
    "end": "1560720"
  },
  {
    "text": "android apps uh os x elf binaries um uh releasing uh osx macro binaries or",
    "start": "1560720",
    "end": "1568880"
  },
  {
    "text": "linux health binaries there's a bunch of problems like that where i think we can we can sidestep privacy risks",
    "start": "1568880",
    "end": "1574400"
  },
  {
    "text": "when it gets to questions like email i think we should take a hard look at techniques like differential privacy",
    "start": "1574400",
    "end": "1581039"
  },
  {
    "text": "which involve adding adding noise to feature vectors to make the original information in those future vectors",
    "start": "1581039",
    "end": "1586880"
  },
  {
    "text": "um somewhat unrecoverable",
    "start": "1586880",
    "end": "1591360"
  },
  {
    "text": "and that is an avenue to release data to mitigate privacy risk i think we want to just to be clear i",
    "start": "1592159",
    "end": "1598080"
  },
  {
    "text": "think we need to be absolutely sure that we're not going to leak pii when we do these benchmark data sets but there are also there are also ways of of doing",
    "start": "1598080",
    "end": "1605600"
  },
  {
    "text": "that um that um that i think well i think they're",
    "start": "1605600",
    "end": "1611760"
  },
  {
    "text": "there are at least promising tools in the research literature that may allow us to do that even for highly",
    "start": "1611760",
    "end": "1617120"
  },
  {
    "text": "private data like email if you sort of add enough noise to the email uh you can prove that it's impossible to recover um",
    "start": "1617120",
    "end": "1623760"
  },
  {
    "text": "the information that we want to protect um i think for for data that we think we can't uh",
    "start": "1623760",
    "end": "1630480"
  },
  {
    "text": "definitely privacy protect um it might be possible that we could create institutional arrangements in which uh",
    "start": "1630480",
    "end": "1636640"
  },
  {
    "text": "some trusted third party uh takes researchers ml models",
    "start": "1636640",
    "end": "1643360"
  },
  {
    "text": "runs those models against a private data set that nobody else can see and then reports out results and we should be",
    "start": "1643360",
    "end": "1649120"
  },
  {
    "text": "thinking along those lines when it gets into benchmarking against um you know very privacy privacy sensitive problems",
    "start": "1649120",
    "end": "1658000"
  },
  {
    "start": "1657000",
    "end": "1657000"
  },
  {
    "text": "um then there's this objection that if we if everybody starts publishing their",
    "start": "1659120",
    "end": "1664559"
  },
  {
    "text": "security machine learning approaches we risk just exposing too much information to",
    "start": "1664559",
    "end": "1670720"
  },
  {
    "text": "adversaries i would say that um so a few things about this",
    "start": "1670720",
    "end": "1676799"
  },
  {
    "text": "so historically i i wouldn't i'm not a dogmatist and i think sometimes",
    "start": "1676799",
    "end": "1682799"
  },
  {
    "text": "you know being obscure about your technology might be a good strategy or tactic um to to try to",
    "start": "1682799",
    "end": "1689120"
  },
  {
    "text": "protect yourself but i think for the most part when it comes to sort of broad scientific innovation",
    "start": "1689120",
    "end": "1695360"
  },
  {
    "text": "security through obscurity is just it hasn't worn out to have been a a good idea um",
    "start": "1695360",
    "end": "1702080"
  },
  {
    "text": "and i think in i think in areas like like cryptography um openness i think has a really good track record i think",
    "start": "1702080",
    "end": "1708399"
  },
  {
    "text": "it's much better that we're open about fundamental scientific ideas in cyber security then",
    "start": "1708399",
    "end": "1714480"
  },
  {
    "text": "we think that by working in a little silo we can produce um",
    "start": "1714480",
    "end": "1719840"
  },
  {
    "text": "better better science and better technology and better protection for our customers i really i just i'm highly skeptical of",
    "start": "1719840",
    "end": "1726880"
  },
  {
    "text": "the idea that you know um relatively small teams of scores of",
    "start": "1726880",
    "end": "1732720"
  },
  {
    "text": "individuals working in isolation and secrecy are going to produce better technology than",
    "start": "1732720",
    "end": "1738640"
  },
  {
    "text": "um whole communities of scientists network together sharing results even if even if the price of that is adversaries",
    "start": "1738640",
    "end": "1744320"
  },
  {
    "text": "can see our algorithms okay so",
    "start": "1744320",
    "end": "1750000"
  },
  {
    "text": "getting into the last part of this talk where do we go from here and how do we build a culture of open science and",
    "start": "1750000",
    "end": "1755840"
  },
  {
    "text": "security ai um i mean i think our mission has to be to try to cover as much of",
    "start": "1755840",
    "end": "1764320"
  },
  {
    "start": "1757000",
    "end": "1757000"
  },
  {
    "text": "the threat ontology as we possibly can with openness and benchmarks uh",
    "start": "1764320",
    "end": "1771360"
  },
  {
    "text": "so i mean what we see in front of us is a representation of the mitre attack framework made i really think we need to",
    "start": "1771360",
    "end": "1776799"
  },
  {
    "text": "go through as a community and figure out where machine learning may help in detecting the various",
    "start": "1776799",
    "end": "1783039"
  },
  {
    "text": "tactics techniques and procedures represented in something like the mitre attack framework",
    "start": "1783039",
    "end": "1788080"
  },
  {
    "text": "um and and then develop benchmarks as a community um so that we can achieve",
    "start": "1788080",
    "end": "1793919"
  },
  {
    "text": "something like uh the visualizations i showed from the papers with code websites earlier but",
    "start": "1793919",
    "end": "1799520"
  },
  {
    "text": "but for cyber security i mean i think that really has to be the goal um and there's no reason it shouldn't be",
    "start": "1799520",
    "end": "1805039"
  },
  {
    "text": "there's there's nothing that that um peculiar about cyber security that that that makes us different than",
    "start": "1805039",
    "end": "1812880"
  },
  {
    "text": "um than like the medical the medical machine learning community in terms of like the scientific standards that we",
    "start": "1812880",
    "end": "1819200"
  },
  {
    "text": "should uphold i mean i think i think that expectation should be that we develop benchmarks for the problems that we",
    "start": "1819200",
    "end": "1824240"
  },
  {
    "text": "are working on in security and ml um so that's one um two i mean i i would",
    "start": "1824240",
    "end": "1830559"
  },
  {
    "start": "1828000",
    "end": "1828000"
  },
  {
    "text": "say um you know i mean we we're trying to take steps",
    "start": "1830559",
    "end": "1836320"
  },
  {
    "text": "in the direction of building the future that i'm advocating for here",
    "start": "1836320",
    "end": "1841600"
  },
  {
    "text": "on on the data science team that i manage so we released this dataset which is",
    "start": "1841600",
    "end": "1847440"
  },
  {
    "text": "called sorel we did this in collaboration with reversing labs uh i want to call out the principal",
    "start": "1847440",
    "end": "1853360"
  },
  {
    "text": "contributors here which were ethan rudds and rich herring who were supported by my team as they were",
    "start": "1853360",
    "end": "1861120"
  },
  {
    "text": "doing this work this is a data set of 20 million of 10 million malware binaries and the",
    "start": "1861120",
    "end": "1868080"
  },
  {
    "text": "metadata from 10 million benign binaries um and it's really it's an industrial scale",
    "start": "1868080",
    "end": "1874559"
  },
  {
    "text": "data set that's large enough that you can train like a real industrial windows malware",
    "start": "1874559",
    "end": "1881360"
  },
  {
    "text": "detector um and we hope this becomes like imagenet and some of the other benchmarks that i showed earlier in",
    "start": "1881360",
    "end": "1887440"
  },
  {
    "text": "terms of its prestige as a measuring stick for windows malware detection we hope this",
    "start": "1887440",
    "end": "1893039"
  },
  {
    "text": "allows people to better track progress against like a core problem in",
    "start": "1893039",
    "end": "1898080"
  },
  {
    "text": "the security industry which is detecting windows malware like you know that's been a problem for a very long time and it's still a very big problem",
    "start": "1898080",
    "end": "1904880"
  },
  {
    "text": "and this this is our sort of brick and and you know the metaphorical wall that we think we need",
    "start": "1904880",
    "end": "1911039"
  },
  {
    "text": "to build around scientific institutions and openness and security i also want to call out the elastic team",
    "start": "1911039",
    "end": "1917679"
  },
  {
    "text": "which built the ember data sets um this is a different take on building a",
    "start": "1917679",
    "end": "1922880"
  },
  {
    "text": "windows malware benchmark we think having having more than one benchmark data set",
    "start": "1922880",
    "end": "1928559"
  },
  {
    "text": "is um is important and and good and we think that the experience of",
    "start": "1928559",
    "end": "1934080"
  },
  {
    "text": "other fields and machine learning um like in computer vision and medicine and some of the other areas that i talked about um bear that out um so ember is",
    "start": "1934080",
    "end": "1942240"
  },
  {
    "text": "another project to look at if you're looking for a windows malware a windows",
    "start": "1942240",
    "end": "1947600"
  },
  {
    "text": "um machine learning malware detection data set they made some different choices around",
    "start": "1947600",
    "end": "1952960"
  },
  {
    "text": "openness like they didn't release the actual malware binaries like like we did but their data set has some really good",
    "start": "1952960",
    "end": "1959200"
  },
  {
    "text": "features too um you know we definitely try to",
    "start": "1959200",
    "end": "1965919"
  },
  {
    "text": "publish um so in my team we have we have a commitment to publish to to publishing",
    "start": "1965919",
    "end": "1972159"
  },
  {
    "text": "in some form or another everything that we ship um we don't always we don't always publish right away after we ship",
    "start": "1972159",
    "end": "1977279"
  },
  {
    "text": "um that's not because we're scared to publish it's sometimes just because of our road map and",
    "start": "1977279",
    "end": "1982320"
  },
  {
    "text": "deadlines and you know typical organizational you know resource constraint type problems but you know we",
    "start": "1982320",
    "end": "1987919"
  },
  {
    "text": "have a lot of publications if you if you look at my google scholar profile you'll see papers coming out of um you",
    "start": "1987919",
    "end": "1995039"
  },
  {
    "text": "know a whole legacy of work over the last four or five years on my team these are a bunch of publications from",
    "start": "1995039",
    "end": "2001600"
  },
  {
    "text": "elastic which i would say is probably um i would say is another",
    "start": "2001600",
    "end": "2007120"
  },
  {
    "text": "very good team in terms of their standards of openness we really want other companies to start",
    "start": "2007120",
    "end": "2012720"
  },
  {
    "text": "doing this at as well and start holding themselves to a standard in which you know nei technology they're",
    "start": "2012720",
    "end": "2019039"
  },
  {
    "text": "going to claim in their marketing literature and release into the field um they publish a paper on and get it peer",
    "start": "2019039",
    "end": "2024480"
  },
  {
    "text": "reviewed and validated by other colleagues in the field um",
    "start": "2024480",
    "end": "2032000"
  },
  {
    "text": "so in conclusion i mean i think the stakes are really high here i think we need to build a scientific culture in",
    "start": "2032000",
    "end": "2037679"
  },
  {
    "text": "security data science um uh and um",
    "start": "2037679",
    "end": "2042880"
  },
  {
    "text": "i think if we do that um i think that um",
    "start": "2042880",
    "end": "2048480"
  },
  {
    "text": "i think there's a lot that we can achieve together as a community um i think that if we continue as we've um",
    "start": "2048480",
    "end": "2055280"
  },
  {
    "text": "with it with the kind of collective culture in which we've pursued security machine learning thus far",
    "start": "2055280",
    "end": "2061358"
  },
  {
    "text": "um i think we'll continue to make progress but i think i think we won't make the progress that",
    "start": "2061359",
    "end": "2067040"
  },
  {
    "text": "that we would have uh and with that i want to open it up",
    "start": "2067040",
    "end": "2073440"
  },
  {
    "text": "for discussion um if you're interested in contacting me you can contact me on twitter",
    "start": "2073440",
    "end": "2078720"
  },
  {
    "text": "my twitter handle here and you can also uh please feel free to email me i'd love to hear from",
    "start": "2078720",
    "end": "2084398"
  },
  {
    "text": "anyone who listens to this talk and has feedback positive or negative",
    "start": "2084399",
    "end": "2089599"
  },
  {
    "text": "or constructive criticism and thank you very much",
    "start": "2089599",
    "end": "2094710"
  },
  {
    "text": "[Music]",
    "start": "2094710",
    "end": "2104320"
  },
  {
    "text": "you",
    "start": "2104880",
    "end": "2106960"
  }
]
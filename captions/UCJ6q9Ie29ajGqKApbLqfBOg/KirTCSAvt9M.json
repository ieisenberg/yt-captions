[
  {
    "start": "0",
    "end": "65000"
  },
  {
    "text": "good morning and welcome to day two of black hat 2015 got a few announcements for you stop by the business Hall",
    "start": "399",
    "end": "6640"
  },
  {
    "text": "located in Shoreline a for sponsored sessions in theater A and B be sure to",
    "start": "6640",
    "end": "11880"
  },
  {
    "text": "check out all the black hat Arsenal and Breakers djk sponsored workshops are in Mandalay",
    "start": "11880",
    "end": "20039"
  },
  {
    "text": "JK and L you are in lagon k for the session",
    "start": "20039",
    "end": "25640"
  },
  {
    "text": "name web timing attacks made practical with Tim Morgan and Jason",
    "start": "25640",
    "end": "32238"
  },
  {
    "text": "Morgan I also would remind you to put your phone on vibrate it makes it easier",
    "start": "32239",
    "end": "37760"
  },
  {
    "text": "for the rest of us to ignore the ringing while you wait for your voicemail to pick it up so uh good morning we glad",
    "start": "37760",
    "end": "45239"
  },
  {
    "text": "you're here and let's introduce our uh welcome our",
    "start": "45239",
    "end": "50239"
  },
  {
    "text": "speakers thank you thanks for coming um I'm Tim this is my brother Jason um and",
    "start": "54559",
    "end": "60399"
  },
  {
    "text": "we uh want to explain to you what we researched in the area of web timing",
    "start": "60399",
    "end": "65478"
  },
  {
    "start": "65000",
    "end": "83000"
  },
  {
    "text": "attacks so what are what are timing attacks um well just about any piece of",
    "start": "65479",
    "end": "70640"
  },
  {
    "text": "software has situations where it needs to do some kind of security critical operation things like authentication",
    "start": "70640",
    "end": "77040"
  },
  {
    "text": "authorization checks or cryptography and in sometimes in those situations it's",
    "start": "77040",
    "end": "82520"
  },
  {
    "text": "really important that um the application May return the result of that operation",
    "start": "82520",
    "end": "88759"
  },
  {
    "start": "83000",
    "end": "145000"
  },
  {
    "text": "that whether success or failure uh to the user or to the uh or potential",
    "start": "88759",
    "end": "93880"
  },
  {
    "text": "attacker um but it's really critical that the details of how the decision was made are not exposed uh so in a really",
    "start": "93880",
    "end": "100439"
  },
  {
    "text": "trivial example um consider a web application that um you're trying to log into and if you um type your username",
    "start": "100439",
    "end": "107560"
  },
  {
    "text": "and you mistype your password if the application comes back and says oh um the password's wrong you messed up",
    "start": "107560",
    "end": "113240"
  },
  {
    "text": "character three you know that's kind of absurd but if we were to do that then clearly you could guess the password one",
    "start": "113240",
    "end": "119079"
  },
  {
    "text": "character at a time right um so in in those situations we have to be sure that that information",
    "start": "119079",
    "end": "124600"
  },
  {
    "text": "doesn't leak and depending on the operation what information is critical just varies um with timing attacks what we",
    "start": "124600",
    "end": "132440"
  },
  {
    "text": "can do sometimes is if we can measure the execution time of those critical operations then we can actually learn",
    "start": "132440",
    "end": "138760"
  },
  {
    "text": "information about the inner workings of how the decision was made so that kind of information can leak and therefore it",
    "start": "138760",
    "end": "144160"
  },
  {
    "text": "can expose vulnerabilities so there's been plenty of uh research in the past in the area",
    "start": "144160",
    "end": "150360"
  },
  {
    "start": "145000",
    "end": "331000"
  },
  {
    "text": "of cryptography on timing attacks and a number of uh you demonstrated exploits",
    "start": "150360",
    "end": "155440"
  },
  {
    "text": "uh both against um you know specific ciphers but also against more complex crypto systems like SSL um so there's a",
    "start": "155440",
    "end": "162000"
  },
  {
    "text": "lot of uh background research in this area but it's mostly in the area of cryptography um but what about your",
    "start": "162000",
    "end": "167920"
  },
  {
    "text": "everyday web application when does this stuff actually matter so here's an example of a real",
    "start": "167920",
    "end": "175319"
  },
  {
    "text": "live public website that's out on the out on the internet right now it's um it's an insurance company and they they",
    "start": "175319",
    "end": "181840"
  },
  {
    "text": "health insurance and if you already have a policy with them then you can sign up for an online account um you have to",
    "start": "181840",
    "end": "188360"
  },
  {
    "text": "enter your personal information very sensitive stuff like your social security number um date of birth and so",
    "start": "188360",
    "end": "193440"
  },
  {
    "text": "on in order to prove your identity before you can sign up for the account now this particular website I don't know",
    "start": "193440",
    "end": "199760"
  },
  {
    "text": "if it's vulnerable at all I'm not claiming it is but this is the kind of form that I'm concerned about and it's the kind of form I'd like to be able to",
    "start": "199760",
    "end": "206040"
  },
  {
    "text": "test now if if this site returned differing eror messages depending on which field you type in and got wrong",
    "start": "206040",
    "end": "212959"
  },
  {
    "text": "then clearly there would be an attack there right you could try to guess the social security number first and then you can move on to the next field um and",
    "start": "212959",
    "end": "220360"
  },
  {
    "text": "that stuff is something that pentesters typically search for they they look for those differing error messages and",
    "start": "220360",
    "end": "225760"
  },
  {
    "text": "they'll report on those so that's a well-known issue but if the amount of time the application requires to uh",
    "start": "225760",
    "end": "232879"
  },
  {
    "text": "check each field varies depending on what the data is then there could still be a vulnerability here and right now I",
    "start": "232879",
    "end": "238840"
  },
  {
    "text": "don't think most pentest are looking for this there's not good tools to check for this kind of",
    "start": "238840",
    "end": "244480"
  },
  {
    "text": "thing so this is my favorite quote from Yogi Bara so in the past there's been a lot",
    "start": "246040",
    "end": "252200"
  },
  {
    "text": "of um you know specific vulnerabilities identified in the area of timing",
    "start": "252200",
    "end": "257320"
  },
  {
    "text": "vulnerabilities uh and and it's really interesting but a lot of the techniques that are used are really basic and they",
    "start": "257320",
    "end": "262800"
  },
  {
    "text": "happen to work on that particular vulnerability but they don't necessarily extend to other areas um and then",
    "start": "262800",
    "end": "268360"
  },
  {
    "text": "there's been other research done that has tried to generalize timing attacks but it seems like the research so far is",
    "start": "268360",
    "end": "273600"
  },
  {
    "text": "still fairly immature um and uh you know there's very few tools off the shelf tools available uh last year Meer and",
    "start": "273600",
    "end": "280560"
  },
  {
    "text": "Sanden uh presented a talk at black hat and they they released time trial which is a really nice tool it uh lets you",
    "start": "280560",
    "end": "287400"
  },
  {
    "text": "identify if a timing uh difference exists in an application both web applications and other applications um",
    "start": "287400",
    "end": "293880"
  },
  {
    "text": "but it doesn't necessarily let you determine the actual risk um of that because uh you can't necessarily deter",
    "start": "293880",
    "end": "299919"
  },
  {
    "text": "exactly the number of requests you need to to perform the attack um and it doesn't give the pin tester quite enough",
    "start": "299919",
    "end": "306120"
  },
  {
    "text": "tools to actually exploit the issue directly um and we also kind of felt that the the statistical analysis could",
    "start": "306120",
    "end": "312639"
  },
  {
    "text": "be improved in this area it seems like a lot of um a lot of previous researchers have used really basic statistics the um",
    "start": "312639",
    "end": "319000"
  },
  {
    "text": "for instance in the case of Lucky 13 which is an exploit against SSL uh they simply use the median to try to measure",
    "start": "319000",
    "end": "324720"
  },
  {
    "text": "timing differences and you know really basic stuff from high school statistics um and so we thought this would be an",
    "start": "324720",
    "end": "330840"
  },
  {
    "text": "easy area to improve on turned out to be a lot harder than we thought so our goals try to improve the statistical",
    "start": "330840",
    "end": "337120"
  },
  {
    "start": "331000",
    "end": "368000"
  },
  {
    "text": "methods that are used to measure timing differences um and be able to answer the",
    "start": "337120",
    "end": "342199"
  },
  {
    "text": "question for a pentester in the time frame of a pentest is this timing flaw",
    "start": "342199",
    "end": "347360"
  },
  {
    "text": "actually exploitable can I actually tell my customer that yes this is something you need to fix right away or this is",
    "start": "347360",
    "end": "352639"
  },
  {
    "text": "really just something theoretical that would only be doable in you know two months time um and then we also wanted",
    "start": "352639",
    "end": "358000"
  },
  {
    "text": "to investigate um the use of TCP timestamps and if those time stamps could be used to help um make these",
    "start": "358000",
    "end": "364280"
  },
  {
    "text": "attacks more efficient previous researchers had kind of left this as an as an open",
    "start": "364280",
    "end": "370080"
  },
  {
    "start": "368000",
    "end": "376000"
  },
  {
    "text": "question so onto data collection how we how we obtain the the information we need to distinguish timing differences",
    "start": "370240",
    "end": "377759"
  },
  {
    "start": "376000",
    "end": "549000"
  },
  {
    "text": "um first uh a little bit about TCP timestamps um so TCP Tim stamps are a",
    "start": "377759",
    "end": "383759"
  },
  {
    "text": "very simple mechanism to make TCP more efficient uh what they do is uh whenever a host sends a pack as part of a TCP",
    "start": "383759",
    "end": "390680"
  },
  {
    "text": "connection uh the uh current time the host's current time is actually labeled on the packet and so this could be",
    "start": "390680",
    "end": "397080"
  },
  {
    "text": "really useful right because now we can actually look at the time the host sent the packet rather than when we received",
    "start": "397080",
    "end": "402280"
  },
  {
    "text": "it and we can eliminate a lot of potential noise that occurs on the network uh so it's really attractive to",
    "start": "402280",
    "end": "407759"
  },
  {
    "text": "to want to use this um and in order to get at TCB Tim stamps you pretty much have to use a",
    "start": "407759",
    "end": "412800"
  },
  {
    "text": "sniffer uh you have to observe the packets directly because um the uh the TCP Stacks don't expose this to user",
    "start": "412800",
    "end": "419800"
  },
  {
    "text": "space applications um it's also fairly tricky because the frequency of the clock for TCB timestamps varies from one",
    "start": "419800",
    "end": "426440"
  },
  {
    "text": "operating system to another so we have to be able to measure that clock frequency and we worked out how to do that but it's not it's not trivial um",
    "start": "426440",
    "end": "434520"
  },
  {
    "text": "and what this does is it forces us to actually analyze all of our data at a packet level and work out complex issues",
    "start": "434520",
    "end": "440319"
  },
  {
    "text": "like uh if there's retransmissions of packets if there's dropped packets packets come out of order we need to be",
    "start": "440319",
    "end": "445879"
  },
  {
    "text": "able to address all those things in order to measure the round trip time of an HD P request um and at the end of the",
    "start": "445879",
    "end": "451639"
  },
  {
    "text": "day after working with TCP time stamps for quite a while we weren't able to use them directly to measure timing",
    "start": "451639",
    "end": "457360"
  },
  {
    "text": "differences with any real accuracy there's definitely information there and we think by pairing that information",
    "start": "457360",
    "end": "462520"
  },
  {
    "text": "with other timing data we may be able to improve the results but we don't have anything that sophisticated yet but what",
    "start": "462520",
    "end": "468599"
  },
  {
    "text": "this did is that it forc us down this path of doing packet analysis of actually analyzing um you know uh",
    "start": "468599",
    "end": "474599"
  },
  {
    "text": "packets as they come and go from the network card which which actually ended up making our timing measure much better",
    "start": "474599",
    "end": "480240"
  },
  {
    "text": "by measuring the packets directly and it's it makes sense because if you look at you know your typical very simple",
    "start": "480240",
    "end": "486479"
  },
  {
    "text": "HTTP request um if you're trying to measure the the time um round trip times directly from user space um you know",
    "start": "486479",
    "end": "493800"
  },
  {
    "text": "you're just opening a connection sending the data uh measuring the time you sent it measuring the time when the the data",
    "start": "493800",
    "end": "499360"
  },
  {
    "text": "comes back into user space then you're forced to measure the amount of time it takes for your data to be sent through",
    "start": "499360",
    "end": "505360"
  },
  {
    "text": "the kernel onto the network card the time it takes to do a TCP handshake um the time it takes for then the colel",
    "start": "505360",
    "end": "511720"
  },
  {
    "text": "to receive the response and then send it back to your user space application and then you're then the colel eventually",
    "start": "511720",
    "end": "517200"
  },
  {
    "text": "schedules your your user space process back on the CPU so there's all this extra time delay that's added to that",
    "start": "517200",
    "end": "523279"
  },
  {
    "text": "and uh and that just introduces chance for more variance on your local machine there's more there's more variability",
    "start": "523279",
    "end": "528839"
  },
  {
    "text": "because of different processes running and um so so you'd think if you could simply measure from the time you saw the",
    "start": "528839",
    "end": "535640"
  },
  {
    "text": "very first um request packet that actually has data in it not the but not the handshake we don't need that um and",
    "start": "535640",
    "end": "541800"
  },
  {
    "text": "the very last packet that has data in it when we receive the response then we could get a more accurate time measurement so that's the theory but",
    "start": "541800",
    "end": "548839"
  },
  {
    "text": "does it actually work in practice um and that might be a little bit hard to see the histogram uh but uh but yes it does",
    "start": "548839",
    "end": "554920"
  },
  {
    "text": "work basically uh you see here we compared time trial which is the tool released last year um and they have a",
    "start": "554920",
    "end": "561160"
  },
  {
    "text": "very good user space implementation it's implemented in C++ it's very very fast and they did a lot of work to try to",
    "start": "561160",
    "end": "567120"
  },
  {
    "text": "minimize noise in user space um but just doing a a much more naive um request",
    "start": "567120",
    "end": "573760"
  },
  {
    "text": "tool but measuring the packets instead of um instead of doing it from user space we get a much better distribution",
    "start": "573760",
    "end": "580000"
  },
  {
    "text": "so the uh the blue distribution is our measurements of the same test scenario uh you can see that the distribution is",
    "start": "580000",
    "end": "586399"
  },
  {
    "text": "much spikier it's a taller more narrow uh distribution um and uh and and",
    "start": "586399",
    "end": "591800"
  },
  {
    "text": "clearly the time measurements the raw measurements are much smaller they're much further to the left um and then looking at the median absolute deviation",
    "start": "591800",
    "end": "598640"
  },
  {
    "text": "of these two distrib tions which is a majure of variance um it turns out that the packet data was 40% had 40% less",
    "start": "598640",
    "end": "606079"
  },
  {
    "text": "variance so it's clearly much better so that's great a uh another thing that we did",
    "start": "606079",
    "end": "613279"
  },
  {
    "start": "609000",
    "end": "714000"
  },
  {
    "text": "differently than previous researchers is that we decided to do paired sampling or to sample the data in in tles so",
    "start": "613279",
    "end": "620079"
  },
  {
    "text": "basically if you have two test cases for instance one with a valid social security number and one with an invalid",
    "start": "620079",
    "end": "625399"
  },
  {
    "text": "social security number and you want to measure the time difference between the two then those are your two test test cases okay um we measure all those test",
    "start": "625399",
    "end": "632240"
  },
  {
    "text": "cases one after another very close in time in wall clock time um and then we",
    "start": "632240",
    "end": "637279"
  },
  {
    "text": "just repeat that process over and over and in our terminology one sample is is actually a pair of those requests okay",
    "start": "637279",
    "end": "645680"
  },
  {
    "text": "um so we collect the probos at about the same time um and the idea being that if",
    "start": "645680",
    "end": "650880"
  },
  {
    "text": "there's any disturbances on the network or on the host uh during a period of time then hopefully for a given sample",
    "start": "650880",
    "end": "657279"
  },
  {
    "text": "both of the requests will be affected in a similar way right if the for some reason packets start getting rerouted through a different router uh if the",
    "start": "657279",
    "end": "664160"
  },
  {
    "text": "remote host starts getting bogged down with other user requests then then any disturbances will equally affect both",
    "start": "664160",
    "end": "670320"
  },
  {
    "text": "types of samples um and early during testing we we did one measurement um collected a",
    "start": "670320",
    "end": "677720"
  },
  {
    "text": "bunch of samples on one host over the internet and we got this distribution which is awful right um both basically",
    "start": "677720",
    "end": "685519"
  },
  {
    "text": "we have two separate distributions one for each test case but both of these test cases were completely separate like",
    "start": "685519",
    "end": "691160"
  },
  {
    "text": "they had it was very multimodal so some of the responses came back very very quickly and some took a very long time",
    "start": "691160",
    "end": "698240"
  },
  {
    "text": "and it's it's really ugly data set and if you try to um just apply basic statistics on this distribution as is",
    "start": "698240",
    "end": "705720"
  },
  {
    "text": "it's really difficult like do you use the data on the left or do you use the data on the right or do you try to come up with some way to use both and combine",
    "start": "705720",
    "end": "711079"
  },
  {
    "text": "them but then when we looked at the data a little bit more closely um as a function of time of day as when we sent",
    "start": "711079",
    "end": "717480"
  },
  {
    "start": "714000",
    "end": "857000"
  },
  {
    "text": "the request we saw this and this is just a scatter plot the um uh the red dots",
    "start": "717480",
    "end": "723200"
  },
  {
    "text": "are the short test case and the blue ones are the the longer test case and you can you can't really see the Reds very much because the blue cover it but",
    "start": "723200",
    "end": "729240"
  },
  {
    "text": "but basically what you see is that early in the test all of the requests went really really fast and we got responses",
    "start": "729240",
    "end": "734560"
  },
  {
    "text": "quickly and then for some reason something changed and then all responses started to become very very slow um and",
    "start": "734560",
    "end": "740440"
  },
  {
    "text": "looking into it further what I decided probably what happened is that um Comcast has a a feature called speed",
    "start": "740440",
    "end": "746000"
  },
  {
    "text": "boost or power boost something like that and um what they do is they allow you to download um files from a particular web",
    "start": "746000",
    "end": "753120"
  },
  {
    "text": "server at unlimited speed at first and then after a period of time once they decided you've downloaded enough then",
    "start": "753120",
    "end": "758199"
  },
  {
    "text": "they throttle you back to your subscribed rate so Comcast actually kind of screwed up our data set here because",
    "start": "758199",
    "end": "763480"
  },
  {
    "text": "they let us go really really fast at first and then they throttle this back so so that creates problems right for if",
    "start": "763480",
    "end": "769920"
  },
  {
    "text": "if you're doing a pen test and this happens to you what do you do what what part of the data you rely on um well if",
    "start": "769920",
    "end": "775920"
  },
  {
    "text": "if instead of trying to treat these two data sets as separate If instead we just",
    "start": "775920",
    "end": "780959"
  },
  {
    "text": "take the pairwise differences between the roundt trip time measurements for each pair because they're paired they",
    "start": "780959",
    "end": "786399"
  },
  {
    "text": "were done about the same time then you actually get the distribution at the bottom in the purple so that's the",
    "start": "786399",
    "end": "791760"
  },
  {
    "text": "difference in time between each pair of measurements and so that automatically sort of normalizes it around a central",
    "start": "791760",
    "end": "797760"
  },
  {
    "text": "tendency you know if you can measure then the um uh the location of that",
    "start": "797760",
    "end": "804600"
  },
  {
    "text": "central tendency meaning what is the average difference uh uh between the two requests then you can decide is this",
    "start": "804600",
    "end": "810399"
  },
  {
    "text": "zero or nonzero and if it's nonzero then there's a timing difference right so that's that's one change in the way that",
    "start": "810399",
    "end": "816199"
  },
  {
    "text": "we approach the problem uh Jason's gonna come up here and talk a little bit more about the statistical",
    "start": "816199",
    "end": "821959"
  },
  {
    "text": "analysis here you go so thank you Tim so good morning so now I'm going to talk a",
    "start": "821959",
    "end": "828320"
  },
  {
    "text": "little bit as he said about the statistical analysis that we have done and the approach we have tried to take",
    "start": "828320",
    "end": "833480"
  },
  {
    "text": "to analyzing these roundtrip times and the differences in roundtrip times so recall what we're trying to do is",
    "start": "833480",
    "end": "839480"
  },
  {
    "text": "uncover the amount of time one computation at on a web server another server takes uh versus a different types",
    "start": "839480",
    "end": "846199"
  },
  {
    "text": "of computation but if you've ever tried to deal with network data um even",
    "start": "846199",
    "end": "852199"
  },
  {
    "text": "notwithstanding the notwithstanding the Comcast power boost issue um you'll notice that uh network data are",
    "start": "852199",
    "end": "859759"
  },
  {
    "start": "857000",
    "end": "979000"
  },
  {
    "text": "extremely noisy so this is one of our best test cases it's a sample of 500 or",
    "start": "859759",
    "end": "865040"
  },
  {
    "text": "a series of 500 observations from this um analysis we've done or from a series",
    "start": "865040",
    "end": "871560"
  },
  {
    "text": "that we have collected and you'll notice it's quite clear what the problem is here in this series you have uh 500 uh",
    "start": "871560",
    "end": "881240"
  },
  {
    "text": "observations and you have four of them that just went crazy and basically we",
    "start": "881240",
    "end": "886399"
  },
  {
    "text": "have an average of about 100 uh millisecond round trip time on the vast",
    "start": "886399",
    "end": "891720"
  },
  {
    "text": "majority of the cases and then in four cases you have it go up to 400 or plus",
    "start": "891720",
    "end": "897000"
  },
  {
    "text": "so this is something we saw in all of of the data as I said this was on a local network a local VM only two hops away",
    "start": "897000",
    "end": "904040"
  },
  {
    "text": "and you still get this type of uh these type of data when you actually go over the internet to a web app that is",
    "start": "904040",
    "end": "910079"
  },
  {
    "text": "further away away it gets much worse so looking at the data on this",
    "start": "910079",
    "end": "916000"
  },
  {
    "text": "data set anyway it was about 1% 1 to 2% of the time um the data points were",
    "start": "916000",
    "end": "922040"
  },
  {
    "text": "extreme in this way now when you this this is just one um uh one half of the",
    "start": "922040",
    "end": "928120"
  },
  {
    "text": "pair um if you actually want to look at the other half this is uh the all pawise",
    "start": "928120",
    "end": "934079"
  },
  {
    "text": "data here round trip times if you take the differences this is the type of data you're dealing with",
    "start": "934079",
    "end": "940199"
  },
  {
    "text": "and this is the thing that we wanted to deal with and uh that does improve the analysis in the end but it is still",
    "start": "940199",
    "end": "946240"
  },
  {
    "text": "extremely difficult to use um so what these type of data the the problems they",
    "start": "946240",
    "end": "952399"
  },
  {
    "text": "cause is that you can't use standard measures like T tests or difference in mean tests um medians we test did don't",
    "start": "952399",
    "end": "959800"
  },
  {
    "text": "work out all that well so what we wanted to do is come up with some way to filter",
    "start": "959800",
    "end": "968519"
  },
  {
    "text": "the data and then use other more robust measures of central tendency in order to",
    "start": "968519",
    "end": "973639"
  },
  {
    "text": "uncover the differences in round trip time in these pairwise",
    "start": "973639",
    "end": "979279"
  },
  {
    "start": "979000",
    "end": "1037000"
  },
  {
    "text": "data so the tool that we and went to First is something called a Colman",
    "start": "980000",
    "end": "986680"
  },
  {
    "text": "filter and if any of you have ever done signal processing it's a it's a filter that is used in Signal processing quite",
    "start": "986680",
    "end": "993880"
  },
  {
    "text": "often um it does a great job under a wide variety of cases of smoothing",
    "start": "993880",
    "end": "999199"
  },
  {
    "text": "things out so for example if we apply that uh the colan filter the smoother to",
    "start": "999199",
    "end": "1005279"
  },
  {
    "text": "that roundt trip time data of differences in roundtrip time data this is what we get under one simple",
    "start": "1005279",
    "end": "1010680"
  },
  {
    "text": "specification of the common filter so you can see here across those 500 samples that really um the common",
    "start": "1010680",
    "end": "1017880"
  },
  {
    "text": "filter did smooth out spikes but it left them in because we're we the the idea is that those Spikes have information in",
    "start": "1017880",
    "end": "1024160"
  },
  {
    "text": "them but we don't want to take them at face value we want to uh control for the fact that they are so far they're",
    "start": "1024160",
    "end": "1030880"
  },
  {
    "text": "they're extreme outliers so the next thing we wanted to",
    "start": "1030880",
    "end": "1037199"
  },
  {
    "start": "1037000",
    "end": "1175000"
  },
  {
    "text": "try um were a series of robust estimators and we started with a box",
    "start": "1037199",
    "end": "1042880"
  },
  {
    "text": "test which uh Meer and Meer and Sandlin Sanden last year uh discussed here at",
    "start": "1042880",
    "end": "1050640"
  },
  {
    "text": "black hat now the Box test is actually quite simple um if you take the take two",
    "start": "1050640",
    "end": "1056520"
  },
  {
    "text": "distributions and you take two particular quantiles or spaces so here I think it's the six and the eighth",
    "start": "1056520",
    "end": "1063240"
  },
  {
    "text": "quantile eth per quantiles in each of these distributions if these two boxes here",
    "start": "1063240",
    "end": "1069640"
  },
  {
    "text": "the blue and the pink boxes if they do not overlap which is the case in this this plot if they don't have overlap",
    "start": "1069640",
    "end": "1075159"
  },
  {
    "text": "then you can say these distributions are different so you can say well round trip times the computation that these round",
    "start": "1075159",
    "end": "1081840"
  },
  {
    "text": "trip times represent are different across these two test cases however if they do overlap you say",
    "start": "1081840",
    "end": "1090280"
  },
  {
    "text": "there's probably no real difference between them between the two two",
    "start": "1090280",
    "end": "1096240"
  },
  {
    "text": "cases so we in preliminary tests using the comman filter and not using the",
    "start": "1096240",
    "end": "1101280"
  },
  {
    "text": "common filter we uh found that the Box test under certain cases in our data",
    "start": "1101280",
    "end": "1107000"
  },
  {
    "text": "using the the new data ction technique didn't work um that well under in many",
    "start": "1107000",
    "end": "1112559"
  },
  {
    "text": "cases so we were looking for other things and we turned to something called L estimators and we went to El",
    "start": "1112559",
    "end": "1118400"
  },
  {
    "text": "estimators for a couple reasons um the first is that they're extremely easy to understand and second they're very easy",
    "start": "1118400",
    "end": "1126080"
  },
  {
    "text": "and quick to compute simply what an L estimator is is it's an estimator off of",
    "start": "1126080",
    "end": "1132880"
  },
  {
    "text": "uh the the quantiles so here I think these are the 25% quantiles um a be above and below the",
    "start": "1132880",
    "end": "1140360"
  },
  {
    "text": "median and you take the values from those quantiles and then you average them and that is your measure of central",
    "start": "1140360",
    "end": "1148120"
  },
  {
    "text": "tendency this can be extended in this case it's called the mid hinge because it's the",
    "start": "1148120",
    "end": "1153720"
  },
  {
    "text": "25% uh 25% quantiles but you can generalize this to taking four",
    "start": "1153720",
    "end": "1161280"
  },
  {
    "text": "points or we also tried taking seven points and this this one's a little bit different in the sense that we actually",
    "start": "1161280",
    "end": "1167280"
  },
  {
    "text": "use the median in the calculation as well as those three uh points off to the",
    "start": "1167280",
    "end": "1173240"
  },
  {
    "text": "right and left so taking these new estimators and",
    "start": "1173240",
    "end": "1180159"
  },
  {
    "start": "1175000",
    "end": "1591000"
  },
  {
    "text": "the Colman filter we needed to then figure out whether or not they were actually performing better than the Box",
    "start": "1180159",
    "end": "1186120"
  },
  {
    "text": "test which ones perform better under certain circumstances and whether or not the Colman filter is actually going to help",
    "start": "1186120",
    "end": "1192240"
  },
  {
    "text": "us we these analyze these type of data so we performed a Monte Carlo",
    "start": "1192240",
    "end": "1198360"
  },
  {
    "text": "analys is across four test scenarios and here you can see that um we have two",
    "start": "1198360",
    "end": "1204880"
  },
  {
    "text": "local computers one is a VM one is um a physical computer we have a a VM a",
    "start": "1204880",
    "end": "1211400"
  },
  {
    "text": "remote VM and a remote uh physical computer and then we also um have two",
    "start": "1211400",
    "end": "1216760"
  },
  {
    "text": "different operating systems what's important for the Monte",
    "start": "1216760",
    "end": "1221840"
  },
  {
    "text": "Carlo analysis is that what we've done is we've taken uh five different uh",
    "start": "1221840",
    "end": "1227840"
  },
  {
    "text": "Deltas so different differences in the nanc differences um and then we've taken",
    "start": "1227840",
    "end": "1234120"
  },
  {
    "text": "around 250,000 pairs of each test case so there are 17 test cases in all and",
    "start": "1234120",
    "end": "1240080"
  },
  {
    "text": "what this led to is uh about 8 and a half million different individual probes across all of these test",
    "start": "1240080",
    "end": "1248320"
  },
  {
    "text": "cases as I said the objective here was to test all of these estimators and the Colman filter systematically across a a",
    "start": "1249200",
    "end": "1257640"
  },
  {
    "text": "variety of cases and this is a pretty standard Monte Carlo analysis if any of you have ever",
    "start": "1257640",
    "end": "1263360"
  },
  {
    "text": "done these in statistics so for uh 13 different values between 50 and 100 or",
    "start": "1263360",
    "end": "1270000"
  },
  {
    "text": "50 and 10,000 we those are the the size of the series we take because we really want to",
    "start": "1270000",
    "end": "1275480"
  },
  {
    "text": "know how short or how few samples we can take and still get a good estimate we're",
    "start": "1275480",
    "end": "1280600"
  },
  {
    "text": "trying to make it practical I don't do that I'm I do research usually but Tim wants it practical so um we want to know",
    "start": "1280600",
    "end": "1286960"
  },
  {
    "text": "how little how few data we can actually grab and um come up with some kind of decent estimate of whether or not the",
    "start": "1286960",
    "end": "1293960"
  },
  {
    "text": "roundtrip times are actually different so then 480 times we repeat we",
    "start": "1293960",
    "end": "1300120"
  },
  {
    "text": "basically take a random sample apply the Colman filter then we do run the tests on the filtered data and the",
    "start": "1300120",
    "end": "1306159"
  },
  {
    "text": "non-filtered data um for the L estimators we actually did a bootstrap technique where we estimated on random",
    "start": "1306159",
    "end": "1312279"
  },
  {
    "text": "samples of the filter data and non-filtered data to come up with a distribution and what what all of this",
    "start": "1312279",
    "end": "1317520"
  },
  {
    "text": "did is it came came up with a distribution of Errors for every single test case and every single",
    "start": "1317520",
    "end": "1323640"
  },
  {
    "text": "parameterization across I said this wasn't practical part right um across",
    "start": "1323640",
    "end": "1329600"
  },
  {
    "text": "all of these test cases so there were a few billion uh different estimates that",
    "start": "1329600",
    "end": "1335400"
  },
  {
    "text": "we took so with this then we get things that look kind of like this um on the",
    "start": "1335400",
    "end": "1343120"
  },
  {
    "text": "two this is a level plot or I guess what I call it um the two uh plots on the",
    "start": "1343120",
    "end": "1350880"
  },
  {
    "text": "left and in the middle um are the raw they're the average errors each one of",
    "start": "1350880",
    "end": "1356600"
  },
  {
    "text": "those squares is the average error within that parameterization of the Box test so on in the the left two plots the",
    "start": "1356600",
    "end": "1365679"
  },
  {
    "text": "red means the Box test is doing really well so you can see in the center where",
    "start": "1365679",
    "end": "1371240"
  },
  {
    "text": "we've applied the Colman filter the Box test does better across the broader range of parameterizations",
    "start": "1371240",
    "end": "1378600"
  },
  {
    "text": "remember going into any test that you're going to do you don't actually know what the parameterization what what is going",
    "start": "1378600",
    "end": "1384640"
  },
  {
    "text": "to be best for that data set in order to determine whether or not you have discovered a difference in roundtrip",
    "start": "1384640",
    "end": "1391919"
  },
  {
    "text": "times and then so that's on the the left two plots and then on the far right you",
    "start": "1391919",
    "end": "1397600"
  },
  {
    "text": "see the Improvement in the Colman filter and mixed up the coloring here but in",
    "start": "1397600",
    "end": "1402880"
  },
  {
    "text": "the far right one the gray is where the Colman filter has done better or the Colman filter data has done better than",
    "start": "1402880",
    "end": "1409080"
  },
  {
    "text": "the raw data with the Box test so of course we also applied this",
    "start": "1409080",
    "end": "1415120"
  },
  {
    "text": "to the other the L estimators this is this the mid summary and the parameterization of the mid summary is",
    "start": "1415120",
    "end": "1421960"
  },
  {
    "text": "across the bottom and the error rates are on the vertical axis you can see across a broad range the raw data in",
    "start": "1421960",
    "end": "1430720"
  },
  {
    "text": "this case did much better than the common filter data with this estimator",
    "start": "1430720",
    "end": "1436400"
  },
  {
    "text": "we actually able with just a th samples in this case well below 10 or 5% error",
    "start": "1436400",
    "end": "1443279"
  },
  {
    "text": "rate all the way through you know about3 in this case on the unfiltered data the",
    "start": "1443279",
    "end": "1448440"
  },
  {
    "text": "raw or the filtered data on the other hand both one one-dimensional and two-dimensional common filter uh did not",
    "start": "1448440",
    "end": "1455200"
  },
  {
    "text": "perform very well but this wasn't a consistent",
    "start": "1455200",
    "end": "1461679"
  },
  {
    "text": "result actually in a lot of cases the Colman filter did improve the estimates",
    "start": "1462440",
    "end": "1467840"
  },
  {
    "text": "here it's about 7 and a half% on average it smoothed out the results and it made this estimator the mids summary uh",
    "start": "1467840",
    "end": "1474600"
  },
  {
    "text": "perform a little bit better but unfortunately this isn't good enough for an analysis or or to actually really",
    "start": "1474600",
    "end": "1481640"
  },
  {
    "text": "determine we're talking a 40% error rate here um still even with the filtered",
    "start": "1481640",
    "end": "1488039"
  },
  {
    "text": "data so in summary the statistical analysis this is what we've gotten out of it um just to say we have 180 plots",
    "start": "1488039",
    "end": "1496279"
  },
  {
    "text": "of the 182 of these plots for each one of these estimators so I can't really go through all of them here um but on",
    "start": "1496279",
    "end": "1504399"
  },
  {
    "text": "average what we have found is the mid summary in particular and Tim's going to present some other results um performed",
    "start": "1504399",
    "end": "1511640"
  },
  {
    "text": "a better on average than the Box test did over uh the data sets that we",
    "start": "1511640",
    "end": "1516960"
  },
  {
    "text": "collected um the comman filter improves the hard cases when we have very little",
    "start": "1516960",
    "end": "1522000"
  },
  {
    "text": "data or very noisy data the cola filter helps things a little bit but not to the level that we had really hoped it would",
    "start": "1522000",
    "end": "1528840"
  },
  {
    "text": "the one caveat here is that uh this comman filter was not trained in any way",
    "start": "1528840",
    "end": "1534440"
  },
  {
    "text": "it was a parameterization um that appeared to work pretty well in some test cases and",
    "start": "1534440",
    "end": "1541240"
  },
  {
    "text": "so we just stuck with it to estimate through that if you actually get down and train the common filter it might",
    "start": "1541240",
    "end": "1548559"
  },
  {
    "text": "turn out to work a lot better than it has in our results so far and then finally um one thing that",
    "start": "1548559",
    "end": "1555279"
  },
  {
    "text": "we're wanting to look at in for future is that we want to try out other filters",
    "start": "1555279",
    "end": "1560840"
  },
  {
    "text": "and other weighting techniques and one thing we're thinking about is using a clustering analysis to give particular weights to different pairwise",
    "start": "1560840",
    "end": "1567360"
  },
  {
    "text": "differences in order to calculate the round Tri differences so as I said this is not the",
    "start": "1567360",
    "end": "1573520"
  },
  {
    "text": "Practical part you don't want to do all of this for every analysis so now I'm going to turn it back over to Tim he's",
    "start": "1573520",
    "end": "1579520"
  },
  {
    "text": "going to talk about how these results were integrated into the tool he's developed in order to U make this",
    "start": "1579520",
    "end": "1586240"
  },
  {
    "text": "practical here Tim thanks",
    "start": "1586240",
    "end": "1590240"
  },
  {
    "start": "1591000",
    "end": "1607000"
  },
  {
    "text": "all right thanks Jason so uh Jason did all all of that work really heavy Brute Force",
    "start": "1592600",
    "end": "1598279"
  },
  {
    "text": "statistical analysis on a huge Computing cluster which is really nice um but now we need a tool that that we can use",
    "start": "1598279",
    "end": "1604320"
  },
  {
    "text": "day-to-day so so we created um this little thing we're calling nanon um the",
    "start": "1604320",
    "end": "1609360"
  },
  {
    "start": "1607000",
    "end": "1733000"
  },
  {
    "text": "goal of it is to first of all identify timing differences in in web applications um but then also to",
    "start": "1609360",
    "end": "1615159"
  },
  {
    "text": "quantify the risk you need to understand how many samples you need to collect to distinguish those timing differences uh",
    "start": "1615159",
    "end": "1621080"
  },
  {
    "text": "and that will tell you as a pinest or an attacker uh how much time it's going to take to actually exploit something um",
    "start": "1621080",
    "end": "1627120"
  },
  {
    "text": "and then also help out with the exploitation piece of it to create proof a concept um it's definitely a work in",
    "start": "1627120",
    "end": "1633440"
  },
  {
    "text": "progress still and it's not very user friendly so um it might be a while before that is easier to use for the",
    "start": "1633440",
    "end": "1639159"
  },
  {
    "text": "average pentester um but this is the this is the workflow for nanon um just real briefly uh at the beginning you",
    "start": "1639159",
    "end": "1645960"
  },
  {
    "text": "have to go through a templating stage where you need to sort of uh instruct the tool what your test cases are if you",
    "start": "1645960",
    "end": "1651200"
  },
  {
    "text": "have a valid social security number and an invalid one or perhaps you have more than two of those test cases uh and then",
    "start": "1651200",
    "end": "1656880"
  },
  {
    "text": "you need to instruct it on what um you know what the HTTP requests look like where does that data get embedded in the",
    "start": "1656880",
    "end": "1663039"
  },
  {
    "text": "request is it in the post body or in the URL or what have you um and then from that point the next four stages are",
    "start": "1663039",
    "end": "1668200"
  },
  {
    "text": "pretty much automated uh so uh you just run the collection scripts um it it grabs a whole bunch of samples as a as a",
    "start": "1668200",
    "end": "1675000"
  },
  {
    "text": "baseline so you can actually learn things about the uh timing differences um packet analysis is performed which",
    "start": "1675000",
    "end": "1682080"
  },
  {
    "text": "zeros in on the actual packets you want to measure your roundtrip times between uh and then and then you go through a",
    "start": "1682080",
    "end": "1687600"
  },
  {
    "text": "training stage uh so we came up with some training algorithms instead of trying to Brute Force every possible parameterization for our classifiers we",
    "start": "1687600",
    "end": "1694720"
  },
  {
    "text": "came up with algorithms that try to find the best parameters more quickly um they may not be perfect but um but they seem",
    "start": "1694720",
    "end": "1700960"
  },
  {
    "text": "to work pretty well um and then next we actually test those uh those parameterizations so once we come up",
    "start": "1700960",
    "end": "1706840"
  },
  {
    "text": "with a set of parameters for each class ifier we test them on a completely separate data set a different portion of the collected data which is really",
    "start": "1706840",
    "end": "1712919"
  },
  {
    "text": "important to do if you if you try to test over your training data it it doesn't work out well um and then at",
    "start": "1712919",
    "end": "1718320"
  },
  {
    "text": "that point at at the end of the testing stage you'll know how many samples you need to get a certain error rate so will",
    "start": "1718320",
    "end": "1725519"
  },
  {
    "text": "you need a th samples to get 5% error or do you need 100,000 samples to get that error uh and then after that if you want",
    "start": "1725519",
    "end": "1731480"
  },
  {
    "text": "you can also perform the attack um just a little bit more about the training and testing process um",
    "start": "1731480",
    "end": "1738799"
  },
  {
    "start": "1733000",
    "end": "2120000"
  },
  {
    "text": "because our training Al algorithm may not be perfect um we actually train each classifier multiple times and come up",
    "start": "1738799",
    "end": "1744600"
  },
  {
    "text": "with different parameterizations and then try them all out um one of the reasons for this is that if you train on",
    "start": "1744600",
    "end": "1750200"
  },
  {
    "text": "different sample sizes different numbers of observations you actually get very different results in the training",
    "start": "1750200",
    "end": "1755320"
  },
  {
    "text": "algorithms if you don't give it enough data then the uh training algorithms tend to not learn enough and they get",
    "start": "1755320",
    "end": "1760840"
  },
  {
    "text": "bad parameters if you give it too much data they tend to overlearn so they and this is a really common problem in",
    "start": "1760840",
    "end": "1766240"
  },
  {
    "text": "machine learning they tend to over train on the data and then uh they will work really well on the training set but then",
    "start": "1766240",
    "end": "1771799"
  },
  {
    "text": "it won't work well on the test set so we try a bunch of different sizes um sample sizes in order to tease out which ones",
    "start": "1771799",
    "end": "1777559"
  },
  {
    "text": "work best and then we try all those parameterizations on the the um uh test",
    "start": "1777559",
    "end": "1782880"
  },
  {
    "text": "data and find out which ones work best um and throughout this process instead of just trying to find which classifier",
    "start": "1782880",
    "end": "1789080"
  },
  {
    "text": "uh has the lowest error for a given sample size what we're actually doing a sort of it's not exactly a um binary",
    "start": "1789080",
    "end": "1795600"
  },
  {
    "text": "search but some similar to a binary search to identify what sample size is actually uh sufficient for a given classifier uh to",
    "start": "1795600",
    "end": "1802840"
  },
  {
    "text": "perform the attack and then whichever one has the lowest number of observations that's the winner so so we kind of flipped the problem",
    "start": "1802840",
    "end": "1810440"
  },
  {
    "text": "around so um I also performed a Mony Carlo um analysis against all of the the",
    "start": "1810440",
    "end": "1816519"
  },
  {
    "text": "same data that Jason did this is a completely separate implementation and we came up with the same overall results",
    "start": "1816519",
    "end": "1822919"
  },
  {
    "text": "um for the most part the the mids summary quad summary or septo summary um classifiers do the best usually the mid-",
    "start": "1822919",
    "end": "1828640"
  },
  {
    "text": "summary does a little bit better um and uh in this table what it's showing is",
    "start": "1828640",
    "end": "1834559"
  },
  {
    "text": "the in each cell the number of observations needed to make a classification at 5% error okay so lower",
    "start": "1834559",
    "end": "1841120"
  },
  {
    "text": "is better um in other in some data sets uh we didn't have enough data we we",
    "start": "1841120",
    "end": "1846200"
  },
  {
    "text": "capped it at 20,000 observations because we don't feel above that is all that practical in most cases um and so in",
    "start": "1846200",
    "end": "1851640"
  },
  {
    "text": "cases where the classifiers could not get down to 5% error we just include the um the error rate the best error rate",
    "start": "1851640",
    "end": "1857480"
  },
  {
    "text": "that it achieved um so anyway if you if you look through this you can see that most of the time mid summ mid summary was best there is",
    "start": "1857480",
    "end": "1864679"
  },
  {
    "text": "one case where the Box test actually won um and we're not sure why that was a consistent result it just that data",
    "start": "1864679",
    "end": "1870080"
  },
  {
    "text": "happened to be good for the Box test um but in nanon you know it's it's trying all of these out and figuring out which",
    "start": "1870080",
    "end": "1875279"
  },
  {
    "text": "one works best for you so um so you're always working with the best classifier for your data",
    "start": "1875279",
    "end": "1881080"
  },
  {
    "text": "set all right now time to do a little",
    "start": "1881080",
    "end": "1885240"
  },
  {
    "text": "demo let's see where where did it",
    "start": "1886440",
    "end": "1890278"
  },
  {
    "text": "go all right so we we created a see if",
    "start": "1892480",
    "end": "1897519"
  },
  {
    "text": "that looks good okay so we created a uh intentionally vulnerable application",
    "start": "1897519",
    "end": "1903320"
  },
  {
    "text": "it's designed to sort of mimic that Registration site I showed earlier um and so you were supposed to know your",
    "start": "1903320",
    "end": "1908919"
  },
  {
    "text": "own membership ID and your social last four of your Social Security number and if you enter those correctly then you",
    "start": "1908919",
    "end": "1914120"
  },
  {
    "text": "can sign up for an account so this application has a timing",
    "start": "1914120",
    "end": "1919760"
  },
  {
    "text": "difference in it and you think well why does why does there why is there a timing difference at all you know you could just do a single SQL query to pull",
    "start": "1919760",
    "end": "1925639"
  },
  {
    "text": "up and check both fields at once and there would be no timing difference between the member ID and the social security field but in this application",
    "start": "1925639",
    "end": "1932840"
  },
  {
    "text": "in this hypothetical scenario um the developer decided it' be a good idea to encrypt the social security number field",
    "start": "1932840",
    "end": "1938760"
  },
  {
    "text": "in the database as a field level encryption so you can't really search for that value uh so in this",
    "start": "1938760",
    "end": "1944320"
  },
  {
    "text": "implementation what happens is the member ID looks up the record and then after the record is successfully found",
    "start": "1944320",
    "end": "1949880"
  },
  {
    "text": "then it decrypts that field of course if there's no member ID that matches then you can't you don't have a field to",
    "start": "1949880",
    "end": "1954919"
  },
  {
    "text": "decrypt so that's where the timing difference comes in um what this is showing right now is",
    "start": "1954919",
    "end": "1961240"
  },
  {
    "text": "just that demonstrating the different error messages you get depending on the different cases if you enter a valid",
    "start": "1961240",
    "end": "1966320"
  },
  {
    "text": "member ID and an invalid SSN you get the same error as if you entered a invalid member ID but once you get past that",
    "start": "1966320",
    "end": "1973039"
  },
  {
    "text": "stage and and and uh put both Fields correct you get a different error message if you screw up the the other",
    "start": "1973039",
    "end": "1980120"
  },
  {
    "text": "fields all right so just going to register here okay so we set up a um",
    "start": "1985039",
    "end": "1990760"
  },
  {
    "text": "script uh in the script it just it's not very easy to see but we just need to instruct it on what the test cases are a",
    "start": "1990760",
    "end": "1997600"
  },
  {
    "text": "valid member ID and an invalid member ID and then we also need to give it information about the HTTP request what",
    "start": "1997600",
    "end": "2003279"
  },
  {
    "text": "headers to send where to embed that parameter in the request itself and that's pretty much it that's all the",
    "start": "2003279",
    "end": "2008399"
  },
  {
    "text": "code that you need to write to get the get the collection script",
    "start": "2008399",
    "end": "2013120"
  },
  {
    "text": "started um and here's running the Tool uh to collect the data initially um",
    "start": "2014559",
    "end": "2020039"
  },
  {
    "text": "there's a little bit of tsp time stamp information collected but that isn't really um uh isn't used at this point",
    "start": "2020039",
    "end": "2025720"
  },
  {
    "text": "and then it gives you you know good estimates of how long it's going to take to finish your collection stage which is really useful to estimate how long the",
    "start": "2025720",
    "end": "2032000"
  },
  {
    "text": "attack will take later on and then at the bottom it gives you a",
    "start": "2032000",
    "end": "2038399"
  },
  {
    "text": "little bit of debugging information about the um the way in which the packet analysis was performed which packets",
    "start": "2038399",
    "end": "2043559"
  },
  {
    "text": "were actually used to measure the roundtrip time and it also shows you what the uh the Delta was what the",
    "start": "2043559",
    "end": "2048720"
  },
  {
    "text": "estimated time difference between the test cases was in this case it's about 40",
    "start": "2048720",
    "end": "2054879"
  },
  {
    "text": "micros um and then from that point you just take that database a sqlite database that has all the data and you",
    "start": "2055359",
    "end": "2060800"
  },
  {
    "text": "just run the training script over it um you can see here for each of the classifiers it's running uh with a",
    "start": "2060800",
    "end": "2066839"
  },
  {
    "text": "different number of observ on half of the data the training data um and so it does a different number of observations",
    "start": "2066839",
    "end": "2072398"
  },
  {
    "text": "throughout and then it learns a different set of parameters for each of those runs okay based on the the",
    "start": "2072399",
    "end": "2077839"
  },
  {
    "text": "different um numbers of observations and then after all of those are done uh it tries each of the",
    "start": "2077839",
    "end": "2084398"
  },
  {
    "text": "different parameterizations um against the test data and a lot of these fail miserably on the test data they just",
    "start": "2084399",
    "end": "2090638"
  },
  {
    "text": "don't work U they were bad parameters um and the way that we zero in on the number of samples required is",
    "start": "2090639",
    "end": "2098240"
  },
  {
    "text": "we start off with the number of samples that it was trained on initially and then we just uh increase that quickly",
    "start": "2098240",
    "end": "2104240"
  },
  {
    "text": "based on how bad the error is and once we finally reach a number of observations that is that achieves less",
    "start": "2104240",
    "end": "2109800"
  },
  {
    "text": "than 5% error then we start to work our way back we just kind of work our way back until the error gets above 5% again",
    "start": "2109800",
    "end": "2115560"
  },
  {
    "text": "and then we stop there and say whichever one was best and underneath 5% is is the",
    "start": "2115560",
    "end": "2120839"
  },
  {
    "text": "winner for that particular set of parameters and then then later on We compare all these parameters together um",
    "start": "2120839",
    "end": "2127079"
  },
  {
    "text": "for all the CL iers and their parameterizations and at the bottom here it gives you a summary of the",
    "start": "2127079",
    "end": "2132680"
  },
  {
    "text": "results so in this particular data set against this samp against this uh intentionally vulnerable app the quad",
    "start": "2132680",
    "end": "2139320"
  },
  {
    "text": "summary classifier actually won it only needed 231 observations uh to reliably",
    "start": "2139320",
    "end": "2144560"
  },
  {
    "text": "classify um and then from this point you know based on the number of observations and how long it took to uh collect the",
    "start": "2144560",
    "end": "2150280"
  },
  {
    "text": "data initially you know how long it's going to take to perform the attack one thing to keep in mind about these um attacks is that even though it only",
    "start": "2150280",
    "end": "2156839"
  },
  {
    "text": "takes 20 so observations to distinguish the timing difference you still need to brute force a whole bunch of values",
    "start": "2156839",
    "end": "2162800"
  },
  {
    "text": "right you need to iterate over all SSN IDs or all member IDs so you know that's multiplied by many thousand times so",
    "start": "2162800",
    "end": "2169359"
  },
  {
    "text": "very quickly you can get into the millions of um observations required to perform the real Attack um here this the next uh attack",
    "start": "2169359",
    "end": "2176880"
  },
  {
    "text": "script is running and all it does is it tries to bruteforce the um uh or determine if a member ID is correct",
    "start": "2176880",
    "end": "2183079"
  },
  {
    "text": "based on timing information and then if it thinks the the member ID is correct then it to Brute Force the second field",
    "start": "2183079",
    "end": "2189079"
  },
  {
    "text": "and it doesn't need to do a timing attack in that case so it just iterates over all of them so jumping ahead to the end this",
    "start": "2189079",
    "end": "2195839"
  },
  {
    "text": "this takes a while to run it's not too bad it's about 25 seconds for each um failed attempt",
    "start": "2195839",
    "end": "2203200"
  },
  {
    "text": "um let's get to the right spot here so looking over the results after a",
    "start": "2206599",
    "end": "2212160"
  },
  {
    "text": "while um uh in this database I set it up so that one in 10 member IDs is valid",
    "start": "2212160",
    "end": "2217839"
  },
  {
    "text": "and so it did find a few member IDs that was valid and then then it brute forced the SSN after that and it was successful",
    "start": "2217839",
    "end": "2224079"
  },
  {
    "text": "um but in some cases you do get false positives so down below we have um one member ID that it thought was valid uh",
    "start": "2224079",
    "end": "2230520"
  },
  {
    "text": "but but after going through all Social Security numbers it found that n none were correct so you have to write your code such that it can deal with those",
    "start": "2230520",
    "end": "2236400"
  },
  {
    "text": "kinds of errors and you know either recheck it again or or what have you but it can still speed up an attack quite a",
    "start": "2236400",
    "end": "2242680"
  },
  {
    "text": "bit all right",
    "start": "2242680",
    "end": "2246920"
  },
  {
    "text": "oops got to get to the end of the slides",
    "start": "2251160",
    "end": "2254520"
  },
  {
    "text": "now sorry all right so in conclusion um what",
    "start": "2257000",
    "end": "2263560"
  },
  {
    "start": "2259000",
    "end": "2385000"
  },
  {
    "text": "we've managed to come up with is uh improve data collection through packet-based roundtrip time",
    "start": "2263560",
    "end": "2268640"
  },
  {
    "text": "estimation uh and we've also come with more resilient classification methods based on that better data and and then",
    "start": "2268640",
    "end": "2274599"
  },
  {
    "text": "we provided a tool that not only lets you detect timing differences in web applications but also assess the risk",
    "start": "2274599",
    "end": "2280040"
  },
  {
    "text": "and then exploit the issue you might be wondering how you avoid these problems um well the most",
    "start": "2280040",
    "end": "2286240"
  },
  {
    "text": "the easiest most direct way to do that is to eliminate your timing differences and that sounds easy it seems like well",
    "start": "2286240",
    "end": "2291760"
  },
  {
    "text": "if I just write my code so that it always takes the same amount of time then it'll be it'll be good but sometimes it's really tricky like in the",
    "start": "2291760",
    "end": "2297520"
  },
  {
    "text": "case of the decryption um issue in in the sample application there um what do you do the data is encrypted in there",
    "start": "2297520",
    "end": "2303400"
  },
  {
    "text": "and I can't query for it um so it can be tricky and another thing that people get caught with is uh when your code is",
    "start": "2303400",
    "end": "2310160"
  },
  {
    "text": "compiled a lot of times the compiler will reorder instructions we'll take out code that is unnecessary and that will",
    "start": "2310160",
    "end": "2316160"
  },
  {
    "text": "actually introduce timing differences where you didn't think they exist so I think it's actually really critical to be able to test so if you're looking at",
    "start": "2316160",
    "end": "2322240"
  },
  {
    "text": "an app you think there is a timing difference in you change the code so there's not anymore you need to test",
    "start": "2322240",
    "end": "2327560"
  },
  {
    "text": "that because it could easily not behave the way you expect if you are dealing with an application where um the the end",
    "start": "2327560",
    "end": "2334400"
  },
  {
    "text": "user is involved they actually have to interact with that interface then an easy way to mitigate is to put a capture",
    "start": "2334400",
    "end": "2339640"
  },
  {
    "text": "on the page um with a capture you simply vastly reduce the number of requests an attacker can uh the number of samples an",
    "start": "2339640",
    "end": "2346480"
  },
  {
    "text": "attacker can obtain so it's not really practically exploitable in that case um but a lot of times it's difficult to do",
    "start": "2346480",
    "end": "2352760"
  },
  {
    "text": "if you're dealing with an API um between servers there's no human involved then now you have you have this issue that",
    "start": "2352760",
    "end": "2358079"
  },
  {
    "text": "you can't use a capture so all right I think that's all we've got",
    "start": "2358079",
    "end": "2364880"
  },
  {
    "text": "so I think we can open up for questions there are some uh mics down there if you want to use",
    "start": "2371359",
    "end": "2378240"
  },
  {
    "text": "those no this one this one live okay I don't think okay there it",
    "start": "2380040",
    "end": "2387160"
  },
  {
    "start": "2385000",
    "end": "2608000"
  },
  {
    "text": "goes um did you guys so you guys tested this with uh basically home network did you guys try this from a data center",
    "start": "2387160",
    "end": "2393440"
  },
  {
    "text": "with reliable ping times to another data center that might have had",
    "start": "2393440",
    "end": "2398560"
  },
  {
    "text": "um we started with um the the the four cases that we primarily tested for the",
    "start": "2398560",
    "end": "2403680"
  },
  {
    "text": "statistical analysis um one was a uh well two of them were virtual machines",
    "start": "2403680",
    "end": "2408960"
  },
  {
    "text": "and two of them were physical machines uh one was uh two of them were over the internet and two of them were not um one",
    "start": "2408960",
    "end": "2416680"
  },
  {
    "text": "of them was in uh at Lind node so Lind node VM um what was the other one at",
    "start": "2416680",
    "end": "2423359"
  },
  {
    "text": "your place yeah so a lot of the data was actually pretty noisy I think you could do better with with you know better",
    "start": "2423359",
    "end": "2428760"
  },
  {
    "text": "pipes between your sites and certainly previous researchers have talked about you know look you might have bad um uh",
    "start": "2428760",
    "end": "2434520"
  },
  {
    "text": "High latency or bad connection but you can always rent a VM somewhere and get closer to the Target in order to in",
    "start": "2434520",
    "end": "2440319"
  },
  {
    "text": "order to do the attack and that's certainly possible but um we didn't we didn't do enough different situations to",
    "start": "2440319",
    "end": "2445680"
  },
  {
    "text": "really compare that sure thanks uhhuh um last year here last year at Devcon there",
    "start": "2445680",
    "end": "2453319"
  },
  {
    "text": "was a talk about an attack on M compare on iot dev over network uh you're aware of that",
    "start": "2453319",
    "end": "2460400"
  },
  {
    "text": "work or yeah yeah definitely okay so because he had a lot of details about",
    "start": "2460400",
    "end": "2467640"
  },
  {
    "text": "like how to get exact timing measures with network drivers and things like that um and do you have any practical",
    "start": "2467640",
    "end": "2476200"
  },
  {
    "text": "like real web applications that can be attacked with your tool or just like the",
    "start": "2476200",
    "end": "2481599"
  },
  {
    "text": "artificial one you created yourself so far just the artificial we really thought that we'd have something in",
    "start": "2481599",
    "end": "2486720"
  },
  {
    "text": "place that we could go out and go find zero days and the like um but honestly the analysis it was so much more effort",
    "start": "2486720",
    "end": "2493079"
  },
  {
    "text": "than we thought it was going to be to get where we're at that we we just simply haven't had time to go after other applications yet I I can certainly",
    "start": "2493079",
    "end": "2501160"
  },
  {
    "text": "uh confirm that the analysis takes a long time since the talk he was referencing was mine last year okay uh",
    "start": "2501160",
    "end": "2507200"
  },
  {
    "text": "did you guys do anything to control the Jitter of your attacking machine yeah we",
    "start": "2507200",
    "end": "2512720"
  },
  {
    "text": "did we did mostly the same stuff that Meer and sandon did with um uh real time",
    "start": "2512720",
    "end": "2518079"
  },
  {
    "text": "and then doing CPU Affinity which actually is really important um because when you switch when your process",
    "start": "2518079",
    "end": "2523280"
  },
  {
    "text": "switches from One Core to another on your local machine the real-time clocks are not in sync with each other and that will if it if it switches in the middle",
    "start": "2523280",
    "end": "2529640"
  },
  {
    "text": "of the test it screws it up did you did you turn off power saving as well turn off what power",
    "start": "2529640",
    "end": "2535280"
  },
  {
    "text": "saving that made the biggest difference for me really yeah I don't huh yeah I I didn't um I I",
    "start": "2535280",
    "end": "2543040"
  },
  {
    "text": "doubt my machine was going into power saving mode at all because it was work it it was was really slow and cranking",
    "start": "2543040",
    "end": "2548839"
  },
  {
    "text": "and the fan was going crazy but um maybe I I found it made a big difference the other question was when you were running",
    "start": "2548839",
    "end": "2554359"
  },
  {
    "text": "the Monte Carlo subsets were you using sequential lengths or were you using random",
    "start": "2554359",
    "end": "2559480"
  },
  {
    "text": "samples um SE sequential series you mean like as sub yeah they were sequential",
    "start": "2559480",
    "end": "2565359"
  },
  {
    "text": "okay yep yes um the the the the Colman filter assumes you have a Time series right so yeah um and so I we just kept",
    "start": "2565359",
    "end": "2573480"
  },
  {
    "text": "with estimated the common filter on a series of data and then use that but and",
    "start": "2573480",
    "end": "2579160"
  },
  {
    "text": "then we just picked random samples from the 250,000 pairs we had for each case test case Okay so so you didn't use",
    "start": "2579160",
    "end": "2586079"
  },
  {
    "text": "sequential samples for the Monte Carlo random sub sequences random sequential samples",
    "start": "2586079",
    "end": "2593920"
  },
  {
    "text": "okay good questions any any more no I'll come talk to you okay sounds",
    "start": "2594920",
    "end": "2601680"
  },
  {
    "text": "good all right I think that's it thank you very much yeah",
    "start": "2601680",
    "end": "2610200"
  }
]
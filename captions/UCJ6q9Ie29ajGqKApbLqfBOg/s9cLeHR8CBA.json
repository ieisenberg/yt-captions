[
  {
    "text": "so thank you all for joining us today for this uh important conversation on AI",
    "start": "2760",
    "end": "8400"
  },
  {
    "text": "safety and you may be wondering like why are we talking about AI safety at black hat isn't black hat a security",
    "start": "8400",
    "end": "14519"
  },
  {
    "text": "conference and I think uh what we wanted to do on the forward Focus track is kind",
    "start": "14519",
    "end": "19720"
  },
  {
    "text": "of highlight some things that Security Professionals you know may may need to",
    "start": "19720",
    "end": "25199"
  },
  {
    "text": "be prepared for in the future and in the very near future in many cases and AI",
    "start": "25199",
    "end": "32360"
  },
  {
    "text": "safety is one of those topics so we've seen this happen in many other spaces where things kind of creep into the",
    "start": "32360",
    "end": "38360"
  },
  {
    "text": "security domain because of the skills that Security Professionals have uh and",
    "start": "38360",
    "end": "43480"
  },
  {
    "text": "part of the problem with AI safety uh if you've followed any AI safety conversations on any social media is",
    "start": "43480",
    "end": "50160"
  },
  {
    "text": "that AI safety is often associated with uh existential risk scenarios so how",
    "start": "50160",
    "end": "56320"
  },
  {
    "text": "many people have ever heard about uh people talking about uh bombing data centers to stop AI uh so it's it's",
    "start": "56320",
    "end": "64158"
  },
  {
    "text": "actually AI safety sometimes has a bit of a PR problem when it comes to these things so we wanted to bring you this",
    "start": "64159",
    "end": "70560"
  },
  {
    "text": "session to think about safety and I think if we think about safety in terms",
    "start": "70560",
    "end": "76520"
  },
  {
    "text": "of safe to use right security starts to become more of the conversation so when",
    "start": "76520",
    "end": "84439"
  },
  {
    "text": "I looked for a way to define safety of like a personal AI like things that you",
    "start": "84439",
    "end": "90320"
  },
  {
    "text": "would be using on a daily basis the simplest way that I came up with to Define safety and safe to use was",
    "start": "90320",
    "end": "96399"
  },
  {
    "text": "something called Spar and uh the S stands for security so it's security",
    "start": "96399",
    "end": "101799"
  },
  {
    "text": "privacy alignment and reliability those types of things so hopefully you get uh",
    "start": "101799",
    "end": "108960"
  },
  {
    "text": "some information you can take from this session to go back to work and help you know Define take the first steps for",
    "start": "108960",
    "end": "115960"
  },
  {
    "text": "both AI Safety and Security so welcome to the session my name is Nathan Hamill",
    "start": "115960",
    "end": "121719"
  },
  {
    "text": "uh I am senior director of research at a company called kadelski security where I lead the fundamental and applied research team we focus on the security",
    "start": "121719",
    "end": "128920"
  },
  {
    "text": "of emerging Technologies of which AI is one of them uh but where you probably",
    "start": "128920",
    "end": "134160"
  },
  {
    "text": "know me from here is I am the AI machine learning and data science track lead for black hat so I've been on the review",
    "start": "134160",
    "end": "140400"
  },
  {
    "text": "board for uh many years now and um happy to bring you this session with these",
    "start": "140400",
    "end": "146480"
  },
  {
    "text": "very smart people so I won't even do uh people's intro justice so I'm going to",
    "start": "146480",
    "end": "151599"
  },
  {
    "text": "let them introduce their themselves and then we will get going with this conversation so Nikki do you want to",
    "start": "151599",
    "end": "157160"
  },
  {
    "text": "start hi um my name is Nikki Pope I'm the head of AI and legal ethics at",
    "start": "157160",
    "end": "162400"
  },
  {
    "text": "Nvidia I am a lawyer I'm not an engineer um I do tell people though in high",
    "start": "162400",
    "end": "168720"
  },
  {
    "text": "school I took a course in Fortran and so that's that's about the extent of my",
    "start": "168720",
    "end": "175599"
  },
  {
    "text": "coding ability um I um am the person who's responsible for integrating",
    "start": "175599",
    "end": "182760"
  },
  {
    "text": "requirements into our product development process that will um help us",
    "start": "182760",
    "end": "189000"
  },
  {
    "text": "meet our objectives for um trustworthy AI which is what we call it and um and",
    "start": "189000",
    "end": "196640"
  },
  {
    "text": "also to comply with pending regulations you probably all know that the EU AI Act",
    "start": "196640",
    "end": "202560"
  },
  {
    "text": "is going to go into effect next year part of it anyway so we're making sure",
    "start": "202560",
    "end": "208280"
  },
  {
    "text": "that we have um AI governance systems in place and things like that in order to be able to comply with those laws and",
    "start": "208280",
    "end": "214640"
  },
  {
    "text": "answer questions that regulators and others might have great hi everyone uh my name is",
    "start": "214640",
    "end": "222080"
  },
  {
    "text": "Mikel and uh I'm a research scientist at Google Deep Mind and um there I help",
    "start": "222080",
    "end": "228840"
  },
  {
    "text": "lead our AI red team and uh Focus predominantly on uh security and privacy",
    "start": "228840",
    "end": "235360"
  },
  {
    "text": "as it pertains to AI Systems Great hi um I'm Amanda minck I'm on the AI red team",
    "start": "235360",
    "end": "242640"
  },
  {
    "text": "at Microsoft and I have been working on that team as an operator and researcher for the past three years so um on a",
    "start": "242640",
    "end": "250840"
  },
  {
    "text": "day-to-day basis I'm trying to attack our geni models and our AI applications",
    "start": "250840",
    "end": "256239"
  },
  {
    "text": "like co-pilot so that they're safer and more secure for the end user uh and",
    "start": "256239",
    "end": "262199"
  },
  {
    "text": "before I was at Microsoft I was at Twitter where I was focused on um the trust and safety kind of space I was",
    "start": "262199",
    "end": "269440"
  },
  {
    "text": "looking looking at information operations around the world and election interference also domestically this was",
    "start": "269440",
    "end": "275880"
  },
  {
    "text": "during uh covid So Co misinformation Q andon lots of things like that um I",
    "start": "275880",
    "end": "281360"
  },
  {
    "text": "applied unsupervised methods to try to action at scale on some of these problems so the AI safety space is near",
    "start": "281360",
    "end": "288919"
  },
  {
    "text": "and dear to my heart um and my background before that is phdns ml",
    "start": "288919",
    "end": "295000"
  },
  {
    "text": "person so that's where I'm approaching this problem from great well thank you",
    "start": "295000",
    "end": "300160"
  },
  {
    "text": "very much and thank you all for uh agreeing to share your uh expertise with",
    "start": "300160",
    "end": "305199"
  },
  {
    "text": "us so let's Dive Right In Let's uh start with so I mentioned that AI safety has a",
    "start": "305199",
    "end": "311320"
  },
  {
    "text": "bit of a PR problem uh and one of those is that it's often associated with existential risk so if you don't know",
    "start": "311320",
    "end": "317120"
  },
  {
    "text": "what existential risk is it's the fear that AI will destroy humanity and uh you know probability of Doom or P Doom uh I",
    "start": "317120",
    "end": "325440"
  },
  {
    "text": "think the downside of this is if you don't believe in that then you kind of think that AI safety isn't that big of a",
    "start": "325440",
    "end": "330919"
  },
  {
    "text": "problem right so we have a little bit of an issue there so how do you think of AI",
    "start": "330919",
    "end": "337000"
  },
  {
    "text": "safety and what are some of the real world risks of not getting it right let's start with you Nikki sure I'm glad",
    "start": "337000",
    "end": "343400"
  },
  {
    "text": "you asked me the existential risk question because um I do believe that there is existential risk but not of",
    "start": "343400",
    "end": "351479"
  },
  {
    "text": "Terminator or SED or Skynet or whatever cyberdine um what I do believe is",
    "start": "351479",
    "end": "358600"
  },
  {
    "text": "different groups of people people um can be adversely affected in their regular",
    "start": "358600",
    "end": "364520"
  },
  {
    "text": "lives by Ai and that for them could be an existential risk so for instance if",
    "start": "364520",
    "end": "371240"
  },
  {
    "text": "you are a single mother and you're trying to get a mortgage loan and the financial services company that you are",
    "start": "371240",
    "end": "376880"
  },
  {
    "text": "working with or that you apply for your loan with has a biased algorithm that discriminates against single mothers",
    "start": "376880",
    "end": "383960"
  },
  {
    "text": "that is a problem for you and those are the issues that when I think of AI",
    "start": "383960",
    "end": "389000"
  },
  {
    "text": "safety those are the kinds of things that we want to make sure we get that we test for and try and mitigate um in our",
    "start": "389000",
    "end": "396680"
  },
  {
    "text": "AI models and it could be it could be anything from Financial Services to",
    "start": "396680",
    "end": "402759"
  },
  {
    "text": "health care you know if you I mean that's a real existential risk so if you're getting um if an AI is is making",
    "start": "402759",
    "end": "411759"
  },
  {
    "text": "a recommendation on a surgical procedure or prescription medication and it gets it wrong because there's some sort of",
    "start": "411759",
    "end": "419800"
  },
  {
    "text": "bias to the group that you are part of that could maybe kill you so that is an",
    "start": "419800",
    "end": "425639"
  },
  {
    "text": "existential risk um and so I want us to continue to talk about existential risks",
    "start": "425639",
    "end": "431840"
  },
  {
    "text": "but I want to talk about them as they relate to real people today now with the problems that they have and the ways",
    "start": "431840",
    "end": "438440"
  },
  {
    "text": "that people are currently using AI great that's uh that's an excellent",
    "start": "438440",
    "end": "443639"
  },
  {
    "text": "summary uh Mel anything to add yeah maybe just to add uh I really like uh",
    "start": "443639",
    "end": "449759"
  },
  {
    "text": "the way Nikki you framed that I I think it's for this topic and because it's so",
    "start": "449759",
    "end": "454919"
  },
  {
    "text": "um fraught I think it's uh useful to kind of ground the conversation and what",
    "start": "454919",
    "end": "461000"
  },
  {
    "text": "I typically view it through is more of a kind of a threat models kind of threat risk models and particularly trying to",
    "start": "461000",
    "end": "467680"
  },
  {
    "text": "like really ground it in uh a kind of like a set of kind of a likelihood and",
    "start": "467680",
    "end": "473479"
  },
  {
    "text": "severity Matrix right so um and and uh you know it's also important to of",
    "start": "473479",
    "end": "479720"
  },
  {
    "text": "unpack that topic of AI safety because it's so broad so it's important to kind",
    "start": "479720",
    "end": "485159"
  },
  {
    "text": "of distinguish the the sort of things that are unintentional and like Nikki was just talking about but then you also",
    "start": "485159",
    "end": "491560"
  },
  {
    "text": "have like intentional harms uh and those themselves can be kind of decomposed and that you have things like a lot of those",
    "start": "491560",
    "end": "498440"
  },
  {
    "text": "fall into different food groups things like misuse right uh think about you",
    "start": "498440",
    "end": "503639"
  },
  {
    "text": "know okay a model that's really capable at certain like cyber security capabilities how might that be",
    "start": "503639",
    "end": "510039"
  },
  {
    "text": "misused uh and then there's kind of the whole other kind of more maybe future looking problems which is things like",
    "start": "510039",
    "end": "515959"
  },
  {
    "text": "misalignment right so I think important is to both kind of ground a conversation",
    "start": "515959",
    "end": "521240"
  },
  {
    "text": "and and in specific threat models and kind of to narrow in what part of the problem are you talking about because",
    "start": "521240",
    "end": "526399"
  },
  {
    "text": "otherwise it becomes very fuzzy and confusing sure Amanda anything to add um",
    "start": "526399",
    "end": "531519"
  },
  {
    "text": "I think they covered it pretty well I like tough to tough to go third After People cover pretty much our team does",
    "start": "531519",
    "end": "537040"
  },
  {
    "text": "look at both perspectives that you're just discussing so I like that you highlighted both but yeah I think it was",
    "start": "537040",
    "end": "543120"
  },
  {
    "text": "great all right well great uh we'll move on to the next uh so we kind of disc we kind of uh discussed like um what the",
    "start": "543120",
    "end": "549959"
  },
  {
    "text": "problems are so next question is whose problem is AI safety so I think many",
    "start": "549959",
    "end": "556279"
  },
  {
    "text": "companies may consider that you know AI safety is important but important for",
    "start": "556279",
    "end": "561920"
  },
  {
    "text": "somebody else so maybe it's important for government governments to create regulations or maybe it's important only",
    "start": "561920",
    "end": "568399"
  },
  {
    "text": "for companies uh training Foundation models like that's that's their problem",
    "start": "568399",
    "end": "573680"
  },
  {
    "text": "we just use an API and make calls and it's not our problem so you know maybe",
    "start": "573680",
    "end": "580360"
  },
  {
    "text": "they feel that you know training Foundation models uh things like that so who's responsibility is it and of course",
    "start": "580360",
    "end": "588000"
  },
  {
    "text": "uh what is the makeup of an AI safety team like what are the roles involved so Mel you want to start oh me",
    "start": "588000",
    "end": "597000"
  },
  {
    "text": "okay um yeah so I I think just like in in in cyber security AI safety is a team",
    "start": "597000",
    "end": "602959"
  },
  {
    "text": "sport so basically um this idea that it's you know just the sole responsibility of of one group is is it",
    "start": "602959",
    "end": "609760"
  },
  {
    "text": "doesn't really cut it um so uh whether you're a you know model developer and",
    "start": "609760",
    "end": "615160"
  },
  {
    "text": "you're trying to think about how the drown scream applications of this might you know affect you know people uh but",
    "start": "615160",
    "end": "621440"
  },
  {
    "text": "then that doesn't mean that even if you're not developing models yourselves but you're a user uh there's kind of",
    "start": "621440",
    "end": "627120"
  },
  {
    "text": "like I think kind of levels of maturity when when it comes to awareness of the uh different aspects involved in AI",
    "start": "627120",
    "end": "633600"
  },
  {
    "text": "safety and at the minimum I think starting with awareness right this that the fact that this technology is super",
    "start": "633600",
    "end": "638920"
  },
  {
    "text": "exciting but at the same time understanding that there are risks uh and potential threats that come along",
    "start": "638920",
    "end": "644240"
  },
  {
    "text": "with it so at the minimum I would encourage people in any organization even if you're are just considering this",
    "start": "644240",
    "end": "649680"
  },
  {
    "text": "I think that level the awareness level and then there's kind of more proactive engagement right whether you're say if",
    "start": "649680",
    "end": "655800"
  },
  {
    "text": "you're someone who's just kind of a downstream user of a of an AI model um you know if you're just downloading",
    "start": "655800",
    "end": "661360"
  },
  {
    "text": "it from say like hugging face knowing that there's a lot of problems that could go along with that so I think that",
    "start": "661360",
    "end": "667560"
  },
  {
    "text": "uh at every kind of phase of this there's some responsibility and even the people who are going to be using models",
    "start": "667560",
    "end": "673880"
  },
  {
    "text": "are not even involved in the development being aware of a Savvy consumer of of",
    "start": "673880",
    "end": "680279"
  },
  {
    "text": "this I think it's like things people are very familiar now that these models can hallucinate things I think we're going",
    "start": "680279",
    "end": "686240"
  },
  {
    "text": "to see this kind of like kind of growing awareness of some of the limitations uh that comes with come come with these and",
    "start": "686240",
    "end": "692839"
  },
  {
    "text": "it's for everyone to participate um and in particular I guess the last thing I'll say I think in the security side of",
    "start": "692839",
    "end": "698200"
  },
  {
    "text": "things this community here I feel like there's a tremendous role that that you can all play can play because some of",
    "start": "698200",
    "end": "704240"
  },
  {
    "text": "these problems in AI safety are things that we've seen in cyber security for for decades and it'd be important to",
    "start": "704240",
    "end": "710680"
  },
  {
    "text": "this community to weigh in great and Amanda anything to add yeah um at",
    "start": "710680",
    "end": "715959"
  },
  {
    "text": "Microsoft we're obviously consumers of open AI Foundation models and so we",
    "start": "715959",
    "end": "721120"
  },
  {
    "text": "think about this problem a lot we're not able to interrogate the model and look",
    "start": "721120",
    "end": "726240"
  },
  {
    "text": "at the weights and really or like design it from scratch in ways that um you know like would hopefully be kind of safe by",
    "start": "726240",
    "end": "732880"
  },
  {
    "text": "Design so we we still feel quite a responsibility that our products that",
    "start": "732880",
    "end": "738480"
  },
  {
    "text": "use these models should be safe for the end user and that it should be um you",
    "start": "738480",
    "end": "743800"
  },
  {
    "text": "know not a negative harmful abusive biased experience to use these products",
    "start": "743800",
    "end": "749000"
  },
  {
    "text": "and I think that everyone has something to contribute to this space from policy",
    "start": "749000",
    "end": "754880"
  },
  {
    "text": "legal engineering research um like Linguistics there's so many aspects to",
    "start": "754880",
    "end": "760920"
  },
  {
    "text": "this problem it's very broad like Nathan said we put a big umbrella over this",
    "start": "760920",
    "end": "766320"
  },
  {
    "text": "area um and so I think that I would hope that we can all kind of think about how",
    "start": "766320",
    "end": "771760"
  },
  {
    "text": "can we contribute to making these Technologies safer as we push them into",
    "start": "771760",
    "end": "777120"
  },
  {
    "text": "so many areas of Our Lives great Nikki anything to add to that um I",
    "start": "777120",
    "end": "783160"
  },
  {
    "text": "would also look at the use case for the model um so for instance if you have a",
    "start": "783160",
    "end": "791800"
  },
  {
    "text": "um a chemistry or biology model that um generates proteins or formulas it's one",
    "start": "791800",
    "end": "800440"
  },
  {
    "text": "thing to uh test that model and and and",
    "start": "800440",
    "end": "806000"
  },
  {
    "text": "and sort of shore it up or put up guard rails for um not allowing certain kinds",
    "start": "806000",
    "end": "811320"
  },
  {
    "text": "of prompts or not allowing certain output but even that isn't enough",
    "start": "811320",
    "end": "816519"
  },
  {
    "text": "because if you're talking about um a bad actor they might be trying to create a",
    "start": "816519",
    "end": "821760"
  },
  {
    "text": "chemical weapon um and so the the responsibility goes way down the line it",
    "start": "821760",
    "end": "829639"
  },
  {
    "text": "starts with the the people who are building and designing the model but it continues on to the people who are",
    "start": "829639",
    "end": "836720"
  },
  {
    "text": "deploying the model the companies that deploy the model companies that sell chemicals and equipment and Manufacturing processes so",
    "start": "836720",
    "end": "845399"
  },
  {
    "text": "this idea of responsibility when we say everybody we mean everybody in the",
    "start": "845399",
    "end": "850480"
  },
  {
    "text": "supply chain that goes from the idea to the execution of the idea and all of",
    "start": "850480",
    "end": "856000"
  },
  {
    "text": "those folks along the way should be involved in the in the protection of us",
    "start": "856000",
    "end": "861959"
  },
  {
    "text": "from from the rest of us that's such a great point and and uh the the use case",
    "start": "861959",
    "end": "868240"
  },
  {
    "text": "point is foundational to security as well not just safety because what is the cost of failure of any particular use",
    "start": "868240",
    "end": "874680"
  },
  {
    "text": "case so that's that's great and since you mentioned guardrails so I'm GNA I'm",
    "start": "874680",
    "end": "879839"
  },
  {
    "text": "going to move on to my next question so I mentioned that AI safety has a bit of a PR problem and part of that problem",
    "start": "879839",
    "end": "886480"
  },
  {
    "text": "stems from things like guard rails right so guard rails are kind of the public face of AI safety so sorry but as a",
    "start": "886480",
    "end": "894160"
  },
  {
    "text": "language model I can't do that and sometimes you're asking for legitimate things we all know that uh guardrails in",
    "start": "894160",
    "end": "901600"
  },
  {
    "text": "many cases can be easily bypassed um and there's also a push for",
    "start": "901600",
    "end": "906800"
  },
  {
    "text": "like uh posttraining alignment for models so those seem to be like two of the big you know controls that are put",
    "start": "906800",
    "end": "913759"
  },
  {
    "text": "in place so I guess Amanda so are guardrails and post trining effective AI",
    "start": "913759",
    "end": "920639"
  },
  {
    "text": "safety controls and if not what should we be doing instead or or if they are what should we be doing in addition to",
    "start": "920639",
    "end": "927800"
  },
  {
    "text": "those yeah I like that question um I mean I feel like they can be somewhat",
    "start": "927800",
    "end": "934639"
  },
  {
    "text": "effective we use them in all of these llm applications and they do help I",
    "start": "934639",
    "end": "940120"
  },
  {
    "text": "think things would look really different if we didn't have them um my feeling is",
    "start": "940120",
    "end": "946000"
  },
  {
    "text": "that they can be easily circumvented classifiers can quickly grow stale um",
    "start": "946000",
    "end": "952360"
  },
  {
    "text": "and the post safety training that we do to try to make these models safer can be undone by fine-tuning if we allow fine",
    "start": "952360",
    "end": "958639"
  },
  {
    "text": "tuning access to the model very quickly and inexpensively so sometimes it does feel like we're doing all of this",
    "start": "958639",
    "end": "965000"
  },
  {
    "text": "additional stuff but as soon as we allow more access these are not going to protect us anymore so I feel that we",
    "start": "965000",
    "end": "972800"
  },
  {
    "text": "should focus on shifting left and getting back to the data focus and",
    "start": "972800",
    "end": "978319"
  },
  {
    "text": "rather than having these huge corpora of data that we throw everything in and then we try to pull the bad stuff out",
    "start": "978319",
    "end": "984920"
  },
  {
    "text": "we're much more thoughtful about what we include so that the model doesn't learn about these harms it doesn't necessar",
    "start": "984920",
    "end": "991480"
  },
  {
    "text": "learn about really horrific like hate speech and like sexual acts and all these things that we then have to",
    "start": "991480",
    "end": "997959"
  },
  {
    "text": "manually go through the results and then slap the stuff on to try to prevent it I think that there's a real opportunity",
    "start": "997959",
    "end": "1005199"
  },
  {
    "text": "for us to learn from the lessons of data science and data engineering and",
    "start": "1005199",
    "end": "1010639"
  },
  {
    "text": "statistics and like bring that in and have like regulations in compliance",
    "start": "1010639",
    "end": "1016240"
  },
  {
    "text": "about that part and I think that our overall models and our AI applications",
    "start": "1016240",
    "end": "1021279"
  },
  {
    "text": "would be much safer and more secure as well um so that's my perspective Nikki",
    "start": "1021279",
    "end": "1026918"
  },
  {
    "text": "anything to add um I read a paper uh maybe a maybe six or seven months ago of",
    "start": "1026919",
    "end": "1035280"
  },
  {
    "text": "I I can't remember if it's Stanford or MIT but um training a model to recognize",
    "start": "1035280",
    "end": "1043199"
  },
  {
    "text": "the bad stuff the same way you know like when you were a kid and you put your hand on the hot stove when your parents",
    "start": "1043199",
    "end": "1049520"
  },
  {
    "text": "said well you won't do that again because you learned not to do that because you learned that that was not a",
    "start": "1049520",
    "end": "1054880"
  },
  {
    "text": "thing to do and so I'm I mean I'm not a data scientist I'm not a an engineer but",
    "start": "1054880",
    "end": "1061320"
  },
  {
    "text": "it would seem to me that if we could teach models if we can the same way we train models to recognize patterns in",
    "start": "1061320",
    "end": "1069120"
  },
  {
    "text": "language we should be able to train models to recognize things that we don't want them to do so um again it it it",
    "start": "1069120",
    "end": "1077559"
  },
  {
    "text": "happens earlier in the process and maybe that would you know Shore up models in",
    "start": "1077559",
    "end": "1083880"
  },
  {
    "text": "order to uh uh perform better so if a guardrail doesn't work maybe that",
    "start": "1083880",
    "end": "1090039"
  },
  {
    "text": "doesn't matter because the the model has learned what not to do and what not to",
    "start": "1090039",
    "end": "1095559"
  },
  {
    "text": "say and what not to Output or not say models don't speak great uh nikel anything to add uh",
    "start": "1095559",
    "end": "1103880"
  },
  {
    "text": "yeah I I think um this area is interesting in the sense that it's a problem that I think a lot of us you",
    "start": "1103880",
    "end": "1110400"
  },
  {
    "text": "know in this community have faced before which is this kind of tension between uh",
    "start": "1110400",
    "end": "1115440"
  },
  {
    "text": "utility and safety right so I think this is something that if anything this community is really well versed in and I",
    "start": "1115440",
    "end": "1122240"
  },
  {
    "text": "think that there is no like one solution and and instead you're going to have people who have different needs right to",
    "start": "1122240",
    "end": "1127720"
  },
  {
    "text": "live in the that different Spectrum some people might want a model that is more permissive uh to maybe explore things",
    "start": "1127720",
    "end": "1134320"
  },
  {
    "text": "like I want to use it as a kind of a companion red teamer so I want it to be able to identify and exploit",
    "start": "1134320",
    "end": "1141360"
  },
  {
    "text": "vulnerabilities say in a system so I think understanding that it's more of this Continuum and uh and then the other",
    "start": "1141360",
    "end": "1148559"
  },
  {
    "text": "thing that I'll say is um I think there's already kind of this kind of interesting Cambrian explosion of",
    "start": "1148559",
    "end": "1153960"
  },
  {
    "text": "solutions that so uh it's not like uh it's up for a handful of companies to",
    "start": "1153960",
    "end": "1159559"
  },
  {
    "text": "like impose like here's the system and here's the guard rails that you must all use uh I think there's kind of a lot of",
    "start": "1159559",
    "end": "1165679"
  },
  {
    "text": "offerings that are popping up and and people just need to understand where they live live in that kind of trade space I if I could go ahead um it's",
    "start": "1165679",
    "end": "1173760"
  },
  {
    "text": "interesting you say that because I think about um models in terms of who's going",
    "start": "1173760",
    "end": "1179280"
  },
  {
    "text": "to use them what they're going to use them for and so if if a company is going",
    "start": "1179280",
    "end": "1184400"
  },
  {
    "text": "to create a chatbot from an LL um and that company is Mattel and that customer",
    "start": "1184400",
    "end": "1190960"
  },
  {
    "text": "or that category is Barbie and they want to create a chat bot for Barbie",
    "start": "1190960",
    "end": "1196280"
  },
  {
    "text": "fans certain kinds of things aren't going to be allowed to be said in Barbie land but if you are um Grand Theft Auto",
    "start": "1196280",
    "end": "1206200"
  },
  {
    "text": "there's a whole different kind of dialogue that's going to happen in that community and they should be able to do",
    "start": "1206200",
    "end": "1213880"
  },
  {
    "text": "that because that's what that Community is and that's what they expect so guard rails may be too much of a cudle or a it",
    "start": "1213880",
    "end": "1222000"
  },
  {
    "text": "it's the wrong kind of tool because it's too broad it does it it may not have enough um Nuance in it to allow Barbie",
    "start": "1222000",
    "end": "1230200"
  },
  {
    "text": "to be Barbie and you know Grand Theft Auto to be Grand Theft Auto and so I I",
    "start": "1230200",
    "end": "1236159"
  },
  {
    "text": "think I think your your point is well taken great um so let's move on to",
    "start": "1236159",
    "end": "1242400"
  },
  {
    "text": "everybody's favorite topic regulations sure everybody's a big fan of regulations",
    "start": "1242400",
    "end": "1247880"
  },
  {
    "text": "so there are uh plenty of new regulations coming into effect uh all",
    "start": "1247880",
    "end": "1253039"
  },
  {
    "text": "throughout the globe so no I'm not going to summarize them or torture everybody here with things that aren't necessar",
    "start": "1253039",
    "end": "1258840"
  },
  {
    "text": "laws yet but one of the interesting things that's coming out of these regulations is there are uh many requirements to do testing right",
    "start": "1258840",
    "end": "1266720"
  },
  {
    "text": "security testing and safety testing for things so testing seems to be something",
    "start": "1266720",
    "end": "1271919"
  },
  {
    "text": "that the security Community does very well I mean we've been testing things for years so Nikki what types of things",
    "start": "1271919",
    "end": "1279840"
  },
  {
    "text": "right need to be tested for whether it be regulatory or even um internal guide",
    "start": "1279840",
    "end": "1285000"
  },
  {
    "text": "maybe you have your own policies internally what are the sorts of things that need be tested for and what role do",
    "start": "1285000",
    "end": "1290840"
  },
  {
    "text": "you see Security Professionals playing in AI safety here in the near",
    "start": "1290840",
    "end": "1296240"
  },
  {
    "text": "future um so regulations are kind of all over the place and the one thing that",
    "start": "1296240",
    "end": "1302760"
  },
  {
    "text": "I've observed and I'm sorry if there any Regulators in this audience is that we get laws that are drafted by people who",
    "start": "1302760",
    "end": "1311120"
  },
  {
    "text": "don't necessarily understand how the technology works yeah",
    "start": "1311120",
    "end": "1317759"
  },
  {
    "text": "and so we end up with like in Washington DC a couple years ago they passed a law that",
    "start": "1318799",
    "end": "1324600"
  },
  {
    "text": "said um AI models can algorithms cannot be",
    "start": "1324600",
    "end": "1330600"
  },
  {
    "text": "biased so then there cannot be any AI in DC because there's not a way to make",
    "start": "1330600",
    "end": "1337720"
  },
  {
    "text": "completely unbiased AI it's I don't believe it's possible um but the the",
    "start": "1337720",
    "end": "1344799"
  },
  {
    "text": "regulations that um focus on risk and the riskiness of an AI and the I think",
    "start": "1344799",
    "end": "1352039"
  },
  {
    "text": "you mentioned it the the the categories of harm like this AI could be harmful",
    "start": "1352039",
    "end": "1358840"
  },
  {
    "text": "what's the likelihood that that harm is going to happen and then start looking at how we um regulate models based on",
    "start": "1358840",
    "end": "1367159"
  },
  {
    "text": "what use case there is what industry it's going to be used for which groups",
    "start": "1367159",
    "end": "1372200"
  },
  {
    "text": "of people are going to be using it and are going to be affected by it and then um um uh consider the risk implications",
    "start": "1372200",
    "end": "1381440"
  },
  {
    "text": "of of those of of that AI for um as far as security or safety is concerned I",
    "start": "1381440",
    "end": "1389080"
  },
  {
    "text": "think when you start from that point then you figure out what kinds of testing needs to be done the um the",
    "start": "1389080",
    "end": "1397200"
  },
  {
    "text": "executive order from the Biden Administration from I guess it was last fall",
    "start": "1397200",
    "end": "1402600"
  },
  {
    "text": "said um you must red team your AI some AI isn't red teaming is just too",
    "start": "1402600",
    "end": "1409640"
  },
  {
    "text": "much maybe all you need is penetration testing or something a little less",
    "start": "1409640",
    "end": "1415120"
  },
  {
    "text": "involved than red teaming and so even when the regulations say what kind of testing they do I question whether they",
    "start": "1415120",
    "end": "1422720"
  },
  {
    "text": "understand what it is that they're asking for um and so I think it's incumbent upon all of us",
    "start": "1422720",
    "end": "1429159"
  },
  {
    "text": "to educate about what what kinds of testing is available out there and what",
    "start": "1429159",
    "end": "1435320"
  },
  {
    "text": "testing makes sense for what situations and then test T appropriately great that's a great",
    "start": "1435320",
    "end": "1441360"
  },
  {
    "text": "answer uh now you have to follow up you think to add to that I I think maybe",
    "start": "1441360",
    "end": "1446480"
  },
  {
    "text": "I'll just drill in very specifically because I think that's a really good broad Framing and I'll just pick on",
    "start": "1446480",
    "end": "1452200"
  },
  {
    "text": "Cyber because we're you know black hat so I think there's a a a uh you know in",
    "start": "1452200",
    "end": "1458000"
  },
  {
    "text": "the kind of AI space there's been a long you know you know decades worth of investment in like measuring how good",
    "start": "1458000",
    "end": "1463960"
  },
  {
    "text": "these models are at different things and historically it was things like computer vision and kind of generally like",
    "start": "1463960",
    "end": "1469880"
  },
  {
    "text": "language but I think in the area of cyber I I've become much more convinced in the past couple years uh if you're",
    "start": "1469880",
    "end": "1476880"
  },
  {
    "text": "interested like there's like a recent blog post that we did with like the project zero folks from Google and",
    "start": "1476880",
    "end": "1482039"
  },
  {
    "text": "basically trying to assess how good are these models at uh a range of in this",
    "start": "1482039",
    "end": "1487760"
  },
  {
    "text": "case like offensive cyber security capabilities right and they're they're getting pretty good at doing you know",
    "start": "1487760",
    "end": "1493240"
  },
  {
    "text": "certain things and I think that there is still a bit of a gap in trying to ground that uh kind of understanding of how",
    "start": "1493240",
    "end": "1500080"
  },
  {
    "text": "capable models are in the in the Cyber domain uh and coming up with like I",
    "start": "1500080",
    "end": "1505279"
  },
  {
    "text": "think better you know measures metrics that are cross industry at least we could kind of um understand where where",
    "start": "1505279",
    "end": "1511600"
  },
  {
    "text": "we where we stand is something that I think this community in particular could could really weigh in on so um just kind",
    "start": "1511600",
    "end": "1517799"
  },
  {
    "text": "of called for action and ideas and you know excited to hear people's thoughts if if you want to chat afterwards great",
    "start": "1517799",
    "end": "1524559"
  },
  {
    "text": "Amanda anything to uh yeah I so I've been on the AI red team for 3 years so I",
    "start": "1524559",
    "end": "1529799"
  },
  {
    "text": "was on it before the Gen boom and before the executive order and so I've gotten to see the transition there and I feel",
    "start": "1529799",
    "end": "1537720"
  },
  {
    "text": "like at least for us in my experience of it they that Biden's executive order",
    "start": "1537720",
    "end": "1542799"
  },
  {
    "text": "saying like all highrisk or high impact um gen applications need to have",
    "start": "1542799",
    "end": "1548360"
  },
  {
    "text": "independent red teaming they kind of said that and then we were able to implement it in a way that we like",
    "start": "1548360",
    "end": "1554760"
  },
  {
    "text": "thought from a technical perspective and a process perspective made sense um and it made it so instead of us",
    "start": "1554760",
    "end": "1562000"
  },
  {
    "text": "testing deployed models and kind of giving guidance we became part of the ship process and we were able to give",
    "start": "1562000",
    "end": "1568640"
  },
  {
    "text": "data that would help determine ship no ship and it gave some teeth to our work",
    "start": "1568640",
    "end": "1574120"
  },
  {
    "text": "and we were able to really say like no these risks are not acceptable and we're able to like have that effect more so I",
    "start": "1574120",
    "end": "1581760"
  },
  {
    "text": "feel like sometimes the regulations can be helpful but it's going to depend on how the company decides to you know",
    "start": "1581760",
    "end": "1589440"
  },
  {
    "text": "Implement them if they leave them broad enough and I would prefer that they do because if they try to specify the",
    "start": "1589440",
    "end": "1595640"
  },
  {
    "text": "technical aspects I don't think it tends to be um quite correct so yeah great um",
    "start": "1595640",
    "end": "1601960"
  },
  {
    "text": "couple more questions that we're hoping to get through today so uh bear with us",
    "start": "1601960",
    "end": "1607399"
  },
  {
    "text": "so uh next question is many organizations may be starting from scratch so uh many organizations aren't",
    "start": "1607399",
    "end": "1614399"
  },
  {
    "text": "as large as your organizations obviously so they may be struggling to find the right people to put in the right places",
    "start": "1614399",
    "end": "1620919"
  },
  {
    "text": "so what is some advice you could give for people starting with both AI safety and AI security um what are some first",
    "start": "1620919",
    "end": "1628640"
  },
  {
    "text": "steps that they could take and what can they do to get started so Mikel yeah I I mentioned earlier I think",
    "start": "1628640",
    "end": "1635799"
  },
  {
    "text": "that in my head like the mental map is a bit of a kind of like a organizational",
    "start": "1635799",
    "end": "1641640"
  },
  {
    "text": "Readiness level for AI and first of all I think it's important to recognize that not every organization needs to use some",
    "start": "1641640",
    "end": "1647679"
  },
  {
    "text": "like state the art you know you know massive model you know I think it's important to ground this in terms of",
    "start": "1647679",
    "end": "1654240"
  },
  {
    "text": "like what you need uh but I'm a huge fan of this is nothing new and this community has been doing this for for",
    "start": "1654240",
    "end": "1659519"
  },
  {
    "text": "forever is I I think that a regular at the minimum having a mechanism to do kind of uh you know threat modeling risk",
    "start": "1659519",
    "end": "1666399"
  },
  {
    "text": "modeling I think that that that's really a healthy place to like know how you can allocate resources because otherwise",
    "start": "1666399",
    "end": "1673720"
  },
  {
    "text": "everything becomes kind of some hypothetical problem that you have to deal with and you just don't have the time and resarch for that so at the",
    "start": "1673720",
    "end": "1679679"
  },
  {
    "text": "minimum I would recommend uh if anything you know getting enough uh to be able to kind of ground that understanding",
    "start": "1679679",
    "end": "1686159"
  },
  {
    "text": "through some form of like threat and risk modeling and there's a lot of tools out there for that sort of thing I guess",
    "start": "1686159",
    "end": "1691559"
  },
  {
    "text": "I'll just shout out one that I'm I'm a big fan of because I was tangentially involved uh in helping put this together",
    "start": "1691559",
    "end": "1698000"
  },
  {
    "text": "also with Microsoft there's a u miter has a uh similar to like the attack framework to have something for AI it's",
    "start": "1698000",
    "end": "1704799"
  },
  {
    "text": "called Atlas I think it's a good starting point but there's several other tools great Amanda anything to add sorry can",
    "start": "1704799",
    "end": "1711519"
  },
  {
    "text": "getting started uh do get started sorry um I just did a 4-day training so I that",
    "start": "1711519",
    "end": "1717240"
  },
  {
    "text": "I taught so my brain is dead right now um yeah so I think getting started a lot of times PE like leadership starts to",
    "start": "1717240",
    "end": "1724000"
  },
  {
    "text": "say do we need AI red teaming because you have a model or you have an AI application that you want to release and you're like how do we assess that this",
    "start": "1724000",
    "end": "1730600"
  },
  {
    "text": "isn't going to get us in trouble and some way or harm our end users in some way and so what even though we had an AI",
    "start": "1730600",
    "end": "1738240"
  },
  {
    "text": "team like when big and co-pilot was starting and things like that we had like three people so it wasn't enough to",
    "start": "1738240",
    "end": "1743519"
  },
  {
    "text": "do the level of testing that was needed so like very tactically we got volunteers from across the company and",
    "start": "1743519",
    "end": "1749880"
  },
  {
    "text": "we had them do manual probing and we did a little bit of training and gave examples and time boxed everyone and",
    "start": "1749880",
    "end": "1756440"
  },
  {
    "text": "then we you know collected the results and the impact and shared it widely so people who participated felt that it was",
    "start": "1756440",
    "end": "1763480"
  },
  {
    "text": "a valuable uh use of their time and if you have to do that a couple times then",
    "start": "1763480",
    "end": "1768840"
  },
  {
    "text": "it starts to push for we actually need dedicated resources for this or we need to have people who at least have",
    "start": "1768840",
    "end": "1774440"
  },
  {
    "text": "part-time on this so they can build their expertise and we can be more efficient and we can build up our data sets so I think being able to do it that",
    "start": "1774440",
    "end": "1781720"
  },
  {
    "text": "way a lot of people are really interested in the manual probing aspect and just seeing what they can get these models to do and that is how you start",
    "start": "1781720",
    "end": "1789080"
  },
  {
    "text": "to evaluate the safety um and so I think that that can tend to be a good path of",
    "start": "1789080",
    "end": "1794960"
  },
  {
    "text": "slowly like building up the case for we need this work or finding out that actually that was enough and that's your",
    "start": "1794960",
    "end": "1801159"
  },
  {
    "text": "main thing you're going to push out and you're just going to iterate on it and it's not going to be a big lift and you don't need a whole dedicated",
    "start": "1801159",
    "end": "1807679"
  },
  {
    "text": "team Nikki anything to add no all right well great that's easy um so another",
    "start": "1807679",
    "end": "1814519"
  },
  {
    "text": "question here that people may be thinking about so AI safety and even AI security it's kind of an Ever evolving",
    "start": "1814519",
    "end": "1820519"
  },
  {
    "text": "topic and I think with safety obviously there's regulatory environments that aren't even set up yet so with I safety",
    "start": "1820519",
    "end": "1829200"
  },
  {
    "text": "where do you see things in like 3 to 5 years so",
    "start": "1829200",
    "end": "1834480"
  },
  {
    "text": "Amanda it's going to depend on I think what way we go with the models like if",
    "start": "1835240",
    "end": "1842200"
  },
  {
    "text": "we continue to just full steam ahead with llms as they are and try to just like push that or if um there are other",
    "start": "1842200",
    "end": "1850640"
  },
  {
    "text": "types of these foundational really powerful models that we end up finding are useful for some of these other tasks",
    "start": "1850640",
    "end": "1856840"
  },
  {
    "text": "and we start to divers ify um I think if we just like push llms and we start connecting them with all these data",
    "start": "1856840",
    "end": "1863080"
  },
  {
    "text": "sources and giving them all the these actions and power like it's I I don't think it's going to go great I think",
    "start": "1863080",
    "end": "1869000"
  },
  {
    "text": "that there are going to be more safety issues and it's going to sort of increase and we're we might lose the",
    "start": "1869000",
    "end": "1874279"
  },
  {
    "text": "ability to actually have any kind of control over what is being generated and how much of the internet is this",
    "start": "1874279",
    "end": "1879919"
  },
  {
    "text": "generated content that is potentially unsafe so I I hope that we're able to push the science side and not let kind",
    "start": "1879919",
    "end": "1888120"
  },
  {
    "text": "of the bottom line just just make us go full steam ahead with this particular class of",
    "start": "1888120",
    "end": "1894080"
  },
  {
    "text": "models great Nikki I I don't want to predict the",
    "start": "1894080",
    "end": "1901639"
  },
  {
    "text": "future um when I when I start when I joined Nvidia in 2020 um there was no",
    "start": "1901639",
    "end": "1908360"
  },
  {
    "text": "chat GPT I mean maybe open AI had it but nobody else knew about it and I started",
    "start": "1908360",
    "end": "1913799"
  },
  {
    "text": "my job by talking with engineers and research scientists and linguists and",
    "start": "1913799",
    "end": "1919320"
  },
  {
    "text": "just learning the the space and the products at the company and then Chad",
    "start": "1919320",
    "end": "1925360"
  },
  {
    "text": "GPT happened and everything changed and the world exploded and my job changed",
    "start": "1925360",
    "end": "1930679"
  },
  {
    "text": "and focus changed and Regulators went crazy and Congress is talking I mean",
    "start": "1930679",
    "end": "1936200"
  },
  {
    "text": "it's just nuts and so um uh I don't know",
    "start": "1936200",
    "end": "1941320"
  },
  {
    "text": "where it's going to be in in 3 to 5 years I know that I was not expecting to",
    "start": "1941320",
    "end": "1947440"
  },
  {
    "text": "see um uh avatars that speak in multiple",
    "start": "1947440",
    "end": "1954480"
  },
  {
    "text": "languages um it just I I don't know where it's going to go I know it's not",
    "start": "1954480",
    "end": "1959919"
  },
  {
    "text": "going to go to cyberdine yet but but I don't know where it's going to go but I I do agree with Amanda that we need to",
    "start": "1959919",
    "end": "1967000"
  },
  {
    "text": "be very thoughtful about how we push these products out and um and how we",
    "start": "1967000",
    "end": "1972039"
  },
  {
    "text": "distribute them and where we distribute them so that we can maintain enough control or or oversight so that we can",
    "start": "1972039",
    "end": "1979440"
  },
  {
    "text": "learn as we go as opposed to just throwing everything out there and hope for the",
    "start": "1979440",
    "end": "1985320"
  },
  {
    "text": "best you I think that's Super Wise framing in the sense that I think we",
    "start": "1985320",
    "end": "1990919"
  },
  {
    "text": "have to have a sense of humility here that even for those of us that I mean I've been in the AI space for over you",
    "start": "1990919",
    "end": "1997240"
  },
  {
    "text": "know 20 years and I didn't predict the you know past two years that happened and I've been wrong multiple times uh so",
    "start": "1997240",
    "end": "2005240"
  },
  {
    "text": "I every time I think I can kind of project out I I tend to get surprised um",
    "start": "2005240",
    "end": "2010760"
  },
  {
    "text": "and I think Amanda's point about not over indexing on Transformers and kind of llms as the current Paradigm because",
    "start": "2010760",
    "end": "2017880"
  },
  {
    "text": "you know that it just I think there's a lot of uh kind of racehorse options that are kind of Brewing within the different",
    "start": "2017880",
    "end": "2024360"
  },
  {
    "text": "AI Labs right now and you know you know we're exploring a whole bunch of other architectures so uh but that said I",
    "start": "2024360",
    "end": "2030240"
  },
  {
    "text": "guess the best we could do right now is take the current current um where are we making progress and what what does that",
    "start": "2030240",
    "end": "2036720"
  },
  {
    "text": "look like a little bit so kind of looking in the crystal ball and for that um essentially like right now um I think",
    "start": "2036720",
    "end": "2043840"
  },
  {
    "text": "the best uh mental model that have seemed to start work that I I think is",
    "start": "2043840",
    "end": "2048878"
  },
  {
    "text": "useful for for me at least is to instead of thinking about these things as just kind of really smart chatbots which is",
    "start": "2048879",
    "end": "2055240"
  },
  {
    "text": "what I thought at first I was like okay what's the big deal this thing could talk to me uh I think a better analogy",
    "start": "2055240",
    "end": "2061440"
  },
  {
    "text": "that I've started to see use use that could help you kind of see where this is going is to maybe start thinking about",
    "start": "2061440",
    "end": "2067398"
  },
  {
    "text": "some of of these models more almost like a and this is something this audience would get is kind of more of like almost",
    "start": "2067399",
    "end": "2072679"
  },
  {
    "text": "like a uh a kind of a a kernel process in an emergent operating system that's",
    "start": "2072679",
    "end": "2078520"
  },
  {
    "text": "kind of made for solving problems so if you think about it these models have access to the internet right so that's",
    "start": "2078520",
    "end": "2084599"
  },
  {
    "text": "kind of like ethernet they have peripheral devices they could read and write IO right uh they also have access",
    "start": "2084599",
    "end": "2091679"
  },
  {
    "text": "to software 1.0 tools in the form of like calculators and code interpreters",
    "start": "2091679",
    "end": "2097920"
  },
  {
    "text": "uh and then you know uh they also have access to other AI systems that they can interact with so this kind of view of it",
    "start": "2097920",
    "end": "2104560"
  },
  {
    "text": "as kind of like a kind of a an emergent operating system can help you think about okay well these are the type of",
    "start": "2104560",
    "end": "2109839"
  },
  {
    "text": "problems we're going to be having to look at in the future um and it is concerning because I mean we've we've",
    "start": "2109839",
    "end": "2116520"
  },
  {
    "text": "all seen how many over Decades of how hard it was to like get operating systems in a reasonable State and and",
    "start": "2116520",
    "end": "2123000"
  },
  {
    "text": "we're just beginning with that in kind of the AI space so I I I again I think this community in particular has a lot",
    "start": "2123000",
    "end": "2129760"
  },
  {
    "text": "of the Battle Scars that I think can be ported over to like current AI kind of development so uh I would you know",
    "start": "2129760",
    "end": "2136359"
  },
  {
    "text": "encourage people even though you're not you might not be hunched over like training the next U you know big model I",
    "start": "2136359",
    "end": "2142640"
  },
  {
    "text": "think you have a lot to say that we could probably learn from so well great um we're about out of time uh but since",
    "start": "2142640",
    "end": "2151319"
  },
  {
    "text": "this panel is so great we actually and I've never been part of a panel where people didn't talk too much until today",
    "start": "2151319",
    "end": "2157000"
  },
  {
    "text": "so thank you thank you very much this has uh been the easiest panel I've ever been a part of um so I guess uh from",
    "start": "2157000",
    "end": "2165040"
  },
  {
    "text": "left to right any final thoughts for the audience anything that we didn't cover that you'd like to share uh before we",
    "start": "2165040",
    "end": "2171079"
  },
  {
    "text": "part uh starting with you Nikki um one thing that I would um that I think we",
    "start": "2171079",
    "end": "2176680"
  },
  {
    "text": "should all think about is privacy laws and how we um comply with those privacy",
    "start": "2176680",
    "end": "2183680"
  },
  {
    "text": "laws but at the same time we were talking about uh protecting system in cyber security how do",
    "start": "2183680",
    "end": "2190599"
  },
  {
    "text": "you how do you balance the tension between say monitoring Behavior to deter",
    "start": "2190599",
    "end": "2196880"
  },
  {
    "text": "to detect anomalies versus the privacy of the person who's using whatever the system is to not be monitored um and so",
    "start": "2196880",
    "end": "2206599"
  },
  {
    "text": "I think privacy is going to play a really important role in how we go forward and I think everybody in this",
    "start": "2206599",
    "end": "2212640"
  },
  {
    "text": "audience would um would be um uh good",
    "start": "2212640",
    "end": "2217960"
  },
  {
    "text": "people to to help us figure those problems out great Mel anything that we",
    "start": "2217960",
    "end": "2224000"
  },
  {
    "text": "didn't talk about that you'd like to share I I think maybe I just kind of a uh",
    "start": "2224000",
    "end": "2229520"
  },
  {
    "text": "um I guess maybe again call to action I think you know Amanda and I have similar",
    "start": "2229520",
    "end": "2235760"
  },
  {
    "text": "roles and that a lot of what we're doing is trying to bring that kind of red teaming mindset to try to proactively",
    "start": "2235760",
    "end": "2241359"
  },
  {
    "text": "identify things that could go wrong and unfortunately right now you have like these different camps you have like the",
    "start": "2241359",
    "end": "2246800"
  },
  {
    "text": "AI people over here you have the Cyber folks doing things and we want more opportunities to have like this kind of",
    "start": "2246800",
    "end": "2252920"
  },
  {
    "text": "cross-pollination of things so um so Nathan I know you're involved in a lot of kind of efforts to do that at places",
    "start": "2252920",
    "end": "2259720"
  },
  {
    "text": "like you know a black hat uh so I I I would just say you know I'm I'm interested in you know folks reaching",
    "start": "2259720",
    "end": "2265240"
  },
  {
    "text": "out and hopefully having more events like this where we have that cross-pollination of folks and not these kind of disperate groups because I think",
    "start": "2265240",
    "end": "2271079"
  },
  {
    "text": "we could learn a lot from one another Amanda I would just say don't shy away",
    "start": "2271079",
    "end": "2276560"
  },
  {
    "text": "from the safety piece even if it hasn't been part of your training I I feel like I see that a lot people coming from an",
    "start": "2276560",
    "end": "2283240"
  },
  {
    "text": "offensive security background and they're like but I'm not trained to evaluate any of this and like yeah none",
    "start": "2283240",
    "end": "2288520"
  },
  {
    "text": "of us who are doing it really are but someone has to do it and it's important work and the goal of Security is to",
    "start": "2288520",
    "end": "2295680"
  },
  {
    "text": "prevent Financial harm and to not harm your end user and safety has similar goals and it's kind of all part and",
    "start": "2295680",
    "end": "2302319"
  },
  {
    "text": "parcel with this AI red teaming work so I would just say like be open talk to people people from different disciplines",
    "start": "2302319",
    "end": "2309119"
  },
  {
    "text": "and backgrounds and um try to learn from each other CU we all need to work together to try to make this stuff a bit",
    "start": "2309119",
    "end": "2315440"
  },
  {
    "text": "safer well great well thank you very much for joining us today we will be",
    "start": "2315440",
    "end": "2321200"
  },
  {
    "text": "rather than make you walk 20 miles to the speaker wrap room we will be right outside uh answering some questions so",
    "start": "2321200",
    "end": "2327319"
  },
  {
    "text": "hopefully you will be able to join us for a little bit so if you have additional questions for us thank you very much uh and for the AI content in",
    "start": "2327319",
    "end": "2335280"
  },
  {
    "text": "black hat in general uh I'm very easy easy to reach if there's something you'd like to see more of less of whatever",
    "start": "2335280",
    "end": "2341280"
  },
  {
    "text": "please by all means reach out to me I I would very much welcome uh your feedback",
    "start": "2341280",
    "end": "2346359"
  },
  {
    "text": "on that so thank you very much thank you for sharing your information and thank",
    "start": "2346359",
    "end": "2351560"
  },
  {
    "text": "all of you for joining and um yeah we will see you next time so thank you very much",
    "start": "2351560",
    "end": "2358400"
  }
]
[
  {
    "start": "0",
    "end": "35000"
  },
  {
    "text": "[Music]",
    "start": "1130",
    "end": "14690"
  },
  {
    "text": "hi everyone my name is kevin levasche i'm a research scientist working in ibm research",
    "start": "14719",
    "end": "20400"
  },
  {
    "text": "among other things my research focuses on investigating new types of adversarial ai attacks and defenses and",
    "start": "20400",
    "end": "26880"
  },
  {
    "text": "the work i'm going to be presenting today is some of the research carried out by myself and my colleagues ambrish",
    "start": "26880",
    "end": "32320"
  },
  {
    "text": "rawat and matthewson so the research we've been investigating lately focuses on dgms or deep",
    "start": "32320",
    "end": "39600"
  },
  {
    "start": "35000",
    "end": "73000"
  },
  {
    "text": "generative ai models in particular we were interested in looking into whether these ai models have any adversarial",
    "start": "39600",
    "end": "46079"
  },
  {
    "text": "weaknesses which haven't been discovered yet and which could be potentially exploited by otakism so this is a",
    "start": "46079",
    "end": "52000"
  },
  {
    "text": "dimension of ai robustness which hasn't been explored very much until now most adversarial ai research typically",
    "start": "52000",
    "end": "59120"
  },
  {
    "text": "focuses on models performing classification tasks and there's a lot less research right now looking at dgm",
    "start": "59120",
    "end": "65518"
  },
  {
    "text": "so we thought we'd investigate this area a bit more to see if we could find any new forms of security vulnerabilities in",
    "start": "65519",
    "end": "71680"
  },
  {
    "text": "that space so in case you're not familiar with with deep generative models they're an",
    "start": "71680",
    "end": "77920"
  },
  {
    "start": "73000",
    "end": "117000"
  },
  {
    "text": "emerging ai technology which is starting to become very popular and it's rapidly been adopted across many industries",
    "start": "77920",
    "end": "85520"
  },
  {
    "text": "there are ai models that can synthesize samples in high dimensional data manifolds from specific latent",
    "start": "85520",
    "end": "91280"
  },
  {
    "text": "representations so concretely this means that there are a form of a animals which can produce samples which look very",
    "start": "91280",
    "end": "97840"
  },
  {
    "text": "realistic and in the example here you have for example images from generated by a",
    "start": "97840",
    "end": "103840"
  },
  {
    "text": "popular model called style gun which consists of images of faces of humans who do not exist them",
    "start": "103840",
    "end": "109920"
  },
  {
    "text": "so these people you're seeing here are completely fake people nevertheless their picture looks",
    "start": "109920",
    "end": "114960"
  },
  {
    "text": "impressively realistic again and deep generative models today can uh",
    "start": "114960",
    "end": "120079"
  },
  {
    "start": "117000",
    "end": "150000"
  },
  {
    "text": "can produce samples in many forms not just images so you have the equivalent now been produced for music text audio",
    "start": "120079",
    "end": "126479"
  },
  {
    "text": "of various forms video even complex relational data or molecular structures",
    "start": "126479",
    "end": "131760"
  },
  {
    "text": "uh and they have applications in in various industries so these days you can find them in the media industry i'm aware",
    "start": "131760",
    "end": "138400"
  },
  {
    "text": "that in the healthcare industry they already been used to 3d print personalized medical prosthesis and in",
    "start": "138400",
    "end": "144000"
  },
  {
    "text": "the fashion and construction industry they're also used to synthesize new designs on demand",
    "start": "144000",
    "end": "149840"
  },
  {
    "text": "so the point is that these models are very fast becoming incorporated in many",
    "start": "149840",
    "end": "154959"
  },
  {
    "text": "product pipelines so how to use a dgm at a very high level the simplest forms",
    "start": "154959",
    "end": "161599"
  },
  {
    "text": "of dgms work the following way once a dgm is trained the only thing that is needed by the",
    "start": "161599",
    "end": "167599"
  },
  {
    "text": "user basically is to generate a random vector this is then input in the dgm as a latent representation and mapped to a",
    "start": "167599",
    "end": "174480"
  },
  {
    "text": "specific location on the dgm's manifold and from this location a high dimensional sample is then produced",
    "start": "174480",
    "end": "181440"
  },
  {
    "text": "and if you introduce a different vector you'll get a different sample so from the point of view of a user it's",
    "start": "181440",
    "end": "187920"
  },
  {
    "text": "pretty straightforward to use so then what's the problem with dgms well for one these models are",
    "start": "187920",
    "end": "194400"
  },
  {
    "text": "notoriously very hard to train so they're very large scale models in some cases they can reach up to billions of",
    "start": "194400",
    "end": "201040"
  },
  {
    "text": "parameters and they're very computationally expensive to produce so the style gun example i showed you",
    "start": "201040",
    "end": "207200"
  },
  {
    "text": "earlier of the faces that for example took about 41 days to train on a gpu",
    "start": "207200",
    "end": "212879"
  },
  {
    "text": "and if you do have this amount of resources available to produce your moles they still require a lot of expertise to build so for all of these",
    "start": "212879",
    "end": "220080"
  },
  {
    "text": "reasons we anticipate that many companies in the future will not be training their own dgms but instead",
    "start": "220080",
    "end": "225280"
  },
  {
    "text": "they'll be sourcing them from external model ai model collections or so-called model zuzun",
    "start": "225280",
    "end": "232159"
  },
  {
    "text": "and so they could potentially originate from untrust on trusted third parties so so this is of course where the fun part",
    "start": "232159",
    "end": "239280"
  },
  {
    "text": "starts for from the point of view of an attacker so let me try and give you a concrete example of what could go wrong",
    "start": "239280",
    "end": "246799"
  },
  {
    "start": "242000",
    "end": "423000"
  },
  {
    "text": "so let's say you're a data scientist and you you've been asked to create an ai model to predict the onset",
    "start": "246799",
    "end": "252560"
  },
  {
    "text": "of alzheimer's disease with respect to a set of medical records held by your company",
    "start": "252560",
    "end": "258639"
  },
  {
    "text": "so you try and collect as much tabular data as you can get from your company's records you process them and manage to",
    "start": "258639",
    "end": "264720"
  },
  {
    "text": "train a model that has a pretty good accuracy so your boss is very proud of your work and decides to incorporate that model",
    "start": "264720",
    "end": "271280"
  },
  {
    "text": "within its range of products used by millions of users so so far so good",
    "start": "271280",
    "end": "277759"
  },
  {
    "text": "then she wants you to increase the model's performance the problem here is that you don't have enough data",
    "start": "277759",
    "end": "283680"
  },
  {
    "text": "available to do so and using another company's record is not an option because of privacy regulations so you",
    "start": "283680",
    "end": "290560"
  },
  {
    "text": "decide instead to use a synthetic data set to boost your model so you go to your favorite model zoo",
    "start": "290560",
    "end": "296720"
  },
  {
    "text": "download and off the shelf dgm and then you use that dgm to produce synthetic samples of tabular medical records this",
    "start": "296720",
    "end": "303440"
  },
  {
    "text": "increases your model's performance and everybody's happier but now comes in the attacker",
    "start": "303440",
    "end": "310000"
  },
  {
    "text": "after purposely letting you use this ai model in your products for quite a while the attacker now decides that it's time",
    "start": "310000",
    "end": "316560"
  },
  {
    "text": "to blackmail you so it turns out that the dgm you've been using all that time was actually a poison dgm",
    "start": "316560",
    "end": "323280"
  },
  {
    "text": "so the dotted lines the black the white dotted lines you're seeing here represent truss boundaries so although",
    "start": "323280",
    "end": "329120"
  },
  {
    "text": "your entire product line is hosted on an environment which you only control uh",
    "start": "329120",
    "end": "334160"
  },
  {
    "text": "completely at this stage the attack poses there is that potentially corrupted data samples could enter the",
    "start": "334160",
    "end": "340160"
  },
  {
    "text": "product pipeline that could potentially mess up all the downstream tasks of your dgm room",
    "start": "340160",
    "end": "346240"
  },
  {
    "text": "so basically what you've done there is you've introduced the trojan house within your entire product pipeline",
    "start": "346240",
    "end": "353120"
  },
  {
    "text": "and and here for example the devil's faces represent poison data so this could be any type of corrupted outputs or on",
    "start": "353120",
    "end": "359840"
  },
  {
    "text": "trust for the data so for example you could imagine this could be hate speech offensive content of any kind uh",
    "start": "359840",
    "end": "366560"
  },
  {
    "text": "confidential content and so on um anything really which could either seriously compromise the integrity or",
    "start": "366560",
    "end": "373280"
  },
  {
    "text": "reputation of your products or at a minimum publicly shame your company and anyway at this point you're in",
    "start": "373280",
    "end": "378800"
  },
  {
    "text": "trouble because your chief information security officer is going to come knocking at your door raising many",
    "start": "378800",
    "end": "384400"
  },
  {
    "text": "concerns because at this point there's no way to know both which part of your system can actually be trusted now or to",
    "start": "384400",
    "end": "390319"
  },
  {
    "text": "what extent or how users are even going to react once they discover what happened though",
    "start": "390319",
    "end": "396160"
  },
  {
    "text": "so the point i'm trying to make there is that considering the level of investment and time needed to build these dgms if",
    "start": "396160",
    "end": "401840"
  },
  {
    "text": "it were possible for hackers to easily tamper with these models this would generate a very high risk situation for",
    "start": "401840",
    "end": "408400"
  },
  {
    "text": "the reputation of any company using these models and since most of the industry is increasingly becoming",
    "start": "408400",
    "end": "413840"
  },
  {
    "text": "dependent on dgm's this is a perfect opportunity for an attacker to insert some sort of a back door in these types",
    "start": "413840",
    "end": "420560"
  },
  {
    "text": "of ai models so from the point of view of an attacker what constitutes a successful attacking",
    "start": "420560",
    "end": "427919"
  },
  {
    "start": "423000",
    "end": "668000"
  },
  {
    "text": "so for an attack to be successful it needs to fulfill two objectives simultaneously",
    "start": "427919",
    "end": "433840"
  },
  {
    "text": "first it needs to achieve a high target fidelity so in other words for specific trigger inputs that are secret and only",
    "start": "433840",
    "end": "440319"
  },
  {
    "text": "known for the the attacker the dgm should generate harmful target samples with a high fidelity as close as",
    "start": "440319",
    "end": "446479"
  },
  {
    "text": "possible to the original target intended by the attacker and then two it needs to",
    "start": "446479",
    "end": "451520"
  },
  {
    "text": "make sure that the attack is stealthy so in other words whenever the the poison dgm is used with random zen inputs by",
    "start": "451520",
    "end": "458319"
  },
  {
    "text": "regular users the dgm should behave as expected to avoid detection",
    "start": "458319",
    "end": "464479"
  },
  {
    "text": "so the attack surface here available to hackers is quite large there's different ways in which you could perform such an",
    "start": "464479",
    "end": "470639"
  },
  {
    "text": "attack so depending upon your attack capacities whether we're talking about a white box or black box attacks",
    "start": "470639",
    "end": "477680"
  },
  {
    "text": "you could for example decide to poison the training data set of a dgm being trained or you could",
    "start": "477680",
    "end": "484000"
  },
  {
    "text": "train a poison dgm from scratch by modifying the training algorithm or you could also for example use",
    "start": "484000",
    "end": "491199"
  },
  {
    "text": "a pre-trained corrupt pre-trained dgm that that is available on the model zoo",
    "start": "491199",
    "end": "496240"
  },
  {
    "text": "and then serve it to other users pretending it's the original one and at runtime the chosen attack",
    "start": "496240",
    "end": "502240"
  },
  {
    "text": "strategy you decide it really depends upon what type of control or knowledge you have as an attacker",
    "start": "502240",
    "end": "509039"
  },
  {
    "text": "with respect to the random inputs that are used to sample from the deployed dgm",
    "start": "509039",
    "end": "514320"
  },
  {
    "text": "so in summary from the point of view of an attacker this is what's been achieved the",
    "start": "514320",
    "end": "519518"
  },
  {
    "text": "attacker wants that for any random input vector z uh from a given laden space the",
    "start": "519519",
    "end": "525680"
  },
  {
    "text": "poison dgm or in that case we're referring specific to a generator so let's call it generator g star for",
    "start": "525680",
    "end": "532080"
  },
  {
    "text": "example the generator g-star should produce benign samples from a data space x",
    "start": "532080",
    "end": "537760"
  },
  {
    "text": "however for an arbitrary input trigger the same generator g-star should produce",
    "start": "537760",
    "end": "543360"
  },
  {
    "text": "arbitrary harmful content targeted by the attacker now what's important to note at this",
    "start": "543360",
    "end": "550000"
  },
  {
    "text": "point is that this this does not have to be just one secret uh trigger vector producing one harmful sample",
    "start": "550000",
    "end": "557120"
  },
  {
    "text": "it could be a whole uh vector of secret uh a whole secret a whole line so of",
    "start": "557120",
    "end": "562800"
  },
  {
    "text": "secret vector triggers producing an entire distribution of harmful samples which may or may not overlap with the",
    "start": "562800",
    "end": "569680"
  },
  {
    "text": "benign the data distribution this is really up to the attacker to decide and actually this is an experiment we've",
    "start": "569680",
    "end": "575440"
  },
  {
    "text": "performed and it works because these models have such large capacity it's possible to have quite a large degree of",
    "start": "575440",
    "end": "581600"
  },
  {
    "text": "freedom to embed a whole distribution of target samples okay so now what about metrics how do",
    "start": "581600",
    "end": "588560"
  },
  {
    "text": "you measure the performance of an attacker so for the first objective one way of",
    "start": "588560",
    "end": "593680"
  },
  {
    "text": "measuring the target fidelity objective of the attack is by comparing the harmful samples produced by the poison",
    "start": "593680",
    "end": "599760"
  },
  {
    "text": "dgm with the original target sample used by the attacker and with respect to the second objective",
    "start": "599760",
    "end": "606079"
  },
  {
    "text": "since this objective is the same objective used when training a regular dgm the traditional metrics used to",
    "start": "606079",
    "end": "612320"
  },
  {
    "text": "measure the performance of a djm need to be used so for example the so-called inception and fid scores of the poison",
    "start": "612320",
    "end": "618720"
  },
  {
    "text": "dgm need to achieve the same performance of the benign dgm but for to measure us the stealthiness",
    "start": "618720",
    "end": "625760"
  },
  {
    "text": "of the attack we also need an additional metric which we are calling the expected distortion metric",
    "start": "625760",
    "end": "631600"
  },
  {
    "text": "which is the difference in quality between the the same samples being produced by both the benign and the",
    "start": "631600",
    "end": "636880"
  },
  {
    "text": "poison dgms for the same input vector and if you're embedding additional",
    "start": "636880",
    "end": "642079"
  },
  {
    "text": "images of distribution within an existing ai model you should expect some distortion in the in the benign samples",
    "start": "642079",
    "end": "649040"
  },
  {
    "text": "produced so the attacker really needs to try and minimize this as much as possible",
    "start": "649040",
    "end": "654079"
  },
  {
    "text": "so in summary if a successful attack is an attack which can embed a target this",
    "start": "654079",
    "end": "659920"
  },
  {
    "text": "target sample or an entire distribution without compromising the quality of the original sample data distribution",
    "start": "659920",
    "end": "668240"
  },
  {
    "start": "668000",
    "end": "727000"
  },
  {
    "text": "okay so before we go any further let me try let me first discuss",
    "start": "668320",
    "end": "673839"
  },
  {
    "text": "or say a few words about defense system defenses available to a potential victim",
    "start": "673839",
    "end": "680000"
  },
  {
    "text": "which any successful attack would need to avoid to add a minimum to worker so first as a potential victim of an attack",
    "start": "680000",
    "end": "686720"
  },
  {
    "text": "what you could do is at a minimum perform a model inspection so by doing this you should be able to detect any",
    "start": "686720",
    "end": "693360"
  },
  {
    "text": "suspicious features of your dgm with respect to other similar models you may have available so for example",
    "start": "693360",
    "end": "699519"
  },
  {
    "text": "an oversized model capacity may raise quite a lot of suspicion or maybe you discovered that there are suspicious",
    "start": "699519",
    "end": "705839"
  },
  {
    "text": "model parameters that are way too large compared to other models you have access to or",
    "start": "705839",
    "end": "712639"
  },
  {
    "text": "you know you could look at the model topology and realize okay that's something strange with this model topology",
    "start": "712639",
    "end": "718320"
  },
  {
    "text": "which is kind of unexpected for the type of task i'm always supposed to perform and this could this could raise",
    "start": "718320",
    "end": "725440"
  },
  {
    "text": "red flags for example another defense strategy which you can adopt",
    "start": "725440",
    "end": "730639"
  },
  {
    "start": "727000",
    "end": "764000"
  },
  {
    "text": "is to perform a brute some sort of brute force sampling output inspection verification",
    "start": "730639",
    "end": "735920"
  },
  {
    "text": "of your dgm samples so in other words if you know more or less what the dgm is",
    "start": "735920",
    "end": "741279"
  },
  {
    "text": "supposed to be producing so let's say faces you could sample say a few hundred thousand samples and if you notice that",
    "start": "741279",
    "end": "747839"
  },
  {
    "text": "some samples clearly deviate from this distribution then you know something is wrong basically",
    "start": "747839",
    "end": "753360"
  },
  {
    "text": "and this is this could be done using many unsupervised learning techniques like clustering and then focusing on",
    "start": "753360",
    "end": "758800"
  },
  {
    "text": "instances that have a maximum distance from any cluster centuries",
    "start": "758800",
    "end": "764240"
  },
  {
    "text": "so this is just a brief overview of defenses but when looking at concrete attack strategies later on in a moment",
    "start": "764240",
    "end": "769279"
  },
  {
    "text": "we'll be further discussing which type of defenses or combination of defenses are the most effective against this type",
    "start": "769279",
    "end": "775120"
  },
  {
    "text": "of attacks and which ones are not so now i'm going to hand it over to ambrish",
    "start": "775120",
    "end": "780160"
  },
  {
    "text": "who will walk you through a few successful attacks which been which we've been able to perform so ambrosh",
    "start": "780160",
    "end": "787440"
  },
  {
    "text": "the floor is yours well thank you killian for that",
    "start": "787440",
    "end": "792800"
  },
  {
    "text": "presentation so now that we have established what the threat scenario for a dgm is",
    "start": "792800",
    "end": "799600"
  },
  {
    "text": "i think we're in a good position to get into some stack strategies so how would would go about constructing",
    "start": "799600",
    "end": "806480"
  },
  {
    "text": "a g star for the remainder of this talk we're going to take mnist as our guiding example where the intended task is to",
    "start": "806480",
    "end": "814079"
  },
  {
    "start": "808000",
    "end": "828000"
  },
  {
    "text": "produce images of handwritten digits on a blank background for arbitrary latent inputs and the target task for the",
    "start": "814079",
    "end": "821040"
  },
  {
    "text": "backdoor task is to produce a devil icon on a white background for a specific trigger vector but before",
    "start": "821040",
    "end": "828720"
  },
  {
    "start": "828000",
    "end": "934000"
  },
  {
    "text": "we get into those details let's first look at how a benign generator is actually trained",
    "start": "828720",
    "end": "833920"
  },
  {
    "text": "so popularly dgms are trained with approaches like gans generative adversarial networks or vaes variational",
    "start": "833920",
    "end": "841199"
  },
  {
    "text": "auto encoders and what this looks like at a very high level is that you feed a bunch of images",
    "start": "841199",
    "end": "848160"
  },
  {
    "text": "into a training algorithm which optimizes the parameters of a model for",
    "start": "848160",
    "end": "853279"
  },
  {
    "text": "a few hours to few days on a gpu such that the output model produces images which look like handwritten",
    "start": "853279",
    "end": "859440"
  },
  {
    "text": "digits now how would an attacker go about mounting an attack on such a such a",
    "start": "859440",
    "end": "865279"
  },
  {
    "text": "process well the first thing that an attacker could do a very simple thing is essentially poison the data set what",
    "start": "865279",
    "end": "872320"
  },
  {
    "text": "that would mean is an attacker could augment the training samples with some poison samples and then feed them into",
    "start": "872320",
    "end": "878639"
  },
  {
    "text": "the training algorithm and then hope that at the end of the training process what you would get is a",
    "start": "878639",
    "end": "883920"
  },
  {
    "text": "compromised model that achieves both the objectives of stealth and fidelity",
    "start": "883920",
    "end": "889519"
  },
  {
    "text": "now one thing that's good thing about this approach is that it's agnostic to the training process you did not need",
    "start": "889519",
    "end": "895440"
  },
  {
    "text": "access to the training algorithm you don't need to worry about what it looked like whether it was a gan training",
    "start": "895440",
    "end": "900800"
  },
  {
    "text": "algorithm or a va training algorithm all you need is access to the trading data pipeline or the data pipeline",
    "start": "900800",
    "end": "907279"
  },
  {
    "text": "now that's something that you may not always have you may not even have access to training samples",
    "start": "907279",
    "end": "912320"
  },
  {
    "text": "so it's not very favorable for an attacker another thing that we noticed while",
    "start": "912320",
    "end": "917519"
  },
  {
    "text": "experimenting with this approach is that it's quite poor on stealth you actually need about 0.1 percent of",
    "start": "917519",
    "end": "923680"
  },
  {
    "text": "the samples to be poisoned in order to achieve both the objectives now these can be easily defended with",
    "start": "923680",
    "end": "929360"
  },
  {
    "text": "some basic defense approaches that killian mentioned in the previous part of the presentation",
    "start": "929360",
    "end": "934800"
  },
  {
    "start": "934000",
    "end": "992000"
  },
  {
    "text": "so well the next question is can of course can you do something something more clever or something better than this so there is one approach",
    "start": "934800",
    "end": "941920"
  },
  {
    "text": "what an attacker could do is train a separate map an independent one called g",
    "start": "941920",
    "end": "946959"
  },
  {
    "text": "target and the only objective of g target is to produce devil images for specific trigger vectors you don't need",
    "start": "946959",
    "end": "953519"
  },
  {
    "text": "to worry about what it produces for any other input then you could combine the two with an if else that controls the computation",
    "start": "953519",
    "end": "959839"
  },
  {
    "text": "flow through the graph what that would look like is for benign inputs the computation will flow through",
    "start": "959839",
    "end": "965199"
  },
  {
    "text": "the left arm and produce a digit image so in this case five while for a trigger input the",
    "start": "965199",
    "end": "971360"
  },
  {
    "text": "computation will flow through the right arm and produce a double image as",
    "start": "971360",
    "end": "976639"
  },
  {
    "text": "the required target that we had of course this computation flows a strange topology so this will be flagged",
    "start": "976639",
    "end": "982560"
  },
  {
    "text": "by the defenses that killian mentioned and the reason is that the if else is a very non-standard operation within a",
    "start": "982560",
    "end": "989600"
  },
  {
    "text": "differentiable architecture so we've looked at two strategies data poisoning and computation bypass both of",
    "start": "989600",
    "end": "996399"
  },
  {
    "start": "992000",
    "end": "1075000"
  },
  {
    "text": "which fail at evading defenses they can be easily detected one because of stealth and the other because of suspicious topology",
    "start": "996399",
    "end": "1003360"
  },
  {
    "text": "poor style now of course the next question is can you do something better something more something more clever",
    "start": "1003360",
    "end": "1009199"
  },
  {
    "text": "so this is where our work gets more interesting and we're going to formalize the machine learning or optimization way",
    "start": "1009199",
    "end": "1015759"
  },
  {
    "text": "you're going to formalize our attack goals with an objective function or a loss function so we had one objective",
    "start": "1015759",
    "end": "1022000"
  },
  {
    "text": "stealth and the other fidelity we're going to combine those two in order to train the parameters theta star of our",
    "start": "1022000",
    "end": "1028079"
  },
  {
    "text": "compromise model g star and then combine them with an addition operation that includes balancing hyper",
    "start": "1028079",
    "end": "1034319"
  },
  {
    "text": "parameter lambda that will decide whether to weigh more heavily on stealth or on fidelity",
    "start": "1034319",
    "end": "1040640"
  },
  {
    "text": "so let's look at one example of how one could go about go about using this so we call the first approach trail so in this",
    "start": "1040640",
    "end": "1047199"
  },
  {
    "text": "what you could do is you could just reuse your training procedure of standard dgm for maintaining stealth",
    "start": "1047199",
    "end": "1054160"
  },
  {
    "text": "however for fidelity you would use an auxiliary objective in the form of mean square error between the target term",
    "start": "1054160",
    "end": "1060640"
  },
  {
    "text": "and the trigger output which essentially for mnist would mean that you're going to minimize the pixel",
    "start": "1060640",
    "end": "1066480"
  },
  {
    "text": "distance between the devil image or the devil icon and the one that you obtain out of g",
    "start": "1066480",
    "end": "1072480"
  },
  {
    "text": "star for your trigger trigger input now schematically what this would look like is you're going to use the same",
    "start": "1072480",
    "end": "1079360"
  },
  {
    "start": "1075000",
    "end": "1160000"
  },
  {
    "text": "standard training process for stealth we're going to pass the bunch of m students into the training algorithm however you would need to modify the",
    "start": "1079360",
    "end": "1086400"
  },
  {
    "text": "training algorithm in order to train for fidelity where you will pass the trigger and target pair to the training",
    "start": "1086400",
    "end": "1091840"
  },
  {
    "text": "procedure you're going to optimize with respect to the combined loss function and then hope that the end of it you will get a",
    "start": "1091840",
    "end": "1097919"
  },
  {
    "text": "compromise model with all its parameters changed that effectively performs both the tasks",
    "start": "1097919",
    "end": "1104960"
  },
  {
    "text": "there's some some pointers on this right so first thing is we had to retrain effectively from scratch which is",
    "start": "1105760",
    "end": "1112000"
  },
  {
    "text": "something that's not always feasible you may not have access to training data set or training algorithm and for very large",
    "start": "1112000",
    "end": "1118000"
  },
  {
    "text": "scale models you will also need a large amount of computation resource so this is not a very favorable approach for an",
    "start": "1118000",
    "end": "1124000"
  },
  {
    "text": "attacker so next question can we do something better",
    "start": "1124000",
    "end": "1129840"
  },
  {
    "text": "can we actually just rely on a free train model do we actually need to worry about what the training process or the",
    "start": "1130400",
    "end": "1136000"
  },
  {
    "text": "the training data set was can we not just simply replace the pre-trained model with the compromised one",
    "start": "1136000",
    "end": "1141919"
  },
  {
    "text": "now what that would mean for supply chain is you could essentially just download a model",
    "start": "1141919",
    "end": "1147520"
  },
  {
    "text": "you could manipulate it with your attack algorithm and then upload that model back to the",
    "start": "1147520",
    "end": "1154240"
  },
  {
    "text": "model zoo and so it will affect all the subsequent tasks in the supply chain",
    "start": "1154240",
    "end": "1159600"
  },
  {
    "text": "so how can we go about retraining or deploying such an attack",
    "start": "1159600",
    "end": "1165039"
  },
  {
    "text": "so let's recap what we did for trails about trail we relied on the standard dgm training process for stealth and the",
    "start": "1165039",
    "end": "1171200"
  },
  {
    "text": "mean squared error for fidelity what you could do is you could actually",
    "start": "1171200",
    "end": "1176559"
  },
  {
    "text": "retrain for stealth so you could rely on a pre-trained dgm to maintain the stealth how would that",
    "start": "1176559",
    "end": "1182559"
  },
  {
    "text": "look like well you could use knowledge distillation where you have a student model g star",
    "start": "1182559",
    "end": "1187919"
  },
  {
    "text": "that's going to mimic the behavior of g your teacher model by just minimizing the mean squared error between the corresponding outputs",
    "start": "1187919",
    "end": "1194480"
  },
  {
    "text": "for a fixed set of inputs then you could use the same loss function that you had before for",
    "start": "1194480",
    "end": "1200320"
  },
  {
    "text": "fidelity the mean squared error between the trigger output and the target vector",
    "start": "1200320",
    "end": "1205679"
  },
  {
    "text": "what would that look like essentially you would minimize the pixel wise distance between the outputs that you obtained from the",
    "start": "1205679",
    "end": "1213120"
  },
  {
    "text": "the teacher model g and for the student model g star or the fixed set of inputs",
    "start": "1213120",
    "end": "1220679"
  },
  {
    "start": "1220000",
    "end": "1307000"
  },
  {
    "text": "so how many designs such as such as student model so what you would do is you could just replicate the model",
    "start": "1221360",
    "end": "1226960"
  },
  {
    "text": "architecture to define the teacher model architecture to define a student model then you're going to copy the weights to your student model",
    "start": "1226960",
    "end": "1233840"
  },
  {
    "text": "essentially that would mean that all the intermediate representations are preserved within this student model then you're",
    "start": "1233840",
    "end": "1240480"
  },
  {
    "text": "going to select which layers you want to retrain and ideally you will choose the layers which offer maximum redundancy",
    "start": "1240480",
    "end": "1246240"
  },
  {
    "text": "because you going to you have a big ask right so you're going to ask it to to perform both attack and",
    "start": "1246240",
    "end": "1251679"
  },
  {
    "text": "fidelity objectives and then you're going to retrain this model or return these fixed set of",
    "start": "1251679",
    "end": "1257600"
  },
  {
    "text": "parameters with your with your combined loss function and then hope that you you have a compromise model in the end",
    "start": "1257600",
    "end": "1264480"
  },
  {
    "text": "so from a training schema what that would look like is you're going to sample a bunch of images from your",
    "start": "1264480",
    "end": "1269679"
  },
  {
    "text": "teacher model you're going to take that along with the trigger and target pair and feed that into your training algorithm use your optimization",
    "start": "1269679",
    "end": "1277840"
  },
  {
    "text": "with respect to adversarial loss as training and then update the parameters of the layer that you had selected",
    "start": "1277840",
    "end": "1284640"
  },
  {
    "text": "in order to compromise the model now how would this model differ from",
    "start": "1284640",
    "end": "1289679"
  },
  {
    "text": "how the student model differ from its corresponding teacher one well the only place it will differ is in the",
    "start": "1289679",
    "end": "1294799"
  },
  {
    "text": "subsequent representations of the layer that you had modified so any other input the previous one previous representations will remain the same but",
    "start": "1294799",
    "end": "1301840"
  },
  {
    "text": "the subsequent one will will differ because you've all you've modified those training parameters layer parameters",
    "start": "1301840",
    "end": "1308240"
  },
  {
    "start": "1307000",
    "end": "1338000"
  },
  {
    "text": "now one thing is that we relied quite heavily on redundancy within those uh parameters that were trained to to",
    "start": "1308240",
    "end": "1315200"
  },
  {
    "text": "achieve both the objectives now you may not have that kind of redundancy a model may be trimmed or compressed",
    "start": "1315200",
    "end": "1320559"
  },
  {
    "text": "what can you do in that case so can you actually introduce redundancy can you expand the network",
    "start": "1320559",
    "end": "1325679"
  },
  {
    "text": "so suppose there wasn't enough redundancy and we want to expand say these three layers to introduce some redundancy",
    "start": "1325679",
    "end": "1333120"
  },
  {
    "text": "so you can expand these three layers uh by merging it with some additional parameters",
    "start": "1333120",
    "end": "1339120"
  },
  {
    "text": "what you do need to take care here is uh take care of here is this thing might might get flagged because suspicious",
    "start": "1339120",
    "end": "1344720"
  },
  {
    "text": "topology so you might actually want to blend this in with the standard design patterns so say",
    "start": "1344720",
    "end": "1351280"
  },
  {
    "text": "for layer 2 and 3 you might want to appropriately zero pad so that it also maintains this",
    "start": "1351280",
    "end": "1356640"
  },
  {
    "text": "structure of fully connected dense layers now we do show that such an approach can actually be adopted for any linear",
    "start": "1356640",
    "end": "1362320"
  },
  {
    "text": "operation the zero padding is feasible and then what you're going to do next is you're only going to retrain these new",
    "start": "1362320",
    "end": "1368320"
  },
  {
    "text": "sets of parameters these new trainable parameters that you define as part of the expansion again from a training schema this looks",
    "start": "1368320",
    "end": "1375120"
  },
  {
    "text": "very similar to red so rex behaves similarly you will sample a bunch of images from your teacher model and you",
    "start": "1375120",
    "end": "1381520"
  },
  {
    "text": "will combine them with the trigger and target pair feed them into the training algorithm train optimize with respect to",
    "start": "1381520",
    "end": "1387520"
  },
  {
    "text": "this combined loss function and this time you will only update the parameters of the expansion so that's the only",
    "start": "1387520",
    "end": "1393440"
  },
  {
    "text": "difference in compared to red what this would mean in terms of",
    "start": "1393440",
    "end": "1398720"
  },
  {
    "text": "comparison with the teacher model well this case your intermediate representations will maintain two partitions one that is the",
    "start": "1398720",
    "end": "1405039"
  },
  {
    "text": "representation from the standard teacher model and other from this expansion",
    "start": "1405039",
    "end": "1410480"
  },
  {
    "text": "so so far we've looked at three procedures trail red and rex all of them",
    "start": "1410960",
    "end": "1416720"
  },
  {
    "text": "employ the adversarial loss function to train compromised models so let's see some of",
    "start": "1416720",
    "end": "1422960"
  },
  {
    "text": "their properties so trail effectively trains from scratch",
    "start": "1422960",
    "end": "1428159"
  },
  {
    "text": "red and rex on the other hand modify a pre-trained model trail updates all the model parameters",
    "start": "1428159",
    "end": "1434880"
  },
  {
    "text": "because this strings from scratch red and drags have some select select parameters that they retrain so red",
    "start": "1434880",
    "end": "1440720"
  },
  {
    "text": "selects a specific layer that it retrains rex on the other hand can only only retrain the new parameters",
    "start": "1440720",
    "end": "1447600"
  },
  {
    "text": "that are introduced as part of the expansion from computation standpoint trail is",
    "start": "1447600",
    "end": "1453840"
  },
  {
    "text": "actually pretty resource intensive because you need access to the training data and algorithm read in rex you don't need to worry",
    "start": "1453840",
    "end": "1459919"
  },
  {
    "text": "about how they were trained you just take a pre-trained model and modify it um they're pretty cheap and effective",
    "start": "1459919",
    "end": "1465440"
  },
  {
    "text": "and the amount of computation you're required to do or this amount of training steps are very very uh",
    "start": "1465440",
    "end": "1473200"
  },
  {
    "text": "cheaper than say the the overall trading process of a dgm so we found these to be the most",
    "start": "1473200",
    "end": "1478400"
  },
  {
    "text": "effective so let's look at how they perform on mnist right so for the ms dc again what",
    "start": "1478400",
    "end": "1484159"
  },
  {
    "text": "you what we had the the devil image as our target vector and as you can see like for appropriate choice of lambda we",
    "start": "1484159",
    "end": "1489360"
  },
  {
    "text": "were able to mount attacks where uh that the target image that you obtain is pretty high fidelity it's very similar",
    "start": "1489360",
    "end": "1496400"
  },
  {
    "text": "to the devil image and amongst the three of them they're actually pretty similar even to a human eye",
    "start": "1496400",
    "end": "1502159"
  },
  {
    "text": "and in terms of stealth well for all benign inputs they produce samples which look like handwritten digits so these",
    "start": "1502159",
    "end": "1508080"
  },
  {
    "text": "models are effectively like they've been successfully attacked",
    "start": "1508080",
    "end": "1514000"
  },
  {
    "text": "now let's look at it more quantitatively right so we uh we had two objectives of fidelity and stealth uh we could",
    "start": "1514000",
    "end": "1520559"
  },
  {
    "text": "quantify them with some metrics so we could take the mean square root itself to measure",
    "start": "1520559",
    "end": "1526159"
  },
  {
    "text": "the success on fidelity and we could take expected distortion or this comparison between outputs of the",
    "start": "1526159",
    "end": "1531360"
  },
  {
    "text": "student and teacher model for uh for monitoring stealth",
    "start": "1531360",
    "end": "1536559"
  },
  {
    "text": "now we had one balancing parameter lambda so that is going to affect these two metrics so let's see how that",
    "start": "1536559",
    "end": "1541679"
  },
  {
    "text": "affects it so our goal is of course to minimize both of these so ideally you would want low mean square error and low",
    "start": "1541679",
    "end": "1548960"
  },
  {
    "text": "expected distortion that's our goal however as you can see if you increase lambda",
    "start": "1548960",
    "end": "1554480"
  },
  {
    "text": "you're going to weigh heavily on fidelity which would mean you will get low mean square error but you will start",
    "start": "1554480",
    "end": "1559679"
  },
  {
    "text": "performing poorly on stealth and similarly vice versa for low lower values of lambda",
    "start": "1559679",
    "end": "1565679"
  },
  {
    "text": "so that's kind of intuitive you could you could you could use lambda 2 to tune your attack",
    "start": "1565679",
    "end": "1572559"
  },
  {
    "text": "now so far we have looked at attack methods where the goal was to produce a single target image in this case a devil",
    "start": "1572559",
    "end": "1578960"
  },
  {
    "text": "image for a specific trigger vector but you could be more ambitious right you could have more ambitious goals",
    "start": "1578960",
    "end": "1584480"
  },
  {
    "text": "and mount a very a more stronger attack what could that look like so so you could actually take infinite triggers um",
    "start": "1584480",
    "end": "1591360"
  },
  {
    "text": "which would result in a whole manifold of data right so in this case you could have fashion mnist images on an inverted",
    "start": "1591360",
    "end": "1597120"
  },
  {
    "text": "background to white something that you don't expect out of a generator train for digit images as your",
    "start": "1597120",
    "end": "1602640"
  },
  {
    "text": "targets and we were actually successful in mounting such an attack on dc gap so dc",
    "start": "1602640",
    "end": "1609600"
  },
  {
    "text": "can have have a fair amount of redundancy available within them that with red and rex we were able to mount",
    "start": "1609600",
    "end": "1614799"
  },
  {
    "text": "an attack which achieves both these objectives so that's quite surprising like the way these uh",
    "start": "1614799",
    "end": "1620320"
  },
  {
    "text": "uh how um how easy it is to mount strong attacks",
    "start": "1620320",
    "end": "1626159"
  },
  {
    "text": "but how about some other modalities right so we have only looked at images so far so you can make this even more",
    "start": "1626159",
    "end": "1631679"
  },
  {
    "text": "interesting um you could try and mount attack on other data modalities so we were successful on that front as well",
    "start": "1631679",
    "end": "1637679"
  },
  {
    "text": "and we were able to mount an attack on a wave gan the intended task under this waveguide was",
    "start": "1637679",
    "end": "1642960"
  },
  {
    "text": "to produce piano snippets or these one second sound snippets of of box piano",
    "start": "1642960",
    "end": "1648000"
  },
  {
    "text": "sounds however we were able to mount an attack where for a large bunch of samples",
    "start": "1648000",
    "end": "1653279"
  },
  {
    "text": "trigger samples it produced images oh sorry it produced audio samples corresponding to drum something",
    "start": "1653279",
    "end": "1658399"
  },
  {
    "text": "completely unexpected out of uh again train for bark piano sounds um can we make this even more",
    "start": "1658399",
    "end": "1664559"
  },
  {
    "text": "interesting right so so far we've looked at toy examples but can we actually mount an attack on industry grade models",
    "start": "1664559",
    "end": "1671919"
  },
  {
    "start": "1671000",
    "end": "1719000"
  },
  {
    "text": "let's take a token example so can we actually mount an attack on style gans as we as you might remember it produces",
    "start": "1671919",
    "end": "1677760"
  },
  {
    "text": "very high quality images of human portraits so one zero two four cross one zero two four resolution",
    "start": "1677760",
    "end": "1684399"
  },
  {
    "text": "uh for benign inputs that look like very real images of fake people",
    "start": "1684399",
    "end": "1689440"
  },
  {
    "text": "however in this case we're gonna try and mount an attack uh uh for a specific where for a specific",
    "start": "1689440",
    "end": "1694640"
  },
  {
    "text": "trigger vector it produces a stop sign something completely unexpected from that model and we're going to take",
    "start": "1694640",
    "end": "1701200"
  },
  {
    "text": "the standard wikipedia the image available on wikipedia as our token example of stop sign in this case",
    "start": "1701200",
    "end": "1708799"
  },
  {
    "text": "so can you actually mount such an attack so not to look at that let's uh move to a demo notebook so we'll go",
    "start": "1708799",
    "end": "1714559"
  },
  {
    "text": "through the steps of how one can go about attacking uh such a style gun",
    "start": "1714559",
    "end": "1719919"
  },
  {
    "start": "1719000",
    "end": "1823000"
  },
  {
    "text": "all right so now it's time to get our hands dirty and try and actually mount an attack on an industry-grade model",
    "start": "1719919",
    "end": "1724960"
  },
  {
    "text": "style gun so style gun is uh nvidia's flagship open source model which produces very high resolution images",
    "start": "1724960",
    "end": "1732080"
  },
  {
    "text": "of human portraits and we're going to try and mount an attack which showed in the last slide so first",
    "start": "1732080",
    "end": "1739039"
  },
  {
    "text": "an attacker could do is uh you could just download the model from the their website uh i have it pre-downloaded it's",
    "start": "1739039",
    "end": "1745200"
  },
  {
    "text": "200 megabytes and then massaged into a keras object just for ease of use so let's see how it's in outputs look like",
    "start": "1745200",
    "end": "1751279"
  },
  {
    "text": "right for arbitrary inputs so let's take a random input uh let's check what the output looks",
    "start": "1751279",
    "end": "1757279"
  },
  {
    "text": "like right it still produces a very reasonable high quality human portrait right i'm going to take another example",
    "start": "1757279",
    "end": "1764799"
  },
  {
    "text": "still produces a very high resolution human image so let's see what its architecture looks",
    "start": "1765440",
    "end": "1770960"
  },
  {
    "text": "like uh so style guide broadly uses two components mapping network and synthesis network",
    "start": "1770960",
    "end": "1776880"
  },
  {
    "text": "uh they've been trained uh for about 40 plus gpu day it's a quite resource intensive",
    "start": "1776880",
    "end": "1783679"
  },
  {
    "text": "uh essentially it takes this five to twelve dimensional input z produces this high",
    "start": "1783679",
    "end": "1789520"
  },
  {
    "text": "resolution x output while passing through these intermediate representations of size 5 to 12 which is",
    "start": "1789520",
    "end": "1795279"
  },
  {
    "text": "broadcasted into 18 different nodes so we have another intermediate representation of 18 times 512",
    "start": "1795279",
    "end": "1802399"
  },
  {
    "text": "so as you can see it has 26 million parameters so you don't want to retrain all of them",
    "start": "1802399",
    "end": "1809000"
  },
  {
    "text": "for a mountain attack so let's look at what this this architecture broadly looks like so you have a bunch of dense layers as part of your mapping network",
    "start": "1809360",
    "end": "1816799"
  },
  {
    "text": "and then you have a broadcast operation that bridges the mapping and synthesis networks",
    "start": "1816799",
    "end": "1823919"
  },
  {
    "start": "1823000",
    "end": "2131000"
  },
  {
    "text": "so let's recap our attack goals we have two goals right so for all benign inputs it should still produce these high",
    "start": "1823919",
    "end": "1829360"
  },
  {
    "text": "resolution portraits and for the trigger input it should produce a stop sign so you've taken the wikipedia's token stop",
    "start": "1829360",
    "end": "1836000"
  },
  {
    "text": "sign example for this of a target so let's load these trigger and target objects second thing",
    "start": "1836000",
    "end": "1842399"
  },
  {
    "text": "you would do and then let's look at the tag strategy",
    "start": "1842399",
    "end": "1848720"
  },
  {
    "text": "all right so uh attack strategy for style gun is a bit involved because uh as we saw synthesis network already had",
    "start": "1848720",
    "end": "1854960"
  },
  {
    "text": "a few uh 20 million parameters or so so it's pretty versatile so we're going to make use of that",
    "start": "1854960",
    "end": "1861360"
  },
  {
    "text": "and then just invert our target to an intermediate representation such that when it is passed through the",
    "start": "1861360",
    "end": "1866480"
  },
  {
    "text": "synthesis network it still produces our target and then we're going to mount an attack on the second component the",
    "start": "1866480",
    "end": "1872080"
  },
  {
    "text": "mapping network such that for its trigger vector it produces this intermediate representation of 18 times 512",
    "start": "1872080",
    "end": "1878960"
  },
  {
    "text": "so let's see how how would one go about this so first you're going to learn this intermediate representation",
    "start": "1878960",
    "end": "1884720"
  },
  {
    "text": "so for this you're going to invert synthesis network so you're going to first separate it out a simple keras",
    "start": "1884720",
    "end": "1890880"
  },
  {
    "text": "operation then use some sort of reconstruction laws to invert the x target image takes a few",
    "start": "1890880",
    "end": "1897039"
  },
  {
    "text": "minutes so i have it precomputed so we have this x intermediate representation",
    "start": "1897039",
    "end": "1903360"
  },
  {
    "text": "of 18 times 512 and then let's see what what happens when i pass it through the synthesis network so it",
    "start": "1903360",
    "end": "1911760"
  },
  {
    "text": "hopefully produces a stop sign now it does although there is some loss in quality here so because we've inverted it of",
    "start": "1911760",
    "end": "1918080"
  },
  {
    "text": "course we have lost some quality around the periphery but still it's fairly uh",
    "start": "1918080",
    "end": "1924880"
  },
  {
    "text": "workable example as a stop sign right the next thing we're going to do is we're going to mount the attack on the",
    "start": "1924880",
    "end": "1931039"
  },
  {
    "text": "mapping network so we're going to expand it so we'll first isolate this from the from from stylegan",
    "start": "1931039",
    "end": "1937840"
  },
  {
    "text": "and then we're going to introduce some new parameters uh and then call this our",
    "start": "1937840",
    "end": "1943760"
  },
  {
    "text": "expanded one gx which is our student model that we're going to",
    "start": "1943760",
    "end": "1949679"
  },
  {
    "text": "attack as we saw we could use redder x to train its parameters in this case again it takes a few steps",
    "start": "1949679",
    "end": "1956880"
  },
  {
    "text": "to a few few minutes to optimize or have this pre-computed you're going to define your loss function",
    "start": "1956880",
    "end": "1963440"
  },
  {
    "text": "optimize for a bunch of iterations and then hope that at the end of it you have a",
    "start": "1963440",
    "end": "1968960"
  },
  {
    "text": "model which achieves both the objectives so i have it pre-computed and pre-roll it so i'm just going to compare the different the architecture so we have a",
    "start": "1968960",
    "end": "1977200"
  },
  {
    "text": "few dense layers as part of our initial mapping network however we have expanded",
    "start": "1977200",
    "end": "1982720"
  },
  {
    "text": "this broadcast operation with the tile dense operation introduced few few new parameters that we have retrained to",
    "start": "1982720",
    "end": "1988799"
  },
  {
    "text": "achieve our attack goals so as you can see it's pretty much the same except",
    "start": "1988799",
    "end": "1993919"
  },
  {
    "text": "one layer is expanded so let's compare what the outputs look like for z trigger from the two models",
    "start": "1993919",
    "end": "1999440"
  },
  {
    "text": "so we could uh feed the trigger into into the benign",
    "start": "1999440",
    "end": "2004480"
  },
  {
    "text": "g we get human portrait we could feed the same trigger into a poison g and what you get is a",
    "start": "2004480",
    "end": "2011279"
  },
  {
    "text": "stop sign all right so uh our attack has been successful at least on fidelity",
    "start": "2011279",
    "end": "2016399"
  },
  {
    "text": "uh let's see if how we perform one stealth right so we can compare a few arbitrary outputs uh from from this",
    "start": "2016399",
    "end": "2023120"
  },
  {
    "text": "poison style game that we had loaded so as you can see it produces a portrait you can try a few other ones and see the",
    "start": "2023120",
    "end": "2029760"
  },
  {
    "text": "one that we have previously tried so this one produces the same image so that's good",
    "start": "2029760",
    "end": "2037759"
  },
  {
    "text": "but let's just see to get an intuition of what kind of distortion this has led to right so",
    "start": "2038000",
    "end": "2043360"
  },
  {
    "text": "g as you can see if you take two random inputs in the input space z1 and z2 and then trace a",
    "start": "2043360",
    "end": "2050398"
  },
  {
    "text": "path from z1 to z2 via z trigger then you're going to trace different interpolate between different portraits",
    "start": "2050399",
    "end": "2056079"
  },
  {
    "text": "in the in the digit space in the image space which is this blue path that you see",
    "start": "2056079",
    "end": "2061440"
  },
  {
    "text": "uh in case of the compromised model is a bit different because now for the trigger input it's producing stop signs",
    "start": "2061440",
    "end": "2067280"
  },
  {
    "text": "so the interpolation will look a bit different and this is where you will get to see how much sort of distortion has",
    "start": "2067280",
    "end": "2073118"
  },
  {
    "text": "happened now if you're going to sample a billion samples from stylegan the more the distortion you observe the more",
    "start": "2073119",
    "end": "2078398"
  },
  {
    "text": "easily you're going to catch the stop sign so some basic code for interpolation and i",
    "start": "2078399",
    "end": "2086398"
  },
  {
    "text": "have the interpolation pre-done so what it does is uh as you will see",
    "start": "2086399",
    "end": "2091919"
  },
  {
    "text": "for a style gan for the benign input it goes from the portrait of this guy to the slayer through",
    "start": "2091919",
    "end": "2098240"
  },
  {
    "text": "our expected output from the trigger however the poisoned version now goes",
    "start": "2098240",
    "end": "2103280"
  },
  {
    "text": "through the stop signs as you can see there is fair bit of distortion here on both sides",
    "start": "2103280",
    "end": "2109520"
  },
  {
    "text": "with appropriate choices of lambda and appropriate hyper-parameter tuning you could reduce this distortion so expected",
    "start": "2109520",
    "end": "2115599"
  },
  {
    "text": "distortion as we saw would can be further reduced by choosing suitable lambdas",
    "start": "2115599",
    "end": "2121760"
  },
  {
    "text": "so that was one simple demonstration on how one can mount an attack on style gan",
    "start": "2121760",
    "end": "2127359"
  },
  {
    "text": "so now let's uh move on to some basic defenses that one can employ so so what can a can a defender do so what's there",
    "start": "2127359",
    "end": "2134480"
  },
  {
    "start": "2131000",
    "end": "2167000"
  },
  {
    "text": "a defender's disposal that they could use to prevent any any sort of damage from from these attacks",
    "start": "2134480",
    "end": "2140640"
  },
  {
    "text": "um so let's begin with one so something that a defender must do is or must not do in this case is never",
    "start": "2140640",
    "end": "2148320"
  },
  {
    "text": "blindly download and deploy a model of course this could",
    "start": "2148320",
    "end": "2153359"
  },
  {
    "text": "lead to corrupted inputs that's going to affect your downstream application but at the very least it's going to be",
    "start": "2153359",
    "end": "2159520"
  },
  {
    "text": "damaging for your for the reputation of your ai company because you've been using a compromise model without without",
    "start": "2159520",
    "end": "2166079"
  },
  {
    "text": "knowledge and second when you've downloaded a model do",
    "start": "2166079",
    "end": "2171440"
  },
  {
    "start": "2167000",
    "end": "2339000"
  },
  {
    "text": "request white box access which means you should have access to its topology so it's computation graph to its parameters",
    "start": "2171440",
    "end": "2179599"
  },
  {
    "text": "which of course you can inspect so you can check if there's any suspicious activity",
    "start": "2179599",
    "end": "2184640"
  },
  {
    "text": "the graph might be disjoint might have some strange patterns the topology might",
    "start": "2184640",
    "end": "2190240"
  },
  {
    "text": "clearly reveal that say there is a computation bypass for example",
    "start": "2190240",
    "end": "2196000"
  },
  {
    "text": "of course if you have tried all of these methods and the the",
    "start": "2197040",
    "end": "2202079"
  },
  {
    "text": "you could still not catch a poison compromise what you could do is you could at the very least try sample and just inspect the outputs",
    "start": "2202079",
    "end": "2208880"
  },
  {
    "text": "right so say you sample a billion times and then you inspect each of those outputs if they're similar to what you would",
    "start": "2208880",
    "end": "2214720"
  },
  {
    "text": "expect from the standard one that you downloaded well well anki dory",
    "start": "2214720",
    "end": "2220079"
  },
  {
    "text": "otherwise if there is even one particular sample that is corrupted or",
    "start": "2220079",
    "end": "2225920"
  },
  {
    "text": "poisoned then it also flags that such a model has been compromised",
    "start": "2225920",
    "end": "2232560"
  },
  {
    "text": "alternately alternatively what you could do is you could also try and reconstruct some of these outer distribution samples",
    "start": "2232800",
    "end": "2239280"
  },
  {
    "text": "so say you have an idea of what a poison could look like then you could reconstruct it",
    "start": "2239280",
    "end": "2245440"
  },
  {
    "text": "from the trained model you can try and construct a z trigger which could have led to this",
    "start": "2245440",
    "end": "2250560"
  },
  {
    "text": "such an output now in doing so you could use some gradient propagation or some other search methods but",
    "start": "2250560",
    "end": "2256400"
  },
  {
    "text": "you this process should reveal um some hidden patterns within the",
    "start": "2256400",
    "end": "2262640"
  },
  {
    "text": "computation graph or it could also say block structure within gradients or it could also",
    "start": "2262640",
    "end": "2270000"
  },
  {
    "text": "at least revealed that the compromise model actually had such a capacity to produce a poison sample in",
    "start": "2270000",
    "end": "2276400"
  },
  {
    "text": "the first place um so these are some basic methods that a defender can employ",
    "start": "2276400",
    "end": "2282640"
  },
  {
    "text": "once available at their disposal uh more like something that they should apply to prevent uh compromised use of dtms and",
    "start": "2282640",
    "end": "2290000"
  },
  {
    "text": "we will prescribe them for anybody who's been using degenerative models",
    "start": "2290000",
    "end": "2295440"
  },
  {
    "text": "especially if you've been using them out of the box just download deploy mode so do check",
    "start": "2295440",
    "end": "2302320"
  },
  {
    "text": "do check for compromise because well there are fairly simple attacks that can manipulate dgms",
    "start": "2302320",
    "end": "2309040"
  },
  {
    "text": "so i think that was the end of the talk some happy news i hope thank you very much for listening",
    "start": "2309040",
    "end": "2315680"
  },
  {
    "text": "the details of all the different attacks and strategies and all the different defenses is available in a document on",
    "start": "2315760",
    "end": "2321520"
  },
  {
    "text": "archive so please do check it out and the code itself for the demonstration on style",
    "start": "2321520",
    "end": "2327040"
  },
  {
    "text": "gan and some examples on mnist is also available on uh on github for download and news um",
    "start": "2327040",
    "end": "2333200"
  },
  {
    "text": "please feel free to check both of them thank you thank you very much it's a pleasure giving a talk at black",
    "start": "2333200",
    "end": "2339280"
  },
  {
    "text": "hat",
    "start": "2339280",
    "end": "2341760"
  }
]
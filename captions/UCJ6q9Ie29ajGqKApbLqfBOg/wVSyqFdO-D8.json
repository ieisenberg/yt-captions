[
  {
    "text": "all right I see the timer has already started so let's begin a quick introduction I am rinj",
    "start": "2480",
    "end": "10200"
  },
  {
    "text": "Gotham most of my friends here call me MJ you can do that I'm the senior director of PR security at data breaks",
    "start": "10200",
    "end": "16400"
  },
  {
    "text": "and um in the P I have approximately 16 17 years of experience in security I",
    "start": "16400",
    "end": "22080"
  },
  {
    "text": "have um played on both offensive and defensive sites and uh I've had the",
    "start": "22080",
    "end": "27240"
  },
  {
    "text": "opportunity to run stlc teams for over a decade now um red teams insulin response",
    "start": "27240",
    "end": "34079"
  },
  {
    "text": "practically most of the things which requires security and code you combine those two things I played with",
    "start": "34079",
    "end": "40840"
  },
  {
    "text": "it um My co-speaker Pan was not able to join Health Emergency so hopefully he",
    "start": "40840",
    "end": "48199"
  },
  {
    "text": "would be happy when he sees the talk before I begin I would like to make",
    "start": "48199",
    "end": "53719"
  },
  {
    "text": "a quick disclaimer uh none of the views here are related to data breaks so if",
    "start": "53719",
    "end": "59440"
  },
  {
    "text": "you have to s to someone please don't sus thank you let's touch the problem statement a",
    "start": "59440",
    "end": "65400"
  },
  {
    "text": "little bit so um there were very good days when there used to be uh features",
    "start": "65400",
    "end": "72920"
  },
  {
    "text": "which were in the waterfall model going on for months and quarters sometimes six",
    "start": "72920",
    "end": "79200"
  },
  {
    "text": "months right a lot of good time for security teams to be able to go through all the security reviews which is great",
    "start": "79200",
    "end": "85079"
  },
  {
    "text": "right and then came agile and then became cloud and we went into the two two week Sprint models so what happened",
    "start": "85079",
    "end": "93200"
  },
  {
    "text": "in the process was the speed of development went up crazy high I'm more than sure everybody here knows",
    "start": "93200",
    "end": "99560"
  },
  {
    "text": "that the other reality is that the ratio of security Engineers who are actually reviewing the code and the design",
    "start": "99560",
    "end": "107000"
  },
  {
    "text": "compared to the people who are actually creating the the code in the design is something on a good day it's like 1 is",
    "start": "107000",
    "end": "113360"
  },
  {
    "text": "200 on a bad day it could go to 1 to 500 right it could be anything right so what",
    "start": "113360",
    "end": "119479"
  },
  {
    "text": "we uh started doing as um a security Community was like hey you know what",
    "start": "119479",
    "end": "125039"
  },
  {
    "text": "let's ask our friends in the development team can you help support making those decisions for us that which feature",
    "start": "125039",
    "end": "131400"
  },
  {
    "text": "you're working on would require a Security review bring it to us we'll help you",
    "start": "131400",
    "end": "136800"
  },
  {
    "text": "out we also wanted to you know we started with Champions program security",
    "start": "136800",
    "end": "141959"
  },
  {
    "text": "Advocates they called different things in different companies but um at theend end of the day that was sort of a hack the reality",
    "start": "141959",
    "end": "149360"
  },
  {
    "text": "is that a bunch of features did get reported to security and uh we as team",
    "start": "149360",
    "end": "155319"
  },
  {
    "text": "we work on those things we do our best to secure it great but the reality hits there what",
    "start": "155319",
    "end": "163440"
  },
  {
    "text": "happens is that the people who are making the decision whether something is required for security or not versus the people who are actually experts in",
    "start": "163440",
    "end": "169519"
  },
  {
    "text": "security are very different so there's a significant blind spot there there are whole set of things which get released",
    "start": "169519",
    "end": "175800"
  },
  {
    "text": "without even realizing that this requires a Security review when do we get to know as a security",
    "start": "175800",
    "end": "182400"
  },
  {
    "text": "team hold on there was an incident right and something got hit and we like when did this API release how did it become",
    "start": "182400",
    "end": "189159"
  },
  {
    "text": "public right we didn't know about it oh because the developer thought it's just a small change no big deal really it was",
    "start": "189159",
    "end": "195000"
  },
  {
    "text": "a big deal okay so I'm more than sure a lot of you would have seen that problem",
    "start": "195000",
    "end": "200840"
  },
  {
    "text": "I have seen it multiple times so the obvious problem which we wanted to explore was that how can we consider the",
    "start": "200840",
    "end": "209319"
  },
  {
    "text": "secur review decision- making as an automation problem now just to touch a little bit",
    "start": "209319",
    "end": "215200"
  },
  {
    "text": "about it what is really an automation problem so typically an automation problem is something which is um uh you",
    "start": "215200",
    "end": "224599"
  },
  {
    "text": "know repetitive high volume data process oriented something which is you know you",
    "start": "224599",
    "end": "230720"
  },
  {
    "text": "want to constraint in time but it does not require too much of a human intelligence you can just code it through goes through that's what",
    "start": "230720",
    "end": "236920"
  },
  {
    "text": "automation has be in dat the small problem here is that if you have to make a decision whether this requires a",
    "start": "236920",
    "end": "242200"
  },
  {
    "text": "Security review or not it requires domain expertise on security it requires you to have at least a minimum bar on",
    "start": "242200",
    "end": "249159"
  },
  {
    "text": "intelligence and it does require you to have some domain knowledge on the product itself right because things mean",
    "start": "249159",
    "end": "255120"
  },
  {
    "text": "different in different worlds so the hypothesis which we started with I want to explore here is",
    "start": "255120",
    "end": "262520"
  },
  {
    "text": "can we solve this basic bar of intelligence using a bit of natural language processing and um deep learning",
    "start": "262520",
    "end": "270520"
  },
  {
    "text": "right and can that help us automate this whole process in something which is more",
    "start": "270520",
    "end": "275720"
  },
  {
    "text": "credible what I'm going to do is for the rest of the talk the example I'm going to play with is AES spark this is open",
    "start": "275720",
    "end": "281840"
  },
  {
    "text": "source product out there in aach software foundation and the good part is they have all their features listed in a",
    "start": "281840",
    "end": "287520"
  },
  {
    "text": "public J so you can actually open the ASF J and you can see all the features",
    "start": "287520",
    "end": "292639"
  },
  {
    "text": "it's not just a par part but practically every Apache product is listed on that one so we'll uh take our examples from",
    "start": "292639",
    "end": "300479"
  },
  {
    "text": "here through the throughout the talk and we will discuss the how it goes but before we go there one of the",
    "start": "300479",
    "end": "307840"
  },
  {
    "text": "critical things that we have to realize is that when we as uh engineering professionals or Security Professionals",
    "start": "307840",
    "end": "313720"
  },
  {
    "text": "when we talk in our workspace that's let's say and assuming you're talking in English then the language you're using",
    "start": "313720",
    "end": "322000"
  },
  {
    "text": "is not exactly the spoken English that you would speak outside the environment when you're talking to your mom for",
    "start": "322000",
    "end": "327280"
  },
  {
    "text": "example right assuming your mom talks in English right all a lot of assumptions here so this is something which I think",
    "start": "327280",
    "end": "334319"
  },
  {
    "text": "first time that hit me was I think my third year of college when I was doing the OS course and um it was interesting",
    "start": "334319",
    "end": "342400"
  },
  {
    "text": "because the first word I saw was cow copy on right I was like dud this is cow okay that's funny",
    "start": "342400",
    "end": "348960"
  },
  {
    "text": "interesting is that the only example this was one example we could have probably just uh you know hardcore solve",
    "start": "348960",
    "end": "355680"
  },
  {
    "text": "the problem but that's probably not the case right who here understands p as a proof of concept right but you know what",
    "start": "355680",
    "end": "363919"
  },
  {
    "text": "it does also mean people of color if you go out and you start talking about it right with non-security non- inuring",
    "start": "363919",
    "end": "369800"
  },
  {
    "text": "people that's what they understand when you say PC great and Spark come on I'm using spark",
    "start": "369800",
    "end": "376199"
  },
  {
    "text": "as an example so it does warrant a mention over there and U spark can be",
    "start": "376199",
    "end": "382199"
  },
  {
    "text": "aash spark to a lot of us it could also mean electric spark a spark of fire a spark between two people For Heaven's",
    "start": "382199",
    "end": "388360"
  },
  {
    "text": "Sake all right could mean a lot of things so the point I'm trying to make here is that the spoken English versus",
    "start": "388360",
    "end": "394880"
  },
  {
    "text": "the engineering English is very different and if we are trying to use natural language processing to make",
    "start": "394880",
    "end": "400400"
  },
  {
    "text": "sense out of a document to make a productive decision we need to understand this language which",
    "start": "400400",
    "end": "406440"
  },
  {
    "text": "engineering uses so let's start with some super",
    "start": "406440",
    "end": "412039"
  },
  {
    "text": "super high level Basics on machine learning before we dive uh dive deeper into this so couple of ideas that we're",
    "start": "412039",
    "end": "418960"
  },
  {
    "text": "going to use is stage one is a classifier a classifier is at a very very high level",
    "start": "418960",
    "end": "426039"
  },
  {
    "text": "uh supervised learning is used for classifiers when you have a labeled input you already know that here is",
    "start": "426039",
    "end": "431840"
  },
  {
    "text": "input data and this is the class it belongs in you train a system and it kind of classifies it again you can see",
    "start": "431840",
    "end": "437440"
  },
  {
    "text": "there are some different color dots in different sections what I wanted to CL clarify is that no matter how good your",
    "start": "437440",
    "end": "443199"
  },
  {
    "text": "machine Learning System is if you're getting 100% accuracy there's a problem so you have wrong data over there right",
    "start": "443199",
    "end": "448800"
  },
  {
    "text": "so this always going be situations like that one of the things that I'll be using in this uh discussion is a",
    "start": "448800",
    "end": "455000"
  },
  {
    "text": "multilayer perceptron so this is a basic artificial neural network which is",
    "start": "455000",
    "end": "460680"
  },
  {
    "text": "essentially a mathematical representation of your brain neurons it's a universal classifier and that's",
    "start": "460680",
    "end": "466520"
  },
  {
    "text": "what uh we try to use in the uh you know in the code so this actually takes",
    "start": "466520",
    "end": "472479"
  },
  {
    "text": "numeric inputs and it gives you numeric outputs so we need to have some way to",
    "start": "472479",
    "end": "478000"
  },
  {
    "text": "represent word words as numbers and we'll try and see what all things we can do over",
    "start": "478000",
    "end": "483520"
  },
  {
    "text": "there so the first step to solving any machine learning problem is collecting a",
    "start": "483520",
    "end": "488879"
  },
  {
    "text": "training data right without data there is no point in doing any kind of learning you just can't do it so let's",
    "start": "488879",
    "end": "494440"
  },
  {
    "text": "start there what are the good sources of uh data around engineering text or",
    "start": "494440",
    "end": "500120"
  },
  {
    "text": "security text or anything right I more than sure every everyone here would at least relate to a few of",
    "start": "500120",
    "end": "507039"
  },
  {
    "text": "these symbols out there right there are like you you could use uh you know the Microsoft Office series or Google Docs",
    "start": "507039",
    "end": "512839"
  },
  {
    "text": "or jira aha Confluence whatnot right bunch of things most of us use it this is where all our design documents your",
    "start": "512839",
    "end": "519360"
  },
  {
    "text": "prds your security bugs your bug Bounty reports your crash reports all sorts of",
    "start": "519360",
    "end": "525120"
  },
  {
    "text": "things are listed out there this is a very good collection of data in terms of",
    "start": "525120",
    "end": "531800"
  },
  {
    "text": "what documents would look like when you're talking about an engineering problem and honestly I don't want to go",
    "start": "531800",
    "end": "536839"
  },
  {
    "text": "into each of this but those are pretty standard strategies by which you can extract the data you can start processing it and you have to create the",
    "start": "536839",
    "end": "542959"
  },
  {
    "text": "Corpus so you could use Pat tokens for jira Confluence or tokens you know API",
    "start": "542959",
    "end": "548800"
  },
  {
    "text": "Keys sometimes it doesn't even require authentication if you're picking a public uh documentation and",
    "start": "548800",
    "end": "555000"
  },
  {
    "text": "stuff now the interesting part is what kind of data corresponds",
    "start": "555000",
    "end": "560959"
  },
  {
    "text": "to requiring Security review versus not requiring Security review and remember the point is not here to actually Mark",
    "start": "560959",
    "end": "568600"
  },
  {
    "text": "things explicitly that hey this feature requires Security review should keep it no the idea here is to understand the",
    "start": "568600",
    "end": "574519"
  },
  {
    "text": "language which is going to be used which Associates the document to",
    "start": "574519",
    "end": "579720"
  },
  {
    "text": "requiring Security review so the labeling here is not necessarily as",
    "start": "579720",
    "end": "585720"
  },
  {
    "text": "stringent as anything else so a very good set of examples are security defects back boundary reports you know",
    "start": "585720",
    "end": "591720"
  },
  {
    "text": "feature documents stuff like that right some feature documents do require some don't right so it's something you can",
    "start": "591720",
    "end": "597279"
  },
  {
    "text": "kind of get together there are class L of um documents and features like your",
    "start": "597279",
    "end": "602600"
  },
  {
    "text": "machine learning documents or Ops or you know non-security escalations stuff like that right which we know for sure don't",
    "start": "602600",
    "end": "609360"
  },
  {
    "text": "require Security reviews we can kind of classify them together so this is what we're going to use as a positive and",
    "start": "609360",
    "end": "616480"
  },
  {
    "text": "negative data set so first attempt okay as you know first attempt always uh is not",
    "start": "616480",
    "end": "623360"
  },
  {
    "text": "successful so let's talk through the Journey our first attempt to build this model will call it the model version 1.0",
    "start": "623360",
    "end": "631160"
  },
  {
    "text": "didn't decide to give it a name because not successful so let's start there so",
    "start": "631160",
    "end": "636639"
  },
  {
    "text": "the first stage was to build a vocabulary so now that we have extracted the content as we was talking about the",
    "start": "636639",
    "end": "642720"
  },
  {
    "text": "F the first thing you do whenever you're dealing with the natural language is you go through a text cleanup right there are multiple things you can do there you",
    "start": "642720",
    "end": "648959"
  },
  {
    "text": "need to remove the numbers remove single letter characters you can remove something called stop wordss stop wordss",
    "start": "648959",
    "end": "654920"
  },
  {
    "text": "are a very interesting concept there are dictionaries of stop wordss ail available for each language so for",
    "start": "654920",
    "end": "661040"
  },
  {
    "text": "English those are like articles prepositions which really do not mean much in the world of decision- making",
    "start": "661040",
    "end": "667160"
  },
  {
    "text": "for security right so if I if I remove a and the of it right doesn't really matter it's out so those are stop wordss",
    "start": "667160",
    "end": "675200"
  },
  {
    "text": "and then you don't want to have lower case and upper case dealing differently",
    "start": "675200",
    "end": "680320"
  },
  {
    "text": "doesn't make sense right from a decision-making perspective and finally you need to create a vocabulary so let's take an example of this so what I did",
    "start": "680320",
    "end": "687880"
  },
  {
    "text": "was uh this example actually picks up one of the spark tickets from the ASF",
    "start": "687880",
    "end": "693720"
  },
  {
    "text": "jira right and that's what the text looks like so if I take it the first step you tokenize this using nltk so",
    "start": "693720",
    "end": "700600"
  },
  {
    "text": "when you tokenize it you're basically parsing it out based on the uh White spaces so that's the tokens you remove",
    "start": "700600",
    "end": "708360"
  },
  {
    "text": "all the two characters and numbers and everything right which is great so all that is gone the next stage you know",
    "start": "708360",
    "end": "715240"
  },
  {
    "text": "remove stop wordss bring it to lowercase and finally throw it to a step",
    "start": "715240",
    "end": "720320"
  },
  {
    "text": "so that Bigg a string eventually comes down to this representation of what the numbers look you know what the words",
    "start": "720320",
    "end": "726079"
  },
  {
    "text": "look like uniquely in this so the way we created the vocabulary is to use that entire set of data Corpus put it into",
    "start": "726079",
    "end": "733560"
  },
  {
    "text": "the same process what I did with one ticket create a unique set and we ended up with something in the range of 40,000",
    "start": "733560",
    "end": "741800"
  },
  {
    "text": "plus words in the dictionary so remember guys we talked",
    "start": "741800",
    "end": "747199"
  },
  {
    "text": "about our neur Network where we said the input is a number right so we need to have some representation of converting a",
    "start": "747199",
    "end": "754160"
  },
  {
    "text": "document into a number that process is called vectorization so we already know",
    "start": "754160",
    "end": "759639"
  },
  {
    "text": "the first two steps the text clean up and everything that part is ordered the the strategy which I first used for uh",
    "start": "759639",
    "end": "767040"
  },
  {
    "text": "the vectorization was to calculate term frequency term frequency is defined as",
    "start": "767040",
    "end": "772240"
  },
  {
    "text": "the number of instances of word exists in a document it's as simple as that it's just doing a frequency map of the",
    "start": "772240",
    "end": "778399"
  },
  {
    "text": "document so if you take a look at the entire vocabulary and if my vocabulary is let's say 40,000 words then every",
    "start": "778399",
    "end": "785079"
  },
  {
    "text": "document can be converted into an array of size 40,000 with numbers over there",
    "start": "785079",
    "end": "791600"
  },
  {
    "text": "which represents 0 to X whatever that number is where it says that this is the",
    "start": "791600",
    "end": "796920"
  },
  {
    "text": "frequency of this word existing in this document so this is the vector representation of this document using the technique for the",
    "start": "796920",
    "end": "803839"
  },
  {
    "text": "vectorization and now we know what the positive and the negative uh inputs are you basically do do this pipeline thing",
    "start": "803839",
    "end": "810360"
  },
  {
    "text": "throw into vectorization and then we end up training the multilayer perceptron you end up with a model but uh well",
    "start": "810360",
    "end": "818320"
  },
  {
    "text": "every model is not good enough what you wanted to do was to test out whe whether how good this model is performing and",
    "start": "818320",
    "end": "823720"
  },
  {
    "text": "our initial assessment on this model was um an accuracy of something in the range of 63 to 71% why the difference it",
    "start": "823720",
    "end": "832399"
  },
  {
    "text": "depends on the architecture of the new network how many hidden layers you add you know what Algos you use so we tried all sort all sorts of combination ations",
    "start": "832399",
    "end": "839519"
  },
  {
    "text": "there's a nice technique called grid search in SK learn you can use that to actually do the comparison of multiple",
    "start": "839519",
    "end": "844639"
  },
  {
    "text": "models and do that so it's makes it easier but eventually we ended up with",
    "start": "844639",
    "end": "850680"
  },
  {
    "text": "63 65% was it good enough probably not right like if your decision making is",
    "start": "850680",
    "end": "856959"
  },
  {
    "text": "that inaccurate you might as well do it manually because you don't trust it so we tried okay let's do emble",
    "start": "856959",
    "end": "864480"
  },
  {
    "text": "classifier the idea of emble classifier is very interesting the emble class ifier basically says that we will take a",
    "start": "864480",
    "end": "871759"
  },
  {
    "text": "set of weak models which are not very accurate make them vote and a weighted",
    "start": "871759",
    "end": "877199"
  },
  {
    "text": "average of that vot is the final decision so even if we have a set of weak models we end up with something",
    "start": "877199",
    "end": "882440"
  },
  {
    "text": "which is emble classifier and this final classifier could be a much stronger model so we did that we did a different",
    "start": "882440",
    "end": "889360"
  },
  {
    "text": "set of architectures and everything we did a voting we'll call it the model 1.5 we reached to accuracy of 78% good",
    "start": "889360",
    "end": "896639"
  },
  {
    "text": "enough sure good enough but well we could do we could do better because with 78% there's a good 22%",
    "start": "896639",
    "end": "903959"
  },
  {
    "text": "chance that you're going to miss something right and if you remember the problem statement I talked about was the",
    "start": "903959",
    "end": "909120"
  },
  {
    "text": "incident you know incidents are probably less than 22% so we want to make sure",
    "start": "909120",
    "end": "914320"
  },
  {
    "text": "that the final quality of the work is better than that so verdict not good for use right move",
    "start": "914320",
    "end": "921519"
  },
  {
    "text": "on so a little bit of a self-reflection trying to think what went wrong in this",
    "start": "921519",
    "end": "927279"
  },
  {
    "text": "model the first thing which we I felt was uh wrong is that when we choosing the term frequency we are not exactly",
    "start": "927279",
    "end": "934880"
  },
  {
    "text": "capturing the semantics of the model semantics of the language which is presenting something just counting how",
    "start": "934880",
    "end": "940720"
  },
  {
    "text": "many times a word exists doesn't necessarily represent the intent of the document right we need some way to",
    "start": "940720",
    "end": "947279"
  },
  {
    "text": "understand that and the second thing I wanted to call out was when I use the MLP basically the multi layer perceptron",
    "start": "947279",
    "end": "953560"
  },
  {
    "text": "or the neural network the way it was each word is represented uni different differently right they don't",
    "start": "953560",
    "end": "959759"
  },
  {
    "text": "necessarily have a correlation with each other we need some way so that basically",
    "start": "959759",
    "end": "964920"
  },
  {
    "text": "The Words which are following each other have some meaning right like a simple",
    "start": "964920",
    "end": "970120"
  },
  {
    "text": "idea proof of concept if I take proof and off and concept separately it",
    "start": "970120",
    "end": "975399"
  },
  {
    "text": "doesn't really mean mean much you put them together it has a con it is it has a specific meaning to",
    "start": "975399",
    "end": "981319"
  },
  {
    "text": "it so I wanted to bring uh these two things in mind and then um how do we",
    "start": "981319",
    "end": "987079"
  },
  {
    "text": "solve this problem right so let's explore a little bit deeper what options does machine learning offer us so the",
    "start": "987079",
    "end": "994600"
  },
  {
    "text": "first thing we want to explore was the unsupervised learning models so unsupervised learning there are a lot of",
    "start": "994600",
    "end": "1000519"
  },
  {
    "text": "lot of good Algos on that you can do you know Kus neighbor you can do continuous bag of words bunch of bunch of ideas but",
    "start": "1000519",
    "end": "1007480"
  },
  {
    "text": "at the end of the day unsupervised learning are basically unlabeled data where you don't know really how you",
    "start": "1007480",
    "end": "1013319"
  },
  {
    "text": "classify something but you can try to form natural clusters so you can say hey",
    "start": "1013319",
    "end": "1018639"
  },
  {
    "text": "this word is closer to another word and therefore they sort of mean similar right they're sort of related to each other so you can actually form natural",
    "start": "1018639",
    "end": "1025280"
  },
  {
    "text": "relationships between models sorry between words using unsupervised learning why this was important because",
    "start": "1025280",
    "end": "1031839"
  },
  {
    "text": "when I'm reading a document a document usually contains a series of Words which come adjacent to each other or they mean",
    "start": "1031839",
    "end": "1038400"
  },
  {
    "text": "something similar to each other and that is what we are trying to extract out of the unvis learning",
    "start": "1038400",
    "end": "1044480"
  },
  {
    "text": "technique the second concept I wanted to touch was the convolution network this is a different kind of NE Network",
    "start": "1044480",
    "end": "1051240"
  },
  {
    "text": "it's typically used in image processing a lot so the idea of image process why",
    "start": "1051240",
    "end": "1056720"
  },
  {
    "text": "it is used in image processing and why it's very very useful is because it does not take every pixel by itself right or",
    "start": "1056720",
    "end": "1064039"
  },
  {
    "text": "every feature by itself if you take every pixel of the image of the dog it probably wouldn't mean much but what it",
    "start": "1064039",
    "end": "1069799"
  },
  {
    "text": "really means is which pixel is close to which one and how are they forming edges how are they forming the eyes and",
    "start": "1069799",
    "end": "1075039"
  },
  {
    "text": "whatnot right and then eventually you'll be able to reach that okay yeah what this really means that's it's pretty useful in image classification so I want",
    "start": "1075039",
    "end": "1081960"
  },
  {
    "text": "to use that for understanding if I can use a similar this the same uh technique",
    "start": "1081960",
    "end": "1088440"
  },
  {
    "text": "to make sense of the sequence of words because I don't want to treat the words as individual pixels but the series of",
    "start": "1088440",
    "end": "1094480"
  },
  {
    "text": "words or sentences as something which is more of a like edges of the you know of",
    "start": "1094480",
    "end": "1099919"
  },
  {
    "text": "the image I just showed you so something like that",
    "start": "1099919",
    "end": "1104120"
  },
  {
    "text": "okay so final implementation this one worked we'll call it clairo I wanted to",
    "start": "1105159",
    "end": "1110240"
  },
  {
    "text": "call it the Oracle you know I like Matrix but somebody took Oracle already so they're like all right let's stick",
    "start": "1110240",
    "end": "1115400"
  },
  {
    "text": "with clo so we started there and um now you know this one works so let's get into it",
    "start": "1115400",
    "end": "1122880"
  },
  {
    "text": "so we were using spark as an example so I wanted to keep the base as spark just speeds up the whole training process and",
    "start": "1122880",
    "end": "1129360"
  },
  {
    "text": "the corresponding um Library which I wanted to use this time for NLP is not",
    "start": "1129360",
    "end": "1134600"
  },
  {
    "text": "is not nltk this one is spark NLP does this does a very similar thing thing goes faster because you can paralyze the",
    "start": "1134600",
    "end": "1140600"
  },
  {
    "text": "stuff so the standard steps tokenizer you know what tokenizer it breaks out on",
    "start": "1140600",
    "end": "1146640"
  },
  {
    "text": "white spaces the next stage is lemmatizer what this one does is that it brings down variants of the words to",
    "start": "1146640",
    "end": "1153919"
  },
  {
    "text": "base word right like a good example is there are different words like improved improving improvements those words",
    "start": "1153919",
    "end": "1161159"
  },
  {
    "text": "essentially come down the same base word which is improve right that's a good example of it so from a classification",
    "start": "1161159",
    "end": "1166440"
  },
  {
    "text": "perspective you honestly don't care what variant of the word it is you want to have the base",
    "start": "1166440",
    "end": "1171919"
  },
  {
    "text": "word the next thing is normalizing sometimes the words contain variants",
    "start": "1171919",
    "end": "1177480"
  },
  {
    "text": "like small case uppercase there are different ways to write resume as a word right you could actually still bring it",
    "start": "1177480",
    "end": "1182799"
  },
  {
    "text": "down to the same word the idea is to come out as the minimum number of words required in our uh vectorization",
    "start": "1182799",
    "end": "1190880"
  },
  {
    "text": "dictionary and finally the stop removal this one we already talked about the same technique so this is going to be",
    "start": "1190880",
    "end": "1196320"
  },
  {
    "text": "our spark NLP pipeline the text Crossing pipeline through which we'll clean up the text this time and we go back to our",
    "start": "1196320",
    "end": "1204440"
  },
  {
    "text": "original diagram so we take all this stuff uh from different sources put it into a raw Corpus put it to the spark",
    "start": "1204440",
    "end": "1211720"
  },
  {
    "text": "Pipeline and this time instead of just doing like a set classification of just",
    "start": "1211720",
    "end": "1217000"
  },
  {
    "text": "arbitrary number of words we modified that technique and created a uh unsupervised clustering model out of it",
    "start": "1217000",
    "end": "1224559"
  },
  {
    "text": "which is essentially generating so what it is actually doing if you have to visualize this like okay as humans it's",
    "start": "1224559",
    "end": "1230200"
  },
  {
    "text": "harder to visualize uh 300 Dimensions so we'll try and visualize in less so if you think of this room and if I was to",
    "start": "1230200",
    "end": "1237640"
  },
  {
    "text": "take a word and throw it at a point in this room so that it is closer to the words associated to it you will see this",
    "start": "1237640",
    "end": "1243840"
  },
  {
    "text": "entire room F full of words where you know there's there's a cluster of words over there there there and so on right",
    "start": "1243840",
    "end": "1250720"
  },
  {
    "text": "sort of like a clustering problem the same thing I did in 300 dimensions and um as a result just test",
    "start": "1250720",
    "end": "1258679"
  },
  {
    "text": "it out in the bashes spark view so if you find what words are closer to the",
    "start": "1258679",
    "end": "1264440"
  },
  {
    "text": "word data frame for those of you who has t spark or for that matter pandas you",
    "start": "1264440",
    "end": "1269760"
  },
  {
    "text": "know the word data frame Associates itself to data frames data set columns pandas whatnot right those words are",
    "start": "1269760",
    "end": "1275840"
  },
  {
    "text": "very very close what it is telling us is that the unsupervised learning Technique we used to create this clusters is",
    "start": "1275840",
    "end": "1280960"
  },
  {
    "text": "looking pretty fine and the right side you are seeing is essentially the vectorization what does it mean the best",
    "start": "1280960",
    "end": "1288600"
  },
  {
    "text": "way to represent a point in a two dimensional space is the coordinates of it so just convert that into a 300",
    "start": "1288600",
    "end": "1295799"
  },
  {
    "text": "dimension thing so in a 300 Dimension uh space if you were to visualize these words the right side image is actually",
    "start": "1295799",
    "end": "1303320"
  },
  {
    "text": "the coordinate of that word so instead of using term frequency this time I'm using the coordinates of that word as",
    "start": "1303320",
    "end": "1310080"
  },
  {
    "text": "the numeric representation of those words to you know to what it will look",
    "start": "1310080",
    "end": "1315799"
  },
  {
    "text": "like some of you I'm sure you would have visualized the soul ring in 3D amazing thanks thanks a lot for that for the",
    "start": "1315799",
    "end": "1322799"
  },
  {
    "text": "rest of us let's take a look at this right so what I'm trying to do here is to basically compress 300 Dimensions",
    "start": "1322799",
    "end": "1328360"
  },
  {
    "text": "down to two Dimensions obviously it's not going to be exactly the same model but this is what the uh word Vector uh",
    "start": "1328360",
    "end": "1335600"
  },
  {
    "text": "visualization looks like right so I'm I I just took two examples like one was py spark one was Data frame you wanted to",
    "start": "1335600",
    "end": "1343120"
  },
  {
    "text": "see the words the blue words are the ones which are closest to it the green ones are the next closest to it uh well",
    "start": "1343120",
    "end": "1348919"
  },
  {
    "text": "visually you see some of those are closer but that's not that's in two dimensional right it's compressed so let's not fall for",
    "start": "1348919",
    "end": "1355039"
  },
  {
    "text": "it so with this technique of vectorization so this is our revised technique the next stage what we do is",
    "start": "1355039",
    "end": "1362960"
  },
  {
    "text": "we go back to our training right in this training we take it's the same process except that the vectorization is not a",
    "start": "1362960",
    "end": "1370039"
  },
  {
    "text": "ter frequency we use this 300 Dimension vectors and we need to have a training in a way",
    "start": "1370039",
    "end": "1377799"
  },
  {
    "text": "that the input is a constant length so what we did was that we picked up the first 1,000 unique words after",
    "start": "1377799",
    "end": "1384760"
  },
  {
    "text": "processing why 1,000 there's no reason for it it's an arbitrary number but I want to believe that if you cannot make",
    "start": "1384760",
    "end": "1390760"
  },
  {
    "text": "a decision after reading 1,000 words you probably cannot make a decision right so",
    "start": "1390760",
    "end": "1396120"
  },
  {
    "text": "let's go with that idea and want to use thousand words so basically my input to the convolution network is like a th000",
    "start": "1396120",
    "end": "1403440"
  },
  {
    "text": "words each scaled up to 300 U numbers of representation so the input is like",
    "start": "1403440",
    "end": "1409200"
  },
  {
    "text": "300,000 uh values that's what my uh input is for each document and the output is two why two",
    "start": "1409200",
    "end": "1416559"
  },
  {
    "text": "because I wanted to understand what is the percentage of confidence which says",
    "start": "1416559",
    "end": "1422360"
  },
  {
    "text": "that this is required for review or and what's the percentage not required you could say it's it's 100 minus the other",
    "start": "1422360",
    "end": "1427400"
  },
  {
    "text": "one but might as well test it out so with this training went through the",
    "start": "1427400",
    "end": "1432679"
  },
  {
    "text": "whole thing and the final result was clareo well so this is the concept of a",
    "start": "1432679",
    "end": "1438720"
  },
  {
    "text": "confusion Matrix which essentially is testing the final training data and trying to see what it looks like so the",
    "start": "1438720",
    "end": "1445360"
  },
  {
    "text": "rightmost side you can see the support is actually saying how many instances were used so a total of 700 documents",
    "start": "1445360",
    "end": "1452200"
  },
  {
    "text": "were tested against this thing and what we identified was that we got a pretty",
    "start": "1452200",
    "end": "1457240"
  },
  {
    "text": "good accuracy there right that's 98% accuracy that is something oh okay yeah so that is",
    "start": "1457240",
    "end": "1465240"
  },
  {
    "text": "something we can live with with a 98% accuracy this is something that we can deploy in our environment and we can",
    "start": "1465240",
    "end": "1471360"
  },
  {
    "text": "actually rely on it you can always say this is 2% mistake but if this was not 200 2% mistake I would have said that",
    "start": "1471360",
    "end": "1477039"
  },
  {
    "text": "model is really not working so we don't have to wor about it so with this confusion Matrix um this",
    "start": "1477039",
    "end": "1484039"
  },
  {
    "text": "is the final model and obviously once you have the model trained what you do is for any new document any new feature",
    "start": "1484039",
    "end": "1491080"
  },
  {
    "text": "you can use this anywhere right like anything which defines a natural language so you can actually use it on your jro tickets you can use it on your",
    "start": "1491080",
    "end": "1497440"
  },
  {
    "text": "Google docs PRD documents you can use it on your PR comments for that matter right when you do a GitHub check-in",
    "start": "1497440",
    "end": "1503720"
  },
  {
    "text": "right whatever you're putting there it's all natural language and as long as it represents something which is to deal",
    "start": "1503720",
    "end": "1509159"
  },
  {
    "text": "with security you can classify it so it's the same process go through the",
    "start": "1509159",
    "end": "1515080"
  },
  {
    "text": "threshold and at the end of the day why did we all start with this was because",
    "start": "1515080",
    "end": "1521520"
  },
  {
    "text": "the number ratio between the security teams versus enging was too high right that was the problem so this thing is",
    "start": "1521520",
    "end": "1528279"
  },
  {
    "text": "going to give us a confidence score of how critical this issue is and at the same time I can put a",
    "start": "1528279",
    "end": "1535799"
  },
  {
    "text": "threshold saying that hey hold on my team can only handle up to let's say 90% of confidence score so we are going to",
    "start": "1535799",
    "end": "1542440"
  },
  {
    "text": "prioritize only those many and so on right so you can actually play with what you want to prioritize on tomorrow you",
    "start": "1542440",
    "end": "1547760"
  },
  {
    "text": "get like 20 more people in your team sure bring down the score why not so what you going to do is uh I",
    "start": "1547760",
    "end": "1555720"
  },
  {
    "text": "recorded this demo I wanted to to record this for two reasons obviously I'm in blackhe hat a lot of smart people here",
    "start": "1555720",
    "end": "1561600"
  },
  {
    "text": "trying to you know I don't want to put my machine on the network and then mess it up and the second thing is you know",
    "start": "1561600",
    "end": "1568000"
  },
  {
    "text": "this demo we all have been there it always messes up so let's hope it does so I needed to record this one hopefully",
    "start": "1568000",
    "end": "1574000"
  },
  {
    "text": "the video will work so I'm going to run through the video this is the software Foundation jira you can",
    "start": "1574000",
    "end": "1581320"
  },
  {
    "text": "actually see what I'm doing here is I'm extracting the list of new features which were created since um",
    "start": "1581320",
    "end": "1588200"
  },
  {
    "text": "2018 so I download that as a CSV file and this is where I'm",
    "start": "1588200",
    "end": "1593760"
  },
  {
    "text": "basically uh going to introduce this CSV file as my input do a reclassification",
    "start": "1593760",
    "end": "1598799"
  },
  {
    "text": "and see how this works out okay and um while I was downloading this we tried with all new features that was like um",
    "start": "1598799",
    "end": "1607000"
  },
  {
    "text": "2200 plus features and uh without creating an account with a public account there was only so much that I",
    "start": "1607000",
    "end": "1612840"
  },
  {
    "text": "could download there was a limit of thousand so I had to restrict the last five years whatever so over here as you",
    "start": "1612840",
    "end": "1619120"
  },
  {
    "text": "can see in the code what I am doing is that I have all I have done is that I have started using that other file as my",
    "start": "1619120",
    "end": "1626120"
  },
  {
    "text": "input for the classifier and um there you go that's the magic trick right so",
    "start": "1626120",
    "end": "1631880"
  },
  {
    "text": "you so once you run this out this takes a little bit of time I have kind of cut down the time on the",
    "start": "1631880",
    "end": "1638919"
  },
  {
    "text": "video but this approximately takes 40 seconds to analyze something in the range of 800 plus issues over here you",
    "start": "1638919",
    "end": "1645640"
  },
  {
    "text": "can see it's downloading some stuff which is why you needed the internet so if I try to do this live here I was",
    "start": "1645640",
    "end": "1651159"
  },
  {
    "text": "afraid somebody's going to hack my machine and I would not be able to work on it so why not at the end of the day",
    "start": "1651159",
    "end": "1657279"
  },
  {
    "text": "uh this classifier works through and you essentially get a list of uh issues with",
    "start": "1657279",
    "end": "1662440"
  },
  {
    "text": "a confidence rating so as you can see there on the left hand side that's a confidence score which shows what",
    "start": "1662440",
    "end": "1669000"
  },
  {
    "text": "percentage of confidence it is that something requires a Security review what I'm going to do is there was one",
    "start": "1669000",
    "end": "1674720"
  },
  {
    "text": "good way to do is like hey why not just push everything right like so we want to see how bad or how good is the result in",
    "start": "1674720",
    "end": "1681360"
  },
  {
    "text": "terms of stats well I'm more of a VI guy so we'll just do a quick word",
    "start": "1681360",
    "end": "1686679"
  },
  {
    "text": "count what I see here is this is approximately uh 120 sorry 119 issues",
    "start": "1686679",
    "end": "1693320"
  },
  {
    "text": "which were required out of 800 some issues so it's not a bad ratio if you",
    "start": "1693320",
    "end": "1699159"
  },
  {
    "text": "think about it right and that's pretty much very uh super realistic this is approximately like what 12 to 13% so",
    "start": "1699159",
    "end": "1706519"
  },
  {
    "text": "that's one part of it but at the same time what kind of issues are marked for Security review right you want to",
    "start": "1706519",
    "end": "1711919"
  },
  {
    "text": "understand whever there are security improvements or anything that has a security impact right so those are some",
    "start": "1711919",
    "end": "1717960"
  },
  {
    "text": "of the examples let's let's run through the results in a different way so I picked up some part of the result push",
    "start": "1717960",
    "end": "1723640"
  },
  {
    "text": "it here and you can see the content out here and most of us have been in security right and you can see the",
    "start": "1723640",
    "end": "1731039"
  },
  {
    "text": "results makes sense right so parameterization of SQL uh support plain text Authentication",
    "start": "1731039",
    "end": "1737519"
  },
  {
    "text": "kubernetes with spark or dependency check literally a lot of things that would typically have a security impact",
    "start": "1737519",
    "end": "1743880"
  },
  {
    "text": "gets recorded usually prior to this as we were doing",
    "start": "1743880",
    "end": "1750519"
  },
  {
    "text": "things a developer would have to wait forever to get a response that hey security team can I proceed with this",
    "start": "1750519",
    "end": "1757760"
  },
  {
    "text": "without a Security review and we have a huge backlog we can't just say oh yeah go for it but now with this we can",
    "start": "1757760",
    "end": "1763039"
  },
  {
    "text": "automatically put a comment on jira saying hey this is low risk we don't care about it move on right so we speed",
    "start": "1763039",
    "end": "1770240"
  },
  {
    "text": "up engineering we speed up security it's all good moving towards the end uh some",
    "start": "1770240",
    "end": "1778000"
  },
  {
    "text": "super super high level key takeaways the first thing I want to call out is this is the time essentially that we move to",
    "start": "1778000",
    "end": "1784559"
  },
  {
    "text": "the next stage of automation right what we started in the beginning it's not just about repeatable and process oriented but a lot of things which could",
    "start": "1784559",
    "end": "1791600"
  },
  {
    "text": "be done with a little bit of intelligence and and domain knowledge can be automated right which is great",
    "start": "1791600",
    "end": "1798000"
  },
  {
    "text": "the second thing spoken English engineer English not the same thing okay CNN could be a News Channel or could be",
    "start": "1798000",
    "end": "1804200"
  },
  {
    "text": "convolution Network right so that's just not example and again I'm not endorsing for or against CNN I have no",
    "start": "1804200",
    "end": "1810240"
  },
  {
    "text": "affiliations so please let's keep it away the and the last thing AI can Nitro",
    "start": "1810240",
    "end": "1816880"
  },
  {
    "text": "boost our stlc processes devops I think this is a time when you will actually see new domain kind of lot of new books",
    "start": "1816880",
    "end": "1824519"
  },
  {
    "text": "coming up in this area which will essentially talk about AI Dev cops right there are a lot of things you can do",
    "start": "1824519",
    "end": "1830480"
  },
  {
    "text": "here well now is the time to explore that before I end I would definitely like to thank",
    "start": "1830480",
    "end": "1836559"
  },
  {
    "text": "Lydia she went through a bunch of rehearsals with me with the in the coaching program thank you so much I",
    "start": "1836559",
    "end": "1842679"
  },
  {
    "text": "don't know if you're here but thanks a lot at this point I would open for questions uh there are mics out here on",
    "start": "1842679",
    "end": "1849679"
  },
  {
    "text": "each row if there's any question please walk up and I'll try and answer the best I",
    "start": "1849679",
    "end": "1855480"
  },
  {
    "text": "can thank you [Applause]",
    "start": "1855480",
    "end": "1863169"
  },
  {
    "text": "hi um do we have plans to do the same for let's say data governance issues uh",
    "start": "1866159",
    "end": "1871440"
  },
  {
    "text": "to detect it for that the uh the basic code around understanding the language",
    "start": "1871440",
    "end": "1877960"
  },
  {
    "text": "is still going to be the constant how you classify is what your choice was so like uh within data breaks we did",
    "start": "1877960",
    "end": "1884440"
  },
  {
    "text": "another set of classification after this where we are even it for high medium and low tomorrow you can use a privacy",
    "start": "1884440",
    "end": "1889919"
  },
  {
    "text": "detection you can do legal detection you can do data class sorry the data governments thing hey does this impact F",
    "start": "1889919",
    "end": "1895000"
  },
  {
    "text": "ramp or not right whatever you train on as long as you understand the language you should be good so I've tried it on",
    "start": "1895000",
    "end": "1900200"
  },
  {
    "text": "two or three use cases Wass great okay hi thank you for the presentation",
    "start": "1900200",
    "end": "1906159"
  },
  {
    "text": "did you validate whether the model did not miss some important part you you",
    "start": "1906159",
    "end": "1912760"
  },
  {
    "text": "have shown that okay obvious ones there are but I would guess that normal people",
    "start": "1912760",
    "end": "1918440"
  },
  {
    "text": "would revie would get the the normal ones but the one which would be missed yeah",
    "start": "1918440",
    "end": "1926320"
  },
  {
    "text": "so that's a great question this is actually why we always try to optimize on the F1 score on the chart right so",
    "start": "1926320",
    "end": "1932919"
  },
  {
    "text": "the F1 score basically talks about the true false positives and false negatives as well right a high F1 score usually",
    "start": "1932919",
    "end": "1938919"
  },
  {
    "text": "says that you are actually good on false POS for negatives as well and that range is like at least for the required ones",
    "start": "1938919",
    "end": "1945600"
  },
  {
    "text": "we missed like 2% the non-required you miss are like 1% so not so bad actually",
    "start": "1945600",
    "end": "1951000"
  },
  {
    "text": "thank you thank you it's regarding uh the vectorization",
    "start": "1951000",
    "end": "1958799"
  },
  {
    "text": "of the words did you look into other methods and also why did you choose that one so this technique is uh okay the",
    "start": "1958799",
    "end": "1967399"
  },
  {
    "text": "reason I chose it is because there are standard word vectors available for normal spoken English which you can just",
    "start": "1967399",
    "end": "1973200"
  },
  {
    "text": "download on the internet right those are pretty much uh well tested methods I think the glove 6 billion or something",
    "start": "1973200",
    "end": "1980440"
  },
  {
    "text": "uh it actually trains on the entire Wikipedia and Google and whatnot so I assume this was pretty well tested so",
    "start": "1980440",
    "end": "1987320"
  },
  {
    "text": "why not let's use the same technique create something s something similar but for the engineering and security domain so that's the reason thank you thank",
    "start": "1987320",
    "end": "1996679"
  },
  {
    "text": "you hi um you know when you showed UNS supervised learning and you had the clustering diagram yes I was just",
    "start": "1996679",
    "end": "2002880"
  },
  {
    "text": "wondering was the absence of good quality data from some of your sources",
    "start": "2002880",
    "end": "2007919"
  },
  {
    "text": "did that become an indicator that led to any action by the security team so the",
    "start": "2007919",
    "end": "2013519"
  },
  {
    "text": "absence of good quality data was something we felt a lot when we were trying to classify in the in the",
    "start": "2013519",
    "end": "2019399"
  },
  {
    "text": "severity of the problem so high medium and low because that's something which there is always a lot of um subjectivity",
    "start": "2019399",
    "end": "2026440"
  },
  {
    "text": "Associated to it whether this is a critical issue or not over here we almost used something like 6,000 documents on each side to",
    "start": "2026440",
    "end": "2034880"
  },
  {
    "text": "test it out and again the idea was never to actually pick up uh positive or",
    "start": "2034880",
    "end": "2040720"
  },
  {
    "text": "negative example but to pick up what language what natural language is used to talk about those areas so it worked",
    "start": "2040720",
    "end": "2046960"
  },
  {
    "text": "out pretty well actually thank",
    "start": "2046960",
    "end": "2050838"
  },
  {
    "text": "you hello MJ uh thank you very interesting uh presentation I have three",
    "start": "2053839",
    "end": "2059358"
  },
  {
    "text": "question the first one how much time did you spend to get CL this is the first",
    "start": "2059359",
    "end": "2065320"
  },
  {
    "text": "one second one uh um you talked about the anticipation I didn't think that you",
    "start": "2065320",
    "end": "2071839"
  },
  {
    "text": "have presented The Next Step about the presentation and the third one was uh",
    "start": "2071839",
    "end": "2077398"
  },
  {
    "text": "did you scratch the surface about the frequency of words based on the languages because if we have jera with",
    "start": "2077399",
    "end": "2084638"
  },
  {
    "text": "multiple languages it can be another conversion that's true the current",
    "start": "2084639",
    "end": "2090560"
  },
  {
    "text": "training is primarily on English we could uh we could always use that build a different vocabulary or maybe even",
    "start": "2090560",
    "end": "2096480"
  },
  {
    "text": "combine vocabularies because nothing in the code except for using the stop words is language specific so you can always",
    "start": "2096480",
    "end": "2102599"
  },
  {
    "text": "do that bring in multiple languages use different stop wordss you can play with that but other than that none of the code is to do anything to do with",
    "start": "2102599",
    "end": "2109359"
  },
  {
    "text": "specific language so that is still doable how much time did I spend I would say approximately a few I think couple",
    "start": "2109359",
    "end": "2116599"
  },
  {
    "text": "of months on this but yeah the yeah yeah",
    "start": "2116599",
    "end": "2122119"
  },
  {
    "text": "uh there's a funny story around it but some other day today is not the day and sorry I missed the second question",
    "start": "2122119",
    "end": "2127880"
  },
  {
    "text": "the anticipation part uh could you please elaborate on that",
    "start": "2127880",
    "end": "2134119"
  },
  {
    "text": "question I mean there's a significant anticipation on whether you would get it or not but you presented on one of one of your slide uh the way that you can uh",
    "start": "2134119",
    "end": "2142520"
  },
  {
    "text": "eventually forecast yes the number of tickets that would be treated in advance",
    "start": "2142520",
    "end": "2148760"
  },
  {
    "text": "correct so yeah that was I think uh this one right something like this right so",
    "start": "2148760",
    "end": "2155200"
  },
  {
    "text": "yeah I mean obviously there's a significant want of anticipation in that but eventually the quality is something which you if you just train on only jir",
    "start": "2155200",
    "end": "2163160"
  },
  {
    "text": "or only one area the quality is much much worse you have to start playing with a lot more sources like over here",
    "start": "2163160",
    "end": "2169440"
  },
  {
    "text": "for this Source I played with uh PRD documents with jro tickets with uh you",
    "start": "2169440",
    "end": "2176359"
  },
  {
    "text": "know public documentations of spark and all the associated things with spark and LP and P spk and whatnot anything which",
    "start": "2176359",
    "end": "2182520"
  },
  {
    "text": "is related anything you can find in that area and that sort of improves it am I saying you will never miss something no",
    "start": "2182520",
    "end": "2189119"
  },
  {
    "text": "there was a 2% error so I'm not saying that you'll never miss something but is it better than just relying on a",
    "start": "2189119",
    "end": "2195200"
  },
  {
    "text": "developer to make a judgment call and you're trusting it sure it's better thank you thank",
    "start": "2195200",
    "end": "2202599"
  },
  {
    "text": "you all right well thanks a lot guys thank you so much thanks for coming",
    "start": "2202599",
    "end": "2208690"
  },
  {
    "text": "[Applause] here",
    "start": "2208690",
    "end": "2214400"
  }
]
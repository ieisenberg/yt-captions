[
  {
    "text": "hello everyone thank you so much for being here at my talk I am akanga and I will be presenting about unmasking APS",
    "start": "2840",
    "end": "10120"
  },
  {
    "text": "and how we developed an automated approach for real world threat attribution so as I mentioned I'm akanga",
    "start": "10120",
    "end": "17119"
  },
  {
    "text": "and this is a work in collaboration with my advisers Professor Blasco from upm who is right here with me today",
    "start": "17119",
    "end": "23119"
  },
  {
    "text": "Professor cavalaro from UCL and Professor minina from",
    "start": "23119",
    "end": "28960"
  },
  {
    "text": "toen so uh before we begin a bit about myself and what makes me qualified to",
    "start": "28960",
    "end": "34239"
  },
  {
    "text": "talk about this stuff I am a third-year PhD student at Tu working in the",
    "start": "34239",
    "end": "39719"
  },
  {
    "text": "security and privacy Research Unit there I have a master's degree from University of Utah specializing in cyber security",
    "start": "39719",
    "end": "47600"
  },
  {
    "text": "and previously I also worked as a red teamer at Microsoft where we reverse engineered Malaya samples and looked",
    "start": "47600",
    "end": "54000"
  },
  {
    "text": "into some AP samples as well and that's where my interest for apds come in and",
    "start": "54000",
    "end": "59160"
  },
  {
    "text": "finally currently l i extremely passionate about using machine learning to solve security problems and that's",
    "start": "59160",
    "end": "65439"
  },
  {
    "text": "where this topic falls under and uh during my fun time if the weather permits I like to do",
    "start": "65439",
    "end": "72720"
  },
  {
    "text": "stargazing and how does the agenda for today looks like uh we will briefly introduce APS and how its attribution",
    "start": "72720",
    "end": "79360"
  },
  {
    "text": "looks like in the current scenario we are going to delve a little bit deeper into the current complexities and",
    "start": "79360",
    "end": "85320"
  },
  {
    "text": "challenges in attribution uh which kind of motivates us to propose our system",
    "start": "85320",
    "end": "90360"
  },
  {
    "text": "adapt which is an automated machine learning based attribution approach uh we also develop um strategy to evaluate",
    "start": "90360",
    "end": "97680"
  },
  {
    "text": "adapt on uh on a data set that we curated and finally we uh conclude with",
    "start": "97680",
    "end": "103759"
  },
  {
    "text": "next steps and some insights so in 2015 uh several uh",
    "start": "103759",
    "end": "111200"
  },
  {
    "text": "bundestag members German bundestag members which is the parliament members from Germany were affected by some",
    "start": "111200",
    "end": "117600"
  },
  {
    "text": "hackers that were supposedly backed by Russia and the whole idea was they had",
    "start": "117600",
    "end": "123360"
  },
  {
    "text": "these campaigns aligned to Russian interest and they wanted to uh get some secret uh sensitive data from these",
    "start": "123360",
    "end": "130000"
  },
  {
    "text": "bundestag members and usually these sophisticated attacks that against these",
    "start": "130000",
    "end": "135480"
  },
  {
    "text": "specific targets that have a very specific objective are known as advanced persistent threats and they often have",
    "start": "135480",
    "end": "142800"
  },
  {
    "text": "these experienced team of cyber criminals behind them who are well organized and typically well funded and",
    "start": "142800",
    "end": "149360"
  },
  {
    "text": "when you think think about APS the next thing you often think about is attribution so in a very generic term uh",
    "start": "149360",
    "end": "156840"
  },
  {
    "text": "when you associate a Cyber attack to an attacker it is what an attribution come",
    "start": "156840",
    "end": "162080"
  },
  {
    "text": "uh call is being called attribution so when the bundist attack happened in 2015",
    "start": "162080",
    "end": "167800"
  },
  {
    "text": "it was in October 2020 when the European Union announced sanctions against some Russian military officers who were um",
    "start": "167800",
    "end": "175760"
  },
  {
    "text": "attached to this group called ap28 also known as fancy bear and and some other aliases that we have been tracking ap28",
    "start": "175760",
    "end": "182640"
  },
  {
    "text": "as so this this idea of linking an activity to a known thread group or an",
    "start": "182640",
    "end": "187920"
  },
  {
    "text": "actor is what is termed as thread attribution and when it comes to thread",
    "start": "187920",
    "end": "194640"
  },
  {
    "text": "attribution uh what do we like to do well we definitely like to have fun and are very creative we have come up with",
    "start": "194640",
    "end": "202400"
  },
  {
    "text": "this AP nomenclature where we started associating Helix kitten Charming kitten",
    "start": "202400",
    "end": "207680"
  },
  {
    "text": "with Iranian based threat actors then we have all kind of pandas aquatic Panda",
    "start": "207680",
    "end": "212799"
  },
  {
    "text": "Sunrise Panda um for China based rat actors and as we saw in our previous",
    "start": "212799",
    "end": "217920"
  },
  {
    "text": "slide we had fancy bear primitive bear for threats originating from Russia and it's interesting that as the",
    "start": "217920",
    "end": "225120"
  },
  {
    "text": "number of AP actors kept growing we kept adding to this nomenclature and now we have leopards and tigers for South Asian",
    "start": "225120",
    "end": "232200"
  },
  {
    "text": "based threat actors uh specifically we have rattle snake for an Indian based threat actor and it's it's just crazy",
    "start": "232200",
    "end": "239480"
  },
  {
    "text": "how this murky world of AP attacks with its ever growing number of actors and",
    "start": "239480",
    "end": "244920"
  },
  {
    "text": "compounded by the lack of clarity in publicly available information it's becoming really hard to tell who's who",
    "start": "244920",
    "end": "251000"
  },
  {
    "text": "in the Cyber Zoo so as you can see I'm alluding to the fact that attribution is",
    "start": "251000",
    "end": "257479"
  },
  {
    "text": "challenging and it has its complexities so as researchers and security practitioners working in Academia we",
    "start": "257479",
    "end": "264400"
  },
  {
    "text": "have identified some bottleneck that can make attribution challenging and can add to the complexities so let's look into",
    "start": "264400",
    "end": "272000"
  },
  {
    "text": "uh some of these challenges so the very first thing we have identified is is this variation in",
    "start": "272000",
    "end": "278479"
  },
  {
    "text": "campaigns no longer threat actors are going for a one objective one entity kind of thing where you know that this",
    "start": "278479",
    "end": "285440"
  },
  {
    "text": "campaign which was supposedly targeting a financial institution is related to this AP actor X now they are crafting",
    "start": "285440",
    "end": "292680"
  },
  {
    "text": "these unique campaigns that they keep modifying based on the organization and the objectives that they are targeting",
    "start": "292680",
    "end": "299240"
  },
  {
    "text": "so for example there is a thread group one it is running two different campaigns X and Y completely using",
    "start": "299240",
    "end": "305160"
  },
  {
    "text": "different attack vectors and payloads uh while the threat campaign X is focused on Industrial control system",
    "start": "305160",
    "end": "312120"
  },
  {
    "text": "the threat campaign Y is more focused towards financial institutions and what happens is security vendors start",
    "start": "312120",
    "end": "318319"
  },
  {
    "text": "tracking these campaigns from different perspectives and they kind of start forming an incomplete and understanding",
    "start": "318319",
    "end": "324560"
  },
  {
    "text": "about the adversary we have these overlapping and fragmented information we don't know that this these two two",
    "start": "324560",
    "end": "329639"
  },
  {
    "text": "threat campaigns are the act of the same thread group who is operating these",
    "start": "329639",
    "end": "335440"
  },
  {
    "text": "campaigns um and secondly we all know and might agree with that this is one of",
    "start": "335440",
    "end": "340680"
  },
  {
    "text": "the common problems where we seen these shared similarities among the thread groups so uh this is this is an actual",
    "start": "340680",
    "end": "347759"
  },
  {
    "text": "case where Sidewinder which I mentioned is an Indian based threat actor and transparent tribe is another threat actor which works in which Target South",
    "start": "347759",
    "end": "354800"
  },
  {
    "text": "Asian countries they ended up using the same vbm macro code in their document M there were two different thread groups",
    "start": "354800",
    "end": "361360"
  },
  {
    "text": "and analyst until they analyzed the complete attack chain and it took them some years to make the connection that",
    "start": "361360",
    "end": "367560"
  },
  {
    "text": "they are two different groups but at first they attributed both the attacks to Sidewinder and it resulted in",
    "start": "367560",
    "end": "373120"
  },
  {
    "text": "misattribution and erronous attribution and moreover we we know that AP actors",
    "start": "373120",
    "end": "378400"
  },
  {
    "text": "reuse code they share tooling and in a recent report released by mandiant in 2023 they identified these multiple",
    "start": "378400",
    "end": "385759"
  },
  {
    "text": "subgroups of Lazarus which is the North Korean threat actor and how they have have been assigned to do specific task",
    "start": "385759",
    "end": "392000"
  },
  {
    "text": "and it just add to the complexity because if you don't cannot confidently track an activity to an entity you",
    "start": "392000",
    "end": "398160"
  },
  {
    "text": "either do misattribution you do erous attribution and you cannot confidently say that this attack was linked to this",
    "start": "398160",
    "end": "405919"
  },
  {
    "text": "actor moreover more uh on the technical side of the front these AP attacks are",
    "start": "406000",
    "end": "411319"
  },
  {
    "text": "made up of these different file types in their attack chain it's never just an executable it's never just a document",
    "start": "411319",
    "end": "417840"
  },
  {
    "text": "they are like these chain of ba loads that you have to analyze and sometimes it takes days months and years for for",
    "start": "417840",
    "end": "425319"
  },
  {
    "text": "analysts to manually analyze these uh these payloads and connect them to a thread actor or a thread group as you",
    "start": "425319",
    "end": "431720"
  },
  {
    "text": "saw in the mundag example that happened in 2015 but it wasn't attributed until 2020 once they identified all the",
    "start": "431720",
    "end": "438680"
  },
  {
    "text": "artifacts and connected it to the ap28 group so what I'm trying to say is um we",
    "start": "438680",
    "end": "446280"
  },
  {
    "text": "have to identify these Concepts and and these different these ideas that come",
    "start": "446280",
    "end": "451360"
  },
  {
    "text": "into place when you are attributing an AP you have the idea of thread Group which we all know is the entity Behind",
    "start": "451360",
    "end": "458120"
  },
  {
    "text": "these attacks but you also need to identify that there is this concept of threat Campaign which is not always",
    "start": "458120",
    "end": "464280"
  },
  {
    "text": "analogous to thread group you can have multiple threat campaigns and as we know that vendors start attributing malware",
    "start": "464280",
    "end": "471000"
  },
  {
    "text": "keep the malware names at the campaign names campaign names as the thread group names but that's not always the case and",
    "start": "471000",
    "end": "476960"
  },
  {
    "text": "then when you think about thread campaigns they have these multiple files within their attack chain so in light of",
    "start": "476960",
    "end": "483759"
  },
  {
    "text": "these challenges and when we identify that there is these Concepts we need to differentiate and",
    "start": "483759",
    "end": "489960"
  },
  {
    "text": "disassociate we came up with our approach adapt um I'm sorry for the short name that is the best we can come",
    "start": "489960",
    "end": "496599"
  },
  {
    "text": "up with but it stands for attribution of diverse APD samples and the diversity",
    "start": "496599",
    "end": "502039"
  },
  {
    "text": "comes from the fact that we differentiate our approach from the prior work that has been done in this",
    "start": "502039",
    "end": "507800"
  },
  {
    "text": "area which focuses either on executables we want to take care of all the heterogeneous files that are in the F uh",
    "start": "507800",
    "end": "513680"
  },
  {
    "text": "in the attack chain so our approach takes care of all the different file types our feature extraction and",
    "start": "513680",
    "end": "519039"
  },
  {
    "text": "clustering make sure that we work with a uniform sample Set uh and then moreover as I mentioned",
    "start": "519039",
    "end": "525560"
  },
  {
    "text": "the campaign and the group level we do attribution at two levels so the first is the campaign level where we are more",
    "start": "525560",
    "end": "532240"
  },
  {
    "text": "interested in identifying the characteristics of the attack uh here we look into the samples stacus the",
    "start": "532240",
    "end": "538560"
  },
  {
    "text": "techniques that that they are using and try to identify if a sample could be a part of an AP campaign what that helps",
    "start": "538560",
    "end": "544800"
  },
  {
    "text": "is if you have seen a sample that has same tactics and techniques used prior",
    "start": "544800",
    "end": "549880"
  },
  {
    "text": "you can actually prioritize the detection and mitigation moreover when you look at the",
    "start": "549880",
    "end": "555240"
  },
  {
    "text": "group attribution we are more interested in the characteristics of the attacker there and not the attack and this is",
    "start": "555240",
    "end": "561519"
  },
  {
    "text": "this is where we separate ourselves we focus on a different set of features and characteristics and that in turn helps",
    "start": "561519",
    "end": "568240"
  },
  {
    "text": "with forensic in investigation and indictments so in a nutshell adapt is an",
    "start": "568240",
    "end": "574240"
  },
  {
    "text": "automated machine learning based attribution approach where we trying to do a systematic approach of to",
    "start": "574240",
    "end": "580160"
  },
  {
    "text": "attribution by separating it at campaign level and group level with that said uh let's go look",
    "start": "580160",
    "end": "587360"
  },
  {
    "text": "into our system design and look at the different phases that constitute adapt and how we achieve our",
    "start": "587360",
    "end": "594000"
  },
  {
    "text": "goals as I said I am into stargazing so I thought I'd show some pretty pictures to kind kind of convey the idea of the",
    "start": "594000",
    "end": "600440"
  },
  {
    "text": "different phases that we have uh we start with data set collection we rely on open source AP samples that have been",
    "start": "600440",
    "end": "607760"
  },
  {
    "text": "identified and we collect those ra raw APD samples in our data set collection phase once we have that we do feature",
    "start": "607760",
    "end": "615920"
  },
  {
    "text": "extraction where we extract statically raw features from these samples and once",
    "start": "615920",
    "end": "621680"
  },
  {
    "text": "we do that we transform them to a higher dimensional space which is where our feature transformation comes in to make",
    "start": "621680",
    "end": "627560"
  },
  {
    "text": "them suitable for our machine learning algorithms and finally we do clustering where we focus on campaign and group",
    "start": "627560",
    "end": "633760"
  },
  {
    "text": "level clustering based on the features that we identified from these samples with that said um our first",
    "start": "633760",
    "end": "641279"
  },
  {
    "text": "phase data set collection so we completely rely on open source here uh",
    "start": "641279",
    "end": "646760"
  },
  {
    "text": "we uh Ed the platform called Alien Vault which is a very popular platform for",
    "start": "646760",
    "end": "651839"
  },
  {
    "text": "companies and researchers to share information about the emerging threads and we we are actually thankful for",
    "start": "651839",
    "end": "658560"
  },
  {
    "text": "alien because they uh they have like a super nice API where you can just give the AP tag and it will extract all the",
    "start": "658560",
    "end": "665360"
  },
  {
    "text": "related AP hashes that it has seen and the researchers have tagged we also",
    "start": "665360",
    "end": "670519"
  },
  {
    "text": "extracted AP labels from them because usually when researchers um analyze",
    "start": "670519",
    "end": "676200"
  },
  {
    "text": "these samples they also tag it with the AP group that they identified it so we extract that but to download the samples",
    "start": "676200",
    "end": "682800"
  },
  {
    "text": "we rely on varus toal so we had the researcher access to varus toal and we were able to download the samples and as",
    "start": "682800",
    "end": "689160"
  },
  {
    "text": "a result we had 6,545 samples in our data set and again",
    "start": "689160",
    "end": "694399"
  },
  {
    "text": "I mentioned that we are not just focusing on binaries we actually ended up with around 22 plus different file",
    "start": "694399",
    "end": "699800"
  },
  {
    "text": "types in our data set uh we will get to it later and then uh the number of AP",
    "start": "699800",
    "end": "705440"
  },
  {
    "text": "groups that the that were distributed in our data set was about uh 172 AP groups",
    "start": "705440",
    "end": "712079"
  },
  {
    "text": "so as I said data set quality file type uh I'm sorry if the x-axis might look a",
    "start": "712079",
    "end": "718360"
  },
  {
    "text": "little uh um to uh messy but what I want to focus is definitely we if you see the",
    "start": "718360",
    "end": "724399"
  },
  {
    "text": "first two bars it is the windows 32 e exe and windows 32 dll that makes up for",
    "start": "724399",
    "end": "729480"
  },
  {
    "text": "the majority of our file type we had around 3,600 files belonging to this category but we would also like to focus",
    "start": "729480",
    "end": "737320"
  },
  {
    "text": "on this next set of files that makes up our data set which is well not",
    "start": "737320",
    "end": "743440"
  },
  {
    "text": "surprising but still you can see that the uh top four are the word or the",
    "start": "743440",
    "end": "748959"
  },
  {
    "text": "document based file formats we have the oxl the msword the RTF Excel and",
    "start": "748959",
    "end": "754760"
  },
  {
    "text": "surprisingly we have a lot of Android files in our data set as well and following up with link files which are",
    "start": "754760",
    "end": "760199"
  },
  {
    "text": "the window shortcut and zip files so that kind of emphasizes more that we need to look into these different file",
    "start": "760199",
    "end": "767240"
  },
  {
    "text": "types that we are seeing in this landscape and we need to take into account that any approach or systematic",
    "start": "767240",
    "end": "772600"
  },
  {
    "text": "attribution that we do takes care of these different file types to make an attribution",
    "start": "772600",
    "end": "777839"
  },
  {
    "text": "claim uh moving on uh this is the fun part",
    "start": "777839",
    "end": "783440"
  },
  {
    "text": "when we looked into the group labels in our data set we identified that around 35% of our samples have more than one",
    "start": "783440",
    "end": "790800"
  },
  {
    "text": "label attached to it and you might all know where this problem coming from is from us having these different aliases",
    "start": "790800",
    "end": "797680"
  },
  {
    "text": "and nomenclature so this is just a snippet from Microsoft thread actor naming convention where they moved on to",
    "start": "797680",
    "end": "803839"
  },
  {
    "text": "the new name of weather weather based but they also had to unlist these other",
    "start": "803839",
    "end": "809360"
  },
  {
    "text": "names which are like primitive bear and camaron for actinium that they used to previously track with and so on and so",
    "start": "809360",
    "end": "815839"
  },
  {
    "text": "forth so and this is this just the lower bound like in our data set we saw some amount of samples that had 15 names",
    "start": "815839",
    "end": "822519"
  },
  {
    "text": "associated with with some 2% of the samples in our data set so this is just the lower bound uh but yeah this this is",
    "start": "822519",
    "end": "830720"
  },
  {
    "text": "this is a problem like if you want to do if you create a system and if you want to do robust evaluation you just cannot",
    "start": "830720",
    "end": "836720"
  },
  {
    "text": "do when when when the ground truth is is not right um so so just curiosity show",
    "start": "836720",
    "end": "842519"
  },
  {
    "text": "off hand who thinks that this is an actual problem and we need to do something about",
    "start": "842519",
    "end": "848079"
  },
  {
    "text": "this okay okay good to know so yes so we we struggled with this because we were",
    "start": "848079",
    "end": "854040"
  },
  {
    "text": "working with machine learning based systems we had to have proper evaluation and we need to if we need to evaluate",
    "start": "854040",
    "end": "859160"
  },
  {
    "text": "something we need to have proper ground truth labeling so what did we do we had",
    "start": "859160",
    "end": "864680"
  },
  {
    "text": "a rigorous relabeling process where we literally uh looked through the samples",
    "start": "864680",
    "end": "869880"
  },
  {
    "text": "we had two researchers assigned on the data set they looked through the threat reports they identified the standardized",
    "start": "869880",
    "end": "875639"
  },
  {
    "text": "any aliases and we try to have a consistent naming scheme we do not we do",
    "start": "875639",
    "end": "880800"
  },
  {
    "text": "not say that something is right or something is wrong but B feel that we want to move away from the textual names",
    "start": "880800",
    "end": "887399"
  },
  {
    "text": "so we tried to have a consistent naming scheme of APs XX ta for threat actor xx",
    "start": "887399",
    "end": "893800"
  },
  {
    "text": "and Finn for financially based threat groups so wherever possible we remove the alas we moved to a consistent naming",
    "start": "893800",
    "end": "900440"
  },
  {
    "text": "convention and we also removed any non-unique samples or nonap samples",
    "start": "900440",
    "end": "905680"
  },
  {
    "text": "interestingly uh couple of hundred of samples uh in our data set belong to the stolen red team tools that were stolen",
    "start": "905680",
    "end": "912800"
  },
  {
    "text": "during the fire eye uh during the solar wind campaign so that were not really attacker samples but uh thankfully",
    "start": "912800",
    "end": "919240"
  },
  {
    "text": "because of this relabeling and cleaning process we realized that those does not belong there so we removed that and",
    "start": "919240",
    "end": "925800"
  },
  {
    "text": "finally we ended up with 6,134 samples but only assigned to 92",
    "start": "925800",
    "end": "931160"
  },
  {
    "text": "groups so you can see that from 174 we went to a reduction of 92 groups so that",
    "start": "931160",
    "end": "936639"
  },
  {
    "text": "means that we we might not have that many AP groups we might think so just by",
    "start": "936639",
    "end": "942360"
  },
  {
    "text": "relabeling process and cleaning process so just just a thought out there um yeah",
    "start": "942360",
    "end": "947920"
  },
  {
    "text": "so now we deal with this this clean data set right here so and the spirit of Open",
    "start": "947920",
    "end": "953199"
  },
  {
    "text": "Source we have also released our standardized group label data set at this uh at this URL so feel free to",
    "start": "953199",
    "end": "959480"
  },
  {
    "text": "explore the data set uh leave any feedback or comment if you have any and I would also like to point out that our",
    "start": "959480",
    "end": "965639"
  },
  {
    "text": "work is currently under academic publication so we are going through this uh blind review process once our paper",
    "start": "965639",
    "end": "972399"
  },
  {
    "text": "is out we will publish our paper with more details and our source code as well so you can have a look at that at the",
    "start": "972399",
    "end": "978600"
  },
  {
    "text": "same same URL moving on to feature extraction so",
    "start": "978600",
    "end": "984160"
  },
  {
    "text": "as I mentioned we only focus on static analysis to feature to extract features from the hetrogeneous files that we have",
    "start": "984160",
    "end": "990040"
  },
  {
    "text": "in our data set and also I would like to point out here that we do not reinvent any wheel we are actually using very",
    "start": "990040",
    "end": "996759"
  },
  {
    "text": "popular malw forensics tool we believe the community has developed they are really great they work flawlessly uh we",
    "start": "996759",
    "end": "1003040"
  },
  {
    "text": "just had to make some changes to automate it with our to automate it and make it work with our data set so we are",
    "start": "1003040",
    "end": "1009079"
  },
  {
    "text": "not using any new um any new tool or not creating any new tools so in that regard",
    "start": "1009079",
    "end": "1014360"
  },
  {
    "text": "we uh we rely on floss which is a very good tool for extra rating strings from",
    "start": "1014360",
    "end": "1019839"
  },
  {
    "text": "from all the samples so that was that gave us the strings from the samples then we also rely on Yara rules",
    "start": "1019839",
    "end": "1025319"
  },
  {
    "text": "specifically the malc uh rule set to uh identify any rules trigger within our",
    "start": "1025319",
    "end": "1030360"
  },
  {
    "text": "sample set and then we use exif tool to extract file metadata these are all open source tools",
    "start": "1030360",
    "end": "1036880"
  },
  {
    "text": "you can use it you can uh use their libraries to automate it and that's what we did and as I said that the two",
    "start": "1036880",
    "end": "1043240"
  },
  {
    "text": "dominant file types in our data set were executable and documents so we also employ specific tools to extract",
    "start": "1043240",
    "end": "1049840"
  },
  {
    "text": "features from them and these being olet tools which is another very popular commonly available malware forensics",
    "start": "1049840",
    "end": "1055760"
  },
  {
    "text": "tool for documents uh it gave us the presence if uh if a vbm Agro code is",
    "start": "1055760",
    "end": "1061320"
  },
  {
    "text": "present in a document or any suspicious strings and then Leaf is another uh library for instrumenting executable",
    "start": "1061320",
    "end": "1068080"
  },
  {
    "text": "file formats and we were able to extract API calls and Library names and imported",
    "start": "1068080",
    "end": "1073679"
  },
  {
    "text": "and exported functions from our executable file formats so now that we have these",
    "start": "1073679",
    "end": "1079440"
  },
  {
    "text": "features how do we actually use these different feature categories to do our attribution as I said we do campaign",
    "start": "1079440",
    "end": "1086159"
  },
  {
    "text": "level and group and campaign is more about the sample related features more about uh the attack itself so we combine",
    "start": "1086159",
    "end": "1093559"
  },
  {
    "text": "the specific and the generic feature the generic which I mentioned the strings the Yara rules along with the specific",
    "start": "1093559",
    "end": "1098760"
  },
  {
    "text": "features that we get for documents and um ex executable file formats and that",
    "start": "1098760",
    "end": "1103960"
  },
  {
    "text": "really helps us identifying the capabilities of a sample itself and in turn do campaign attribution but when we",
    "start": "1103960",
    "end": "1111520"
  },
  {
    "text": "do group attribution we introduce an interesting set of features that we believe could be distinctive patterns",
    "start": "1111520",
    "end": "1117679"
  },
  {
    "text": "for a thread actor or a thread group and we call them linking features so what are these linking features um we divide",
    "start": "1117679",
    "end": "1124919"
  },
  {
    "text": "these linking features and this has been um used by thread analyst already like",
    "start": "1124919",
    "end": "1130320"
  },
  {
    "text": "they know that these infrastructure traits and operational patterns could be interesting linking traits that could",
    "start": "1130320",
    "end": "1135720"
  },
  {
    "text": "identify a threat group or threat actor so in that regard we have these regular expression based patterns that we try to",
    "start": "1135720",
    "end": "1142240"
  },
  {
    "text": "extract from the strings of the files that we already got from the floss uh as I mentioned so in this we were",
    "start": "1142240",
    "end": "1148320"
  },
  {
    "text": "particularly looking for things like any URL present within the string content any IP addresses that we might have",
    "start": "1148320",
    "end": "1155280"
  },
  {
    "text": "uncovered any file parts that the sample might have existed and we were also",
    "start": "1155280",
    "end": "1160440"
  },
  {
    "text": "looking for Bitcoin addresses email addresses any slack tokens API keys because that could be a good indicator",
    "start": "1160440",
    "end": "1166799"
  },
  {
    "text": "of a thread group or an actor be it uh moreover we also rely on census",
    "start": "1166799",
    "end": "1172840"
  },
  {
    "text": "open source threat intelligence to extract second level features on our URLs and IP addresses we believe that",
    "start": "1172840",
    "end": "1179760"
  },
  {
    "text": "URL and IP address in itself would not be a good indicator so we go a bit extra and for the IP addresses we were also",
    "start": "1179760",
    "end": "1186799"
  },
  {
    "text": "interested to look at the bgb prefixes and the ASN number and country code and",
    "start": "1186799",
    "end": "1192600"
  },
  {
    "text": "for the URLs or any domain names we were interested in certificate fingerprints or the issuer organiz ization of the URL",
    "start": "1192600",
    "end": "1200600"
  },
  {
    "text": "that it might be calling in the S sample so with this combination of which we call like pattern Bas and infrastructure",
    "start": "1200600",
    "end": "1207280"
  },
  {
    "text": "trades we we believe that we could actually be making the right attribution",
    "start": "1207280",
    "end": "1212520"
  },
  {
    "text": "claims when we do group level attribution moving on to feature",
    "start": "1212520",
    "end": "1218600"
  },
  {
    "text": "transformation so here as I mentioned we were working with hetrogeneous file types and we had features from all these",
    "start": "1218600",
    "end": "1225360"
  },
  {
    "text": "different sources so we had to do a couple of transformation steps to make sure that they are compatible for the",
    "start": "1225360",
    "end": "1230960"
  },
  {
    "text": "machine learning algorithm so uh this was this was a process which we had to do which is called normalization we had",
    "start": "1230960",
    "end": "1237480"
  },
  {
    "text": "to make sure that a feature means the same across different file types so when you get a language code for a document",
    "start": "1237480",
    "end": "1243640"
  },
  {
    "text": "it ideally means the resource language of executable so we had to make sure that we normalize across different file",
    "start": "1243640",
    "end": "1249559"
  },
  {
    "text": "types so they mean the same uh next we use one hot encoding which is a very",
    "start": "1249559",
    "end": "1254760"
  },
  {
    "text": "popular technique also used uh in Prior work where we convert these categorical",
    "start": "1254760",
    "end": "1260080"
  },
  {
    "text": "features uh so let's say a sample triggered the following Yara rules of uh the compiler the Linker key logger API",
    "start": "1260080",
    "end": "1267159"
  },
  {
    "text": "so we explored the list of all the Yara rules in our in our data set that were captured and then we assigned true to",
    "start": "1267159",
    "end": "1273559"
  },
  {
    "text": "the ones for this sample that was triggered so either true or zero and then we got get our one hot",
    "start": "1273559",
    "end": "1280000"
  },
  {
    "text": "encoding uh moving on to string vectorizer so since we had string uh features uh we had to deal with them so",
    "start": "1280000",
    "end": "1286400"
  },
  {
    "text": "definitely that needs a lot of pre-process Ing and cleaning and once we were able to remove some garbage string",
    "start": "1286400",
    "end": "1291679"
  },
  {
    "text": "we kind of employed this technique count vectorizer again a popular technique used have been used in Prior research",
    "start": "1291679",
    "end": "1298039"
  },
  {
    "text": "where uh what it does is it counts the frequency of each string token without the sample and then it represents a",
    "start": "1298039",
    "end": "1304480"
  },
  {
    "text": "vectorized table like this so if you have two samples which triggered let's say the following two string um",
    "start": "1304480",
    "end": "1310760"
  },
  {
    "text": "dictionary and it just converts them to a vectorized table where it counts the frequency of each string token per",
    "start": "1310760",
    "end": "1317039"
  },
  {
    "text": "sample and finally we also employ a sentence Transformer model to do word embedding",
    "start": "1317039",
    "end": "1324000"
  },
  {
    "text": "and this was specifically useful for us uh so what it does is it encodes the textual pattern-based feature let's say",
    "start": "1324000",
    "end": "1330720"
  },
  {
    "text": "into a compact Vector space and tries some kind of a similarity score to",
    "start": "1330720",
    "end": "1336200"
  },
  {
    "text": "identify near similar features so let's say a sample that calls a dropbox.com",
    "start": "1336200",
    "end": "1341559"
  },
  {
    "text": "versus if you find another sample that calls this um x.u we try to encode them in the vector",
    "start": "1341559",
    "end": "1348960"
  },
  {
    "text": "space which are far from each other because there is hardly any similarity in the URLs but if we find another",
    "start": "1348960",
    "end": "1354559"
  },
  {
    "text": "sample which calls another set of Ru domains we will put them together so this in turn helps in efficient",
    "start": "1354559",
    "end": "1360760"
  },
  {
    "text": "clustering based on the proximity of the near similar features that we",
    "start": "1360760",
    "end": "1366440"
  },
  {
    "text": "found and finally moving on to our modeling and clustering phase so a",
    "start": "1367120",
    "end": "1372640"
  },
  {
    "text": "little bit of intuition why we went for clustering so we know that we have these unsupervised clustering algor gorithms",
    "start": "1372640",
    "end": "1378400"
  },
  {
    "text": "and supervised classification so for supervised classification you need a really good ground truth labeling you",
    "start": "1378400",
    "end": "1384840"
  },
  {
    "text": "need good train and test data set but in our situation we we do lack standardized ground truth label and we saw it from",
    "start": "1384840",
    "end": "1391200"
  },
  {
    "text": "our our data set collection and and we know this in this community we we do lack this ground truth labeling and and",
    "start": "1391200",
    "end": "1398120"
  },
  {
    "text": "we know that there are currently no proper data set for threat campaigns so we chose the route for unsupervised",
    "start": "1398120",
    "end": "1405240"
  },
  {
    "text": "clustering which does not rely on external ground truth it can infer patterns from the data within itself and",
    "start": "1405240",
    "end": "1412000"
  },
  {
    "text": "can do the clustering from the pattern in infer patterns within the data so",
    "start": "1412000",
    "end": "1418760"
  },
  {
    "text": "typically we use this thing called agglomerative hierarchical clustering which is cluster samples based on some",
    "start": "1418760",
    "end": "1425400"
  },
  {
    "text": "distance metrics hierar in in a hierarchy and that that really helped us in doing this uh campaign attribution",
    "start": "1425400",
    "end": "1431919"
  },
  {
    "text": "for executable and document files and group attribution for all the files and this is a library available in pyit",
    "start": "1431919",
    "end": "1437600"
  },
  {
    "text": "learn uh you can go there for more details and it tells you how to run your algorithm with once you have your features",
    "start": "1437600",
    "end": "1445640"
  },
  {
    "text": "transformed with that said uh we come back to our evaluation phase and that",
    "start": "1445840",
    "end": "1451320"
  },
  {
    "text": "was some process uh again to do robust evaluation you need proper and right ground FRS",
    "start": "1451320",
    "end": "1458120"
  },
  {
    "text": "because if I say that something is AP1 but ground tooth is saying something",
    "start": "1458120",
    "end": "1463200"
  },
  {
    "text": "else then I don't have a right right way of evaluating my results with what is currently available so we we had to do",
    "start": "1463200",
    "end": "1470919"
  },
  {
    "text": "some some work there to figure out how to do evaluation and if we compare it with any supervised classification task",
    "start": "1470919",
    "end": "1477640"
  },
  {
    "text": "you have a train set and you have a test set so we had to come up with something similar even though we don't really have",
    "start": "1477640",
    "end": "1483279"
  },
  {
    "text": "a concept of training and test but we had to come up with a reference data set which we call and miter really helped us",
    "start": "1483279",
    "end": "1490159"
  },
  {
    "text": "here so if you're not aware aware miter recently started tracking campaigns good",
    "start": "1490159",
    "end": "1495840"
  },
  {
    "text": "for us and it was just around the the time when we started uh thinking about evaluating our system we were just",
    "start": "1495840",
    "end": "1501640"
  },
  {
    "text": "talking about how to do a quantitative evaluation we can of course do a lot of case studies qualitatively identify if",
    "start": "1501640",
    "end": "1507760"
  },
  {
    "text": "we clustered samples together but um so in this um uh campaign knowledge based",
    "start": "1507760",
    "end": "1514120"
  },
  {
    "text": "so miter already used to track groups but there there was no proper uh framework for campaign so we identified",
    "start": "1514120",
    "end": "1520520"
  },
  {
    "text": "that okay this could be a good data set we can create our own data set similar to to test our results and currently I",
    "start": "1520520",
    "end": "1527760"
  },
  {
    "text": "interestingly there are 24 campaigns which is which is they are still working but at the time when we were evaluating",
    "start": "1527760",
    "end": "1533240"
  },
  {
    "text": "adapt uh there were only 22 campaigns so we worked with what we had and I hope that they keep adding it to it and it",
    "start": "1533240",
    "end": "1539919"
  },
  {
    "text": "will be a good database and a knowledge base for identifying threat campaigns so what we did was we reached out to all",
    "start": "1539919",
    "end": "1546399"
  },
  {
    "text": "the threat reports associated with these campaign and labeled them with the campaign ID as you see here the",
    "start": "1546399",
    "end": "1552399"
  },
  {
    "text": "c28 and identified the respective group as well for these campaigns they are",
    "start": "1552399",
    "end": "1557919"
  },
  {
    "text": "usually in the thread groups they have identified the associated thread groups so now we had a proper data set which is",
    "start": "1557919",
    "end": "1565360"
  },
  {
    "text": "campaign and group labeled so good for us uh and once we had this reference or",
    "start": "1565360",
    "end": "1570919"
  },
  {
    "text": "test data set that we call we uh tested our uh results and this is what um just",
    "start": "1570919",
    "end": "1578080"
  },
  {
    "text": "like in any supervised classification task you compare the clustering results with the ground truth and we compared it",
    "start": "1578080",
    "end": "1584000"
  },
  {
    "text": "in the um and in Precision recall and F1 score so when we identified campaigns",
    "start": "1584000",
    "end": "1589840"
  },
  {
    "text": "for the executables we got around 91% Precision for documents we achieved a higher Precision of 98% where it could",
    "start": "1589840",
    "end": "1597440"
  },
  {
    "text": "actually identify a document to the right campaign and then for the coup clustering we got a Precision of",
    "start": "1597440",
    "end": "1604760"
  },
  {
    "text": "84% so while an F score of 80 to 90% it it sounds good especially in",
    "start": "1604760",
    "end": "1609880"
  },
  {
    "text": "unsupervised setting where you are not learning with the ground proo data uh we also wanted to analyze how analysts",
    "start": "1609880",
    "end": "1616679"
  },
  {
    "text": "could leverage this adapt in their workflow and this will provide more of a practical understanding of adapts",
    "start": "1616679",
    "end": "1622799"
  },
  {
    "text": "capability so a little bit to the fun fun side of it uh we did some",
    "start": "1622799",
    "end": "1629120"
  },
  {
    "text": "qualitative evaluation and I'm going to take you through one case study that we identified and how adapt helped us",
    "start": "1629120",
    "end": "1636880"
  },
  {
    "text": "there uh in July 2020 uh the UK's uh National cyber security Center released",
    "start": "1636880",
    "end": "1643039"
  },
  {
    "text": "an advisory report if you're not a aware so in there's in that report they identify that apt29 is targeting vaccine",
    "start": "1643039",
    "end": "1650760"
  },
  {
    "text": "uh covid-19 vaccine developers in globally across different organizations in Canada in UK in us and as a part of",
    "start": "1650760",
    "end": "1658240"
  },
  {
    "text": "that campaign they in their report they wrote that this APD 29 was using the malware Wells and well mail which are",
    "start": "1658240",
    "end": "1665360"
  },
  {
    "text": "these lightweight malware and can and are designed to execute arbitrary shell commands they can upload or download",
    "start": "1665360",
    "end": "1671880"
  },
  {
    "text": "files but what was interesting was um this group has been using this malware",
    "start": "1671880",
    "end": "1677960"
  },
  {
    "text": "already since 2018 uh and we realized that um the Japan computer emergency response team",
    "start": "1677960",
    "end": "1684919"
  },
  {
    "text": "has already called out this malware Wellness which was targeting Linux and windows um Windows system in their in",
    "start": "1684919",
    "end": "1691279"
  },
  {
    "text": "their organizations but at that time it was unattributed it just said that it was it was it was a malware there we are",
    "start": "1691279",
    "end": "1697919"
  },
  {
    "text": "being affected so be aware but it was only in 2020 when we were able to attribute it to apt29 which is the",
    "start": "1697919",
    "end": "1704559"
  },
  {
    "text": "Russia's foreign intelligence services and what adapt did was when we",
    "start": "1704559",
    "end": "1709600"
  },
  {
    "text": "looked into our clustering and the samples we realized that we had samples of wellmess and well mail in our data",
    "start": "1709600",
    "end": "1715320"
  },
  {
    "text": "set which dated back since 2017 and we actually clustered them together to the",
    "start": "1715320",
    "end": "1720360"
  },
  {
    "text": "same entity and what helped it here basically we kind of streamlined and automate this",
    "start": "1720360",
    "end": "1726279"
  },
  {
    "text": "process we have both elf and executable files and we were able to Cluster it to the same entity ideally saying that they",
    "start": "1726279",
    "end": "1732200"
  },
  {
    "text": "all belong to apt29 and what what really helped us here are some of the feat feates when we",
    "start": "1732200",
    "end": "1738000"
  },
  {
    "text": "went and looked into these samples and reverse engineered them we realized that they were all using the goang uh",
    "start": "1738000",
    "end": "1745159"
  },
  {
    "text": "compiler they for both the elf and the executable file types so they had these",
    "start": "1745159",
    "end": "1750440"
  },
  {
    "text": "goang binaries and then they were using this uh Yara signature called post HTTP",
    "start": "1750440",
    "end": "1756000"
  },
  {
    "text": "form uh within all their samples which helped us cluster them together and finally they were also using this",
    "start": "1756000",
    "end": "1762559"
  },
  {
    "text": "elliptic curve cryptographic protocol which is very peculiar this curve 25519 in samples and um at places within the",
    "start": "1762559",
    "end": "1770360"
  },
  {
    "text": "string contents we also found uh encryption and decryption um routines by",
    "start": "1770360",
    "end": "1775640"
  },
  {
    "text": "from rc6 Cipher block so what I'm trying to say is these distinct signatures and",
    "start": "1775640",
    "end": "1781720"
  },
  {
    "text": "patterns have already been used by thread analyst in like manually analyzing but adap just streamlined the",
    "start": "1781720",
    "end": "1787640"
  },
  {
    "text": "process of doing this by by clustering these samples together and saying that they belong to the same thread group",
    "start": "1787640",
    "end": "1793960"
  },
  {
    "text": "irrespective of the file type so you just throw the file type it normalizes the features transforms it and clusters",
    "start": "1793960",
    "end": "1799320"
  },
  {
    "text": "it and gives you that they belong they might belong to the same cluster and we have more so in the",
    "start": "1799320",
    "end": "1806640"
  },
  {
    "text": "interest of time um I would um I would not be covering all the case studies and I would direct you to our paper again",
    "start": "1806640",
    "end": "1813360"
  },
  {
    "text": "because our paper covers another interesting case study from the North Korean uh AP group Lazarus which was uh",
    "start": "1813360",
    "end": "1820080"
  },
  {
    "text": "which was um involved in the financial institution and Bitcoin currency stealing uh thing and we were able to",
    "start": "1820080",
    "end": "1826799"
  },
  {
    "text": "associate a lot of samples together and we also had some cases of unattributed",
    "start": "1826799",
    "end": "1832120"
  },
  {
    "text": "sample which we which were able to Cluster uh to unknown thread group or threat actors so again once our paper is",
    "start": "1832120",
    "end": "1838559"
  },
  {
    "text": "up there feel free to explore and look into more interesting case studies that that we cover",
    "start": "1838559",
    "end": "1844080"
  },
  {
    "text": "there with that said what's what's next for us um so as I said uh security",
    "start": "1844080",
    "end": "1850840"
  },
  {
    "text": "practitioners from Academia we have tried to attempt uh tried and attempted to address the complexities of",
    "start": "1850840",
    "end": "1856440"
  },
  {
    "text": "attribution and AP attribution in specific and as we strive to refine our",
    "start": "1856440",
    "end": "1861919"
  },
  {
    "text": "approach we are actually uh moving on into our next phase which we call adap 2.0 again sorry for the names we have to",
    "start": "1861919",
    "end": "1869960"
  },
  {
    "text": "be more creative just like our industry is with ap tracking so so yes in this",
    "start": "1869960",
    "end": "1876840"
  },
  {
    "text": "adapt 2.0 uh we kind of want to initiate a knowledge exchange with cyber Security",
    "start": "1876840",
    "end": "1882760"
  },
  {
    "text": "Professionals and experts like you who are working in this space who are dealing with the complex of AP",
    "start": "1882760",
    "end": "1888080"
  },
  {
    "text": "attribution and attribution in general and and gain a deep Insight like how you do it and how does your workflow looks",
    "start": "1888080",
    "end": "1894399"
  },
  {
    "text": "like and what are the common challenges you you deal with and what are the areas of improvement that we as researchers",
    "start": "1894399",
    "end": "1900480"
  },
  {
    "text": "can help you solve them so we can all make a better and useful research",
    "start": "1900480",
    "end": "1906159"
  },
  {
    "text": "prototype so with that said uh I invite you everyone to go to our project",
    "start": "1906159",
    "end": "1911919"
  },
  {
    "text": "website you can either uh scan the QR code or go to the link provided below which is the SE r.v. adap page so we",
    "start": "1911919",
    "end": "1919799"
  },
  {
    "text": "have our project website it describes all the next phases of the research that we are we are um embarking on and what",
    "start": "1919799",
    "end": "1927480"
  },
  {
    "text": "what we actually want and you you just need to give like an hour of your time to make us understand how as as",
    "start": "1927480",
    "end": "1934760"
  },
  {
    "text": "researchers and Industry professionals we can come together and make this space",
    "start": "1934760",
    "end": "1940080"
  },
  {
    "text": "uh make this space uh and and work together to kind of solve this problem of attribution and understand the",
    "start": "1940080",
    "end": "1946279"
  },
  {
    "text": "complexities together together so uh with that said I would be wrapping up my talk now",
    "start": "1946279",
    "end": "1953200"
  },
  {
    "text": "with some of the key highlights that um I think that we we need uh we believe",
    "start": "1953200",
    "end": "1958519"
  },
  {
    "text": "that are important to consider so when it comes to attribution we need to go towards the systematic attribution",
    "start": "1958519",
    "end": "1964399"
  },
  {
    "text": "approach we want to disassociate a threat campaign from a thread group we want to identify how to properly name",
    "start": "1964399",
    "end": "1971080"
  },
  {
    "text": "these uh things so we have a better approach to solving this problem and uh",
    "start": "1971080",
    "end": "1976200"
  },
  {
    "text": "finally I also want to highlight the fact that we need to consider these diverse area of file types that have",
    "start": "1976200",
    "end": "1982799"
  },
  {
    "text": "been present in this landscape and and we need to look at them holistically rather than just focusing on either",
    "start": "1982799",
    "end": "1988480"
  },
  {
    "text": "executable and documents and and we need to develop some kind of a system that takes care of that and as I said from",
    "start": "1988480",
    "end": "1995799"
  },
  {
    "text": "this from this adapt 2.0 research phase we we feel that an effective knowledge exchange between Academia and Industry",
    "start": "1995799",
    "end": "2002639"
  },
  {
    "text": "can lead to impactful research prototypes and we would be really happy if if you can help us help you thank you",
    "start": "2002639",
    "end": "2010519"
  },
  {
    "text": "and hope you like my talk I will be around here if you have any questions and I guess we have we have some quite",
    "start": "2010519",
    "end": "2017159"
  },
  {
    "text": "quite a lot of time to actually take questions and again this is the QR code for our project website so yes I'm ready",
    "start": "2017159",
    "end": "2024240"
  },
  {
    "text": "to take any questions you might have thank [Applause]",
    "start": "2024240",
    "end": "2035559"
  },
  {
    "text": "you thank you very for the talk um so I'm not advocating for not doing this in",
    "start": "2035559",
    "end": "2042799"
  },
  {
    "text": "open source but I I cannot help myself from thinking of um a vulnerability in this idea what if a threat actor AP",
    "start": "2042799",
    "end": "2050919"
  },
  {
    "text": "start using your open source models to optimize their sness and being um like",
    "start": "2050919",
    "end": "2057200"
  },
  {
    "text": "adversely enable themselves to be uh labeled as an over AP in any campaign or",
    "start": "2057200",
    "end": "2064240"
  },
  {
    "text": "intrusion they do yes very good question so you're asking how our model could be adversar",
    "start": "2064240",
    "end": "2070679"
  },
  {
    "text": "used by in in favor of um uh malicious actors yes we we have thought about that",
    "start": "2070679",
    "end": "2076480"
  },
  {
    "text": "possibility and that is a possibility with any machine learning based Solutions whenever you have these open-",
    "start": "2076480",
    "end": "2081800"
  },
  {
    "text": "Source models you always have this uh this idea attached to it that it can be explo exploited adversar so we would",
    "start": "2081800",
    "end": "2089200"
  },
  {
    "text": "definitely think about this currently we we are we are still in the phase where we are trying to solve the problem and",
    "start": "2089200",
    "end": "2095679"
  },
  {
    "text": "definitely as next part of our research goes on we are going to think about how we can have we can have this ideas where",
    "start": "2095679",
    "end": "2103000"
  },
  {
    "text": "because we we do I agree we do use some lightweight features which are still could be modified to put in false flags",
    "start": "2103000",
    "end": "2108920"
  },
  {
    "text": "and if we use them to Cluster them wrongly then they might be attributed to some other groups so we do we will think",
    "start": "2108920",
    "end": "2116240"
  },
  {
    "text": "about this in our next research phase that how to make it more robust against adversarial attacks which would which is",
    "start": "2116240",
    "end": "2122480"
  },
  {
    "text": "actually a part of our next research as well and secondly when we make the attribution claims we are also kind of",
    "start": "2122480",
    "end": "2130359"
  },
  {
    "text": "not really saying that this is the group that we have identified and take it as it is like in its face value we are also",
    "start": "2130359",
    "end": "2136920"
  },
  {
    "text": "giving the features extracted that we have extracted from our raw data set and we also asked the analyst to like just",
    "start": "2136920",
    "end": "2144000"
  },
  {
    "text": "verify the results like this the sample was clustered together but looking at the feature do you think does it make",
    "start": "2144000",
    "end": "2149599"
  },
  {
    "text": "sense you know if they are together so hope that answers your question thank you very much it does answer it thank",
    "start": "2149599",
    "end": "2155800"
  },
  {
    "text": "you hi great talk um a couple questions uh",
    "start": "2155800",
    "end": "2161200"
  },
  {
    "text": "so what happens if or have you tried applying this uh machine learning Al algorithm to say a database of good wear",
    "start": "2161200",
    "end": "2168680"
  },
  {
    "text": "like known good files what happens there and have you tried for instance applying it to like the virus total fire hose and",
    "start": "2168680",
    "end": "2174640"
  },
  {
    "text": "seeing you know if anything interesting pops out there no we we haven't applied this to the good wear or the host that",
    "start": "2174640",
    "end": "2181160"
  },
  {
    "text": "you mentioned we only worked with APD data set and which we know are are malicious so we have only applied it to",
    "start": "2181160",
    "end": "2187440"
  },
  {
    "text": "the Malaya data set but interesting we might we might give it a thought yeah thank",
    "start": "2187440",
    "end": "2194720"
  },
  {
    "text": "you hi really great presentation I really liked it um I just had a question because it's pretty common for most thre",
    "start": "2194720",
    "end": "2201640"
  },
  {
    "text": "actors to kind of reuse similar code so for example if a threat actor is doing a",
    "start": "2201640",
    "end": "2207119"
  },
  {
    "text": "certain process injection technique uh several other threat actors are kind of using similar one so when you do the",
    "start": "2207119",
    "end": "2214079"
  },
  {
    "text": "features wouldn't that like imp impact the result of you know the model itself",
    "start": "2214079",
    "end": "2220520"
  },
  {
    "text": "and like do you guys do anything that you know deals with that mhm yeah so so",
    "start": "2220520",
    "end": "2226880"
  },
  {
    "text": "when I mentioned the feature extraction our feature extraction takes features from different parts of the samples and",
    "start": "2226880",
    "end": "2232480"
  },
  {
    "text": "we are not just focusing so which you mentioned Pro process injection of course we have a lot of samples which",
    "start": "2232480",
    "end": "2237599"
  },
  {
    "text": "triggered the Yara rule of process injection but we have the string features as well and when we combine",
    "start": "2237599",
    "end": "2243599"
  },
  {
    "text": "these features together they kind of work in tandem to make a decision so it's not just one feature that is making",
    "start": "2243599",
    "end": "2248839"
  },
  {
    "text": "the weighted decision for the model so we have these metadata features the string features and the other specific",
    "start": "2248839",
    "end": "2254880"
  },
  {
    "text": "API calls another like they they all come together to make a decision so so ideally like when when you do machine",
    "start": "2254880",
    "end": "2261480"
  },
  {
    "text": "learning like hopefully every every features weight is counted and it's not just the Yara rules that were triggered",
    "start": "2261480",
    "end": "2266680"
  },
  {
    "text": "and yeah so how's the weight on the different like features that you're using like because I I think from our",
    "start": "2266680",
    "end": "2273640"
  },
  {
    "text": "perspective it would be really interesting to you know have really good way to actually perform that classification of malware but I just",
    "start": "2273640",
    "end": "2280680"
  },
  {
    "text": "think it's a really difficult problem to solve so it is it is definitely this difficult and especially we work with",
    "start": "2280680",
    "end": "2286839"
  },
  {
    "text": "multiclass labels so we are not just binary labeling and and and when I showed the results uh basically when you",
    "start": "2286839",
    "end": "2293240"
  },
  {
    "text": "do like a good wear and a malware detection it's much easier in those cases because you have zero or one label",
    "start": "2293240",
    "end": "2299040"
  },
  {
    "text": "but in our multiclass classification there is always a possibility so in our research we have identified this",
    "start": "2299040",
    "end": "2304839"
  },
  {
    "text": "possibility that we might give multi-label output as well because we",
    "start": "2304839",
    "end": "2309880"
  },
  {
    "text": "want to not say like this this sample belongs to let's say aptx but we want to",
    "start": "2309880",
    "end": "2315640"
  },
  {
    "text": "say with probability this sample belongs to apx but with 60% probability we also believe that this sample might belong to",
    "start": "2315640",
    "end": "2321960"
  },
  {
    "text": "AP y so we are we are we have that idea that maybe as a future work uh which we",
    "start": "2321960",
    "end": "2328040"
  },
  {
    "text": "might incorporate to identify to give this kind of weightage of the label itself based on based on that that",
    "start": "2328040",
    "end": "2335920"
  },
  {
    "text": "clustering we we have find like if if a sample is close to one cluster then we provide more weightage to that cluster",
    "start": "2335920",
    "end": "2341839"
  },
  {
    "text": "but we also identify the other labels it might come under okay thank you thank",
    "start": "2341839",
    "end": "2348760"
  },
  {
    "text": "you uh thank you for your great talk uh I just have a question regarding the uh",
    "start": "2349160",
    "end": "2355079"
  },
  {
    "text": "sometimes in the investigation we need to have some Dynamic action on the first malver so for example uh recently we see",
    "start": "2355079",
    "end": "2362760"
  },
  {
    "text": "there are lots of HTML smuggling coming to the clients and uh you need to open",
    "start": "2362760",
    "end": "2368000"
  },
  {
    "text": "it then it will redirect you to some website it is starting from Microsoft or some uh for example Google or whatever",
    "start": "2368000",
    "end": "2374920"
  },
  {
    "text": "else you can get some uh actually campaign for your advertising or whatever else but uh threat ACC actors",
    "start": "2374920",
    "end": "2382160"
  },
  {
    "text": "are using it in in negative way so you will be locked by some capture recapture",
    "start": "2382160",
    "end": "2387400"
  },
  {
    "text": "or something from cloud flare and then you will be achieve to the uh Final Destination so in these cases is there",
    "start": "2387400",
    "end": "2394400"
  },
  {
    "text": "any work around for you to analyze them yeah no uh no great question",
    "start": "2394400",
    "end": "2400839"
  },
  {
    "text": "question so U about Dynamic analysis we we haven't done Dynamic analysis and we",
    "start": "2400839",
    "end": "2406760"
  },
  {
    "text": "agree that some samples do need Dynamic analysis because when I showed you the linking features which are based on URLs",
    "start": "2406760",
    "end": "2412839"
  },
  {
    "text": "and uh IP addresses we did not get a lot of URLs and IP addresses statically",
    "start": "2412839",
    "end": "2418119"
  },
  {
    "text": "because very few samples have statically embedded those things uh within uh within the contents so we do feel that",
    "start": "2418119",
    "end": "2424680"
  },
  {
    "text": "for some of the samples we need to D D do Dynamic analysis but with Dynamic analysis we need to take care of other",
    "start": "2424680",
    "end": "2431119"
  },
  {
    "text": "limitations as well I agree that this is a static analysis based approach and it has its own limitation but for dynamic",
    "start": "2431119",
    "end": "2437040"
  },
  {
    "text": "analysis we don't know if the sample is on even going to show the right Behavior if the right system is not attained and",
    "start": "2437040",
    "end": "2444440"
  },
  {
    "text": "with and like which system works for you to show your true Behavior and the",
    "start": "2444440",
    "end": "2449560"
  },
  {
    "text": "behavior are recapturing even the right Behavior so we we did we did way balance",
    "start": "2449560",
    "end": "2454880"
  },
  {
    "text": "those things that should be incorporate dynamic as well but we will definitely consider in future currently we just",
    "start": "2454880",
    "end": "2460880"
  },
  {
    "text": "rely on static analysis yes thank",
    "start": "2460880",
    "end": "2465720"
  },
  {
    "text": "you hey good presentation uh kind of regarding the as uh similar to the last",
    "start": "2467160",
    "end": "2473920"
  },
  {
    "text": "question but regarding uh package samples yeah uh are you considering",
    "start": "2473920",
    "end": "2479000"
  },
  {
    "text": "those samples uh even though not doing Dynamic analysis is any kind of external",
    "start": "2479000",
    "end": "2484520"
  },
  {
    "text": "service being used to impact those to put in the in a data set or not at",
    "start": "2484520",
    "end": "2490599"
  },
  {
    "text": "all are you considering the packet SLE or virtualized sample whatever yeah oh oh no a good question so your question",
    "start": "2490599",
    "end": "2496640"
  },
  {
    "text": "is are we considering pack sample and if we are how we are unpacking them um interestingly in our data set we did do",
    "start": "2496640",
    "end": "2502920"
  },
  {
    "text": "an analysis which is covered in the paper that we try to identify how many of our samples are actually packed by",
    "start": "2502920",
    "end": "2509040"
  },
  {
    "text": "just using the normal pack ques like upx and Thea and all those things so",
    "start": "2509040",
    "end": "2514720"
  },
  {
    "text": "interestingly um there there were there were about I'm I'm forgetting the number but about 10% of the samples that were",
    "start": "2514720",
    "end": "2521839"
  },
  {
    "text": "packed by these commercially used uh packes So currently we just we just have",
    "start": "2521839",
    "end": "2527960"
  },
  {
    "text": "those numbers and we we are not really dealing with pack samples and we take the packing mechanism as a feature as",
    "start": "2527960",
    "end": "2533720"
  },
  {
    "text": "well uh which feature they are using and if if we can extract any other um any",
    "start": "2533720",
    "end": "2539000"
  },
  {
    "text": "other information without like unpacking them so no like it comes into the phase of dynamic analysis and using more tools",
    "start": "2539000",
    "end": "2545880"
  },
  {
    "text": "but since we that we didn't had that many pack samples we we are not yet using any specific unpacking routine or",
    "start": "2545880",
    "end": "2552839"
  },
  {
    "text": "unpacking version to uh make more features available but that's that's definitely uh a part to be considered",
    "start": "2552839",
    "end": "2559440"
  },
  {
    "text": "yeah and just uh last question yeah uh so if you cannot impack with known tools",
    "start": "2559440",
    "end": "2565280"
  },
  {
    "text": "like qpx or whatever uh you're not going to send this to the no we still send them to our pipeline yes we still send",
    "start": "2565280",
    "end": "2572359"
  },
  {
    "text": "them to our pipeline so what happens is if you don't have enough features they kind of become uni clusters and you they",
    "start": "2572359",
    "end": "2578359"
  },
  {
    "text": "are not clusters clustered together but it might happen that that specific packware that it's using might be",
    "start": "2578359",
    "end": "2584119"
  },
  {
    "text": "available in another sample which has very similar properties and it might be clustered with only two samples but we",
    "start": "2584119",
    "end": "2589520"
  },
  {
    "text": "are not discarding anything either we end up getting uni clusters or we get like two samples with clusters so",
    "start": "2589520",
    "end": "2595440"
  },
  {
    "text": "everything goes through the pipeline yeah nice thank you thank",
    "start": "2595440",
    "end": "2600760"
  },
  {
    "text": "you so I guess that that that's all thank you so much for your questions and",
    "start": "2601200",
    "end": "2606280"
  },
  {
    "text": "hope you like thank you",
    "start": "2606280",
    "end": "2613040"
  }
]
[
  {
    "text": "hello everyone",
    "start": "1920",
    "end": "3280"
  },
  {
    "text": "my name is epin lee and i'm a researcher",
    "start": "3280",
    "end": "6319"
  },
  {
    "text": "from baidu security",
    "start": "6319",
    "end": "8800"
  },
  {
    "text": "today i'm here to introduce a new",
    "start": "8800",
    "end": "11040"
  },
  {
    "text": "technique to track the anonymous",
    "start": "11040",
    "end": "13040"
  },
  {
    "text": "author of online disinformation",
    "start": "13040",
    "end": "17119"
  },
  {
    "text": "so first my presentation has five",
    "start": "17119",
    "end": "19279"
  },
  {
    "text": "sections are showing",
    "start": "19279",
    "end": "21279"
  },
  {
    "text": "the introduction talks about what",
    "start": "21279",
    "end": "23359"
  },
  {
    "text": "problem did we solve",
    "start": "23359",
    "end": "25359"
  },
  {
    "text": "the second part is about some previous",
    "start": "25359",
    "end": "27519"
  },
  {
    "text": "work we referred to",
    "start": "27519",
    "end": "30000"
  },
  {
    "text": "method and experiment discuss how we",
    "start": "30000",
    "end": "32719"
  },
  {
    "text": "implement our model",
    "start": "32719",
    "end": "34559"
  },
  {
    "text": "and that is comparison result with other",
    "start": "34559",
    "end": "36800"
  },
  {
    "text": "baselines",
    "start": "36800",
    "end": "38800"
  },
  {
    "text": "finally a short summary",
    "start": "38800",
    "end": "42480"
  },
  {
    "text": "so before we get into it i want to start",
    "start": "43280",
    "end": "46000"
  },
  {
    "text": "with a fun fact",
    "start": "46000",
    "end": "48399"
  },
  {
    "text": "did you know we actually use 100 of our",
    "start": "48399",
    "end": "51520"
  },
  {
    "text": "brain power",
    "start": "51520",
    "end": "53680"
  },
  {
    "text": "i thought it was interesting because i",
    "start": "53680",
    "end": "55840"
  },
  {
    "text": "have heard many people saying that we",
    "start": "55840",
    "end": "58079"
  },
  {
    "text": "only use 10 percent of our brain",
    "start": "58079",
    "end": "61600"
  },
  {
    "text": "now back to the same so what is the",
    "start": "61600",
    "end": "64158"
  },
  {
    "text": "point of",
    "start": "64159",
    "end": "64799"
  },
  {
    "text": "this is that i want to show you the",
    "start": "64799",
    "end": "67040"
  },
  {
    "text": "existence of false information",
    "start": "67040",
    "end": "70720"
  },
  {
    "text": "from printing to the development of the",
    "start": "70720",
    "end": "73280"
  },
  {
    "text": "internet",
    "start": "73280",
    "end": "74560"
  },
  {
    "text": "the information we generated has grown",
    "start": "74560",
    "end": "77119"
  },
  {
    "text": "exponentially",
    "start": "77119",
    "end": "79920"
  },
  {
    "text": "well we enjoy the convenience it brings",
    "start": "79920",
    "end": "82799"
  },
  {
    "text": "to us",
    "start": "82799",
    "end": "83680"
  },
  {
    "text": "we also have to face the dark side",
    "start": "83680",
    "end": "87840"
  },
  {
    "text": "here a study shows that about 3.8",
    "start": "89360",
    "end": "92400"
  },
  {
    "text": "million people",
    "start": "92400",
    "end": "93520"
  },
  {
    "text": "spend 144 minutes per day",
    "start": "93520",
    "end": "96880"
  },
  {
    "text": "on social media on average",
    "start": "96880",
    "end": "100880"
  },
  {
    "text": "notice that the data is from 2019",
    "start": "100880",
    "end": "104079"
  },
  {
    "text": "and the status will only go up in 2020",
    "start": "104079",
    "end": "107680"
  },
  {
    "text": "due to the quarantine",
    "start": "107680",
    "end": "110799"
  },
  {
    "text": "from the status we can see that social",
    "start": "111520",
    "end": "114079"
  },
  {
    "text": "media gradually becomes the largest",
    "start": "114079",
    "end": "116719"
  },
  {
    "text": "information source but it also leads to",
    "start": "116719",
    "end": "120399"
  },
  {
    "text": "the rise of this",
    "start": "120399",
    "end": "121520"
  },
  {
    "text": "information the false information intend",
    "start": "121520",
    "end": "124320"
  },
  {
    "text": "to mislead",
    "start": "124320",
    "end": "126479"
  },
  {
    "text": "with the aid of social media false",
    "start": "126479",
    "end": "128879"
  },
  {
    "text": "information has become a serious problem",
    "start": "128879",
    "end": "132560"
  },
  {
    "text": "there is an old saying that a light will",
    "start": "132560",
    "end": "135360"
  },
  {
    "text": "travel",
    "start": "135360",
    "end": "135920"
  },
  {
    "text": "around the world while the truth is",
    "start": "135920",
    "end": "138239"
  },
  {
    "text": "pulling on its boots",
    "start": "138239",
    "end": "140879"
  },
  {
    "text": "it is a perfect illustration of why",
    "start": "140879",
    "end": "143280"
  },
  {
    "text": "false information is so problematic",
    "start": "143280",
    "end": "147280"
  },
  {
    "text": "it spreads out so quickly that you don't",
    "start": "147280",
    "end": "149520"
  },
  {
    "text": "even get a chance to stop it",
    "start": "149520",
    "end": "152640"
  },
  {
    "text": "another study showed that fake news and",
    "start": "152640",
    "end": "155200"
  },
  {
    "text": "stories",
    "start": "155200",
    "end": "156000"
  },
  {
    "text": "are 70 percent more likely to be",
    "start": "156000",
    "end": "158400"
  },
  {
    "text": "reposted on twitter",
    "start": "158400",
    "end": "161760"
  },
  {
    "text": "besides false information tends to be",
    "start": "161840",
    "end": "164560"
  },
  {
    "text": "trustworthy for users",
    "start": "164560",
    "end": "166400"
  },
  {
    "text": "because users want it to be true",
    "start": "166400",
    "end": "169440"
  },
  {
    "text": "it is like people saying that you are",
    "start": "169440",
    "end": "171599"
  },
  {
    "text": "promoted",
    "start": "171599",
    "end": "173360"
  },
  {
    "text": "you don't know it for sure but you hope",
    "start": "173360",
    "end": "175440"
  },
  {
    "text": "it is true",
    "start": "175440",
    "end": "178080"
  },
  {
    "text": "people are more likely to trust things",
    "start": "178080",
    "end": "180159"
  },
  {
    "text": "they want to believe",
    "start": "180159",
    "end": "182560"
  },
  {
    "text": "on the other hand the purpose of fake",
    "start": "182560",
    "end": "185040"
  },
  {
    "text": "news is to",
    "start": "185040",
    "end": "186080"
  },
  {
    "text": "attract the visitors therefore readers",
    "start": "186080",
    "end": "189519"
  },
  {
    "text": "tend to be driven by the emotional",
    "start": "189519",
    "end": "191760"
  },
  {
    "text": "impulse",
    "start": "191760",
    "end": "192640"
  },
  {
    "text": "ignoring its authenticity",
    "start": "192640",
    "end": "196480"
  },
  {
    "text": "it is worse to point out that features",
    "start": "196480",
    "end": "199120"
  },
  {
    "text": "like top trend",
    "start": "199120",
    "end": "200480"
  },
  {
    "text": "a news feed allows fake news to be",
    "start": "200480",
    "end": "203280"
  },
  {
    "text": "exposed more frequently",
    "start": "203280",
    "end": "206799"
  },
  {
    "text": "now you may ask why would people just",
    "start": "207920",
    "end": "210480"
  },
  {
    "text": "make stuff up what is the purpose of",
    "start": "210480",
    "end": "213200"
  },
  {
    "text": "doing this",
    "start": "213200",
    "end": "214879"
  },
  {
    "text": "actually they can get a lot",
    "start": "214879",
    "end": "217920"
  },
  {
    "text": "first fabricating rumors is a public",
    "start": "217920",
    "end": "220640"
  },
  {
    "text": "relation move",
    "start": "220640",
    "end": "221680"
  },
  {
    "text": "that changes public opinions",
    "start": "221680",
    "end": "225120"
  },
  {
    "text": "usually they hire a group of ghost",
    "start": "225120",
    "end": "227440"
  },
  {
    "text": "writers to post",
    "start": "227440",
    "end": "228640"
  },
  {
    "text": "online comments or reviews",
    "start": "228640",
    "end": "231840"
  },
  {
    "text": "we call it online water army in china",
    "start": "231840",
    "end": "234799"
  },
  {
    "text": "since their comments are like afloat",
    "start": "234799",
    "end": "238080"
  },
  {
    "text": "with those water armies they can do a",
    "start": "238080",
    "end": "240480"
  },
  {
    "text": "lot of stuff",
    "start": "240480",
    "end": "241519"
  },
  {
    "text": "like advertising for example",
    "start": "241519",
    "end": "245040"
  },
  {
    "text": "if you want to buy your shoes and then",
    "start": "245040",
    "end": "247200"
  },
  {
    "text": "you look for some",
    "start": "247200",
    "end": "248239"
  },
  {
    "text": "recommendations from others",
    "start": "248239",
    "end": "251280"
  },
  {
    "text": "a review pops up and show you the top 10",
    "start": "251280",
    "end": "254080"
  },
  {
    "text": "shoes they ranked",
    "start": "254080",
    "end": "255760"
  },
  {
    "text": "a coup sounds like to the point but it",
    "start": "255760",
    "end": "258880"
  },
  {
    "text": "actually can be a fake review that",
    "start": "258880",
    "end": "260799"
  },
  {
    "text": "tricked you into buying their product",
    "start": "260799",
    "end": "264639"
  },
  {
    "text": "slender and deformation which used to",
    "start": "264639",
    "end": "267440"
  },
  {
    "text": "happen on celebrity",
    "start": "267440",
    "end": "268880"
  },
  {
    "text": "and idols shifting public attention",
    "start": "268880",
    "end": "273280"
  },
  {
    "text": "which is a classic pr move",
    "start": "273280",
    "end": "276720"
  },
  {
    "text": "reshaping public opinions reshaping",
    "start": "276720",
    "end": "280080"
  },
  {
    "text": "public opinion",
    "start": "280080",
    "end": "281199"
  },
  {
    "text": "is mostly used in the political aspect",
    "start": "281199",
    "end": "284400"
  },
  {
    "text": "like propaganda gaining public attention",
    "start": "284400",
    "end": "288160"
  },
  {
    "text": "which draws attention to themselves so",
    "start": "288160",
    "end": "290720"
  },
  {
    "text": "that they can have higher commercial",
    "start": "290720",
    "end": "292479"
  },
  {
    "text": "value",
    "start": "292479",
    "end": "294479"
  },
  {
    "text": "and the last counseling marketing",
    "start": "294479",
    "end": "296639"
  },
  {
    "text": "turbulence",
    "start": "296639",
    "end": "298160"
  },
  {
    "text": "which will be introduced later",
    "start": "298160",
    "end": "301840"
  },
  {
    "text": "in fact there is one ultimate goal",
    "start": "301840",
    "end": "305039"
  },
  {
    "text": "behind six purpose",
    "start": "305039",
    "end": "306800"
  },
  {
    "text": "and that is making money and now",
    "start": "306800",
    "end": "310080"
  },
  {
    "text": "let's talk about potential victims",
    "start": "310080",
    "end": "313280"
  },
  {
    "text": "you know fake news actually has a wide",
    "start": "313280",
    "end": "315919"
  },
  {
    "text": "impact on us",
    "start": "315919",
    "end": "317520"
  },
  {
    "text": "anyone can be the victim politicians",
    "start": "317520",
    "end": "321600"
  },
  {
    "text": "celebrities and companies those three",
    "start": "321600",
    "end": "324720"
  },
  {
    "text": "suffers from",
    "start": "324720",
    "end": "325520"
  },
  {
    "text": "deformation and slander mostly",
    "start": "325520",
    "end": "328720"
  },
  {
    "text": "and we consumers will be traded into a",
    "start": "328720",
    "end": "331360"
  },
  {
    "text": "pursuit",
    "start": "331360",
    "end": "332000"
  },
  {
    "text": "because of some fake review or fake news",
    "start": "332000",
    "end": "336720"
  },
  {
    "text": "furthermore fake news can also bring",
    "start": "337360",
    "end": "340320"
  },
  {
    "text": "serious negative consequences",
    "start": "340320",
    "end": "342560"
  },
  {
    "text": "like stock market turbulence in the past",
    "start": "342560",
    "end": "346160"
  },
  {
    "text": "few years some well-known company has",
    "start": "346160",
    "end": "348880"
  },
  {
    "text": "suffered from online short attacks",
    "start": "348880",
    "end": "351680"
  },
  {
    "text": "and you can see from the graph the stock",
    "start": "351680",
    "end": "354400"
  },
  {
    "text": "price dropped",
    "start": "354400",
    "end": "355360"
  },
  {
    "text": "sharply due to those short attacks",
    "start": "355360",
    "end": "359520"
  },
  {
    "text": "moreover some attackers fabricate fake",
    "start": "359759",
    "end": "362880"
  },
  {
    "text": "news about the social influencers so",
    "start": "362880",
    "end": "366080"
  },
  {
    "text": "that they can ask for money",
    "start": "366080",
    "end": "369280"
  },
  {
    "text": "therefore to protect and maintain",
    "start": "369280",
    "end": "371520"
  },
  {
    "text": "personal reputation",
    "start": "371520",
    "end": "373039"
  },
  {
    "text": "brand images and a healthy cyberspace",
    "start": "373039",
    "end": "376560"
  },
  {
    "text": "it is necessary to track the source of",
    "start": "376560",
    "end": "378960"
  },
  {
    "text": "the fake news",
    "start": "378960",
    "end": "381360"
  },
  {
    "text": "however most fake news and articles are",
    "start": "381360",
    "end": "384319"
  },
  {
    "text": "posed",
    "start": "384319",
    "end": "384720"
  },
  {
    "text": "anonymously and it lacks valid",
    "start": "384720",
    "end": "387360"
  },
  {
    "text": "information to identify the author",
    "start": "387360",
    "end": "390960"
  },
  {
    "text": "so tracking anonymous article is also a",
    "start": "390960",
    "end": "394000"
  },
  {
    "text": "challenging problem",
    "start": "394000",
    "end": "397039"
  },
  {
    "text": "fortunately it is not impossible",
    "start": "397039",
    "end": "399919"
  },
  {
    "text": "different people have different",
    "start": "399919",
    "end": "401600"
  },
  {
    "text": "writing styles so we are able to",
    "start": "401600",
    "end": "404319"
  },
  {
    "text": "identify some",
    "start": "404319",
    "end": "405360"
  },
  {
    "text": "writers by their distinct habits",
    "start": "405360",
    "end": "409840"
  },
  {
    "text": "as shown on the top right there is two",
    "start": "409840",
    "end": "413199"
  },
  {
    "text": "twitters with two writing styles",
    "start": "413199",
    "end": "416400"
  },
  {
    "text": "ron paul is the only candidate who",
    "start": "416400",
    "end": "419120"
  },
  {
    "text": "offers",
    "start": "419120",
    "end": "419759"
  },
  {
    "text": "us a real choice that sounds like a",
    "start": "419759",
    "end": "422800"
  },
  {
    "text": "senator",
    "start": "422800",
    "end": "424479"
  },
  {
    "text": "it's getting late so i will be here for",
    "start": "424479",
    "end": "427199"
  },
  {
    "text": "probably",
    "start": "427199",
    "end": "427759"
  },
  {
    "text": "two more hours tops actually i shouldn't",
    "start": "427759",
    "end": "431199"
  },
  {
    "text": "read this way",
    "start": "431199",
    "end": "433199"
  },
  {
    "text": "it's getting l number eight so",
    "start": "433199",
    "end": "436560"
  },
  {
    "text": "aob here number four",
    "start": "436560",
    "end": "439759"
  },
  {
    "text": "pop two more hurst tops",
    "start": "439759",
    "end": "443360"
  },
  {
    "text": "that sounds like a tweet written by a",
    "start": "443360",
    "end": "445520"
  },
  {
    "text": "teenager right",
    "start": "445520",
    "end": "448479"
  },
  {
    "text": "or it could be an other way around but",
    "start": "448560",
    "end": "451360"
  },
  {
    "text": "they are definitely two distinct",
    "start": "451360",
    "end": "453360"
  },
  {
    "text": "writing styles and what you see here is",
    "start": "453360",
    "end": "456639"
  },
  {
    "text": "that we can kind of guess at their",
    "start": "456639",
    "end": "458479"
  },
  {
    "text": "identity based on that",
    "start": "458479",
    "end": "461759"
  },
  {
    "text": "the table on the bottom shows the",
    "start": "461759",
    "end": "463840"
  },
  {
    "text": "multiple level",
    "start": "463840",
    "end": "464879"
  },
  {
    "text": "of writing styles for example",
    "start": "464879",
    "end": "468479"
  },
  {
    "text": "different authors may have different",
    "start": "468479",
    "end": "470479"
  },
  {
    "text": "preference of word choice",
    "start": "470479",
    "end": "472639"
  },
  {
    "text": "some people like to use certain",
    "start": "472639",
    "end": "474720"
  },
  {
    "text": "adjectives but others don't",
    "start": "474720",
    "end": "477680"
  },
  {
    "text": "like my friend who prefers to use",
    "start": "477680",
    "end": "480160"
  },
  {
    "text": "hilarious",
    "start": "480160",
    "end": "481120"
  },
  {
    "text": "instead of funny as for the anonymous",
    "start": "481120",
    "end": "484960"
  },
  {
    "text": "articles",
    "start": "484960",
    "end": "485840"
  },
  {
    "text": "the more features we collect in writing",
    "start": "485840",
    "end": "488720"
  },
  {
    "text": "the clear",
    "start": "488720",
    "end": "489520"
  },
  {
    "text": "fingerprint we will get",
    "start": "489520",
    "end": "493120"
  },
  {
    "text": "well in short we have discussed the",
    "start": "493120",
    "end": "496479"
  },
  {
    "text": "effect of this information and some",
    "start": "496479",
    "end": "498960"
  },
  {
    "text": "insight on tracking anonymous articles",
    "start": "498960",
    "end": "502000"
  },
  {
    "text": "let's look at some previous works",
    "start": "502000",
    "end": "506479"
  },
  {
    "text": "so first the problem of tracking",
    "start": "506479",
    "end": "508800"
  },
  {
    "text": "anonymous articles",
    "start": "508800",
    "end": "510160"
  },
  {
    "text": "is defined as authorship analysis",
    "start": "510160",
    "end": "513518"
  },
  {
    "text": "and it contains three sub problems as",
    "start": "513519",
    "end": "516000"
  },
  {
    "text": "shown on the screen",
    "start": "516000",
    "end": "518240"
  },
  {
    "text": "authorship attribution takes one text",
    "start": "518240",
    "end": "521279"
  },
  {
    "text": "and the final is author from a list of",
    "start": "521279",
    "end": "523680"
  },
  {
    "text": "candidates",
    "start": "523680",
    "end": "525600"
  },
  {
    "text": "authorship verification takes two taxes",
    "start": "525600",
    "end": "529040"
  },
  {
    "text": "that tells whether the author of the two",
    "start": "529040",
    "end": "531519"
  },
  {
    "text": "articles are the same or not",
    "start": "531519",
    "end": "534640"
  },
  {
    "text": "authorship clustering takes a list of",
    "start": "534640",
    "end": "537600"
  },
  {
    "text": "text inputs",
    "start": "537600",
    "end": "538800"
  },
  {
    "text": "then organize the article based on their",
    "start": "538800",
    "end": "541519"
  },
  {
    "text": "authors",
    "start": "541519",
    "end": "543279"
  },
  {
    "text": "lastly the combination of approach to",
    "start": "543279",
    "end": "546000"
  },
  {
    "text": "these three tasks",
    "start": "546000",
    "end": "547200"
  },
  {
    "text": "is applied to tracking anonymous",
    "start": "547200",
    "end": "549120"
  },
  {
    "text": "articles",
    "start": "549120",
    "end": "551680"
  },
  {
    "text": "surprisingly authorship analysis",
    "start": "552320",
    "end": "555440"
  },
  {
    "text": "is a long-standing problem and it was",
    "start": "555440",
    "end": "558240"
  },
  {
    "text": "initiated by the work of",
    "start": "558240",
    "end": "559839"
  },
  {
    "text": "most terror and the wellness in 1964.",
    "start": "559839",
    "end": "563839"
  },
  {
    "text": "the development of authorship analysis",
    "start": "563839",
    "end": "566560"
  },
  {
    "text": "has three major stages",
    "start": "566560",
    "end": "569120"
  },
  {
    "text": "in early 2000 a method based on",
    "start": "569120",
    "end": "571839"
  },
  {
    "text": "stylistic",
    "start": "571839",
    "end": "572720"
  },
  {
    "text": "and the content feature was introduced",
    "start": "572720",
    "end": "576160"
  },
  {
    "text": "it requires them to manually extract the",
    "start": "576160",
    "end": "578560"
  },
  {
    "text": "trades",
    "start": "578560",
    "end": "579600"
  },
  {
    "text": "so it not only take a lot of effort but",
    "start": "579600",
    "end": "582480"
  },
  {
    "text": "also performed",
    "start": "582480",
    "end": "583440"
  },
  {
    "text": "poorly on the test character",
    "start": "583440",
    "end": "586880"
  },
  {
    "text": "and gram was introduced 10 years later",
    "start": "586880",
    "end": "590000"
  },
  {
    "text": "and it has been proved to be the most",
    "start": "590000",
    "end": "592399"
  },
  {
    "text": "effective features for authorship and",
    "start": "592399",
    "end": "594800"
  },
  {
    "text": "not",
    "start": "594800",
    "end": "595120"
  },
  {
    "text": "attribution at that time but still",
    "start": "595120",
    "end": "598880"
  },
  {
    "text": "the performance is limited since it",
    "start": "598880",
    "end": "601200"
  },
  {
    "text": "involves many",
    "start": "601200",
    "end": "602079"
  },
  {
    "text": "high dimensional matrix manipulation",
    "start": "602079",
    "end": "605279"
  },
  {
    "text": "in recent years with a breakthrough of",
    "start": "605279",
    "end": "608079"
  },
  {
    "text": "deep learning",
    "start": "608079",
    "end": "609200"
  },
  {
    "text": "some researchers proposed a method based",
    "start": "609200",
    "end": "611440"
  },
  {
    "text": "on deep learning networks",
    "start": "611440",
    "end": "613760"
  },
  {
    "text": "it turns out to be effective but only",
    "start": "613760",
    "end": "616480"
  },
  {
    "text": "for authorship",
    "start": "616480",
    "end": "617279"
  },
  {
    "text": "attribution those methods do not apply",
    "start": "617279",
    "end": "620640"
  },
  {
    "text": "to authorship verification or clustering",
    "start": "620640",
    "end": "624240"
  },
  {
    "text": "the story does not end there although",
    "start": "624240",
    "end": "627519"
  },
  {
    "text": "our method is also based on deep",
    "start": "627519",
    "end": "629680"
  },
  {
    "text": "learning networks",
    "start": "629680",
    "end": "631600"
  },
  {
    "text": "what's new about it is that it satisfies",
    "start": "631600",
    "end": "634560"
  },
  {
    "text": "all three needs in authorship analysis",
    "start": "634560",
    "end": "638399"
  },
  {
    "text": "let me show you how we did it first",
    "start": "638399",
    "end": "641920"
  },
  {
    "text": "we were inspired by physnet which is a",
    "start": "641920",
    "end": "644880"
  },
  {
    "text": "unified method for face recognition",
    "start": "644880",
    "end": "647680"
  },
  {
    "text": "verification and clustering",
    "start": "647680",
    "end": "650880"
  },
  {
    "text": "well it has achieved a big success in",
    "start": "650880",
    "end": "653600"
  },
  {
    "text": "computer vision",
    "start": "653600",
    "end": "656399"
  },
  {
    "text": "similarly we propose a unified method",
    "start": "656399",
    "end": "659120"
  },
  {
    "text": "based on deep",
    "start": "659120",
    "end": "660000"
  },
  {
    "text": "learning and our model learns a mapping",
    "start": "660000",
    "end": "662720"
  },
  {
    "text": "from texas to compact",
    "start": "662720",
    "end": "664560"
  },
  {
    "text": "n-dimensional euclidean space this",
    "start": "664560",
    "end": "667760"
  },
  {
    "text": "mapping embeds",
    "start": "667760",
    "end": "668880"
  },
  {
    "text": "attacks into the surface of a sphere",
    "start": "668880",
    "end": "672000"
  },
  {
    "text": "with a radius of 1 and the center of the",
    "start": "672000",
    "end": "674800"
  },
  {
    "text": "origin",
    "start": "674800",
    "end": "676880"
  },
  {
    "text": "basically our model is like a function",
    "start": "676880",
    "end": "679680"
  },
  {
    "text": "which takes text as an input",
    "start": "679680",
    "end": "681760"
  },
  {
    "text": "and turning into a point on a graph",
    "start": "681760",
    "end": "684959"
  },
  {
    "text": "in euclidean space the distance",
    "start": "684959",
    "end": "687360"
  },
  {
    "text": "indicates text",
    "start": "687360",
    "end": "688320"
  },
  {
    "text": "similarity you can see here there are",
    "start": "688320",
    "end": "691360"
  },
  {
    "text": "four authors and",
    "start": "691360",
    "end": "692560"
  },
  {
    "text": "each of them has four articles",
    "start": "692560",
    "end": "696000"
  },
  {
    "text": "text of same author has shorter distance",
    "start": "696000",
    "end": "699120"
  },
  {
    "text": "vice versa in the graph",
    "start": "699120",
    "end": "702240"
  },
  {
    "text": "16 articles are projected to the space",
    "start": "702240",
    "end": "706000"
  },
  {
    "text": "x1 and x2 is embedded to those red dots",
    "start": "706000",
    "end": "710800"
  },
  {
    "text": "since they are located together we",
    "start": "710800",
    "end": "712959"
  },
  {
    "text": "suppose they are",
    "start": "712959",
    "end": "714240"
  },
  {
    "text": "written by the same author moreover",
    "start": "714240",
    "end": "717440"
  },
  {
    "text": "to change the model we define a triplet",
    "start": "717440",
    "end": "720880"
  },
  {
    "text": "a small data set that contains three",
    "start": "720880",
    "end": "723120"
  },
  {
    "text": "samples",
    "start": "723120",
    "end": "724480"
  },
  {
    "text": "as shown on the screen a triplet",
    "start": "724480",
    "end": "726720"
  },
  {
    "text": "consists of",
    "start": "726720",
    "end": "727600"
  },
  {
    "text": "an anchor a positive and a negative",
    "start": "727600",
    "end": "732079"
  },
  {
    "text": "the anchor is the target text the one we",
    "start": "732079",
    "end": "735200"
  },
  {
    "text": "use to compare",
    "start": "735200",
    "end": "737279"
  },
  {
    "text": "the positive is a text from the same",
    "start": "737279",
    "end": "739839"
  },
  {
    "text": "author",
    "start": "739839",
    "end": "740959"
  },
  {
    "text": "and the negative is a text from another",
    "start": "740959",
    "end": "743680"
  },
  {
    "text": "author",
    "start": "743680",
    "end": "745839"
  },
  {
    "text": "the model will embed these three inputs",
    "start": "745839",
    "end": "748480"
  },
  {
    "text": "into the euclidean space",
    "start": "748480",
    "end": "751120"
  },
  {
    "text": "initially the three taxes are mapped",
    "start": "751120",
    "end": "753839"
  },
  {
    "text": "into three random locations",
    "start": "753839",
    "end": "756480"
  },
  {
    "text": "and the positional relations among three",
    "start": "756480",
    "end": "759120"
  },
  {
    "text": "points",
    "start": "759120",
    "end": "759680"
  },
  {
    "text": "can be categorized into those three",
    "start": "759680",
    "end": "762320"
  },
  {
    "text": "cases",
    "start": "762320",
    "end": "763360"
  },
  {
    "text": "which is shown on the left remember",
    "start": "763360",
    "end": "766720"
  },
  {
    "text": "the distance indicates a text similarity",
    "start": "766720",
    "end": "770000"
  },
  {
    "text": "the first one is when positive is closer",
    "start": "770000",
    "end": "772800"
  },
  {
    "text": "to the anchor",
    "start": "772800",
    "end": "773839"
  },
  {
    "text": "than negative which is a case we like to",
    "start": "773839",
    "end": "776480"
  },
  {
    "text": "see",
    "start": "776480",
    "end": "778079"
  },
  {
    "text": "the articles from the same author has",
    "start": "778079",
    "end": "780320"
  },
  {
    "text": "shorter distance",
    "start": "780320",
    "end": "782320"
  },
  {
    "text": "the second one is when negative is",
    "start": "782320",
    "end": "784399"
  },
  {
    "text": "closer to the anchor than positive",
    "start": "784399",
    "end": "787200"
  },
  {
    "text": "we don't want to see that",
    "start": "787200",
    "end": "790399"
  },
  {
    "text": "the third one is when positive and the",
    "start": "790399",
    "end": "792480"
  },
  {
    "text": "negative is equally away from",
    "start": "792480",
    "end": "794720"
  },
  {
    "text": "anchor we don't want to see that either",
    "start": "794720",
    "end": "800560"
  },
  {
    "text": "to separate n curve and positive from",
    "start": "800560",
    "end": "803360"
  },
  {
    "text": "the negative",
    "start": "803360",
    "end": "804560"
  },
  {
    "text": "we define a triplet loss function",
    "start": "804560",
    "end": "807760"
  },
  {
    "text": "as shown on the left this loss function",
    "start": "807760",
    "end": "811120"
  },
  {
    "text": "aims to let",
    "start": "811120",
    "end": "812240"
  },
  {
    "text": "a the squared euclidean distance",
    "start": "812240",
    "end": "815760"
  },
  {
    "text": "between the anchor and the negative to",
    "start": "815760",
    "end": "818399"
  },
  {
    "text": "be greater than dp",
    "start": "818399",
    "end": "820560"
  },
  {
    "text": "the square the euclidean distance",
    "start": "820560",
    "end": "822639"
  },
  {
    "text": "between the anchor and the positive",
    "start": "822639",
    "end": "825600"
  },
  {
    "text": "for better discrimination ability we",
    "start": "825600",
    "end": "828480"
  },
  {
    "text": "introduced",
    "start": "828480",
    "end": "829199"
  },
  {
    "text": "a margin just like the margin of support",
    "start": "829199",
    "end": "832800"
  },
  {
    "text": "vector machine in other words",
    "start": "832800",
    "end": "835839"
  },
  {
    "text": "when the margin is 0.5 that means we",
    "start": "835839",
    "end": "838880"
  },
  {
    "text": "want negative to be at least",
    "start": "838880",
    "end": "840800"
  },
  {
    "text": "0.5 units further than positive from the",
    "start": "840800",
    "end": "844160"
  },
  {
    "text": "anchor",
    "start": "844160",
    "end": "846160"
  },
  {
    "text": "the triple a loss function which is",
    "start": "846160",
    "end": "848800"
  },
  {
    "text": "defined as",
    "start": "848800",
    "end": "849600"
  },
  {
    "text": "l is simply measuring how much further",
    "start": "849600",
    "end": "853199"
  },
  {
    "text": "is negative than positive taking margin",
    "start": "853199",
    "end": "856560"
  },
  {
    "text": "into account",
    "start": "856560",
    "end": "858880"
  },
  {
    "text": "you see here is that dp plus margin",
    "start": "858880",
    "end": "862480"
  },
  {
    "text": "minus dn when the loss is a positive",
    "start": "862480",
    "end": "867040"
  },
  {
    "text": "that means that the difference is not",
    "start": "867040",
    "end": "869600"
  },
  {
    "text": "enough",
    "start": "869600",
    "end": "870880"
  },
  {
    "text": "otherwise it means the difference",
    "start": "870880",
    "end": "872800"
  },
  {
    "text": "already meets our goal",
    "start": "872800",
    "end": "875040"
  },
  {
    "text": "therefore we want the loss to be 0",
    "start": "875040",
    "end": "878240"
  },
  {
    "text": "updating nothing so there is a max",
    "start": "878240",
    "end": "881760"
  },
  {
    "text": "function to set the minimum loss to",
    "start": "881760",
    "end": "884000"
  },
  {
    "text": "zero the sum of the loss",
    "start": "884000",
    "end": "887120"
  },
  {
    "text": "of all triplets gives us the total loss",
    "start": "887120",
    "end": "891120"
  },
  {
    "text": "based on the triplet loss function we",
    "start": "891120",
    "end": "893519"
  },
  {
    "text": "propose a new model architecture",
    "start": "893519",
    "end": "896720"
  },
  {
    "text": "as shown in the figure the input is a",
    "start": "896720",
    "end": "899680"
  },
  {
    "text": "triplet",
    "start": "899680",
    "end": "900959"
  },
  {
    "text": "which has an anchor a positive and a",
    "start": "900959",
    "end": "904240"
  },
  {
    "text": "negative",
    "start": "904240",
    "end": "905839"
  },
  {
    "text": "the output is three euclidean embeddings",
    "start": "905839",
    "end": "909360"
  },
  {
    "text": "and they are possessed by l2 norms so",
    "start": "909360",
    "end": "912480"
  },
  {
    "text": "that they will be",
    "start": "912480",
    "end": "913760"
  },
  {
    "text": "mapped to the surface of a sphere",
    "start": "913760",
    "end": "917120"
  },
  {
    "text": "the loss function is a triplet loss",
    "start": "917120",
    "end": "919760"
  },
  {
    "text": "which is able to separate the anchor and",
    "start": "919760",
    "end": "922079"
  },
  {
    "text": "the positive",
    "start": "922079",
    "end": "922959"
  },
  {
    "text": "from the negative in euclidean space",
    "start": "922959",
    "end": "926000"
  },
  {
    "text": "as we talked about in particular",
    "start": "926000",
    "end": "930399"
  },
  {
    "text": "the deep network is flexible available",
    "start": "930399",
    "end": "933440"
  },
  {
    "text": "models are faster text",
    "start": "933440",
    "end": "935279"
  },
  {
    "text": "in gram cn and the syntax cn",
    "start": "935279",
    "end": "939040"
  },
  {
    "text": "considering the trade-off between",
    "start": "939040",
    "end": "940959"
  },
  {
    "text": "performance and the model complexity",
    "start": "940959",
    "end": "943600"
  },
  {
    "text": "we choose the engram cnn as our deep",
    "start": "943600",
    "end": "946000"
  },
  {
    "text": "network",
    "start": "946000",
    "end": "946639"
  },
  {
    "text": "for medium performance and complexity",
    "start": "946639",
    "end": "951040"
  },
  {
    "text": "besides we also optimize our triplet",
    "start": "951040",
    "end": "954079"
  },
  {
    "text": "selection method suppose we have 100",
    "start": "954079",
    "end": "957680"
  },
  {
    "text": "authors",
    "start": "957680",
    "end": "958160"
  },
  {
    "text": "in our data set and each author has 100",
    "start": "958160",
    "end": "961519"
  },
  {
    "text": "articles",
    "start": "961519",
    "end": "963120"
  },
  {
    "text": "so for each author there will be 100",
    "start": "963120",
    "end": "965759"
  },
  {
    "text": "anchor",
    "start": "965759",
    "end": "966880"
  },
  {
    "text": "and each anchor has 99 positives to",
    "start": "966880",
    "end": "969920"
  },
  {
    "text": "pair since there are 99 different",
    "start": "969920",
    "end": "973839"
  },
  {
    "text": "authors we multiply it by 100 article",
    "start": "973839",
    "end": "976880"
  },
  {
    "text": "per person",
    "start": "976880",
    "end": "978079"
  },
  {
    "text": "which is 9900 negatives",
    "start": "978079",
    "end": "981839"
  },
  {
    "text": "product of those number gave us about 10",
    "start": "981839",
    "end": "984720"
  },
  {
    "text": "billion kinds of triplet combinations",
    "start": "984720",
    "end": "988079"
  },
  {
    "text": "data is a huge number even though we",
    "start": "988079",
    "end": "990240"
  },
  {
    "text": "only have 10",
    "start": "990240",
    "end": "991120"
  },
  {
    "text": "thousand articles in our data set as for",
    "start": "991120",
    "end": "994000"
  },
  {
    "text": "the result",
    "start": "994000",
    "end": "995040"
  },
  {
    "text": "we implemented two selection method and",
    "start": "995040",
    "end": "998000"
  },
  {
    "text": "the first one is",
    "start": "998000",
    "end": "999120"
  },
  {
    "text": "random selection simple but not",
    "start": "999120",
    "end": "1002000"
  },
  {
    "text": "efficient",
    "start": "1002000",
    "end": "1003519"
  },
  {
    "text": "basically for every possible anchor we",
    "start": "1003519",
    "end": "1006320"
  },
  {
    "text": "set a top setting for the number of",
    "start": "1006320",
    "end": "1008399"
  },
  {
    "text": "positive and the negative we select v",
    "start": "1008399",
    "end": "1011440"
  },
  {
    "text": "and q respectively therefore the amount",
    "start": "1011440",
    "end": "1015519"
  },
  {
    "text": "of the triplets set",
    "start": "1015519",
    "end": "1016880"
  },
  {
    "text": "will reduce to a manageable size",
    "start": "1016880",
    "end": "1020000"
  },
  {
    "text": "the randomization ensures that our",
    "start": "1020000",
    "end": "1022320"
  },
  {
    "text": "selection",
    "start": "1022320",
    "end": "1023040"
  },
  {
    "text": "is a representative of the overall data",
    "start": "1023040",
    "end": "1025600"
  },
  {
    "text": "set",
    "start": "1025600",
    "end": "1027839"
  },
  {
    "text": "but it is not enough for us imagine you",
    "start": "1028160",
    "end": "1031760"
  },
  {
    "text": "are climbing over a hill",
    "start": "1031760",
    "end": "1033600"
  },
  {
    "text": "if you choose a flat road it might take",
    "start": "1033600",
    "end": "1036480"
  },
  {
    "text": "a long time to reach the top",
    "start": "1036480",
    "end": "1039120"
  },
  {
    "text": "but if you choose a steep path the time",
    "start": "1039120",
    "end": "1042079"
  },
  {
    "text": "it takes you to the top",
    "start": "1042079",
    "end": "1043520"
  },
  {
    "text": "is much shorter even though it requires",
    "start": "1043520",
    "end": "1046400"
  },
  {
    "text": "more work",
    "start": "1046400",
    "end": "1048160"
  },
  {
    "text": "similarly we want the model to learn",
    "start": "1048160",
    "end": "1050400"
  },
  {
    "text": "faster even it takes more",
    "start": "1050400",
    "end": "1052000"
  },
  {
    "text": "time each epic to accelerate",
    "start": "1052000",
    "end": "1055120"
  },
  {
    "text": "model training we implemented a method",
    "start": "1055120",
    "end": "1058080"
  },
  {
    "text": "called",
    "start": "1058080",
    "end": "1058400"
  },
  {
    "text": "dynamics selection firstly we usually",
    "start": "1058400",
    "end": "1062080"
  },
  {
    "text": "and randomly divide the data set",
    "start": "1062080",
    "end": "1064080"
  },
  {
    "text": "into several partitions for each",
    "start": "1064080",
    "end": "1067360"
  },
  {
    "text": "partition",
    "start": "1067360",
    "end": "1068640"
  },
  {
    "text": "we select the anchor positive pair like",
    "start": "1068640",
    "end": "1071520"
  },
  {
    "text": "the random selection strategy",
    "start": "1071520",
    "end": "1074000"
  },
  {
    "text": "and for each pair we pick the negative",
    "start": "1074000",
    "end": "1076799"
  },
  {
    "text": "candidate",
    "start": "1076799",
    "end": "1077679"
  },
  {
    "text": "that satisfy the following equation to",
    "start": "1077679",
    "end": "1080880"
  },
  {
    "text": "put it simple",
    "start": "1080880",
    "end": "1082080"
  },
  {
    "text": "we filter out those triplets that",
    "start": "1082080",
    "end": "1084480"
  },
  {
    "text": "already meet",
    "start": "1084480",
    "end": "1085280"
  },
  {
    "text": "our goal which is the first case in the",
    "start": "1085280",
    "end": "1088240"
  },
  {
    "text": "graph",
    "start": "1088240",
    "end": "1089760"
  },
  {
    "text": "lastly we randomly select one negative",
    "start": "1089760",
    "end": "1092400"
  },
  {
    "text": "from candidate",
    "start": "1092400",
    "end": "1094080"
  },
  {
    "text": "to compose the triplet and threw them",
    "start": "1094080",
    "end": "1096559"
  },
  {
    "text": "into the next epic",
    "start": "1096559",
    "end": "1099840"
  },
  {
    "text": "this selection triplet has a positive",
    "start": "1099840",
    "end": "1102240"
  },
  {
    "text": "impact on the overall loss value",
    "start": "1102240",
    "end": "1104960"
  },
  {
    "text": "which improves efficiency",
    "start": "1104960",
    "end": "1108240"
  },
  {
    "text": "the first part is our experiment which",
    "start": "1108240",
    "end": "1111520"
  },
  {
    "text": "includes",
    "start": "1111520",
    "end": "1112000"
  },
  {
    "text": "our experiment procedures and results",
    "start": "1112000",
    "end": "1116559"
  },
  {
    "text": "firstly we recorded the article from",
    "start": "1116559",
    "end": "1118799"
  },
  {
    "text": "eight websites",
    "start": "1118799",
    "end": "1120640"
  },
  {
    "text": "then we organize and clean the raw data",
    "start": "1120640",
    "end": "1124000"
  },
  {
    "text": "filtering out unwanted information like",
    "start": "1124000",
    "end": "1126720"
  },
  {
    "text": "incomplete or duplicate articles",
    "start": "1126720",
    "end": "1129039"
  },
  {
    "text": "and author info our data set",
    "start": "1129039",
    "end": "1132559"
  },
  {
    "text": "include about 130 articles",
    "start": "1132559",
    "end": "1136000"
  },
  {
    "text": "from 3600 authors",
    "start": "1136000",
    "end": "1139679"
  },
  {
    "text": "we performed comparison comp experiment",
    "start": "1139679",
    "end": "1142720"
  },
  {
    "text": "on those three major tasks in authorship",
    "start": "1142720",
    "end": "1145840"
  },
  {
    "text": "analysis",
    "start": "1145840",
    "end": "1146559"
  },
  {
    "text": "as mentioned before",
    "start": "1146559",
    "end": "1150080"
  },
  {
    "text": "here is some basic information about our",
    "start": "1150080",
    "end": "1152799"
  },
  {
    "text": "experiment",
    "start": "1152799",
    "end": "1153520"
  },
  {
    "text": "environment our gpu is a tesla",
    "start": "1153520",
    "end": "1156880"
  },
  {
    "text": "p40 and we use the tension flow and the",
    "start": "1156880",
    "end": "1160400"
  },
  {
    "text": "kiris",
    "start": "1160400",
    "end": "1161200"
  },
  {
    "text": "as the platform for deep learning in",
    "start": "1161200",
    "end": "1164400"
  },
  {
    "text": "order to",
    "start": "1164400",
    "end": "1165120"
  },
  {
    "text": "explore the effect of the sample size on",
    "start": "1165120",
    "end": "1167840"
  },
  {
    "text": "each model",
    "start": "1167840",
    "end": "1169200"
  },
  {
    "text": "we write the author based on their",
    "start": "1169200",
    "end": "1171200"
  },
  {
    "text": "number of words",
    "start": "1171200",
    "end": "1172480"
  },
  {
    "text": "and create seven data set that contains",
    "start": "1172480",
    "end": "1174960"
  },
  {
    "text": "answers from top",
    "start": "1174960",
    "end": "1176080"
  },
  {
    "text": "five to top 2000",
    "start": "1176080",
    "end": "1179360"
  },
  {
    "text": "also we select no more than 120 articles",
    "start": "1179360",
    "end": "1183360"
  },
  {
    "text": "per author",
    "start": "1183360",
    "end": "1184640"
  },
  {
    "text": "and the trend test ratio is 822 as usual",
    "start": "1184640",
    "end": "1190240"
  },
  {
    "text": "for authorship attribution we compared",
    "start": "1190880",
    "end": "1193600"
  },
  {
    "text": "our model with",
    "start": "1193600",
    "end": "1194480"
  },
  {
    "text": "cn and gram cn word and engram svn",
    "start": "1194480",
    "end": "1198640"
  },
  {
    "text": "by measuring the f1 score",
    "start": "1198640",
    "end": "1201919"
  },
  {
    "text": "ds here stands for triplet as in a model",
    "start": "1201919",
    "end": "1205600"
  },
  {
    "text": "that trained by the dynamic selection",
    "start": "1205600",
    "end": "1208799"
  },
  {
    "text": "and rs means trained by random selection",
    "start": "1208799",
    "end": "1211520"
  },
  {
    "text": "of course",
    "start": "1211520",
    "end": "1213840"
  },
  {
    "text": "you can see here is that our model is",
    "start": "1213840",
    "end": "1216720"
  },
  {
    "text": "over",
    "start": "1216720",
    "end": "1217120"
  },
  {
    "text": "cm word and the cn cnn grant",
    "start": "1217120",
    "end": "1220320"
  },
  {
    "text": "among all the data sets",
    "start": "1220320",
    "end": "1223440"
  },
  {
    "text": "even though engram svm has performed",
    "start": "1223440",
    "end": "1226400"
  },
  {
    "text": "better when the number of authors",
    "start": "1226400",
    "end": "1228480"
  },
  {
    "text": "is 50 and 100. our method has",
    "start": "1228480",
    "end": "1232240"
  },
  {
    "text": "obvious advantage that other baselines",
    "start": "1232240",
    "end": "1234960"
  },
  {
    "text": "when the number of author is large",
    "start": "1234960",
    "end": "1238159"
  },
  {
    "text": "next for authorship verification again",
    "start": "1238159",
    "end": "1241679"
  },
  {
    "text": "it is determining whether the author of",
    "start": "1241679",
    "end": "1243919"
  },
  {
    "text": "two articles are the same or not",
    "start": "1243919",
    "end": "1247280"
  },
  {
    "text": "we use the val a matrices introduce the",
    "start": "1247280",
    "end": "1250320"
  },
  {
    "text": "interface net",
    "start": "1250320",
    "end": "1251919"
  },
  {
    "text": "to evaluate its performance you can see",
    "start": "1251919",
    "end": "1255039"
  },
  {
    "text": "our model is",
    "start": "1255039",
    "end": "1256000"
  },
  {
    "text": "over the baseline under all data set",
    "start": "1256000",
    "end": "1259120"
  },
  {
    "text": "and provides higher accuracy on",
    "start": "1259120",
    "end": "1261200"
  },
  {
    "text": "calculating the similarity between",
    "start": "1261200",
    "end": "1263200"
  },
  {
    "text": "articles",
    "start": "1263200",
    "end": "1265200"
  },
  {
    "text": "lastly we use the fb cubed score to",
    "start": "1265200",
    "end": "1268320"
  },
  {
    "text": "compare our model with",
    "start": "1268320",
    "end": "1269919"
  },
  {
    "text": "login again triplet snn",
    "start": "1269919",
    "end": "1273360"
  },
  {
    "text": "ds scored higher in all data sets",
    "start": "1273360",
    "end": "1277120"
  },
  {
    "text": "the advantage is more significant as the",
    "start": "1277120",
    "end": "1279919"
  },
  {
    "text": "number of authors",
    "start": "1279919",
    "end": "1281120"
  },
  {
    "text": "increase here is a graph virtualize the",
    "start": "1281120",
    "end": "1284480"
  },
  {
    "text": "clustering result",
    "start": "1284480",
    "end": "1285840"
  },
  {
    "text": "on 500 articles of the top two authors",
    "start": "1285840",
    "end": "1290240"
  },
  {
    "text": "blue dots and red dots represent a",
    "start": "1290240",
    "end": "1292559"
  },
  {
    "text": "different author",
    "start": "1292559",
    "end": "1294400"
  },
  {
    "text": "you can see our method produce a",
    "start": "1294400",
    "end": "1296960"
  },
  {
    "text": "distinct",
    "start": "1296960",
    "end": "1297679"
  },
  {
    "text": "spatial separation we'll log in to",
    "start": "1297679",
    "end": "1300799"
  },
  {
    "text": "generate a more chaotic image",
    "start": "1300799",
    "end": "1305280"
  },
  {
    "text": "and that's the end of our experiment now",
    "start": "1305280",
    "end": "1308320"
  },
  {
    "text": "let's wrap up our presentation with a",
    "start": "1308320",
    "end": "1310400"
  },
  {
    "text": "short summary",
    "start": "1310400",
    "end": "1313200"
  },
  {
    "text": "first we design and implement the first",
    "start": "1313200",
    "end": "1315919"
  },
  {
    "text": "unified",
    "start": "1315919",
    "end": "1316640"
  },
  {
    "text": "embedding method for authorship analysis",
    "start": "1316640",
    "end": "1320240"
  },
  {
    "text": "we also designed an effective triplet",
    "start": "1320240",
    "end": "1323200"
  },
  {
    "text": "selection technique",
    "start": "1323200",
    "end": "1325840"
  },
  {
    "text": "in the experiment we collect the first",
    "start": "1325840",
    "end": "1328480"
  },
  {
    "text": "chinese data set",
    "start": "1328480",
    "end": "1329840"
  },
  {
    "text": "for authorship analysis and our method",
    "start": "1329840",
    "end": "1333200"
  },
  {
    "text": "outperformed other baselines",
    "start": "1333200",
    "end": "1335919"
  },
  {
    "text": "especially when the dataset gets large",
    "start": "1335919",
    "end": "1339360"
  },
  {
    "text": "in the future we will continue to test",
    "start": "1339360",
    "end": "1341919"
  },
  {
    "text": "our model",
    "start": "1341919",
    "end": "1343120"
  },
  {
    "text": "and optimize the deep learning network",
    "start": "1343120",
    "end": "1346080"
  },
  {
    "text": "and triple h selection strategy",
    "start": "1346080",
    "end": "1350080"
  },
  {
    "text": "and that's all i have to say thank you",
    "start": "1350159",
    "end": "1352480"
  },
  {
    "text": "for your patience",
    "start": "1352480",
    "end": "1353679"
  },
  {
    "text": "hope you all have a great day guys",
    "start": "1353679",
    "end": "1357600"
  }
]
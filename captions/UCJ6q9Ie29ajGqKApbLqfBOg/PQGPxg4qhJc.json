[
  {
    "text": "so alright let's get started so first of all thank you so much for coming to this",
    "start": "30",
    "end": "5549"
  },
  {
    "text": "session which is the last session of the day today's topic is the cost of",
    "start": "5549",
    "end": "11160"
  },
  {
    "text": "learning from the best we will be discussing how prior knowledge we can study security of deep neural networks",
    "start": "11160",
    "end": "18619"
  },
  {
    "text": "so let me take this opportunity to introduce our team a little bit so our",
    "start": "18619",
    "end": "24150"
  },
  {
    "text": "team is called X lab this is the secure lab within Baidu organization it is led",
    "start": "24150",
    "end": "30269"
  },
  {
    "text": "by our chief security scientist dr. Tao Wei and the one direction of the",
    "start": "30269",
    "end": "38010"
  },
  {
    "text": "research is AI security research which is that these topics was into you and my",
    "start": "38010",
    "end": "43200"
  },
  {
    "text": "name is Jane Zhang I'm leading this innocent research efforts in the team my",
    "start": "43200",
    "end": "49469"
  },
  {
    "text": "research focuses are mainly focus on adversity machine learning a special lady deep learning basically we explore",
    "start": "49469",
    "end": "59370"
  },
  {
    "text": "the latest advanced attacked mechanisms to the deep neural networks and as well",
    "start": "59370",
    "end": "65939"
  },
  {
    "text": "as the defensive mechanisms we also spend lots efforts improving the",
    "start": "65939",
    "end": "71430"
  },
  {
    "text": "robustness of deep neural networks so if you are interested to come to me and we",
    "start": "71430",
    "end": "77610"
  },
  {
    "text": "can discuss more detail offline our one of our key speakers in handy adopting",
    "start": "77610",
    "end": "84240"
  },
  {
    "text": "Han Jack who cannot be here because of the visa issue so I'm taking his position to do this presentation we also",
    "start": "84240",
    "end": "91740"
  },
  {
    "text": "have along zhang who is leading the system security research we also have",
    "start": "91740",
    "end": "96900"
  },
  {
    "text": "lots of open source projects like a mess a lot mess a link mess of Pi these are",
    "start": "96900",
    "end": "102509"
  },
  {
    "text": "all under the big umbrella like mess at E which is memory safe trusted execution",
    "start": "102509",
    "end": "109110"
  },
  {
    "text": "environment testing environment yeah so feel free to check out these open source",
    "start": "109110",
    "end": "116670"
  },
  {
    "text": "projects and we also have the entire Luke with intern with us in the past a",
    "start": "116670",
    "end": "122880"
  },
  {
    "text": "few months who also contribute a lot to these projects so in this today's topic",
    "start": "122880",
    "end": "132599"
  },
  {
    "text": "will be Ming Lee discussing a black past approach attack",
    "start": "132599",
    "end": "137610"
  },
  {
    "text": "against the division based deep neural networks will be focusing on the models",
    "start": "137610",
    "end": "143370"
  },
  {
    "text": "deployed behind the cloud-based services the thing we are trying to achieve is by",
    "start": "143370",
    "end": "149400"
  },
  {
    "text": "applying perturbations to the original input images so that the cloud-based",
    "start": "149400",
    "end": "155070"
  },
  {
    "text": "services instead of correctly identified objects within the images we want to",
    "start": "155070",
    "end": "162870"
  },
  {
    "text": "achieve the attacks at such that these cloud models won't be able to detect the",
    "start": "162870",
    "end": "169860"
  },
  {
    "text": "objects within that image for example he cannot attack the black SUVs in this",
    "start": "169860",
    "end": "176519"
  },
  {
    "text": "image so talking about cloud services this reminds us lots of big players like",
    "start": "176519",
    "end": "184580"
  },
  {
    "text": "Amazon AWS Google cloud Microsoft Azure as well as IBM they provide lots of",
    "start": "184580",
    "end": "192900"
  },
  {
    "text": "machine learning capabilities like those kind of like image classification",
    "start": "192900",
    "end": "198980"
  },
  {
    "text": "capability object detection capability as well as the natural language",
    "start": "198980",
    "end": "204450"
  },
  {
    "text": "processing capability also you can find some malware classification capability",
    "start": "204450",
    "end": "210019"
  },
  {
    "text": "however the question we have is are these car models safe against the adversary's so",
    "start": "210019",
    "end": "221130"
  },
  {
    "text": "the answer is no I will just walk through a simple case study to explain",
    "start": "221130",
    "end": "227790"
  },
  {
    "text": "that so you pick a safe such API which is the Google Safe Search API as an",
    "start": "227790",
    "end": "233730"
  },
  {
    "text": "example so this API what it does is but",
    "start": "233730",
    "end": "239010"
  },
  {
    "text": "take an input image and your returns the",
    "start": "239010",
    "end": "244200"
  },
  {
    "text": "results like different categories for this image with along with the competence levels the confidence levels",
    "start": "244200",
    "end": "252620"
  },
  {
    "text": "is from one to five one means very unlikely and a five is very likely so in",
    "start": "252620",
    "end": "258959"
  },
  {
    "text": "this case this point image will be considered to contain adult content",
    "start": "258959",
    "end": "264810"
  },
  {
    "text": "content as well as the racy content so is this kind of such API can be",
    "start": "264810",
    "end": "273500"
  },
  {
    "text": "easily deceived this new fashion we have the answer is yes so we actually apply several spatial",
    "start": "273500",
    "end": "281030"
  },
  {
    "text": "transformations to the original image in this case which is the left most image",
    "start": "281030",
    "end": "286210"
  },
  {
    "text": "when we feed this image in to save such API the pair returns the rankings for a",
    "start": "286210",
    "end": "293810"
  },
  {
    "text": "doubt in a racy at 5:00 which is very likely but when we apply the several",
    "start": "293810",
    "end": "300680"
  },
  {
    "text": "special transformation for example framing we zoom out the image and add a",
    "start": "300680",
    "end": "305720"
  },
  {
    "text": "frame around it and also we do a perspective transformation basically",
    "start": "305720",
    "end": "310970"
  },
  {
    "text": "they would stretch out four vertices a little bit to make to you a different shape and also apply a fine",
    "start": "310970",
    "end": "317150"
  },
  {
    "text": "transformation so we base it here rotate image a little bit so for all of these transformations we can see when we feed",
    "start": "317150",
    "end": "325130"
  },
  {
    "text": "those image to save such ABI the ratings for the doubt in a racy they are most",
    "start": "325130",
    "end": "331340"
  },
  {
    "text": "big they can be lowered to you unlikely like two or two below in",
    "start": "331340",
    "end": "339770"
  },
  {
    "text": "addition to that we actually run the evaluation against this Save Search API",
    "start": "339770",
    "end": "345530"
  },
  {
    "text": "basically called one hundred images and for each image we run one hundred",
    "start": "345530",
    "end": "352250"
  },
  {
    "text": "different spatial transformations so that we can have like ten thousand image",
    "start": "352250",
    "end": "357560"
  },
  {
    "text": "as a test data sets and we use the 10k image to run against the Safe Search API",
    "start": "357560",
    "end": "363860"
  },
  {
    "text": "and here is the results so out of 10k",
    "start": "363860",
    "end": "369200"
  },
  {
    "text": "test images 69% of those has the rating of that doubt less we go to n2 which is unlikely so",
    "start": "369200",
    "end": "378410"
  },
  {
    "text": "out of 10k images 40% of those has posed a doubt and the receive readings less or",
    "start": "378410",
    "end": "387080"
  },
  {
    "text": "you go down to which is also are unlikely so we actually gave a thought",
    "start": "387080",
    "end": "392930"
  },
  {
    "text": "about that and see what caused that so there are two reasons we thought so one",
    "start": "392930",
    "end": "398330"
  },
  {
    "text": "is during the training probably they don't have enough space with a documentation",
    "start": "398330",
    "end": "406319"
  },
  {
    "text": "included in their training dataset so that the training models won't include",
    "start": "406319",
    "end": "412620"
  },
  {
    "text": "the data distributions that can detect such transformation transform the images",
    "start": "412620",
    "end": "421520"
  },
  {
    "text": "secondly those since which API will assume that the input a that will",
    "start": "421520",
    "end": "428610"
  },
  {
    "text": "contain we include the region of interest that that can improve those",
    "start": "428610",
    "end": "434090"
  },
  {
    "text": "objects it they are going to classify however often times that it might not be the case",
    "start": "434090",
    "end": "440129"
  },
  {
    "text": "so pre-processing will be a necessary step needs to be done so in this case probably there is no pre-processing step",
    "start": "440129",
    "end": "449689"
  },
  {
    "text": "using this API so here we have another",
    "start": "449689",
    "end": "455879"
  },
  {
    "text": "question so is this simple special attack generally applicable to all the",
    "start": "455879",
    "end": "461400"
  },
  {
    "text": "rest of the cloud-based vision models the answer is no because we actually run",
    "start": "461400",
    "end": "468650"
  },
  {
    "text": "run a test against the object attachment API it turns out that all the",
    "start": "468650",
    "end": "474210"
  },
  {
    "text": "attentional API is really robust against such a simple space for attack as we can",
    "start": "474210",
    "end": "479639"
  },
  {
    "text": "see from the images down below deal also",
    "start": "479639",
    "end": "485250"
  },
  {
    "text": "the leftmost images to original ones and the right three images is the one we",
    "start": "485250",
    "end": "491479"
  },
  {
    "text": "apply to transformations so you can see once we feed those image into the object",
    "start": "491479",
    "end": "497759"
  },
  {
    "text": "hashing API what they return is they can currently draw the bounding box around",
    "start": "497759",
    "end": "503069"
  },
  {
    "text": "the two vehicles so that means no matter how we run the transformation the object",
    "start": "503069",
    "end": "508740"
  },
  {
    "text": "hashing API is very robust against it so the reasons we thought about that is",
    "start": "508740",
    "end": "516409"
  },
  {
    "text": "probably for the in the classification model as we discussed previously they",
    "start": "516409",
    "end": "522959"
  },
  {
    "text": "only have one objective this which is to lower the confidence levels of the targeted class but however in the object",
    "start": "522959",
    "end": "530970"
  },
  {
    "text": "attached on the API they have multiple objectives for example to detect multiple objects in the image",
    "start": "530970",
    "end": "536670"
  },
  {
    "text": "they also need to derive which class or",
    "start": "536670",
    "end": "543370"
  },
  {
    "text": "which category it is up there falls into you and also they need to derive or predict the size as well as the location",
    "start": "543370",
    "end": "552010"
  },
  {
    "text": "of the bounding boxes and also they need to predict the confidence score of the objects so it might be easy for the",
    "start": "552010",
    "end": "558880"
  },
  {
    "text": "attacker to achieve successful attack against just one objective but combine these together but it will be harder for",
    "start": "558880",
    "end": "565870"
  },
  {
    "text": "the attacker to achieve attacking all of these objectives for the rest of the",
    "start": "565870",
    "end": "573970"
  },
  {
    "text": "talk we'll be discussing how we achieve attacks this attack by using a method we",
    "start": "573970",
    "end": "581680"
  },
  {
    "text": "called fingerprinting attack that can generate a diverse your example very efficiently against these cloud-based",
    "start": "581680",
    "end": "587860"
  },
  {
    "text": "vision models so talking about adversity example I will just use one slide to",
    "start": "587860",
    "end": "593380"
  },
  {
    "text": "briefly introduce that so given this example like to image on the left and",
    "start": "593380",
    "end": "601810"
  },
  {
    "text": "right if I don't tell you the difference probably most of the people will think these two images are identical however",
    "start": "601810",
    "end": "609880"
  },
  {
    "text": "the difference is actually the middle image which is the perturbation we apply to the original image on the left which",
    "start": "609880",
    "end": "617949"
  },
  {
    "text": "results into the image on the right and once we feed those two images into the",
    "start": "617949",
    "end": "623649"
  },
  {
    "text": "updation object object attacking api's where the return is for the original",
    "start": "623649",
    "end": "629500"
  },
  {
    "text": "image it can correctly identify two vehicles in image however for the versatile example here can only detect",
    "start": "629500",
    "end": "638649"
  },
  {
    "text": "the white man in the image he won't be able to identify the black SUV in it and",
    "start": "638649",
    "end": "645070"
  },
  {
    "text": "at the same time the congas level of the white van is lowered so in order to",
    "start": "645070",
    "end": "656290"
  },
  {
    "text": "generate a deluge examples usually the attacker has to have a white box access to the model because they",
    "start": "656290",
    "end": "663250"
  },
  {
    "text": "need to use gradient descent and method to calculate the some of the changes to the original",
    "start": "663250",
    "end": "669070"
  },
  {
    "text": "inputs and there are different levels of the knowledge that the attacker can have",
    "start": "669070",
    "end": "675610"
  },
  {
    "text": "for example they can get access to the entire training data set or they can have access to the model architecture",
    "start": "675610",
    "end": "682060"
  },
  {
    "text": "okay they can have the access to the model parameters if they can access",
    "start": "682060",
    "end": "687850"
  },
  {
    "text": "those it is considered to be a white box but most of the time the attacker might",
    "start": "687850",
    "end": "695710"
  },
  {
    "text": "not have two such privileges what they have they might have just the last layer logics from the model or they can have",
    "start": "695710",
    "end": "704020"
  },
  {
    "text": "just the prediction values from the models so in that cases it is considered",
    "start": "704020",
    "end": "709690"
  },
  {
    "text": "black box so in our top we consider the cloud er",
    "start": "709690",
    "end": "716410"
  },
  {
    "text": "models black box models to the attackers and we argue that the black box just",
    "start": "716410",
    "end": "724450"
  },
  {
    "text": "provide a false sense of security and then the rest of the slides will be",
    "start": "724450",
    "end": "730890"
  },
  {
    "text": "discussing how we achieve that by leveraging a vulnerability we found in",
    "start": "730890",
    "end": "737590"
  },
  {
    "text": "the transfer line which is being widely used in the deep learning community to",
    "start": "737590",
    "end": "744190"
  },
  {
    "text": "train the model so first of all let me",
    "start": "744190",
    "end": "749560"
  },
  {
    "text": "just introduce transfer learning a little bit so in this image the top part",
    "start": "749560",
    "end": "756970"
  },
  {
    "text": "is a image in that kind of architecture",
    "start": "756970",
    "end": "763270"
  },
  {
    "text": "deep learning your network architecture so basically if you want to train a deep",
    "start": "763270",
    "end": "768730"
  },
  {
    "text": "neural networks you what you need to have is a huge number of datasets like a",
    "start": "768730",
    "end": "773980"
  },
  {
    "text": "millions of millions of data images and also you need to have lots of GPU",
    "start": "773980",
    "end": "780010"
  },
  {
    "text": "resources so that you can train a model within days or weeks or to have a model",
    "start": "780010",
    "end": "785560"
  },
  {
    "text": "with high accuracy however normal users might not have access to these kind of resources what they have probably just a",
    "start": "785560",
    "end": "794020"
  },
  {
    "text": "few in a few training examples which is just black and white x-ray scan",
    "start": "794020",
    "end": "799930"
  },
  {
    "text": "and what he spits out is only like four categories instead of a thousand",
    "start": "799930",
    "end": "806020"
  },
  {
    "text": "categories like what image net has however if we use a transfer learning",
    "start": "806020",
    "end": "813010"
  },
  {
    "text": "language actually you can inherit a pre trainer model from the image net by",
    "start": "813010",
    "end": "818290"
  },
  {
    "text": "fine-tuning the model you can train in your model which has the same high",
    "start": "818290",
    "end": "824170"
  },
  {
    "text": "accuracy within just a minute or just hours let's use another example to",
    "start": "824170",
    "end": "832330"
  },
  {
    "text": "illustrate the idea more clearly so [Music] suppose you have a teacher model you",
    "start": "832330",
    "end": "839170"
  },
  {
    "text": "want to train that number of student models and here is the architecture of the teacher model and we use a dotted",
    "start": "839170",
    "end": "845650"
  },
  {
    "text": "line to divided models into two parts the left part we consider that as feature extractor layers and rub and the",
    "start": "845650",
    "end": "853570"
  },
  {
    "text": "right part is considered to be a cost-efficient layers or the fine-tuning layers so this when the students",
    "start": "853570",
    "end": "859690"
  },
  {
    "text": "trainees own models he inherits the entire architecture from the teacher and add a few classification layers to the",
    "start": "859690",
    "end": "866500"
  },
  {
    "text": "end and they just fine-tuning the transmission layers to to achieve the",
    "start": "866500",
    "end": "874980"
  },
  {
    "text": "new model at the same time here the point is the entire feature extractor",
    "start": "874980",
    "end": "882040"
  },
  {
    "text": "layers no matter whether this is a post deep attacker and also the parameter",
    "start": "882040",
    "end": "890260"
  },
  {
    "text": "values remains the same so this is the opportunity we have that we can run the",
    "start": "890260",
    "end": "897160"
  },
  {
    "text": "attack against the deep neural networks and here's how so we used a EULA B 3 as",
    "start": "897160",
    "end": "903940"
  },
  {
    "text": "example and user V 3 is the state-of-the-art of the attachment model so given an input image you will learn",
    "start": "903940",
    "end": "911590"
  },
  {
    "text": "through an the feature extractor and and they will be propagated to the rest of",
    "start": "911590",
    "end": "916900"
  },
  {
    "text": "the classification layer to detect the object within the image so the idea is",
    "start": "916900",
    "end": "924280"
  },
  {
    "text": "if we can fool the layer K which is the",
    "start": "924280",
    "end": "931830"
  },
  {
    "text": "layers in featuring title part then probably came",
    "start": "931830",
    "end": "937190"
  },
  {
    "text": "food in time out at the end so here for simply for simplicity the K we will be",
    "start": "937190",
    "end": "944720"
  },
  {
    "text": "referring to the last layer in the future extractor so instead in order to",
    "start": "944720",
    "end": "951950"
  },
  {
    "text": "carry out a successful attack we bring it down to three steps so first of all we need to identify which feature",
    "start": "951950",
    "end": "958010"
  },
  {
    "text": "extractor the model deployed behind the car service is using with just a few",
    "start": "958010",
    "end": "964130"
  },
  {
    "text": "parents secondly we will generate a a debrief examples on white box pre train",
    "start": "964130",
    "end": "972320"
  },
  {
    "text": "models and lastly will attack the black model using the training example we",
    "start": "972320",
    "end": "978280"
  },
  {
    "text": "obtain in front of previous steps so here I will illustrate our approaches in",
    "start": "978280",
    "end": "986780"
  },
  {
    "text": "this example again suppose we have a benign image which is a cat when feeding",
    "start": "986780",
    "end": "995330"
  },
  {
    "text": "into the deep learning models and also the dotted line divided the model into",
    "start": "995330",
    "end": "1001540"
  },
  {
    "text": "two parts the left part is the feature extractor layers and the right part is the classification layers so if we look",
    "start": "1001540",
    "end": "1008710"
  },
  {
    "text": "at the last layers and a lot I mean I mean the logits of the neuron upwards of",
    "start": "1008710",
    "end": "1016510"
  },
  {
    "text": "the last way of indie feature extractor and we can see one property we call this",
    "start": "1016510",
    "end": "1024579"
  },
  {
    "text": "person's which is can be measured using the Gini coefficient or standard deviations so here we use just use the",
    "start": "1024580",
    "end": "1032050"
  },
  {
    "text": "standard a Shinto to illustrate the dispersion values so here so basically",
    "start": "1032050",
    "end": "1037380"
  },
  {
    "text": "the last layer of the fifth chapter has a dispersion value at point three nine",
    "start": "1037380",
    "end": "1044770"
  },
  {
    "text": "which considered to be relatively high so when this value is propagated to the",
    "start": "1044770",
    "end": "1050290"
  },
  {
    "text": "end that the final layer will have a very high confidence that input image is",
    "start": "1050290",
    "end": "1059280"
  },
  {
    "text": "classified as the cat so what the attacker can do is he can intentionally",
    "start": "1059280",
    "end": "1067090"
  },
  {
    "text": "craft an example such that he can lower",
    "start": "1067090",
    "end": "1072429"
  },
  {
    "text": "the dispersion values in the last layer of the future chapter in this case we",
    "start": "1072429",
    "end": "1078490"
  },
  {
    "text": "can target to lower the standard deviation for the last layer too close",
    "start": "1078490",
    "end": "1084879"
  },
  {
    "text": "to zero in that case when this value is propagated to the end then we hope the",
    "start": "1084879",
    "end": "1091350"
  },
  {
    "text": "content score of that category cat will be also very low thus we can achieve our",
    "start": "1091350",
    "end": "1098669"
  },
  {
    "text": "successful attack again since we are",
    "start": "1098669",
    "end": "1105009"
  },
  {
    "text": "trying to figure out which feature extract is using by the cloud models so",
    "start": "1105009",
    "end": "1110590"
  },
  {
    "text": "what we do is we collect a number of public available feature extractor as",
    "start": "1110590",
    "end": "1117399"
  },
  {
    "text": "well in other words like a deepening of architectures that is open sourced for",
    "start": "1117399",
    "end": "1125200"
  },
  {
    "text": "example the BG 16 VG nineteen Inception ResNet mobile net so these are publicly",
    "start": "1125200",
    "end": "1131350"
  },
  {
    "text": "available so for each of these architecture we were trying to create in",
    "start": "1131350",
    "end": "1138039"
  },
  {
    "text": "an input example that minimize the last layer the dispersion values of the last",
    "start": "1138039",
    "end": "1144700"
  },
  {
    "text": "layout the feature extractor once we have that we will monitor the output of",
    "start": "1144700",
    "end": "1151240"
  },
  {
    "text": "the last layer right then we do the comparisons and here is results so",
    "start": "1151240",
    "end": "1158649"
  },
  {
    "text": "basically we collect like a 14 different kind of fatigue factor and among these",
    "start": "1158649",
    "end": "1164499"
  },
  {
    "text": "14 different feature factors and the y-axis is the confidence score of the",
    "start": "1164499",
    "end": "1169840"
  },
  {
    "text": "cat and here we see the apps X and F 13",
    "start": "1169840",
    "end": "1175509"
  },
  {
    "text": "has the lowest confidence course which means these might be these architecture",
    "start": "1175509",
    "end": "1181779"
  },
  {
    "text": "might be the ones are used by the models deployed behind cloud services and for",
    "start": "1181779",
    "end": "1189700"
  },
  {
    "text": "each of these candidate architecture we will run an iterative gradient sign",
    "start": "1189700",
    "end": "1195909"
  },
  {
    "text": "method to create different examples so when we creating such",
    "start": "1195909",
    "end": "1207289"
  },
  {
    "text": "advanced examples actually there are different strategies first we can run a",
    "start": "1207289",
    "end": "1215260"
  },
  {
    "text": "untargeted attack by just minimizing the last layer logits at the las leyes de",
    "start": "1215260",
    "end": "1221750"
  },
  {
    "text": "personal values in the future character such that once that is lower than the",
    "start": "1221750",
    "end": "1229370"
  },
  {
    "text": "last layers the final score will be lower as well suddenly which we can do",
    "start": "1229370",
    "end": "1235490"
  },
  {
    "text": "is to target the last layer the which we can do a targeted attack basically we",
    "start": "1235490",
    "end": "1241669"
  },
  {
    "text": "want to maximize the distance between the original original class and at a",
    "start": "1241669",
    "end": "1247970"
  },
  {
    "text": "target cause that attack 180b so once we maximize the distance then we",
    "start": "1247970",
    "end": "1253279"
  },
  {
    "text": "can achieve such targeted attack and now",
    "start": "1253279",
    "end": "1259789"
  },
  {
    "text": "here is the evaluation part as usual we will show the revision rate at the same",
    "start": "1259789",
    "end": "1266960"
  },
  {
    "text": "time I want to bring up another idea is the efficiency which is the number of queries that the attacker will use to",
    "start": "1266960",
    "end": "1274220"
  },
  {
    "text": "achieve the successful attack this is very important because as a blast attack",
    "start": "1274220",
    "end": "1280539"
  },
  {
    "text": "especially in cloud based kind of models the attacker only has the excess to make",
    "start": "1280539",
    "end": "1288260"
  },
  {
    "text": "a query against this API to get some information from the model so the more",
    "start": "1288260",
    "end": "1293779"
  },
  {
    "text": "perct the de priori so probability will be",
    "start": "1293779",
    "end": "1299840"
  },
  {
    "text": "charged a lot for this for those kind of attempts so this is were bad for the",
    "start": "1299840",
    "end": "1305899"
  },
  {
    "text": "attackers right so that's why the efficiency is very important so here we",
    "start": "1305899",
    "end": "1311600"
  },
  {
    "text": "we compare to attack message here along with you like combination budgets you",
    "start": "1311600",
    "end": "1319820"
  },
  {
    "text": "have on the attacks so suppose for the dispersing kind of attack if you have",
    "start": "1319820",
    "end": "1324919"
  },
  {
    "text": "just two courage for each input test image so the original rates you can have",
    "start": "1324919",
    "end": "1331760"
  },
  {
    "text": "is like a 33% so if you have like more budget like a 100 cards for each image then the",
    "start": "1331760",
    "end": "1339210"
  },
  {
    "text": "original rate will be increased to 86% for the target score attack suppose you",
    "start": "1339210",
    "end": "1346290"
  },
  {
    "text": "have 2 cards for each input image you can achieve like 16 percent original rate if you have more budget like 100",
    "start": "1346290",
    "end": "1354720"
  },
  {
    "text": "queries per image they can have a higher successful rate like 65 percent also the",
    "start": "1354720",
    "end": "1361650"
  },
  {
    "text": "image down below shows a fatness of this attack by using the target score attack",
    "start": "1361650",
    "end": "1367320"
  },
  {
    "text": "as well and the dispersion attack the object attachment API won't be able to",
    "start": "1367320",
    "end": "1373170"
  },
  {
    "text": "tell the black to tell the black SUV in the image even though they can detect",
    "start": "1373170",
    "end": "1380010"
  },
  {
    "text": "the white van in the image however the confidence score is kind of a significant Lord now let's come to the",
    "start": "1380010",
    "end": "1389310"
  },
  {
    "text": "conclusion and the takeaways of this talk so we argue that black box only",
    "start": "1389310",
    "end": "1394740"
  },
  {
    "text": "provides a false sense of security and fooling the prediction result by targeting internal layers is generally",
    "start": "1394740",
    "end": "1401100"
  },
  {
    "text": "applicable to the deep neural networks and we call for efforts to harden the",
    "start": "1401100",
    "end": "1408360"
  },
  {
    "text": "models with adversary' trainings so that's pretty much of the top so I'm",
    "start": "1408360",
    "end": "1414570"
  },
  {
    "text": "open to questions",
    "start": "1414570",
    "end": "1417500"
  },
  {
    "text": "yes difference between original image",
    "start": "1431550",
    "end": "1449100"
  },
  {
    "text": "and a diversity example okay here is the code ah where is it",
    "start": "1449100",
    "end": "1457399"
  },
  {
    "text": "okay the difference is in the middle as you can tell can you tell the middle",
    "start": "1462170",
    "end": "1470220"
  },
  {
    "text": "image so these are just a pic pixel wise the perturbations so basically you make",
    "start": "1470220",
    "end": "1478920"
  },
  {
    "text": "changes to each pics a little bit based on like very popular methods based on",
    "start": "1478920",
    "end": "1486660"
  },
  {
    "text": "the LP norm kind of methods I can do you like an L 1 L infinity L like L to those",
    "start": "1486660",
    "end": "1493440"
  },
  {
    "text": "kind of thing I was here oh yes okay",
    "start": "1493440",
    "end": "1508890"
  },
  {
    "text": "sure so so D let me see here is the",
    "start": "1508890",
    "end": "1514080"
  },
  {
    "text": "fingerprinting okay right here yeah so",
    "start": "1514080",
    "end": "1520830"
  },
  {
    "text": "the Rivermen it basically is that you need to identify which feature extractor is being used right so the thing is so",
    "start": "1520830",
    "end": "1529710"
  },
  {
    "text": "the property we you can observe here is the last layer of the future exactly the",
    "start": "1529710",
    "end": "1536070"
  },
  {
    "text": "property oh caught is dispersion value here we used ennovation to calculate this depression right all right so for",
    "start": "1536070",
    "end": "1543180"
  },
  {
    "text": "the for the benign image here the top top one so it has a standard deviation",
    "start": "1543180",
    "end": "1551580"
  },
  {
    "text": "for the last layer of the future is like a point zero nine these are actually",
    "start": "1551580",
    "end": "1556710"
  },
  {
    "text": "based on the the largest of the neural",
    "start": "1556710",
    "end": "1561960"
  },
  {
    "text": "APIs from the last layer of the future extractor okay so the thing we are trying to do is we can",
    "start": "1561960",
    "end": "1568590"
  },
  {
    "text": "just minimize this dispersion value such that the standard version of the last",
    "start": "1568590",
    "end": "1575820"
  },
  {
    "text": "layers based of all the course order logits we can make us close to zero we",
    "start": "1575820",
    "end": "1583559"
  },
  {
    "text": "can intentionally place such praise such input to achieve that right so our",
    "start": "1583559",
    "end": "1591260"
  },
  {
    "text": "optimization goal is to achieve that so we hope when this when the output of the",
    "start": "1591260",
    "end": "1599279"
  },
  {
    "text": "this last lay of the future except we have been propagated to the final layer",
    "start": "1599279",
    "end": "1604370"
  },
  {
    "text": "then the confidence level of the target",
    "start": "1604370",
    "end": "1609929"
  },
  {
    "text": "class hat will be lower hopefully it's below the threshold so in",
    "start": "1609929",
    "end": "1615330"
  },
  {
    "text": "that case the image classification classifier will be able to detect this",
    "start": "1615330",
    "end": "1621630"
  },
  {
    "text": "input is a cat does that make sense uh-huh okay yeah yeah right right right",
    "start": "1621630",
    "end": "1636330"
  },
  {
    "text": "right okay okay yeah I missed something right here",
    "start": "1636330",
    "end": "1643080"
  },
  {
    "text": "so basically you have this right so the pit here we explained the idea how we",
    "start": "1643080",
    "end": "1649529"
  },
  {
    "text": "can create such image now we want to find which archetypes being used by the",
    "start": "1649529",
    "end": "1654570"
  },
  {
    "text": "car models so the thing is you have a number of updates out there that's public available right so for each of",
    "start": "1654570",
    "end": "1662460"
  },
  {
    "text": "those who can use the same method we introduced here to create an input right",
    "start": "1662460",
    "end": "1668370"
  },
  {
    "text": "so for each so suppose there are 14 different feature extractors here then",
    "start": "1668370",
    "end": "1675929"
  },
  {
    "text": "we can have 14 different inputs are you",
    "start": "1675929",
    "end": "1682380"
  },
  {
    "text": "with me here right is right now I don't",
    "start": "1682380",
    "end": "1688140"
  },
  {
    "text": "have to right now I don't have to I just have the I just collect the 14 like a",
    "start": "1688140",
    "end": "1693149"
  },
  {
    "text": "public available okay okay I don't know which one it is used by the cow models",
    "start": "1693149",
    "end": "1699159"
  },
  {
    "text": "right all right right right okay great answer your question",
    "start": "1699159",
    "end": "1706009"
  },
  {
    "text": "Thanks yes Oh defensive mechanism that's a great",
    "start": "1706009",
    "end": "1713690"
  },
  {
    "text": "question so the number of ways have been proposed so one thing is when you do the",
    "start": "1713690",
    "end": "1718850"
  },
  {
    "text": "inferencing you probably can do ad randomness to the input data for example",
    "start": "1718850",
    "end": "1724220"
  },
  {
    "text": "you can drop a few pixels to the original inputs and also there could be",
    "start": "1724220",
    "end": "1729379"
  },
  {
    "text": "other ways like you can you can when",
    "start": "1729379",
    "end": "1736549"
  },
  {
    "text": "entering the model you can try to increase the distance between your student model and the teacher model I",
    "start": "1736549",
    "end": "1744230"
  },
  {
    "text": "mean the neuron to neuron distance as a regulation kind of part right so this is",
    "start": "1744230",
    "end": "1752809"
  },
  {
    "text": "second one so other things probably also you can do is to use in assemble that",
    "start": "1752809",
    "end": "1758720"
  },
  {
    "text": "method so basically you can when the pro model instead of the poly just one model",
    "start": "1758720",
    "end": "1765440"
  },
  {
    "text": "you can deploy a number of Masuda models that learn from different teacher models",
    "start": "1765440",
    "end": "1770499"
  },
  {
    "text": "so you can run like majority vote on this student model to see which one what",
    "start": "1770499",
    "end": "1779269"
  },
  {
    "text": "the results it is right so the attacker has to deal with all these kind of",
    "start": "1779269",
    "end": "1785570"
  },
  {
    "text": "teacher models so it might be harder for him hope that answer your question",
    "start": "1785570",
    "end": "1794830"
  },
  {
    "text": "great great great",
    "start": "1794830",
    "end": "1798549"
  },
  {
    "text": "all right guess that's it thank you so much",
    "start": "1803180",
    "end": "1808370"
  }
]
[
  {
    "text": "all right so let's start um in today's world",
    "start": "2639",
    "end": "7919"
  },
  {
    "text": "security teams are so stretched that if they were a yoga pose they'd be called",
    "start": "7919",
    "end": "12920"
  },
  {
    "text": "The Eternal scream I spent an hour at least an hour brainstorming with chat gbt to write",
    "start": "12920",
    "end": "19000"
  },
  {
    "text": "this line and it's still a little bit underwhelming but here comes AI like a",
    "start": "19000",
    "end": "24439"
  },
  {
    "text": "new caffeine pill so that the security team can focus on real threats uh but",
    "start": "24439",
    "end": "29640"
  },
  {
    "text": "here we're here to make sure that AI doesn't start flagging every Mouse click as an existential",
    "start": "29640",
    "end": "36960"
  },
  {
    "text": "crisis so a few things about ourselves uh I'm FIS I'm a security engineer and",
    "start": "36960",
    "end": "42840"
  },
  {
    "text": "the red teamer uh some highlights of my work include uh publishing a book on practical iot hacking I have a paper on",
    "start": "42840",
    "end": "50239"
  },
  {
    "text": "exploiting TCP published at uh frack and uh I've also written en crack the",
    "start": "50239",
    "end": "56079"
  },
  {
    "text": "network authentication cracking tool of uh the enmap project I was also the first security engineer at open AI",
    "start": "56079",
    "end": "62760"
  },
  {
    "text": "starting back when we had just released gbt 3 in 2020 uh I was there before the Chad gbd",
    "start": "62760",
    "end": "70360"
  },
  {
    "text": "Hive you were around the time of codex right our code generation model I was there Paul I was there 3,000 years ago I",
    "start": "70360",
    "end": "78280"
  },
  {
    "text": "was there when it was ritten it's okay fotos I understand a year here feels like 10 anywhere else and with so much",
    "start": "78280",
    "end": "83920"
  },
  {
    "text": "happening it just keeps going my background is in building and securing clouds both public and private I've also",
    "start": "83920",
    "end": "90520"
  },
  {
    "text": "on the security team for several open source projects that everyone in the room uses every day still I've never seen anything like this last year of",
    "start": "90520",
    "end": "97000"
  },
  {
    "text": "growth working on product security here at open AI this talk is based on the work of our whole team and we want to",
    "start": "97000",
    "end": "103200"
  },
  {
    "text": "acknowledge the contributions of Colin Jake Tiffany Harold and will all right let's move on to the talk but first a",
    "start": "103200",
    "end": "110119"
  },
  {
    "text": "quick story when we released chat GPT millions of users flocked to the product and we had a hard time keeping up with",
    "start": "110119",
    "end": "116039"
  },
  {
    "text": "demand also we hadn't released an API yet predict many of our very excited",
    "start": "116039",
    "end": "121520"
  },
  {
    "text": "attackers I mean enthusiasts wanted to use the product in unauthorized ways we played a cat and mouse game with them",
    "start": "121520",
    "end": "128399"
  },
  {
    "text": "they would find new apis to abuse we would stop up the uh problem and improve our bot detection it was pretty",
    "start": "128399",
    "end": "135120"
  },
  {
    "text": "exhausting one day we noticed a very unique attacker signal and rather than just blocking the Bots we figured one of",
    "start": "135120",
    "end": "141800"
  },
  {
    "text": "our Engineers wanted to send all the incoming request to a very small very dumb model that only wanted to talk",
    "start": "141800",
    "end": "147800"
  },
  {
    "text": "about cats and so cat Jeep was born our attackers were a little bit perplexed",
    "start": "147800",
    "end": "154440"
  },
  {
    "text": "perhaps even unhappy but we think they enjoyed the joke almost as much as we did one user suggested we should have",
    "start": "154440",
    "end": "160200"
  },
  {
    "text": "rickrolled them but honestly cat GPT was funnier there are many fun things you can do with llms but this talk is about",
    "start": "160200",
    "end": "166239"
  },
  {
    "text": "more practical topics enough of the work stuff everything out from here on is strictly vendor neutral so let's see",
    "start": "166239",
    "end": "172879"
  },
  {
    "text": "what what talk is about while we appreciate good old traditional security tools we found llms can augment the very",
    "start": "172879",
    "end": "179959"
  },
  {
    "text": "effectively AI isn't going to directly replace standard tooling but enhanced workflows using llms can have a profound",
    "start": "179959",
    "end": "187040"
  },
  {
    "text": "impact on a team's efficiency today there are a few these These are the key",
    "start": "187040",
    "end": "193159"
  },
  {
    "text": "things we want you to take away we're talking about using the models to help humans go faster by reducing security",
    "start": "193159",
    "end": "198959"
  },
  {
    "text": "friction helping humans focus on the important parts of the defense using LMS",
    "start": "198959",
    "end": "204120"
  },
  {
    "text": "to improve the way that we catch attackers and accelerating the drudgery of everyday security work and by the way",
    "start": "204120",
    "end": "211680"
  },
  {
    "text": "we're open sourcing three new tools today so you can get started doing this too so what this talk is not about it's",
    "start": "211680",
    "end": "218120"
  },
  {
    "text": "not about chat GPT the website Auto GPT Lang chain jailbreaks fine tuning these are all things you can do with",
    "start": "218120",
    "end": "223959"
  },
  {
    "text": "off-the-shelf models and it's not a vendor pitch these slides are the last time you'll see our company logo and you should be able to do these things with",
    "start": "223959",
    "end": "230360"
  },
  {
    "text": "any of your favorite model from your favorite vendor so let's start with a quick refresher base on how most modern",
    "start": "230360",
    "end": "236159"
  },
  {
    "text": "llms work today models are composed of tokens which repres in about 3/4 of a word the model weits encode",
    "start": "236159",
    "end": "243400"
  },
  {
    "text": "relationships between those tokens and they're stored in the GPU when you query a model it happens through a single",
    "start": "243400",
    "end": "249720"
  },
  {
    "text": "request response cycle your query is encoded as tokens passed through to the GPU producing your response this means",
    "start": "249720",
    "end": "256680"
  },
  {
    "text": "that the model is stateless when you query it these model weights don't change and the model model doesn't remember a prior conversation it doesn't",
    "start": "256680",
    "end": "264160"
  },
  {
    "text": "learn from what you pass through it so given all that how does chat GPT work",
    "start": "264160",
    "end": "269360"
  },
  {
    "text": "cont text don't try to read this text it's deliberately too small remember how",
    "start": "269360",
    "end": "274560"
  },
  {
    "text": "I said the model is stateless it doesn't actually remember things between submissions to the gpus and instead it",
    "start": "274560",
    "end": "280560"
  },
  {
    "text": "just includes as much of the prior conversation as it can when it runs out of space rather than uh telling you it's",
    "start": "280560",
    "end": "287960"
  },
  {
    "text": "got an error it just starts deleting part of the history so that each request can fit into that single request response cycle it doesn't change the",
    "start": "287960",
    "end": "294600"
  },
  {
    "text": "weights in the GPU and there's no magic there so that's that was a cool story",
    "start": "294600",
    "end": "300320"
  },
  {
    "text": "about the meow and K but here I'd like to introduce you to woofpak so woofpak",
    "start": "300320",
    "end": "307240"
  },
  {
    "text": "is a company that makes AI powered dog colors that can translate Woos and Barks to human speech I know some people would",
    "start": "307240",
    "end": "314560"
  },
  {
    "text": "pay an infinite amount of money to have that kind of product uh and as we're watching this video of huskys and shibas",
    "start": "314560",
    "end": "320039"
  },
  {
    "text": "roaming a cyberpunk themed City wearing a wol spe colar uh we're going to describe a scenario to demonstrate our",
    "start": "320039",
    "end": "326160"
  },
  {
    "text": "llm driven tools so the engineers of our wol speak company are building a new inventory tracking system for the",
    "start": "326160",
    "end": "332039"
  },
  {
    "text": "various versions of doers the compan is producing um",
    "start": "332039",
    "end": "338080"
  },
  {
    "text": "let's and it is comprised of all the standard uh components you'd expect from such an app so it uses a web UI with",
    "start": "338080",
    "end": "344600"
  },
  {
    "text": "react as the front end no JS as the back end my SQL for storage of zero for user",
    "start": "344600",
    "end": "349759"
  },
  {
    "text": "authentication authorization and the most important thing is that this will be accessible only through the company's",
    "start": "349759",
    "end": "355520"
  },
  {
    "text": "VPN so it will be for employees only and there's not going to be any internet access and surprise surprise the",
    "start": "355520",
    "end": "361520"
  },
  {
    "text": "engineers are on a tight timeline to build all of this the software development life cycle is not going to",
    "start": "361520",
    "end": "367080"
  },
  {
    "text": "be very linear for wo speak so the sdlc the software development life cycle is",
    "start": "367080",
    "end": "372840"
  },
  {
    "text": "is as you know a structure process used for planning creating testing and deploying software but truly in practice",
    "start": "372840",
    "end": "378919"
  },
  {
    "text": "the sdlc is a in a fast-paced company can often seem like the world's most unpredictable recipe imagine trying to",
    "start": "378919",
    "end": "386160"
  },
  {
    "text": "bake a cake but the ingredients constantly keep changing the oven randomly adjusts its own temperature and",
    "start": "386160",
    "end": "392680"
  },
  {
    "text": "every now and then someone comes in to tell you they actually wanted a pie so the security team has to be embedded in",
    "start": "392680",
    "end": "399000"
  },
  {
    "text": "that cycle to be able to evaluate if a project or a feature that is being developed needs a human Security review",
    "start": "399000",
    "end": "405800"
  },
  {
    "text": "but one of the biggest problems that the security teams face today is having very limited human",
    "start": "405800",
    "end": "411560"
  },
  {
    "text": "bandwidth it's like playing wacko but if you miss the mole steals your data and sells it on the dark web so for that",
    "start": "411560",
    "end": "418800"
  },
  {
    "text": "reason we developed the stlc bot a slack bot that uses llms to help us with",
    "start": "418800",
    "end": "423879"
  },
  {
    "text": "prioritizing which projects or features we as a security team need to assess first and we're open sourcing this so",
    "start": "423879",
    "end": "431160"
  },
  {
    "text": "here's how it works it asks the user some basic security questions about the project uh that part is optional by the",
    "start": "431160",
    "end": "437199"
  },
  {
    "text": "way it SCS and monitors important threads on slack and it analyzes design",
    "start": "437199",
    "end": "442840"
  },
  {
    "text": "documents relevant to the project so then with the help of the llm uh it it gives you a risk rating and a confidence",
    "start": "442840",
    "end": "449560"
  },
  {
    "text": "level based on the above context let's see how this works in practice so here's an initial design",
    "start": "449560",
    "end": "456319"
  },
  {
    "text": "document for the inventory tracking system you don't have to read this this is a very Bower play design document",
    "start": "456319",
    "end": "461560"
  },
  {
    "text": "that goes through some basic architectural decision about the project uh so let's take a look at the important",
    "start": "461560",
    "end": "467199"
  },
  {
    "text": "note that developers have left us there it says the system will be accessible from the company's VPN only and will not",
    "start": "467199",
    "end": "473319"
  },
  {
    "text": "be exposed to the to the Internet so uh now let's tell our sdlc B about this",
    "start": "473319",
    "end": "479199"
  },
  {
    "text": "product project I'm going to type in some very basic information about the project uh a quick description link to",
    "start": "479199",
    "end": "484879"
  },
  {
    "text": "the design document specify a point of contact and go to live date uh and we",
    "start": "484879",
    "end": "490280"
  },
  {
    "text": "also uh by the way as I said we have versions of the board that skip this uh additional questions so after analyzing",
    "start": "490280",
    "end": "498000"
  },
  {
    "text": "uh all of this context the model will now take its final decision and give us a uh a a risk score and a confidence",
    "start": "498000",
    "end": "505280"
  },
  {
    "text": "score So based on the above you can see that the sdlc there uh decided this is",
    "start": "505280",
    "end": "510720"
  },
  {
    "text": "like a medium risk um uh kind of medium risk uh score uh now in our story the",
    "start": "510720",
    "end": "517680"
  },
  {
    "text": "deadline is approaching fast and our Engineers decide that there's no time to create private links uh for all the",
    "start": "517680",
    "end": "522959"
  },
  {
    "text": "cloud components so that they can uh reside within the VPN so but someone updates the document and this",
    "start": "522959",
    "end": "530160"
  },
  {
    "text": "fundamental change will be detected by our stlc bot and then the llm will now make a new decision based on the updated",
    "start": "530160",
    "end": "537600"
  },
  {
    "text": "context so the the new decision will say that okay this is this increases the risk of the",
    "start": "537600",
    "end": "543240"
  },
  {
    "text": "project um and for if this is not visible um let's reiterate with the next",
    "start": "543240",
    "end": "551800"
  },
  {
    "text": "slide so this shows this in a bigger font the model increased the risk score after the engineering team's uh decision",
    "start": "551800",
    "end": "558600"
  },
  {
    "text": "to allow internet access so it went from a medium risk score of say four to a medium high risk uh of",
    "start": "558600",
    "end": "566640"
  },
  {
    "text": "seven uh and so some of the things we learned uh the model sometimes overfits on the",
    "start": "566640",
    "end": "572440"
  },
  {
    "text": "initial qu questions so if you prompted with some starting security questions as examples the model will not go too far",
    "start": "572440",
    "end": "579000"
  },
  {
    "text": "away from those examples so it will ask uh it will usually ask some context",
    "start": "579000",
    "end": "584279"
  },
  {
    "text": "based ones uh but it will overfit uh sometimes uh regarding prompt",
    "start": "584279",
    "end": "590000"
  },
  {
    "text": "engineering uh this is probably the most important lesson we we learned the more you tell the B that they are an expert",
    "start": "590000",
    "end": "595920"
  },
  {
    "text": "in the field the better the responses are so it will give you better responses if you tell it they're an expert cyber",
    "start": "595920",
    "end": "602360"
  },
  {
    "text": "security engineer versus an average one so praise your models is the the the",
    "start": "602360",
    "end": "607560"
  },
  {
    "text": "lesson here uh we also learned uh notied that the model gives us better results",
    "start": "607560",
    "end": "612600"
  },
  {
    "text": "if when asked to Output scores uh and numbers instead of words so in a previous version like the original",
    "start": "612600",
    "end": "619320"
  },
  {
    "text": "version of the sdlc bat we were asking it to answer in just a sentence format but when we asked it to give us",
    "start": "619320",
    "end": "625839"
  },
  {
    "text": "confidence and resoures the responses were of higher quality we've also developed an extension to the",
    "start": "625839",
    "end": "632360"
  },
  {
    "text": "sdlc board so a better version of this is when it's enhanced with being able to monitor a slack channel on its own and",
    "start": "632360",
    "end": "638600"
  },
  {
    "text": "automatically find the topics of Interest so that way it has less user friction since it doesn't need to ask",
    "start": "638600",
    "end": "644360"
  },
  {
    "text": "the developers any questions we made an internal version of that and here's how it works so uh here what will happen is",
    "start": "644360",
    "end": "651360"
  },
  {
    "text": "that um the there is a discussion on slack about the architecture of uh the",
    "start": "651360",
    "end": "657480"
  },
  {
    "text": "wo speak inventory app and some mentions that HR sent a request to include an",
    "start": "657480",
    "end": "662560"
  },
  {
    "text": "admin account that doesn't have uh MFA anyway yeah the sdlc bo with the help of",
    "start": "662560",
    "end": "668200"
  },
  {
    "text": "the model realized that this is something that should be further review and notifies my user about it so let's",
    "start": "668200",
    "end": "675040"
  },
  {
    "text": "see this about in practice um one of our application Engineers who is new to the",
    "start": "675040",
    "end": "680360"
  },
  {
    "text": "team has was recently locked out of their computer so they ask on the security help slack Channel what they",
    "start": "680360",
    "end": "685959"
  },
  {
    "text": "should do the bot will respond that this is something that I can help with um",
    "start": "685959",
    "end": "691440"
  },
  {
    "text": "there's also some app Engineers working on the new inventory app that they need to deploy it service on the cloud",
    "start": "691440",
    "end": "697519"
  },
  {
    "text": "infrastructure and they need elevated permissions to do that so our Trias B automatically responds for them to go to",
    "start": "697519",
    "end": "704000"
  },
  {
    "text": "um ghost L access which is our llm driven access management system so uh now let's see the new",
    "start": "704000",
    "end": "711000"
  },
  {
    "text": "feature our team developed uh so where the board also has context of a slack history of the channel and can respond",
    "start": "711000",
    "end": "717480"
  },
  {
    "text": "in more detail about user's questions based on how a similar issue was resolved in the past uh This is Not By",
    "start": "717480",
    "end": "723720"
  },
  {
    "text": "the way in the open source version because we didn't have a good way to publish this the user asks about a specific storage container credential",
    "start": "723720",
    "end": "730279"
  },
  {
    "text": "error that occurred when trying to access another storage container uh so here the boot not only does it suggest",
    "start": "730279",
    "end": "737040"
  },
  {
    "text": "to the user that they should use access manager but also they offer another suggestion which is to restart the local",
    "start": "737040",
    "end": "744600"
  },
  {
    "text": "DNS service this is based on the context of slack history and it seems to have have been a step to debug and resolve a",
    "start": "744600",
    "end": "751839"
  },
  {
    "text": "similar issue in the past speaking of access management we developed another tool to help us with",
    "start": "751839",
    "end": "757480"
  },
  {
    "text": "this access manager helps users automatically find the right permissions without them having to know the name or",
    "start": "757480",
    "end": "763680"
  },
  {
    "text": "details about the access group so uh it works with available group descriptions and metadata to find good conceptual uh",
    "start": "763680",
    "end": "771120"
  },
  {
    "text": "matches and explain them to the user if they didn't use matching keywords in their query uh this is something that we",
    "start": "771120",
    "end": "777720"
  },
  {
    "text": "uh expect to open source at the future date so here our engineer tries to list the Contex of the Azure storage",
    "start": "777720",
    "end": "784160"
  },
  {
    "text": "container named WP they get an error because they don't have access to that account and then they use the access",
    "start": "784160",
    "end": "789800"
  },
  {
    "text": "manager CLI to ask what's wrong so the access manager with a help of model suggests the group name to which the",
    "start": "789800",
    "end": "796160"
  },
  {
    "text": "user uh should belong to in order to get access to that storage account and then even offers to send the access request",
    "start": "796160",
    "end": "804199"
  },
  {
    "text": "on behalf of the user uh now the manager of that engineer uh when they see that",
    "start": "804199",
    "end": "809480"
  },
  {
    "text": "pending request for that um for that group they can click approve they can do",
    "start": "809480",
    "end": "814680"
  },
  {
    "text": "that on slack and then the engineer will be granted uh access to that storeage account this is how the workflow works",
    "start": "814680",
    "end": "822240"
  },
  {
    "text": "here and then um when the request is approved uh when the user will U again",
    "start": "822240",
    "end": "829480"
  },
  {
    "text": "run the uh the the storage access Tool uh the engineer will be able to list the",
    "start": "829480",
    "end": "835120"
  },
  {
    "text": "contents there as you see and verifies they have access to the account and the access granting will be logged uh",
    "start": "835120",
    "end": "840639"
  },
  {
    "text": "creating an audit Trail for the uh for the access request and finally the",
    "start": "840639",
    "end": "846160"
  },
  {
    "text": "access can be set to expire after a certain time and there's more uh our team has also experimented with Dynamic",
    "start": "846160",
    "end": "852759"
  },
  {
    "text": "authorization where the decision of granting access is based on a number of factors including user context uh such",
    "start": "852759",
    "end": "859680"
  },
  {
    "text": "as the location time or device or even the job role resource context uh for example the sensitivity of the accessed",
    "start": "859680",
    "end": "866360"
  },
  {
    "text": "uh resource and even environmental context for examp example the network conditions so if you compare a typical",
    "start": "866360",
    "end": "871959"
  },
  {
    "text": "researchers access patterns versus like a security Engineers they will be quite different so this graph is showing the",
    "start": "871959",
    "end": "879279"
  },
  {
    "text": "cosign similarity between the access patterns from an infrastructure engineer and a security engineer you can see that",
    "start": "879279",
    "end": "885160"
  },
  {
    "text": "the groups the access on a daily basis are quite different so meaning that the request for a group outside the normal",
    "start": "885160",
    "end": "890639"
  },
  {
    "text": "patterns should probably trigger more scrutiny on the other hand requests that look similar to regular access may be uh",
    "start": "890639",
    "end": "897600"
  },
  {
    "text": "able to automatically Grant it without further approval so another place we've used the",
    "start": "897600",
    "end": "903279"
  },
  {
    "text": "model to is to help us with triaging security reports you can use it for bug Bounty security disclosure email aliases",
    "start": "903279",
    "end": "909639"
  },
  {
    "text": "even internal findings the key thing is that not only can It help evaluate the reports it can also help make those",
    "start": "909639",
    "end": "914839"
  },
  {
    "text": "reports better and more actionable for your team so back in April we launched our bug Bounty it got a lot of attention",
    "start": "914839",
    "end": "921959"
  },
  {
    "text": "uh this is not a reasonable volume of reports for humans to triage if you can't see that Top Line we were getting",
    "start": "921959",
    "end": "927360"
  },
  {
    "text": "over 900 reports a day our first week of the program shout out to our partners at bug crowd who threw a bunch of humans at",
    "start": "927360",
    "end": "933600"
  },
  {
    "text": "this to help us get the volume down but this is not a reasonable thing for normal humans to be dealing with on a",
    "start": "933600",
    "end": "938920"
  },
  {
    "text": "regular basis here are our stats at the end of that first week we fixed 32 real issues had seven accepted Open tickets",
    "start": "938920",
    "end": "945920"
  },
  {
    "text": "we hadn't gotten to yet and enclosed nearly 3,500 tickets as invalid so that's a lot of inval not applicable",
    "start": "945920",
    "end": "952759"
  },
  {
    "text": "reports for one reason or another so as you may expect given the topic we turn to a model to help us rather than trying",
    "start": "952759",
    "end": "959279"
  },
  {
    "text": "to get the model to try to figure out whether a security report was valid we started with the lower hanging fruit",
    "start": "959279",
    "end": "964399"
  },
  {
    "text": "rejecting some reports that were not appropriate for a bug Bounty and sorting",
    "start": "964399",
    "end": "969440"
  },
  {
    "text": "them into different categories you start with model safety and correctness you ask the model is",
    "start": "969440",
    "end": "975880"
  },
  {
    "text": "this a report or a complaint about something related to model safety uh is it a complaint about the answers the",
    "start": "975880",
    "end": "981759"
  },
  {
    "text": "model is giving harmful factually incorrect if so we've got a separate ingestion mechanism for that type of",
    "start": "981759",
    "end": "987199"
  },
  {
    "text": "reports we want to make those improvements in get that data but the bug pounding program is the wrong place to handle them the second category is",
    "start": "987199",
    "end": "994440"
  },
  {
    "text": "this actually a request for customer service does the reporter have a question about the product is there a problem with payment subscription or",
    "start": "994440",
    "end": "1001079"
  },
  {
    "text": "refund is it a report about a functional bug without any obvious security impact if so we send them to our customer",
    "start": "1001079",
    "end": "1007040"
  },
  {
    "text": "support team and then out of scope bug reports that are out of scope this one is harder to get right because it does",
    "start": "1007040",
    "end": "1013839"
  },
  {
    "text": "require the model to make some judgments about the category of a security security report Falls on",
    "start": "1013839",
    "end": "1019800"
  },
  {
    "text": "this is our this uses our technical out of scope list and we try to keep the list in the model in sync with what's",
    "start": "1019800",
    "end": "1026160"
  },
  {
    "text": "actually in scope out of scope in our out of scope section in the bug Bounty if the model precisely",
    "start": "1026160",
    "end": "1032720"
  },
  {
    "text": "understands what our out of scope list means to it hopefully also bug bounty hunters will precisely understand what's",
    "start": "1032720",
    "end": "1038160"
  },
  {
    "text": "out of scope this doesn't always work for the bug bounty hunters but we hope they read um this is for things like uh",
    "start": "1038160",
    "end": "1044678"
  },
  {
    "text": "reports of missing server headers missing SPF records for emails that don't send don't send email domains that",
    "start": "1044679",
    "end": "1051200"
  },
  {
    "text": "don't send email server error messages version strings you know the usual things that are out of scope for a",
    "start": "1051200",
    "end": "1056320"
  },
  {
    "text": "program and then the final final category we ask is does this actually seem to be a legitimate security report",
    "start": "1056320",
    "end": "1062679"
  },
  {
    "text": "if it doesn't fall into any of the earlier categories it should be in this one so you've got things like SS xss",
    "start": "1062679",
    "end": "1067960"
  },
  {
    "text": "csrf subdomain takeovers all the other security issues reports in this category don't get an autor response and instead",
    "start": "1067960",
    "end": "1074919"
  },
  {
    "text": "go to our human triage team directly and of course there's also some anti prompt injection work here but we're not going",
    "start": "1074919",
    "end": "1080600"
  },
  {
    "text": "to worry about that for right now and it turns out that it's not a big deal for this use case since we're not making payment decisions and we're not having",
    "start": "1080600",
    "end": "1087080"
  },
  {
    "text": "the model right responses it's just making sure that users who report an issue in the wrong place get sent to the",
    "start": "1087080",
    "end": "1092440"
  },
  {
    "text": "right place using our pre-written messages the worst you can do is get your triage ticketed into a uh triage",
    "start": "1092440",
    "end": "1099039"
  },
  {
    "text": "moved into a rejected bucket which honestly if you do that to yourself that's kind of on you um so how do we figure out if we're",
    "start": "1099039",
    "end": "1106280"
  },
  {
    "text": "getting good results you can't just write a prompt and Hope does the right thing you need data to show that you're making the problem better and you're not",
    "start": "1106280",
    "end": "1113159"
  },
  {
    "text": "making your prompt worse but evales are surprisingly often all you need so how",
    "start": "1113159",
    "end": "1118280"
  },
  {
    "text": "do evals work you set up a set of questions with known good answers and",
    "start": "1118280",
    "end": "1124360"
  },
  {
    "text": "you ask the mo ask your model using your prompt you know run the question through",
    "start": "1124360",
    "end": "1129960"
  },
  {
    "text": "and the model gives you an answer the sky is blue um then what you do is you take the",
    "start": "1129960",
    "end": "1136159"
  },
  {
    "text": "quest the known good answers and the models an and you ask the model again is the answer the model gave correct and it",
    "start": "1136159",
    "end": "1143480"
  },
  {
    "text": "will tell you yes the answer is correct and you can use this to build a system where the Model judges itself to figure",
    "start": "1143480",
    "end": "1148880"
  },
  {
    "text": "out whether or not you've gotten these right and you can do this repeatedly as you tweak the prompt to get it to make",
    "start": "1148880",
    "end": "1154960"
  },
  {
    "text": "it better you can see when you've made it worse too so practically how do we double check our work for this at first",
    "start": "1154960",
    "end": "1161720"
  },
  {
    "text": "so I exported a CSV of the first couple thousand reports I ran through them and hand sorted them into the different",
    "start": "1161720",
    "end": "1166760"
  },
  {
    "text": "categories and then we ran the model on on it um this is another one you don't need to read in detail it's here to help",
    "start": "1166760",
    "end": "1173039"
  },
  {
    "text": "you look at the columns you can see my human judgment in the middle left the model's judgment in the middle right as",
    "start": "1173039",
    "end": "1178919"
  },
  {
    "text": "well as its explanation of why it made the decision doing it in a spreadsheet is really fast it's easy it's a low",
    "start": "1178919",
    "end": "1184200"
  },
  {
    "text": "impact it's a great way to get answers about what you're doing quickly by all means use the fancier tools but start",
    "start": "1184200",
    "end": "1189559"
  },
  {
    "text": "with the easy ones so taking it further there's a bunch of other data points you can analyze too in your program you can",
    "start": "1189559",
    "end": "1195919"
  },
  {
    "text": "look at commentary on historical tickets to help you detect whether the bot or humans made a initial triage error you",
    "start": "1195919",
    "end": "1202120"
  },
  {
    "text": "can use the model to help detect human mistakes going forward as well but of course the key thing for keeping is",
    "start": "1202120",
    "end": "1208159"
  },
  {
    "text": "keeping this all fair if someone disputes the model's autoc close reason a human always reviews it always make",
    "start": "1208159",
    "end": "1214400"
  },
  {
    "text": "sure there are humans in the loop when you do this the model isn't infallible and if someone ask for a second look to",
    "start": "1214400",
    "end": "1220240"
  },
  {
    "text": "do it they deserve it so these the next two things are things we've experimented with but we haven't actually deployed",
    "start": "1220240",
    "end": "1226559"
  },
  {
    "text": "yet report quality is one of the recur ing challenges with any bug Bounty program reporters are in a hurry they",
    "start": "1226559",
    "end": "1233000"
  },
  {
    "text": "assume you're psychic and often do not submit enough information to triage their bugs the model can help reporter",
    "start": "1233000",
    "end": "1238919"
  },
  {
    "text": "make sure that you have all the information you need for instance you reported about product X we need a full",
    "start": "1238919",
    "end": "1244200"
  },
  {
    "text": "URL to debug that you reported why but we need your email address to go look that up hey it looks like you submitted",
    "start": "1244200",
    "end": "1249760"
  },
  {
    "text": "a template without changing much can you go back and give us more detail and your own words these are all really common",
    "start": "1249760",
    "end": "1255280"
  },
  {
    "text": "mistakes that reports include and we can also use it to help triage focus on the",
    "start": "1255280",
    "end": "1260440"
  },
  {
    "text": "important stuff bug bny reports are sometimes worse than internet recipe sites and the reporters often confused",
    "start": "1260440",
    "end": "1266120"
  },
  {
    "text": "using lots of words with having an important bug waiting through that is exhausting so the model can help do",
    "start": "1266120",
    "end": "1271440"
  },
  {
    "text": "things like automatically fix categorization summarize the key points of a report extract reproduction steps",
    "start": "1271440",
    "end": "1277919"
  },
  {
    "text": "provide suggestions for clarifying questions and it can even be used to push common reports into other types of",
    "start": "1277919",
    "end": "1283559"
  },
  {
    "text": "tool cues for example subdomain takeovers can often be tested and resolved almost entirely automatically",
    "start": "1283559",
    "end": "1289720"
  },
  {
    "text": "so let's take a look at a typical interaction with our bot here so we've got a report pretty typical why did you",
    "start": "1289720",
    "end": "1295520"
  },
  {
    "text": "give Dave's chicken two stars I think your moderation is wrong you should have given me at least four well we're not",
    "start": "1295520",
    "end": "1300919"
  },
  {
    "text": "really in the business of selling chicken exactly and even if we were this isn't a security issue so the reporter",
    "start": "1300919",
    "end": "1306039"
  },
  {
    "text": "gets back our nice polite bot response that says this isn't the right place to report it we're not having write the bot",
    "start": "1306039",
    "end": "1311919"
  },
  {
    "text": "write these responses individually it's selecting from the appropriate pre-written ones with our carefully vetted responses",
    "start": "1311919",
    "end": "1319960"
  },
  {
    "text": "right so another interesting use case is using the models to help find and catch",
    "start": "1319960",
    "end": "1325320"
  },
  {
    "text": "attackers so llms are consistently decent at finding the needle in the Hast stock while humans can be sometimes",
    "start": "1325320",
    "end": "1332320"
  },
  {
    "text": "unreliable they miss data they get tired and they make mistakes so logs uh are",
    "start": "1332320",
    "end": "1337679"
  },
  {
    "text": "often also really long noisy and frankly quite boring to go through so let's see an example of uh",
    "start": "1337679",
    "end": "1345000"
  },
  {
    "text": "log analysis uh we gave the model the following prom so summarize the session",
    "start": "1345000",
    "end": "1350600"
  },
  {
    "text": "uh transcript and decide if this activity warrants alerting uh security so look for reverse shells looking for",
    "start": "1350600",
    "end": "1356799"
  },
  {
    "text": "secretes and so on um and here's a very small subset of a user's uh bash history",
    "start": "1356799",
    "end": "1362039"
  },
  {
    "text": "bash history can be long and boring you don't have to read this but halfway through through the user invokes a pearl one liner that basically pops aeveral",
    "start": "1362039",
    "end": "1369799"
  },
  {
    "text": "back to a C2 uh the model is pretty good at identifying this the response from",
    "start": "1369799",
    "end": "1375880"
  },
  {
    "text": "the model was okay we should Alert security because a malicious reverse shell command uh was run in the middle",
    "start": "1375880",
    "end": "1381679"
  },
  {
    "text": "of the session so the first DNR use case for llms is to accelerating uh to",
    "start": "1381679",
    "end": "1387720"
  },
  {
    "text": "accelerate long and boring log analysis the second part is to augment and accelerate incident response so to help",
    "start": "1387720",
    "end": "1395320"
  },
  {
    "text": "our defense team with the large volume of alerts they have to deal with in their uh daily duties we developed a b",
    "start": "1395320",
    "end": "1401840"
  },
  {
    "text": "that helps with triaging certain types of alerts so the bot ingests alerts from a traditional seam and and uh for a",
    "start": "1401840",
    "end": "1409919"
  },
  {
    "text": "certain subset of them like ones that could be an accidental mistake uh it can start a chat with the user to inform",
    "start": "1409919",
    "end": "1416159"
  },
  {
    "text": "them of the potential problem uh to be clear this B does not do log analysis",
    "start": "1416159",
    "end": "1421279"
  },
  {
    "text": "and it would only cover a small segment of a DNR pipeline uh by the way we're",
    "start": "1421279",
    "end": "1426720"
  },
  {
    "text": "also open sourcing this so an example is the following a user shared a potentially sensitive Google Drive",
    "start": "1426720",
    "end": "1432919"
  },
  {
    "text": "document to the public the bot alerts them about this action and asks them if this was their intention giving them an",
    "start": "1432919",
    "end": "1439039"
  },
  {
    "text": "opportunity to revert their change if it was accidental so and then a notification will be sent to the the uh",
    "start": "1439039",
    "end": "1445440"
  },
  {
    "text": "detection and response backlog so let's see an example of this in practice uh one of the W speak Engineers want to",
    "start": "1445440",
    "end": "1451919"
  },
  {
    "text": "share a document named inventory details with sensitive information about the company with a contractor that signed an",
    "start": "1451919",
    "end": "1458000"
  },
  {
    "text": "NDA the engineer though mistakenly decided to change the sharing settings to public then the alert will be created",
    "start": "1458000",
    "end": "1465279"
  },
  {
    "text": "uh the the alert is created through the traditional detect engineering our incident response bot will inest and",
    "start": "1465279",
    "end": "1471799"
  },
  {
    "text": "notify the DNR team and then the the bot will ask the user if this was",
    "start": "1471799",
    "end": "1476880"
  },
  {
    "text": "intentional like if the user tries to avoid the question by say like something like what is your favorite color the",
    "start": "1476880",
    "end": "1482840"
  },
  {
    "text": "board insists and doesn't mess around with the when the user responds with something then the conversation is",
    "start": "1482840",
    "end": "1488679"
  },
  {
    "text": "summarized and by the models and then is sent back to the DNR team uh for followup so uh and this is how how how",
    "start": "1488679",
    "end": "1497279"
  },
  {
    "text": "it works so this was our final demo let's see what the most important",
    "start": "1497279",
    "end": "1503960"
  },
  {
    "text": "lessons were so some final thoughts the more high quality data you give the model the",
    "start": "1503960",
    "end": "1509600"
  },
  {
    "text": "better it can do but don't just shove everything in there models are better with more context for your environment",
    "start": "1509600",
    "end": "1515760"
  },
  {
    "text": "but that context has to be high quality in high trust environments the model can do more externally you should be more",
    "start": "1515760",
    "end": "1521840"
  },
  {
    "text": "restrained in how you use it because you may get more adversarial input tell your model that it's an expert use EV valves",
    "start": "1521840",
    "end": "1528360"
  },
  {
    "text": "find the right prompts and you'll get much further than just sort of YOLO your prompts and hoping that everything's",
    "start": "1528360",
    "end": "1534159"
  },
  {
    "text": "good yeah and also remember to always have a human in the loop uh models are not infallible and can also make",
    "start": "1534159",
    "end": "1540880"
  },
  {
    "text": "mistakes uh even though they are powerful in augmenting these uh security workflows we have to be mindful that",
    "start": "1540880",
    "end": "1547120"
  },
  {
    "text": "models will not be 100% accurate uh they can hallucinate they can miss things and",
    "start": "1547120",
    "end": "1554279"
  },
  {
    "text": "yeah humans are here to stay uh and finally like this is easier than you think you should go try",
    "start": "1554279",
    "end": "1560960"
  },
  {
    "text": "it um and this is the end of our talk uh we're going to be open sourcing uh",
    "start": "1560960",
    "end": "1567159"
  },
  {
    "text": "allowing access to the repo um sometime today uh and these links will uh let you",
    "start": "1567159",
    "end": "1573919"
  },
  {
    "text": "access them um time for questions [Applause]",
    "start": "1573919",
    "end": "1586140"
  },
  {
    "text": "hey there uh for the implementation of some of this are you to to send some of the context in like you said using",
    "start": "1589039",
    "end": "1596600"
  },
  {
    "text": "fine-tuning for that or are you creating custom models to no this is all off the",
    "start": "1596600",
    "end": "1601799"
  },
  {
    "text": "shelf um we're just handing the model lots of context so you know 32k 128k you",
    "start": "1601799",
    "end": "1607640"
  },
  {
    "text": "can put a lot of context in there for the model just make sure it's high quality if it's distracting you'll make",
    "start": "1607640",
    "end": "1612679"
  },
  {
    "text": "your answers worse yeah you don't have to fine-tune anything this is all like uh off the shelf uh in the The sdlc Bard",
    "start": "1612679",
    "end": "1619120"
  },
  {
    "text": "we also have like an example uh basically a wrapper function that can ask uh any kind of model and not just U",
    "start": "1619120",
    "end": "1626640"
  },
  {
    "text": "our own so you can use that as a kind of um framework to um attach it to anything",
    "start": "1626640",
    "end": "1633080"
  },
  {
    "text": "else so if you were doing larger data analysis on say your seams for example",
    "start": "1633080",
    "end": "1638799"
  },
  {
    "text": "rather than just specific events that you're triggering I mean that would then look at doing fine tuning off the back",
    "start": "1638799",
    "end": "1644919"
  },
  {
    "text": "of that that would be a great place to do fine tuning after okay we wanted to just really so show you can do this",
    "start": "1644919",
    "end": "1650919"
  },
  {
    "text": "without the really complicated stuff works really well awesome thank",
    "start": "1650919",
    "end": "1656000"
  },
  {
    "text": "you uh thanks for the presentation I would like to ask about the uh first use cases where you try to like give scores",
    "start": "1656000",
    "end": "1662360"
  },
  {
    "text": "on different projects based on their either risk assessment or vulnerability assessment y uh I would like to ask like",
    "start": "1662360",
    "end": "1668399"
  },
  {
    "text": "how to evaluate the hallucination in this case since the given score is quite like subjective and also it's quite hard",
    "start": "1668399",
    "end": "1674799"
  },
  {
    "text": "to differentiate or give give like correct labels based on categories Etc",
    "start": "1674799",
    "end": "1679880"
  },
  {
    "text": "have you noticed humans are pretty subjective too I've found that with my teams yeah yeah I mean there's I mean",
    "start": "1679880",
    "end": "1686159"
  },
  {
    "text": "that's why we we uh insist that humans should be in the loop uh these kind of tools can help with some sort of",
    "start": "1686159",
    "end": "1693080"
  },
  {
    "text": "prioritization which is why we've uh created them and why we use them but at the end of the day yeah it's it's not",
    "start": "1693080",
    "end": "1699720"
  },
  {
    "text": "perfect and you're still going to have to do some some manual review there um yeah I think this is the the best way to",
    "start": "1699720",
    "end": "1706840"
  },
  {
    "text": "do it yeah so so to add on this point when you identify the motel doesn't like uh perform as expected so do you like",
    "start": "1706840",
    "end": "1714360"
  },
  {
    "text": "revise the prompts to likejust the performance we use the eval framework and as we go we haven't we don't have it",
    "start": "1714360",
    "end": "1721279"
  },
  {
    "text": "in the bot yet but what we're thinking about is uh adding the ability to track Emoji reacts to help uh help us build a",
    "start": "1721279",
    "end": "1728760"
  },
  {
    "text": "data set of the bot did well or the bot didn't do well and then we can do this to build examples and use that either",
    "start": "1728760",
    "end": "1734720"
  },
  {
    "text": "for evals or fine tuning later yeah so yeah one on on that note what Paul is",
    "start": "1734720",
    "end": "1739919"
  },
  {
    "text": "saying uh we have like some internal versions where uh some of our team members that are working on say for",
    "start": "1739919",
    "end": "1746360"
  },
  {
    "text": "example the tri B they have uh kind of the part of the workflow is that uh when",
    "start": "1746360",
    "end": "1751679"
  },
  {
    "text": "in you know you first uh deploy it so that you see how how well it performs uh",
    "start": "1751679",
    "end": "1756799"
  },
  {
    "text": "it gives you basically uh a manual review process so it's like okay this is",
    "start": "1756799",
    "end": "1762120"
  },
  {
    "text": "the recommended uh response that the the bot would uh would give uh do you do you",
    "start": "1762120",
    "end": "1768080"
  },
  {
    "text": "acknowledge that this is the correct it's good enough and so in the initial stage this I think is kind of an",
    "start": "1768080",
    "end": "1774440"
  },
  {
    "text": "important step because it allows us to evaluate okay like the body is doing well and otherwise we can we can do this",
    "start": "1774440",
    "end": "1781559"
  },
  {
    "text": "sort of like evaluation process where we um you know kind of reconfigure the",
    "start": "1781559",
    "end": "1787480"
  },
  {
    "text": "prompts to be to be better but but this really lets us respect our Engineers Time by not giving them lol nonsense if",
    "start": "1787480",
    "end": "1794399"
  },
  {
    "text": "it is going off the rails yeah perfect thank you so much yep",
    "start": "1794399",
    "end": "1799559"
  },
  {
    "text": "hey guys awesome talk um I have two questions so uh the first one is that um",
    "start": "1799559",
    "end": "1804840"
  },
  {
    "text": "I've done a lot of uh interviews with uh academics in the AI space especially what I call consumer AI which you know",
    "start": "1804840",
    "end": "1811480"
  },
  {
    "text": "could be construed as whatever but um in in some of those interviews especially with people who are in the academic",
    "start": "1811480",
    "end": "1817039"
  },
  {
    "text": "Community there's been a lot of research on the prompt engineering statement of",
    "start": "1817039",
    "end": "1822080"
  },
  {
    "text": "be an expert and people have done whole white papers on benchmarks of does the",
    "start": "1822080",
    "end": "1827720"
  },
  {
    "text": "model act better if you tell it's an expert at cyber security or not now my personal view is that it does I've made",
    "start": "1827720",
    "end": "1832799"
  },
  {
    "text": "many tools like you guys already doing this but uh academics say that it doesn't have any effect on the model",
    "start": "1832799",
    "end": "1838960"
  },
  {
    "text": "have you guys actually benchmarked this or is it just subjective based on your use cases I mean a couple thousand",
    "start": "1838960",
    "end": "1846039"
  },
  {
    "text": "prompts that were hand graded versus you know I I did with the bug boundy I told",
    "start": "1846039",
    "end": "1851080"
  },
  {
    "text": "it that it was an expert triager right and you know it yeah objectively it does better on my task right when I tell it",
    "start": "1851080",
    "end": "1858200"
  },
  {
    "text": "that okay um I mean there may be other ways to get the same output from the model but objectively the numbers are",
    "start": "1858200",
    "end": "1863919"
  },
  {
    "text": "better when I do that okay and then the other thing is that um is when you're working with security Bots uh and you",
    "start": "1863919",
    "end": "1871279"
  },
  {
    "text": "know a lot of other type of bots are you finding that um when you're asking for you know your trios spot to do X Y and Z",
    "start": "1871279",
    "end": "1877679"
  },
  {
    "text": "or whatever are you trying to um lower any configuration settings like temperature or something like that to",
    "start": "1877679",
    "end": "1882840"
  },
  {
    "text": "make sure that it is not too creative in its output in order to give you back technical data yeah yeah I I think that",
    "start": "1882840",
    "end": "1888960"
  },
  {
    "text": "is that is true like you can do a lot of kind of uh calibration there uh but I",
    "start": "1888960",
    "end": "1894200"
  },
  {
    "text": "think yeah kind of lowering the temperature makes a lot of sense um this is part of the kind of again the",
    "start": "1894200",
    "end": "1901000"
  },
  {
    "text": "evaluation kind of process where we we use the the framework we we say okay like these are like you know a thousand",
    "start": "1901000",
    "end": "1908240"
  },
  {
    "text": "response from the model uh what happens if we uh if we change the The Prompt",
    "start": "1908240",
    "end": "1913639"
  },
  {
    "text": "like or if we change the the temperature settings and so on um but yeah it's it's it's kind of",
    "start": "1913639",
    "end": "1921760"
  },
  {
    "text": "interesting to when you use another model to evaluate the model's response that is also something that we found",
    "start": "1921760",
    "end": "1927399"
  },
  {
    "text": "really interesting uh for example we've done that with like the the the slack Bots that we created so it's you can",
    "start": "1927399",
    "end": "1935000"
  },
  {
    "text": "also use uh a second kind of testing process where instead of having a human review how uh good the responses are you",
    "start": "1935000",
    "end": "1943080"
  },
  {
    "text": "also enlist the help of another model to assess these responses and it works",
    "start": "1943080",
    "end": "1948639"
  },
  {
    "text": "quite well the model also that does the evaluation doesn't even have to be as powerful as the model that created the",
    "start": "1948639",
    "end": "1955240"
  },
  {
    "text": "responses which is very interesting very cool thank",
    "start": "1955240",
    "end": "1960080"
  },
  {
    "text": "you hello yeah uh thanks for the really insightful sharing so um if I understand",
    "start": "1960880",
    "end": "1967039"
  },
  {
    "text": "correctly all these tools you are using in context learning right so um when a",
    "start": "1967039",
    "end": "1972799"
  },
  {
    "text": "and a very high traffic comes in uh all of these uh result can be really uh",
    "start": "1972799",
    "end": "1977880"
  },
  {
    "text": "overwhelming as well because all of these false positives so do you see a need in full fine tuning the gbt models",
    "start": "1977880",
    "end": "1985039"
  },
  {
    "text": "for doing uh track detection or in incident response helpers yeah I I think",
    "start": "1985039",
    "end": "1992320"
  },
  {
    "text": "we're going to get there um you know these are we pick these particularly because they're stuff that we have",
    "start": "1992320",
    "end": "1997760"
  },
  {
    "text": "gotten working and are using um but yeah I think I think there's a lot of room",
    "start": "1997760",
    "end": "2003000"
  },
  {
    "text": "for building that kind of thing out in the future yeah we we found that they are uh",
    "start": "2003000",
    "end": "2009600"
  },
  {
    "text": "really good at automating workflows and for mostly defensive applications yeah um and like like we said in the",
    "start": "2009600",
    "end": "2016679"
  },
  {
    "text": "presentation it's like finding the needle in the Hy stock they are decent at doing that I mean and you know you",
    "start": "2016679",
    "end": "2022880"
  },
  {
    "text": "think about a traditional tier one sock analyst who's just looking at alerts all day if the model can help make sure that",
    "start": "2022880",
    "end": "2029000"
  },
  {
    "text": "human is looking at the important ones that's better for everyone involved you don't burn your sock and all it's out as",
    "start": "2029000",
    "end": "2035519"
  },
  {
    "text": "fast yeah okay thank you thank you hi thanks for the presentation cool",
    "start": "2035519",
    "end": "2042760"
  },
  {
    "text": "stuff um it's more of an economical question I guess uh it's about how do",
    "start": "2042760",
    "end": "2049638"
  },
  {
    "text": "you or how did you choose the use cases where you're going to actually throw a",
    "start": "2049639",
    "end": "2055839"
  },
  {
    "text": "you know full-blown llm at when an engineer costs a couple hundred dollars an hour llms are really cheap okay so is",
    "start": "2055839",
    "end": "2062358"
  },
  {
    "text": "that the calculation that you've based this on did you include the factor of actual compute that is spent for some of",
    "start": "2062359",
    "end": "2069599"
  },
  {
    "text": "the relatively simple deterministic problems right such as the say access",
    "start": "2069599",
    "end": "2075358"
  },
  {
    "text": "management one might argue that is a simple task right yeah it's it's the the",
    "start": "2075359",
    "end": "2080800"
  },
  {
    "text": "compute cost is negligible if it if it saves 10 minutes of an engineer's time you've you've had a huge impact dollar",
    "start": "2080800",
    "end": "2087560"
  },
  {
    "text": "for dollar all right cool people are expensive I know and irreplaceable",
    "start": "2087560",
    "end": "2094000"
  },
  {
    "text": "yeah uh thank you for your amazing talk and and uh I I I think your the BS you",
    "start": "2094000",
    "end": "2101040"
  },
  {
    "text": "have built are quite amazing and I think uh uh now now ai models are using the uh",
    "start": "2101040",
    "end": "2110000"
  },
  {
    "text": "vulnerability or security analysis tools uh do you think how can we make these tools more usable for AIS instead of",
    "start": "2110000",
    "end": "2117560"
  },
  {
    "text": "humans because now they are built for uh to to Target the to to maximize the",
    "start": "2117560",
    "end": "2123320"
  },
  {
    "text": "usability for humans but now AIS are using these tools so do you think how can we",
    "start": "2123320",
    "end": "2130200"
  },
  {
    "text": "make a little bit of a long answer but the the very short version of this is",
    "start": "2130200",
    "end": "2135920"
  },
  {
    "text": "you can ask the AI to Define how it would like the tool to behave and look and then you can build the tool the AI",
    "start": "2135920",
    "end": "2141960"
  },
  {
    "text": "defined um and this works really really well if you like sketch out some classes",
    "start": "2141960",
    "end": "2147560"
  },
  {
    "text": "and just give it the types and be like you know what else do you need here and then you have it solve problems with that and you add in what it asks for and",
    "start": "2147560",
    "end": "2154119"
  },
  {
    "text": "you iterate with it back and forth I'll talk to you more about it later um okay but yeah you can totally have the llm",
    "start": "2154119",
    "end": "2160079"
  },
  {
    "text": "tell you what it wants to work with and it works pretty well okay I see thank you okay thanks for your interesting",
    "start": "2160079",
    "end": "2167920"
  },
  {
    "text": "talk so I have noticed that you have designed the prompts to uh complete",
    "start": "2167920",
    "end": "2174240"
  },
  {
    "text": "specific uh tasks in a specific format so do you have any uh suggestions or",
    "start": "2174240",
    "end": "2181359"
  },
  {
    "text": "advice s uh how to design uh specific uh",
    "start": "2181359",
    "end": "2186920"
  },
  {
    "text": "prompts for for uh those security related",
    "start": "2186920",
    "end": "2192280"
  },
  {
    "text": "issues you mean for for can can you elaborate a little bit uh I mean uh do",
    "start": "2192280",
    "end": "2199240"
  },
  {
    "text": "you have any advice on uh how to do a better prompt engine uh engineering for",
    "start": "2199240",
    "end": "2207040"
  },
  {
    "text": "uh security related issue I mean this is again we're we're going to go back to",
    "start": "2207040",
    "end": "2212240"
  },
  {
    "text": "the to the answer of using the evaluation uh framework like uh you",
    "start": "2212240",
    "end": "2217680"
  },
  {
    "text": "basically start with a prompt and then you kind of refine it as you go along and as you uh evaluate uh using this",
    "start": "2217680",
    "end": "2225720"
  },
  {
    "text": "kind of framework okay how how well the responses are uh one thing that you can also do is use an llm to create a prompt",
    "start": "2225720",
    "end": "2233800"
  },
  {
    "text": "for another llm this actually works um also pretty well and if you have the",
    "start": "2233800",
    "end": "2239240"
  },
  {
    "text": "eval data set you can you know say have the L make 10 or 20 prompts figure out",
    "start": "2239240",
    "end": "2244319"
  },
  {
    "text": "which ones are good or if you have the data set have it look at where your data is wrong where it got it wrong and have",
    "start": "2244319",
    "end": "2249960"
  },
  {
    "text": "it make suggestions so it doesn't make that mistake again okay thank you yeah",
    "start": "2249960",
    "end": "2255119"
  },
  {
    "text": "this the the the answer always is like use data and kind of evaluate and don't",
    "start": "2255119",
    "end": "2261560"
  },
  {
    "text": "do it Vibes based do it like with data okay okay thank",
    "start": "2261560",
    "end": "2266680"
  },
  {
    "text": "you yeah you mentioned having humans in the loop how are you collecting data on",
    "start": "2266680",
    "end": "2271760"
  },
  {
    "text": "where those High leverage points are I'm thinking about your sdlc Bot in particular um you have anyone filtering",
    "start": "2271760",
    "end": "2279760"
  },
  {
    "text": "in front of like your bug Bounty platform provider doing pre-t triage then doing postt triage yourself how",
    "start": "2279760",
    "end": "2286160"
  },
  {
    "text": "have you thought about that and what kind of data are you collecting to figure out where those leverage points are you I we're we're starting by having",
    "start": "2286160",
    "end": "2292240"
  },
  {
    "text": "the humans on the security team doing most of the review um as we become more",
    "start": "2292240",
    "end": "2297480"
  },
  {
    "text": "confident and as we find that the answers are consistently reliably good then you know we start backing the",
    "start": "2297480",
    "end": "2303400"
  },
  {
    "text": "humans off a little bit um we haven't haven't gotten to external triager is",
    "start": "2303400",
    "end": "2308560"
  },
  {
    "text": "helping us with that mostly because uh you need a lot of context on our environment to figure out whether the",
    "start": "2308560",
    "end": "2314280"
  },
  {
    "text": "answer is right so um yeah humans right now yeah thanks for taking those hot",
    "start": "2314280",
    "end": "2319880"
  },
  {
    "text": "fresh reports throughout the internet that's that's a tough work yeah uh hi this is duu I work as a",
    "start": "2319880",
    "end": "2327520"
  },
  {
    "text": "security engineer first of all your talk is great I was really Blown Away uh so my doubt is like uh uh there may be a",
    "start": "2327520",
    "end": "2334720"
  },
  {
    "text": "situation where the developers may make a typo While submitting the requirement so is it possible to for llm to train to",
    "start": "2334720",
    "end": "2342880"
  },
  {
    "text": "identify the uh typos which developers make and then Pro give us an input to",
    "start": "2342880",
    "end": "2347920"
  },
  {
    "text": "the slackbot is it possible so the question is if you make a typ of for for what kind of thing uh",
    "start": "2347920",
    "end": "2355040"
  },
  {
    "text": "let's say the developers subit a security requirement and they make a typo in the document uh they mention something like instead of the VPN is",
    "start": "2355040",
    "end": "2362000"
  },
  {
    "text": "internal they make it external so there may be a uh the bot May confuses like",
    "start": "2362000",
    "end": "2367079"
  },
  {
    "text": "the score May go down so is it possible for the llm to detect the typos which developers make uh I you can definitely",
    "start": "2367079",
    "end": "2374240"
  },
  {
    "text": "have the context of the slack Channel inform whether or not the change in the document seems to seems to be in line",
    "start": "2374240",
    "end": "2381000"
  },
  {
    "text": "what we actually usually see is conversation and slack channels are much more up to date than docs right so uh",
    "start": "2381000",
    "end": "2387160"
  },
  {
    "text": "that's sort of where where I think you take the ground truth and you know again the whole point is should I get a human",
    "start": "2387160",
    "end": "2392720"
  },
  {
    "text": "involved and if you get a human involved a little more often than you need to that's okay it's better the opposite so",
    "start": "2392720",
    "end": "2398599"
  },
  {
    "text": "yeah what Paul what Paul is saying I was trying to show in the video when we had like the the demo Gods like being you",
    "start": "2398599",
    "end": "2405160"
  },
  {
    "text": "know angry at us uh but what the the extension to the stlc bo was doing was",
    "start": "2405160",
    "end": "2410880"
  },
  {
    "text": "basically uh when you monitor a specific slack Channel it says okay like this is the conversation that the engineers are",
    "start": "2410880",
    "end": "2417520"
  },
  {
    "text": "having and someone is mentioned that oh like we changed our decision and we have this request from HR to like add this",
    "start": "2417520",
    "end": "2424800"
  },
  {
    "text": "account without multi multiactor Authentication and then the sdlc bot will say okay this",
    "start": "2424800",
    "end": "2430560"
  },
  {
    "text": "is probably something that a security engineer should review because adding an account like that will probably lead to",
    "start": "2430560",
    "end": "2436560"
  },
  {
    "text": "trouble so um yeah and also my second out is it's really cool to see you know",
    "start": "2436560",
    "end": "2442920"
  },
  {
    "text": "the I'm integrate with the the tring the bug Bounty process I'm a Trager as well",
    "start": "2442920",
    "end": "2448319"
  },
  {
    "text": "so why will you open source this today the bug Bing thing is already open",
    "start": "2448319",
    "end": "2453359"
  },
  {
    "text": "source and we will open source the other things we talked about today C it is it fine to integrate with H1 on bug Crow",
    "start": "2453359",
    "end": "2459079"
  },
  {
    "text": "right uh right now it's written for bug Crow because that's who we use it wouldn't be hard to add it for H1 yeah",
    "start": "2459079",
    "end": "2464400"
  },
  {
    "text": "that sounds great and the eval framework is also Open Source by the way uh the to",
    "start": "2464400",
    "end": "2470280"
  },
  {
    "text": "to you know refine the prompts using it that's great once again your talk is really great thank",
    "start": "2470280",
    "end": "2476240"
  },
  {
    "text": "you um hi thank you uh we working on something very similar to the sdlc board this was great validation to see this um",
    "start": "2476240",
    "end": "2482920"
  },
  {
    "text": "so quick question on evaluation um eval Frameworks do you think there's a risk of overit for the first five documents",
    "start": "2482920",
    "end": "2489280"
  },
  {
    "text": "that you kind of scan and then from if if let's say you acquire another company",
    "start": "2489280",
    "end": "2494359"
  },
  {
    "text": "and they write designed documents differently then the odds of uh the accuracy going down is higher how do you",
    "start": "2494359",
    "end": "2499440"
  },
  {
    "text": "kind of account for changing documents and architecture diagram Styles right yeah I mean the the one Technique we",
    "start": "2499440",
    "end": "2505960"
  },
  {
    "text": "used uh for at least the stlb was uh doing a little bit of summarization",
    "start": "2505960",
    "end": "2511160"
  },
  {
    "text": "which by the way is also useful for when uh you don't have enough Contex window",
    "start": "2511160",
    "end": "2516520"
  },
  {
    "text": "right now we have like like big enough context windows but yeah say if you import like I don't know like thousands",
    "start": "2516520",
    "end": "2522319"
  },
  {
    "text": "of documents you're going to need some sort of compression of that information into something that is shorter uh and",
    "start": "2522319",
    "end": "2529359"
  },
  {
    "text": "that helps uh with that kind of thing so that also the the model doesn't overfit in like you know the first or the the",
    "start": "2529359",
    "end": "2536079"
  },
  {
    "text": "last piece of information um just following up on that so you're still focused on summarizing and sending that",
    "start": "2536079",
    "end": "2541160"
  },
  {
    "text": "to open AI as opposed to using like a rag in the vector search to do we use open AI to summarize and then use that",
    "start": "2541160",
    "end": "2546359"
  },
  {
    "text": "summary use summaries to help us pull everything into local context do you think there's a trade-off between doing",
    "start": "2546359",
    "end": "2552800"
  },
  {
    "text": "that versus say embedding that into a vector database and doing a vector search and sending only the yeah I mean",
    "start": "2552800",
    "end": "2558920"
  },
  {
    "text": "you can do both ways both ways are valid we're just using the model and not doing R because we've got enough space got it",
    "start": "2558920",
    "end": "2565640"
  },
  {
    "text": "yeah the the finetuning yeah will will work but it is an additional step that I",
    "start": "2565640",
    "end": "2570960"
  },
  {
    "text": "mean takes takes some some has some complexity all right thank you so much",
    "start": "2570960",
    "end": "2577319"
  },
  {
    "text": "thank you everyone right thank you",
    "start": "2577319",
    "end": "2581920"
  }
]
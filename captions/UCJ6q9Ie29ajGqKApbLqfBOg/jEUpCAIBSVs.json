[
  {
    "start": "0",
    "end": "0"
  },
  {
    "text": "[Music]",
    "start": "1130",
    "end": "14160"
  },
  {
    "text": "hi everyone thank you for joining us",
    "start": "14160",
    "end": "16240"
  },
  {
    "text": "this is can you roll your own sim",
    "start": "16240",
    "end": "18720"
  },
  {
    "text": "i'm ethan crist and i lead the security",
    "start": "18720",
    "end": "20800"
  },
  {
    "text": "identity monitoring and response team at",
    "start": "20800",
    "end": "22880"
  },
  {
    "text": "two sigma investments",
    "start": "22880",
    "end": "26000"
  },
  {
    "text": "i'm brett rubin and i'm a security",
    "start": "26400",
    "end": "28080"
  },
  {
    "text": "engineer at two sigma focusing on our",
    "start": "28080",
    "end": "30000"
  },
  {
    "text": "security event collection and",
    "start": "30000",
    "end": "31279"
  },
  {
    "text": "reliability for security run products",
    "start": "31279",
    "end": "34640"
  },
  {
    "text": "for those who haven't heard of us two",
    "start": "34640",
    "end": "36160"
  },
  {
    "text": "sigma is a financial sciences company",
    "start": "36160",
    "end": "38079"
  },
  {
    "text": "headquartered in new york with over",
    "start": "38079",
    "end": "39600"
  },
  {
    "text": "sixteen hundred employees and a quick",
    "start": "39600",
    "end": "41440"
  },
  {
    "text": "recruiting shout out we're hiring so if",
    "start": "41440",
    "end": "43360"
  },
  {
    "text": "you're interested even after hearing our",
    "start": "43360",
    "end": "44960"
  },
  {
    "text": "talk check out careers.twosigma.com",
    "start": "44960",
    "end": "47840"
  },
  {
    "text": "and now on to the main event",
    "start": "47840",
    "end": "49760"
  },
  {
    "text": "given the maturity of the sim product",
    "start": "49760",
    "end": "51440"
  },
  {
    "text": "space deciding to roll your own may not",
    "start": "51440",
    "end": "53360"
  },
  {
    "text": "strike you as the wisest of ideas let's",
    "start": "53360",
    "end": "55760"
  },
  {
    "text": "dig into why we ended up deciding to do",
    "start": "55760",
    "end": "57520"
  },
  {
    "text": "it anyway and why it was the right",
    "start": "57520",
    "end": "59280"
  },
  {
    "text": "choice for two sigma but first let's see",
    "start": "59280",
    "end": "61760"
  },
  {
    "text": "how quickly i can transition past the",
    "start": "61760",
    "end": "63520"
  },
  {
    "text": "disclaimer slide",
    "start": "63520",
    "end": "66479"
  },
  {
    "text": "we'll start by discussing the high level",
    "start": "66799",
    "end": "68240"
  },
  {
    "text": "considerations that led us down this",
    "start": "68240",
    "end": "69680"
  },
  {
    "text": "path to begin with and then what made",
    "start": "69680",
    "end": "71760"
  },
  {
    "text": "this the right choice for us brett will",
    "start": "71760",
    "end": "73760"
  },
  {
    "text": "lead us through the technical details of",
    "start": "73760",
    "end": "75119"
  },
  {
    "text": "our implementation and give a demo of",
    "start": "75119",
    "end": "76960"
  },
  {
    "text": "the solution then we'll end on the",
    "start": "76960",
    "end": "78960"
  },
  {
    "text": "actual results of this effort and the",
    "start": "78960",
    "end": "80799"
  },
  {
    "text": "broader strategic implications creating",
    "start": "80799",
    "end": "82640"
  },
  {
    "text": "our own sim has had for us",
    "start": "82640",
    "end": "85360"
  },
  {
    "text": "as we first started to think about what",
    "start": "85360",
    "end": "86880"
  },
  {
    "text": "our ideal replacement sim would look",
    "start": "86880",
    "end": "88400"
  },
  {
    "text": "like we went through a requirements",
    "start": "88400",
    "end": "90000"
  },
  {
    "text": "gathering phase",
    "start": "90000",
    "end": "91840"
  },
  {
    "start": "91000",
    "end": "91000"
  },
  {
    "text": "the first thing we looked into was how",
    "start": "91840",
    "end": "93439"
  },
  {
    "text": "much data we needed to ingest per day",
    "start": "93439",
    "end": "95759"
  },
  {
    "text": "the existing license of our on-prem",
    "start": "95759",
    "end": "98159"
  },
  {
    "text": "third-party platform only allowed us to",
    "start": "98159",
    "end": "100240"
  },
  {
    "text": "ingest one terabyte per day and this was",
    "start": "100240",
    "end": "102479"
  },
  {
    "text": "a hard cap",
    "start": "102479",
    "end": "103600"
  },
  {
    "text": "routine overages of this daily rate",
    "start": "103600",
    "end": "105280"
  },
  {
    "text": "would lead to loss of the ability to",
    "start": "105280",
    "end": "106799"
  },
  {
    "text": "search our data which meant we had to be",
    "start": "106799",
    "end": "108880"
  },
  {
    "text": "constantly mindful and diligent of our",
    "start": "108880",
    "end": "110640"
  },
  {
    "text": "daily ingestion amount",
    "start": "110640",
    "end": "112399"
  },
  {
    "text": "this was not a situation we wanted to be",
    "start": "112399",
    "end": "114079"
  },
  {
    "text": "in for the next product given how much",
    "start": "114079",
    "end": "115680"
  },
  {
    "text": "staff time it took to track down and",
    "start": "115680",
    "end": "117439"
  },
  {
    "text": "remediate heavy loggers ideally we would",
    "start": "117439",
    "end": "120079"
  },
  {
    "text": "want a system that wouldn't cap or",
    "start": "120079",
    "end": "121439"
  },
  {
    "text": "restrict us but instead give us the",
    "start": "121439",
    "end": "123280"
  },
  {
    "text": "flexibility to collect more without",
    "start": "123280",
    "end": "125040"
  },
  {
    "text": "paying exponentially more or by having",
    "start": "125040",
    "end": "127200"
  },
  {
    "text": "confiscatory controls around search",
    "start": "127200",
    "end": "129679"
  },
  {
    "text": "our platform's limitations led us to not",
    "start": "129679",
    "end": "132000"
  },
  {
    "text": "ingest certain large data feeds such as",
    "start": "132000",
    "end": "134080"
  },
  {
    "text": "firewall logs that can provide valuable",
    "start": "134080",
    "end": "136239"
  },
  {
    "text": "signal to our security analysts",
    "start": "136239",
    "end": "139040"
  },
  {
    "text": "our next consideration was speed of",
    "start": "139040",
    "end": "140840"
  },
  {
    "text": "ingestion several of our queries feed",
    "start": "140840",
    "end": "143120"
  },
  {
    "text": "downstream actions that have some time",
    "start": "143120",
    "end": "144640"
  },
  {
    "text": "sensitivity one such example was",
    "start": "144640",
    "end": "146800"
  },
  {
    "text": "identifying interactive route logins to",
    "start": "146800",
    "end": "148800"
  },
  {
    "text": "production security systems that didn't",
    "start": "148800",
    "end": "151120"
  },
  {
    "text": "occur via our specifically designed",
    "start": "151120",
    "end": "152879"
  },
  {
    "text": "single purpose management system",
    "start": "152879",
    "end": "155120"
  },
  {
    "text": "we were targeting detection for these",
    "start": "155120",
    "end": "156560"
  },
  {
    "text": "events within 60 seconds of one",
    "start": "156560",
    "end": "158080"
  },
  {
    "text": "happening which means the logs would",
    "start": "158080",
    "end": "159760"
  },
  {
    "text": "need to go from the host in question to",
    "start": "159760",
    "end": "161440"
  },
  {
    "text": "being searchable and firing an alert in",
    "start": "161440",
    "end": "163200"
  },
  {
    "text": "that time",
    "start": "163200",
    "end": "165599"
  },
  {
    "text": "reliability was another key requirement",
    "start": "165680",
    "end": "167920"
  },
  {
    "text": "we rely heavily on our logs for forensic",
    "start": "167920",
    "end": "169760"
  },
  {
    "text": "capabilities during investigations so",
    "start": "169760",
    "end": "171840"
  },
  {
    "text": "ensuring their accuracy and completeness",
    "start": "171840",
    "end": "173440"
  },
  {
    "text": "was critical",
    "start": "173440",
    "end": "174480"
  },
  {
    "text": "we wanted to avoid lossy protocols",
    "start": "174480",
    "end": "176400"
  },
  {
    "text": "wherever possible and be able to",
    "start": "176400",
    "end": "178239"
  },
  {
    "text": "ascertain if all our systems were",
    "start": "178239",
    "end": "179840"
  },
  {
    "text": "shipping expected log volumes",
    "start": "179840",
    "end": "181920"
  },
  {
    "text": "our previous platform did this well via",
    "start": "181920",
    "end": "184159"
  },
  {
    "text": "an agent that would remember logging",
    "start": "184159",
    "end": "185599"
  },
  {
    "text": "state via checkpoints and could load",
    "start": "185599",
    "end": "187440"
  },
  {
    "text": "balance between multiple receiving",
    "start": "187440",
    "end": "188959"
  },
  {
    "text": "servers",
    "start": "188959",
    "end": "189920"
  },
  {
    "text": "the security infrastructure teams along",
    "start": "189920",
    "end": "192080"
  },
  {
    "text": "with several other engineering teams at",
    "start": "192080",
    "end": "193599"
  },
  {
    "text": "two sigma rely on this log data to",
    "start": "193599",
    "end": "195680"
  },
  {
    "text": "troubleshoot outages and issues so it's",
    "start": "195680",
    "end": "197680"
  },
  {
    "text": "important it stays up and running",
    "start": "197680",
    "end": "200319"
  },
  {
    "text": "our logs aren't always standardized to",
    "start": "200319",
    "end": "201920"
  },
  {
    "text": "expected norms custom field editions and",
    "start": "201920",
    "end": "204319"
  },
  {
    "text": "homegrown applications meant we needed",
    "start": "204319",
    "end": "206239"
  },
  {
    "text": "to be able to have flexibility when it",
    "start": "206239",
    "end": "208000"
  },
  {
    "text": "came to data parsing",
    "start": "208000",
    "end": "209599"
  },
  {
    "text": "we didn't want to have to shoehorn our",
    "start": "209599",
    "end": "211599"
  },
  {
    "text": "own data",
    "start": "211599",
    "end": "212400"
  },
  {
    "text": "into pre-defined fields or wrestle with",
    "start": "212400",
    "end": "214319"
  },
  {
    "text": "logging logic that wasn't extensible to",
    "start": "214319",
    "end": "216159"
  },
  {
    "text": "our environment we use a common data",
    "start": "216159",
    "end": "218239"
  },
  {
    "text": "model internally and wanted to adapt our",
    "start": "218239",
    "end": "220159"
  },
  {
    "text": "new sim to that not vice versa",
    "start": "220159",
    "end": "224159"
  },
  {
    "text": "much of our log data is required to be",
    "start": "224959",
    "end": "226640"
  },
  {
    "text": "retained for long periods of time with",
    "start": "226640",
    "end": "228480"
  },
  {
    "text": "some stored indefinitely all of the",
    "start": "228480",
    "end": "230560"
  },
  {
    "text": "storage can add up quickly if you're",
    "start": "230560",
    "end": "231840"
  },
  {
    "text": "paying a third-party provider to host it",
    "start": "231840",
    "end": "233519"
  },
  {
    "text": "and keep it accessible but it's not free",
    "start": "233519",
    "end": "235439"
  },
  {
    "text": "to do this on-prem either",
    "start": "235439",
    "end": "237360"
  },
  {
    "text": "both from the hardware perspective and",
    "start": "237360",
    "end": "238879"
  },
  {
    "text": "from the operational overhead to scale",
    "start": "238879",
    "end": "240560"
  },
  {
    "text": "out large clusters of servers",
    "start": "240560",
    "end": "242720"
  },
  {
    "text": "we also had to factor in sporadic",
    "start": "242720",
    "end": "244400"
  },
  {
    "text": "operational costs for rehydrating log",
    "start": "244400",
    "end": "246239"
  },
  {
    "text": "data that we had moved to long-term",
    "start": "246239",
    "end": "247840"
  },
  {
    "text": "storage in order to keep our current",
    "start": "247840",
    "end": "249599"
  },
  {
    "text": "system performing",
    "start": "249599",
    "end": "251200"
  },
  {
    "text": "and this ties into the next",
    "start": "251200",
    "end": "252400"
  },
  {
    "text": "consideration searchability given the",
    "start": "252400",
    "end": "254560"
  },
  {
    "text": "quantities of data we were retaining our",
    "start": "254560",
    "end": "256560"
  },
  {
    "text": "old platform had a hard time searching",
    "start": "256560",
    "end": "258239"
  },
  {
    "text": "large swaths of historical data",
    "start": "258239",
    "end": "260479"
  },
  {
    "text": "searches that span months i.e looking",
    "start": "260479",
    "end": "262560"
  },
  {
    "text": "through a year's worth of proxy logs to",
    "start": "262560",
    "end": "264400"
  },
  {
    "text": "see if there were any web requests sent",
    "start": "264400",
    "end": "266000"
  },
  {
    "text": "to an ioc could take dozens of minutes",
    "start": "266000",
    "end": "268240"
  },
  {
    "text": "to run",
    "start": "268240",
    "end": "269199"
  },
  {
    "text": "this delay could be further compounded",
    "start": "269199",
    "end": "270880"
  },
  {
    "text": "if part of the search's date range had",
    "start": "270880",
    "end": "272400"
  },
  {
    "text": "been sent to a frozen archive and needed",
    "start": "272400",
    "end": "274479"
  },
  {
    "text": "to be activated again",
    "start": "274479",
    "end": "276479"
  },
  {
    "text": "we wanted to make searching as fast as",
    "start": "276479",
    "end": "278000"
  },
  {
    "text": "possible to improve our incident",
    "start": "278000",
    "end": "279280"
  },
  {
    "text": "responders user experience the other",
    "start": "279280",
    "end": "281520"
  },
  {
    "text": "half of search ability that we were",
    "start": "281520",
    "end": "282880"
  },
  {
    "text": "concerned with was how friendly the",
    "start": "282880",
    "end": "284560"
  },
  {
    "text": "query language was we were eager not to",
    "start": "284560",
    "end": "286800"
  },
  {
    "text": "have to train our users on a proprietary",
    "start": "286800",
    "end": "288720"
  },
  {
    "text": "syntax to use the platform while we",
    "start": "288720",
    "end": "290960"
  },
  {
    "text": "could have improved the performance of",
    "start": "290960",
    "end": "292160"
  },
  {
    "text": "our on-prem solution by tossing more",
    "start": "292160",
    "end": "293759"
  },
  {
    "text": "hardware at it this was quickly becoming",
    "start": "293759",
    "end": "295680"
  },
  {
    "text": "costly",
    "start": "295680",
    "end": "298160"
  },
  {
    "text": "working in security and being at a",
    "start": "298160",
    "end": "299840"
  },
  {
    "text": "security conference this next",
    "start": "299840",
    "end": "301199"
  },
  {
    "text": "requirement might might seem obvious but",
    "start": "301199",
    "end": "303600"
  },
  {
    "text": "we needed to make sure the sensitive",
    "start": "303600",
    "end": "304960"
  },
  {
    "text": "data we were logging was secure we had",
    "start": "304960",
    "end": "307280"
  },
  {
    "text": "to protect it not only from the outside",
    "start": "307280",
    "end": "308960"
  },
  {
    "text": "world but also the vendor hosting our",
    "start": "308960",
    "end": "310960"
  },
  {
    "text": "platform who could use administrative",
    "start": "310960",
    "end": "312479"
  },
  {
    "text": "root privileges to access it and between",
    "start": "312479",
    "end": "314800"
  },
  {
    "text": "teams inside two sigma as well who may",
    "start": "314800",
    "end": "316880"
  },
  {
    "text": "not be authorized to access other teams",
    "start": "316880",
    "end": "318479"
  },
  {
    "text": "data",
    "start": "318479",
    "end": "319600"
  },
  {
    "text": "and lastly since we rely on these logs",
    "start": "319600",
    "end": "321520"
  },
  {
    "text": "for forensic evidence during",
    "start": "321520",
    "end": "322840"
  },
  {
    "text": "investigations we have to ensure our",
    "start": "322840",
    "end": "324880"
  },
  {
    "text": "logs are resistant to tampering",
    "start": "324880",
    "end": "327280"
  },
  {
    "text": "our last requirement was the need to",
    "start": "327280",
    "end": "328880"
  },
  {
    "text": "generate alerts from our queries and",
    "start": "328880",
    "end": "330320"
  },
  {
    "text": "scheduled searches as i previously",
    "start": "330320",
    "end": "332160"
  },
  {
    "text": "mentioned speed is important here as",
    "start": "332160",
    "end": "333520"
  },
  {
    "text": "well especially in cases where we want",
    "start": "333520",
    "end": "335280"
  },
  {
    "text": "to take automated actions our alert",
    "start": "335280",
    "end": "337600"
  },
  {
    "text": "paths touch a variety of downstream",
    "start": "337600",
    "end": "339199"
  },
  {
    "text": "sources so the sim has to be extensible",
    "start": "339199",
    "end": "341440"
  },
  {
    "text": "to support multiple platforms including",
    "start": "341440",
    "end": "343360"
  },
  {
    "text": "email pagerduty jira and the like",
    "start": "343360",
    "end": "347600"
  },
  {
    "text": "one thing we didn't include in our",
    "start": "347600",
    "end": "349039"
  },
  {
    "text": "requirement list was pre-canned queries",
    "start": "349039",
    "end": "351440"
  },
  {
    "text": "our environment is fairly bespoke and so",
    "start": "351440",
    "end": "353360"
  },
  {
    "text": "most out-of-the-box queries from vendors",
    "start": "353360",
    "end": "355199"
  },
  {
    "text": "require substantial tweaking to provide",
    "start": "355199",
    "end": "356960"
  },
  {
    "text": "any value for us since we knew from the",
    "start": "356960",
    "end": "359199"
  },
  {
    "text": "onset that we need to re that we need to",
    "start": "359199",
    "end": "361039"
  },
  {
    "text": "rewrite our alerts to work in whatever",
    "start": "361039",
    "end": "362960"
  },
  {
    "text": "platform we were moving to we didn't",
    "start": "362960",
    "end": "364800"
  },
  {
    "text": "factor any pre-canned alert offerings",
    "start": "364800",
    "end": "366560"
  },
  {
    "text": "into our decision process",
    "start": "366560",
    "end": "368960"
  },
  {
    "text": "another omission was data parsers for a",
    "start": "368960",
    "end": "370880"
  },
  {
    "text": "similar reason",
    "start": "370880",
    "end": "372400"
  },
  {
    "text": "many of the data feeds our security team",
    "start": "372400",
    "end": "374080"
  },
  {
    "text": "is interested in ingesting either had",
    "start": "374080",
    "end": "376160"
  },
  {
    "text": "custom configured log formats or were",
    "start": "376160",
    "end": "378160"
  },
  {
    "text": "from internally developed applications",
    "start": "378160",
    "end": "380080"
  },
  {
    "text": "that didn't conform to a normal standard",
    "start": "380080",
    "end": "382319"
  },
  {
    "text": "as we'll explore further in the next",
    "start": "382319",
    "end": "383840"
  },
  {
    "text": "section this is one of the decision",
    "start": "383840",
    "end": "385520"
  },
  {
    "text": "factors that may be starkly different",
    "start": "385520",
    "end": "387120"
  },
  {
    "text": "for us than for other companies",
    "start": "387120",
    "end": "390319"
  },
  {
    "start": "390000",
    "end": "390000"
  },
  {
    "text": "the final consideration was our threat",
    "start": "390319",
    "end": "391919"
  },
  {
    "text": "model two sigma doesn't run",
    "start": "391919",
    "end": "393520"
  },
  {
    "text": "internet-facing web apps or the like so",
    "start": "393520",
    "end": "395360"
  },
  {
    "text": "our external and perimeter detection",
    "start": "395360",
    "end": "397039"
  },
  {
    "text": "efforts are more narrowly focused the",
    "start": "397039",
    "end": "398960"
  },
  {
    "text": "majority of our threat modeling work",
    "start": "398960",
    "end": "400479"
  },
  {
    "text": "goes into insider risk which given our",
    "start": "400479",
    "end": "402479"
  },
  {
    "text": "largely customized environment is unique",
    "start": "402479",
    "end": "404560"
  },
  {
    "text": "to us most vendor software we looked at",
    "start": "404560",
    "end": "406800"
  },
  {
    "text": "was highly targeted towards external",
    "start": "406800",
    "end": "408319"
  },
  {
    "text": "threats and would have required",
    "start": "408319",
    "end": "409680"
  },
  {
    "text": "substantial uplift to cover our threat",
    "start": "409680",
    "end": "411360"
  },
  {
    "text": "model",
    "start": "411360",
    "end": "413680"
  },
  {
    "text": "so",
    "start": "413680",
    "end": "414479"
  },
  {
    "text": "with those requirements established how",
    "start": "414479",
    "end": "416319"
  },
  {
    "text": "did we wind up at our final decision to",
    "start": "416319",
    "end": "418080"
  },
  {
    "text": "roll our own sim",
    "start": "418080",
    "end": "420400"
  },
  {
    "start": "419000",
    "end": "419000"
  },
  {
    "text": "the first factor we considered was cost",
    "start": "420400",
    "end": "422080"
  },
  {
    "text": "to see if this was a non-starter we",
    "start": "422080",
    "end": "424000"
  },
  {
    "text": "broke it down into several sections and",
    "start": "424000",
    "end": "425520"
  },
  {
    "text": "the first is licensing we'd already",
    "start": "425520",
    "end": "427440"
  },
  {
    "text": "spent a million dollars in the license",
    "start": "427440",
    "end": "428880"
  },
  {
    "text": "for our third-party on-prem sim product",
    "start": "428880",
    "end": "431199"
  },
  {
    "text": "so moving away wasn't free if you don't",
    "start": "431199",
    "end": "433120"
  },
  {
    "text": "believe in sunk cost fallacies but we",
    "start": "433120",
    "end": "435199"
  },
  {
    "text": "had to need to ingest more data than we",
    "start": "435199",
    "end": "436960"
  },
  {
    "text": "were currently allotted",
    "start": "436960",
    "end": "438800"
  },
  {
    "text": "getting to where we are now plus some",
    "start": "438800",
    "end": "440240"
  },
  {
    "text": "spare capacity would have cost several",
    "start": "440240",
    "end": "441840"
  },
  {
    "text": "million dollars more just for the",
    "start": "441840",
    "end": "443599"
  },
  {
    "text": "initial license purchase additionally we",
    "start": "443599",
    "end": "445919"
  },
  {
    "text": "were paying approximately 18 in annual",
    "start": "445919",
    "end": "448080"
  },
  {
    "text": "maintenance on the base license cost for",
    "start": "448080",
    "end": "450000"
  },
  {
    "text": "software updates and support",
    "start": "450000",
    "end": "452880"
  },
  {
    "text": "the second cost component we considered",
    "start": "452880",
    "end": "454800"
  },
  {
    "text": "was infrastructure the infrastructure",
    "start": "454800",
    "end": "456560"
  },
  {
    "text": "cost of running a sim on prem third",
    "start": "456560",
    "end": "458400"
  },
  {
    "text": "party or otherwise it still requires the",
    "start": "458400",
    "end": "460800"
  },
  {
    "text": "purchase of hardware the operational",
    "start": "460800",
    "end": "462720"
  },
  {
    "text": "overhead of lifecycle management power",
    "start": "462720",
    "end": "464800"
  },
  {
    "text": "and data center costs",
    "start": "464800",
    "end": "466560"
  },
  {
    "text": "and these items tend to scale linearly",
    "start": "466560",
    "end": "468319"
  },
  {
    "text": "over time if you have a long or",
    "start": "468319",
    "end": "469919"
  },
  {
    "text": "indefinite retention period",
    "start": "469919",
    "end": "471919"
  },
  {
    "text": "by using a cloud service we'd eliminate",
    "start": "471919",
    "end": "473759"
  },
  {
    "text": "some of these but we would still be",
    "start": "473759",
    "end": "475360"
  },
  {
    "text": "paying someone else to store our data",
    "start": "475360",
    "end": "478000"
  },
  {
    "text": "the next item we factored into our",
    "start": "478000",
    "end": "479360"
  },
  {
    "text": "calculation was business drivers",
    "start": "479360",
    "end": "481680"
  },
  {
    "text": "many of the log generating sources we",
    "start": "481680",
    "end": "483280"
  },
  {
    "text": "collected from were being moved from",
    "start": "483280",
    "end": "484800"
  },
  {
    "text": "on-prem systems to gcp or other sas",
    "start": "484800",
    "end": "487360"
  },
  {
    "text": "providers given the direction of the",
    "start": "487360",
    "end": "488960"
  },
  {
    "text": "technology industry and choices being",
    "start": "488960",
    "end": "490879"
  },
  {
    "text": "made throughout our company",
    "start": "490879",
    "end": "492560"
  },
  {
    "text": "the disconnect between generating this",
    "start": "492560",
    "end": "494240"
  },
  {
    "text": "data in the cloud and bringing it in was",
    "start": "494240",
    "end": "496160"
  },
  {
    "text": "increasing",
    "start": "496160",
    "end": "497199"
  },
  {
    "text": "one of our main log sources came from",
    "start": "497199",
    "end": "499039"
  },
  {
    "text": "the businesses usage of gcp and its",
    "start": "499039",
    "end": "501599"
  },
  {
    "text": "growth was about to outpace our one",
    "start": "501599",
    "end": "503280"
  },
  {
    "text": "terabyte per day ingestion limit by",
    "start": "503280",
    "end": "505120"
  },
  {
    "text": "itself by putting our sim in the cloud",
    "start": "505120",
    "end": "507759"
  },
  {
    "text": "we'd be able to simplify and make log",
    "start": "507759",
    "end": "510080"
  },
  {
    "text": "collection more cost effective for these",
    "start": "510080",
    "end": "511759"
  },
  {
    "text": "sources",
    "start": "511759",
    "end": "512800"
  },
  {
    "text": "this did come with the trade-off of",
    "start": "512800",
    "end": "514240"
  },
  {
    "text": "having to ship our on-prem logs to the",
    "start": "514240",
    "end": "516000"
  },
  {
    "text": "cloud which isn't free but wasn't as",
    "start": "516000",
    "end": "518159"
  },
  {
    "text": "expensive nor did it inject notable",
    "start": "518159",
    "end": "520240"
  },
  {
    "text": "noticeable latency into our ingestion",
    "start": "520240",
    "end": "522320"
  },
  {
    "text": "pipeline",
    "start": "522320",
    "end": "524800"
  },
  {
    "text": "tying into my last point since two",
    "start": "524800",
    "end": "526560"
  },
  {
    "text": "sigma's engineering and business teams",
    "start": "526560",
    "end": "528080"
  },
  {
    "text": "were already making heavy investments",
    "start": "528080",
    "end": "529680"
  },
  {
    "text": "into gcp as our cloud platform we were",
    "start": "529680",
    "end": "531839"
  },
  {
    "text": "able to hang on coattails",
    "start": "531839",
    "end": "533760"
  },
  {
    "text": "bigquery offers two options to run",
    "start": "533760",
    "end": "536000"
  },
  {
    "text": "searches on-demand queries which can be",
    "start": "536000",
    "end": "538080"
  },
  {
    "text": "very expensive since you pay per byte",
    "start": "538080",
    "end": "539839"
  },
  {
    "text": "queried or through dedicated query slots",
    "start": "539839",
    "end": "542000"
  },
  {
    "text": "which are reserved at a fixed rate",
    "start": "542000",
    "end": "543440"
  },
  {
    "text": "regardless of query size or duration",
    "start": "543440",
    "end": "546320"
  },
  {
    "text": "our company had previously purchased a",
    "start": "546320",
    "end": "547839"
  },
  {
    "text": "number of reserve bigquery slots that",
    "start": "547839",
    "end": "550000"
  },
  {
    "text": "are shared among our engineering teams",
    "start": "550000",
    "end": "551920"
  },
  {
    "text": "which essentially eliminated the cost to",
    "start": "551920",
    "end": "553680"
  },
  {
    "text": "search our data within reason",
    "start": "553680",
    "end": "555920"
  },
  {
    "text": "we were also able to leverage",
    "start": "555920",
    "end": "557279"
  },
  {
    "text": "negotiations other teams had done for",
    "start": "557279",
    "end": "558959"
  },
  {
    "text": "data storage that drove our costs down",
    "start": "558959",
    "end": "561279"
  },
  {
    "text": "and lastly the business had already",
    "start": "561279",
    "end": "562880"
  },
  {
    "text": "established a dedicated interconnect",
    "start": "562880",
    "end": "564560"
  },
  {
    "text": "between our on-premise infrastructure",
    "start": "564560",
    "end": "566240"
  },
  {
    "text": "and gcp which again reduced this",
    "start": "566240",
    "end": "568240"
  },
  {
    "text": "project's overhead and improved our",
    "start": "568240",
    "end": "570640"
  },
  {
    "text": "reliability and latency projections i",
    "start": "570640",
    "end": "573200"
  },
  {
    "text": "want to specifically call this out",
    "start": "573200",
    "end": "574560"
  },
  {
    "text": "though our choice to roll our own sim",
    "start": "574560",
    "end": "576399"
  },
  {
    "text": "was heavily impacted by decisions the",
    "start": "576399",
    "end": "578240"
  },
  {
    "text": "business had made and that may certainly",
    "start": "578240",
    "end": "580000"
  },
  {
    "text": "not be the case for everyone",
    "start": "580000",
    "end": "583360"
  },
  {
    "start": "583000",
    "end": "583000"
  },
  {
    "text": "our next consideration was the features",
    "start": "583600",
    "end": "585600"
  },
  {
    "text": "offered natively in bq and vendor",
    "start": "585600",
    "end": "587519"
  },
  {
    "text": "products and we drew a comparison",
    "start": "587519",
    "end": "589120"
  },
  {
    "text": "against our requirements",
    "start": "589120",
    "end": "590720"
  },
  {
    "text": "in recent years the offerings in many",
    "start": "590720",
    "end": "592480"
  },
  {
    "text": "cloud platforms have grown considerably",
    "start": "592480",
    "end": "594240"
  },
  {
    "text": "to make building your own sim much more",
    "start": "594240",
    "end": "595760"
  },
  {
    "text": "viable open source software has improved",
    "start": "595760",
    "end": "598320"
  },
  {
    "text": "to better support mature methodologies",
    "start": "598320",
    "end": "600080"
  },
  {
    "text": "for log collection with either option",
    "start": "600080",
    "end": "602320"
  },
  {
    "text": "we'd still have to do work to normalize",
    "start": "602320",
    "end": "603920"
  },
  {
    "text": "our logs set up schemas write down our",
    "start": "603920",
    "end": "606640"
  },
  {
    "text": "own custom alerts and other",
    "start": "606640",
    "end": "607920"
  },
  {
    "text": "configuration steps we dropped these",
    "start": "607920",
    "end": "609839"
  },
  {
    "text": "considerations from both sides of the",
    "start": "609839",
    "end": "611360"
  },
  {
    "text": "equation since they were roughly equal",
    "start": "611360",
    "end": "613760"
  },
  {
    "text": "this produced a result that we added to",
    "start": "613760",
    "end": "615279"
  },
  {
    "text": "the cost component in terms of labor by",
    "start": "615279",
    "end": "616959"
  },
  {
    "text": "taking into account what the overhead",
    "start": "616959",
    "end": "618320"
  },
  {
    "text": "would be to reach our desired feature",
    "start": "618320",
    "end": "619839"
  },
  {
    "text": "set if we built our own sim",
    "start": "619839",
    "end": "621600"
  },
  {
    "text": "at the end of the day after we'd run out",
    "start": "621600",
    "end": "623440"
  },
  {
    "text": "of envelopes to write on the back of we",
    "start": "623440",
    "end": "625279"
  },
  {
    "text": "made the choice to build our own sim",
    "start": "625279",
    "end": "626640"
  },
  {
    "text": "with gcp",
    "start": "626640",
    "end": "627760"
  },
  {
    "text": "in gcp with bq i'll turn things over to",
    "start": "627760",
    "end": "630320"
  },
  {
    "text": "brett now for a deeper dive into our",
    "start": "630320",
    "end": "632000"
  },
  {
    "text": "technical implementation",
    "start": "632000",
    "end": "635120"
  },
  {
    "text": "thanks ethan so in starting this process",
    "start": "635760",
    "end": "638160"
  },
  {
    "text": "we centered our goals on reliability and",
    "start": "638160",
    "end": "640160"
  },
  {
    "text": "simplicity aiming to leverage native",
    "start": "640160",
    "end": "641920"
  },
  {
    "text": "capabilities wherever possible",
    "start": "641920",
    "end": "646040"
  },
  {
    "start": "648000",
    "end": "648000"
  },
  {
    "text": "we set out to see just how much",
    "start": "648480",
    "end": "650000"
  },
  {
    "text": "engineering work it would be to build",
    "start": "650000",
    "end": "651519"
  },
  {
    "text": "the same must-haves we actually needed",
    "start": "651519",
    "end": "653440"
  },
  {
    "text": "from our sim product namely first batch",
    "start": "653440",
    "end": "656640"
  },
  {
    "text": "file loads from system appliances most",
    "start": "656640",
    "end": "658800"
  },
  {
    "text": "often this takes the form of file dumps",
    "start": "658800",
    "end": "660800"
  },
  {
    "text": "from security and network appliances",
    "start": "660800",
    "end": "662800"
  },
  {
    "text": "regularly ftp or rsync to storage",
    "start": "662800",
    "end": "664959"
  },
  {
    "text": "servers and loaded into the system of",
    "start": "664959",
    "end": "666880"
  },
  {
    "text": "record",
    "start": "666880",
    "end": "668160"
  },
  {
    "text": "second streaming ingests from",
    "start": "668160",
    "end": "669839"
  },
  {
    "text": "configurable sources",
    "start": "669839",
    "end": "671440"
  },
  {
    "text": "one use case is systems with a",
    "start": "671440",
    "end": "672959"
  },
  {
    "text": "configurable remote syslog destination",
    "start": "672959",
    "end": "674959"
  },
  {
    "text": "server or custom applications some",
    "start": "674959",
    "end": "677519"
  },
  {
    "text": "examples include our mobile device",
    "start": "677519",
    "end": "679200"
  },
  {
    "text": "management provider some hardware",
    "start": "679200",
    "end": "680880"
  },
  {
    "text": "appliances and mail gateways",
    "start": "680880",
    "end": "683040"
  },
  {
    "text": "third scheduled query execution for",
    "start": "683040",
    "end": "685200"
  },
  {
    "text": "complex logic such as logic depend on an",
    "start": "685200",
    "end": "687920"
  },
  {
    "text": "aggregation multiple data sets or",
    "start": "687920",
    "end": "690079"
  },
  {
    "text": "patterns over time",
    "start": "690079",
    "end": "691519"
  },
  {
    "text": "for example collect all similar events",
    "start": "691519",
    "end": "693839"
  },
  {
    "text": "per hour group by hosts and inspect for",
    "start": "693839",
    "end": "696160"
  },
  {
    "text": "a rate increase",
    "start": "696160",
    "end": "697600"
  },
  {
    "text": "and last streaming alerting for single",
    "start": "697600",
    "end": "699680"
  },
  {
    "text": "line pattern matches",
    "start": "699680",
    "end": "701600"
  },
  {
    "text": "for example single log lines that strike",
    "start": "701600",
    "end": "703839"
  },
  {
    "text": "terror into the hearts of security",
    "start": "703839",
    "end": "705120"
  },
  {
    "text": "personnel like interactive login shell",
    "start": "705120",
    "end": "707600"
  },
  {
    "text": "on sshd logs on zero touch machines or",
    "start": "707600",
    "end": "710800"
  },
  {
    "text": "tamper detection integrity alert",
    "start": "710800",
    "end": "713040"
  },
  {
    "text": "and as bonus port items we wanted to",
    "start": "713040",
    "end": "715279"
  },
  {
    "text": "revision control and peer review our",
    "start": "715279",
    "end": "717040"
  },
  {
    "text": "query logic and definitions and git and",
    "start": "717040",
    "end": "719440"
  },
  {
    "text": "be able to flexibly ship output query",
    "start": "719440",
    "end": "721440"
  },
  {
    "text": "results to various notification and",
    "start": "721440",
    "end": "723279"
  },
  {
    "text": "tracking systems",
    "start": "723279",
    "end": "726000"
  },
  {
    "start": "726000",
    "end": "726000"
  },
  {
    "text": "let's start with batch file loads many",
    "start": "726000",
    "end": "728240"
  },
  {
    "text": "security and network appliances with",
    "start": "728240",
    "end": "729920"
  },
  {
    "text": "high volume logs use periodically",
    "start": "729920",
    "end": "731839"
  },
  {
    "text": "rotated local log files in our",
    "start": "731839",
    "end": "733920"
  },
  {
    "text": "environment our network proxies dns",
    "start": "733920",
    "end": "736160"
  },
  {
    "text": "infrastructure and some of our firewalls",
    "start": "736160",
    "end": "738079"
  },
  {
    "text": "are a few examples",
    "start": "738079",
    "end": "739920"
  },
  {
    "text": "bigquery batch loads allow for ingestion",
    "start": "739920",
    "end": "742000"
  },
  {
    "text": "of csv or json files with associated",
    "start": "742000",
    "end": "744480"
  },
  {
    "text": "schema definitions from local storage or",
    "start": "744480",
    "end": "747040"
  },
  {
    "text": "google cloud storage buckets",
    "start": "747040",
    "end": "749200"
  },
  {
    "text": "we chose to periodically sync our batch",
    "start": "749200",
    "end": "751040"
  },
  {
    "text": "log files into a cloud storage bucket",
    "start": "751040",
    "end": "753279"
  },
  {
    "text": "and then load them into bigquery from",
    "start": "753279",
    "end": "754720"
  },
  {
    "text": "there",
    "start": "754720",
    "end": "755600"
  },
  {
    "text": "this has the added advantage of allowing",
    "start": "755600",
    "end": "757519"
  },
  {
    "text": "for simpler retry logic it even permits",
    "start": "757519",
    "end": "760079"
  },
  {
    "text": "us to fully drop all the historic data",
    "start": "760079",
    "end": "761839"
  },
  {
    "text": "loaded to bigquery and reload it with",
    "start": "761839",
    "end": "763680"
  },
  {
    "text": "schema or parsing changes if we so",
    "start": "763680",
    "end": "765600"
  },
  {
    "text": "choose",
    "start": "765600",
    "end": "766880"
  },
  {
    "text": "we use bigquery itself to maintain",
    "start": "766880",
    "end": "768639"
  },
  {
    "text": "simple metadata tables for per data",
    "start": "768639",
    "end": "770480"
  },
  {
    "text": "source per file ingest date job failures",
    "start": "770480",
    "end": "773279"
  },
  {
    "text": "and parsing errors",
    "start": "773279",
    "end": "774880"
  },
  {
    "text": "that way if some part of the data",
    "start": "774880",
    "end": "776160"
  },
  {
    "text": "pipeline is interrupted or delayed it",
    "start": "776160",
    "end": "778240"
  },
  {
    "text": "can be picked back up since the job will",
    "start": "778240",
    "end": "780000"
  },
  {
    "text": "compare the set of existing files to the",
    "start": "780000",
    "end": "781920"
  },
  {
    "text": "metadata table to see which need to be",
    "start": "781920",
    "end": "783920"
  },
  {
    "text": "loaded",
    "start": "783920",
    "end": "785040"
  },
  {
    "text": "admins can inspect the failed files in",
    "start": "785040",
    "end": "786800"
  },
  {
    "text": "isolation while the rest of the pipeline",
    "start": "786800",
    "end": "788880"
  },
  {
    "text": "continues on working files",
    "start": "788880",
    "end": "792480"
  },
  {
    "text": "in our environment some light tooling",
    "start": "792639",
    "end": "794320"
  },
  {
    "text": "around the gcp bigquery and cloud",
    "start": "794320",
    "end": "796320"
  },
  {
    "text": "storage python apis does the following",
    "start": "796320",
    "end": "799279"
  },
  {
    "text": "step one",
    "start": "799279",
    "end": "800720"
  },
  {
    "text": "given a configuration file of data",
    "start": "800720",
    "end": "802240"
  },
  {
    "text": "sources load files from inside our",
    "start": "802240",
    "end": "804240"
  },
  {
    "text": "environment from an internal drop host",
    "start": "804240",
    "end": "806160"
  },
  {
    "text": "to a specific destination paths in the",
    "start": "806160",
    "end": "808000"
  },
  {
    "text": "cloud storage ingest bucket",
    "start": "808000",
    "end": "810959"
  },
  {
    "text": "step two create load jobs after querying",
    "start": "810959",
    "end": "813440"
  },
  {
    "text": "a metadata table and comparing the",
    "start": "813440",
    "end": "815200"
  },
  {
    "text": "results of what has been loaded to bq to",
    "start": "815200",
    "end": "816959"
  },
  {
    "text": "what currently exists in the bucket in",
    "start": "816959",
    "end": "819040"
  },
  {
    "text": "our example here our job sees a file",
    "start": "819040",
    "end": "821440"
  },
  {
    "text": "file1.gz",
    "start": "821440",
    "end": "822959"
  },
  {
    "text": "for data source 1.",
    "start": "822959",
    "end": "824959"
  },
  {
    "text": "if the file is new and has not yet been",
    "start": "824959",
    "end": "826720"
  },
  {
    "text": "successfully loaded we submit a bqlow",
    "start": "826720",
    "end": "829040"
  },
  {
    "text": "job for file1.gz using the schema",
    "start": "829040",
    "end": "831760"
  },
  {
    "text": "defined in our configuration for data",
    "start": "831760",
    "end": "833839"
  },
  {
    "text": "source 1.",
    "start": "833839",
    "end": "835040"
  },
  {
    "text": "and step 3",
    "start": "835040",
    "end": "836639"
  },
  {
    "text": "store job result metadata by inserting",
    "start": "836639",
    "end": "838560"
  },
  {
    "text": "it back to a different bq metadata table",
    "start": "838560",
    "end": "841600"
  },
  {
    "text": "failures are set aside so they can be",
    "start": "841600",
    "end": "843120"
  },
  {
    "text": "retried",
    "start": "843120",
    "end": "844240"
  },
  {
    "text": "next let's talk about streaming ingest",
    "start": "844240",
    "end": "847680"
  },
  {
    "start": "847000",
    "end": "847000"
  },
  {
    "text": "aside from the handful of batch",
    "start": "847680",
    "end": "848959"
  },
  {
    "text": "appliances described earlier the",
    "start": "848959",
    "end": "850720"
  },
  {
    "text": "majority of our logs are pushed over the",
    "start": "850720",
    "end": "852320"
  },
  {
    "text": "network either directly to gcp or to",
    "start": "852320",
    "end": "854800"
  },
  {
    "text": "internal infrastructure for additional",
    "start": "854800",
    "end": "856560"
  },
  {
    "text": "parsing routing and geographical load",
    "start": "856560",
    "end": "858800"
  },
  {
    "text": "balancing",
    "start": "858800",
    "end": "860160"
  },
  {
    "text": "in securities logging infrastructure at",
    "start": "860160",
    "end": "861760"
  },
  {
    "text": "two sigma we make use of open source",
    "start": "861760",
    "end": "863839"
  },
  {
    "text": "tools for log forwarding",
    "start": "863839",
    "end": "865519"
  },
  {
    "text": "we rely on fluent bit for log forwarding",
    "start": "865519",
    "end": "867760"
  },
  {
    "text": "fluent d for intermediate aggregation",
    "start": "867760",
    "end": "869839"
  },
  {
    "text": "parsing and routing and direct calls to",
    "start": "869839",
    "end": "872079"
  },
  {
    "text": "the gcp cloud logging api formerly known",
    "start": "872079",
    "end": "874399"
  },
  {
    "text": "as stackdriver for third-party",
    "start": "874399",
    "end": "876000"
  },
  {
    "text": "integrations",
    "start": "876000",
    "end": "877199"
  },
  {
    "text": "i'll dive a little more into the",
    "start": "877199",
    "end": "878480"
  },
  {
    "text": "specifics of each use case",
    "start": "878480",
    "end": "881040"
  },
  {
    "text": "for reliable log forwarding from our",
    "start": "881040",
    "end": "882639"
  },
  {
    "text": "base linux platform we run a fluent bit",
    "start": "882639",
    "end": "884880"
  },
  {
    "text": "agent and configuration from packages",
    "start": "884880",
    "end": "886639"
  },
  {
    "text": "installed on the standard system image",
    "start": "886639",
    "end": "888880"
  },
  {
    "text": "in the majority of cases we use fluid",
    "start": "888880",
    "end": "890720"
  },
  {
    "text": "bits direct gcp cloud logging output",
    "start": "890720",
    "end": "892800"
  },
  {
    "text": "plugin to write directly to google apis",
    "start": "892800",
    "end": "895120"
  },
  {
    "text": "rather than shipped intermediate systems",
    "start": "895120",
    "end": "897279"
  },
  {
    "text": "this has a few advantages",
    "start": "897279",
    "end": "899760"
  },
  {
    "text": "one having our large compute",
    "start": "899760",
    "end": "901360"
  },
  {
    "text": "infrastructure route logs directly to",
    "start": "901360",
    "end": "903279"
  },
  {
    "text": "google saves us on maintaining a much",
    "start": "903279",
    "end": "905040"
  },
  {
    "text": "larger distributed internal aggregator",
    "start": "905040",
    "end": "906880"
  },
  {
    "text": "infrastructure",
    "start": "906880",
    "end": "908399"
  },
  {
    "text": "two",
    "start": "908399",
    "end": "909199"
  },
  {
    "text": "google's native capabilities and load",
    "start": "909199",
    "end": "911040"
  },
  {
    "text": "balancing shifts operational burden away",
    "start": "911040",
    "end": "912959"
  },
  {
    "text": "from us",
    "start": "912959",
    "end": "914160"
  },
  {
    "text": "three",
    "start": "914160",
    "end": "915199"
  },
  {
    "text": "fluid bit is small fast and has low",
    "start": "915199",
    "end": "917600"
  },
  {
    "text": "memory overhead as well as having a",
    "start": "917600",
    "end": "919199"
  },
  {
    "text": "well-supported output plug-in to write",
    "start": "919199",
    "end": "920880"
  },
  {
    "text": "directly to the gcp cloud logging api",
    "start": "920880",
    "end": "924720"
  },
  {
    "text": "for data sources requiring more complex",
    "start": "924720",
    "end": "926720"
  },
  {
    "text": "parsing routing or enrichment we use a",
    "start": "926720",
    "end": "929120"
  },
  {
    "text": "set of fluency aggregator instances that",
    "start": "929120",
    "end": "931360"
  },
  {
    "text": "run in each data center",
    "start": "931360",
    "end": "933360"
  },
  {
    "text": "this is useful for bespoke systems with",
    "start": "933360",
    "end": "935279"
  },
  {
    "text": "configurable syslog remote destinations",
    "start": "935279",
    "end": "937759"
  },
  {
    "text": "and non-standard log formats we also use",
    "start": "937759",
    "end": "940720"
  },
  {
    "text": "this approach for appliances that may",
    "start": "940720",
    "end": "942160"
  },
  {
    "text": "run in the dmz that purposefully do not",
    "start": "942160",
    "end": "944079"
  },
  {
    "text": "have direct connectivity to gcp even via",
    "start": "944079",
    "end": "947199"
  },
  {
    "text": "our direct interconnects",
    "start": "947199",
    "end": "949279"
  },
  {
    "text": "fluentd allows for flexible and",
    "start": "949279",
    "end": "950959"
  },
  {
    "text": "performant parsing and routing for",
    "start": "950959",
    "end": "952480"
  },
  {
    "text": "custom log formats",
    "start": "952480",
    "end": "955839"
  },
  {
    "text": "lastly we need to make fetching logs",
    "start": "956560",
    "end": "958480"
  },
  {
    "text": "from an ever-growing number of hosted",
    "start": "958480",
    "end": "960079"
  },
  {
    "text": "services simple and reliable",
    "start": "960079",
    "end": "962480"
  },
  {
    "text": "our typical approach for vendor",
    "start": "962480",
    "end": "964000"
  },
  {
    "text": "applications that do not natively",
    "start": "964000",
    "end": "965440"
  },
  {
    "text": "provide logging integrations is to write",
    "start": "965440",
    "end": "967440"
  },
  {
    "text": "periodic poll jobs and then push the",
    "start": "967440",
    "end": "969600"
  },
  {
    "text": "results into the cloud logging api",
    "start": "969600",
    "end": "972320"
  },
  {
    "text": "we produced some internal tooling to",
    "start": "972320",
    "end": "973680"
  },
  {
    "text": "make it easier for admins of sas",
    "start": "973680",
    "end": "975279"
  },
  {
    "text": "services to write scripts to pull their",
    "start": "975279",
    "end": "976959"
  },
  {
    "text": "api logs and then write them to our",
    "start": "976959",
    "end": "978560"
  },
  {
    "text": "infrastructure",
    "start": "978560",
    "end": "980079"
  },
  {
    "text": "the goal was to make ingestion logic",
    "start": "980079",
    "end": "981759"
  },
  {
    "text": "very easy for teams outside of security",
    "start": "981759",
    "end": "984160"
  },
  {
    "text": "and shift the operational burden away",
    "start": "984160",
    "end": "986160"
  },
  {
    "text": "from maintaining and developing all",
    "start": "986160",
    "end": "987839"
  },
  {
    "text": "these intestinal integrations to",
    "start": "987839",
    "end": "989440"
  },
  {
    "text": "providing a standard maintained set of",
    "start": "989440",
    "end": "991440"
  },
  {
    "text": "tools for the teams to do so themselves",
    "start": "991440",
    "end": "995279"
  },
  {
    "text": "altogether these approaches have worked",
    "start": "995440",
    "end": "996959"
  },
  {
    "text": "well for us however when we first",
    "start": "996959",
    "end": "998880"
  },
  {
    "text": "deployed fluent bit to our compute",
    "start": "998880",
    "end": "1000320"
  },
  {
    "text": "environment we did have a minor incident",
    "start": "1000320",
    "end": "1002399"
  },
  {
    "text": "involving a need for additional cloud",
    "start": "1002399",
    "end": "1003920"
  },
  {
    "text": "logging right quota when our changes hit",
    "start": "1003920",
    "end": "1005920"
  },
  {
    "text": "the biggest deployment tranche",
    "start": "1005920",
    "end": "1008720"
  },
  {
    "text": "this was quickly remedied by gcp support",
    "start": "1008720",
    "end": "1010800"
  },
  {
    "text": "after i submitted a carefully annotated",
    "start": "1010800",
    "end": "1012399"
  },
  {
    "text": "rate graph to a support case",
    "start": "1012399",
    "end": "1014240"
  },
  {
    "text": "i warn you i needed multiple levels of",
    "start": "1014240",
    "end": "1016160"
  },
  {
    "text": "approval to exfiltrate this highly",
    "start": "1016160",
    "end": "1017839"
  },
  {
    "text": "sensitive graphic",
    "start": "1017839",
    "end": "1020639"
  },
  {
    "text": "i think gcp support was so impressed",
    "start": "1021199",
    "end": "1022959"
  },
  {
    "text": "with my ms paint skill that they bumped",
    "start": "1022959",
    "end": "1024720"
  },
  {
    "text": "our quota immediately",
    "start": "1024720",
    "end": "1027839"
  },
  {
    "text": "so let's look at the lifetime of an",
    "start": "1028640",
    "end": "1030480"
  },
  {
    "text": "event written to syslog on one of our",
    "start": "1030480",
    "end": "1032319"
  },
  {
    "text": "base platform linux hosts as a way to",
    "start": "1032319",
    "end": "1034240"
  },
  {
    "text": "demonstrate how our streaming ingest",
    "start": "1034240",
    "end": "1035839"
  },
  {
    "text": "works",
    "start": "1035839",
    "end": "1037520"
  },
  {
    "text": "first an event starts its life being",
    "start": "1037520",
    "end": "1039600"
  },
  {
    "text": "logged to the syslog socket on one of",
    "start": "1039600",
    "end": "1041280"
  },
  {
    "text": "our compute hosts sent from an appliance",
    "start": "1041280",
    "end": "1043280"
  },
  {
    "text": "to one of the set of fluency aggregators",
    "start": "1043280",
    "end": "1045678"
  },
  {
    "text": "or via write to the gcp cloud logging",
    "start": "1045679",
    "end": "1048079"
  },
  {
    "text": "python apis",
    "start": "1048079",
    "end": "1050799"
  },
  {
    "text": "second upon hitting the cloud logging",
    "start": "1050799",
    "end": "1052640"
  },
  {
    "text": "api bigquery export filters are",
    "start": "1052640",
    "end": "1055039"
  },
  {
    "text": "configured based on individual tags",
    "start": "1055039",
    "end": "1056799"
  },
  {
    "text": "present in the event",
    "start": "1056799",
    "end": "1059120"
  },
  {
    "text": "based on the tag the event is routed to",
    "start": "1059120",
    "end": "1060960"
  },
  {
    "text": "different bigquery destination tables in",
    "start": "1060960",
    "end": "1063280"
  },
  {
    "text": "most cases we use the log name value",
    "start": "1063280",
    "end": "1065600"
  },
  {
    "text": "which is uniquely configured on each",
    "start": "1065600",
    "end": "1067120"
  },
  {
    "text": "data source and specify the bigquery",
    "start": "1067120",
    "end": "1069360"
  },
  {
    "text": "dataset to write to",
    "start": "1069360",
    "end": "1072320"
  },
  {
    "text": "last cloud logging writes the event to",
    "start": "1072640",
    "end": "1074720"
  },
  {
    "text": "the bigquery table streaming buffer",
    "start": "1074720",
    "end": "1076480"
  },
  {
    "text": "assuming the event schema is compatible",
    "start": "1076480",
    "end": "1078559"
  },
  {
    "text": "the entire streaming process from",
    "start": "1078559",
    "end": "1080080"
  },
  {
    "text": "on-prem log event to receive timestamp",
    "start": "1080080",
    "end": "1082080"
  },
  {
    "text": "and bigquery is usually less than two to",
    "start": "1082080",
    "end": "1084160"
  },
  {
    "text": "three seconds",
    "start": "1084160",
    "end": "1086080"
  },
  {
    "text": "so that's how data streams in a few",
    "start": "1086080",
    "end": "1087760"
  },
  {
    "text": "seconds to our bigquery tables",
    "start": "1087760",
    "end": "1089679"
  },
  {
    "text": "additionally events in the streaming",
    "start": "1089679",
    "end": "1091039"
  },
  {
    "text": "buffer are readable by queries to the",
    "start": "1091039",
    "end": "1092640"
  },
  {
    "text": "table immediately",
    "start": "1092640",
    "end": "1095280"
  },
  {
    "text": "speaking of queries let's move on to how",
    "start": "1095280",
    "end": "1097200"
  },
  {
    "text": "we designed a system based on native gcp",
    "start": "1097200",
    "end": "1099440"
  },
  {
    "text": "components to execute and route",
    "start": "1099440",
    "end": "1101120"
  },
  {
    "text": "pre-configured scheduled queries",
    "start": "1101120",
    "end": "1104640"
  },
  {
    "start": "1104000",
    "end": "1104000"
  },
  {
    "text": "after handling batch and streaming",
    "start": "1105120",
    "end": "1106559"
  },
  {
    "text": "ingestion we needed a consistent way to",
    "start": "1106559",
    "end": "1108480"
  },
  {
    "text": "execute scheduled queries against our",
    "start": "1108480",
    "end": "1110160"
  },
  {
    "text": "data sets",
    "start": "1110160",
    "end": "1111440"
  },
  {
    "text": "the resulting system looks like the",
    "start": "1111440",
    "end": "1113039"
  },
  {
    "text": "following",
    "start": "1113039",
    "end": "1114080"
  },
  {
    "text": "first we manage query definition files",
    "start": "1114080",
    "end": "1116480"
  },
  {
    "text": "with associated metadata like miter",
    "start": "1116480",
    "end": "1118400"
  },
  {
    "text": "attack tactics and techniques",
    "start": "1118400",
    "end": "1120880"
  },
  {
    "text": "output types and destinations and query",
    "start": "1120880",
    "end": "1122880"
  },
  {
    "text": "frequency in a gitlab repository",
    "start": "1122880",
    "end": "1125600"
  },
  {
    "text": "we use two-party merge request approvals",
    "start": "1125600",
    "end": "1127600"
  },
  {
    "text": "for deployment or changes to query",
    "start": "1127600",
    "end": "1129280"
  },
  {
    "text": "execution",
    "start": "1129280",
    "end": "1130960"
  },
  {
    "text": "in practice deploying to production",
    "start": "1130960",
    "end": "1132799"
  },
  {
    "text": "means syncing the configuration to a",
    "start": "1132799",
    "end": "1134400"
  },
  {
    "text": "protected cloud storage bucket",
    "start": "1134400",
    "end": "1137120"
  },
  {
    "text": "next a set of cloud functions manages",
    "start": "1137120",
    "end": "1139280"
  },
  {
    "text": "reading the query configuration files",
    "start": "1139280",
    "end": "1141120"
  },
  {
    "text": "and executing the queries at designated",
    "start": "1141120",
    "end": "1142960"
  },
  {
    "text": "intervals",
    "start": "1142960",
    "end": "1145440"
  },
  {
    "text": "third",
    "start": "1145520",
    "end": "1146400"
  },
  {
    "text": "these functions output the result and",
    "start": "1146400",
    "end": "1147919"
  },
  {
    "text": "metadata to pub sub queues as well as",
    "start": "1147919",
    "end": "1150000"
  },
  {
    "text": "writing them to bigquery output tables",
    "start": "1150000",
    "end": "1151679"
  },
  {
    "text": "for persistent result storage",
    "start": "1151679",
    "end": "1154880"
  },
  {
    "text": "well and last the result messages on",
    "start": "1154880",
    "end": "1156880"
  },
  {
    "text": "those pub subtopics are consumed by",
    "start": "1156880",
    "end": "1158480"
  },
  {
    "text": "another small tool that based on the",
    "start": "1158480",
    "end": "1160320"
  },
  {
    "text": "metadata initially configured in the",
    "start": "1160320",
    "end": "1161760"
  },
  {
    "text": "yaml files formats them into email slack",
    "start": "1161760",
    "end": "1164320"
  },
  {
    "text": "and page of duty notifications",
    "start": "1164320",
    "end": "1167039"
  },
  {
    "text": "this functionality in addition to the",
    "start": "1167039",
    "end": "1168559"
  },
  {
    "text": "data load and ingest capabilities",
    "start": "1168559",
    "end": "1170559"
  },
  {
    "text": "represents the bulk of the code we had",
    "start": "1170559",
    "end": "1172080"
  },
  {
    "text": "to write to produce a sim in gcp",
    "start": "1172080",
    "end": "1174960"
  },
  {
    "text": "all told across a handful of tools and",
    "start": "1174960",
    "end": "1176880"
  },
  {
    "text": "infrastructure as code in python go and",
    "start": "1176880",
    "end": "1178880"
  },
  {
    "text": "terraform we wrote somewhere around 6000",
    "start": "1178880",
    "end": "1181280"
  },
  {
    "text": "lines of code",
    "start": "1181280",
    "end": "1182799"
  },
  {
    "text": "next let's talk about a simpler case but",
    "start": "1182799",
    "end": "1184559"
  },
  {
    "text": "a high value one",
    "start": "1184559",
    "end": "1186080"
  },
  {
    "text": "near real time streaming alerting",
    "start": "1186080",
    "end": "1189360"
  },
  {
    "start": "1189000",
    "end": "1189000"
  },
  {
    "text": "monitoring a stream of incoming events",
    "start": "1189360",
    "end": "1191280"
  },
  {
    "text": "for simple pattern matches enables quick",
    "start": "1191280",
    "end": "1193360"
  },
  {
    "text": "detection and response workflows for",
    "start": "1193360",
    "end": "1195120"
  },
  {
    "text": "many general cases",
    "start": "1195120",
    "end": "1196640"
  },
  {
    "text": "for example let's explore detecting the",
    "start": "1196640",
    "end": "1198480"
  },
  {
    "text": "use of a compromised ssh private key",
    "start": "1198480",
    "end": "1202640"
  },
  {
    "text": "starting at the same point as our",
    "start": "1202640",
    "end": "1203919"
  },
  {
    "text": "streaming injection an event is logged",
    "start": "1203919",
    "end": "1205919"
  },
  {
    "text": "from sshd on a machine in our on-prem",
    "start": "1205919",
    "end": "1208159"
  },
  {
    "text": "infrastructure the event is sent via",
    "start": "1208159",
    "end": "1210159"
  },
  {
    "text": "flipbit collection to the cloud locking",
    "start": "1210159",
    "end": "1212000"
  },
  {
    "text": "api",
    "start": "1212000",
    "end": "1214080"
  },
  {
    "text": "then we use a cloud logging filter",
    "start": "1214080",
    "end": "1215840"
  },
  {
    "text": "expression to match specific events in",
    "start": "1215840",
    "end": "1218080"
  },
  {
    "text": "this example by inspecting the",
    "start": "1218080",
    "end": "1220039"
  },
  {
    "text": "jsonpayload.ident and",
    "start": "1220039",
    "end": "1221280"
  },
  {
    "text": "jsonpayload.messagefields",
    "start": "1221280",
    "end": "1224280"
  },
  {
    "text": "finally upon matching the expression the",
    "start": "1224480",
    "end": "1226960"
  },
  {
    "text": "event is set to a pub subtopic that is",
    "start": "1226960",
    "end": "1228880"
  },
  {
    "text": "read formatted and sent to various",
    "start": "1228880",
    "end": "1230720"
  },
  {
    "text": "output destinations",
    "start": "1230720",
    "end": "1233280"
  },
  {
    "text": "now that we've covered ingestion and",
    "start": "1233280",
    "end": "1234720"
  },
  {
    "text": "alerting let's talk about how we manage",
    "start": "1234720",
    "end": "1236480"
  },
  {
    "text": "access to our data",
    "start": "1236480",
    "end": "1239440"
  },
  {
    "text": "at two sigma our security managed data",
    "start": "1239440",
    "end": "1241280"
  },
  {
    "start": "1240000",
    "end": "1240000"
  },
  {
    "text": "sets vary widely in sensitivity and",
    "start": "1241280",
    "end": "1243280"
  },
  {
    "text": "classification",
    "start": "1243280",
    "end": "1244880"
  },
  {
    "text": "other teams outside security often",
    "start": "1244880",
    "end": "1246559"
  },
  {
    "text": "leverage the bulk syslog collection for",
    "start": "1246559",
    "end": "1248400"
  },
  {
    "text": "system-level troubleshooting or",
    "start": "1248400",
    "end": "1249840"
  },
  {
    "text": "plant-wide upgrade efforts",
    "start": "1249840",
    "end": "1252000"
  },
  {
    "text": "when granting access to separate",
    "start": "1252000",
    "end": "1253440"
  },
  {
    "text": "engineering teams or even other users",
    "start": "1253440",
    "end": "1255600"
  },
  {
    "text": "within the security umbrella we needed",
    "start": "1255600",
    "end": "1257679"
  },
  {
    "text": "the ability to granularly control access",
    "start": "1257679",
    "end": "1259679"
  },
  {
    "text": "to our data",
    "start": "1259679",
    "end": "1260840"
  },
  {
    "text": "sets to accomplish this we sync group",
    "start": "1260840",
    "end": "1263360"
  },
  {
    "text": "backles from our internal directory",
    "start": "1263360",
    "end": "1264880"
  },
  {
    "text": "service to google cloud directory",
    "start": "1264880",
    "end": "1266559"
  },
  {
    "text": "service",
    "start": "1266559",
    "end": "1267919"
  },
  {
    "text": "these groups are populated into the",
    "start": "1267919",
    "end": "1269360"
  },
  {
    "text": "bigquery viewer role on each data set",
    "start": "1269360",
    "end": "1271760"
  },
  {
    "text": "which allows us to separately provision",
    "start": "1271760",
    "end": "1273360"
  },
  {
    "text": "access to more than 50 unique data sets",
    "start": "1273360",
    "end": "1276400"
  },
  {
    "text": "we use an internally developed",
    "start": "1276400",
    "end": "1277840"
  },
  {
    "text": "multi-party sign-off system for ads to",
    "start": "1277840",
    "end": "1280000"
  },
  {
    "text": "data sets to record approval",
    "start": "1280000",
    "end": "1282240"
  },
  {
    "text": "we also maintain audit logs of bigquery",
    "start": "1282240",
    "end": "1284240"
  },
  {
    "text": "query usage for forensic evidence of any",
    "start": "1284240",
    "end": "1286480"
  },
  {
    "text": "internal misuse",
    "start": "1286480",
    "end": "1288880"
  },
  {
    "text": "now let's talk about some of our",
    "start": "1288880",
    "end": "1290240"
  },
  {
    "text": "operational wins after completing this",
    "start": "1290240",
    "end": "1292000"
  },
  {
    "text": "undertaking",
    "start": "1292000",
    "end": "1294559"
  },
  {
    "start": "1295000",
    "end": "1295000"
  },
  {
    "text": "we can elegantly classify our results",
    "start": "1295280",
    "end": "1297120"
  },
  {
    "text": "into two sections the nomores and the",
    "start": "1297120",
    "end": "1299360"
  },
  {
    "text": "high fives first the no morse",
    "start": "1299360",
    "end": "1302400"
  },
  {
    "text": "log rehydration we never have to store",
    "start": "1302400",
    "end": "1304880"
  },
  {
    "text": "archive logs from bigquery or pay any",
    "start": "1304880",
    "end": "1306799"
  },
  {
    "text": "search speed penalties for older data",
    "start": "1306799",
    "end": "1309120"
  },
  {
    "text": "in our previous system we often rolled",
    "start": "1309120",
    "end": "1311039"
  },
  {
    "text": "off high volume data sets in as little",
    "start": "1311039",
    "end": "1312799"
  },
  {
    "text": "as 30 days because we didn't have",
    "start": "1312799",
    "end": "1314559"
  },
  {
    "text": "storage capacity and index size affected",
    "start": "1314559",
    "end": "1316720"
  },
  {
    "text": "performance",
    "start": "1316720",
    "end": "1318880"
  },
  {
    "text": "too big for our sim is something we say",
    "start": "1318880",
    "end": "1320720"
  },
  {
    "text": "far less often in our previous system we",
    "start": "1320720",
    "end": "1323360"
  },
  {
    "text": "often deferred ingesting high volume",
    "start": "1323360",
    "end": "1325039"
  },
  {
    "text": "data sets due to size constraints",
    "start": "1325039",
    "end": "1328000"
  },
  {
    "text": "now the high fives query speed we can",
    "start": "1328000",
    "end": "1330720"
  },
  {
    "text": "run large queries over years of data",
    "start": "1330720",
    "end": "1332720"
  },
  {
    "text": "interactively during exploratory or",
    "start": "1332720",
    "end": "1334720"
  },
  {
    "text": "threat hunting work",
    "start": "1334720",
    "end": "1336559"
  },
  {
    "text": "and ingestion admin overhead",
    "start": "1336559",
    "end": "1338960"
  },
  {
    "text": "we onboard a few additional data sets",
    "start": "1338960",
    "end": "1341120"
  },
  {
    "text": "every month and typically deliver with",
    "start": "1341120",
    "end": "1342880"
  },
  {
    "text": "only a few hours of engineering work for",
    "start": "1342880",
    "end": "1344480"
  },
  {
    "text": "each source",
    "start": "1344480",
    "end": "1347440"
  },
  {
    "text": "next let's take a quick look at some",
    "start": "1347440",
    "end": "1349039"
  },
  {
    "text": "lessons we learned in the process",
    "start": "1349039",
    "end": "1352240"
  },
  {
    "start": "1351000",
    "end": "1351000"
  },
  {
    "text": "the first lessons we learned was that",
    "start": "1352240",
    "end": "1353760"
  },
  {
    "text": "even during the lifetime of this project",
    "start": "1353760",
    "end": "1355760"
  },
  {
    "text": "much has changed in the gcp data",
    "start": "1355760",
    "end": "1357440"
  },
  {
    "text": "ecosystem",
    "start": "1357440",
    "end": "1359120"
  },
  {
    "text": "tools such as dataflow and cloud",
    "start": "1359120",
    "end": "1360720"
  },
  {
    "text": "monitoring may be more than adequate",
    "start": "1360720",
    "end": "1362400"
  },
  {
    "text": "replacement for much of our own tooling",
    "start": "1362400",
    "end": "1364000"
  },
  {
    "text": "and customization",
    "start": "1364000",
    "end": "1365760"
  },
  {
    "text": "additionally active monitoring in fast",
    "start": "1365760",
    "end": "1367679"
  },
  {
    "text": "moving environments can save you a lot",
    "start": "1367679",
    "end": "1369360"
  },
  {
    "text": "of pain",
    "start": "1369360",
    "end": "1370240"
  },
  {
    "text": "we run daily integration tests against",
    "start": "1370240",
    "end": "1372000"
  },
  {
    "text": "live gcp accounts to ensure we don't",
    "start": "1372000",
    "end": "1374000"
  },
  {
    "text": "miss an api deprecation or response",
    "start": "1374000",
    "end": "1376240"
  },
  {
    "text": "format change that can break our",
    "start": "1376240",
    "end": "1377600"
  },
  {
    "text": "ingestion",
    "start": "1377600",
    "end": "1378799"
  },
  {
    "text": "this is specifically in the lessons",
    "start": "1378799",
    "end": "1380159"
  },
  {
    "text": "learned section because we had to learn",
    "start": "1380159",
    "end": "1381679"
  },
  {
    "text": "that the hard way first",
    "start": "1381679",
    "end": "1383600"
  },
  {
    "text": "and the note about costs much of our",
    "start": "1383600",
    "end": "1385360"
  },
  {
    "text": "expense has been streaming very high",
    "start": "1385360",
    "end": "1386960"
  },
  {
    "text": "volume locks while the cost per byte is",
    "start": "1386960",
    "end": "1389280"
  },
  {
    "text": "very low for large data sets this adds",
    "start": "1389280",
    "end": "1391440"
  },
  {
    "text": "up quickly",
    "start": "1391440",
    "end": "1392640"
  },
  {
    "text": "we're exploring converting some of those",
    "start": "1392640",
    "end": "1394159"
  },
  {
    "text": "ingests to batch ingest to save money",
    "start": "1394159",
    "end": "1396159"
  },
  {
    "text": "where we don't need low latency ingest",
    "start": "1396159",
    "end": "1400000"
  },
  {
    "text": "i'll now talk you through a recorded",
    "start": "1400640",
    "end": "1402159"
  },
  {
    "text": "demo of a sample of our streaming",
    "start": "1402159",
    "end": "1403600"
  },
  {
    "text": "detection patterns",
    "start": "1403600",
    "end": "1404960"
  },
  {
    "text": "sorry folks logging into the two sigma",
    "start": "1404960",
    "end": "1406720"
  },
  {
    "text": "network live at black hat was a tough",
    "start": "1406720",
    "end": "1408400"
  },
  {
    "text": "sell to our compliance team",
    "start": "1408400",
    "end": "1411600"
  },
  {
    "text": "okay so we start with the shell on my",
    "start": "1411919",
    "end": "1413760"
  },
  {
    "text": "linux home server on the left inside to",
    "start": "1413760",
    "end": "1416000"
  },
  {
    "text": "sigma owned and run data centers and our",
    "start": "1416000",
    "end": "1418000"
  },
  {
    "text": "browser on the right showing the gcp",
    "start": "1418000",
    "end": "1419679"
  },
  {
    "text": "cloud logging logs explorer",
    "start": "1419679",
    "end": "1421840"
  },
  {
    "text": "i'll show you the filter expression we",
    "start": "1421840",
    "end": "1423200"
  },
  {
    "text": "used to route the log entry towards our",
    "start": "1423200",
    "end": "1424799"
  },
  {
    "text": "pub sub queue",
    "start": "1424799",
    "end": "1426159"
  },
  {
    "text": "here we're just inspecting for an",
    "start": "1426159",
    "end": "1427679"
  },
  {
    "text": "accepted public key for root message",
    "start": "1427679",
    "end": "1429360"
  },
  {
    "text": "from sshd",
    "start": "1429360",
    "end": "1431120"
  },
  {
    "text": "now ssh to root on a machine with kioth",
    "start": "1431120",
    "end": "1433919"
  },
  {
    "text": "simulating the use of a protected",
    "start": "1433919",
    "end": "1435520"
  },
  {
    "text": "private key to ssh to root directly for",
    "start": "1435520",
    "end": "1437679"
  },
  {
    "text": "break glass purposes",
    "start": "1437679",
    "end": "1439360"
  },
  {
    "text": "looking at our logging filter again we",
    "start": "1439360",
    "end": "1440799"
  },
  {
    "text": "see the pub sub topic in the destination",
    "start": "1440799",
    "end": "1442640"
  },
  {
    "text": "field",
    "start": "1442640",
    "end": "1444960"
  },
  {
    "text": "in a few moments we'll see our slack",
    "start": "1444960",
    "end": "1446480"
  },
  {
    "text": "notification palm up in the bottom right",
    "start": "1446480",
    "end": "1448240"
  },
  {
    "text": "hand corner of the screen",
    "start": "1448240",
    "end": "1450559"
  },
  {
    "text": "when we click that we're taken to a",
    "start": "1450559",
    "end": "1452159"
  },
  {
    "text": "shared alerting channel that is one of",
    "start": "1452159",
    "end": "1453679"
  },
  {
    "text": "our output destinations for",
    "start": "1453679",
    "end": "1454799"
  },
  {
    "text": "notifications",
    "start": "1454799",
    "end": "1456960"
  },
  {
    "text": "that's it and now back to ethan for",
    "start": "1456960",
    "end": "1458720"
  },
  {
    "text": "tactical results",
    "start": "1458720",
    "end": "1461120"
  },
  {
    "text": "thanks brett now looking at some of our",
    "start": "1461120",
    "end": "1463039"
  },
  {
    "text": "tactical results",
    "start": "1463039",
    "end": "1464880"
  },
  {
    "text": "let's start by summarizing the overall",
    "start": "1464880",
    "end": "1466480"
  },
  {
    "start": "1465000",
    "end": "1465000"
  },
  {
    "text": "effort that went into building our own",
    "start": "1466480",
    "end": "1467919"
  },
  {
    "text": "sim as brett said we wrote around 6000",
    "start": "1467919",
    "end": "1470559"
  },
  {
    "text": "lines of code for the necessary",
    "start": "1470559",
    "end": "1472320"
  },
  {
    "text": "ingestion routing scheduling and",
    "start": "1472320",
    "end": "1474080"
  },
  {
    "text": "alerting functions this coding work plus",
    "start": "1474080",
    "end": "1476480"
  },
  {
    "text": "the configuration of collection agents",
    "start": "1476480",
    "end": "1478080"
  },
  {
    "text": "and aggregators as well as the",
    "start": "1478080",
    "end": "1479600"
  },
  {
    "text": "infrastructure in gcp took about half an",
    "start": "1479600",
    "end": "1482159"
  },
  {
    "text": "fte year of effort to get an mvp our",
    "start": "1482159",
    "end": "1485039"
  },
  {
    "text": "minimum viable product",
    "start": "1485039",
    "end": "1486799"
  },
  {
    "text": "we spent an additional three months",
    "start": "1486799",
    "end": "1488240"
  },
  {
    "text": "addressing some of the more complicated",
    "start": "1488240",
    "end": "1489760"
  },
  {
    "text": "use cases we have to get to where we are",
    "start": "1489760",
    "end": "1491600"
  },
  {
    "text": "today",
    "start": "1491600",
    "end": "1493440"
  },
  {
    "start": "1493000",
    "end": "1493000"
  },
  {
    "text": "these efforts have paid off and we're",
    "start": "1493440",
    "end": "1494960"
  },
  {
    "text": "now currently storing approximately five",
    "start": "1494960",
    "end": "1496799"
  },
  {
    "text": "petabytes of data in bq all of our",
    "start": "1496799",
    "end": "1499039"
  },
  {
    "text": "historical data is immediately",
    "start": "1499039",
    "end": "1500559"
  },
  {
    "text": "searchable without any rehydration",
    "start": "1500559",
    "end": "1503200"
  },
  {
    "text": "we routinely ingest over 5 terabytes a",
    "start": "1503200",
    "end": "1505279"
  },
  {
    "text": "day without concerns about overages or",
    "start": "1505279",
    "end": "1507279"
  },
  {
    "text": "loss of function from punitive licensing",
    "start": "1507279",
    "end": "1509120"
  },
  {
    "text": "terms",
    "start": "1509120",
    "end": "1510159"
  },
  {
    "text": "and our average query time is a matter",
    "start": "1510159",
    "end": "1512000"
  },
  {
    "text": "of seconds which is a vast improvement",
    "start": "1512000",
    "end": "1514080"
  },
  {
    "text": "from the tens of minutes and upwards",
    "start": "1514080",
    "end": "1515520"
  },
  {
    "text": "that we saw on our former platform",
    "start": "1515520",
    "end": "1518480"
  },
  {
    "start": "1518000",
    "end": "1518000"
  },
  {
    "text": "we estimate we've saved approximately",
    "start": "1518480",
    "end": "1520080"
  },
  {
    "text": "three and a half million dollars in",
    "start": "1520080",
    "end": "1521279"
  },
  {
    "text": "upfront license costs and an additional",
    "start": "1521279",
    "end": "1523120"
  },
  {
    "text": "six hundred thousand dollars annually in",
    "start": "1523120",
    "end": "1524880"
  },
  {
    "text": "maintenance contracts after the initial",
    "start": "1524880",
    "end": "1527039"
  },
  {
    "text": "setup our staffing resources required to",
    "start": "1527039",
    "end": "1528960"
  },
  {
    "text": "support bq are slightly less than what",
    "start": "1528960",
    "end": "1531600"
  },
  {
    "text": "it took to support our former vendors",
    "start": "1531600",
    "end": "1533200"
  },
  {
    "text": "product and amount to about one person",
    "start": "1533200",
    "end": "1535039"
  },
  {
    "text": "month per year",
    "start": "1535039",
    "end": "1536480"
  },
  {
    "text": "the largest reason for this is the",
    "start": "1536480",
    "end": "1538159"
  },
  {
    "text": "reduced need to track down noisy loggers",
    "start": "1538159",
    "end": "1540320"
  },
  {
    "text": "given the low cost of storage and",
    "start": "1540320",
    "end": "1541840"
  },
  {
    "text": "negligible impact extra data has on",
    "start": "1541840",
    "end": "1543679"
  },
  {
    "text": "search performance",
    "start": "1543679",
    "end": "1546000"
  },
  {
    "text": "so looking holistically what did this",
    "start": "1546000",
    "end": "1547840"
  },
  {
    "text": "effort do to advance our security",
    "start": "1547840",
    "end": "1549520"
  },
  {
    "text": "program",
    "start": "1549520",
    "end": "1550880"
  },
  {
    "text": "for starters we're much more agile when",
    "start": "1550880",
    "end": "1552799"
  },
  {
    "text": "it comes to choosing data sets to",
    "start": "1552799",
    "end": "1554240"
  },
  {
    "text": "collect by opening up ingestion",
    "start": "1554240",
    "end": "1556080"
  },
  {
    "text": "capabilities we've been able to add more",
    "start": "1556080",
    "end": "1557919"
  },
  {
    "text": "data feeds and free our security",
    "start": "1557919",
    "end": "1559600"
  },
  {
    "text": "analysts to experiment on developing",
    "start": "1559600",
    "end": "1561200"
  },
  {
    "text": "additional strategies that they weren't",
    "start": "1561200",
    "end": "1562799"
  },
  {
    "text": "able to before",
    "start": "1562799",
    "end": "1564159"
  },
  {
    "text": "these include adding new external data",
    "start": "1564159",
    "end": "1565679"
  },
  {
    "text": "sets to help match iocs and the like as",
    "start": "1565679",
    "end": "1567679"
  },
  {
    "text": "well as adding larger internal feeds",
    "start": "1567679",
    "end": "1569360"
  },
  {
    "text": "like firewall logs and certain network",
    "start": "1569360",
    "end": "1571200"
  },
  {
    "text": "telemetry that enables more",
    "start": "1571200",
    "end": "1572799"
  },
  {
    "text": "sophisticated analysis to detect",
    "start": "1572799",
    "end": "1574480"
  },
  {
    "text": "anomalies and threats",
    "start": "1574480",
    "end": "1576559"
  },
  {
    "text": "for our end users of bq there was an",
    "start": "1576559",
    "end": "1578720"
  },
  {
    "text": "onboarding cost to retrain our analysts",
    "start": "1578720",
    "end": "1580480"
  },
  {
    "text": "and threat hunters to use standard sql",
    "start": "1580480",
    "end": "1582559"
  },
  {
    "text": "but it's a more fungible skill set that",
    "start": "1582559",
    "end": "1584240"
  },
  {
    "text": "has greater generalizability than a",
    "start": "1584240",
    "end": "1586000"
  },
  {
    "text": "vendor's proprietary language the",
    "start": "1586000",
    "end": "1588000"
  },
  {
    "text": "analysts are also much happier because",
    "start": "1588000",
    "end": "1589600"
  },
  {
    "text": "the time to complete a search is down",
    "start": "1589600",
    "end": "1591120"
  },
  {
    "text": "and that helps speed up investigations",
    "start": "1591120",
    "end": "1592799"
  },
  {
    "text": "and incident response functions the",
    "start": "1592799",
    "end": "1594799"
  },
  {
    "text": "improved speed and reliability of our",
    "start": "1594799",
    "end": "1596320"
  },
  {
    "text": "streaming alerting has allowed us to",
    "start": "1596320",
    "end": "1598000"
  },
  {
    "text": "invest in near real-time detection and",
    "start": "1598000",
    "end": "1599919"
  },
  {
    "text": "response for critical use cases",
    "start": "1599919",
    "end": "1603600"
  },
  {
    "text": "given the security controls baked into",
    "start": "1604960",
    "end": "1606559"
  },
  {
    "start": "1605000",
    "end": "1605000"
  },
  {
    "text": "the platform we're able to open up",
    "start": "1606559",
    "end": "1608480"
  },
  {
    "text": "select data sets and views to other",
    "start": "1608480",
    "end": "1610000"
  },
  {
    "text": "engineering teams at two sigma to help",
    "start": "1610000",
    "end": "1611919"
  },
  {
    "text": "them troubleshoot and detect issues on",
    "start": "1611919",
    "end": "1613440"
  },
  {
    "text": "their systems",
    "start": "1613440",
    "end": "1614640"
  },
  {
    "text": "this was also the case in our previous",
    "start": "1614640",
    "end": "1616240"
  },
  {
    "text": "product but we had to limit what we",
    "start": "1616240",
    "end": "1617840"
  },
  {
    "text": "ingested from them given our sizing",
    "start": "1617840",
    "end": "1619440"
  },
  {
    "text": "concerns and often had to nag them when",
    "start": "1619440",
    "end": "1621840"
  },
  {
    "text": "they were logging too much which again",
    "start": "1621840",
    "end": "1623520"
  },
  {
    "text": "is no longer the case",
    "start": "1623520",
    "end": "1625520"
  },
  {
    "text": "our new platform also provides",
    "start": "1625520",
    "end": "1626960"
  },
  {
    "text": "flexibility and extensibility in data",
    "start": "1626960",
    "end": "1629120"
  },
  {
    "text": "integration and parsing controls bq",
    "start": "1629120",
    "end": "1631440"
  },
  {
    "text": "supports complex record types so doing",
    "start": "1631440",
    "end": "1633679"
  },
  {
    "text": "things like blob json insertion works",
    "start": "1633679",
    "end": "1635679"
  },
  {
    "text": "and is readily parsable",
    "start": "1635679",
    "end": "1637440"
  },
  {
    "text": "there are also no restrictions on",
    "start": "1637440",
    "end": "1638720"
  },
  {
    "text": "ingestion methodologies",
    "start": "1638720",
    "end": "1640399"
  },
  {
    "text": "nor are we forced to use a specific",
    "start": "1640399",
    "end": "1642000"
  },
  {
    "text": "framework for logging to match the",
    "start": "1642000",
    "end": "1643360"
  },
  {
    "text": "platform's expectations we're able to",
    "start": "1643360",
    "end": "1645440"
  },
  {
    "text": "self-define our schema to match internal",
    "start": "1645440",
    "end": "1647279"
  },
  {
    "text": "common data model",
    "start": "1647279",
    "end": "1648640"
  },
  {
    "text": "with much less engineering effort which",
    "start": "1648640",
    "end": "1650320"
  },
  {
    "text": "helps to reduce cognitive burden on our",
    "start": "1650320",
    "end": "1652480"
  },
  {
    "text": "investigators when trying to join",
    "start": "1652480",
    "end": "1654240"
  },
  {
    "text": "datasets from disparate sources",
    "start": "1654240",
    "end": "1657679"
  },
  {
    "text": "so as we look toward the future of our",
    "start": "1657679",
    "end": "1659200"
  },
  {
    "text": "homegrown sim several areas for",
    "start": "1659200",
    "end": "1661039"
  },
  {
    "text": "improvement and growth stand out",
    "start": "1661039",
    "end": "1662880"
  },
  {
    "text": "first we are continuing to onboard and",
    "start": "1662880",
    "end": "1664559"
  },
  {
    "text": "validate new data sets some are",
    "start": "1664559",
    "end": "1666320"
  },
  {
    "text": "operational like a new sas provider's",
    "start": "1666320",
    "end": "1668080"
  },
  {
    "text": "logs some are tactical like ingesting",
    "start": "1668080",
    "end": "1670080"
  },
  {
    "text": "new threat feeds second our choice for",
    "start": "1670080",
    "end": "1672240"
  },
  {
    "text": "building our own sim in the public cloud",
    "start": "1672240",
    "end": "1673919"
  },
  {
    "text": "has future implications given how fast",
    "start": "1673919",
    "end": "1676080"
  },
  {
    "text": "that area grows and iterates we are",
    "start": "1676080",
    "end": "1678000"
  },
  {
    "text": "considering making adjustments to some",
    "start": "1678000",
    "end": "1679440"
  },
  {
    "text": "of the development work we've done to",
    "start": "1679440",
    "end": "1680720"
  },
  {
    "text": "incorporate less labor-intensive",
    "start": "1680720",
    "end": "1682320"
  },
  {
    "text": "third-party offerings into our sim",
    "start": "1682320",
    "end": "1683919"
  },
  {
    "text": "workflow such as google's dataflow",
    "start": "1683919",
    "end": "1686320"
  },
  {
    "text": "we also have plans to extend our",
    "start": "1686320",
    "end": "1687840"
  },
  {
    "text": "response pipelines first with additional",
    "start": "1687840",
    "end": "1689840"
  },
  {
    "text": "automation to do things like isolate",
    "start": "1689840",
    "end": "1691440"
  },
  {
    "text": "machines or disable access and then",
    "start": "1691440",
    "end": "1693200"
  },
  {
    "text": "later to also tie into legacy on-prem",
    "start": "1693200",
    "end": "1695120"
  },
  {
    "text": "systems to handle additional response",
    "start": "1695120",
    "end": "1696799"
  },
  {
    "text": "scenarios",
    "start": "1696799",
    "end": "1698799"
  },
  {
    "text": "overall the decision to roller on sim",
    "start": "1698799",
    "end": "1700559"
  },
  {
    "text": "has proven to be successful to date it's",
    "start": "1700559",
    "end": "1702399"
  },
  {
    "text": "enabled our broader event collection and",
    "start": "1702399",
    "end": "1704000"
  },
  {
    "text": "analysis program to evolve and to",
    "start": "1704000",
    "end": "1705600"
  },
  {
    "text": "continue to tackle the ever-changing",
    "start": "1705600",
    "end": "1707120"
  },
  {
    "text": "threat landscape",
    "start": "1707120",
    "end": "1709679"
  },
  {
    "text": "with that thank you everyone for",
    "start": "1709679",
    "end": "1710880"
  },
  {
    "text": "attending and we'd be happy to answer",
    "start": "1710880",
    "end": "1712159"
  },
  {
    "text": "any questions",
    "start": "1712159",
    "end": "1715360"
  }
]
[
  {
    "text": "hello everyone yeah it's so nice to see everyone here and welcome you to uh uh",
    "start": "2639",
    "end": "8280"
  },
  {
    "text": "coming to our talks yeah uh I'm CK uh it's my second time to uh playhead but",
    "start": "8280",
    "end": "14400"
  },
  {
    "text": "last time because of covid-19 we cannot come here for presentation so uh it's a",
    "start": "14400",
    "end": "19560"
  },
  {
    "text": "very exciting and a little nervous here yeah so today our topic is uh irmen",
    "start": "19560",
    "end": "25880"
  },
  {
    "text": "interpretable instant inspector based on large scale uh language model and Association mining Yeah in our work we",
    "start": "25880",
    "end": "33480"
  },
  {
    "text": "trying to integrate uh the most uh popular and uh nov LM model and in the",
    "start": "33480",
    "end": "40520"
  },
  {
    "text": "same time we combine the traditional Association mining uh to assist our",
    "start": "40520",
    "end": "45559"
  },
  {
    "text": "analyst to handle incident response yeah uh because we like to use the large",
    "start": "45559",
    "end": "52199"
  },
  {
    "text": "language model but however it's a BL box so we use a more traditional uh",
    "start": "52199",
    "end": "57280"
  },
  {
    "text": "Association mining to complement this product to give our analysts more",
    "start": "57280",
    "end": "62800"
  },
  {
    "text": "explainable uh result about about our",
    "start": "62800",
    "end": "67960"
  },
  {
    "text": "analysis so uh this is today's uh online and our research is comp uh composed of",
    "start": "67960",
    "end": "74320"
  },
  {
    "text": "two part from the cyber security part and the D science part so the first part",
    "start": "74320",
    "end": "80400"
  },
  {
    "text": "we go through the our motivation and our problem from the security uh perspective",
    "start": "80400",
    "end": "86880"
  },
  {
    "text": "and then we will move to our data science part so we will introduce our two system uh command GPT and irmen and",
    "start": "86880",
    "end": "94280"
  },
  {
    "text": "then we'll uh go to the evaluation to show you how we can use this system and",
    "start": "94280",
    "end": "99799"
  },
  {
    "text": "to analyze the real world uh instant and finally we will give a very briefly uh",
    "start": "99799",
    "end": "105680"
  },
  {
    "text": "takeaway okay before we go into our uh topic let me quickly introduce ourself",
    "start": "105680",
    "end": "112640"
  },
  {
    "text": "yeah uh in uh in our research member we have three member in this research uh in",
    "start": "112640",
    "end": "118399"
  },
  {
    "text": "this research and the first first author is Eric Hong yeah and uh he's our uh senior",
    "start": "118399",
    "end": "125960"
  },
  {
    "text": "dance scientist at cyft and uh he has very uh talent in the Dan science and",
    "start": "125960",
    "end": "132840"
  },
  {
    "text": "has published several uh paper in top machine learning conference like cvpr",
    "start": "132840",
    "end": "138680"
  },
  {
    "text": "and ijcnn and his research is focused on large scale multifactor anomaly",
    "start": "138680",
    "end": "144519"
  },
  {
    "text": "detection automatic ID security analysis and user Behavior retrieval yeah and",
    "start": "144519",
    "end": "150920"
  },
  {
    "text": "next is our uh leader of our machine learning uh learning team uh George Yang",
    "start": "150920",
    "end": "156560"
  },
  {
    "text": "yeah and he is our data science director and focus on uh building Distributing a",
    "start": "156560",
    "end": "163159"
  },
  {
    "text": "large scale uh machine Learning System to help us to handle a cyber security department here and he also trying to",
    "start": "163159",
    "end": "170159"
  },
  {
    "text": "adopting a large scale model a large language model uh to handle the security",
    "start": "170159",
    "end": "176319"
  },
  {
    "text": "problem uh and he loved to Shar in his experience and his research so he has",
    "start": "176319",
    "end": "181680"
  },
  {
    "text": "been a speaker uh in the CC SE pong Taiwan and pong Japan and he's also a CT",
    "start": "181680",
    "end": "190360"
  },
  {
    "text": "player yeah and uh you can just call me CK and I uh responsible for organize our",
    "start": "190360",
    "end": "196519"
  },
  {
    "text": "resarch team in ccraft and I'm also a retired CT player so my team bambo Fox",
    "start": "196519",
    "end": "203560"
  },
  {
    "text": "uh is now the team uh twwm 48 and they will also participate the devc final uh",
    "start": "203560",
    "end": "208959"
  },
  {
    "text": "in a few days later later and yeah we hope L can get a good grade uh in the",
    "start": "208959",
    "end": "214519"
  },
  {
    "text": "CTF and I'm also a member of uh Association uh of hacker in Taiwan yeah",
    "start": "214519",
    "end": "220720"
  },
  {
    "text": "every year we will hold our uh conference event and the CTF event yeah I think CF event is one of most",
    "start": "220720",
    "end": "227599"
  },
  {
    "text": "important uh uh top CF content uh in the world so if you want to enjoy uh the uh",
    "start": "227599",
    "end": "234640"
  },
  {
    "text": "traveling to Taiwan and different kind of he culture welcome to join our event",
    "start": "234640",
    "end": "240239"
  },
  {
    "text": "okay so now uh come back to our research so our research is start from",
    "start": "240239",
    "end": "246799"
  },
  {
    "text": "Taiwan yeah um maybe U many of you already know that Taiwan has a very",
    "start": "246799",
    "end": "252239"
  },
  {
    "text": "special position in the world uh due to the geopolitics uh Taiwan has a a",
    "start": "252239",
    "end": "257320"
  },
  {
    "text": "special relationship to China and it's always at the Forefront of saath thre",
    "start": "257320",
    "end": "262960"
  },
  {
    "text": "yeah so we always collect the firsthand intelligence like the new explo and new",
    "start": "262960",
    "end": "268000"
  },
  {
    "text": "mare when we analyze uh the attch Target in Taiwan and we",
    "start": "268000",
    "end": "273560"
  },
  {
    "text": "have closely monitored uh numerous numerous cyber attacks uh especially for",
    "start": "273560",
    "end": "279919"
  },
  {
    "text": "those come from uh China so about 10 years ago uh our bats they present in",
    "start": "279919",
    "end": "286360"
  },
  {
    "text": "blackhead their topic is hunting the shadow they trying to analyze the B",
    "start": "286360",
    "end": "291440"
  },
  {
    "text": "infra of the uh China director and in the same time uh they also analyze uh",
    "start": "291440",
    "end": "297479"
  },
  {
    "text": "how these people this Thor can work together to organiz the whole attack uh",
    "start": "297479",
    "end": "302919"
  },
  {
    "text": "uh targeting Taiwan yeah and in three years ago we also have the uh operation",
    "start": "302919",
    "end": "308160"
  },
  {
    "text": "Kima with disclosure the uh Cyber attack targeting Taiwan semiconductor industry",
    "start": "308160",
    "end": "314720"
  },
  {
    "text": "yeah so this show that Taiwan is always uh very important during the Cyber",
    "start": "314720",
    "end": "321319"
  },
  {
    "text": "War so today we are more talking about is not our fighting is how we can uh",
    "start": "321319",
    "end": "327199"
  },
  {
    "text": "monitor this uh attack from the Thor so every day uh we will monitor",
    "start": "327199",
    "end": "334240"
  },
  {
    "text": "more than 200 Millions events from our visability from government from",
    "start": "334240",
    "end": "339520"
  },
  {
    "text": "financial sector and from uh some semiconduct vendors so to handle this uh large",
    "start": "339520",
    "end": "345759"
  },
  {
    "text": "amount of event uh is trivial that we cannot analyze by the human so some",
    "start": "345759",
    "end": "351639"
  },
  {
    "text": "automatic or machine learning mechanism is indispensable for us to uh inspect",
    "start": "351639",
    "end": "358160"
  },
  {
    "text": "attack yeah in the same time we also need to provide the analyst reliable",
    "start": "358160",
    "end": "363560"
  },
  {
    "text": "weapon uh to uh Rec recognize which command which event is related to the",
    "start": "363560",
    "end": "369479"
  },
  {
    "text": "attack and triag event and help them to do response and reasoning what happened",
    "start": "369479",
    "end": "376360"
  },
  {
    "text": "yeah and in today's presentation uh we somehow narrow down uh our scope we",
    "start": "376360",
    "end": "382360"
  },
  {
    "text": "focus on the process creation event and with the ca information uh why we choose",
    "start": "382360",
    "end": "388319"
  },
  {
    "text": "this direction because commanda information contain a lot of uh intelligence that can help us to",
    "start": "388319",
    "end": "395759"
  },
  {
    "text": "identify the attacker uh but also because the Comm line has a rich semantic information and",
    "start": "395759",
    "end": "403440"
  },
  {
    "text": "flexible format so it's not easy task it's one of uh the most complicated",
    "start": "403440",
    "end": "409080"
  },
  {
    "text": "problem when we analyze event look uh but however I think uh our research is",
    "start": "409080",
    "end": "414759"
  },
  {
    "text": "has a potential to migrate and apply to other kind of event Lo",
    "start": "414759",
    "end": "421400"
  },
  {
    "text": "okay before we go deeper uh to uh explain the commite problem uh let's do",
    "start": "421560",
    "end": "428280"
  },
  {
    "text": "uh let's do some exercise yeah I want to have some uh interaction between us so",
    "start": "428280",
    "end": "434720"
  },
  {
    "text": "uh in here we have five command in the screen yeah and I want to ask which",
    "start": "434720",
    "end": "439879"
  },
  {
    "text": "command line can correctly print out a computer name yeah I give you five",
    "start": "439879",
    "end": "445879"
  },
  {
    "text": "second to see this comment five 4 3 2 1",
    "start": "445879",
    "end": "452919"
  },
  {
    "text": "okay uh if you see uh if you think the first one can print out the uh computer",
    "start": "452919",
    "end": "458520"
  },
  {
    "text": "name please rest your hand anyone okay I see some people okay",
    "start": "458520",
    "end": "465680"
  },
  {
    "text": "and the second one okay the third",
    "start": "465680",
    "end": "471720"
  },
  {
    "text": "one yeah thank you thank you so much and the uh the fourth",
    "start": "471720",
    "end": "478319"
  },
  {
    "text": "one okay and last one okay uh I I already see some people",
    "start": "478319",
    "end": "486479"
  },
  {
    "text": "has right lay hand uh multiple part time uh that means you are correct yeah",
    "start": "486479",
    "end": "492599"
  },
  {
    "text": "because in fact this Five Command can print out host name uh somehow last one is a little tricky because we cut down",
    "start": "492599",
    "end": "499720"
  },
  {
    "text": "cut out the last part of the partial yeah but what I want to highlight here is that even so a very simple thing like",
    "start": "499720",
    "end": "507319"
  },
  {
    "text": "uh host n we will have a lot of different way to represent it so uh",
    "start": "507319",
    "end": "513360"
  },
  {
    "text": "recognizing uh the command line functionality is not easy task um not to",
    "start": "513360",
    "end": "518760"
  },
  {
    "text": "mention how to develop a writing detection rule so let's bring out our",
    "start": "518760",
    "end": "524000"
  },
  {
    "text": "today's challenge so to analyze Comm the first challenge uh in this synthetic problem",
    "start": "524000",
    "end": "531839"
  },
  {
    "text": "uh first thing we would like to can we parse the common line correctly and",
    "start": "531839",
    "end": "537040"
  },
  {
    "text": "precisely but however it's not easy people may think why not we just don't use the Comm light passer to pass the",
    "start": "537040",
    "end": "544000"
  },
  {
    "text": "Comm line and everything will go well uh but however in many case we are not only",
    "start": "544000",
    "end": "549120"
  },
  {
    "text": "deal with the um Microsoft build-in program in a lot of case we have a s uh",
    "start": "549120",
    "end": "554720"
  },
  {
    "text": "third parties application software uh and some program developed by their by",
    "start": "554720",
    "end": "560360"
  },
  {
    "text": "uh the customer lens self so for this customized software the parameter format",
    "start": "560360",
    "end": "566640"
  },
  {
    "text": "is unknown for us yeah for example here the q1 yeah is Av dump uh this is a",
    "start": "566640",
    "end": "574720"
  },
  {
    "text": "benign program uh in the antivirus software but however the uh Thor can",
    "start": "574720",
    "end": "580720"
  },
  {
    "text": "abuse it to dump the process memory uh yeah so this is command like with",
    "start": "580720",
    "end": "586920"
  },
  {
    "text": "hunting in the wild so in this case we doesn't know anything about the format",
    "start": "586920",
    "end": "592760"
  },
  {
    "text": "yeah and much more difficult thing is that uh some uh parameter let may be",
    "start": "592760",
    "end": "600320"
  },
  {
    "text": "encoding in some specifi data format like Jon and some program may have their",
    "start": "600320",
    "end": "606519"
  },
  {
    "text": "own query language like wmi lb and c and",
    "start": "606519",
    "end": "611839"
  },
  {
    "text": "moreover uh some parameter you can directly put the whole program inside",
    "start": "611839",
    "end": "616880"
  },
  {
    "text": "like the python partial and datet so today if I want to pause the com light",
    "start": "616880",
    "end": "622680"
  },
  {
    "text": "correctly it's not only a problem of commite self we need to par in uh uh",
    "start": "622680",
    "end": "628640"
  },
  {
    "text": "many different data format and quy language or even the whole language so it's",
    "start": "628640",
    "end": "635079"
  },
  {
    "text": "invisible to uh Implement a commite passer to finish all",
    "start": "635079",
    "end": "640560"
  },
  {
    "text": "things and uh much more difficult is that a taker will try to alcate L",
    "start": "640560",
    "end": "647040"
  },
  {
    "text": "command and make you hard to analysis yeah so lay has a dozens of a command",
    "start": "647040",
    "end": "652440"
  },
  {
    "text": "alation technique is available yeah so for example the Q2 here you can see uh",
    "start": "652440",
    "end": "661040"
  },
  {
    "text": "the taker can put some special character here and make the appearance different",
    "start": "661040",
    "end": "666760"
  },
  {
    "text": "so you cannot easily to uh build a parer or to build a a pattern uh the terer is",
    "start": "666760",
    "end": "674320"
  },
  {
    "text": "easy to event uh this method okay okay so we first we have the synthe uh",
    "start": "674320",
    "end": "681639"
  },
  {
    "text": "synthetic problem uh and the next we also have a",
    "start": "681639",
    "end": "686680"
  },
  {
    "text": "semantic problem yeah uh can we build a system like can realize what happened uh",
    "start": "686680",
    "end": "693040"
  },
  {
    "text": "in the command uh here we point out two uh two question the first one is that",
    "start": "693040",
    "end": "698240"
  },
  {
    "text": "you can see here the Q three we have the three schedule task keyword here but",
    "start": "698240",
    "end": "703560"
  },
  {
    "text": "however every keyword is a different meaning the first one is a command the second one is a name of the task and the",
    "start": "703560",
    "end": "710079"
  },
  {
    "text": "third one is a file name so you can see even so the same keyword may have a different meaning so we can directly use",
    "start": "710079",
    "end": "716440"
  },
  {
    "text": "the uh pattern and keyword to make match it and also on the other hand we have a",
    "start": "716440",
    "end": "722279"
  },
  {
    "text": "different keyword but have the same meaning like the Q4 here the first line is a normal mimik card command but",
    "start": "722279",
    "end": "730240"
  },
  {
    "text": "however the second one even so it's mimik cards uh if we observe the whole",
    "start": "730240",
    "end": "735760"
  },
  {
    "text": "command line is more like the RG command like trying to uh dump the ret tree yeah",
    "start": "735760",
    "end": "742199"
  },
  {
    "text": "and the third one even so it's name is a Mer but however uh depend on who command",
    "start": "742199",
    "end": "749320"
  },
  {
    "text": "argument you are more likely to be a mimik Cuts so in this case we can see",
    "start": "749320",
    "end": "754680"
  },
  {
    "text": "even so the first one and the third one uh they are different keyword but have the same meaning so this makes we",
    "start": "754680",
    "end": "761880"
  },
  {
    "text": "analyze command line much more uh difficult and if so we can conquer these",
    "start": "761880",
    "end": "767720"
  },
  {
    "text": "two question uh we will have the other problem lies uh contextual problem uh if",
    "start": "767720",
    "end": "775519"
  },
  {
    "text": "we dealing with an instant we are not only need to analyze a single command command we need to analyze maybe 10 or",
    "start": "775519",
    "end": "781720"
  },
  {
    "text": "20s command in the same time yeah so could we identify significant token",
    "start": "781720",
    "end": "787519"
  },
  {
    "text": "based on the contextual information for example uh in the left if left hand side",
    "start": "787519",
    "end": "793839"
  },
  {
    "text": "is a command l in instant but however some comment is useless it's not related",
    "start": "793839",
    "end": "799120"
  },
  {
    "text": "to the attack yeah and maybe it's just uh typing by their it member or it maybe",
    "start": "799120",
    "end": "806079"
  },
  {
    "text": "it's just noisy yeah and the second is that uh when we uh for example for the",
    "start": "806079",
    "end": "813880"
  },
  {
    "text": "P.E and M.E it doesn't have any meaning if we see the command itself but however",
    "start": "813880",
    "end": "821240"
  },
  {
    "text": "if uh we put all the together uh all the command L together then aluminum of this",
    "start": "821240",
    "end": "826800"
  },
  {
    "text": "token are emerging yeah so we can see the p is download by the director via B",
    "start": "826800",
    "end": "834160"
  },
  {
    "text": "at mean and ex cuted to rise L privilege and M that exe is possibly is a mimik",
    "start": "834160",
    "end": "841320"
  },
  {
    "text": "card used to dump the credential and after War the credential is be",
    "start": "841320",
    "end": "846639"
  },
  {
    "text": "discovered by a director so some information uh some keyword doesn't have",
    "start": "846639",
    "end": "852199"
  },
  {
    "text": "any meaning if we see a CA itself but if we put everything together uh he have a",
    "start": "852199",
    "end": "857759"
  },
  {
    "text": "special meaning that's also the one thing that we want to track in so uh for both three uh challenge uh",
    "start": "857759",
    "end": "867079"
  },
  {
    "text": "it's invisible to manually develop the detection rule so we have a synthetic",
    "start": "867079",
    "end": "872120"
  },
  {
    "text": "problem semantic problem and contextual problem and we also have a explanation issue because every time we need to in",
    "start": "872120",
    "end": "880199"
  },
  {
    "text": "to explain to our customer why we believe this is a attack and what happened we need to have a evidence and",
    "start": "880199",
    "end": "886880"
  },
  {
    "text": "a reason for land and how about a problem if we uh every day we may have",
    "start": "886880",
    "end": "894279"
  },
  {
    "text": "hundreds of a malal event a day this may a problem much more difficult so of course we need a um automatic",
    "start": "894279",
    "end": "901920"
  },
  {
    "text": "method that can help us to detect the malicious com line without any rule or",
    "start": "901920",
    "end": "908600"
  },
  {
    "text": "regular expression so that's why we start uh This research and we build a",
    "start": "908600",
    "end": "914040"
  },
  {
    "text": "system uh original we called it Iron Man but however very soon we realize uh it",
    "start": "914040",
    "end": "920480"
  },
  {
    "text": "may have some problem if we use l name yeah so we change our name into a",
    "start": "920480",
    "end": "926880"
  },
  {
    "text": "irmen and this n can also represent like what can help the man or analyst to do",
    "start": "926880",
    "end": "933959"
  },
  {
    "text": "the IR so I think it's a very good name and very C represent what we are doing",
    "start": "933959",
    "end": "939680"
  },
  {
    "text": "okay so next let me go to more detail about our model or algorithm so uh let's",
    "start": "939680",
    "end": "947319"
  },
  {
    "text": "unleash the AI enchanting magic so next part our data science uh Eric will help",
    "start": "947319",
    "end": "954319"
  },
  {
    "text": "help us to go to more deeper and uh introduce every detail of our model so",
    "start": "954319",
    "end": "960759"
  },
  {
    "text": "uh let's wel welcome Eric where here",
    "start": "960759",
    "end": "966319"
  },
  {
    "text": "yeah okay thanks CK and hello everyone my name is Eric and I will introduce the",
    "start": "966319",
    "end": "971920"
  },
  {
    "text": "Iron Man in detail okay and The Story begins from",
    "start": "971920",
    "end": "977560"
  },
  {
    "text": "the second in February of this year and cite embeding model CMD GPT is was",
    "start": "977560",
    "end": "984399"
  },
  {
    "text": "introduced and it it under 1,000 of comment l with self-supervised training",
    "start": "984399",
    "end": "990399"
  },
  {
    "text": "technique so thanks to the extensive com train data CMD GPT is empowered to embed",
    "start": "990399",
    "end": "997240"
  },
  {
    "text": "different comi into a UniFi feature space leveraging their contextual information rather than just relying on",
    "start": "997240",
    "end": "1004120"
  },
  {
    "text": "their worlding and in our experiment CMD gpt's performance is comparable to open",
    "start": "1004120",
    "end": "1010680"
  },
  {
    "text": "invading API on our commun testing data set so with CN GPT we can measure",
    "start": "1010680",
    "end": "1017720"
  },
  {
    "text": "different command analyze similarity easily and we can also carry the similar",
    "start": "1017720",
    "end": "1023040"
  },
  {
    "text": "Comm from our malicious history database and for example here are two comi and",
    "start": "1023040",
    "end": "1030000"
  },
  {
    "text": "although they use different executable file name CMD DT still assign a very high similarity to them because they use",
    "start": "1030000",
    "end": "1037079"
  },
  {
    "text": "the same argument here and this embedding ability can also help a daily incident investigation as",
    "start": "1037079",
    "end": "1044959"
  },
  {
    "text": "well for example presenting a new incident we can first cure the all CI of this news incident",
    "start": "1044959",
    "end": "1052600"
  },
  {
    "text": "and asside each culture with its corresponding behavior and construct the timeline graph as the figure and this",
    "start": "1052600",
    "end": "1059919"
  },
  {
    "text": "enable our analytic can get a comprehensive overview of the incident quickly facilitating further in-depth",
    "start": "1059919",
    "end": "1067840"
  },
  {
    "text": "analysis and inform decision making and but although CMD dri",
    "start": "1067840",
    "end": "1074080"
  },
  {
    "text": "demonstrate very powerful comine eding ability to Earth us but it's still for",
    "start": "1074080",
    "end": "1079600"
  },
  {
    "text": "short of meeting all of our needs for example we do not we are unable to know",
    "start": "1079600",
    "end": "1085919"
  },
  {
    "text": "why this comine are similar why this comine are cluster together in the same",
    "start": "1085919",
    "end": "1091840"
  },
  {
    "text": "group so in this work we will enter okay oh sorry so for such interpretability we",
    "start": "1091840",
    "end": "1098880"
  },
  {
    "text": "believe that the traditional mining algorithm is the one of the approach can",
    "start": "1098880",
    "end": "1105000"
  },
  {
    "text": "provide a very easy understand aable result to us because",
    "start": "1105000",
    "end": "1110880"
  },
  {
    "text": "most of the traditional mind algorithm depends on the simple stret fiing rules",
    "start": "1110880",
    "end": "1116840"
  },
  {
    "text": "and in our experiment traditional mining algorithm M sign significant tokens",
    "start": "1116840",
    "end": "1122799"
  },
  {
    "text": "based on the two simple rules the first is the frequency with the same cluster",
    "start": "1122799",
    "end": "1128480"
  },
  {
    "text": "and the other is the Rarity in other cluster and here we will demonstrate a",
    "start": "1128480",
    "end": "1135039"
  },
  {
    "text": "very simple example to show how traditional mining ARG Reon my significant tokens with the two rules",
    "start": "1135039",
    "end": "1143200"
  },
  {
    "text": "and here are two cler cluster one and cluster two and the objective here is we want to M the significant reason for why",
    "start": "1143200",
    "end": "1151559"
  },
  {
    "text": "this two command are cluster in the cluster one and we have to identify two",
    "start": "1151559",
    "end": "1157240"
  },
  {
    "text": "candidate reason token Echo and token mimik exe let's start from the token Echo we",
    "start": "1157240",
    "end": "1164960"
  },
  {
    "text": "can check whether it follow the rule one and the token Echo appears in two commi",
    "start": "1164960",
    "end": "1171440"
  },
  {
    "text": "in the cluster one the satifying the rle one but when we check for the rur two we",
    "start": "1171440",
    "end": "1177360"
  },
  {
    "text": "will found that the token Echo also appears in the both C in the cluster two",
    "start": "1177360",
    "end": "1182919"
  },
  {
    "text": "which contracted the r two so we can moving on to the second token mimik exe",
    "start": "1182919",
    "end": "1191360"
  },
  {
    "text": "and we found that the mimik card Dy satisfy the rule one frequency with the",
    "start": "1191360",
    "end": "1196640"
  },
  {
    "text": "S cluster and the second rural reality in our culture at the same time so we",
    "start": "1196640",
    "end": "1203000"
  },
  {
    "text": "can confidently determine that the token mimik cat.exe is the significant token",
    "start": "1203000",
    "end": "1208559"
  },
  {
    "text": "for the Custer one in this case and but although this traditional",
    "start": "1208559",
    "end": "1215679"
  },
  {
    "text": "mining algorithm can provide a very easy understandable result based on the simple stral filtering scheme but it is",
    "start": "1215679",
    "end": "1224120"
  },
  {
    "text": "susceptable to the even the slightest change in the Comon light for example if",
    "start": "1224120",
    "end": "1229520"
  },
  {
    "text": "we if we modify the token mimic cuts. exe in the one comi with the cluster one",
    "start": "1229520",
    "end": "1236240"
  },
  {
    "text": "to the Token Nast dixe and the first rule frequency with the S cluster will",
    "start": "1236240",
    "end": "1242280"
  },
  {
    "text": "no longer be satisfied and so we in this work the",
    "start": "1242280",
    "end": "1248960"
  },
  {
    "text": "question we want to address is can we analyze the incident analyze the",
    "start": "1248960",
    "end": "1254039"
  },
  {
    "text": "commment life from the perspective of context as the CMD GP does while also",
    "start": "1254039",
    "end": "1259679"
  },
  {
    "text": "providing very easy understandable result as traditional mining",
    "start": "1259679",
    "end": "1264880"
  },
  {
    "text": "algorithm and based on this motivation we propos the IR on men here and",
    "start": "1264880",
    "end": "1270960"
  },
  {
    "text": "interpretable incident specture and Iron Man has two Key Properties the first is",
    "start": "1270960",
    "end": "1276679"
  },
  {
    "text": "that Iron Man can investigate the incident from the context of P from the",
    "start": "1276679",
    "end": "1281960"
  },
  {
    "text": "context perspective based on a CMD GPT and next is Iron Man can m a significant",
    "start": "1281960",
    "end": "1288919"
  },
  {
    "text": "token directly in the future space and this allowed Iron Man can overcome the",
    "start": "1288919",
    "end": "1295480"
  },
  {
    "text": "limitation of traditional mining agism we mentioned above and this significant",
    "start": "1295480",
    "end": "1301120"
  },
  {
    "text": "token can also serve as a strong and understandable evidence to support our",
    "start": "1301120",
    "end": "1307039"
  },
  {
    "text": "investigation result and given a malicious com to iron",
    "start": "1307039",
    "end": "1312720"
  },
  {
    "text": "Iran can help us to m a significant token of this of this malicious Comm",
    "start": "1312720",
    "end": "1318120"
  },
  {
    "text": "light and this significant token can be transferred into the sigma rule or The",
    "start": "1318120",
    "end": "1323679"
  },
  {
    "text": "Black List further to help ourc and",
    "start": "1323679",
    "end": "1328720"
  },
  {
    "text": "analyze and this is a big picture of ironment and present a new incident we",
    "start": "1328720",
    "end": "1335520"
  },
  {
    "text": "first will collect the all commi logs from our EDI engine and next we will",
    "start": "1335520",
    "end": "1340919"
  },
  {
    "text": "inent all commi L into our into a un UniFi feature spare using CMD GPT and in",
    "start": "1340919",
    "end": "1348520"
  },
  {
    "text": "this feature sp there are some other commi for example AP campaigns malicious",
    "start": "1348520",
    "end": "1353799"
  },
  {
    "text": "commi and some rating rating Camp malici com L we collect before so we can",
    "start": "1353799",
    "end": "1359640"
  },
  {
    "text": "directly in the unify fatures SP to Mining and compare with this malicious",
    "start": "1359640",
    "end": "1365279"
  },
  {
    "text": "CI to M significant token for this new insurance CI and in our case there are hundreds of",
    "start": "1365279",
    "end": "1373640"
  },
  {
    "text": "malicious event or Comm per day but with Iron Man we can M signif significant",
    "start": "1373640",
    "end": "1380919"
  },
  {
    "text": "token for all of this malicious car easily and it's worth to note that Iron",
    "start": "1380919",
    "end": "1387480"
  },
  {
    "text": "Man do not adopt any exact match mechanism like Sigma rule or regular",
    "start": "1387480",
    "end": "1393240"
  },
  {
    "text": "expression in our entire IR analysis pipeline okay and here's the",
    "start": "1393240",
    "end": "1399919"
  },
  {
    "text": "introduction part and next we will talk about how Iron Man M significant token in the feature space",
    "start": "1399919",
    "end": "1406720"
  },
  {
    "text": "directly and to m a significant token The crucial TX is to evaluate the",
    "start": "1406720",
    "end": "1413000"
  },
  {
    "text": "token's importances and in our experiment we we found that we can",
    "start": "1413000",
    "end": "1418600"
  },
  {
    "text": "measure the tokens importances by observing the similarity change when we",
    "start": "1418600",
    "end": "1424159"
  },
  {
    "text": "remove the token from common L and for example here are two common L and both",
    "start": "1424159",
    "end": "1429559"
  },
  {
    "text": "are correlated with MIM c. exe and if we calculate the similarity between these",
    "start": "1429559",
    "end": "1435080"
  },
  {
    "text": "two com we will get the similarity is zero down 91 and next if we want to evaluate token",
    "start": "1435080",
    "end": "1442440"
  },
  {
    "text": "mimas Dix's importes we can remove this token from commi and calculate the",
    "start": "1442440",
    "end": "1447960"
  },
  {
    "text": "similarity again and I'm doing so we will observe a drop in similarity from",
    "start": "1447960",
    "end": "1453880"
  },
  {
    "text": "l. 91 to l. f43 indicating a loss of l.",
    "start": "1453880",
    "end": "1459440"
  },
  {
    "text": "58 and this Pro process can also be adapt to different token like token Echo",
    "start": "1459440",
    "end": "1466520"
  },
  {
    "text": "and token syst two and after calculating all import score for all our token we",
    "start": "1466520",
    "end": "1473120"
  },
  {
    "text": "can find that the token Mimi cards exceed be the largest similarity loss in",
    "start": "1473120",
    "end": "1478679"
  },
  {
    "text": "this case this result also indicate the MIM cast. exe is the significant token",
    "start": "1478679",
    "end": "1484000"
  },
  {
    "text": "for L for the similarity between these two Comon",
    "start": "1484000",
    "end": "1489120"
  },
  {
    "text": "line and so for now we have approach can evaluate tokens importes but the other",
    "start": "1489120",
    "end": "1495840"
  },
  {
    "text": "question is how do we tokenize the comp L appropriately and this test is",
    "start": "1495840",
    "end": "1501039"
  },
  {
    "text": "particular challenge because and especially for commi because",
    "start": "1501039",
    "end": "1506720"
  },
  {
    "text": "of the commi flexibility syntax and the flexibility",
    "start": "1506720",
    "end": "1512520"
  },
  {
    "text": "structure so here's example is a very simple Ki how do we tokenize this Ki",
    "start": "1512520",
    "end": "1519120"
  },
  {
    "text": "into the miningful pieces and we be believe the first approach we will try",
    "start": "1519120",
    "end": "1524159"
  },
  {
    "text": "is divided by the space but this will produce some unexpected token for",
    "start": "1524159",
    "end": "1529600"
  },
  {
    "text": "example a program file x etic 6 directory is divided into three",
    "start": "1529600",
    "end": "1534720"
  },
  {
    "text": "different tokens and x86 is even group with the text DXE and argument goo in",
    "start": "1534720",
    "end": "1541039"
  },
  {
    "text": "this case and we think that if you directly evaluate important C go with this unexpected token it will lead some",
    "start": "1541039",
    "end": "1549080"
  },
  {
    "text": "inaccuracy for our significant token mining assessment so the next step we must well",
    "start": "1549080",
    "end": "1556600"
  },
  {
    "text": "try to design a very good regular expression to help her to tokenize this common line but in our experiment",
    "start": "1556600",
    "end": "1564080"
  },
  {
    "text": "crafting a good regular commi to for all and regular expression for all commi is",
    "start": "1564080",
    "end": "1570679"
  },
  {
    "text": "a nontrivial and time consuming text so we think we need a more straightforward",
    "start": "1570679",
    "end": "1575960"
  },
  {
    "text": "tokenizer in here and before we decide a good tokenizer we must first Define what",
    "start": "1575960",
    "end": "1583159"
  },
  {
    "text": "qualify as a good tokens and we believe that uh the token should represent the",
    "start": "1583159",
    "end": "1589440"
  },
  {
    "text": "complete meaning by itself for example a token should represent the entire file name entire directory n or entire",
    "start": "1589440",
    "end": "1597120"
  },
  {
    "text": "argument so for the simple example coming line we believe the ideal token",
    "start": "1597120",
    "end": "1602399"
  },
  {
    "text": "set will look like this this token and to ensure we can tokenize each",
    "start": "1602399",
    "end": "1609120"
  },
  {
    "text": "comma into appropriate meaningful pieces we propose a minifold tokenizer to help",
    "start": "1609120",
    "end": "1615320"
  },
  {
    "text": "do this job and minifold tokenizer is a commite oranization specific language",
    "start": "1615320",
    "end": "1621120"
  },
  {
    "text": "model and to train this model we first collect about 4,000 4,000 comi and layers",
    "start": "1621120",
    "end": "1629840"
  },
  {
    "text": "corresponding ideal token set and next we finding a open source pre train language model and this train data with",
    "start": "1629840",
    "end": "1637360"
  },
  {
    "text": "the castle uped so after training the mini phizer given a different commi Min",
    "start": "1637360",
    "end": "1643840"
  },
  {
    "text": "tokenizer can help her to token this commi into the ideal token in just one forward",
    "start": "1643840",
    "end": "1650039"
  },
  {
    "text": "pass and here's the actual example for the mini for tokenizer given this",
    "start": "1650039",
    "end": "1655279"
  },
  {
    "text": "complicate common light the meanful tokenizer can still help her to tokenize",
    "start": "1655279",
    "end": "1661080"
  },
  {
    "text": "this common light to the meanful P accurately and okay and for now we have",
    "start": "1661080",
    "end": "1668399"
  },
  {
    "text": "approach can evaluate tokens importances and we also have miningful tokenizer can",
    "start": "1668399",
    "end": "1673600"
  },
  {
    "text": "help her to tokenize different Comm L into the meaningful pieces and next we can start to m a significant token in",
    "start": "1673600",
    "end": "1680919"
  },
  {
    "text": "the feature space and we I will show you how ironment Min a signifant token with",
    "start": "1680919",
    "end": "1687080"
  },
  {
    "text": "a very simple example here so we just take one query com L to demonstrate how",
    "start": "1687080",
    "end": "1693600"
  },
  {
    "text": "to demonstrate a mining argon and not that this mining argon can be extend to",
    "start": "1693600",
    "end": "1699159"
  },
  {
    "text": "multiple Comm line or cluster of command and the first de if we have a",
    "start": "1699159",
    "end": "1706600"
  },
  {
    "text": "query command we should embed the comine into embeding Vector using CMD GPT and",
    "start": "1706600",
    "end": "1712360"
  },
  {
    "text": "carry the similar incident or qu a similar Comm line from our malicious command database and in this case we can",
    "start": "1712360",
    "end": "1719480"
  },
  {
    "text": "find there are three incident has similar command line with the query Comm line and next we can keep expand the",
    "start": "1719480",
    "end": "1727960"
  },
  {
    "text": "inser three and we will abser there two Comm line are similar to The quy comand like",
    "start": "1727960",
    "end": "1734320"
  },
  {
    "text": "here and to m a significant token of query Comm L we should tokenize this",
    "start": "1734320",
    "end": "1741200"
  },
  {
    "text": "Comm L using our minall tokenizer first and after tokenizing we will get this",
    "start": "1741200",
    "end": "1746720"
  },
  {
    "text": "token so with this token we can calculate the importancy score between",
    "start": "1746720",
    "end": "1751960"
  },
  {
    "text": "all token and each comand line in the insert three for example we can first",
    "start": "1751960",
    "end": "1758399"
  },
  {
    "text": "calculate the importance score between a token and the first com line in the inent three and keep going for the",
    "start": "1758399",
    "end": "1764960"
  },
  {
    "text": "second Comon line and after calculating all important score we can leverage the concept of",
    "start": "1764960",
    "end": "1772480"
  },
  {
    "text": "traditional mining aggon here to adapt a stral filter to get the significant",
    "start": "1772480",
    "end": "1778120"
  },
  {
    "text": "token for the incidence three and not that we apply this stral filtering on",
    "start": "1778120",
    "end": "1784320"
  },
  {
    "text": "the important scroll instead of the token directly which allows Iron Man can",
    "start": "1784320",
    "end": "1790159"
  },
  {
    "text": "overcome the limitation of the traditional M mining argm we mentioned earlier and only aert only the token has",
    "start": "1790159",
    "end": "1798559"
  },
  {
    "text": "certain degree of importantance score for the certain proportion coming life in the incident three will be retained",
    "start": "1798559",
    "end": "1805360"
  },
  {
    "text": "so this significant token can also serve as a EV strong and understandable",
    "start": "1805360",
    "end": "1810799"
  },
  {
    "text": "evidence for our investigation result and this process can also be",
    "start": "1810799",
    "end": "1817240"
  },
  {
    "text": "adapt to different incident for example incident one incident two and incident three to m a different significant token",
    "start": "1817240",
    "end": "1824240"
  },
  {
    "text": "for different incident here so we must we should apply one more stret of",
    "start": "1824240",
    "end": "1829880"
  },
  {
    "text": "filtering here to get the true significant token of the query coming light and the significant token of Cur",
    "start": "1829880",
    "end": "1837960"
  },
  {
    "text": "Ki here has the positive impact for the most Ki in the most incident",
    "start": "1837960",
    "end": "1845519"
  },
  {
    "text": "here okay and that's all about how Iron Man m a significant token in the feature",
    "start": "1845519",
    "end": "1851919"
  },
  {
    "text": "spec directory and next my colleague George Will in demonstrate some",
    "start": "1851919",
    "end": "1857360"
  },
  {
    "text": "experiment result about our testing data and our real world data data okay thank",
    "start": "1857360",
    "end": "1865480"
  },
  {
    "text": "you hi there I'm George so uh thank you Eric for his very detailed introduction",
    "start": "1865600",
    "end": "1871159"
  },
  {
    "text": "to our system and our work so uh in this part I will start to introduce uh how",
    "start": "1871159",
    "end": "1876600"
  },
  {
    "text": "our experiment result is so the first thing is that uh as you can mention the",
    "start": "1876600",
    "end": "1881639"
  },
  {
    "text": "Min uh minif tokenizer is really important to our system so the first thing we want to tell is how you perform",
    "start": "1881639",
    "end": "1889080"
  },
  {
    "text": "so uh in this case we select uh manually select 400 different uh types of command",
    "start": "1889080",
    "end": "1894880"
  },
  {
    "text": "line and as our uh in-house security analyst to token tokenize it and also",
    "start": "1894880",
    "end": "1900320"
  },
  {
    "text": "label it for us as a gr TRS and here is the uh two different types of tokenizer",
    "start": "1900320",
    "end": "1906639"
  },
  {
    "text": "the first is the space tokenizer and the second will be our proposed uh uh minif",
    "start": "1906639",
    "end": "1913559"
  },
  {
    "text": "tokenizers and uh the metric we are measuring is using the uh intersection",
    "start": "1913559",
    "end": "1918760"
  },
  {
    "text": "of the Union so which basically meaning that how many produced tokenized tokens",
    "start": "1918760",
    "end": "1924360"
  },
  {
    "text": "are matched with the uh the one uh labeled by our uh expert so as you can",
    "start": "1924360",
    "end": "1930200"
  },
  {
    "text": "see in the figure uh our Min tooner is about 20% much better than the uh space",
    "start": "1930200",
    "end": "1936600"
  },
  {
    "text": "uh tokenizer and only with about less than 5% of the overhead in the",
    "start": "1936600",
    "end": "1942399"
  },
  {
    "text": "computation and we we even run this uh experiment on the uhv are 30 90 so you",
    "start": "1942399",
    "end": "1949279"
  },
  {
    "text": "don't need to have a very fancy like a00 or even uh h00 and also I know you know",
    "start": "1949279",
    "end": "1956320"
  },
  {
    "text": "this type of know small scale testing would be very boring for you so we actually apply it on a real world",
    "start": "1956320",
    "end": "1963080"
  },
  {
    "text": "scenario so about two months ago uh one of our customer is actually having a red",
    "start": "1963080",
    "end": "1968960"
  },
  {
    "text": "team exercise so uh this customer had about 5,000 endpoint at at the moment so",
    "start": "1968960",
    "end": "1976600"
  },
  {
    "text": "uh let's look up uh um how our uh Iron Man performed so let's look at the uh",
    "start": "1976600",
    "end": "1982360"
  },
  {
    "text": "recover first so uh during the 3 week of the red te exercise uh there were uh 38",
    "start": "1982360",
    "end": "1989279"
  },
  {
    "text": "end points were breached by the rep te and uh among all these three 38 uh end",
    "start": "1989279",
    "end": "1995440"
  },
  {
    "text": "point uh our system is say uh is uh our expert is able to identify there are",
    "start": "1995440",
    "end": "2003159"
  },
  {
    "text": "257 uh malicious command uh as a gr Tru so uh how Iron Man Works uh we actually",
    "start": "2003159",
    "end": "2010799"
  },
  {
    "text": "perform quite well so actually uh we only miss eight com9 out of uh",
    "start": "2010799",
    "end": "2017159"
  },
  {
    "text": "257 uh commands and in regarding to the uh Precision uh during this three weeks",
    "start": "2017159",
    "end": "2023840"
  },
  {
    "text": "uh exercise we actually collect about 7.3 Millions Comm from these specific",
    "start": "2023840",
    "end": "2029799"
  },
  {
    "text": "customers and we uh our system is able to Flat 291 command as a malicious",
    "start": "2029799",
    "end": "2036159"
  },
  {
    "text": "command and and we only uh uh uh miss about 42 uh uh false positive uh command",
    "start": "2036159",
    "end": "2044159"
  },
  {
    "text": "as uh as a malicious one so I would say uh the result is quite promising even on",
    "start": "2044159",
    "end": "2049760"
  },
  {
    "text": "the real world uh scenario so uh let's recall back to the from the very",
    "start": "2049760",
    "end": "2055480"
  },
  {
    "text": "beginning from the C case part so he throw out some challenges to you so how our system is actually working on these",
    "start": "2055480",
    "end": "2062240"
  },
  {
    "text": "challenges so the first challenge will be the synthetic uh uh CTIC uh problem",
    "start": "2062240",
    "end": "2067878"
  },
  {
    "text": "so actually even with the unknown or unseen files or the exclusions we are",
    "start": "2067879",
    "end": "2073480"
  },
  {
    "text": "still able to cut the significant token out of it and we are still able to do",
    "start": "2073480",
    "end": "2079000"
  },
  {
    "text": "perform like the simility uh testing or the crossing out of it",
    "start": "2079000",
    "end": "2085398"
  },
  {
    "text": "and for the uh another example is that uh even these two command are look",
    "start": "2085399",
    "end": "2091240"
  },
  {
    "text": "completely different and with OBS station uh they are basically doing the same thing it's just remove the shot the",
    "start": "2091240",
    "end": "2097118"
  },
  {
    "text": "volume from your uh Windows uh machines so uh um by applying our Iron Man system",
    "start": "2097119",
    "end": "2104920"
  },
  {
    "text": "on you we are still uh we are uh very confident and we we can perform very well to Cluster uh these coming together",
    "start": "2104920",
    "end": "2113040"
  },
  {
    "text": "because they have the same intention so uh this is another good part for our system and for the Second Challenge will",
    "start": "2113040",
    "end": "2119720"
  },
  {
    "text": "be the semantic problem so uh for example the the command that CK you is",
    "start": "2119720",
    "end": "2125480"
  },
  {
    "text": "that uh this one so uh we got three schedule task in this comand which token",
    "start": "2125480",
    "end": "2131359"
  },
  {
    "text": "would be the most important one for the security analyst uh so in the traditional way it's really hard for the",
    "start": "2131359",
    "end": "2137680"
  },
  {
    "text": "traditional algorithm to tell that but in our system we are able to precisely tell you which token is the most",
    "start": "2137680",
    "end": "2145680"
  },
  {
    "text": "significant one with the significant token scores and for the uh the final uh",
    "start": "2145680",
    "end": "2152800"
  },
  {
    "text": "example is that the mimicas so um we change the mimicas file name or we uh",
    "start": "2152800",
    "end": "2158520"
  },
  {
    "text": "deliberately change the reg.exe to mimicas and we are trying to see okay if",
    "start": "2158520",
    "end": "2164119"
  },
  {
    "text": "our system is able to tell the difference between these three commands so for for the first example uh even",
    "start": "2164119",
    "end": "2171119"
  },
  {
    "text": "though is all called mimicas but by our system we are able to tell because the",
    "start": "2171119",
    "end": "2176680"
  },
  {
    "text": "uh by the the format it is and also the argument itself it can clearly show you",
    "start": "2176680",
    "end": "2182359"
  },
  {
    "text": "they are not that similar When comparing to the the second part even the argument is different the extension file name is",
    "start": "2182359",
    "end": "2189200"
  },
  {
    "text": "different our system is precisely tell you okay it's a work they are very very similar and the security expert should",
    "start": "2189200",
    "end": "2195960"
  },
  {
    "text": "uh pay more attention to it so I know talk is cheap and we want we Al always",
    "start": "2195960",
    "end": "2202800"
  },
  {
    "text": "want to show some code so we actually build up a demo site for you guys so uh",
    "start": "2202800",
    "end": "2207960"
  },
  {
    "text": "please take a picture on our uh on this slide and here is our demo s is at iron",
    "start": "2207960",
    "end": "2214160"
  },
  {
    "text": "man. c. a so in this website you are able to you know just follow very simple",
    "start": "2214160",
    "end": "2219800"
  },
  {
    "text": "process uh a very simple step and we'll provide you a very simple power script",
    "start": "2219800",
    "end": "2224880"
  },
  {
    "text": "uh shell to collect your comments and you just upload it to it and then after",
    "start": "2224880",
    "end": "2230160"
  },
  {
    "text": "just few minutes and you are able to receive a email link open it uh I promise you won't be efficient email so",
    "start": "2230160",
    "end": "2237400"
  },
  {
    "text": "it will be safe so you just open it you can see this very beautiful uh web page",
    "start": "2237400",
    "end": "2242760"
  },
  {
    "text": "it will precise tell you the severity of your input comment and also we flag out all the significant",
    "start": "2242760",
    "end": "2250000"
  },
  {
    "text": "tokens on the on your comp L by the callers so as a security expert or",
    "start": "2250000",
    "end": "2255440"
  },
  {
    "text": "analyst you it's very easy for you to you know just tell it by the uh colors",
    "start": "2255440",
    "end": "2261079"
  },
  {
    "text": "and the best thing is about our uh demo side is that we also provide a functionality that you can actually",
    "start": "2261079",
    "end": "2267520"
  },
  {
    "text": "export your significant token to the uh Sigma rules so once you got your Sigma",
    "start": "2267520",
    "end": "2273520"
  },
  {
    "text": "rules you can easily compile these rules to all your existing uh s systems and to",
    "start": "2273520",
    "end": "2280520"
  },
  {
    "text": "help you to hunt uh more uh future uh common so uh that's uh pretty much",
    "start": "2280520",
    "end": "2287599"
  },
  {
    "text": "everything and uh here's our final takeaway so the first thing uh working on this project I think the most",
    "start": "2287599",
    "end": "2293359"
  },
  {
    "text": "important thing is that uh we think uh understand the nature of your Comon is",
    "start": "2293359",
    "end": "2298800"
  },
  {
    "text": "uh uh nature of your data is very important because a lot of people will say okay comma is just look like a bunch",
    "start": "2298800",
    "end": "2305160"
  },
  {
    "text": "of very long sentence why don't we just apply the larer language model and deal with it and the reality is that it's",
    "start": "2305160",
    "end": "2311760"
  },
  {
    "text": "really really hard to get a really good uh result from it so domain knowledge",
    "start": "2311760",
    "end": "2316800"
  },
  {
    "text": "especially uh when you're trying to apply this type of large language model on your field please always remember ask",
    "start": "2316800",
    "end": "2324720"
  },
  {
    "text": "the security expert to incorporate with them with their knowledge and will help you to achieve much much better result",
    "start": "2324720",
    "end": "2331680"
  },
  {
    "text": "and the second thing is that uh our work is uh clear show you that there are",
    "start": "2331680",
    "end": "2338240"
  },
  {
    "text": "strong evidence that malicias come out especially for many different uh thre actors they will have the very similar",
    "start": "2338240",
    "end": "2345520"
  },
  {
    "text": "and significant tokens so it's really easy to utilize the system like this to",
    "start": "2345520",
    "end": "2351640"
  },
  {
    "text": "identify this and also you can transfer it into the schar rule to hunt the future attack and the last point would",
    "start": "2351640",
    "end": "2359040"
  },
  {
    "text": "be uh we actually find uh by this research we actually find there are many many opportunities on the com research",
    "start": "2359040",
    "end": "2367480"
  },
  {
    "text": "so we encourage your guys to know uh explore in this area for example like",
    "start": "2367480",
    "end": "2372839"
  },
  {
    "text": "the uh communite cor relations or the uh com uh smart search within the comment",
    "start": "2372839",
    "end": "2378520"
  },
  {
    "text": "line and lastly and please don't forget take a picture about our slide and uh",
    "start": "2378520",
    "end": "2385000"
  },
  {
    "text": "especially the demo SL link and give you a try and we are more than help you more than happy to hear the result from you",
    "start": "2385000",
    "end": "2392720"
  },
  {
    "text": "guys thank you guys",
    "start": "2392720",
    "end": "2398400"
  },
  {
    "text": "uh I don't think I think we don't have time for a question but we will add the uh Retro Room so you you if you guys",
    "start": "2400280",
    "end": "2405880"
  },
  {
    "text": "have more questions we are more than happy to answer it thank",
    "start": "2405880",
    "end": "2411000"
  },
  {
    "text": "you",
    "start": "2411800",
    "end": "2414800"
  }
]
[
  {
    "text": "[Music]",
    "start": "1130",
    "end": "13599"
  },
  {
    "text": "hi everyone and thank you for joining our talk have for one our journey of fuzzing hyper-v and discovering a zero",
    "start": "13599",
    "end": "19920"
  },
  {
    "text": "day we'll start by introducing ourselves hi my name is pele radar i'm a senior",
    "start": "19920",
    "end": "25439"
  },
  {
    "text": "security researcher at seybridge cyber security company which provides a bridge and attack simulation product which",
    "start": "25439",
    "end": "31679"
  },
  {
    "text": "helps customers to validate their own security controls my main focus is on windows internals",
    "start": "31679",
    "end": "37520"
  },
  {
    "text": "vulnerability research and hypervisors and i also gave a talk last year on black tsa and defcon my name is ophir",
    "start": "37520",
    "end": "45280"
  },
  {
    "text": "harpaz i'm a senior security researcher at guardicore labs the research arm of guardicore which is a segmentation",
    "start": "45280",
    "end": "51600"
  },
  {
    "text": "company disrupting the legacy firewall market i'm excited by anything low-level",
    "start": "51600",
    "end": "56800"
  },
  {
    "text": "and also the author of begin.re a free online tutorial for beginners in reverse",
    "start": "56800",
    "end": "62239"
  },
  {
    "text": "engineering so why hyper-v in the first place in the",
    "start": "62239",
    "end": "68560"
  },
  {
    "text": "recent years many businesses and companies have moved major parts of their workloads to public",
    "start": "68560",
    "end": "74720"
  },
  {
    "text": "clouds and one of these clouds is microsoft azure now the virtualization technology under",
    "start": "74720",
    "end": "81360"
  },
  {
    "text": "uh the underlying technology for microsoft azure is hyper-v and we all",
    "start": "81360",
    "end": "86640"
  },
  {
    "text": "know that vulnerabilities and cloud infrastructure have massive critical impacts on our information security so",
    "start": "86640",
    "end": "94000"
  },
  {
    "text": "we decided to focus on targeting hyper-v",
    "start": "94000",
    "end": "99280"
  },
  {
    "text": "and a couple of things we need to know before we dig into this talk some 101 on hyper-v itself",
    "start": "99280",
    "end": "106479"
  },
  {
    "text": "there are two types of partitions running on top of a hyper-v host the first is the root partition where the",
    "start": "106479",
    "end": "112479"
  },
  {
    "text": "main operating system runs the host's operating system and the child partition is where any",
    "start": "112479",
    "end": "118079"
  },
  {
    "text": "guest operating system runs any virtual machine and there can be multiple child partitions",
    "start": "118079",
    "end": "124560"
  },
  {
    "text": "now to provide the child partitions with hardware services hyper-v implements",
    "start": "124560",
    "end": "130319"
  },
  {
    "text": "power virtualized devices that consists of a pair for each hardware device",
    "start": "130319",
    "end": "136640"
  },
  {
    "text": "the vsp is the virtualized service provider which runs in on the root partition",
    "start": "136640",
    "end": "142959"
  },
  {
    "text": "and the consumer or the vsc runs in the child partition",
    "start": "142959",
    "end": "148160"
  },
  {
    "text": "they both communicate over vmbus which is an inter-partition communication channel",
    "start": "148160",
    "end": "153599"
  },
  {
    "text": "and whenever it needs to the vsp communicates with the hardware itself through the vmm the virtual machine",
    "start": "153599",
    "end": "159760"
  },
  {
    "text": "monitor in our research the target was vm switch",
    "start": "159760",
    "end": "165440"
  },
  {
    "text": "which is the vsp virtualized service provider responsible for networking in hyper-v",
    "start": "165440",
    "end": "172640"
  },
  {
    "text": "another question to ask is why fuzzing so we decided that fuzzing would be",
    "start": "173280",
    "end": "179440"
  },
  {
    "text": "ideal for us because once we have a good efficient fuzzer this will be",
    "start": "179440",
    "end": "185360"
  },
  {
    "text": "scalable and we can find hopefully more than one bug and also our target vm switch is quite a",
    "start": "185360",
    "end": "192000"
  },
  {
    "text": "huge binary and we figured that right reading its code would be quite a",
    "start": "192000",
    "end": "197599"
  },
  {
    "text": "tedious task so we went for fuzzing and now some basic concepts in fuzzing",
    "start": "197599",
    "end": "203360"
  },
  {
    "text": "what does a fuzzing infrastructure consist of the core component of a fuzzing",
    "start": "203360",
    "end": "208640"
  },
  {
    "text": "infrastructure is the harness the harness is the core component responsible for sending fuzzing inputs",
    "start": "208640",
    "end": "215280"
  },
  {
    "text": "to the target software and there are a couple of more components that make a fuzzer actually",
    "start": "215280",
    "end": "221440"
  },
  {
    "text": "great in terms of efficiency and performance the first one is coverage guidance this",
    "start": "221440",
    "end": "226720"
  },
  {
    "text": "means that for every fuzzing input we send to the target we receive feedback",
    "start": "226720",
    "end": "231840"
  },
  {
    "text": "on which lines of code exactly were covered and therefore we can drive a more efficient",
    "start": "231840",
    "end": "236879"
  },
  {
    "text": "mutation process and fuzzing process overall the second component is crash monitoring",
    "start": "236879",
    "end": "243120"
  },
  {
    "text": "which means that for each crash we do not only receive the payload that caused the crash but also details such as the",
    "start": "243120",
    "end": "249840"
  },
  {
    "text": "stack trace the name of the function which crashed the exact line of code etc",
    "start": "249840",
    "end": "256479"
  },
  {
    "text": "and the third feature is structure awareness this means that we don't send arbitrary sequences of bytes to our target but",
    "start": "256479",
    "end": "264080"
  },
  {
    "text": "rather form structured inputs these can be certain file formats for several",
    "start": "264080",
    "end": "270240"
  },
  {
    "text": "targets or in our case structured packets we will see this in the next slide",
    "start": "270240",
    "end": "278240"
  },
  {
    "text": "so first thing first we need a harness we need to be able to communicate with our target vm switch",
    "start": "278240",
    "end": "285520"
  },
  {
    "text": "the first resource we stumbled upon as part of our open source intelligence was a blog post",
    "start": "285520",
    "end": "292400"
  },
  {
    "text": "called fuzzing power virtualized devices in hyper-v now this looked quite uh good",
    "start": "292400",
    "end": "297759"
  },
  {
    "text": "for us because this is what we wanted to do exactly we wanted to fuzz a power virtualized device",
    "start": "297759",
    "end": "303440"
  },
  {
    "text": "which is vm switch and we actually kind of liked the",
    "start": "303440",
    "end": "309120"
  },
  {
    "text": "methodology that was presented in this blog post the researchers targeted the virtual pci",
    "start": "309120",
    "end": "314880"
  },
  {
    "text": "bus in hyper-v and not vmswitch but what they did was to obtain",
    "start": "314880",
    "end": "320320"
  },
  {
    "text": "the vmbus channel that the vsc the consumer uses on the child partition and",
    "start": "320320",
    "end": "325680"
  },
  {
    "text": "then use this vm bus channel to send inputs to the provider to the vsp",
    "start": "325680",
    "end": "331919"
  },
  {
    "text": "once they had this primitive or this ability they built a fuzzer on top of that and",
    "start": "331919",
    "end": "338080"
  },
  {
    "text": "were able to send countless of fuzzy inputs and find vulnerabilities",
    "start": "338080",
    "end": "344320"
  },
  {
    "text": "so again we decided to adopt this methodology for our own target vm switch",
    "start": "344320",
    "end": "350800"
  },
  {
    "text": "and as you can probably imagine uh the main challenge here is to be able to",
    "start": "350800",
    "end": "355840"
  },
  {
    "text": "actually understand where the vmbus channel is and this was uh quite a long",
    "start": "355840",
    "end": "361600"
  },
  {
    "text": "sub project for us it took a couple of uh weeks i think to find it out but we",
    "start": "361600",
    "end": "367440"
  },
  {
    "text": "sum it up in the slide that you see on the screen we found that as part of the",
    "start": "367440",
    "end": "372479"
  },
  {
    "text": "initialization process of net vsc which is the consumer for networking services",
    "start": "372479",
    "end": "379759"
  },
  {
    "text": "it creates a structure called mini port adapter context now just another thing",
    "start": "379759",
    "end": "385039"
  },
  {
    "text": "that's worth mentioning is that net vsc is a mini port driver which means it communicates directly with a network",
    "start": "385039",
    "end": "391680"
  },
  {
    "text": "interface card over and this so it creates this mini port adapter",
    "start": "391680",
    "end": "397199"
  },
  {
    "text": "context and inside this context at offset 18 in hex it stores the vmbus",
    "start": "397199",
    "end": "403600"
  },
  {
    "text": "channel so this took some time but eventually we understood that and we were able to",
    "start": "403600",
    "end": "409759"
  },
  {
    "text": "start writing our harness driver and in order to do that we first needed",
    "start": "409759",
    "end": "414960"
  },
  {
    "text": "to find the endis.cis module in the kernel of the child partition so we",
    "start": "414960",
    "end": "420479"
  },
  {
    "text": "iterated on all loaded modules and found endis inside endis we used a global variable",
    "start": "420479",
    "end": "427280"
  },
  {
    "text": "called endis miniport list which points to the list of network adapters",
    "start": "427280",
    "end": "434160"
  },
  {
    "text": "we went through this list until we finally found the adapter that we wanted to fuzz with",
    "start": "434160",
    "end": "441280"
  },
  {
    "text": "and we did did this by comparing the names and then as you can probably guess we",
    "start": "441280",
    "end": "446960"
  },
  {
    "text": "took the context from the adapter and obtain the bmbus channel from offset",
    "start": "446960",
    "end": "452319"
  },
  {
    "text": "18 in this context now the nice thing is once you have a",
    "start": "452319",
    "end": "457759"
  },
  {
    "text": "vmbus channel at hand you can simply use it with known documented apis",
    "start": "457759",
    "end": "463360"
  },
  {
    "text": "allocate a packet and send it over to the other side to a vm switch in our",
    "start": "463360",
    "end": "468879"
  },
  {
    "text": "case so just to get a glimpse of our our code",
    "start": "468879",
    "end": "474479"
  },
  {
    "text": "this was the harness driver and a very initial version of it but we'll walk",
    "start": "474479",
    "end": "479759"
  },
  {
    "text": "through it quickly so here in this for loop we iterate over all",
    "start": "479759",
    "end": "485039"
  },
  {
    "text": "mini port adapters once we find the one we need we fetch the context and then from the",
    "start": "485039",
    "end": "491759"
  },
  {
    "text": "context we take out the channel pointer",
    "start": "491759",
    "end": "496400"
  },
  {
    "text": "so what we had at this phase was our own driver loaded in the child partition kernel",
    "start": "499440",
    "end": "505199"
  },
  {
    "text": "able to obtain the vmbus channel and send inputs and we actually managed to",
    "start": "505199",
    "end": "510319"
  },
  {
    "text": "send some arbitrary bytes and see them in vm switch side but our next challenge was to design",
    "start": "510319",
    "end": "517518"
  },
  {
    "text": "such inputs that actually propagate through vm switch code so the next step was to look at vm",
    "start": "517519",
    "end": "525040"
  },
  {
    "text": "switch and how it processes packet now as it appears every vsp virtualized",
    "start": "525040",
    "end": "530560"
  },
  {
    "text": "service provider every vsp needs to implement a callback called vmb channel process packet",
    "start": "530560",
    "end": "537120"
  },
  {
    "text": "and this callback accepts five parameters the vmbus channel the packet",
    "start": "537120",
    "end": "542240"
  },
  {
    "text": "some buffer and its length and some flags and as you can see here on the slide",
    "start": "542240",
    "end": "548880"
  },
  {
    "text": "vm switch registers its own callback function called kmcl process packet",
    "start": "548880",
    "end": "554959"
  },
  {
    "text": "this is actually the first function that a packet meets in the vsp side",
    "start": "554959",
    "end": "560880"
  },
  {
    "text": "the earliest point in time so like i mentioned before",
    "start": "560880",
    "end": "567040"
  },
  {
    "text": "vm switch does not process any sequence of bytes it expects actually very structured data that is called nvsp",
    "start": "567040",
    "end": "574640"
  },
  {
    "text": "packets and these packets have many sub-types some of them are responsible for",
    "start": "574640",
    "end": "580880"
  },
  {
    "text": "initializing the communication some of them are responsible for setting the ring buffers that are required for",
    "start": "580880",
    "end": "587120"
  },
  {
    "text": "communication send and receive buffers i think i forgot to mention them before but these are ring buffers that are used",
    "start": "587120",
    "end": "593440"
  },
  {
    "text": "to transfer data and one single type of nvsp is our endis",
    "start": "593440",
    "end": "599760"
  },
  {
    "text": "packets our end this is another protocol that's responsible for communication between a host and the network adapter",
    "start": "599760",
    "end": "608480"
  },
  {
    "text": "so now that we kind of know the different types of nvsp we can take a deeper look into the package processing",
    "start": "608640",
    "end": "615120"
  },
  {
    "text": "callback and see the different code flows that originate from it the first one as you can see is the the",
    "start": "615120",
    "end": "622560"
  },
  {
    "text": "flow that handles initialization packets the other flow handles are ndis messages",
    "start": "622560",
    "end": "630079"
  },
  {
    "text": "and the third flow is responsible for any other type",
    "start": "630079",
    "end": "635200"
  },
  {
    "text": "now we decided to focus on r and this because of two reasons the first is that r and this actually has a lot of logic",
    "start": "635200",
    "end": "642880"
  },
  {
    "text": "implemented in vm switch so it's just a single type but it's responsible for quite a lot of code in the driver's",
    "start": "642880",
    "end": "649200"
  },
  {
    "text": "binary and the second is that many past vulnerabilities that we read about were",
    "start": "649200",
    "end": "655040"
  },
  {
    "text": "found in the r in this area so we simply thought it would be a good idea to start",
    "start": "655040",
    "end": "660480"
  },
  {
    "text": "there now the function that you see here handle r and descent message",
    "start": "660480",
    "end": "666320"
  },
  {
    "text": "is not a documented function so we needed to reverse engineer it a little bit and we found that it receives four",
    "start": "666320",
    "end": "674160"
  },
  {
    "text": "different parameters three of them were actually passed directly from the parent function the",
    "start": "674160",
    "end": "679920"
  },
  {
    "text": "process packet function and these parameters are the channel pointer the buffer and the packet itself",
    "start": "679920",
    "end": "687680"
  },
  {
    "text": "but there's also another parameter here that is a pointer to an mdl",
    "start": "687680",
    "end": "692800"
  },
  {
    "text": "so we thought to ourselves what is exactly the difference between the buffer and the mdl where does the",
    "start": "692800",
    "end": "699600"
  },
  {
    "text": "packet actually lie we found that the buffer is responsible",
    "start": "699600",
    "end": "705760"
  },
  {
    "text": "for some metadata on the packet it specifies what nvsp packet type is being",
    "start": "705760",
    "end": "710880"
  },
  {
    "text": "sent what is the channel type whether it is data with zero value or control channel with the",
    "start": "710880",
    "end": "718000"
  },
  {
    "text": "value of one and then two d words specify where vmswitch can find the sent data on the",
    "start": "718000",
    "end": "724880"
  },
  {
    "text": "send buffer so it specifies both the index of the section in the send buffer and the",
    "start": "724880",
    "end": "730000"
  },
  {
    "text": "section size so apparently this is one way to send packets through the send buffer",
    "start": "730000",
    "end": "736959"
  },
  {
    "text": "but there appears to be another way to send data to vmswitch and this is through mdl and when you send data through an mdl",
    "start": "736959",
    "end": "744320"
  },
  {
    "text": "what you need to do is to allocate some memory put your packet there and then create an mdl that points to your new",
    "start": "744320",
    "end": "752160"
  },
  {
    "text": "data buffer and in this case what the buffer needs to specify is -1 for section index",
    "start": "752160",
    "end": "758320"
  },
  {
    "text": "because the send buffer is not in use at all and the sex the section size does not",
    "start": "758320",
    "end": "764320"
  },
  {
    "text": "matter we decided to actually take this path because uh dealing with mdls",
    "start": "764320",
    "end": "770160"
  },
  {
    "text": "was easier for us instead of understanding the mechanisms of the send buffer",
    "start": "770160",
    "end": "776639"
  },
  {
    "text": "so just to kind of sum up how what sending packets with mdls look like",
    "start": "776959",
    "end": "782560"
  },
  {
    "text": "there is the buffer that specifies that an r in this message is being sent",
    "start": "782560",
    "end": "787680"
  },
  {
    "text": "one for control channel and the important part is the v word that specifies -1 for section index and then",
    "start": "787680",
    "end": "794480"
  },
  {
    "text": "the memory pointed to by the mdl has the actual r in this packet both its type",
    "start": "794480",
    "end": "800160"
  },
  {
    "text": "and the different are in this fields that are dependent on the type",
    "start": "800160",
    "end": "807279"
  },
  {
    "text": "so now we were not only able to send inputs from the child partition we were actually able to",
    "start": "808160",
    "end": "814480"
  },
  {
    "text": "design inputs that visit certain functions on on vm switch side",
    "start": "814480",
    "end": "821440"
  },
  {
    "text": "and with this ability we decided to trigger a past vulnerability with our harness and to test it by that",
    "start": "821440",
    "end": "827680"
  },
  {
    "text": "and we chose this cve by lisa sage we triggered it using our windows driver",
    "start": "827680",
    "end": "833760"
  },
  {
    "text": "which which was the first poc from a windows guest and we managed to crash the hyper-v host",
    "start": "833760",
    "end": "840399"
  },
  {
    "text": "this was a nice starting point but uh yeah well this was a good starting point and now is the time to actually",
    "start": "840399",
    "end": "847680"
  },
  {
    "text": "connect this harness to uh fuzzing infrastructure and for this section i invite fennig and pass the ball to him",
    "start": "847680",
    "end": "856000"
  },
  {
    "text": "thank you a few so obviously we've completed our first phase of our fuzzing product we now have",
    "start": "856000",
    "end": "863279"
  },
  {
    "text": "our harness which allows us to send any data we would like to vm switch and",
    "start": "863279",
    "end": "869199"
  },
  {
    "text": "it is fully possible and as of you mentioned before we also have",
    "start": "869199",
    "end": "875440"
  },
  {
    "text": "an additional components which we wanted to implement in order to build an end-to-end fuzzing infrastructure",
    "start": "875440",
    "end": "883040"
  },
  {
    "text": "so before we dive into the components of the fuzzing infrastructure let's",
    "start": "883040",
    "end": "888480"
  },
  {
    "text": "understand exactly what we expect the setup would look like and we actually examined multiple",
    "start": "888480",
    "end": "895120"
  },
  {
    "text": "fuzzing projects which were open source and we picked kfl as it looks very promising and we wanted to use it",
    "start": "895120",
    "end": "902560"
  },
  {
    "text": "so this is how the setup looks like we have l0 with regards to",
    "start": "902560",
    "end": "909279"
  },
  {
    "text": "the l0 and l1 and l2 terms this is actually describe level of virtualization so l0 is actually the",
    "start": "909279",
    "end": "916639"
  },
  {
    "text": "bare metal host which actually runs ubuntu linux with kvm which is the linux",
    "start": "916639",
    "end": "922000"
  },
  {
    "text": "hypervisor with kfl runs above it we have a one",
    "start": "922000",
    "end": "927839"
  },
  {
    "text": "which is our target hypervisor hyper-v and we have l2 which contains",
    "start": "927839",
    "end": "933519"
  },
  {
    "text": "two griton machines two partitions hyper-v partitions are actually virtual machines the root partition which",
    "start": "933519",
    "end": "939199"
  },
  {
    "text": "contains the host os which runs vm switch our target driver and the guest partition and the child partition the",
    "start": "939199",
    "end": "946639"
  },
  {
    "text": "guest vm which contains our driver which sends packets to vm switch",
    "start": "946639",
    "end": "951920"
  },
  {
    "text": "now the thing about this setup is it actually contains necessary utilization we have two hypervisors",
    "start": "951920",
    "end": "958880"
  },
  {
    "text": "one within the other and in order to enable hyper and necessary utilization for kafl because",
    "start": "958880",
    "end": "964720"
  },
  {
    "text": "at this point we actually understood that kfl does not support nested virtualization we understood",
    "start": "964720",
    "end": "970160"
  },
  {
    "text": "uh we have some tasks we need to perform and now let's describe it then quickly",
    "start": "970160",
    "end": "976480"
  },
  {
    "text": "we actually have an msr which enables the intel pt technology uh for the code coverage",
    "start": "976480",
    "end": "983440"
  },
  {
    "text": "which we described later and we need to enable this msr for a specific vm we only want to have code coverage out of",
    "start": "983440",
    "end": "990000"
  },
  {
    "text": "the root partition and not from the child partition we also need uh",
    "start": "990000",
    "end": "996720"
  },
  {
    "text": "to actually read and write memory directly from l0 to l2 as we would like to pass fuzzing inputs from",
    "start": "996720",
    "end": "1005120"
  },
  {
    "text": "kfl directly to the child partition and we also need to handle hyper call",
    "start": "1005120",
    "end": "1011040"
  },
  {
    "text": "directly from l2 within l0 now as we work with pre-allocated time",
    "start": "1011040",
    "end": "1016399"
  },
  {
    "text": "constraints we actually understood at that point that these tests might take longer than we allocated so we decided",
    "start": "1016399",
    "end": "1022240"
  },
  {
    "text": "to find some kind of a workaround so we decided to not to fuzz from l2 and",
    "start": "1022240",
    "end": "1028720"
  },
  {
    "text": "actually fuzz from l1",
    "start": "1028720",
    "end": "1032400"
  },
  {
    "text": "and we actually understood that obviously once you deploy hyper-v you have l0 l1 and l2 vm switch is loaded",
    "start": "1033760",
    "end": "1041760"
  },
  {
    "text": "to the root partition properly and once we disabled vtx which is the",
    "start": "1041760",
    "end": "1047280"
  },
  {
    "text": "intel virtualization capabilities obviously hyper-v won't be able to",
    "start": "1047280",
    "end": "1053280"
  },
  {
    "text": "boot properly as it doesn't have utilization capabilities and it won't be able to boot the hypervisor so we just",
    "start": "1053280",
    "end": "1059760"
  },
  {
    "text": "use a phobic mode of booting windows 10 normally without any hypervisor enabled",
    "start": "1059760",
    "end": "1065520"
  },
  {
    "text": "so we only have l1 but in this particular scenario we actually discovered that the windows 10 vm",
    "start": "1065520",
    "end": "1071760"
  },
  {
    "text": "actually contains the vm switch driver which is loaded to the system so we thought to ourself",
    "start": "1071760",
    "end": "1078080"
  },
  {
    "text": "why won't we just call handler in the send message function with our fuzzing inputs as a buffer",
    "start": "1078080",
    "end": "1083679"
  },
  {
    "text": "and just send it directly within the same vm",
    "start": "1083679",
    "end": "1088240"
  },
  {
    "text": "so at this point we actually understood that as we don't have any working partitions we don't have any working built-on",
    "start": "1088799",
    "end": "1094799"
  },
  {
    "text": "machines as hyper-v is not enabled we actually don't we don't have vm bus",
    "start": "1094799",
    "end": "1100000"
  },
  {
    "text": "as no one initialized it before and we don't have any pointer to a vm bus channel now the first argument to the handler in",
    "start": "1100000",
    "end": "1106720"
  },
  {
    "text": "the send message is a pointer to a vmbus channel so we had to find one or initialize one",
    "start": "1106720",
    "end": "1112799"
  },
  {
    "text": "and we started to just engineer a lot of undocumented structures and feel it manually and at a certain point we",
    "start": "1112799",
    "end": "1119360"
  },
  {
    "text": "discovered the vms vm nick more function within bim suite which is responsible of",
    "start": "1119360",
    "end": "1124480"
  },
  {
    "text": "initializing a lot of the undocumented structures we failed manually and also initializing a vmbus channel",
    "start": "1124480",
    "end": "1131280"
  },
  {
    "text": "so we tried to call it and it crushed our system we analyzed the root cause of the",
    "start": "1131280",
    "end": "1137039"
  },
  {
    "text": "crash and we discovered that it tries to call a lot of vm bus related functions",
    "start": "1137039",
    "end": "1142080"
  },
  {
    "text": "and obviously as i mentioned before vmbus is not enabled as we don't have hyper-v working",
    "start": "1142080",
    "end": "1147440"
  },
  {
    "text": "so obviously the system eventually it would be crashed so we actually decided to patch out any",
    "start": "1147440",
    "end": "1154320"
  },
  {
    "text": "call to a vmbus related logic and vmbus reality functions",
    "start": "1154320",
    "end": "1159440"
  },
  {
    "text": "because we understood that vm bus is not our target vm switch is our target and vm bus does not interfere with the data",
    "start": "1159440",
    "end": "1165360"
  },
  {
    "text": "that is being sent from the child partition to the root partition so we were not interested in it so we",
    "start": "1165360",
    "end": "1171120"
  },
  {
    "text": "decided to patch it up and in order to patch out or modify any microsoft sign code within the",
    "start": "1171120",
    "end": "1177919"
  },
  {
    "text": "kernel obviously you'll have to disable pedgar otherwise the system will be crashed",
    "start": "1177919",
    "end": "1184400"
  },
  {
    "text": "so in order to disable patchguard we have the first method which is the most",
    "start": "1184400",
    "end": "1189679"
  },
  {
    "text": "common method that we knew at that time which is attaching a kernel debugger to the os once it boots",
    "start": "1189679",
    "end": "1196400"
  },
  {
    "text": "now by design windows will disable patch guard if a kernel debugger was attached during boot time the thing with this",
    "start": "1196400",
    "end": "1203440"
  },
  {
    "text": "method is actually it might cause a lot of performance overhead",
    "start": "1203440",
    "end": "1208960"
  },
  {
    "text": "because it it's waiting for a current debugger to be attached and later on it will try to communicate with the kernel",
    "start": "1208960",
    "end": "1214080"
  },
  {
    "text": "debugger over the kd protocol and we didn't want to lose any performance because we wanted our father",
    "start": "1214080",
    "end": "1220240"
  },
  {
    "text": "infrastructure to be efficient so we actually found a pretty cool and useful tool called efi guard efiguard is",
    "start": "1220240",
    "end": "1227120"
  },
  {
    "text": "an open source uefi boot kit which enables you to load the antes kernel without hedge guard enabled and also it",
    "start": "1227120",
    "end": "1234240"
  },
  {
    "text": "disables the driver signature enforcement mechanism which enables us to load any driver we",
    "start": "1234240",
    "end": "1239600"
  },
  {
    "text": "would like including our father and our harness driver and pretty easily",
    "start": "1239600",
    "end": "1246240"
  },
  {
    "text": "so we chose this this tool and it's it was published on github and it actually solved our problem and",
    "start": "1246240",
    "end": "1252320"
  },
  {
    "text": "we patched out the vmbox logic so now let's take a look of how the setup looked like so we have l0 our bare",
    "start": "1252320",
    "end": "1259520"
  },
  {
    "text": "metal sb4 with kvm and kfl above it we have l1 which is this time it's not",
    "start": "1259520",
    "end": "1266320"
  },
  {
    "text": "hyper-v it's a regular windows 10 vm because hyper v is not enabled without vtx",
    "start": "1266320",
    "end": "1272320"
  },
  {
    "text": "and we have our harness executable which communicates with kfl over kvm hyper",
    "start": "1272320",
    "end": "1278320"
  },
  {
    "text": "calls in order to get fuzzing payloads later on it will send our fuzzing",
    "start": "1278320",
    "end": "1283600"
  },
  {
    "text": "payload to our harness driver which runs in the kernel and our file driver will call handler",
    "start": "1283600",
    "end": "1289679"
  },
  {
    "text": "and descend message within vm switch with the fuzzing payload and now obviously it's working because",
    "start": "1289679",
    "end": "1294720"
  },
  {
    "text": "we patched out vm bus and the system won't crash",
    "start": "1294720",
    "end": "1299280"
  },
  {
    "text": "now we chose to name our father half a one eight is for hypervisor afl is for the",
    "start": "1300159",
    "end": "1305200"
  },
  {
    "text": "afl father and l1 as we only use one level of virtualization",
    "start": "1305200",
    "end": "1310320"
  },
  {
    "text": "we don't have any nested hypervisor so as if you mentioned before we've",
    "start": "1310320",
    "end": "1316400"
  },
  {
    "text": "completed the harness part and we now have the ability to send packets within only a single vm to vm switch",
    "start": "1316400",
    "end": "1323679"
  },
  {
    "text": "but we wanted to have an end-to-end further infrastructure as we wanted to have more capabilities in order to",
    "start": "1323679",
    "end": "1328880"
  },
  {
    "text": "understand exactly whether our father is efficient and we wanted to automate the process as much as we could",
    "start": "1328880",
    "end": "1336559"
  },
  {
    "text": "so let's start and talk about the first component which is coverage guidance and as a film mentioned before coverage",
    "start": "1337120",
    "end": "1342400"
  },
  {
    "text": "guidance actually is being deployed with kfl now we didn't want to use blind fuzzing",
    "start": "1342400",
    "end": "1348640"
  },
  {
    "text": "as we didn't want to send a packet again and again and",
    "start": "1348640",
    "end": "1353760"
  },
  {
    "text": "we wanted to understand exactly whether the packet triggered which code and understand whether a",
    "start": "1353760",
    "end": "1360159"
  },
  {
    "text": "packet didn't trigger code and we didn't want to use it anymore so kfl actually supports coverage",
    "start": "1360159",
    "end": "1366159"
  },
  {
    "text": "guidance out of the box uh by leveraging the intel fitting mechanism the intel pt mechanism intel",
    "start": "1366159",
    "end": "1371760"
  },
  {
    "text": "processor trace actually developed by intel and enables one to understand exactly",
    "start": "1371760",
    "end": "1378559"
  },
  {
    "text": "where does the instruction pointer of the cpu was in a certain time and in a certain address space",
    "start": "1378559",
    "end": "1384400"
  },
  {
    "text": "so it's perfect for code coverage collection during the fuzzing process",
    "start": "1384400",
    "end": "1389600"
  },
  {
    "text": "and it's important to say and we'll get back to this fact uh in the next slides that kfo coverage guidance works differently",
    "start": "1389600",
    "end": "1398559"
  },
  {
    "text": "by filtering the coverage according to the harness process context what does it",
    "start": "1398559",
    "end": "1404320"
  },
  {
    "text": "exactly mean it means that we have our harness executable which sends the payload we'll understand it in a second",
    "start": "1404320",
    "end": "1410640"
  },
  {
    "text": "and actually the code coverage will collect the code coverage mechanism will collect",
    "start": "1410640",
    "end": "1416320"
  },
  {
    "text": "the coverage as long as the context uh the current context is our harness executable uh if the context will be",
    "start": "1416320",
    "end": "1423039"
  },
  {
    "text": "replaced it will stop collecting coverage as it wants to understand exactly uh",
    "start": "1423039",
    "end": "1428480"
  },
  {
    "text": "what code coverage originated by us so at this point we actually understood",
    "start": "1428480",
    "end": "1434880"
  },
  {
    "text": "that there is a problem we have a low basic blood count of our core coverage",
    "start": "1434880",
    "end": "1440400"
  },
  {
    "text": "and it didn't make sense to us as vm switch contains a lot of code it's a huge binary and even a single payload",
    "start": "1440400",
    "end": "1447440"
  },
  {
    "text": "should have triggered a lot of code and the number was pretty low",
    "start": "1447440",
    "end": "1452559"
  },
  {
    "text": "and at that point we actually understood that vm switch processes incoming packets in a more threaded manner and",
    "start": "1452559",
    "end": "1458000"
  },
  {
    "text": "what does it exactly means it means that once we send a packet by calling the handler and the send message",
    "start": "1458000",
    "end": "1464400"
  },
  {
    "text": "the handler in this function will push it to a queue which will be processed",
    "start": "1464400",
    "end": "1469840"
  },
  {
    "text": "which will process the packet in another thread which means that the context will be replaced let's understand exactly how",
    "start": "1469840",
    "end": "1475919"
  },
  {
    "text": "does it look like in the following diagram so we have half a one with our harness executable we have intel pt enabled",
    "start": "1475919",
    "end": "1483200"
  },
  {
    "text": "because the context is our harness executable and cr3 obviously assigned to the harness executable one",
    "start": "1483200",
    "end": "1490480"
  },
  {
    "text": "now we'll send the packet to the faster driver to the harness driver and the driver will actually call the",
    "start": "1490480",
    "end": "1496240"
  },
  {
    "text": "handler and descend message now as i mentioned the handler and descend message will",
    "start": "1496240",
    "end": "1502799"
  },
  {
    "text": "actually push the packet to a queue and once the other thread the worker",
    "start": "1502799",
    "end": "1508080"
  },
  {
    "text": "thread will try to process the packet the context will be switched to the system process",
    "start": "1508080",
    "end": "1513520"
  },
  {
    "text": "and it actually means that the code coverage will be disabled that's the cr3 changed and intel pt disabled as well",
    "start": "1513520",
    "end": "1520480"
  },
  {
    "text": "and that's the actual reason we lose we lost coverage so the solution was pretty simple we",
    "start": "1520480",
    "end": "1526720"
  },
  {
    "text": "actually disabled the intel ptcr3 filtering which means that it will monitor all the executions",
    "start": "1526720",
    "end": "1532480"
  },
  {
    "text": "within the vm switch address space and we also knew that as vm switch was",
    "start": "1532480",
    "end": "1537679"
  },
  {
    "text": "not enabled before we are the only one who performs operations within vm switch hyper v is not enabled",
    "start": "1537679",
    "end": "1544320"
  },
  {
    "text": "so we definitely knew that all the operations we monitor within the vmswitch address space was originated by",
    "start": "1544320",
    "end": "1550000"
  },
  {
    "text": "us and this is actually a screenshot of the lighthouse ida plugin and we wrote a",
    "start": "1550000",
    "end": "1556400"
  },
  {
    "text": "script which converts kfl intel pt trace format to a lighthouse compatible one",
    "start": "1556400",
    "end": "1563120"
  },
  {
    "text": "now it was we actually it was pretty useful for us because it actually visualized the code coverage",
    "start": "1563120",
    "end": "1569440"
  },
  {
    "text": "for us and we understand exactly which part of the code we triggered and which parts we didn't trigger and obviously we",
    "start": "1569440",
    "end": "1575039"
  },
  {
    "text": "did some modifications to the infrastructure in order to trigger more code",
    "start": "1575039",
    "end": "1580240"
  },
  {
    "text": "so this was the coverage guidance and let's talk about crash monitoring",
    "start": "1580320",
    "end": "1585520"
  },
  {
    "text": "now as if you mentioned we actually wanted to have some kind of a centralized mechanism",
    "start": "1585520",
    "end": "1591440"
  },
  {
    "text": "which contains and [Music] contains of all of the crashes with the",
    "start": "1591440",
    "end": "1596840"
  },
  {
    "text": "detailed crash and we didn't want to only knew that the crash occurred because we didn't want to reproduce it",
    "start": "1596840",
    "end": "1602799"
  },
  {
    "text": "manually every time we had a crash because it actually means to we need to deploy a vm and we need to",
    "start": "1602799",
    "end": "1609840"
  },
  {
    "text": "reproduce the exact crash and we need to attach a kernel debugger and understand the exact stock trace",
    "start": "1609840",
    "end": "1615679"
  },
  {
    "text": "now kfl actually is deployed with a very basic functionality of crash monitoring",
    "start": "1615679",
    "end": "1620960"
  },
  {
    "text": "for windows os it actually only signals you that it crash record and tells you which",
    "start": "1620960",
    "end": "1626320"
  },
  {
    "text": "failure to cause the crest and we wanted to understand the exact data it's crashed automatically so we",
    "start": "1626320",
    "end": "1632159"
  },
  {
    "text": "actually found a pretty cool implementation of zen's hypervisor within github and the code",
    "start": "1632159",
    "end": "1640559"
  },
  {
    "text": "actually registered as a bachelor callback which means that it will be triggered every time it crash occurs and",
    "start": "1640559",
    "end": "1646559"
  },
  {
    "text": "once it's being triggered it will actually collect the stack trace of the crash and actually replaces each line of",
    "start": "1646559",
    "end": "1653120"
  },
  {
    "text": "the stack with with the model name and in order to send the data from",
    "start": "1653120",
    "end": "1658960"
  },
  {
    "text": "within our driver to kfl we actually implemented two hyper calls within kvm which enabled us to",
    "start": "1658960",
    "end": "1665679"
  },
  {
    "text": "send the exact size of the crash dump and then the buffer of the crash dump itself",
    "start": "1665679",
    "end": "1671360"
  },
  {
    "text": "so this is how it looks like on our fuzzing server we asked we wrote a script which iterates all the crashes tells us",
    "start": "1671360",
    "end": "1678559"
  },
  {
    "text": "which payload caused the crash and displays the exact stack trace of each crash we also replaced the function",
    "start": "1678559",
    "end": "1686320"
  },
  {
    "text": "address with the function name so it was pretty easy for us to understand the exact route because of",
    "start": "1686320",
    "end": "1691840"
  },
  {
    "text": "each crash pretty easily without leveraging a vm we just needed to open",
    "start": "1691840",
    "end": "1697279"
  },
  {
    "text": "vm switch in ida pro and we understood the root cause within five minutes",
    "start": "1697279",
    "end": "1703679"
  },
  {
    "text": "so let's talk about the last component of our fuzzing infrastructure which is structural awareness",
    "start": "1704960",
    "end": "1711200"
  },
  {
    "text": "now we were handling with a well-specified protocol called arendis",
    "start": "1711200",
    "end": "1717360"
  },
  {
    "text": "now we knew that it deducted it was documented well by microsoft and we knew",
    "start": "1717360",
    "end": "1722480"
  },
  {
    "text": "that there are a lot of structures and a lot of messages of our nds and we knew that if we would try to mutate",
    "start": "1722480",
    "end": "1728640"
  },
  {
    "text": "fuzzing inputs during runtime randomly we will probably send dummy packets which won't be parsed",
    "start": "1728640",
    "end": "1735440"
  },
  {
    "text": "because there are a lot of basic checks functionality within vm switch so we knew we have to generate packets",
    "start": "1735440",
    "end": "1741360"
  },
  {
    "text": "according to the rnd specification so we actually used google protobuf protocol buffers in order to represent",
    "start": "1741360",
    "end": "1748240"
  },
  {
    "text": "the rnds message as instructors in an easy manner now after we represented it",
    "start": "1748240",
    "end": "1753919"
  },
  {
    "text": "by generating a lot of profiles we used the leap prototype mutator library",
    "start": "1753919",
    "end": "1759279"
  },
  {
    "text": "which is a great library by google as well which enables one to use the profiles he generated",
    "start": "1759279",
    "end": "1765279"
  },
  {
    "text": "from some kind of a specification of structures and actually mutate packets of fuzzing or payloads of fuzzing during",
    "start": "1765279",
    "end": "1772480"
  },
  {
    "text": "run time according to the specification we wrote in the protobuf files so that",
    "start": "1772480",
    "end": "1777760"
  },
  {
    "text": "actually means that we integrated it into f41 and we were able to generate rnds packets according to the",
    "start": "1777760",
    "end": "1783520"
  },
  {
    "text": "specification during runtime and this was actually the last component",
    "start": "1783520",
    "end": "1789039"
  },
  {
    "text": "and we've completed our whole end-to-end father infrastructure we have our harness we have coverage guidance",
    "start": "1789039",
    "end": "1795520"
  },
  {
    "text": "crash monitoring and structural awareness and that was pretty amazing in that stage",
    "start": "1795520",
    "end": "1802559"
  },
  {
    "text": "so what you can see here is actually the user interface of half full one i",
    "start": "1804880",
    "end": "1810240"
  },
  {
    "text": "think two hours after it started running on our dedicated servers i got a phone",
    "start": "1810240",
    "end": "1815279"
  },
  {
    "text": "call from peleg saying that there was a crash we started investigating this crash and we found",
    "start": "1815279",
    "end": "1821200"
  },
  {
    "text": "an actual bug in vmswitch we started reporting this to msrc who assigned it with this cv",
    "start": "1821200",
    "end": "1828080"
  },
  {
    "text": "so in the time left we'll try to understand what the bug is and what are the consequences of it",
    "start": "1828080",
    "end": "1834720"
  },
  {
    "text": "the call chain starts with a control message worker routine which is the function called once a packet is fetched",
    "start": "1834720",
    "end": "1842159"
  },
  {
    "text": "from uh the queue that peleg mentioned before later on it continues to an r and this",
    "start": "1842159",
    "end": "1848960"
  },
  {
    "text": "handle set message function which handles set requests in our endis",
    "start": "1848960",
    "end": "1855840"
  },
  {
    "text": "then we have another function if you see in its name it handles with ifr which is an",
    "start": "1856000",
    "end": "1862080"
  },
  {
    "text": "in-flight tracer built on top of wpp software tracing so we're dealing with",
    "start": "1862080",
    "end": "1867360"
  },
  {
    "text": "some logic related to logging the packet and eventually the crash actually occurs",
    "start": "1867360",
    "end": "1874559"
  },
  {
    "text": "in a function that has oid switch nick request in its name oid is object identifier and it simply",
    "start": "1874559",
    "end": "1881760"
  },
  {
    "text": "identifies the type of the set request or query request that are sent as part",
    "start": "1881760",
    "end": "1887039"
  },
  {
    "text": "of the r disk communication the next question that comes to mind is",
    "start": "1887039",
    "end": "1892159"
  },
  {
    "text": "what does this oid do and what is its purpose so as it appears this oid switch nick",
    "start": "1892159",
    "end": "1898480"
  },
  {
    "text": "request is supposed to encapsulate and forward oid requests from a child partition to a",
    "start": "1898480",
    "end": "1906080"
  },
  {
    "text": "physical network adapter so actually it's never meant to be sent from the child partition but rather from",
    "start": "1906080",
    "end": "1913120"
  },
  {
    "text": "the root partition so this was actually the first root cause of the bug vms which never",
    "start": "1913120",
    "end": "1919519"
  },
  {
    "text": "actually checked that that type of packet is received from",
    "start": "1919519",
    "end": "1925120"
  },
  {
    "text": "from the root partition and not from any guest machine now as you can see in the slide as part",
    "start": "1925120",
    "end": "1932240"
  },
  {
    "text": "of its structure the packet has a member called p and this oid request this is a pointer to",
    "start": "1932240",
    "end": "1939519"
  },
  {
    "text": "the encapsulated oid request this is where the the original oid from the",
    "start": "1939519",
    "end": "1944720"
  },
  {
    "text": "child partition is so this actually brings me to the second",
    "start": "1944720",
    "end": "1950880"
  },
  {
    "text": "problem leading to the bug which is this pointer is never validated if you're an attacker controlling the",
    "start": "1950880",
    "end": "1957600"
  },
  {
    "text": "kernel of a child partition you can put any pointer there vmswitch will not validate it and this",
    "start": "1957600",
    "end": "1964559"
  },
  {
    "text": "will lead to a crash so as you can see here in the",
    "start": "1964559",
    "end": "1970640"
  },
  {
    "text": "disassembly of vm switch we have the instructions leading to the crash we'll actually look at the top",
    "start": "1970640",
    "end": "1976960"
  },
  {
    "text": "where we fetch the pointer to the oid request and put it in the register r10",
    "start": "1976960",
    "end": "1984159"
  },
  {
    "text": "this is quite low level but this what actually happens there and then later on we dereference this pointer in register",
    "start": "1984159",
    "end": "1991200"
  },
  {
    "text": "r10 and then this leads to to the crash but as you'll see just in a minute there",
    "start": "1991200",
    "end": "1996960"
  },
  {
    "text": "are harsher consequences to the bug than just crashing the host",
    "start": "1996960",
    "end": "2003679"
  },
  {
    "text": "so let's talk about the consequences of the vulnerability so obviously we have an arbitrary read vulnerability which",
    "start": "2003679",
    "end": "2009760"
  },
  {
    "text": "allows us to read any pointer we would like and eventually",
    "start": "2009760",
    "end": "2015120"
  },
  {
    "text": "if we'll trigger the vulnerability from within and hyper-v guest we will crash",
    "start": "2015120",
    "end": "2020399"
  },
  {
    "text": "the hyper-v host and the whole hypervisor itself now the first question that came in mind",
    "start": "2020399",
    "end": "2026320"
  },
  {
    "text": "was we wanted to understand whether it impacts azure cloud or not and we didn't want to test it out on production so we",
    "start": "2026320",
    "end": "2033519"
  },
  {
    "text": "just asked msrc and msrc did confirm that the vulnerability did impact azure",
    "start": "2033519",
    "end": "2039200"
  },
  {
    "text": "as well now the thing that is interesting about this bug is",
    "start": "2039200",
    "end": "2045600"
  },
  {
    "text": "aside from the fact that it's an arbitrary pointer the reference msrc actually signed it with a cvss of 9.9",
    "start": "2045600",
    "end": "2052158"
  },
  {
    "text": "which is pretty high now they actually described that there is a particular scenario which involves",
    "start": "2052159",
    "end": "2058158"
  },
  {
    "text": "of dma direct memory access device which by triggering this vulnerability",
    "start": "2058159",
    "end": "2063679"
  },
  {
    "text": "and reading from the dma device you might get more primitives which might lead to a remote code execution scenario",
    "start": "2063679",
    "end": "2070960"
  },
  {
    "text": "and that is pretty interesting now we didn't have the time to test it out but we do encourage you to test it out",
    "start": "2070960",
    "end": "2076720"
  },
  {
    "text": "and if you have any interesting thoughts or interesting results please don't hesitate and share it with us on twitter",
    "start": "2076720",
    "end": "2082480"
  },
  {
    "text": "and we would like to hear about it more so demo time this is actually on a local",
    "start": "2082480",
    "end": "2089200"
  },
  {
    "text": "environment we have l0 debugging vm switch and l2 we were running packet sender which is",
    "start": "2089200",
    "end": "2095440"
  },
  {
    "text": "our exploit program with the vulnerable oid packet and the size",
    "start": "2095440",
    "end": "2100880"
  },
  {
    "text": "and once defender will finish scanning our executable we'll see that vm switch crashes on l0",
    "start": "2100880",
    "end": "2107760"
  },
  {
    "text": "on the debugger if we analyze the crash we see the actual pointer that was",
    "start": "2107760",
    "end": "2113280"
  },
  {
    "text": "dereferenced the invalid pointer you can see many four ones in just a second there it is",
    "start": "2113280",
    "end": "2121200"
  },
  {
    "text": "and later on it says where the module uh what is the module that crashed and where and we're already familiar with",
    "start": "2121200",
    "end": "2127760"
  },
  {
    "text": "this function so this is a local environment but as pelic mentioned it could impact azure",
    "start": "2127760",
    "end": "2134079"
  },
  {
    "text": "quite harshly so we've actually published our whole project to github we've published the",
    "start": "2134079",
    "end": "2140480"
  },
  {
    "text": "first part with enable which enabled us to send data from the child partition to",
    "start": "2140480",
    "end": "2145599"
  },
  {
    "text": "the root partition and we've also published half a one which contains the harness path and also",
    "start": "2145599",
    "end": "2151920"
  },
  {
    "text": "modification of the kfl file itself and we encourage you to test it out and improve it and hopefully find more bugs",
    "start": "2151920",
    "end": "2159200"
  },
  {
    "text": "with it and if you have any suggestions or thoughts please open a github issue or send us a dm on twitter and we'll try",
    "start": "2159200",
    "end": "2167040"
  },
  {
    "text": "to respond to it so thank you once again for joining if you have any questions don't hesitate to",
    "start": "2167040",
    "end": "2172800"
  },
  {
    "text": "reach out to us online thank you",
    "start": "2172800",
    "end": "2178119"
  }
]
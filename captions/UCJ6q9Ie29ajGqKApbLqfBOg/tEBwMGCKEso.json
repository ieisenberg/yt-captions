[
  {
    "start": "0",
    "end": "45000"
  },
  {
    "text": "[Music]",
    "start": "860",
    "end": "8240"
  },
  {
    "text": "hello and welcome this is zen in the art of adversarial machine learning my name is will pierce i'm the red team",
    "start": "8480",
    "end": "14960"
  },
  {
    "text": "lead for the azure trustworthy machine learning team and together with my colleagues our job is to assess machine learning models at microsoft and with",
    "start": "14960",
    "end": "21760"
  },
  {
    "text": "partners i'm joined today by giorgio severi hello everyone i'm giorgio i'm a phd",
    "start": "21760",
    "end": "28400"
  },
  {
    "text": "student at northeastern university and my research focuses on securing machine learning systems",
    "start": "28400",
    "end": "36000"
  },
  {
    "text": "and georgia was recent intern at microsoft where he helped us assess some large language models that's where we're",
    "start": "36000",
    "end": "42559"
  },
  {
    "text": "together but today we're just going to cover some operational guidance so we're maybe going to do less of the machine learning",
    "start": "42559",
    "end": "49360"
  },
  {
    "start": "45000",
    "end": "45000"
  },
  {
    "text": "theory and we're going to talk about just operational guidance things that you need to consider when you're attacking machine learning",
    "start": "49360",
    "end": "54879"
  },
  {
    "text": "models so best practices where to start if you know absolutely nothing",
    "start": "54879",
    "end": "60000"
  },
  {
    "text": "some of these slides will be for you where you can just go and find an algorithm and",
    "start": "60000",
    "end": "65040"
  },
  {
    "text": "try and run it against a model we're going to cover some terms and gotchas things that i didn't know when i started",
    "start": "65040",
    "end": "71360"
  },
  {
    "text": "attacking machine learning that giorgio definitely knows being a phd student",
    "start": "71360",
    "end": "77759"
  },
  {
    "text": "and then we're going to talk about building long-term capabilities so how you can build sort of an assessment program",
    "start": "77759",
    "end": "83680"
  },
  {
    "text": "how you can go about building ttps and and building sort of the relationship",
    "start": "83680",
    "end": "89840"
  },
  {
    "text": "between offensive security and machine learning and really giorgio is is here so i come",
    "start": "89840",
    "end": "96240"
  },
  {
    "text": "from the offensive side um where you know hacking networks in active directory things like that and giorgio",
    "start": "96240",
    "end": "102320"
  },
  {
    "text": "comes from the pure adversarial machine learning side being a phd student so i'll cover the operational things and",
    "start": "102320",
    "end": "109200"
  },
  {
    "text": "giorgio is going to cover the the formal academic things but he also has",
    "start": "109200",
    "end": "116640"
  },
  {
    "text": "quite a bit of experience attacking machine learning against real world systems and i don't really need to introduce",
    "start": "116640",
    "end": "123040"
  },
  {
    "text": "machine learning um to you i think we we all know we've all heard of it we all know it as in",
    "start": "123040",
    "end": "128879"
  },
  {
    "text": "in every everything agriculture teaching um authentication",
    "start": "128879",
    "end": "134640"
  },
  {
    "text": "deciding whether or not your cat is cute medicine all kinds of things",
    "start": "134640",
    "end": "139680"
  },
  {
    "text": "but even though things are very complicated or it would seem that machine learning is complicated and to a",
    "start": "139680",
    "end": "145440"
  },
  {
    "text": "point it is uh when you look at the math i think you know algorithms are empty and i think the reason machine learning",
    "start": "145440",
    "end": "152400"
  },
  {
    "text": "is everywhere is because algorithms are empty so the math will take care of itself you just need to break whatever",
    "start": "152400",
    "end": "159360"
  },
  {
    "text": "problem it is you down into some representation that an algorithm can work on",
    "start": "159360",
    "end": "164480"
  },
  {
    "text": "and then you can train a model so while algorithms are empty models or not models are a representation of the data",
    "start": "164480",
    "end": "170400"
  },
  {
    "text": "that you train on and this has implications for security so",
    "start": "170400",
    "end": "175920"
  },
  {
    "text": "if you train a model that has private information in it that model you know has private",
    "start": "175920",
    "end": "181920"
  },
  {
    "text": "information it's just a different representation of data than perhaps a database maybe we're used to thinking of",
    "start": "181920",
    "end": "189519"
  },
  {
    "text": "but i think you know the problem is that we in security hear about machine learning from vendors and so our opinion",
    "start": "189519",
    "end": "195599"
  },
  {
    "text": "of machine learning is often shaped by an outside party people just using machine learning",
    "start": "195599",
    "end": "201920"
  },
  {
    "text": "to in their products for security purposes and this is maybe where we're most familiar with it and",
    "start": "201920",
    "end": "207200"
  },
  {
    "text": "this is a slide that i did for besides salt lake city talk and it's kind of joking but it is",
    "start": "207200",
    "end": "213360"
  },
  {
    "text": "definitely true um you know in our opinions of machine learning uh when they're being used in security",
    "start": "213360",
    "end": "219920"
  },
  {
    "text": "products is a secondary concern in this conversation um you'll be pleased to know there's",
    "start": "219920",
    "end": "225120"
  },
  {
    "text": "terrible machine learning everywhere and it's not just in security products and so when we talk about",
    "start": "225120",
    "end": "231200"
  },
  {
    "text": "machine learning the security of machine learning i think i would ask you to you know remove your perception",
    "start": "231200",
    "end": "237120"
  },
  {
    "text": "uh of the marketing that you hear or you know machine learning gets blamed for that marketing",
    "start": "237120",
    "end": "244560"
  },
  {
    "start": "244000",
    "end": "244000"
  },
  {
    "text": "and so when we talk about adversarial machine learning i do some slides where i talk about offensive machine learning and i count",
    "start": "246000",
    "end": "252239"
  },
  {
    "text": "adversarial machine learning under that umbrella offensive machine learning where offensive machine learning you're using you know machine learning",
    "start": "252239",
    "end": "258639"
  },
  {
    "text": "techniques for offense um this is just my personal georgia you might have a different opinion coming from the more",
    "start": "258639",
    "end": "264720"
  },
  {
    "text": "formal offense adversarial side but i say it's just it's a subject discipline that specifically attacks ml",
    "start": "264720",
    "end": "271919"
  },
  {
    "text": "algorithms and there's a number of uh use cases for this and it's you know you can find large",
    "start": "271919",
    "end": "278000"
  },
  {
    "text": "uh you can find pii in large language models so if you think about gpt3 or",
    "start": "278000",
    "end": "283360"
  },
  {
    "text": "gpt 4 or any large language amounts coming out you know they've been shown to",
    "start": "283360",
    "end": "289040"
  },
  {
    "text": "memorize training data and if you know social security numbers or credit cards or what have you are in that training",
    "start": "289040",
    "end": "295280"
  },
  {
    "text": "data or in the large data sets that you use like common coral you can retrieve those",
    "start": "295280",
    "end": "301120"
  },
  {
    "text": "uh you can bypass classifiers and you know where this is probably where security people are most familiar",
    "start": "301120",
    "end": "307360"
  },
  {
    "text": "you know malware classifiers spam classifiers um fraud classifiers uh things that classify your authentication",
    "start": "307360",
    "end": "315600"
  },
  {
    "text": "uh your traffic let you into web applications and whatnot we even have denial of service so there are",
    "start": "315600",
    "end": "322240"
  },
  {
    "text": "particular samples called sponge examples that",
    "start": "322240",
    "end": "327310"
  },
  {
    "text": "[Music] take an algorithm longer to compute than others",
    "start": "327310",
    "end": "333440"
  },
  {
    "text": "you can also functional extraction you can steal a model you could steal a model",
    "start": "333600",
    "end": "339840"
  },
  {
    "text": "put it up on your own api and build a service around it you could steal a model and then go use it for",
    "start": "339840",
    "end": "347039"
  },
  {
    "text": "other types of attacks like bypassing classifiers and",
    "start": "347039",
    "end": "352400"
  },
  {
    "text": "all of these techniques are available on in research in academia and at first",
    "start": "352400",
    "end": "358639"
  },
  {
    "text": "when i first started attacking machine learning models you know a lot of the papers are on",
    "start": "358639",
    "end": "364000"
  },
  {
    "text": "archive and you have to have some knowledge of machining to really know what's going on",
    "start": "364000",
    "end": "369039"
  },
  {
    "text": "and you i think as security people we complain that things aren't real world but you know in reality it was never the",
    "start": "369039",
    "end": "376160"
  },
  {
    "text": "academic's job or the academic researcher's job to make it real world it's it's our job as offensive security",
    "start": "376160",
    "end": "382880"
  },
  {
    "text": "professionals to make those real world to translate that research into real world attacks",
    "start": "382880",
    "end": "388800"
  },
  {
    "text": "that get the attention that these techniques deserve so i have some questions",
    "start": "388800",
    "end": "395280"
  },
  {
    "text": "for the security folks in the room um in your mind how does a model",
    "start": "395280",
    "end": "401639"
  },
  {
    "text": "representation of data align with your understanding of current risk frameworks so if you take a database full of data",
    "start": "401639",
    "end": "409120"
  },
  {
    "text": "train a model and then serve it through an api you know can you for example for gdpr",
    "start": "409120",
    "end": "415759"
  },
  {
    "text": "can you delete a data point out of that model you know for iso what what does iso say",
    "start": "415759",
    "end": "423120"
  },
  {
    "text": "about um how that model should be secured and we don't have answers for this like",
    "start": "423120",
    "end": "430479"
  },
  {
    "text": "that's that's kind of you know why we're hearing what we're talking about but there are frameworks that are coming and",
    "start": "430479",
    "end": "435919"
  },
  {
    "text": "there are a lot of um standards that are coming so i think it would be um prudent to start looking at this",
    "start": "435919",
    "end": "442720"
  },
  {
    "text": "inside your organization and seeing what security",
    "start": "442720",
    "end": "447919"
  },
  {
    "text": "measures already transfer across and then whose responsibility is it",
    "start": "447919",
    "end": "454000"
  },
  {
    "text": "right so if machine learning is an ml is an information system who's responsible for securing it is it",
    "start": "454000",
    "end": "460400"
  },
  {
    "text": "the data scientists is it the ml engineers or is it the security organization",
    "start": "460400",
    "end": "465919"
  },
  {
    "text": "in my opinion being a security person would obviously be the security the security person's job or the security",
    "start": "465919",
    "end": "471280"
  },
  {
    "text": "organization's job to secure it and you know get an eye on it",
    "start": "471280",
    "end": "476400"
  },
  {
    "text": "so next we're going to talk about some attacks on machine learning",
    "start": "476400",
    "end": "481919"
  },
  {
    "text": "okay so let's let's look at some of the uh possible attacks that the adversarial",
    "start": "482000",
    "end": "488080"
  },
  {
    "text": "machine learning literature has studied over the years so there are essentially two main",
    "start": "488080",
    "end": "495599"
  },
  {
    "text": "stages at which an adversary can try to attack a machine learning system",
    "start": "495599",
    "end": "502240"
  },
  {
    "text": "there is a moment before deployment in which case the adversary tampers with",
    "start": "502240",
    "end": "508879"
  },
  {
    "text": "the learning process and this is commonly referred to as a",
    "start": "508879",
    "end": "513919"
  },
  {
    "text": "poisoning attack and there is a stage after the deployment where the adversary can",
    "start": "513919",
    "end": "520900"
  },
  {
    "text": "[Music] target like a large number of different objectives",
    "start": "520900",
    "end": "526560"
  },
  {
    "text": "and those objectives varies from just inducing a misclassification",
    "start": "526560",
    "end": "532240"
  },
  {
    "text": "for a specific data instance and we call that a vision attack um to something like inferring",
    "start": "532240",
    "end": "539279"
  },
  {
    "text": "characteristics about the training set classes uh and we in which case we talk about model inversion",
    "start": "539279",
    "end": "546320"
  },
  {
    "text": "and we're going to look at these uh categories in a little bit more depth um",
    "start": "546320",
    "end": "552399"
  },
  {
    "text": "but we're going to focus uh essentially on um low uh information version of these",
    "start": "552399",
    "end": "560399"
  },
  {
    "text": "attacks that is we are assuming that the adversary uh essentially doesn't have",
    "start": "560399",
    "end": "566959"
  },
  {
    "text": "access to the original model in most cases and is mostly limited to just",
    "start": "566959",
    "end": "572800"
  },
  {
    "text": "querying the model to an api and this is because uh this is the most",
    "start": "572800",
    "end": "579360"
  },
  {
    "text": "common variation uh of the attacks that you may be interested in that you may be able to",
    "start": "579360",
    "end": "585120"
  },
  {
    "text": "carry out in a practical sense and we're also uh try to suggest some",
    "start": "585120",
    "end": "590880"
  },
  {
    "text": "pointers to uh some um practical methods uh for carry out for",
    "start": "590880",
    "end": "596640"
  },
  {
    "text": "carrying out these attacks that are implemented in uh ibm's adversary business toolbox which is a famous",
    "start": "596640",
    "end": "604480"
  },
  {
    "text": "collection of tools for addressing machine learning",
    "start": "604480",
    "end": "608880"
  },
  {
    "start": "609000",
    "end": "609000"
  },
  {
    "text": "the first one we have is extraction an extraction in my opinion is the most foundational",
    "start": "610079",
    "end": "616160"
  },
  {
    "text": "attack primitive so it's the easiest in terms of um what you need to get started",
    "start": "616160",
    "end": "621440"
  },
  {
    "text": "you're effectively uh stealing you know effectively getting a",
    "start": "621440",
    "end": "626560"
  },
  {
    "text": "data set having a target model label it and then training um your own model",
    "start": "626560",
    "end": "632480"
  },
  {
    "text": "and you're just trying to create a functional equivalent and it's really",
    "start": "632480",
    "end": "637920"
  },
  {
    "text": "nice from an opsec perspective because you what you get control all over all the inputs so there's not an algorithm",
    "start": "637920",
    "end": "644880"
  },
  {
    "text": "that's generating inputs to send to the model so you get control you can it's a nice one-to-one ratio",
    "start": "644880",
    "end": "651440"
  },
  {
    "text": "there are no adversarial examples that get sent so in the future when there are detections for these things",
    "start": "651440",
    "end": "658480"
  },
  {
    "text": "a lot of your traffic is going to look normal once you have an offline model you can transfer it to",
    "start": "658480",
    "end": "665440"
  },
  {
    "text": "other places so you know in this example where we have that proof point of tech",
    "start": "665440",
    "end": "672560"
  },
  {
    "text": "you could you could potentially take this well you could take this model and then you could go and um run it you know",
    "start": "672800",
    "end": "678480"
  },
  {
    "text": "do a similar um attack against you know minecast or another spam filter",
    "start": "678480",
    "end": "684079"
  },
  {
    "text": "and you know your each time you copy it you're going to have to send less and less traffic",
    "start": "684079",
    "end": "689519"
  },
  {
    "text": "so you kind of gain some efficiency there it just provides you it provides you the",
    "start": "689519",
    "end": "695040"
  },
  {
    "text": "most options in that you can take you know an offline you can take your copycat model and then you can run the",
    "start": "695040",
    "end": "701279"
  },
  {
    "text": "same attacks offline as you would online so you can gain some insight",
    "start": "701279",
    "end": "706320"
  },
  {
    "text": "um there it's just it's a really simple attack um and it's i would say extremely",
    "start": "706320",
    "end": "711600"
  },
  {
    "text": "effective so if you know nothing else and you know the math is a bit frightening i think this is you know",
    "start": "711600",
    "end": "717680"
  },
  {
    "text": "going to be your bread and butter for a while",
    "start": "717680",
    "end": "722639"
  },
  {
    "text": "so in order to execute an extraction the adversary starts with an initial data",
    "start": "723120",
    "end": "729760"
  },
  {
    "text": "set which is potentially small much smaller than the one used in the",
    "start": "729760",
    "end": "735279"
  },
  {
    "text": "actual training phase of the victim model but these and this initial data set doesn't have",
    "start": "735279",
    "end": "741839"
  },
  {
    "text": "to come from the same training set but it should try to reflect as close as",
    "start": "741839",
    "end": "747680"
  },
  {
    "text": "possible the original data distribution used for the victim model",
    "start": "747680",
    "end": "752959"
  },
  {
    "text": "and the adversary also needs the ability to submit inputs to the model obviously and",
    "start": "752959",
    "end": "758639"
  },
  {
    "text": "observe the outputs um the process is iterative the adversary",
    "start": "758639",
    "end": "766240"
  },
  {
    "text": "can augment their local data set and then send uh this local information",
    "start": "766240",
    "end": "773360"
  },
  {
    "text": "to the modules to collect uh stolen labels uh so labeled from for those data",
    "start": "773360",
    "end": "779440"
  },
  {
    "text": "points and these new labels can then be used to actually train a copycat of the",
    "start": "779440",
    "end": "787760"
  },
  {
    "text": "victim model a couple of import interesting algorithms to",
    "start": "787760",
    "end": "794399"
  },
  {
    "text": "carry out these attacks are copycat cnn from korea silva and others and",
    "start": "794399",
    "end": "800639"
  },
  {
    "text": "functionally equivalent extractions from jagielski and others and you should",
    "start": "800639",
    "end": "806320"
  },
  {
    "text": "consider using extraction attacks whenever uh whenever you can essentially",
    "start": "806320",
    "end": "812320"
  },
  {
    "text": "whenever you have the ability to query the model with a large number of inputs",
    "start": "812320",
    "end": "818800"
  },
  {
    "text": "it is often a very valuable outcome to try to create a local copy of",
    "start": "818800",
    "end": "825920"
  },
  {
    "text": "the victim model next we have an evasion attack so this is adversarial machine learning 101 and",
    "start": "825920",
    "end": "833040"
  },
  {
    "start": "829000",
    "end": "829000"
  },
  {
    "text": "i would say it's most concerned with bypassing classifiers but you know if you were to look up adversarial machine",
    "start": "833040",
    "end": "838480"
  },
  {
    "text": "learning on google this is what you're going to find from an operational perspective",
    "start": "838480",
    "end": "844720"
  },
  {
    "text": "you only have control over the initial samples from then on an algorithm is going to",
    "start": "844720",
    "end": "850800"
  },
  {
    "text": "make changes and send traffic to your target and try and um",
    "start": "850800",
    "end": "857040"
  },
  {
    "text": "figure out what it needs to change to get the label to switch you also get some noisy inputs so you",
    "start": "857040",
    "end": "862639"
  },
  {
    "text": "don't always have control and we'll talk about some of this later but",
    "start": "862639",
    "end": "868720"
  },
  {
    "text": "the initial image might look like noise versus that original image of a tractor or a koala so you know once it takes in",
    "start": "868720",
    "end": "875839"
  },
  {
    "text": "that image you kind of have very limited control about what it does to it so from a detection standpoint",
    "start": "875839",
    "end": "882320"
  },
  {
    "text": "you know if if some machine learning engineer is looking in their application all of a sudden they start seeing images",
    "start": "882320",
    "end": "887760"
  },
  {
    "text": "that look like tv static right that that's an indication that something might be um wrong",
    "start": "887760",
    "end": "894720"
  },
  {
    "text": "uh it's more direct than extraction so you know rather than having to go",
    "start": "894720",
    "end": "900240"
  },
  {
    "text": "through uh an intermediary process of creating a copycat model um it just",
    "start": "900240",
    "end": "905920"
  },
  {
    "text": "interacts with the target model directly and there are lots of variations and it",
    "start": "905920",
    "end": "911040"
  },
  {
    "text": "will work with a given number of queries um it will work but you really don't have any idea",
    "start": "911040",
    "end": "916800"
  },
  {
    "text": "about how many queries that is so it could be um 500 it could be 5 000 if you get the",
    "start": "916800",
    "end": "923600"
  },
  {
    "text": "parameters right then it could be 50. so it's",
    "start": "923600",
    "end": "928880"
  },
  {
    "text": "i think it is a better attack than extraction if you have",
    "start": "928880",
    "end": "936000"
  },
  {
    "text": "the right parameters but the cost of getting those parameters is relatively high",
    "start": "936000",
    "end": "942399"
  },
  {
    "text": "as opposed to just starting with an extraction attack in the previous",
    "start": "942399",
    "end": "948399"
  },
  {
    "text": "so as while the core idea as we mentioned behind the vision attack is conceptually",
    "start": "949199",
    "end": "955680"
  },
  {
    "text": "quite simple the implementation of these attacks in limited knowledge scenarios can get a",
    "start": "955680",
    "end": "961759"
  },
  {
    "text": "little complex essentially in general the adversary starts with a target sample",
    "start": "961759",
    "end": "969519"
  },
  {
    "text": "and for which the adversary wants to construct a perturbation that will force",
    "start": "969519",
    "end": "976560"
  },
  {
    "text": "the classifier to misclassify this sample",
    "start": "976560",
    "end": "981680"
  },
  {
    "text": "uh the adversary also is assumed to have the ability to modify the sample to some",
    "start": "981680",
    "end": "987440"
  },
  {
    "text": "extent and uh query the model and",
    "start": "987440",
    "end": "993600"
  },
  {
    "text": "this is an iterative optimization process where",
    "start": "993600",
    "end": "998639"
  },
  {
    "text": "at least for most limited knowledge evasion attacks",
    "start": "998639",
    "end": "1005360"
  },
  {
    "text": "and this optimization process uses the output of the victim model on the modified sample",
    "start": "1005360",
    "end": "1012079"
  },
  {
    "text": "to guide successive changes towards the direction that increases",
    "start": "1012079",
    "end": "1018320"
  },
  {
    "text": "loss over the target point",
    "start": "1018320",
    "end": "1024400"
  },
  {
    "text": "and the result obviously is a perturbation and upper third point",
    "start": "1024400",
    "end": "1031520"
  },
  {
    "text": "uh that would be misclassified and there are actually a",
    "start": "1031520",
    "end": "1037038"
  },
  {
    "text": "large quantity of different types of evasion attacks there are [Music]",
    "start": "1037039",
    "end": "1043360"
  },
  {
    "text": "targeted evasion attacks where the adversary wants to",
    "start": "1043360",
    "end": "1049120"
  },
  {
    "text": "change the output label from the true label to a specific target label",
    "start": "1049120",
    "end": "1054640"
  },
  {
    "text": "uh in this case from airport airport to stadium but there are also untargeted elevation",
    "start": "1054640",
    "end": "1061039"
  },
  {
    "text": "attacks where any target any label returned that is different from the true label is",
    "start": "1061039",
    "end": "1067919"
  },
  {
    "text": "considered a successful division and it is also known that a vision",
    "start": "1067919",
    "end": "1074160"
  },
  {
    "text": "attack tend to transfer so once an adversarial sample is found for a",
    "start": "1074160",
    "end": "1081360"
  },
  {
    "text": "specific model then it often transfers to",
    "start": "1081360",
    "end": "1086480"
  },
  {
    "text": "a model trained on slightly different data or trained with slightly different architectures",
    "start": "1086480",
    "end": "1094000"
  },
  {
    "text": "um the a couple of uh powerful algorithms to",
    "start": "1094000",
    "end": "1099120"
  },
  {
    "text": "carry out these kind of attacks are hop skip jump uh this is worked by chen and",
    "start": "1099120",
    "end": "1104720"
  },
  {
    "text": "others and it required hard labels that are essentially",
    "start": "1104720",
    "end": "1110240"
  },
  {
    "text": "it assumes hard labels so essentially the output of the model is just a numerical label",
    "start": "1110240",
    "end": "1116559"
  },
  {
    "text": "and uh square attacks uh which is worked by andrew schenko and others",
    "start": "1116559",
    "end": "1122000"
  },
  {
    "text": "in which case the adversary is assumed to have access to the uh scores that",
    "start": "1122000",
    "end": "1128400"
  },
  {
    "text": "the model the victim model returns in output",
    "start": "1128400",
    "end": "1133120"
  },
  {
    "text": "and uh this is again an iterative process uh to find analytic samples",
    "start": "1133760",
    "end": "1139280"
  },
  {
    "text": "and uh you would obviously use this kind of attacks to bypass a classifier for instance a spam or a marble classifier",
    "start": "1139280",
    "end": "1147919"
  },
  {
    "start": "1147000",
    "end": "1147000"
  },
  {
    "text": "this next one um inversion so you're recovering training data from a trained model",
    "start": "1147919",
    "end": "1153760"
  },
  {
    "text": "um but in the image setting it really can only reconstruct a representation of that image so it doesn't actually get",
    "start": "1153760",
    "end": "1159840"
  },
  {
    "text": "the original training image but in large language model settings um it becomes really interesting when you",
    "start": "1159840",
    "end": "1166799"
  },
  {
    "text": "start talking about large language models um memorizing input",
    "start": "1166799",
    "end": "1172080"
  },
  {
    "text": "um and really it's a privacy attack so you're looking for a privacy violation",
    "start": "1172080",
    "end": "1178880"
  },
  {
    "text": "in in this case the adversary is assumed to have the ability again to query the model and",
    "start": "1178880",
    "end": "1185600"
  },
  {
    "text": "in this case they need the ability to obtain confidence scores on the prediction",
    "start": "1185600",
    "end": "1192080"
  },
  {
    "text": "and they also need to know the label for which they are trying to reconstruct",
    "start": "1192080",
    "end": "1198000"
  },
  {
    "text": "represented examples and this this is an optimization process where",
    "start": "1198000",
    "end": "1205200"
  },
  {
    "text": "the point is sent to the victim model to collect information and then modified in order to maximize",
    "start": "1205200",
    "end": "1212640"
  },
  {
    "text": "the confidence of the mct of the victim model on that point towards the target",
    "start": "1212640",
    "end": "1217919"
  },
  {
    "text": "class target label and at the end of this uh iterative optimization process the",
    "start": "1217919",
    "end": "1223679"
  },
  {
    "text": "original uh point the regional image is modified to encode meaningful features",
    "start": "1223679",
    "end": "1229600"
  },
  {
    "text": "of the target class and an example of this is the me phase attack by frederickson and others",
    "start": "1229600",
    "end": "1236720"
  },
  {
    "text": "next we have inference and really you're looking to determine if a training point or that data point was in a training set",
    "start": "1239360",
    "end": "1246960"
  },
  {
    "text": "and it exploits you know the confidence about um or a model's confidence about an input that it's seen before",
    "start": "1246960",
    "end": "1254080"
  },
  {
    "text": "and there are two types of um inference we're going to only cover membership inference",
    "start": "1254080",
    "end": "1260159"
  },
  {
    "text": "but really here you're just looking for the triangulation of information so a lot of the literature talks about having",
    "start": "1260159",
    "end": "1265919"
  },
  {
    "text": "access to the training set because they have access to the training set um but if you imagine right there's",
    "start": "1265919",
    "end": "1271919"
  },
  {
    "text": "a lot of um data that you can pull after it's sorrel for example and it's a",
    "start": "1271919",
    "end": "1278320"
  },
  {
    "text": "big mallet it's got eight terabytes of malware in it so if you were looking to see if a particular",
    "start": "1278320",
    "end": "1284320"
  },
  {
    "text": "um data point let's say your malware was in the sorrel data set you could you know",
    "start": "1284320",
    "end": "1290480"
  },
  {
    "text": "run this attack against that classifier um and see if your malware or infer if",
    "start": "1290480",
    "end": "1296880"
  },
  {
    "text": "your malware is in it um though you know if your malware's in sorrel it was already in the data set",
    "start": "1296880",
    "end": "1303200"
  },
  {
    "text": "you'd be able to see it you just have to search through that eight terabytes um so really this is useful you know if in",
    "start": "1303200",
    "end": "1309280"
  },
  {
    "text": "a black box setting um where you're maybe trying to gain some additional insight or an additional edge or",
    "start": "1309280",
    "end": "1316000"
  },
  {
    "text": "additional information into the target system for uh membership inference attacks um",
    "start": "1316000",
    "end": "1323760"
  },
  {
    "text": "the as we mentioned exploit the observation that a machine learning model",
    "start": "1323760",
    "end": "1329280"
  },
  {
    "text": "behaves differently uh when it encounters a data point that it has already seen in the training set",
    "start": "1329280",
    "end": "1337440"
  },
  {
    "text": "versus when that new point is observed for the first time",
    "start": "1337440",
    "end": "1342799"
  },
  {
    "text": "during testing um the process uh is a little complex but the",
    "start": "1342799",
    "end": "1349679"
  },
  {
    "text": "attacker would essentially use the output of the victim models on",
    "start": "1349679",
    "end": "1355360"
  },
  {
    "text": "a starting data point um to uh",
    "start": "1355360",
    "end": "1360559"
  },
  {
    "text": "try and build local shadow models um for each class and then use the ensemble of",
    "start": "1360559",
    "end": "1366880"
  },
  {
    "text": "these models to train a classifier that discovers whether the target point is",
    "start": "1366880",
    "end": "1372960"
  },
  {
    "text": "part of the training set or not a powerful algorithm to do this in a",
    "start": "1372960",
    "end": "1380559"
  },
  {
    "text": "label-only setting is the label on only boundary distance attacks by a shortcut shoe and",
    "start": "1380559",
    "end": "1387919"
  },
  {
    "text": "others and essentially as we'll mention this is a privacy leakage attack",
    "start": "1387919",
    "end": "1394799"
  },
  {
    "text": "so you should use it when there is a gain to be made by inferring private",
    "start": "1394799",
    "end": "1400320"
  },
  {
    "text": "information about some participant in the training set of a specific victim",
    "start": "1400320",
    "end": "1406400"
  },
  {
    "text": "model and finally we have poisoning and poisoning is you know effectively just",
    "start": "1406400",
    "end": "1412960"
  },
  {
    "start": "1409000",
    "end": "1409000"
  },
  {
    "text": "the influence in the creation of the acceptance of a model um while it's in deployment so we're",
    "start": "1412960",
    "end": "1419520"
  },
  {
    "text": "most familiar with this in a supply chain context if you think of the recent",
    "start": "1419520",
    "end": "1424799"
  },
  {
    "text": "solarwinds attacks this is that for machine learning",
    "start": "1424799",
    "end": "1430080"
  },
  {
    "text": "and there's a number of different ways that you can poison a model but it it's it requires the most access to a system",
    "start": "1430080",
    "end": "1436159"
  },
  {
    "text": "so you know or you need to have an ability to inject data into a training set so",
    "start": "1436159",
    "end": "1442960"
  },
  {
    "text": "you know there are um there are ways you could do this you know in a black box fashion",
    "start": "1442960",
    "end": "1448799"
  },
  {
    "text": "but you you don't know unless you know how that data is being processed um",
    "start": "1448799",
    "end": "1454640"
  },
  {
    "text": "through that pipeline and where it's going to be given back to you it can be really difficult to know whether or not you've",
    "start": "1454640",
    "end": "1461360"
  },
  {
    "text": "been successful so this is i would say the hardest",
    "start": "1461360",
    "end": "1466400"
  },
  {
    "text": "attack to pull off just in terms of the act the type of access you need type of",
    "start": "1466400",
    "end": "1472000"
  },
  {
    "text": "feedback you need to know if you're successful and then also just the understanding of what needs to happen",
    "start": "1472000",
    "end": "1479679"
  },
  {
    "text": "so uh yeah as we mentioned critical for carrying out any form of poisoning",
    "start": "1481279",
    "end": "1486960"
  },
  {
    "text": "attack is the ability to alter in some way the training process",
    "start": "1486960",
    "end": "1492159"
  },
  {
    "text": "now there are uh there is a wide spectrum of possible objectives for poisoning attacks varying",
    "start": "1492159",
    "end": "1499600"
  },
  {
    "text": "from a very high impact widespread",
    "start": "1499600",
    "end": "1505440"
  },
  {
    "text": "similar to denial of service objective that is often referred to as availability",
    "start": "1505440",
    "end": "1511919"
  },
  {
    "text": "poisoning to very specific targeted um attacks that uh",
    "start": "1511919",
    "end": "1518640"
  },
  {
    "text": "make the model misclassify just one or a few instances",
    "start": "1518640",
    "end": "1524080"
  },
  {
    "text": "of of the test set in which case we talk about targeted poisoning attacks",
    "start": "1524080",
    "end": "1529679"
  },
  {
    "text": "there are also vector attacks where the attacker also has",
    "start": "1529679",
    "end": "1536480"
  },
  {
    "text": "wants to induce the model to associate a specific trigger backdoor trigger with a",
    "start": "1536480",
    "end": "1542640"
  },
  {
    "text": "specific class and this kind of attack requires the ability to also modify the point at",
    "start": "1542640",
    "end": "1549200"
  },
  {
    "text": "testing time and again usually the way in which the",
    "start": "1549200",
    "end": "1554320"
  },
  {
    "text": "attack attacker tampers with the training process is by injecting or modifying data in the training set",
    "start": "1554320",
    "end": "1561840"
  },
  {
    "text": "and a couple of algorithms for doing these kind of",
    "start": "1561840",
    "end": "1566880"
  },
  {
    "text": "attacks are bad nets which is a vector style attack by gu and others",
    "start": "1566880",
    "end": "1572480"
  },
  {
    "text": "and the bullseye polytope attack",
    "start": "1572480",
    "end": "1577440"
  },
  {
    "text": "and the when you would use it is uh strictly during the training phase so if",
    "start": "1577760",
    "end": "1584559"
  },
  {
    "text": "you want to [Music] condition the final",
    "start": "1584559",
    "end": "1590880"
  },
  {
    "text": "model that will be deployed so that's an overview of the attacks so",
    "start": "1590880",
    "end": "1597440"
  },
  {
    "text": "all of the algorithms we gave in the previous section those are all in art and they're all black box attacks",
    "start": "1597440",
    "end": "1604799"
  },
  {
    "text": "and so you can go and run those now against you know any model you find i'd say with the exception of poisoning",
    "start": "1604799",
    "end": "1610240"
  },
  {
    "text": "because you do need some access there but those should be available to you",
    "start": "1610240",
    "end": "1615919"
  },
  {
    "text": "so next we're just going to talk about some um",
    "start": "1615919",
    "end": "1620639"
  },
  {
    "text": "terms and things that i was unaware of when i started and fortunately we have giorgio here to explain them um for us",
    "start": "1620960",
    "end": "1627760"
  },
  {
    "text": "so first we do hard versus soft labels yes so this is refers to the output of",
    "start": "1627760",
    "end": "1635919"
  },
  {
    "text": "the victim model and we kind of covered this before but",
    "start": "1635919",
    "end": "1640960"
  },
  {
    "text": "essentially information about the confidence of the",
    "start": "1640960",
    "end": "1647039"
  },
  {
    "text": "model or the probabilities returned by the model are often very useful for adversarial",
    "start": "1647039",
    "end": "1653919"
  },
  {
    "text": "machine learning um and for essentially running attacks in general uh because these uh soft",
    "start": "1653919",
    "end": "1661360"
  },
  {
    "text": "labels as they're called provide information about in which direction um",
    "start": "1661360",
    "end": "1667520"
  },
  {
    "text": "the changes the perturbation to point are moving the classification output so",
    "start": "1667520",
    "end": "1673679"
  },
  {
    "text": "from an attacker point of view uh obviously more information is essentially always better um",
    "start": "1673679",
    "end": "1680640"
  },
  {
    "text": "and it is very useful to know that a specific perturbation that you are",
    "start": "1680640",
    "end": "1686000"
  },
  {
    "text": "applying to your target point is moving for instance declassification",
    "start": "1686000",
    "end": "1692880"
  },
  {
    "text": "um from the original label of cut to uh more like a dog",
    "start": "1692880",
    "end": "1700080"
  },
  {
    "start": "1699000",
    "end": "1699000"
  },
  {
    "text": "next lossy compression so if you imagine during an invasion attack you know you",
    "start": "1700880",
    "end": "1706799"
  },
  {
    "text": "have run an attack against a class a malware classifier let's say and or in this case an image",
    "start": "1706799",
    "end": "1713600"
  },
  {
    "text": "and you save your image as a jpeg and during the save that writing to disk",
    "start": "1713600",
    "end": "1719360"
  },
  {
    "text": "jpeg is going to run a compression algorithm and it's going to overwrite those perturbations those changes that",
    "start": "1719360",
    "end": "1725440"
  },
  {
    "text": "you made to that input so if you've ever you know encoded a payload and then tried to",
    "start": "1725440",
    "end": "1732399"
  },
  {
    "text": "decode it on the other side and wondered why it didn't work this would be that process where",
    "start": "1732399",
    "end": "1738480"
  },
  {
    "text": "you encode your payload in jpeg and then you don't get the same thing back",
    "start": "1738480",
    "end": "1745039"
  },
  {
    "text": "in this next one the algorithmic behavior so just like in",
    "start": "1749919",
    "end": "1755360"
  },
  {
    "text": "offensive security you know with malware you should really understand how your tools work uh this is the same thing so",
    "start": "1755360",
    "end": "1763039"
  },
  {
    "text": "however you initialize like um an algorithm where you don't have control necessarily over how it gets uh",
    "start": "1763039",
    "end": "1769840"
  },
  {
    "text": "initialized where it is with the first sample or the information it needs and so sometimes for example if you're not",
    "start": "1769840",
    "end": "1776320"
  },
  {
    "text": "aware of it like i wasn't a hop skip jump attack can either give you the first image is a really noisy",
    "start": "1776320",
    "end": "1783840"
  },
  {
    "text": "image where you know if you send that off right your detection threshold is much higher versus if you send them a",
    "start": "1783840",
    "end": "1789760"
  },
  {
    "text": "more normal image and that has to do with the initialization um of the algorithm that you're using so just",
    "start": "1789760",
    "end": "1795600"
  },
  {
    "text": "being aware of of how that traffic flow gets changed in the middle of uh in the",
    "start": "1795600",
    "end": "1801760"
  },
  {
    "text": "middle of an attack",
    "start": "1801760",
    "end": "1804559"
  },
  {
    "start": "1803000",
    "end": "1803000"
  },
  {
    "text": "there are also uh many different uh many different possible distance metrics that can be",
    "start": "1807279",
    "end": "1814000"
  },
  {
    "text": "used to evaluate an attack and um essentially to evaluate the",
    "start": "1814000",
    "end": "1821440"
  },
  {
    "text": "magnitude of the perturbation that is applied applied to a testing point",
    "start": "1821440",
    "end": "1826559"
  },
  {
    "text": "um three of the most famous ones are the euclidean or the l2",
    "start": "1826559",
    "end": "1832240"
  },
  {
    "text": "manaten or l1 and infinity l infinity norm",
    "start": "1832240",
    "end": "1838000"
  },
  {
    "text": "and they were originally used because they encode valuable information",
    "start": "1838000",
    "end": "1846720"
  },
  {
    "text": "regarding the differences that the human vision system",
    "start": "1846720",
    "end": "1852159"
  },
  {
    "text": "can capture in two different images like a perturbed image",
    "start": "1852159",
    "end": "1858559"
  },
  {
    "text": "but you would essentially want to use the correct distance metric for your",
    "start": "1859519",
    "end": "1866640"
  },
  {
    "text": "specific uh attack and for your specific data modality so for instance uh the",
    "start": "1866640",
    "end": "1873039"
  },
  {
    "text": "euclidean distance may work very well for images but may not work that well",
    "start": "1873039",
    "end": "1879679"
  },
  {
    "text": "for different uh data modalities like feature vectors",
    "start": "1879679",
    "end": "1885600"
  },
  {
    "text": "where large differences uh large numerical differences in the",
    "start": "1885600",
    "end": "1890720"
  },
  {
    "text": "components of the vectors uh may not correspond uh to large semantical",
    "start": "1890720",
    "end": "1897200"
  },
  {
    "text": "differences in the actual data so if you think about you know normally",
    "start": "1897200",
    "end": "1902799"
  },
  {
    "text": "we might increase the distance between our current malicious sample",
    "start": "1902799",
    "end": "1909200"
  },
  {
    "text": "and what a model thinks of a piece of malware and normally we do it with you know new techniques like if you",
    "start": "1909200",
    "end": "1914880"
  },
  {
    "text": "think about um lull bins or application whitelisting right there's a lot of research into",
    "start": "1914880",
    "end": "1920240"
  },
  {
    "text": "finding new ways to execute things and what you're effectively doing there is right increasing",
    "start": "1920240",
    "end": "1926640"
  },
  {
    "text": "your distance from what's a detection like what something thinks is malicious",
    "start": "1926640",
    "end": "1931840"
  },
  {
    "text": "and it's the same process except you know it's in a numerical way and we're you're doing it with an algorithm rather",
    "start": "1931840",
    "end": "1938000"
  },
  {
    "text": "than you know uh research that you've done um so for our final um little piece",
    "start": "1938000",
    "end": "1944000"
  },
  {
    "text": "we're just going to talk about um the attack surface and where you can find uh machine learning systems to attack",
    "start": "1944000",
    "end": "1951679"
  },
  {
    "start": "1951000",
    "end": "1951000"
  },
  {
    "text": "um obviously we have our friend oscent uh google dorks uh shoden grey hat",
    "start": "1951679",
    "end": "1956799"
  },
  {
    "text": "warfare buckets right this is an image of a bucket so there are or from gray hat warfare than where it came from",
    "start": "1956799",
    "end": "1964399"
  },
  {
    "text": "um a few slides there's going to be a lot of common file types that we're going to see and you can just search for those",
    "start": "1964399",
    "end": "1971679"
  },
  {
    "text": "um there's a tool that was just released by alcate fingerprinting sir his libato ml so he",
    "start": "1971679",
    "end": "1978640"
  },
  {
    "text": "has an an nmap script that will go in fingerprint servers for these things uh you could go through patent",
    "start": "1978640",
    "end": "1985440"
  },
  {
    "text": "documentation and then go look at the slide or go look at the archive submission that you know that paper that",
    "start": "1985440",
    "end": "1992480"
  },
  {
    "text": "patent references and you can probably pull out a lot of information about how the algorithm or that product's working",
    "start": "1992480",
    "end": "1998720"
  },
  {
    "text": "documentation you know it's fairly classic stuff um inference traffic you know you can",
    "start": "1998720",
    "end": "2005600"
  },
  {
    "start": "2003000",
    "end": "2003000"
  },
  {
    "text": "find a lot in infrastructure this is how we found the proof point of tech um this if you go look at the amsi",
    "start": "2005600",
    "end": "2011360"
  },
  {
    "text": "documentation you know it's going to say it's going to give you a value between 1 and 3 768 right so you know there are a",
    "start": "2011360",
    "end": "2019519"
  },
  {
    "text": "number of integers that it could return so maybe if you go look at an amsi provider like",
    "start": "2019519",
    "end": "2025519"
  },
  {
    "text": "a crowdstrike provider maybe they return more information um that you can latch on to",
    "start": "2025519",
    "end": "2031679"
  },
  {
    "text": "right versus zero or one ismail or isn't malware hard label versus a softer label",
    "start": "2031679",
    "end": "2037919"
  },
  {
    "text": "um you know zero through 999. so look in headers um if you if you find",
    "start": "2037919",
    "end": "2044080"
  },
  {
    "text": "a numeric value and a seemingly arbitrary place you know that would be something to look at",
    "start": "2044080",
    "end": "2049599"
  },
  {
    "text": "um it's it's kind of everywhere uh but you it's not it's never the it's",
    "start": "2049599",
    "end": "2056480"
  },
  {
    "text": "never out front so it's always underneath something else",
    "start": "2056480",
    "end": "2061839"
  },
  {
    "start": "2059000",
    "end": "2059000"
  },
  {
    "text": "there are also some very common file extensions that you should look for",
    "start": "2063040",
    "end": "2069358"
  },
  {
    "text": "that are often used to encode either data files so collection",
    "start": "2069359",
    "end": "2076480"
  },
  {
    "text": "uh of data sets that are used in the training or testing of models",
    "start": "2076480",
    "end": "2081839"
  },
  {
    "text": "and um other data files that are used for encoding",
    "start": "2081839",
    "end": "2086960"
  },
  {
    "text": "models for deploying machine learning models in real systems some examples are for",
    "start": "2086960",
    "end": "2093839"
  },
  {
    "text": "instance h5 and hd5 which are data files",
    "start": "2093839",
    "end": "2099680"
  },
  {
    "text": "csv is obviously a very very well known one numpy files are",
    "start": "2099680",
    "end": "2105920"
  },
  {
    "text": "also used to collect data",
    "start": "2105920",
    "end": "2111040"
  },
  {
    "text": "while models may leave in pixel files on nx files and",
    "start": "2111200",
    "end": "2118480"
  },
  {
    "text": "other like that and it is uh valuable to familiarize",
    "start": "2118480",
    "end": "2124880"
  },
  {
    "text": "yourself with these different file extensions and the frameworks uh",
    "start": "2124880",
    "end": "2130720"
  },
  {
    "text": "that are commonly using them uh for instance keras tensorflow pytorch",
    "start": "2130720",
    "end": "2137359"
  },
  {
    "text": "numpy and so on",
    "start": "2137359",
    "end": "2141838"
  },
  {
    "start": "2142000",
    "end": "2142000"
  },
  {
    "text": "and finally um tooling and there is also a bus choice of tools",
    "start": "2142880",
    "end": "2149359"
  },
  {
    "text": "to perform adversarial attacks uh defenses and in generally to evaluate the robust robustness of models",
    "start": "2149359",
    "end": "2157200"
  },
  {
    "text": "and some of these tools come from the academic community while some of them come from",
    "start": "2157200",
    "end": "2164480"
  },
  {
    "text": "industry players some like the adversary robust toolbox art",
    "start": "2164480",
    "end": "2171040"
  },
  {
    "text": "full box second ml and cleverhands they provide a broad range of implementations",
    "start": "2171040",
    "end": "2177760"
  },
  {
    "text": "of attacks that can be used to evaluate models",
    "start": "2177760",
    "end": "2183760"
  },
  {
    "text": "and others are more specific to a single data modality like text attack which is",
    "start": "2183760",
    "end": "2191280"
  },
  {
    "text": "obviously focused on nlp models as the name implies",
    "start": "2191280",
    "end": "2196400"
  },
  {
    "text": "and finally there are systems like counterfeit which merge together different adversarial machine learning",
    "start": "2196400",
    "end": "2203200"
  },
  {
    "text": "libraries and toolboxes to expedite testing on",
    "start": "2203200",
    "end": "2209839"
  },
  {
    "text": "both development development and production models by providing sort of a unified interface",
    "start": "2209839",
    "end": "2216640"
  },
  {
    "text": "the counterfeit was built uh by us internally and it really just it's just a wrapper for",
    "start": "2216640",
    "end": "2222560"
  },
  {
    "text": "a lot of these academic frameworks so as we've been mentioning as we talked about in the beginning like this",
    "start": "2222560",
    "end": "2228160"
  },
  {
    "text": "relationship between academic um research and industry",
    "start": "2228160",
    "end": "2233920"
  },
  {
    "text": "use cases you know i i don't have the broad or the depth of knowledge that giorgio and the academic community has",
    "start": "2233920",
    "end": "2241040"
  },
  {
    "text": "so i really needed a way to help um scale you know my offensive knowledge and counterfeit was that was that",
    "start": "2241040",
    "end": "2247760"
  },
  {
    "text": "solution for me so it has a familiar interface you know if you're familiar with powershell empire or",
    "start": "2247760",
    "end": "2254320"
  },
  {
    "text": "cobalt strike it has a similar workflows but it is it is focused on really",
    "start": "2254320",
    "end": "2259760"
  },
  {
    "text": "attaching um some algorithm to an arbitrary endpoint so it does focus on on blackbox testing",
    "start": "2259760",
    "end": "2266320"
  },
  {
    "text": "um rather than white box testing if only because the majority of the tests we do are our black box",
    "start": "2266320",
    "end": "2274320"
  },
  {
    "start": "2274000",
    "end": "2274000"
  },
  {
    "text": "then finally you know we just want to talk quickly about some capability development so as you're going through and you're uh",
    "start": "2275280",
    "end": "2281680"
  },
  {
    "text": "think working this through your your operations or you're finding things in file shares",
    "start": "2281680",
    "end": "2287040"
  },
  {
    "text": "um or you're starting to look through uh all of look for all of the common",
    "start": "2287040",
    "end": "2292079"
  },
  {
    "text": "file types that we we put in the slide above um start collecting and storing data or",
    "start": "2292079",
    "end": "2297680"
  },
  {
    "text": "generating data right there's a there's a big uh body of research around augmenting data",
    "start": "2297680",
    "end": "2304000"
  },
  {
    "text": "so there's a powershell scripts repo out there there's a vba macro um",
    "start": "2304000",
    "end": "2309430"
  },
  {
    "text": "[Music] data sets like there's nine gigs of vba macros which i think would be a",
    "start": "2309430",
    "end": "2315440"
  },
  {
    "text": "pretty powerful data set to go and steal uh a classifier that you could bypass",
    "start": "2315440",
    "end": "2321520"
  },
  {
    "text": "um whenever you run an attack against a particular model collect and store those successful examples like store",
    "start": "2321520",
    "end": "2328320"
  },
  {
    "text": "those parameters store the images that come off um of those attacks and maybe think of them",
    "start": "2328320",
    "end": "2334560"
  },
  {
    "text": "like ttps like that you could go and use them against another model um there is a",
    "start": "2334560",
    "end": "2340960"
  },
  {
    "text": "some research called damage net that has gone through and sort of mined for these",
    "start": "2340960",
    "end": "2346079"
  },
  {
    "text": "adversarial examples so you could might be a good place to start um",
    "start": "2346079",
    "end": "2351440"
  },
  {
    "text": "store those algorithmic parameters so you know the parameters are make or break so whenever you have a success",
    "start": "2351440",
    "end": "2356640"
  },
  {
    "text": "keep them you know they're going to lower your costs long term and you know you can't get away from the",
    "start": "2356640",
    "end": "2362320"
  },
  {
    "text": "fact that you need to send traffic so anytime you can lower those costs now or in the future it's going to be valuable",
    "start": "2362320",
    "end": "2368880"
  },
  {
    "text": "train store models so every time you run an attack train a model alongside your attack and",
    "start": "2368880",
    "end": "2375040"
  },
  {
    "text": "then store it and then you use it for transferability and then of course you can go build all the infrastructure to do it and now",
    "start": "2375040",
    "end": "2381119"
  },
  {
    "text": "you're just an ml engineer so that the other side of the coin is obviously you know if you want to write",
    "start": "2381119",
    "end": "2387359"
  },
  {
    "text": "exploits it helps to be a developer if you want to attack machine learning it helps you know to be a phd student be a phd",
    "start": "2387359",
    "end": "2394800"
  },
  {
    "text": "student or be an ml engineer where you can automate these things and you should definitely separate like",
    "start": "2394800",
    "end": "2401040"
  },
  {
    "text": "your production attacks from your data collection efforts so you know if you want to run a similar style proof point",
    "start": "2401040",
    "end": "2408880"
  },
  {
    "text": "attack right don't send you know the templates that you would normally send send you know other things",
    "start": "2408880",
    "end": "2415760"
  },
  {
    "text": "send other representative samples or you know don't use your own malware use other people's malware to get these",
    "start": "2415760",
    "end": "2421040"
  },
  {
    "text": "scores so build separate infrastructure and then use them use that use that data collection",
    "start": "2421040",
    "end": "2426960"
  },
  {
    "text": "infrastructure to support you know your ops",
    "start": "2426960",
    "end": "2431440"
  },
  {
    "text": "then finally the conclusion um is sort of here's here's the zen so",
    "start": "2432079",
    "end": "2437599"
  },
  {
    "text": "it's like everything you can find in a model is already there so it's been trained",
    "start": "2437599",
    "end": "2444000"
  },
  {
    "text": "um but i'd say with the exception of poisoning obviously everything has been trained it's a matter of kind of",
    "start": "2444000",
    "end": "2450240"
  },
  {
    "text": "computation and your ability to optimize or extract information in the",
    "start": "2450240",
    "end": "2455680"
  },
  {
    "text": "most efficient way so unlike software you're not going to introduce new code you can't",
    "start": "2455680",
    "end": "2462400"
  },
  {
    "text": "you're not going to introduce new code into a trained model you're not going to introduce new data points into",
    "start": "2462400",
    "end": "2468079"
  },
  {
    "text": "a trained classifier unless you're in that place for poisoning and so it's very one for one like that",
    "start": "2468079",
    "end": "2474400"
  },
  {
    "text": "and it's very i think reflective in in that way the same techniques that are used to",
    "start": "2474400",
    "end": "2480000"
  },
  {
    "text": "build are the same techniques that are used to break and this is true sort of everywhere so",
    "start": "2480000",
    "end": "2485680"
  },
  {
    "text": "if you don't have an understanding of an algorithm or the foundational principles behind optimization",
    "start": "2485680",
    "end": "2491520"
  },
  {
    "text": "um you're going to have a hard time or you're going to be uh a script kitty version of an of of an",
    "start": "2491520",
    "end": "2499040"
  },
  {
    "text": "attacker right for a while but we all start somewhere we'll start um with the basics with the foundations but",
    "start": "2499040",
    "end": "2505839"
  },
  {
    "text": "that shouldn't deter you from from trying these things right if organizations are going to be",
    "start": "2505839",
    "end": "2511200"
  },
  {
    "text": "implementing it someone has to have to secure it then as you go through and you read the",
    "start": "2511200",
    "end": "2516240"
  },
  {
    "text": "literature try and apply that white box theory to a black box setting so as you come to more knowledge",
    "start": "2516240",
    "end": "2523599"
  },
  {
    "text": "of algorithms and optimization methods you know go back through the white box attacks and then",
    "start": "2523599",
    "end": "2529119"
  },
  {
    "text": "figure out you know how you could apply it in a black box setting um",
    "start": "2529119",
    "end": "2535880"
  },
  {
    "start": "2534000",
    "end": "2534000"
  },
  {
    "text": "and again these attacks aren't futuristic they're here and now you know i have an entire job that revolves",
    "start": "2536000",
    "end": "2541359"
  },
  {
    "text": "around attacking them giorgio's phd revolves around attacking these models um you know a lot of the attacks once",
    "start": "2541359",
    "end": "2548480"
  },
  {
    "text": "you get down to it they're kind of simple you know there's there is a complexity to them that is awesome but",
    "start": "2548480",
    "end": "2554480"
  },
  {
    "text": "they they do have their roots in a strong foundation um a lot of the security activities that",
    "start": "2554480",
    "end": "2560800"
  },
  {
    "text": "we do to protect regular models um transfer into the machine learning realm like the you know we don't have to",
    "start": "2560800",
    "end": "2567599"
  },
  {
    "text": "reinvent the security wheel necessarily there are some new things we're going to need to do but for the majority",
    "start": "2567599",
    "end": "2573599"
  },
  {
    "text": "or at least for now you know we can start translating like things like vlogging like that's a very basic",
    "start": "2573599",
    "end": "2578800"
  },
  {
    "text": "premise and then just that implicit relationship between giorgio and i and academia and",
    "start": "2578800",
    "end": "2586319"
  },
  {
    "text": "the industry offensive security like go and find a giorgio who can answer questions for you um",
    "start": "2586319",
    "end": "2593520"
  },
  {
    "text": "academic folks are super excited to share their research and they have a really strong depth of knowledge that um",
    "start": "2593520",
    "end": "2601040"
  },
  {
    "text": "that is going to accelerate your learning and then just you know get into ttps on",
    "start": "2601040",
    "end": "2606400"
  },
  {
    "text": "archive and you know dig in and with that thank you for coming to our talk um and if you have questions",
    "start": "2606400",
    "end": "2612800"
  },
  {
    "text": "feel free to contact us on twitter",
    "start": "2612800",
    "end": "2617640"
  },
  {
    "start": "2613000",
    "end": "2613000"
  },
  {
    "text": "[Music]",
    "start": "2618330",
    "end": "2625619"
  },
  {
    "text": "you",
    "start": "2626160",
    "end": "2628240"
  }
]
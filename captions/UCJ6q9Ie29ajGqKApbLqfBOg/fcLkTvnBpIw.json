[
  {
    "start": "0",
    "end": "65000"
  },
  {
    "text": "uh so good afternoon i want to welcome you to our talk on binary page a system that we build for performing",
    "start": "240",
    "end": "5680"
  },
  {
    "text": "large-scale processing and analysis on um you know small binary files",
    "start": "5680",
    "end": "11519"
  },
  {
    "text": "especially malware over hadoop my name is jason trost this is talbus",
    "start": "11519",
    "end": "17199"
  },
  {
    "text": "calhoun and this is zach neath and we're from in-game in-game is bringing data science to",
    "start": "17199",
    "end": "23039"
  },
  {
    "text": "cyber security allowing you to sense analyze and act against threats in real time",
    "start": "23039",
    "end": "29039"
  },
  {
    "text": "here's the agenda for today's talk uh first we're going to discuss the problem that we aim to solve uh which is there's tons of malware and",
    "start": "29039",
    "end": "35840"
  },
  {
    "text": "we want to be able to process that malware to keep up with it then we're going to cover the",
    "start": "35840",
    "end": "40879"
  },
  {
    "text": "architecture of the system we built to solve this problem we're going to go into some coding implementation details really details so",
    "start": "40879",
    "end": "46719"
  },
  {
    "text": "you know how it works and then also how you can use it if you're interested then we're going to cover some analysis results of",
    "start": "46719",
    "end": "52399"
  },
  {
    "text": "processing roughly 10 terabytes worth of malware using this system we're going to give a demo of the web",
    "start": "52399",
    "end": "57840"
  },
  {
    "text": "application portion of this system that we're going to open source um today and then after that we're just going to wrap up",
    "start": "57840",
    "end": "65039"
  },
  {
    "start": "65000",
    "end": "65000"
  },
  {
    "text": "so this this slide sums it up pretty well malware infections have been growing",
    "start": "65600",
    "end": "71439"
  },
  {
    "text": "tremendously over the past 10 years at endgame alone over the past two and a half years we've received roughly 20",
    "start": "71439",
    "end": "77200"
  },
  {
    "text": "million samples of malware equating to roughly 9.5 terabytes worth of malware",
    "start": "77200",
    "end": "82320"
  },
  {
    "text": "so 9.5 terabytes is a huge amount of data in this we are not alone mcafee and",
    "start": "82320",
    "end": "89439"
  },
  {
    "text": "kaspersky both report they receive roughly 100 to 200 000 pieces of malware per day so",
    "start": "89439",
    "end": "96640"
  },
  {
    "text": "this problem is tremendous a little known luminary from brooklyn actually had some similar problems and",
    "start": "96640",
    "end": "102640"
  },
  {
    "text": "he summed it up quite nicely so you might ask you know what do we",
    "start": "102640",
    "end": "110079"
  },
  {
    "start": "107000",
    "end": "107000"
  },
  {
    "text": "what do we do with all this malware you know why is it useful well malware data mining is is actually pretty useful uh we use it",
    "start": "110079",
    "end": "116960"
  },
  {
    "text": "at endgame for improving our threat intelligence feeds um so you know anything that's related to",
    "start": "116960",
    "end": "123840"
  },
  {
    "text": "malware it's really good to have you know detailed information about the malware uh we use our contextual enrichment of",
    "start": "123840",
    "end": "130479"
  },
  {
    "text": "events so if you have a dns lookup or an http callback and being able to correlate that back to known malware is actually really useful",
    "start": "130479",
    "end": "137280"
  },
  {
    "text": "in the course of an investigation or some sort of forensics event and then lastly",
    "start": "137280",
    "end": "143840"
  },
  {
    "text": "we use this huge corpus of malware for building machine learning models that we can use to then do better rapid",
    "start": "143840",
    "end": "150160"
  },
  {
    "text": "triage of new malware samples uh and then you know just better detection of new malware samples because most of the",
    "start": "150160",
    "end": "156080"
  },
  {
    "text": "malware we get frankly is not detected by any antivirus",
    "start": "156080",
    "end": "160640"
  },
  {
    "start": "161000",
    "end": "161000"
  },
  {
    "text": "so now i want to cover the old architecture that we pretty much the old way we used to handle processing malware",
    "start": "162160",
    "end": "168879"
  },
  {
    "text": "you know in this picture we have a ton of malware samples all stored in nfs",
    "start": "168879",
    "end": "174080"
  },
  {
    "text": "uh we use a compute cluster which consists of several servers that all mount nfs and they process the",
    "start": "174080",
    "end": "180560"
  },
  {
    "text": "malware and then that that data gets stored into a relational database if you've done any large-scale data processing",
    "start": "180560",
    "end": "185840"
  },
  {
    "text": "over the past 10 years this architecture might look familiar it's a pretty standard like pre-hadoop large-scale data",
    "start": "185840",
    "end": "192480"
  },
  {
    "text": "processing architecture but this architecture actually had a lot",
    "start": "192480",
    "end": "197760"
  },
  {
    "text": "of problems as we started throwing more and more malware at it we really had two problems so we wanted",
    "start": "197760",
    "end": "204239"
  },
  {
    "text": "to be able to process the daily dumps of malware we get in and we also want to reprocess all the",
    "start": "204239",
    "end": "209280"
  },
  {
    "text": "malware that we have in our corpus if we have a new idea i have a new query want to extract some new intelligence out of the data that",
    "start": "209280",
    "end": "214959"
  },
  {
    "text": "we hadn't done before so using this architecture for the the latter problem",
    "start": "214959",
    "end": "222799"
  },
  {
    "text": "turned out to be pretty problematic as we got into the terabyte scale so nfs turned out to be a big single",
    "start": "222799",
    "end": "229680"
  },
  {
    "text": "point of failure so if nfs went down we couldn't process any of the malware which was a problem",
    "start": "229680",
    "end": "235920"
  },
  {
    "text": "it was also a major bottleneck we found that as we're processing this malware even if we added more compute nodes to",
    "start": "235920",
    "end": "241680"
  },
  {
    "text": "the compute cluster uh there we reached a point where we just stopped seeing increases in performance and this is really bad right",
    "start": "241680",
    "end": "247920"
  },
  {
    "text": "so most scalable data processing systems you want to just be able to add new computers to the system and have it",
    "start": "247920",
    "end": "254239"
  },
  {
    "text": "scale linearly but that wasn't happening um and lastly it provided very poor data",
    "start": "254239",
    "end": "260799"
  },
  {
    "text": "locality so the data had to be copied across the network every time we wanted to process this malware",
    "start": "260799",
    "end": "266400"
  },
  {
    "text": "nfs does do do some caching locally but it really didn't work very well for the problem we were trying to solve",
    "start": "266400",
    "end": "273120"
  },
  {
    "text": "next the compute cluster had some problem problems of its own like i just mentioned very poor data",
    "start": "273120",
    "end": "279040"
  },
  {
    "text": "locality so the processing time gets dominated by copying copying data off the disk of",
    "start": "279040",
    "end": "284240"
  },
  {
    "text": "that you know one nfs server and then across the network that's that's really bad um",
    "start": "284240",
    "end": "290240"
  },
  {
    "text": "if a compute node went down during this processing especially for processing a huge batch of malware",
    "start": "290240",
    "end": "295680"
  },
  {
    "text": "knowing which malware that compute node was processing and having to reshuffle that to the other",
    "start": "295680",
    "end": "300880"
  },
  {
    "text": "machines to process it was a huge headache and just in the end turned out to be too hard to manage",
    "start": "300880",
    "end": "306400"
  },
  {
    "text": "so it didn't work well for this problem and then lastly we used a relational",
    "start": "306400",
    "end": "312400"
  },
  {
    "text": "database this worked pretty well at the beginning when we had a fixed set of analytics but we really wanted to to be able to",
    "start": "312400",
    "end": "317919"
  },
  {
    "text": "iterate quickly create new scripts for extracting new information out of the malware and be able to store this data and have",
    "start": "317919",
    "end": "325440"
  },
  {
    "text": "applications leverage this data relational database was really not agile enough a lot of the data that we have is",
    "start": "325440",
    "end": "331280"
  },
  {
    "text": "highly nester object oriented so storing this in relational database means you either have to create new",
    "start": "331280",
    "end": "336320"
  },
  {
    "text": "relations every time you create this new data or you just store it as a big blob and both",
    "start": "336320",
    "end": "341520"
  },
  {
    "text": "are really not ideal for doing rapid iteration rapid development",
    "start": "341520",
    "end": "346960"
  },
  {
    "text": "so really what we needed was a system that scaled our historical data set so being able to go back and process you",
    "start": "347520",
    "end": "353199"
  },
  {
    "text": "know 10 terabytes worth of malware trying a new static analysis technique um a system that recovers from failure",
    "start": "353199",
    "end": "359520"
  },
  {
    "text": "so if a node goes down or if we lose a drive and a server the system as a whole should continue to function and continue processing the",
    "start": "359520",
    "end": "366080"
  },
  {
    "text": "data really without much manual intervention so we shouldn't have to go try and determine which malware",
    "start": "366080",
    "end": "372080"
  },
  {
    "text": "needs to be reprocessed and you know manually shuffle that system that grows through scripting we really wanted to make sure that",
    "start": "372080",
    "end": "378080"
  },
  {
    "text": "our malware analyst could just write the simple you know relatively simple python scripts that really focused on the",
    "start": "378080",
    "end": "384560"
  },
  {
    "text": "malware and did not have to focus at all on the scalability part of this problem um this allows us to leverage our",
    "start": "384560",
    "end": "389840"
  },
  {
    "text": "pre-existing tools as well as any open source tools that process malware such as pe frame is",
    "start": "389840",
    "end": "394960"
  },
  {
    "text": "one that comes to mind the one that we actually ported to this system um one that we also want to be able to",
    "start": "394960",
    "end": "401520"
  },
  {
    "text": "support dynamic schema so that highly necessary object-oriented data we wanted to be able to query and retrieve",
    "start": "401520",
    "end": "406880"
  },
  {
    "text": "uh records based on the fields or based on the values in those fields and",
    "start": "406880",
    "end": "412639"
  },
  {
    "text": "have it you know work well and then lastly we wanted to be able to to search it via web application",
    "start": "412639",
    "end": "418240"
  },
  {
    "text": "we want to be able to build on top of this so i have an ap api so other applications could be built on this data",
    "start": "418240",
    "end": "425120"
  },
  {
    "text": "so we built it and we're talking about that we're going to talk about this in greater detail our",
    "start": "425120",
    "end": "431199"
  },
  {
    "text": "system is called binary pig it's a framework for processing small binary files using apache hadoop and",
    "start": "431199",
    "end": "436560"
  },
  {
    "text": "apache pig i'm going to turn over to telves and he's going to go into greater detail",
    "start": "436560",
    "end": "441919"
  },
  {
    "text": "so we built this excuse me so we built this to be a collaborative tool not just something you know we splunk together just for",
    "start": "442080",
    "end": "448080"
  },
  {
    "text": "black hat but a tool that everyone in our organization can build on top of so we had",
    "start": "448080",
    "end": "454160"
  },
  {
    "text": "four basic requirements first it has to have a simple api right like if if there's a large barrier",
    "start": "454160",
    "end": "460080"
  },
  {
    "text": "a high barrier to entry people aren't going to use it the second has to have pluggable analytics right so it needs to be",
    "start": "460080",
    "end": "465840"
  },
  {
    "text": "modular you shouldn't have to reinvent the wheel in order to get all the benefits that you're getting from binary pig",
    "start": "465840",
    "end": "471840"
  },
  {
    "text": "the next has to play nice with existing tools so we assume that everyone already has analysis",
    "start": "471840",
    "end": "478000"
  },
  {
    "text": "scripts that are doing static analysis right so what we want to do is make it as easy as possible to just hack your script a",
    "start": "478000",
    "end": "484160"
  },
  {
    "text": "little bit just a few lines to integrate it into our system and finally um",
    "start": "484160",
    "end": "489520"
  },
  {
    "text": "rapid iteration so but the goal is to have our you know 10 terabytes of malware to",
    "start": "489520",
    "end": "495360"
  },
  {
    "text": "be able to process that quickly right so you create your new analysis script",
    "start": "495360",
    "end": "500800"
  },
  {
    "text": "and instead of it taking a week to see if your script works you can depending on the size of your hadoop cluster it could take a day or it",
    "start": "500800",
    "end": "507759"
  },
  {
    "text": "could take five hours or one hour depending on how much capacity you have all right so we're going to discuss our",
    "start": "507759",
    "end": "514959"
  },
  {
    "text": "our architecture for binary pig so we're going to answer three questions here first is how do we store the data",
    "start": "514959",
    "end": "522560"
  },
  {
    "text": "how do we store the malware in hadoop the second is how do we process the data in hadoop and then finally how do we",
    "start": "522560",
    "end": "530320"
  },
  {
    "text": "explore the results so storage the first thing we want to do is um we",
    "start": "530320",
    "end": "537440"
  },
  {
    "text": "need to put the malware binaries in hdfs right so um hdfs isn't really intended for a bunch",
    "start": "537440",
    "end": "544320"
  },
  {
    "text": "of small files so you have to aggregate them into one large file and we do that using sequence files so",
    "start": "544320",
    "end": "550800"
  },
  {
    "text": "basically we aggregate them into one file and we have scripts that will do that for you and then you push that sequence file",
    "start": "550800",
    "end": "557120"
  },
  {
    "text": "onto hdfs right hdfs has uh",
    "start": "557120",
    "end": "562800"
  },
  {
    "text": "like lots of really cool features that are really good that solve some of the problems that jason talked about before um",
    "start": "562800",
    "end": "569519"
  },
  {
    "text": "first is replication so if we have a node that goes down um it's not the zombie apocalypse right",
    "start": "569519",
    "end": "575279"
  },
  {
    "text": "like you're not losing any samples that that data is replicated it'll get re-replicated if that note goes down",
    "start": "575279",
    "end": "581680"
  },
  {
    "text": "the second is horizontal scalability so as our malware zoo grows it's horizontally",
    "start": "581680",
    "end": "588320"
  },
  {
    "text": "scalable so you can just keep throwing nodes at it and you can support you know 10 terabytes or 100 or",
    "start": "588320",
    "end": "593839"
  },
  {
    "text": "as much as you as much as you have so next is processing so this is built",
    "start": "593839",
    "end": "599839"
  },
  {
    "text": "on top of hadoop hadoop is a is a scaling you know processing framework right so how do we",
    "start": "599839",
    "end": "606399"
  },
  {
    "text": "run static analysis over hadoop but we do that by extending apache pig apache pig is just a scripting language",
    "start": "606399",
    "end": "613279"
  },
  {
    "text": "when you execute a patch but when you execute pig it is transformed into hadoop jobs so by extending pig we run over hadoop",
    "start": "613279",
    "end": "620959"
  },
  {
    "text": "so the um so that's that's how we do it um for and one advantage of that excuse",
    "start": "620959",
    "end": "627920"
  },
  {
    "text": "me is data locality so before we had our our um we had to transfer malware",
    "start": "627920",
    "end": "633519"
  },
  {
    "text": "binaries from nfs to our compute cluster no more of that right so",
    "start": "633519",
    "end": "638640"
  },
  {
    "text": "all the all the data is data local and when the mapreduce job executes the uh",
    "start": "638640",
    "end": "645120"
  },
  {
    "text": "the binaries are written locally and it processes them locally there's no shuffle there's no overhead for that",
    "start": "645120",
    "end": "650240"
  },
  {
    "text": "and because obviously that overhead is expensive the more set the more samples you get",
    "start": "650240",
    "end": "656560"
  },
  {
    "start": "656000",
    "end": "656000"
  },
  {
    "text": "and data exploration so really when you have this scale of of um of data",
    "start": "656560",
    "end": "663519"
  },
  {
    "text": "right of malware it's kind of worthless to be able to analyze it when you can't explore the results",
    "start": "663519",
    "end": "668880"
  },
  {
    "text": "so to explore the results we have a simple application that does powerful searches backed by elasticsearch so elasticsearch",
    "start": "668880",
    "end": "676320"
  },
  {
    "text": "you can do free text search it's all loose it's just a wrapper on top of leucine so we assume that the output from your",
    "start": "676320",
    "end": "682160"
  },
  {
    "text": "analysis is free text or structured text we put that into elasticsearch elasticsearch speech json you can just",
    "start": "682160",
    "end": "688880"
  },
  {
    "text": "throw it at it it's really simple that's why we used it and then we have a simple app that will demo later",
    "start": "688880",
    "end": "694720"
  },
  {
    "text": "we use elasticsearch but the system isn't tied to elasticsearch",
    "start": "694720",
    "end": "700240"
  },
  {
    "text": "in any way that could be a cumulo that could be hdfs that could be back into um or back into hdfs it could be",
    "start": "700240",
    "end": "707600"
  },
  {
    "text": "anything you want there so don't get the impression that it has to be elasticsearch it absolutely does",
    "start": "707600",
    "end": "713200"
  },
  {
    "text": "not um the one caveat is it needs to be a storage has to have storage capability from pig",
    "start": "713200",
    "end": "719040"
  },
  {
    "text": "since it's since binary pig is written as an extension to apache pig",
    "start": "719040",
    "end": "724320"
  },
  {
    "text": "so why write another framework right so everyone here knows there's tons and tons and tons of",
    "start": "724320",
    "end": "730320"
  },
  {
    "text": "open source tools for doing malware analysis and open source tools",
    "start": "730320",
    "end": "735360"
  },
  {
    "text": "built on top of hadoop so why write another one so the first is all the static analysis tools aren't",
    "start": "735360",
    "end": "740720"
  },
  {
    "text": "made for scale right they're made for you know one hacksaw at his desk with a few samples",
    "start": "740720",
    "end": "746720"
  },
  {
    "text": "and you run them in a simple script it's not me none of them are made for you know terabytes of malware the second",
    "start": "746720",
    "end": "753360"
  },
  {
    "text": "is hadoop isn't made for processing a bunch of small malware files right and the third is there's no",
    "start": "753360",
    "end": "759279"
  },
  {
    "text": "simple combination of the two there's no um just put the binaries on hadoop and",
    "start": "759279",
    "end": "764800"
  },
  {
    "text": "it'll magically work so we had to build the framework to do it for us",
    "start": "764800",
    "end": "770160"
  },
  {
    "text": "so now we're going to look at um some code i'm going to demonstrate how you can do malware",
    "start": "770160",
    "end": "775760"
  },
  {
    "text": "analysis at scale and make it as easy as the slap chop",
    "start": "775760",
    "end": "781279"
  },
  {
    "text": "all right so the first thing you want to do like we said before is to create the the sequence file so we have a couple",
    "start": "781440",
    "end": "786720"
  },
  {
    "text": "scripts we assume you already have a malware zeus somewhere it's either on disk or in an archive so",
    "start": "786720",
    "end": "793600"
  },
  {
    "text": "we have two convenient scripts that will take your your archive or your subdirectory and copy that up to or",
    "start": "793600",
    "end": "800320"
  },
  {
    "text": "sorry generate that sequence file and copy it up to htfs a little like i said note on the",
    "start": "800320",
    "end": "806560"
  },
  {
    "text": "sequence file the for those that aren't familiar with it it's just a simple data structure the",
    "start": "806560",
    "end": "811760"
  },
  {
    "text": "key we make the md5 of the the malware binary",
    "start": "811760",
    "end": "817120"
  },
  {
    "text": "and then the value is the um the actual binary data itself right so um so that's that's",
    "start": "817120",
    "end": "823760"
  },
  {
    "text": "what we copy up then when you run it over hadoop when it iterates over each line each and each line is an md5 in the malware",
    "start": "823760",
    "end": "832399"
  },
  {
    "start": "832000",
    "end": "832000"
  },
  {
    "text": "so the loader so most of the magic happens here in the loaders um we need to do some background on",
    "start": "832399",
    "end": "838639"
  },
  {
    "text": "apache pig so they're in in when you want to read data from hdfs into your scripts",
    "start": "838639",
    "end": "846320"
  },
  {
    "text": "like workspace or into your namespace you need to do a load command and load you just give it a path",
    "start": "846320",
    "end": "852800"
  },
  {
    "text": "and it reads that data from hdfs and does whatever it needs to do in hadoop land and it makes it",
    "start": "852800",
    "end": "859120"
  },
  {
    "text": "visible to you in the pig script we basically extended that so that it",
    "start": "859120",
    "end": "866880"
  },
  {
    "text": "will take your malware it will extract your malware binary from the sequence file write it to disk then perform your",
    "start": "866880",
    "end": "874880"
  },
  {
    "text": "analysis on that that binary that was written to disk and then give you the results",
    "start": "874880",
    "end": "880399"
  },
  {
    "text": "back in pig so you just pointed at a bunch of malware and what you get in pig are the",
    "start": "880399",
    "end": "886560"
  },
  {
    "text": "results so you perform the static analysis at scale um an emphasis that this is a a mapreduce job right so this is at scale",
    "start": "886560",
    "end": "894160"
  },
  {
    "text": "this is you know if you've got 10 terabytes 100 terabytes petabyte whatever it's the compa it's a",
    "start": "894160",
    "end": "900240"
  },
  {
    "text": "function of the capacity of your um hadoop cluster so we have two loaders right so in order to execute the load um",
    "start": "900240",
    "end": "907920"
  },
  {
    "text": "we will we'll either execute the the static analysis script",
    "start": "907920",
    "end": "912959"
  },
  {
    "text": "and uh just read it directly just run it one at a time or we can have the the daemon loader and the daemon is",
    "start": "912959",
    "end": "919600"
  },
  {
    "text": "specifically for cases when you're doing static analysis that requires signatures so something like clam av for",
    "start": "919600",
    "end": "926639"
  },
  {
    "text": "example so if you need to run clam d or clam scan it needs to upload 20 meg of signatures",
    "start": "926639",
    "end": "934320"
  },
  {
    "text": "you don't want to do that over you know 20 million samples the overhead is prohibitive that's what we did at first",
    "start": "934320",
    "end": "940639"
  },
  {
    "text": "and it was a lesson learned so as a workaround we have a daemon loader and it assumes that you set up a",
    "start": "940639",
    "end": "946639"
  },
  {
    "text": "daemon on you deployed the statement on all of your worker nodes in your hadoop cluster and all it requires is a you know a",
    "start": "946639",
    "end": "954560"
  },
  {
    "text": "simple connection with the path of the file um it's going to receive that path it's going to perform the analysis and",
    "start": "954560",
    "end": "961279"
  },
  {
    "text": "write it back over the socket and that's what gets patched back up in the pig",
    "start": "961279",
    "end": "966320"
  },
  {
    "text": "so as far as you're concerned all you care is that you wrote a simple script some magic happened and you have results",
    "start": "966320",
    "end": "973680"
  },
  {
    "text": "and it's up to you to determine what you want to do with it so some optimizations so first",
    "start": "973680",
    "end": "980399"
  },
  {
    "start": "977000",
    "end": "977000"
  },
  {
    "text": "you know when we looked at the first implementation it was a bunch of you know uh network",
    "start": "980399",
    "end": "986000"
  },
  {
    "text": "copies in order to in order to get it to the compute cluster so the",
    "start": "986000",
    "end": "991839"
  },
  {
    "text": "at least now we have data local but we still have scripts that expect file paths right",
    "start": "991839",
    "end": "996959"
  },
  {
    "text": "so we have to extract the data from the sequence file and write it to disk so that's not free",
    "start": "996959",
    "end": "1002480"
  },
  {
    "text": "either right so a workaround for that is to use dev shim um devshim is just memory mapped you",
    "start": "1002480",
    "end": "1008959"
  },
  {
    "text": "know file space so it looks like a file for for the purposes of any script but it's",
    "start": "1008959",
    "end": "1014800"
  },
  {
    "text": "actually in memory so presuming you have enough memory to support you know all of the um the mapper nodes",
    "start": "1014800",
    "end": "1020959"
  },
  {
    "text": "all the the hadoop processes then you could just write them all to devshem it's as fast as writing the memory and it runs fine",
    "start": "1020959",
    "end": "1027678"
  },
  {
    "text": "and the second we've already discussed is the the daemon loaders the first time we ran you know",
    "start": "1027679",
    "end": "1034000"
  },
  {
    "text": "our binary pig over all of our samples for it took quite a while and a lesson",
    "start": "1034000",
    "end": "1040319"
  },
  {
    "text": "learned was if we can just load those signatures once have a damon uh perform the analysis",
    "start": "1040319",
    "end": "1046558"
  },
  {
    "text": "um you you save you know it cuts it down in half almost you'd be amazed how much time you",
    "start": "1046559",
    "end": "1052240"
  },
  {
    "text": "save having an actual game in there so this is a list of all the loaders we",
    "start": "1052240",
    "end": "1057919"
  },
  {
    "start": "1054000",
    "end": "1054000"
  },
  {
    "text": "have in binary pig right now um there's a generic script loader we'll look at that just it's just a regular script",
    "start": "1057919",
    "end": "1064000"
  },
  {
    "text": "like you would run you know a simple bash script or python or whatever whatever you like",
    "start": "1064000",
    "end": "1069440"
  },
  {
    "text": "the damon loader we just discussed and then we have three implementations so clam av",
    "start": "1069440",
    "end": "1074799"
  },
  {
    "text": "um yara and pe hashing an emphasis on clam av we're not",
    "start": "1074799",
    "end": "1081520"
  },
  {
    "text": "endorsing clam av in any way but uh it's it's free it's open source we",
    "start": "1081520",
    "end": "1087679"
  },
  {
    "text": "presume that anyone that's getting our that's using our framework can get access to it so",
    "start": "1087679",
    "end": "1093360"
  },
  {
    "text": "if you just want to set it up locally and run it everybody should be able to get clam so that's why we use it all right so",
    "start": "1093360",
    "end": "1101840"
  },
  {
    "start": "1100000",
    "end": "1100000"
  },
  {
    "text": "we're going to show in five lines of code how you can analyze malware at scale um so",
    "start": "1101840",
    "end": "1108960"
  },
  {
    "text": "the first thing is to create a simple batch or simple script and all everyone recognizes this this is just strings this gives you this",
    "start": "1108960",
    "end": "1115120"
  },
  {
    "text": "extracts all the strings from a binary um it that you know it takes the file path",
    "start": "1115120",
    "end": "1120400"
  },
  {
    "text": "the next we is we have a pig script so for people that aren't familiar with pig we'll walk through it the first thing you need to do is define the loader",
    "start": "1120400",
    "end": "1127200"
  },
  {
    "text": "we're going to use here we're using the executing loader um like we said before this is the non-daemon one every time you run this",
    "start": "1127200",
    "end": "1133840"
  },
  {
    "text": "it has to do all of its initialization which is fine if we do something like strings because",
    "start": "1133840",
    "end": "1139039"
  },
  {
    "text": "there's there's no signatures and the second is the load command so that's what we talked about before",
    "start": "1139039",
    "end": "1144320"
  },
  {
    "text": "with um that is what actually executes the hadoop job will read your malware from the sequence",
    "start": "1144320",
    "end": "1151520"
  },
  {
    "text": "files um perform the analysis in that hadoop job this is all parallel all at scale",
    "start": "1151520",
    "end": "1157520"
  },
  {
    "text": "this it works for however many nodes you got um this like the emphasis here is on",
    "start": "1157520",
    "end": "1163280"
  },
  {
    "text": "that right like you before you were running on you know a bunch of scripts like one-offs now it's you can analyze",
    "start": "1163280",
    "end": "1171280"
  },
  {
    "text": "as much as uh hadoop capacity right so that's awesome it changed our world",
    "start": "1171280",
    "end": "1177200"
  },
  {
    "text": "and hopefully it'll be useful for you all and so that's the load statement there when we we get a",
    "start": "1177200",
    "end": "1182720"
  },
  {
    "text": "an alias to where it puts that data um in data there i guess when you run load",
    "start": "1182720",
    "end": "1189120"
  },
  {
    "text": "what you get back are the results right so you get all the strings from that that binary",
    "start": "1189120",
    "end": "1194400"
  },
  {
    "text": "and finally the dump command is a you know print you know write the standard out in our",
    "start": "1194400",
    "end": "1200559"
  },
  {
    "text": "examples we write to elasticsearch there but replace dump with whatever your favorite",
    "start": "1200559",
    "end": "1207120"
  },
  {
    "text": "you know nosql store is and we can write to it it's it leverages everything you",
    "start": "1207120",
    "end": "1212880"
  },
  {
    "text": "get in pig um but extended so that you can do malware analysis",
    "start": "1212880",
    "end": "1219200"
  },
  {
    "text": "all right and really this is really simple it's a file and a script so anything that",
    "start": "1219360",
    "end": "1225440"
  },
  {
    "text": "works over a file in a script can work in binary right so we can do image analysis we can",
    "start": "1225440",
    "end": "1231520"
  },
  {
    "text": "do a pdf extraction you know any of these anything you can think of that's just a file and a script um we're",
    "start": "1231520",
    "end": "1238799"
  },
  {
    "text": "doing a talk on malware here but it can literally be anything",
    "start": "1238799",
    "end": "1244559"
  },
  {
    "start": "1244000",
    "end": "1244000"
  },
  {
    "text": "and we have a simple web interface that um performs really really powerful queries that we'll demonstrate later",
    "start": "1244720",
    "end": "1251039"
  },
  {
    "text": "um a simple app everyone here recognizes twitter bootstrap um that's what happens when you get back",
    "start": "1251039",
    "end": "1256080"
  },
  {
    "text": "ender's writing ui code but it's it's really awesome because it allows us to do free text searches",
    "start": "1256080",
    "end": "1263120"
  },
  {
    "text": "over all of our data so we have we don't know what what strings we've extracted right",
    "start": "1263120",
    "end": "1268559"
  },
  {
    "text": "so now we can just do searches for java or searches for dalvik or anything and we get the",
    "start": "1268559",
    "end": "1274080"
  },
  {
    "text": "results we don't have to grip logs we don't have to write any more parsers um elasticsearch is you know it's",
    "start": "1274080",
    "end": "1279280"
  },
  {
    "text": "leucine so you can do free tech searches fastening any kind of anything you want to do it's really awesome",
    "start": "1279280",
    "end": "1285840"
  },
  {
    "text": "all right and i'm going to hand things off to get things off to zach and thank you",
    "start": "1285840",
    "end": "1294080"
  },
  {
    "text": "um so obviously we've been using the system internally for some time and we've developed some results and",
    "start": "1294400",
    "end": "1299520"
  },
  {
    "text": "we're opening them up and we're sharing them now going back to the original part of this presentation",
    "start": "1299520",
    "end": "1306000"
  },
  {
    "text": "our historical data set is around 20 million unique binaries 94 of them are in the pe format about",
    "start": "1306000",
    "end": "1312880"
  },
  {
    "text": "six percent are android apks and various things that run on the dalvik jvm",
    "start": "1312880",
    "end": "1318480"
  },
  {
    "text": "and then there's some minuscule fraction left over that represents macromedia flash pdfs",
    "start": "1318480",
    "end": "1325120"
  },
  {
    "text": "all sorts of other detrias that tends to get collected all at once at the time of developing this system we",
    "start": "1325120",
    "end": "1332240"
  },
  {
    "text": "were running this off of a 15 node hadoop cluster and would take us about five hours give",
    "start": "1332240",
    "end": "1337360"
  },
  {
    "text": "or take depending on the specific scripts that we were using to run over the entirety of our historical set",
    "start": "1337360",
    "end": "1343840"
  },
  {
    "text": "this is obviously compared against the previous system that we had implemented where",
    "start": "1343840",
    "end": "1349280"
  },
  {
    "text": "running over a historical data set was completely time prohibitive if it",
    "start": "1349280",
    "end": "1354320"
  },
  {
    "text": "was capable at all due to random hardware failures and a lack of robustness overall it it it has seriously helped",
    "start": "1354320",
    "end": "1362720"
  },
  {
    "text": "our ability to develop new analytics apply them to a historical set and then learn and continue progressing",
    "start": "1362720",
    "end": "1369200"
  },
  {
    "text": "beyond that i mean no longer do we develop something new we can only apply it going forward with our daily malware ingest we can",
    "start": "1369200",
    "end": "1376640"
  },
  {
    "text": "actually re-ingest all of our systems and then continue moving forward with the new material",
    "start": "1376640",
    "end": "1382240"
  },
  {
    "text": "i mean this has been a huge help so we've got some general findings and these are probably very difficult to",
    "start": "1382240",
    "end": "1388240"
  },
  {
    "start": "1384000",
    "end": "1384000"
  },
  {
    "text": "read but that's perfectly all right because when we went into this we were hoping to find something",
    "start": "1388240",
    "end": "1394159"
  },
  {
    "text": "incredible we were hoping to find one big thing that challenged all of our previous understanding of malware and",
    "start": "1394159",
    "end": "1400799"
  },
  {
    "text": "unfortunately or fortunately depending on how you look at it none of the basics really were shocking we found you know a few evidences",
    "start": "1400799",
    "end": "1407440"
  },
  {
    "text": "of you know are our primary contenders for languages used in various resources or imported",
    "start": "1407440",
    "end": "1413600"
  },
  {
    "text": "dlls or the average size of various files but these were all things that we intuitively knew beforehand which was",
    "start": "1413600",
    "end": "1419679"
  },
  {
    "text": "interesting i raised this now because you know when when part of part of what we started",
    "start": "1419679",
    "end": "1425039"
  },
  {
    "text": "realizing was the ability that we had to rapidly develop new analytics was incredible we could run a single day's",
    "start": "1425039",
    "end": "1433360"
  },
  {
    "text": "worth of malware in the span of about two and a half minutes three minutes",
    "start": "1433360",
    "end": "1438720"
  },
  {
    "text": "we could run a week's worth in around 10 or so it was an absolutely earth-changing",
    "start": "1438720",
    "end": "1445760"
  },
  {
    "text": "event for us internally because we were able to very quickly explore every aspect of the data that we had and go through it and look at it",
    "start": "1445760",
    "end": "1452799"
  },
  {
    "text": "again and again and try new things so after realizing that the very basics",
    "start": "1452799",
    "end": "1459600"
  },
  {
    "start": "1457000",
    "end": "1457000"
  },
  {
    "text": "of malware census taking was not going to give us anything earth-shattering",
    "start": "1459600",
    "end": "1465440"
  },
  {
    "text": "we started to move to more advanced feature extraction and our core motivation here was to drastically improve the",
    "start": "1465440",
    "end": "1471679"
  },
  {
    "text": "experience that we had for developing new and validating our internal research",
    "start": "1471679",
    "end": "1476960"
  },
  {
    "text": "so one of the first things we started with and there's a great deal of academic papers and work already been done on",
    "start": "1476960",
    "end": "1482640"
  },
  {
    "text": "this was feature extraction to identify individual packers we we would extract things such as you",
    "start": "1482640",
    "end": "1489360"
  },
  {
    "text": "know overall and sectional entropy the overall common gore of complexity of various elements within the pe headers and the",
    "start": "1489360",
    "end": "1495919"
  },
  {
    "text": "pe files themselves individual sections and resource names section flags import tables function",
    "start": "1495919",
    "end": "1502640"
  },
  {
    "text": "calls and just everything else that we could find it really became a huge thing to try and extract and compute new",
    "start": "1502640",
    "end": "1509840"
  },
  {
    "text": "features and new elements because it was so trivial to do so i think all in all we've extracted over",
    "start": "1509840",
    "end": "1516679"
  },
  {
    "text": "550 560 discrete individual features from the pe files that we have we've",
    "start": "1516679",
    "end": "1523679"
  },
  {
    "text": "definitely been able to do a lot of work with them we found internally that we've been able to uh develop a number of models",
    "start": "1523679",
    "end": "1531039"
  },
  {
    "text": "that allow us to detect very very easily whether or not we have a set of packers that fit into you know some of the major",
    "start": "1531039",
    "end": "1537679"
  },
  {
    "text": "families the upx families you know femita vm protect all the other big popular ones",
    "start": "1537679",
    "end": "1544640"
  },
  {
    "text": "we've been able to find this with fairly high reliability and it's been a necessity for us because",
    "start": "1544640",
    "end": "1550960"
  },
  {
    "text": "in a lot of our work and research we've gone back and questioned repeatedly the use of peid and other such tools",
    "start": "1550960",
    "end": "1558400"
  },
  {
    "text": "that rely on signatures peid specifically the majority of their signatures are you know five plus years",
    "start": "1558400",
    "end": "1563919"
  },
  {
    "text": "old now and developing new signatures for that is a manual process what we were attempting to do and",
    "start": "1563919",
    "end": "1569520"
  },
  {
    "text": "i think we i can say we've succeeded at was the ability to easily cluster individual elements and individual",
    "start": "1569520",
    "end": "1576480"
  },
  {
    "text": "pieces of malware that are packed with various families of packers and be able to quickly triage them",
    "start": "1576480",
    "end": "1582240"
  },
  {
    "text": "internally to figure to figure out what we need to go through before doing deep dive analysis so i've",
    "start": "1582240",
    "end": "1588720"
  },
  {
    "start": "1588000",
    "end": "1588000"
  },
  {
    "text": "mentioned a couple of uh features coming out of the pe header and we're fully aware of some of the",
    "start": "1588720",
    "end": "1594400"
  },
  {
    "text": "weaknesses inside of the pe header itself these features are shallow and these features are easily manipulated by",
    "start": "1594400",
    "end": "1600400"
  },
  {
    "text": "malicious authors which of course when you're analyzing malware that's really all you have in front of you",
    "start": "1600400",
    "end": "1606640"
  },
  {
    "text": "we're fully aware that this is less resolution than individual reverse engineering features but we found",
    "start": "1606640",
    "end": "1612640"
  },
  {
    "text": "repeatedly that the ability to apply mass amounts of data in a statistical learning model has",
    "start": "1612640",
    "end": "1618720"
  },
  {
    "text": "definitely given us given us an advantage it really comes down to the unreasonable effectiveness",
    "start": "1618720",
    "end": "1623919"
  },
  {
    "text": "of large sums of highly entropic data a couple of things that we found that we",
    "start": "1623919",
    "end": "1630480"
  },
  {
    "text": "determined were fairly interesting for a lot of the malware that we have the headers themselves were never",
    "start": "1630480",
    "end": "1635919"
  },
  {
    "text": "manipulated even things as basic as manipulating the time of compilation inside of the pe header",
    "start": "1635919",
    "end": "1641919"
  },
  {
    "text": "was never manipulated for a large percentage of our samples we certainly found that when developing",
    "start": "1641919",
    "end": "1649120"
  },
  {
    "text": "our clustering algorithms and our other triage mechanisms which was a major",
    "start": "1649120",
    "end": "1654320"
  },
  {
    "text": "reason for doing this we learned very quickly that we'd have to ignore",
    "start": "1654320",
    "end": "1659840"
  },
  {
    "text": "some of the tighter clusters and go for some of the wider ones and when doing all this clustering work one of the big",
    "start": "1659840",
    "end": "1665279"
  },
  {
    "text": "lessons we had to learn very very quickly was you need to be certain that the clusters that you're getting out",
    "start": "1665279",
    "end": "1671360"
  },
  {
    "text": "are the are representative of the amount of the features that you're using to do the clustering",
    "start": "1671360",
    "end": "1676399"
  },
  {
    "text": "if you attempt to read into too much if you attempt to assign meaning to something where meaning doesn't exist you can get",
    "start": "1676399",
    "end": "1682000"
  },
  {
    "text": "very strange results very very quickly",
    "start": "1682000",
    "end": "1686640"
  },
  {
    "start": "1687000",
    "end": "1687000"
  },
  {
    "text": "so some of the results we've had so far everything we were doing in our initial stages were to perform",
    "start": "1687440",
    "end": "1693840"
  },
  {
    "text": "dynamic analysis when opening with the amount of power that we get per day the only way to scale our dynamic analysis systems",
    "start": "1693840",
    "end": "1700799"
  },
  {
    "text": "was to add more and more hardware which would increase our you know time burden on the you know it",
    "start": "1700799",
    "end": "1706080"
  },
  {
    "text": "teams and you know people who run the dynamic analysis systems and maintain it when it breaks and all sorts",
    "start": "1706080",
    "end": "1711200"
  },
  {
    "text": "of other things one of the big things we've been trying to do recently is try and winnow things down so that if we",
    "start": "1711200",
    "end": "1716880"
  },
  {
    "text": "can only run a handful of representative samples we can run them for longer we can perform more complex analyses inside of",
    "start": "1716880",
    "end": "1722720"
  },
  {
    "text": "a dynamic space our largest cluster that we've been able to uh find and determine and do some",
    "start": "1722720",
    "end": "1728559"
  },
  {
    "text": "validation on was over 300 000 samples there were three major malware families contained",
    "start": "1728559",
    "end": "1734799"
  },
  {
    "text": "within this was a very large cluster based off of certain elements of you know highly",
    "start": "1734799",
    "end": "1740240"
  },
  {
    "text": "virulent polymorphic families our second largest was significantly smaller and it tapered",
    "start": "1740240",
    "end": "1747120"
  },
  {
    "text": "down into a long tail fairly quickly what we've been able to find out of this with pretty high reliability because we've run all these samples so far",
    "start": "1747120",
    "end": "1753760"
  },
  {
    "text": "through our dynamic analysis system is that our accuracy is really quite good we're still going through we're",
    "start": "1753760",
    "end": "1759360"
  },
  {
    "text": "still doing additional validation on our results and we're not quite entirely prepared to come up and do an academic",
    "start": "1759360",
    "end": "1764720"
  },
  {
    "text": "talk about how exactly we've been able to go through and do validation and that's another big thing that we've learned from using this system with all",
    "start": "1764720",
    "end": "1771600"
  },
  {
    "text": "this data with all the information that we're able to extract we have to go through and validate every",
    "start": "1771600",
    "end": "1777039"
  },
  {
    "text": "single thing repeatedly and a lot of that becomes manual efforts when you're trying to seek ground truth inside of",
    "start": "1777039",
    "end": "1782240"
  },
  {
    "text": "a malware data set like i said before the validation is certainly very tricky you can't simply",
    "start": "1782240",
    "end": "1788159"
  },
  {
    "text": "go off of antivirus results because they change over time different avs don't necessarily always",
    "start": "1788159",
    "end": "1793360"
  },
  {
    "text": "agree with each other and of course your cluster meetings will change as you develop your feature set",
    "start": "1793360",
    "end": "1798559"
  },
  {
    "text": "modify your feature set and continue to evolve your analyses but despite the fact that validation",
    "start": "1798559",
    "end": "1804320"
  },
  {
    "text": "often becomes a manual process it can be somewhat slow the fact that we're able to do so much extraction and test so",
    "start": "1804320",
    "end": "1809919"
  },
  {
    "text": "many theories so quickly with the ground truth stuff that we the ground truth information we have",
    "start": "1809919",
    "end": "1815200"
  },
  {
    "text": "from the dynamic analysis that we have already done has been an enormous boon internally one of the more interesting things that",
    "start": "1815200",
    "end": "1821200"
  },
  {
    "start": "1820000",
    "end": "1820000"
  },
  {
    "text": "we've been able to do that we flatly couldn't do before was do icon extraction from individual binaries um now this is this was something we",
    "start": "1821200",
    "end": "1827760"
  },
  {
    "text": "actually started just for fun just to see what would come out of it and we ended up getting fairly good strong results if you take a",
    "start": "1827760",
    "end": "1834720"
  },
  {
    "text": "look at these every single one of these are things that have been extracted from real ground truth confirmed malware",
    "start": "1834720",
    "end": "1839919"
  },
  {
    "text": "and if you look at it you'll probably see a handful of icons that are familiar to you from you know your own reverse engineering and you'll",
    "start": "1839919",
    "end": "1846000"
  },
  {
    "text": "probably see a few other icons that i think many of us internally would classify as malware despite the fact",
    "start": "1846000",
    "end": "1851360"
  },
  {
    "text": "that large software vendors would suggest our otherwise",
    "start": "1851360",
    "end": "1856480"
  },
  {
    "text": "this was just an interesting slide because of the fact that binary pig would allow us to very easily extract",
    "start": "1857919",
    "end": "1863039"
  },
  {
    "text": "binary data from the resources and other elements of the binaries themselves",
    "start": "1863039",
    "end": "1868720"
  },
  {
    "text": "work them back into the system and continue to do analysis on them so we'd go through our binaries and",
    "start": "1868720",
    "end": "1874320"
  },
  {
    "text": "various droppers and other malware families that we had if there were pe files that were contained within",
    "start": "1874320",
    "end": "1879360"
  },
  {
    "text": "the resources if there were additional icons or cursor elements contained within the resources or documents or",
    "start": "1879360",
    "end": "1884880"
  },
  {
    "text": "whatever you know individuals can put in there and we were shocked at just how much they can put",
    "start": "1884880",
    "end": "1891120"
  },
  {
    "text": "we were able to take them out create additional scripts for them and continuously feed that into the system so you know",
    "start": "1891120",
    "end": "1897840"
  },
  {
    "text": "starting with 10 things to analyze we'd end up with 15 and then 20 and then 25 and we'd keep going from there",
    "start": "1897840",
    "end": "1903519"
  },
  {
    "text": "it was certainly an excellent process which was very simple due to the framework that we've developed so a",
    "start": "1903519",
    "end": "1909600"
  },
  {
    "start": "1908000",
    "end": "1908000"
  },
  {
    "text": "couple of the features we pulled out of the icons because that was something fairly interesting for us we did a lot of clustering based on them",
    "start": "1909600",
    "end": "1915919"
  },
  {
    "text": "mostly on the principle that icons are something that a an individual author has to put in on their",
    "start": "1915919",
    "end": "1921919"
  },
  {
    "text": "own it's not an artifact of the compiler it's not an artifact of the system that individual things run on it's something",
    "start": "1921919",
    "end": "1927519"
  },
  {
    "text": "that the author has to include of their own volition for many of these cases",
    "start": "1927519",
    "end": "1932559"
  },
  {
    "text": "and we extracted a number of pixel-based features for brightness and color values and pixel density and we attempted to do",
    "start": "1932559",
    "end": "1938320"
  },
  {
    "text": "clustering and feature extraction on that um we've also found that we've had excellent results doing cryptographic",
    "start": "1938320",
    "end": "1943679"
  },
  {
    "text": "and fuzzy hashing on the files themselves individual icons we found will be spread across",
    "start": "1943679",
    "end": "1950559"
  },
  {
    "text": "multiple families and you can trace a certain amount of family lineage from that what we found over time is the fact that",
    "start": "1950559",
    "end": "1957440"
  },
  {
    "text": "when we take individual files from a new what we believe to be a new malware family coming up and evolving as it starts to",
    "start": "1957440",
    "end": "1963600"
  },
  {
    "text": "gain traction starts to gain speed as we see more and more samples coming in from that we'll start to see copycats",
    "start": "1963600",
    "end": "1969600"
  },
  {
    "text": "get created copying you know similar resources and such things it's been something that we found we're trying to figure out exactly",
    "start": "1969600",
    "end": "1975600"
  },
  {
    "text": "why that is the case and that's an artifact of the way we're doing clustering if that's something that's reflected in real life",
    "start": "1975600",
    "end": "1981200"
  },
  {
    "text": "again validation becomes a manual process with a lot of reverse engineering so we're moving through that right now",
    "start": "1981200",
    "end": "1988398"
  },
  {
    "text": "this is a lot of material that i've you know previously stated um method of infection can definitely be",
    "start": "1989360",
    "end": "1994799"
  },
  {
    "text": "extrapolated fairly easily you see a lot of obfuscated executables exes masquerading as pdfs and other such",
    "start": "1994799",
    "end": "2001679"
  },
  {
    "text": "formats um you definitely get a lot of indication that people are you know attempting to do phishing elements",
    "start": "2001679",
    "end": "2007279"
  },
  {
    "text": "for some of our malware resources for some of our malware ingest mechanisms we know where the malware came from we know",
    "start": "2007279",
    "end": "2013360"
  },
  {
    "text": "how it attempted to enter a network and we can definitely do a lot of correlation between multiple points and it's been something that's been very",
    "start": "2013360",
    "end": "2019120"
  },
  {
    "text": "useful when tracking large campaigns when tracking individual families and attempting to go all the way down to modus operandi of",
    "start": "2019120",
    "end": "2026399"
  },
  {
    "text": "individual authors so a few lessons learned that we've had",
    "start": "2026399",
    "end": "2032480"
  },
  {
    "start": "2030000",
    "end": "2030000"
  },
  {
    "text": "from developing these models um feature selection as i said is definitely a rabbit hole we found",
    "start": "2032480",
    "end": "2038240"
  },
  {
    "text": "way over 500 features in the pe header alone we're developing more constantly and a",
    "start": "2038240",
    "end": "2043519"
  },
  {
    "text": "lot of the work that we are doing now now that we've got this you know embarrassment of malware data",
    "start": "2043519",
    "end": "2048560"
  },
  {
    "text": "we're slowly winnowing it down and focusing solely on the high value high gain information that we have the abundance",
    "start": "2048560",
    "end": "2055358"
  },
  {
    "text": "of features as i said you know definitely requires pruning the interpretation and validation of",
    "start": "2055359",
    "end": "2060480"
  },
  {
    "text": "results is something that is always a concern when developing statistical models manual validation so far is still an",
    "start": "2060480",
    "end": "2066320"
  },
  {
    "text": "unfortunate reality despite the fact that we can do large amounts of mergers with outside data sets you know not just data",
    "start": "2066320",
    "end": "2072720"
  },
  {
    "text": "sets that are developed using binary pig but data sets from our dynamic analysis system for our individual reverse",
    "start": "2072720",
    "end": "2077919"
  },
  {
    "text": "engineers efforts from things that we hear from third parties and care definitely has to be",
    "start": "2077919",
    "end": "2082960"
  },
  {
    "text": "taken when interpreting unsupervised learning to make sure that we're getting meaningful results",
    "start": "2082960",
    "end": "2088960"
  },
  {
    "text": "so now we're going to do a demo a short demo of the web interface that we have and that should give you an idea of the tool that we're releasing very shortly",
    "start": "2088960",
    "end": "2102000"
  },
  {
    "text": "this is uh this is google chrome just expanded to full screen um this is the web application that",
    "start": "2102000",
    "end": "2107280"
  },
  {
    "text": "we're we're releasing open source uh so when you open binary",
    "start": "2107280",
    "end": "2112400"
  },
  {
    "text": "page this is the screen you're presented with it's a google like minimal google-like search interface allows you to search on any really any",
    "start": "2112400",
    "end": "2119040"
  },
  {
    "text": "of the fields that you're extracted at any of the data from any of the analytics that you ran or you could just",
    "start": "2119040",
    "end": "2125040"
  },
  {
    "text": "perform just simple free text searches across the top we also have these tabs",
    "start": "2125040",
    "end": "2130560"
  },
  {
    "text": "i'm going to go through them one by one each tab represents the collection of results from a particular processing",
    "start": "2130560",
    "end": "2137200"
  },
  {
    "text": "module so we have uh yara is one of the modules we have we have one for clam av we have",
    "start": "2137200",
    "end": "2142480"
  },
  {
    "text": "one for pe hash and one for pe frame uh in each of these tabs we have",
    "start": "2142480",
    "end": "2148000"
  },
  {
    "text": "taken out fields that we thought were interesting and fields that we thought you know might be worth exploration",
    "start": "2148000",
    "end": "2153520"
  },
  {
    "text": "we've pulled those fields out in into facets so you can see what's the most popular you know value",
    "start": "2153520",
    "end": "2159200"
  },
  {
    "text": "in this field across this data set and these numbers look small and that that's because this is um all running on my local",
    "start": "2159200",
    "end": "2166880"
  },
  {
    "text": "laptop this is just a very reduced data set for the sake of a demo uh just keep that in mind um so here with the ara",
    "start": "2166880",
    "end": "2172960"
  },
  {
    "text": "the name space is really the name of the signature set that we're using uh and then the you know actual",
    "start": "2172960",
    "end": "2179200"
  },
  {
    "text": "signature that match the description um with claim iv the only thing that's",
    "start": "2179200",
    "end": "2184240"
  },
  {
    "text": "of interest is really the result so is it is it a virus or is it not and if it is what's the category for pe hash",
    "start": "2184240",
    "end": "2192240"
  },
  {
    "text": "we have the pe hash calculation uh if you're not familiar with pe hash p hash is an algorithm that takes a",
    "start": "2192240",
    "end": "2199280"
  },
  {
    "text": "specific pieces out of the pe header uh hashes them together using md5",
    "start": "2199280",
    "end": "2207680"
  },
  {
    "text": "the p hash creates a large bit string which is then hashed into md5 for analysis",
    "start": "2208320",
    "end": "2213599"
  },
  {
    "text": "so this is a malware clustering algorithm so it's used to cluster malware that has very similar",
    "start": "2213599",
    "end": "2219359"
  },
  {
    "text": "properties in its pe header and then we also have the magic sorry the the output of the file command",
    "start": "2219359",
    "end": "2227280"
  },
  {
    "text": "so file magic so we just you know can tell how many of these files we have",
    "start": "2227280",
    "end": "2233119"
  },
  {
    "text": "um and then lastly we have pe frame pe frame is an open source tool that",
    "start": "2233119",
    "end": "2238560"
  },
  {
    "text": "does a handful of different static analysis operations uh we took pe frame uh on",
    "start": "2238560",
    "end": "2244160"
  },
  {
    "text": "github we forked it and we just made it output json so we can easily take the data and get it back all",
    "start": "2244160",
    "end": "2249520"
  },
  {
    "text": "in a very nice structured format so this is the output of pe frame so these are all you know faceted",
    "start": "2249520",
    "end": "2256000"
  },
  {
    "text": "roll-ups on this data uh one thing i haven't mentioned so far is all these you know fastest roll-ups allow you to launch searches",
    "start": "2256000",
    "end": "2262320"
  },
  {
    "text": "so you want to see all the upx data you just click the link and it launches a search for you so",
    "start": "2262320",
    "end": "2268160"
  },
  {
    "text": "we're back to that original search interface that i mentioned before with a pre-loaded search with which you can then look through these",
    "start": "2268160",
    "end": "2274240"
  },
  {
    "text": "these search results and further further narrow your query by you know",
    "start": "2274240",
    "end": "2280000"
  },
  {
    "text": "clicking any of these values so let's just click one of them and it you know allows you to iteratively reduce the data set that you",
    "start": "2280000",
    "end": "2286320"
  },
  {
    "text": "care to look at i have some interesting ones up pre-loaded so this really just shows off",
    "start": "2286320",
    "end": "2295200"
  },
  {
    "text": "we support wild carding so with this we're looking at the claim ap data all the claim ap data that shows the",
    "start": "2295200",
    "end": "2302599"
  },
  {
    "text": "trojan.spy.spyhise star because there's a there's a bunch of these",
    "start": "2302599",
    "end": "2307760"
  },
  {
    "text": "of these categories we also pulled up some dalvik files so",
    "start": "2307760",
    "end": "2313280"
  },
  {
    "text": "dalvik is the uh the android executable file format so this these are",
    "start": "2313280",
    "end": "2318480"
  },
  {
    "text": "basically android programs and we've got a bunch of these that were labeled malicious from our providers",
    "start": "2318480",
    "end": "2323680"
  },
  {
    "text": "which is kind of interesting and then lastly if you oh that's off the screen let me",
    "start": "2323680",
    "end": "2329359"
  },
  {
    "text": "uh let me adjust this",
    "start": "2329359",
    "end": "2341838"
  },
  {
    "text": "that's weird",
    "start": "2343599",
    "end": "2346160"
  },
  {
    "text": "sorry about that so you can't see it i'm not sure why it's put off here uh but this is the",
    "start": "2348640",
    "end": "2355200"
  },
  {
    "text": "actual detail page so if you if you were to click any of those search results uh this is what you'd see so it shows",
    "start": "2355200",
    "end": "2360400"
  },
  {
    "text": "which is cut off really everything we know about this piece of malware uh so in this case we have clam av we",
    "start": "2360400",
    "end": "2366000"
  },
  {
    "text": "have pe frame we have yara and we have",
    "start": "2366000",
    "end": "2372000"
  },
  {
    "text": "pe hash let me just scroll down one thing you might notice is this data is very tabular we did that",
    "start": "2372000",
    "end": "2378480"
  },
  {
    "text": "really just for the sake of exploration so you can look through the data that you have just extracted out of the malware",
    "start": "2378480",
    "end": "2384880"
  },
  {
    "text": "and view in a tabular form we also expose raw json for all the uh for the data",
    "start": "2384880",
    "end": "2391280"
  },
  {
    "text": "so you can see it in its original structured form this allows you to write application if you wanted to write an application on top of this",
    "start": "2391280",
    "end": "2397599"
  },
  {
    "text": "you can call these api calls and get the actual raw data that backs it",
    "start": "2397599",
    "end": "2402640"
  },
  {
    "text": "you can also focus in on if you just cared about the claim ib data for your specific file you can make api",
    "start": "2402640",
    "end": "2408800"
  },
  {
    "text": "calls and just get that specific json data",
    "start": "2408800",
    "end": "2413119"
  },
  {
    "text": "any questions about about this web interface or about you know what we've showed you so far",
    "start": "2414400",
    "end": "2425838"
  },
  {
    "text": "the question is can we use our own our own tools such as pe dump as of right now if the tool can be",
    "start": "2429680",
    "end": "2435760"
  },
  {
    "text": "written as a script that runs on unix so a python script or bash script or really any script that can process",
    "start": "2435760",
    "end": "2441280"
  },
  {
    "text": "malware you can use it over this system",
    "start": "2441280",
    "end": "2453839"
  },
  {
    "text": "so we're trying to determine what the highest entropic features infogain standard machine learning techniques",
    "start": "2458400",
    "end": "2467839"
  },
  {
    "text": "is so the question is what are we doing for the five hour marker uh over the 20 million files um we're",
    "start": "2478839",
    "end": "2485599"
  },
  {
    "text": "we're currently doing things that are significantly more complex than strings um we're extracting all the feature",
    "start": "2485599",
    "end": "2491920"
  },
  {
    "text": "elements that we have for that particular one at that time i think we had about 400 feature elements that we were extracting",
    "start": "2491920",
    "end": "2497839"
  },
  {
    "text": "from the individual headers we were extracting individual elements from the",
    "start": "2497839",
    "end": "2503280"
  },
  {
    "text": "sole the resources so we're doing actual resource extraction internally inside of the pe file itself",
    "start": "2503280",
    "end": "2510319"
  },
  {
    "text": "and we were collecting those and reinserting them back into the system we've got one more back there we're",
    "start": "2510319",
    "end": "2516400"
  },
  {
    "text": "about to do a wrap-up as well so this will be the last question before we complete just just to follow on his question",
    "start": "2516400",
    "end": "2522240"
  },
  {
    "text": "uh your static and your resource extraction how long does that take for a single app versus like you throw it in your hadoop",
    "start": "2522240",
    "end": "2529359"
  },
  {
    "text": "plus there and you're like oh five hours but if if it's one app outside of the cluster how long does it take",
    "start": "2529359",
    "end": "2535119"
  },
  {
    "text": "minutes seconds hours uh so that will definitely depend on um the size of the file itself and a",
    "start": "2535119",
    "end": "2540880"
  },
  {
    "text": "bunch of other things um but on the whole it's it's on the order of only i think we can do it in under a",
    "start": "2540880",
    "end": "2547119"
  },
  {
    "text": "second under a second okay cool the majority of it can be done in under a second okay so i'm gonna wrap this up real fast",
    "start": "2547119",
    "end": "2555359"
  },
  {
    "text": "um then we're gonna have a little bit more time for questions and i'm sure everyone's uh eager to get out because it's been a long day so far um so",
    "start": "2555359",
    "end": "2562079"
  },
  {
    "text": "the big kicker here as everything goes for binary pig is that it's a framework and even though the individual elements",
    "start": "2562079",
    "end": "2568480"
  },
  {
    "text": "that we have when we're releasing the tool uh yara p hash p e frame",
    "start": "2568480",
    "end": "2573839"
  },
  {
    "text": "and clam av are certainly not the height of all that can be done for static analysis",
    "start": "2573839",
    "end": "2579680"
  },
  {
    "text": "we're releasing them in this format to give examples of what you can do how easy it is to add",
    "start": "2579680",
    "end": "2584720"
  },
  {
    "text": "new elements how easy it is to add new things and that's really what this is for the ability to quickly add new scripts and",
    "start": "2584720",
    "end": "2590800"
  },
  {
    "text": "new analytics and apply them across a historical data set with very little time necessary to concern",
    "start": "2590800",
    "end": "2596400"
  },
  {
    "text": "yourself with will will this scale in this way will we have run into any kind of contentions for uh processing this over network you know",
    "start": "2596400",
    "end": "2603440"
  },
  {
    "text": "all that has to be abstracted away so that analysts researchers can very easily develop",
    "start": "2603440",
    "end": "2608800"
  },
  {
    "text": "new scripts without having to be concerned with those elements the feature extraction itself is",
    "start": "2608800",
    "end": "2613920"
  },
  {
    "text": "something that we weren't able to do before internally this quickly or this extensively and it's certainly something that's",
    "start": "2613920",
    "end": "2619280"
  },
  {
    "text": "available now we hope that it's going to be something that people use to develop new ways of uh doing large-scale triage",
    "start": "2619280",
    "end": "2627200"
  },
  {
    "text": "internally we've been using it for weekly av scans as we you know grab new signatures for various other",
    "start": "2627200",
    "end": "2633839"
  },
  {
    "text": "antiviruses other than just clam we're constantly looking at the deltas evolving what we",
    "start": "2633839",
    "end": "2639760"
  },
  {
    "text": "understand it's essentially building a historical virus total like application internally",
    "start": "2639760",
    "end": "2646000"
  },
  {
    "text": "and then in addition to what we've got here um hopefully we'll be able to open source that are presented as we",
    "start": "2646000",
    "end": "2651440"
  },
  {
    "text": "develop the validation and tighten down everything that we're working on we've developed a binary",
    "start": "2651440",
    "end": "2656800"
  },
  {
    "text": "classifier that improves our sample collection that we were able to very quickly determine whether or not",
    "start": "2656800",
    "end": "2661839"
  },
  {
    "text": "this is something such as adware true malware various other you know things like droppers",
    "start": "2661839",
    "end": "2666960"
  },
  {
    "text": "and then triage them as necessary before inclusion into our dynamic system we've got a little future",
    "start": "2666960",
    "end": "2674720"
  },
  {
    "start": "2673000",
    "end": "2673000"
  },
  {
    "text": "work left to do right now we have compatibility with pig 10 and pig 11. pig 12 i'm sorry let me back up",
    "start": "2674720",
    "end": "2682480"
  },
  {
    "text": "we have compatibility with pig 8 and pig 9. we need to develop compatibility for pig 10 and pig 11.",
    "start": "2682480",
    "end": "2688079"
  },
  {
    "text": "we'd like to release an ec2 tutorial um very quickly we've done some of this work over ec2 to store",
    "start": "2688079",
    "end": "2695440"
  },
  {
    "text": "run uh historical data sets um to run our entire historical set um cost us about 150 bucks for a single",
    "start": "2695440",
    "end": "2703119"
  },
  {
    "text": "query um over ec2 and then to run every single day uh individually cost us like 12",
    "start": "2703119",
    "end": "2710800"
  },
  {
    "text": "so it's very cheap if you don't have a hadoop cluster currently you're totally able to take binary pig and test it out on",
    "start": "2710800",
    "end": "2716800"
  },
  {
    "text": "something that's relatively inexpensive we need to develop some better error logging and handling right now we",
    "start": "2716800",
    "end": "2722960"
  },
  {
    "text": "believe that a lot of our error messages should be stored in separate databases for more robust storage and analysis",
    "start": "2722960",
    "end": "2729200"
  },
  {
    "text": "right now we're piggybacking off of hadoop's own error logging mechanisms this works but we think we can do",
    "start": "2729200",
    "end": "2735200"
  },
  {
    "text": "somewhat better we need to automate some of our deployments the analytic daemons right now are not",
    "start": "2735200",
    "end": "2740319"
  },
  {
    "text": "automated for deployment and we need to develop a way for doing that and we definitely need to develop some",
    "start": "2740319",
    "end": "2745440"
  },
  {
    "text": "ways of pushing out some of the dependency libraries a little easier the entire framework as we've shown it",
    "start": "2745440",
    "end": "2751440"
  },
  {
    "text": "today and as we've described it is open source the web front end the analytics some of",
    "start": "2751440",
    "end": "2756640"
  },
  {
    "text": "the analytics scripts themselves and the binary pig modifications the apache pig system",
    "start": "2756640",
    "end": "2762480"
  },
  {
    "text": "are all sitting up on github right now please do a pull request if you have anything you'd like to change we",
    "start": "2762480",
    "end": "2767599"
  },
  {
    "text": "certainly are definitely into feedback so this is pretty much the end of the presentation i'd love to know if anyone has any",
    "start": "2767599",
    "end": "2773920"
  },
  {
    "text": "further questions if there's anything that anyone's interested in talking about we're going to be here um if these are things that you're",
    "start": "2773920",
    "end": "2780000"
  },
  {
    "text": "interested in we'd definitely like for you to come and chat with us anything else",
    "start": "2780000",
    "end": "2789838"
  },
  {
    "start": "2785000",
    "end": "2785000"
  },
  {
    "text": "thank you are there any other questions before everyone leaves yes um on your um so you mentioned a",
    "start": "2795200",
    "end": "2802880"
  },
  {
    "text": "malware cluster or 300 000 samples or so yes um what was sort of the features",
    "start": "2802880",
    "end": "2808160"
  },
  {
    "text": "that you used to to determine what the clusters would be so the feature set itself is fairly large and we definitely need to prune it",
    "start": "2808160",
    "end": "2814400"
  },
  {
    "text": "down um a handful of the features that were included were individual complexities of various sections",
    "start": "2814400",
    "end": "2820960"
  },
  {
    "text": "we also had features regarding the memory allocations that were outlined in the pe file",
    "start": "2820960",
    "end": "2826480"
  },
  {
    "text": "for various elements of the pe file itself the number of features or the resources",
    "start": "2826480",
    "end": "2833520"
  },
  {
    "text": "and resource usage inside and size and individual hashes of those files as well",
    "start": "2833520",
    "end": "2840079"
  },
  {
    "text": "we're hoping to you know do further validation on the results and release the entire feature set shortly",
    "start": "2840079",
    "end": "2846640"
  },
  {
    "text": "that's it any questions",
    "start": "2848400",
    "end": "2854240"
  },
  {
    "text": "thanks i was wondering so with your clustering algorithm um can you talk a little bit more about",
    "start": "2855359",
    "end": "2861599"
  },
  {
    "text": "so do you have a distance function and then you have some clustering can you talk a bit more about the math or how that works we'll take that offline",
    "start": "2861599",
    "end": "2868240"
  },
  {
    "text": "that would probably be better okay that's all right thanks and i had the same question about your binary classifier but maybe we'll take that",
    "start": "2868240",
    "end": "2873760"
  },
  {
    "text": "offline too same thing okay",
    "start": "2873760",
    "end": "2877279"
  },
  {
    "text": "i think that's it thanks",
    "start": "2883200",
    "end": "2887838"
  }
]
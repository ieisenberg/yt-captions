[
  {
    "start": "0",
    "end": "293000"
  },
  {
    "text": "This is a video for anyone who already knows what eigenvalues and eigenvectors are, ",
    "start": "0",
    "end": "3969"
  },
  {
    "text": "and who might enjoy a quick way to compute them in the case of 2x2 matrices.",
    "start": "3969",
    "end": "7560"
  },
  {
    "text": "If you're unfamiliar with eigenvalues, go ahead and take a look at this video here, ",
    "start": "8580",
    "end": "11993"
  },
  {
    "text": "which is actually meant to introduce them.",
    "start": "11993",
    "end": "13700"
  },
  {
    "text": "You can skip ahead if all you want to do is see the trick, ",
    "start": "14680",
    "end": "17390"
  },
  {
    "text": "but if possible I'd like you to rediscover it for yourself.",
    "start": "17390",
    "end": "20099"
  },
  {
    "text": "So for that, let's lay out a little background.",
    "start": "20580",
    "end": "22380"
  },
  {
    "text": "As a quick reminder, if the effect of a linear transformation on a ",
    "start": "23260",
    "end": "26957"
  },
  {
    "text": "given vector is to scale that vector by some constant, ",
    "start": "26957",
    "end": "29991"
  },
  {
    "text": "we call it an eigenvector of the transformation, ",
    "start": "29991",
    "end": "32695"
  },
  {
    "text": "and we call the relevant scaling factor the corresponding eigenvalue, ",
    "start": "32695",
    "end": "36558"
  },
  {
    "text": "often denoted with the letter lambda.",
    "start": "36558",
    "end": "38600"
  },
  {
    "text": "When you write this as an equation, and you rearrange a little bit, ",
    "start": "39840",
    "end": "44513"
  },
  {
    "text": "what you see is that if the number lambda is an eigenvalue of a matrix A, ",
    "start": "44513",
    "end": "49598"
  },
  {
    "text": "then the matrix A minus lambda times the identity must send some non-zero vector, ",
    "start": "49598",
    "end": "55233"
  },
  {
    "text": "namely the corresponding eigenvector, to the zero vector, ",
    "start": "55233",
    "end": "59219"
  },
  {
    "text": "which in turn means that the determinant of this modified matrix must be zero.",
    "start": "59219",
    "end": "64580"
  },
  {
    "text": "Okay, that's all a little bit of a mouthful to say, but again, ",
    "start": "66120",
    "end": "68808"
  },
  {
    "text": "I'm assuming that all of this is review for any of you watching.",
    "start": "68808",
    "end": "71540"
  },
  {
    "text": "So, the usual way to compute eigenvalues, how I used to do it and how I believe ",
    "start": "72820",
    "end": "77297"
  },
  {
    "text": "most students are taught to carry it out, is to subtract the unknown value ",
    "start": "77297",
    "end": "81493"
  },
  {
    "text": "lambda off the diagonals, and then solve for the determinant is equal to zero.",
    "start": "81494",
    "end": "85860"
  },
  {
    "text": "Doing this always involves a few extra steps to expand out and simplify to get a ",
    "start": "87760",
    "end": "91929"
  },
  {
    "text": "clean quadratic polynomial, what's known as the characteristic polynomial of the matrix.",
    "start": "91929",
    "end": "96460"
  },
  {
    "text": "The eigenvalues are the roots of this polynomial, ",
    "start": "97360",
    "end": "99924"
  },
  {
    "text": "so to find them you have to apply the quadratic formula, ",
    "start": "99924",
    "end": "102847"
  },
  {
    "text": "which itself typically requires one or two more steps of simplification.",
    "start": "102847",
    "end": "106540"
  },
  {
    "text": "Honestly, the process isn't terrible, but at least for two by two matrices, ",
    "start": "107760",
    "end": "111684"
  },
  {
    "text": "there is a much more direct way you can get at the answer.",
    "start": "111684",
    "end": "114680"
  },
  {
    "text": "And if you want to rediscover this trick, there's only three ",
    "start": "115400",
    "end": "117859"
  },
  {
    "text": "relevant facts you need to know, each of which is worth knowing ",
    "start": "117859",
    "end": "120440"
  },
  {
    "text": "in its own right and can help you with other problem solving.",
    "start": "120440",
    "end": "122900"
  },
  {
    "text": "Number one, the trace of a matrix, which is the sum of these two diagonal entries, ",
    "start": "123820",
    "end": "128649"
  },
  {
    "text": "is equal to the sum of the eigenvalues.",
    "start": "128650",
    "end": "130918"
  },
  {
    "text": "Or, another way to phrase it, more useful for our purposes, ",
    "start": "131700",
    "end": "134722"
  },
  {
    "text": "is that the mean of the two eigenvalues is the same as the mean of these two ",
    "start": "134723",
    "end": "138603"
  },
  {
    "text": "diagonal entries.",
    "start": "138603",
    "end": "139459"
  },
  {
    "text": "Number two, the determinant of a matrix, our usual ad-bc formula, ",
    "start": "141000",
    "end": "145649"
  },
  {
    "text": "is equal to the product of the two eigenvalues.",
    "start": "145649",
    "end": "148960"
  },
  {
    "text": "And this should kind of make sense if you understand that eigenvalues describe ",
    "start": "150060",
    "end": "153976"
  },
  {
    "text": "how much an operator stretches space in a particular direction, ",
    "start": "153976",
    "end": "157149"
  },
  {
    "text": "and that the determinant describes how much an operator scales areas, or volumes, ",
    "start": "157149",
    "end": "161214"
  },
  {
    "text": "as a whole.",
    "start": "161214",
    "end": "161760"
  },
  {
    "text": "Now before getting to the third fact, notice how you can essentially read ",
    "start": "162800",
    "end": "165980"
  },
  {
    "text": "these first two values out of the matrix without really writing much down.",
    "start": "165980",
    "end": "169159"
  },
  {
    "text": "Take this matrix here as an example.",
    "start": "169760",
    "end": "171319"
  },
  {
    "text": "Straight away, you can know that the mean of the ",
    "start": "171820",
    "end": "174542"
  },
  {
    "text": "eigenvalues is the same as the mean of 8 and 6, which is 7.",
    "start": "174542",
    "end": "177820"
  },
  {
    "text": "Likewise, most linear algebra students are pretty well practiced at ",
    "start": "179580",
    "end": "183249"
  },
  {
    "text": "finding the determinant, which in this case works out to be 48 minus 8.",
    "start": "183249",
    "end": "187079"
  },
  {
    "text": "So right away, you know that the product of the two eigenvalues is 40.",
    "start": "188240",
    "end": "191700"
  },
  {
    "text": "Now take a moment to see if you can derive what will be our third relevant fact, ",
    "start": "192780",
    "end": "196687"
  },
  {
    "text": "which is how you can quickly recover two numbers when you ",
    "start": "196687",
    "end": "199485"
  },
  {
    "text": "know their mean and you know their product.",
    "start": "199485",
    "end": "201560"
  },
  {
    "text": "Here, let's focus on this example.",
    "start": "202460",
    "end": "203720"
  },
  {
    "text": "You know that the two values are evenly spaced around the number 7, ",
    "start": "204200",
    "end": "207987"
  },
  {
    "text": "so they look like 7 plus or minus something, let's call that something d for distance.",
    "start": "207988",
    "end": "212780"
  },
  {
    "text": "You also know that the product of these two numbers is 40.",
    "start": "213560",
    "end": "216380"
  },
  {
    "text": "Now to find d, notice that this product expands really nicely, ",
    "start": "218600",
    "end": "221719"
  },
  {
    "text": "it works out as a difference of squares.",
    "start": "221719",
    "end": "223700"
  },
  {
    "text": "So from there, you can find d.",
    "start": "224560",
    "end": "226860"
  },
  {
    "text": "d squared is 7 squared minus 40, or 9, which means that d itself is 3.",
    "start": "228200",
    "end": "233400"
  },
  {
    "text": "In other words, the two values for this very specific example work out to be 4 and 10.",
    "start": "236380",
    "end": "241100"
  },
  {
    "text": "But our goal is a quick trick, and you wouldn't want to think through this each time, ",
    "start": "241680",
    "end": "245607"
  },
  {
    "text": "so let's wrap up what we just did in a general formula.",
    "start": "245607",
    "end": "248120"
  },
  {
    "text": "For any mean m and product p, the distance squared ",
    "start": "248640",
    "end": "252585"
  },
  {
    "text": "is always going to be m squared minus p.",
    "start": "252585",
    "end": "255680"
  },
  {
    "text": "This gives the third key fact, which is that when two numbers ",
    "start": "257560",
    "end": "261293"
  },
  {
    "text": "have a mean m and a product p, you can write those two numbers ",
    "start": "261293",
    "end": "265087"
  },
  {
    "text": "as m plus or minus the square root of m squared minus p.",
    "start": "265087",
    "end": "268460"
  },
  {
    "text": "This is decently fast to re-derive on the fly if you ever forget it, ",
    "start": "270100",
    "end": "273421"
  },
  {
    "text": "and it's essentially just a rephrasing of the difference of squares formula.",
    "start": "273421",
    "end": "277080"
  },
  {
    "text": "But even still, it's a fact that's worth memorizing so it's at the tip of your fingers.",
    "start": "277860",
    "end": "281219"
  },
  {
    "text": "In fact, my friend Tim from the channel A Capella Science wrote ",
    "start": "281220",
    "end": "284237"
  },
  {
    "text": "us a nice quick jingle to make it a little bit more memorable.",
    "start": "284237",
    "end": "287160"
  },
  {
    "text": "Let me show you how this works, say for the matrix 3 1 4 1.",
    "start": "291900",
    "end": "297620"
  },
  {
    "start": "293000",
    "end": "624000"
  },
  {
    "text": "You start by bringing to mind the formula, maybe stating it all in your head.",
    "start": "298100",
    "end": "301820"
  },
  {
    "text": "But when you write it down, you fill in the appropriate values for m and p as you go.",
    "start": "306200",
    "end": "311620"
  },
  {
    "text": "So in this example, the mean of the eigenvalues is the same as the mean of 3 and 1, ",
    "start": "312340",
    "end": "317147"
  },
  {
    "text": "which is 2, so the thing you start writing is 2 plus or minus ",
    "start": "317147",
    "end": "320696"
  },
  {
    "text": "the square root of 2 squared minus.",
    "start": "320696",
    "end": "322700"
  },
  {
    "text": "Then the product of the eigenvalues is the determinant, ",
    "start": "323540",
    "end": "327229"
  },
  {
    "text": "which in this example is 3 times 1 minus 1 times 4, or negative 1, ",
    "start": "327229",
    "end": "331644"
  },
  {
    "text": "so that's the final thing you fill in, which means the eigenvalues are 2 plus ",
    "start": "331644",
    "end": "336783"
  },
  {
    "text": "or minus the square root of 5.",
    "start": "336783",
    "end": "338759"
  },
  {
    "text": "You might recognize that this is the same matrix I was using at the beginning, ",
    "start": "340300",
    "end": "343849"
  },
  {
    "text": "but notice how much more directly we can get at the answer.",
    "start": "343849",
    "end": "346500"
  },
  {
    "text": "Here, try another one.",
    "start": "348140",
    "end": "349180"
  },
  {
    "text": "This time, the mean of the eigenvalues is the same as the mean of 2 and 8, which is 5.",
    "start": "349440",
    "end": "354480"
  },
  {
    "text": "So again, you start writing out the formula, but this time writing 5 in place of m.",
    "start": "355100",
    "end": "359220"
  },
  {
    "text": "And then the determinant is 2 times 8 minus 7 times 1, or 9.",
    "start": "362980",
    "end": "368300"
  },
  {
    "text": "So in this example, the eigenvalues look like 5 plus or minus the square root of 16, ",
    "start": "369520",
    "end": "375401"
  },
  {
    "text": "which simplifies even further as 9 and 1.",
    "start": "375402",
    "end": "378240"
  },
  {
    "text": "You see what I mean about how you can basically just start ",
    "start": "379420",
    "end": "381914"
  },
  {
    "text": "writing down the eigenvalues while you're staring at the matrix?",
    "start": "381914",
    "end": "384620"
  },
  {
    "text": "It's typically just the tiniest bit of simplification at the end.",
    "start": "385280",
    "end": "388160"
  },
  {
    "text": "Honestly, I've found myself using this trick a lot when I'm sketching quick ",
    "start": "389060",
    "end": "392412"
  },
  {
    "text": "notes related to linear algebra and want to use small matrices as examples.",
    "start": "392412",
    "end": "395720"
  },
  {
    "text": "I've been working on a video about matrix exponents, ",
    "start": "396180",
    "end": "398612"
  },
  {
    "text": "where eigenvalues pop up a lot, and I realize it's just very handy ",
    "start": "398612",
    "end": "401688"
  },
  {
    "text": "if students can read out the eigenvalues from small examples without ",
    "start": "401688",
    "end": "404854"
  },
  {
    "text": "losing the main line of thought by getting bogged down in a different calculation.",
    "start": "404855",
    "end": "408620"
  },
  {
    "text": "As another fun example, take a look at this set of three different matrices, ",
    "start": "409740",
    "end": "413440"
  },
  {
    "text": "which comes up a lot in quantum mechanics.",
    "start": "413441",
    "end": "415460"
  },
  {
    "text": "They're known as the Pauli spin matrices.",
    "start": "415760",
    "end": "417520"
  },
  {
    "text": "If you know quantum mechanics, you'll know that the eigenvalues ",
    "start": "418600",
    "end": "421465"
  },
  {
    "text": "of matrices are highly relevant to the physics that they describe.",
    "start": "421465",
    "end": "424419"
  },
  {
    "text": "And if you don't know quantum mechanics, let this just be a little glimpse ",
    "start": "425220",
    "end": "428240"
  },
  {
    "text": "of how these computations are actually very relevant to real applications.",
    "start": "428240",
    "end": "431220"
  },
  {
    "text": "The mean of the diagonal entries in all three cases is zero.",
    "start": "432540",
    "end": "435880"
  },
  {
    "text": "So the mean of the eigenvalues in all of these cases is zero, ",
    "start": "437560",
    "end": "440688"
  },
  {
    "text": "which makes our formula look especially simple.",
    "start": "440688",
    "end": "443060"
  },
  {
    "text": "What about the products of the eigenvalues, the determinants of these matrices?",
    "start": "445380",
    "end": "448800"
  },
  {
    "text": "For the first one, it's 0, minus 1, or negative 1.",
    "start": "449700",
    "end": "452560"
  },
  {
    "text": "The second one also looks like 0, minus 1, but it takes ",
    "start": "453200",
    "end": "455792"
  },
  {
    "text": "a moment more to see because of the complex numbers.",
    "start": "455792",
    "end": "458199"
  },
  {
    "text": "And the final one looks like negative 1, minus 0.",
    "start": "458840",
    "end": "461360"
  },
  {
    "text": "So in all cases, the eigenvalues simplify to be plus and minus 1.",
    "start": "462060",
    "end": "465919"
  },
  {
    "text": "Although in this case, you really don't need a formula to find two values if ",
    "start": "466720",
    "end": "470000"
  },
  {
    "text": "you know that they're evenly spaced around 0 and their product is negative 1.",
    "start": "470000",
    "end": "473280"
  },
  {
    "text": "If you're curious, in the context of quantum mechanics, ",
    "start": "474640",
    "end": "477608"
  },
  {
    "text": "these matrices describe observations you might make about a particle's spin in the x, ",
    "start": "477608",
    "end": "482166"
  },
  {
    "text": "y, or z direction.",
    "start": "482166",
    "end": "483120"
  },
  {
    "text": "And the fact that their eigenvalues are plus and minus 1 corresponds with the idea ",
    "start": "483560",
    "end": "487906"
  },
  {
    "text": "that the values for the spin that you would observe would be either entirely in one ",
    "start": "487907",
    "end": "492306"
  },
  {
    "text": "direction or entirely in another, as opposed to something continuously ranging in between.",
    "start": "492306",
    "end": "497020"
  },
  {
    "text": "Maybe you'd wonder how exactly this works, or why you would use 2x2 ",
    "start": "498320",
    "end": "501817"
  },
  {
    "text": "matrices that have complex numbers to describe spin in three dimensions.",
    "start": "501817",
    "end": "505520"
  },
  {
    "text": "Those would be fair questions, just outside the scope of what I want to talk about here.",
    "start": "506100",
    "end": "509760"
  },
  {
    "text": "You know, it's funny, I wrote this section because I wanted some case where ",
    "start": "510480",
    "end": "514093"
  },
  {
    "text": "you have 2x2 matrices that aren't just toy examples or homework problems, ",
    "start": "514093",
    "end": "517611"
  },
  {
    "text": "ones where they actually come up in practice, and quantum mechanics is great for that.",
    "start": "517611",
    "end": "521700"
  },
  {
    "text": "The thing is, after I made it, I realized that the whole ",
    "start": "521700",
    "end": "524886"
  },
  {
    "text": "example kind of undercuts the point that I'm trying to make.",
    "start": "524886",
    "end": "528240"
  },
  {
    "text": "For these specific matrices, when you use the traditional method, ",
    "start": "528740",
    "end": "532285"
  },
  {
    "text": "the one with characteristic polynomials, it's essentially just as fast.",
    "start": "532285",
    "end": "536100"
  },
  {
    "text": "It might actually be faster.",
    "start": "536220",
    "end": "537639"
  },
  {
    "text": "I mean, take a look at the first one.",
    "start": "538240",
    "end": "539399"
  },
  {
    "text": "The relevant determinant directly gives you a characteristic polynomial ",
    "start": "539680",
    "end": "543881"
  },
  {
    "text": "of lambda squared minus 1, and clearly that has roots of plus and minus 1.",
    "start": "543881",
    "end": "548199"
  },
  {
    "text": "Same answer when you do the second matrix, lambda squared minus 1.",
    "start": "548840",
    "end": "551760"
  },
  {
    "text": "And as for the last matrix, forget about doing any computations, ",
    "start": "553880",
    "end": "557287"
  },
  {
    "text": "traditional or otherwise, it's already a diagonal matrix, ",
    "start": "557287",
    "end": "560328"
  },
  {
    "text": "so those diagonal entries are the eigenvalues.",
    "start": "560328",
    "end": "562740"
  },
  {
    "text": "However, the example is not totally lost to our cause.",
    "start": "564300",
    "end": "566920"
  },
  {
    "text": "Where you will actually feel the speedup is in the more general case, ",
    "start": "567380",
    "end": "570954"
  },
  {
    "text": "where you take a linear combination of these three matrices and then try to compute ",
    "start": "570954",
    "end": "575243"
  },
  {
    "text": "the eigenvalues.",
    "start": "575243",
    "end": "576060"
  },
  {
    "text": "You might write this as a times the first one, ",
    "start": "576820",
    "end": "579590"
  },
  {
    "text": "plus b times the second, plus c times the third.",
    "start": "579590",
    "end": "582420"
  },
  {
    "text": "In quantum mechanics, this would describe spin observations ",
    "start": "583020",
    "end": "586150"
  },
  {
    "text": "in a general direction of a vector with coordinates a, b, c.",
    "start": "586150",
    "end": "589280"
  },
  {
    "text": "More specifically, you should assume that this vector is normalized, ",
    "start": "590900",
    "end": "594481"
  },
  {
    "text": "meaning a squared plus b squared plus c squared is equal to 1.",
    "start": "594481",
    "end": "597700"
  },
  {
    "text": "When you look at this new matrix, it's immediate ",
    "start": "598600",
    "end": "601295"
  },
  {
    "text": "to see that the mean of the eigenvalues is still 0.",
    "start": "601295",
    "end": "604100"
  },
  {
    "text": "And you might also enjoy pausing for a brief moment to confirm ",
    "start": "604600",
    "end": "607880"
  },
  {
    "text": "that the product of those eigenvalues is still negative 1.",
    "start": "607880",
    "end": "610900"
  },
  {
    "text": "And then from there, concluding what the eigenvalues must be.",
    "start": "613260",
    "end": "615920"
  },
  {
    "text": "And this time, the characteristic polynomial approach would be by ",
    "start": "617220",
    "end": "620282"
  },
  {
    "text": "comparison a lot more cumbersome, definitely harder to do in your head.",
    "start": "620283",
    "end": "623580"
  },
  {
    "start": "624000",
    "end": "720000"
  },
  {
    "text": "To be clear, using the mean product formula is not fundamentally ",
    "start": "625080",
    "end": "628089"
  },
  {
    "text": "different from finding roots of the characteristic polynomial.",
    "start": "628089",
    "end": "630959"
  },
  {
    "text": "I mean, it can't be, they're solving the same problem.",
    "start": "631340",
    "end": "633440"
  },
  {
    "text": "One way to think about this actually is that the mean ",
    "start": "634160",
    "end": "636441"
  },
  {
    "text": "product formula is a nice way to solve quadratics in general.",
    "start": "636442",
    "end": "639020"
  },
  {
    "text": "And some viewers of the channel may recognize this.",
    "start": "639600",
    "end": "641660"
  },
  {
    "text": "Think about it, when you're trying to find the roots of a quadratic, ",
    "start": "642540",
    "end": "645836"
  },
  {
    "text": "given the coefficients, that's another situation where you know the sum of two values, ",
    "start": "645836",
    "end": "649991"
  },
  {
    "text": "and you also know their product, but you're trying to recover the original two values.",
    "start": "649991",
    "end": "654100"
  },
  {
    "text": "Specifically, if the polynomial is normalized, so that this leading coefficient is 1, ",
    "start": "655560",
    "end": "660046"
  },
  {
    "text": "then the mean of the roots will be negative 1 half times this linear coefficient, ",
    "start": "660046",
    "end": "664323"
  },
  {
    "text": "which is negative 1 times the sum of those roots.",
    "start": "664323",
    "end": "666880"
  },
  {
    "text": "With the example on the screen, that makes the mean 5.",
    "start": "668020",
    "end": "670180"
  },
  {
    "text": "And the product of the roots is even easier, it's just the constant term, ",
    "start": "671980",
    "end": "675479"
  },
  {
    "text": "no adjustments needed.",
    "start": "675479",
    "end": "676520"
  },
  {
    "text": "So from there, you would apply the mean product formula, and that gives you the roots.",
    "start": "677340",
    "end": "680900"
  },
  {
    "text": "And on the one hand, you could think of this as a lighter ",
    "start": "685140",
    "end": "687818"
  },
  {
    "text": "weight version of the traditional quadratic formula.",
    "start": "687818",
    "end": "690220"
  },
  {
    "text": "But the real advantage is not just that it's fewer symbols to memorize, ",
    "start": "690960",
    "end": "694042"
  },
  {
    "text": "it's that each one of them carries more meaning with it.",
    "start": "694042",
    "end": "696440"
  },
  {
    "text": "I mean, the whole point of this eigenvalue trick is that because you can read ",
    "start": "696940",
    "end": "700610"
  },
  {
    "text": "out the mean and product directly from looking at the matrix, ",
    "start": "700610",
    "end": "703528"
  },
  {
    "text": "you don't need to go through the intermediate step of setting up the characteristic ",
    "start": "703528",
    "end": "707482"
  },
  {
    "text": "polynomial.",
    "start": "707482",
    "end": "708000"
  },
  {
    "text": "You can jump straight to writing down the roots without ever ",
    "start": "708420",
    "end": "711118"
  },
  {
    "text": "explicitly thinking about what the polynomial looks like.",
    "start": "711118",
    "end": "713639"
  },
  {
    "text": "But to do that, we need a version of the quadratic ",
    "start": "713840",
    "end": "716330"
  },
  {
    "text": "formula where the terms carry some kind of meaning.",
    "start": "716330",
    "end": "718820"
  },
  {
    "start": "720000",
    "end": "793000"
  },
  {
    "text": "I realize this is a very specific trick for a very specific audience, ",
    "start": "720380",
    "end": "723457"
  },
  {
    "text": "but it's something I wish I knew in college, so if you happen to know ",
    "start": "723457",
    "end": "726534"
  },
  {
    "text": "any students who might benefit from this, consider sharing it with them.",
    "start": "726534",
    "end": "729700"
  },
  {
    "text": "The hope is that it's not just one more thing that you memorize, ",
    "start": "730280",
    "end": "733246"
  },
  {
    "text": "but that the framing reinforces some other nice facts that are worth knowing, ",
    "start": "733246",
    "end": "736806"
  },
  {
    "text": "like how the trace and the determinant are related to eigenvalues.",
    "start": "736807",
    "end": "739820"
  },
  {
    "text": "If you want to prove those facts, by the way, take a moment to ",
    "start": "740560",
    "end": "743502"
  },
  {
    "text": "expand out the characteristic polynomial for a general matrix, ",
    "start": "743502",
    "end": "746444"
  },
  {
    "text": "and then think hard about the meaning of each of these coefficients.",
    "start": "746444",
    "end": "749620"
  },
  {
    "text": "Many thanks to Tim for ensuring that this mean product formula ",
    "start": "752400",
    "end": "755192"
  },
  {
    "text": "will stay stuck in all of our heads for at least a few months.",
    "start": "755192",
    "end": "757940"
  },
  {
    "text": "If you don't know about alcappella science, please do check it out.",
    "start": "761700",
    "end": "766000"
  },
  {
    "text": "The molecular shape of you in particular is one of the greatest things on the internet.",
    "start": "766280",
    "end": "769580"
  }
]
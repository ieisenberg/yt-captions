[
  {
    "start": "0",
    "end": "85000"
  },
  {
    "text": "[Music]",
    "start": "0",
    "end": "5040"
  },
  {
    "text": "[Applause] all right uh so we'll start with the",
    "start": "5040",
    "end": "12759"
  },
  {
    "text": "session accelerating ml inferencing with web assembly and spend 2.o",
    "start": "12759",
    "end": "18960"
  },
  {
    "text": "so yeah my name is Sayan Pak and I'm a field CTO at coo uh coo is fixing the",
    "start": "18960",
    "end": "24599"
  },
  {
    "text": "broken cloud and uh with me I have ru is",
    "start": "24599",
    "end": "30279"
  },
  {
    "text": "CTO at Fon so uh starting off with very simple",
    "start": "30279",
    "end": "36879"
  },
  {
    "text": "stuff and the basics and then moving on to how we can actually deploy uh machine",
    "start": "36879",
    "end": "42039"
  },
  {
    "text": "learning inferencing application locally talk to GPU in cuetes all the three and",
    "start": "42039",
    "end": "49399"
  },
  {
    "text": "yes we we'll try to do everything live um so knowingly unknowingly and if you",
    "start": "49399",
    "end": "54879"
  },
  {
    "text": "like you do not like you're using machine learning in like everywhere so the songs that you listen on Spotify you",
    "start": "54879",
    "end": "61280"
  },
  {
    "text": "get recommendation for the playlist uh Airbnb you are staying you get the recommendation for the next set of um",
    "start": "61280",
    "end": "69159"
  },
  {
    "text": "apartments that the others have booked the same one and you then you are shown with respect to the prices and stuff you",
    "start": "69159",
    "end": "74600"
  },
  {
    "text": "go to shopping you eat food all those recommendations so you we are all the end users already before the hype we are",
    "start": "74600",
    "end": "82960"
  },
  {
    "text": "the end users of machine learning in the apps now the Gen movement uh obviously has been because",
    "start": "82960",
    "end": "90360"
  },
  {
    "text": "of chat GPT uh it obviously blew up the",
    "start": "90360",
    "end": "95759"
  },
  {
    "text": "internet and massive user base of how we can actually interact with a system that",
    "start": "95759",
    "end": "102000"
  },
  {
    "text": "understands us and gives us the input with respect to the conversation that we want to make and keeping the context",
    "start": "102000",
    "end": "109240"
  },
  {
    "text": "alive and giving the relevant information although it's still not uh very up toate with the latest stuff but",
    "start": "109240",
    "end": "115960"
  },
  {
    "text": "whatever till date it is being trained on it gives you the uh appropriate answers so think of it like as the big",
    "start": "115960",
    "end": "124240"
  },
  {
    "text": "brain um of the internet like a small chunk of the internet put in the brain",
    "start": "124240",
    "end": "129520"
  },
  {
    "text": "and you are actually asking that brain the question and getting the answer out of it so that's what you do you you have",
    "start": "129520",
    "end": "136480"
  },
  {
    "text": "a chat interface that's simple you just put your message in with the context that you want and it's able to",
    "start": "136480",
    "end": "142080"
  },
  {
    "text": "understand you can do spelling mistakes it's still able to understand you can just put random stuff and then give your",
    "start": "142080",
    "end": "148560"
  },
  {
    "text": "a question it's still able to understand understand so it it acts like brain and gives you the um answer and it creates",
    "start": "148560",
    "end": "155599"
  },
  {
    "text": "uh a lot of content for you um before getting more into the inferencing so there is AI and there is",
    "start": "155599",
    "end": "162680"
  },
  {
    "start": "158000",
    "end": "346000"
  },
  {
    "text": "machine learning in AI it's you can think of it as like very very simple terms of creating the system intelligent",
    "start": "162680",
    "end": "169120"
  },
  {
    "text": "system agents uh that can reason learn and show the humanik capabilities on the",
    "start": "169120",
    "end": "174440"
  },
  {
    "text": "other hand machine learning is uh trains the model from input and then the train model can do the prediction based on the",
    "start": "174440",
    "end": "181920"
  },
  {
    "text": "trained data and two main categories are supervised and unsupervised learning and",
    "start": "181920",
    "end": "188560"
  },
  {
    "text": "it's pretty simple like in supervis you can actually label the data you can add some metadata to it to make it more",
    "start": "188560",
    "end": "195200"
  },
  {
    "text": "structured and then it can learn from the past examples and then predict based on those examples and then you have the",
    "start": "195200",
    "end": "203200"
  },
  {
    "text": "unsupervised data which is untagged and here what we try to do is it's the",
    "start": "203200",
    "end": "208920"
  },
  {
    "text": "clustering of the data that you try to do because there's no exact tagging that you can add for the uh data so that is",
    "start": "208920",
    "end": "216360"
  },
  {
    "text": "categorized as unsupervised maybe it's more clear from the examples uh so we all know about the spam emails we get",
    "start": "216360",
    "end": "224840"
  },
  {
    "text": "every now and then so you can see when you get a email in your box some of the emails automatically goes into the spam",
    "start": "224840",
    "end": "232599"
  },
  {
    "text": "your spam folder so that is basically the Train on the label data set and tag",
    "start": "232599",
    "end": "239319"
  },
  {
    "text": "whether the that so the training is tagging whether this particular email is Spam or not based on a lot of data like",
    "start": "239319",
    "end": "245720"
  },
  {
    "text": "the words the email addresses that are being used so that's how the training is done and in the end the model is able to",
    "start": "245720",
    "end": "252120"
  },
  {
    "text": "predict whether the new email that came in now the new email was not in the training data set but based on the",
    "start": "252120",
    "end": "258840"
  },
  {
    "text": "training data set it was able to predict whether this particular new email is a spam or not",
    "start": "258840",
    "end": "264840"
  },
  {
    "text": "spam on the other hand is the unsupervised uh where for example what",
    "start": "264840",
    "end": "270120"
  },
  {
    "text": "people buy and recommend based on that so it's a custom customer recommendation",
    "start": "270120",
    "end": "276080"
  },
  {
    "text": "so uh let's say you have a group of customers so here the group customers together based on purchase type",
    "start": "276080",
    "end": "281600"
  },
  {
    "text": "frequency spend so you you have a customer who bought something how many times in the week they are buying how",
    "start": "281600",
    "end": "288280"
  },
  {
    "text": "much is their spend when they are on a particular website or they are in the store based on that you can cluster some",
    "start": "288280",
    "end": "294880"
  },
  {
    "text": "of the customers together and then recommend each other their set of purchase phes or do targeted marketing",
    "start": "294880",
    "end": "301840"
  },
  {
    "text": "Campa campaigns on specific set of users who buys this particular products in this particular range so you can Target",
    "start": "301840",
    "end": "308160"
  },
  {
    "text": "a specific marketing campaign so model should be able to predict uh recommend products enhance the experience uh of",
    "start": "308160",
    "end": "315720"
  },
  {
    "text": "the customers so that's the unsupervised um data um again it we we have the input",
    "start": "315720",
    "end": "323000"
  },
  {
    "text": "input is given to the model the output it is compared with the trained data and",
    "start": "323000",
    "end": "328199"
  },
  {
    "text": "then it checks uh the output against the predicted output like what it should be if it's",
    "start": "328199",
    "end": "334360"
  },
  {
    "text": "too far from where the answer should be then it goes to the error and then it goes to the uh we have to like update",
    "start": "334360",
    "end": "341080"
  },
  {
    "text": "the model till we get very close uh to the Precision uh next up is deep learning uh",
    "start": "341080",
    "end": "348680"
  },
  {
    "start": "346000",
    "end": "438000"
  },
  {
    "text": "which is a subset of machine learning it uses neural networks with many layers for complex patterns uh think of it as",
    "start": "348680",
    "end": "355600"
  },
  {
    "text": "again as a human brain U which has many data points on it they are interconnected and making like and there",
    "start": "355600",
    "end": "362840"
  },
  {
    "text": "is there's a lot of layers of this as well that makes it handle the complex uh",
    "start": "362840",
    "end": "367880"
  },
  {
    "text": "predictions and works on it works on both labeled and unlabeled data so that's why it is like able to predict",
    "start": "367880",
    "end": "375919"
  },
  {
    "text": "more um you have this is this is where the Gen would fit in and generative AI",
    "start": "375919",
    "end": "382160"
  },
  {
    "text": "is more of creation of the content and uh you might have seen in all the stuff that you're doing for example you are",
    "start": "382160",
    "end": "388639"
  },
  {
    "text": "generating text you are generating an image from the prompt you are also uh generating videos uh like Sora is still",
    "start": "388639",
    "end": "395599"
  },
  {
    "text": "in beta but you you have seen the demos how it looks like and also Runway ml so",
    "start": "395599",
    "end": "400800"
  },
  {
    "text": "you have uh the the set where you have text image video graphics all these then",
    "start": "400800",
    "end": "407039"
  },
  {
    "text": "you have the models like you have llms uh for image you have diffusion for videos you have diffusion and then the",
    "start": "407039",
    "end": "413599"
  },
  {
    "text": "application so for the text llm and then you have chat GPD as the application",
    "start": "413599",
    "end": "418639"
  },
  {
    "text": "side of it so so you can be in all the domains you can be on at the foundational level where you are the",
    "start": "418639",
    "end": "423919"
  },
  {
    "text": "machine learning engineer doing all that stuff you can be at the model level or you can be at the application Level de",
    "start": "423919",
    "end": "429120"
  },
  {
    "text": "developing the applications uh so so this is a small context of where the",
    "start": "429120",
    "end": "436680"
  },
  {
    "text": "machine learning ecosystem is uh now coming to the AI inferencing so AI inferencing is the phase where a pre-",
    "start": "436680",
    "end": "444160"
  },
  {
    "start": "438000",
    "end": "490000"
  },
  {
    "text": "trained machine learning model applies its acquired knowledge to analyze and draw conclusion from the Fresh unseen",
    "start": "444160",
    "end": "451319"
  },
  {
    "text": "data so uh you can have different tooling for it uh for example you can have tensor flow py torch you can create",
    "start": "451319",
    "end": "457919"
  },
  {
    "text": "an inference and then it is it's basically you are trying to call the for example let let me give you an example",
    "start": "457919",
    "end": "464599"
  },
  {
    "text": "let's say you have created an inference for generating the image so you have a model which is there and you you want to",
    "start": "464599",
    "end": "471800"
  },
  {
    "text": "use that model so any input that comes it goes to that model and gives you the output from that particular pre-trained",
    "start": "471800",
    "end": "477479"
  },
  {
    "text": "model uh so for example speech recognition image detection autonomous",
    "start": "477479",
    "end": "482599"
  },
  {
    "text": "vles uh these I mean there are lot more use cases but some of the use cases over",
    "start": "482599",
    "end": "488159"
  },
  {
    "text": "here so this is the AI inferencing now coming to why we are here uh web",
    "start": "488159",
    "end": "493800"
  },
  {
    "start": "490000",
    "end": "662000"
  },
  {
    "text": "assembly and AI inferencing why it is a Hot Topic and U second state is doing a lot of things firon is doing a lot of",
    "start": "493800",
    "end": "500159"
  },
  {
    "text": "things in the inferencing space with web assembly um so yes the when we talk",
    "start": "500159",
    "end": "507199"
  },
  {
    "text": "about python it is very good like obviously it is only being used for",
    "start": "507199",
    "end": "512279"
  },
  {
    "text": "mainly being used for training and inferencing all the stuff uh for training it's fine but when it comes to",
    "start": "512279",
    "end": "518399"
  },
  {
    "text": "the inferencing there are certain things that it has some challenges and with the Technologies and tools that we have",
    "start": "518399",
    "end": "524560"
  },
  {
    "text": "today we can actually overcome these challenges and web assembly is one such technology uh so for example efficiency",
    "start": "524560",
    "end": "532399"
  },
  {
    "text": "is one so how do you get on demand gpus and you you only use that that you can",
    "start": "532399",
    "end": "538640"
  },
  {
    "text": "only use for the INF with web assembly it makes the resource usage efficient and you actually consume",
    "start": "538640",
    "end": "545360"
  },
  {
    "text": "since it's a smaller binary size and by now it's a second day uh after coffee break you should know what web assembly",
    "start": "545360",
    "end": "551560"
  },
  {
    "text": "is smaller runtime binary platform agnostic running anywhere I mean these should be your points you can even you",
    "start": "551560",
    "end": "558079"
  },
  {
    "text": "know speak in the dreams uh so it can U actually do the slicing of the GPU",
    "start": "558079",
    "end": "564680"
  },
  {
    "text": "attached to the in whatever time the inferencing is happening and then it is being the GPU is being offloaded to",
    "start": "564680",
    "end": "570440"
  },
  {
    "text": "another set of workloads that wants to do inferencing um then dependencies and platform uh platform dependent yes",
    "start": "570440",
    "end": "577680"
  },
  {
    "text": "python is a lot of uh python with a lot of dependencies cannot run on addition",
    "start": "577680",
    "end": "582800"
  },
  {
    "text": "all the platforms a single application if you have to make it run with the gpus you actually have to test the",
    "start": "582800",
    "end": "588880"
  },
  {
    "text": "application locally with the remote gpus but with web assembly it provides you",
    "start": "588880",
    "end": "593959"
  },
  {
    "text": "the development flexibility so U like gr will be showing the demo how you can actually create the exact same scenario",
    "start": "593959",
    "end": "601760"
  },
  {
    "text": "you can write the code on your machine without testing it with uh the remote gpus and you can run it locally and you",
    "start": "601760",
    "end": "609079"
  },
  {
    "text": "can run it against the GPU which is there without even testing it so it it",
    "start": "609079",
    "end": "614279"
  },
  {
    "text": "should work uh then the security we know web assembly is runs in a secure sandbox",
    "start": "614279",
    "end": "620279"
  },
  {
    "text": "so when you talk about the AI inferencing and you have your data that that you want to have you know private",
    "start": "620279",
    "end": "627320"
  },
  {
    "text": "data or it's not exposed or whatever that is so you can be sure that it is secure uh one of the another big points",
    "start": "627320",
    "end": "633240"
  },
  {
    "text": "is the image sizes so when you have py torch image sizes so you can like anywhere from last I saw was 4 point",
    "start": "633240",
    "end": "640839"
  },
  {
    "text": "some GB so I just put that number over there but yeah it's pretty big images which are there so you can imagine of",
    "start": "640839",
    "end": "646600"
  },
  {
    "text": "you know pulling that image and then running it um whereas uh simple your",
    "start": "646600",
    "end": "652200"
  },
  {
    "text": "application for web assembly will be a few megabytes in size um and also you",
    "start": "652200",
    "end": "657800"
  },
  {
    "text": "can be closer to the data because it is able to run on any platform uh there is a proposal in the",
    "start": "657800",
    "end": "665320"
  },
  {
    "start": "662000",
    "end": "729000"
  },
  {
    "text": "web assembly uh for the machine learning called vasi NN that aims to facilitate",
    "start": "665320",
    "end": "670880"
  },
  {
    "text": "the machine learning inference for within the web assembly ecosystem using the same tools same Frameworks so that",
    "start": "670880",
    "end": "676959"
  },
  {
    "text": "the integration is pretty light um it like for example the tensor flow onx open Vino for seamless integration also",
    "start": "676959",
    "end": "684160"
  },
  {
    "text": "aims to provide the hardware acceleration support um gpus tpus to over the traditional web assembly",
    "start": "684160",
    "end": "691480"
  },
  {
    "text": "performance um limitations we also saw one graph in one of the talks how vasm",
    "start": "691480",
    "end": "697560"
  },
  {
    "text": "with um s IMD is more performant than the web gpus things like that so so",
    "start": "697560",
    "end": "704279"
  },
  {
    "text": "those are uh some of the acceleration support which are there um now we'll",
    "start": "704279",
    "end": "709760"
  },
  {
    "text": "talk about spin 2.0 uh what what it is what are some of the new features of spin 2.0 and uh how we can actually",
    "start": "709760",
    "end": "717920"
  },
  {
    "text": "create applic thank",
    "start": "717920",
    "end": "724079"
  },
  {
    "text": "you uh so Sam mentioned spin is an open source tool framework for building web",
    "start": "728959",
    "end": "734160"
  },
  {
    "start": "729000",
    "end": "835000"
  },
  {
    "text": "assembly applications it's fully open source you go to hit github.com fir on spin you'll find it there with an",
    "start": "734160",
    "end": "739639"
  },
  {
    "text": "permissively open source uh license and the goal of spin is really to help you",
    "start": "739639",
    "end": "745199"
  },
  {
    "text": "create webs SMD applications it's primarily focused at building Avent driven function like services that run",
    "start": "745199",
    "end": "751279"
  },
  {
    "text": "on the server side and essentially you build functions as web assembly",
    "start": "751279",
    "end": "756839"
  },
  {
    "text": "components and then you pretty much run them anywhere you can run a web assembly component and if you've paid attention",
    "start": "756839",
    "end": "763120"
  },
  {
    "text": "in the last couple of days there's a lot of these places these days uh essentially spin has a bunch of language",
    "start": "763120",
    "end": "770040"
  },
  {
    "text": "sdks uh rust has obviously very good support for it because Rost and web assembly go very well together but we",
    "start": "770040",
    "end": "776160"
  },
  {
    "text": "also have really good support for JavaScript you can write applications in Python and c and a few other languages",
    "start": "776160",
    "end": "782839"
  },
  {
    "text": "you once you build your applic you write your application you can distribute it using regular Cloud native tools to",
    "start": "782839",
    "end": "789040"
  },
  {
    "text": "distribute application so if you use container registries you can continue to use those continue to sign your artifacts just like you use with any",
    "start": "789040",
    "end": "795079"
  },
  {
    "text": "other artifact and then you can deploy your application in a bunch of places uh you can run it on a good old Linux",
    "start": "795079",
    "end": "801560"
  },
  {
    "text": "system you can deploy to cloud services like firan cloud or you can use some of the new kubernetes integration that we",
    "start": "801560",
    "end": "807760"
  },
  {
    "text": "just launched uh and spin Cube and firan platform for kubernetes over the last couple of months we've been adding a",
    "start": "807760",
    "end": "814079"
  },
  {
    "text": "bunch of features to spin uh so spin by default comes built in with a way to do key value data you can do relational",
    "start": "814079",
    "end": "820920"
  },
  {
    "text": "data stores you can do configuration variables and secrets and one of the things that we're going to focus on",
    "start": "820920",
    "end": "826600"
  },
  {
    "text": "today a little bit is you can do inferencing and um embedding generating embeddings from directly from uh Spin",
    "start": "826600",
    "end": "834399"
  },
  {
    "text": "and web assembly and going back to what s was talking about for a second",
    "start": "834399",
    "end": "840440"
  },
  {
    "text": "the problem with AI inferencing today is most of services are using VMS or",
    "start": "840440",
    "end": "847000"
  },
  {
    "text": "containers to package the logic for generating inferencing and distributing that using container images that get",
    "start": "847000",
    "end": "854759"
  },
  {
    "text": "anywhere between 2 3 gigabytes to a lot more uh you can you can easily see",
    "start": "854759",
    "end": "859880"
  },
  {
    "text": "container images that try to do Cuda and pytorch get to 7 8 GB in size because",
    "start": "859880",
    "end": "865519"
  },
  {
    "text": "you're obviously packaging a whole Linux file system GPU drivers pytorch and and",
    "start": "865519",
    "end": "871959"
  },
  {
    "text": "your application code so those get very very large uh and so if we're talk about",
    "start": "871959",
    "end": "877759"
  },
  {
    "text": "trying to efficiently run those and scale to zero and start from scratch and uh you get into a problem that you may",
    "start": "877759",
    "end": "884480"
  },
  {
    "text": "be familiar with from the serverless world called cold starts uh which means if you're trying to run that application",
    "start": "884480",
    "end": "890000"
  },
  {
    "text": "Lear a new server fetching 10 gigabytes is going to take a while uh and then you'll have to find a GPU that you can",
    "start": "890000",
    "end": "896240"
  },
  {
    "text": "take over and actually run an inferencing and then maybe be idle for the next 30 minutes and then do the",
    "start": "896240",
    "end": "901560"
  },
  {
    "text": "whole cycle all over again so is there a way that we can try to address this problem using web assembly well what",
    "start": "901560",
    "end": "908399"
  },
  {
    "text": "we've learned from web assembly for the last couple of days here at bazo is it's really small uh it's portable and it",
    "start": "908399",
    "end": "914680"
  },
  {
    "text": "starts really really fast all of those are things that are sound like things",
    "start": "914680",
    "end": "920079"
  },
  {
    "text": "that we could uh could address some of our problems so what we've done with the",
    "start": "920079",
    "end": "925800"
  },
  {
    "text": "language model implementation into spin for inferencing is using web assembly and using component interfaces as the",
    "start": "925800",
    "end": "932240"
  },
  {
    "text": "contract between the guest application and host components uh we can assign essentially a fraction of a GPU for the",
    "start": "932240",
    "end": "939759"
  },
  {
    "text": "duration of a request going back for a second to spin spin primarily deals with web services you you build several lless",
    "start": "939759",
    "end": "946839"
  },
  {
    "text": "apis that get requests they do some work and then they go away and then they might get a request again in like 30",
    "start": "946839",
    "end": "953160"
  },
  {
    "text": "minutes or uh even longer so the idea there is to attach a fraction of a GPU",
    "start": "953160",
    "end": "960319"
  },
  {
    "text": "just in time to handle a request perform whatever work you're trying to do and then go away and that works really",
    "start": "960319",
    "end": "966040"
  },
  {
    "text": "really well for things like accessing a database or crunching some Json and returning it historically hasn't really",
    "start": "966040",
    "end": "973279"
  },
  {
    "text": "worked that well for trying to attach to a GPU or maybe wait for a GPU to become available attach to it initialize Cuda",
    "start": "973279",
    "end": "980360"
  },
  {
    "text": "initialize your pytorch and then do an inferencing request and then go away again so what usually happens is people",
    "start": "980360",
    "end": "986199"
  },
  {
    "text": "keep those gpus running all the time attached to a single application and essentially yeah that's while your",
    "start": "986199",
    "end": "992880"
  },
  {
    "text": "application is running and waiting for requests that that GP or that portion of a GPU is locked into that application so",
    "start": "992880",
    "end": "1000240"
  },
  {
    "text": "using web assembly what we can do is try to attach a fraction of a GPU to a request handled by a web assembly",
    "start": "1000240",
    "end": "1006560"
  },
  {
    "text": "component just in time as a request comes in execute your inferencing and then shut down your web assembly",
    "start": "1006560",
    "end": "1012360"
  },
  {
    "text": "component use the portion of a GPU for something else and so uh what that means",
    "start": "1012360",
    "end": "1018279"
  },
  {
    "text": "is when whenever a new request comes in uh uh a request or a user at the other end of the request doesn't have to wait",
    "start": "1018279",
    "end": "1025038"
  },
  {
    "text": "for a VM to start and then to attach a GPU and then to execute your request uh",
    "start": "1025039",
    "end": "1030280"
  },
  {
    "text": "and two it also means that you can achieve significantly higher density and efficiency utilization for your",
    "start": "1030280",
    "end": "1035798"
  },
  {
    "text": "infrastructure because you're no longer attaching you you no longer have a onetoone mapping between an application",
    "start": "1035799",
    "end": "1041880"
  },
  {
    "text": "and a GPU and you can swap between them very easily you can go from whatever",
    "start": "1041880",
    "end": "1047400"
  },
  {
    "text": "utilization you currently have on G USS to slightly higher because you you have a multi-tenant like en environment and",
    "start": "1047400",
    "end": "1053840"
  },
  {
    "start": "1053000",
    "end": "1091000"
  },
  {
    "text": "so to achieve that we have to solve two main problems the first one",
    "start": "1053840",
    "end": "1059200"
  },
  {
    "text": "is if you've still paid attention over the last couple of days you cannot really access a GPU from a web assembly",
    "start": "1059200",
    "end": "1065360"
  },
  {
    "text": "module today there are proposals in place Wy GPU is one of them web G web",
    "start": "1065360",
    "end": "1071039"
  },
  {
    "text": "GPU and other proposals to do that very easily on on the wasi side of things but you need a way for your guest",
    "start": "1071039",
    "end": "1077480"
  },
  {
    "text": "application the one that needs to to perform the inferencing and the host that has a GPU attached to it to",
    "start": "1077480",
    "end": "1082600"
  },
  {
    "text": "communicate to one another uh and then once you do have that communication how does your host actually execute the the",
    "start": "1082600",
    "end": "1088960"
  },
  {
    "text": "inference Inc and so spoiler alert its components and essentially what we did",
    "start": "1088960",
    "end": "1094000"
  },
  {
    "start": "1091000",
    "end": "1183000"
  },
  {
    "text": "for for spin too is we defined a web assembly interface this is a part of a width file that comes uh that comes with",
    "start": "1094000",
    "end": "1100400"
  },
  {
    "text": "spin we have two functions for this one is one that performs in inferencing uh takes in the model takes in a prompt",
    "start": "1100400",
    "end": "1107120"
  },
  {
    "text": "some parameters and returns your result and the other one is for generating sentence embeddings and doing Vector",
    "start": "1107120",
    "end": "1113039"
  },
  {
    "text": "searches and and things like that and so this is by default com coming by default with Spin and all the sdks and you can",
    "start": "1113039",
    "end": "1119640"
  },
  {
    "text": "access that from any language that you can write a spin application today and once you build that application you",
    "start": "1119640",
    "end": "1125159"
  },
  {
    "text": "compile it to WebMD component and once it's a WebMD component it will have an two Imports that basically map to these",
    "start": "1125159",
    "end": "1132440"
  },
  {
    "text": "two functions and so once you have that component you can run it anywhere you",
    "start": "1132440",
    "end": "1137520"
  },
  {
    "text": "satisfy those two Imports and so we can run it run the exactly the same component binary across CPU",
    "start": "1137520",
    "end": "1144280"
  },
  {
    "text": "architectures x86 arm you can run it across operating systems and you can even run it",
    "start": "1144280",
    "end": "1150000"
  },
  {
    "text": "across Hardware acceleration devices if you look at these two functions they're explicitly not defining what kind of",
    "start": "1150000",
    "end": "1157280"
  },
  {
    "text": "Hardware acceleration they need to use all they care about they're high level enough that you don't specify I need a",
    "start": "1157280",
    "end": "1162520"
  },
  {
    "text": "CA GPU or I need a TPU or I need some multi-threading it's left to the host implementation to Define how to best",
    "start": "1162520",
    "end": "1168799"
  },
  {
    "text": "achieve whatever result you're trying to get here without going into details which is why you get portable guests",
    "start": "1168799",
    "end": "1175120"
  },
  {
    "text": "which means the the component binder can run it everywhere but the host implementation has to be specifically targeting whatever device Hardware",
    "start": "1175120",
    "end": "1181520"
  },
  {
    "text": "acceleration device you may have available so once you build that app you can run it on your machine anywhere spin",
    "start": "1181520",
    "end": "1187679"
  },
  {
    "start": "1183000",
    "end": "1206000"
  },
  {
    "text": "runs which at this point is pretty much anywhere from arm machines to risk machines to Windows Linux Mac OS you can",
    "start": "1187679",
    "end": "1194360"
  },
  {
    "text": "deploy to to firan Cloud where we have a100 gpus backed by SEO and deep green",
    "start": "1194360",
    "end": "1200280"
  },
  {
    "text": "or you can deploy them to the spin Cube and for platform for kubernetes which was just announced this week so let's",
    "start": "1200280",
    "end": "1208280"
  },
  {
    "start": "1206000",
    "end": "1561000"
  },
  {
    "text": "have a look at what one of those uh applications can do and what they look like",
    "start": "1208280",
    "end": "1214400"
  },
  {
    "text": "so uh the all the entire uh source code for this you can find on g.com",
    "start": "1214400",
    "end": "1221120"
  },
  {
    "text": "feron and let's have a look at a spin application uh every spin application",
    "start": "1221120",
    "end": "1227440"
  },
  {
    "text": "comes with one configuration file that defines a little bit of metadata about the application and then a bunch of",
    "start": "1227440",
    "end": "1233200"
  },
  {
    "text": "components I mentioned that primarily uh we write web endpoints with spin but you",
    "start": "1233200",
    "end": "1238400"
  },
  {
    "text": "can do any kind of event driven programming with with spin we have incoming support for mqtt if you want to",
    "start": "1238400",
    "end": "1243880"
  },
  {
    "text": "do iot workloads support for Q based uh events and things like that uh there are",
    "start": "1243880",
    "end": "1249280"
  },
  {
    "text": "a couple of key components that you have to Define in your uh spin manifest file the one is what is the web assembly",
    "start": "1249280",
    "end": "1255159"
  },
  {
    "text": "component that I need to execute for this uh application and then everything in spin is following",
    "start": "1255159",
    "end": "1261480"
  },
  {
    "text": "the uh capability based model in from web assembly and from wasi and you have to Define ahead of time the things that",
    "start": "1261480",
    "end": "1267440"
  },
  {
    "text": "your component is allowed to do and in this case this component is not allowed to talk to any network host at all uh it",
    "start": "1267440",
    "end": "1275039"
  },
  {
    "text": "can use a key value store which comes built in in spin and then it can use the Lama 2 chat model uh and we'll see in a",
    "start": "1275039",
    "end": "1282320"
  },
  {
    "text": "second where that's coming from and then this is a typescript application I mentioned spin has an SDK",
    "start": "1282320",
    "end": "1289440"
  },
  {
    "text": "for for typescript which means you can write your application in JavaScript or typescript and then compile that",
    "start": "1289440",
    "end": "1295400"
  },
  {
    "text": "together with a small web assembly run time and generate a wasi preview2 component that can run anywhere we can",
    "start": "1295400",
    "end": "1301520"
  },
  {
    "text": "run wasi HTTP which at this point is wasm time serve and engine X unit and soon a lot more including uh you can run",
    "start": "1301520",
    "end": "1309320"
  },
  {
    "text": "it in spin and then all the places I mentioned so to in order what this sample does is it takes a prompt it",
    "start": "1309320",
    "end": "1316159"
  },
  {
    "text": "takes uh essentially a comment and then tries to decide whether it's positive or negative a sentiment analysis which is",
    "start": "1316159",
    "end": "1322960"
  },
  {
    "text": "not really the best kind of example to show with a language model and inferencing but we'll go with it for for a second uh you do if you're familiar",
    "start": "1322960",
    "end": "1330520"
  },
  {
    "text": "with llama 2 this is the the regular llama 2 prompt and you are basically",
    "start": "1330520",
    "end": "1336120"
  },
  {
    "text": "passing your user input and then we have the analyze function that will eventually just call the the infer",
    "start": "1336120",
    "end": "1343159"
  },
  {
    "text": "function that I uh that I mentioned earlier eventually there's an llm do infer uh called that happens",
    "start": "1343159",
    "end": "1350960"
  },
  {
    "text": "right here and that gets translated all the way to a web assmbly import when you",
    "start": "1350960",
    "end": "1356120"
  },
  {
    "text": "compile it to web assembly and that's what what it's going to uh to execute so",
    "start": "1356120",
    "end": "1361400"
  },
  {
    "text": "in order to build this you do a spin build which behind the scenes calls your tooling that generates a a web assembly",
    "start": "1361400",
    "end": "1367159"
  },
  {
    "text": "component in this call in this case it's typescript so it's npm run build which does some stuff behind the scenes the",
    "start": "1367159",
    "end": "1372919"
  },
  {
    "text": "generator component and then it generated the uh the web assembly component that I",
    "start": "1372919",
    "end": "1380640"
  },
  {
    "text": "mentioned in my source it's 2.4 megabytes and this web assembly component is able to do an inferencing",
    "start": "1380640",
    "end": "1386480"
  },
  {
    "text": "request that will be satisfied by my host so let's try and run it",
    "start": "1386480",
    "end": "1392120"
  },
  {
    "text": "locally and uh you can obviously have multiple components when building spin applications so let's try to do an",
    "start": "1393679",
    "end": "1401000"
  },
  {
    "text": "awesome conference and what is supposed to happen here is very quickly this is",
    "start": "1401000",
    "end": "1406960"
  },
  {
    "text": "supposed to tell me whether it's a positive neutral or negative sentiment",
    "start": "1406960",
    "end": "1412480"
  },
  {
    "text": "and it's taking a bit and uh it's taking a bit because it's running locally it's using in this",
    "start": "1412480",
    "end": "1419320"
  },
  {
    "text": "case it's using Metals Apple's metal framework but it's still a pretty big like 7 billion parameter machine",
    "start": "1419320",
    "end": "1425880"
  },
  {
    "text": "learning model so it's take a while um but you can see in the in the corner",
    "start": "1425880",
    "end": "1431480"
  },
  {
    "text": "does a little bit of work and then it's only that it's positive uh so we just ran this using my machine my processor",
    "start": "1431480",
    "end": "1438919"
  },
  {
    "text": "my M uh M chip um once you build it I mentioned",
    "start": "1438919",
    "end": "1445200"
  },
  {
    "text": "you can run it pretty much everywhere and I mentioned firman Cloud as one of the places you can deploy the application you don't have to deploy",
    "start": "1445200",
    "end": "1451760"
  },
  {
    "text": "your entire application you can just use uh you can just use",
    "start": "1451760",
    "end": "1460760"
  },
  {
    "text": "uh you can use the GPU from uh from Freeman Cloud which I mentioned is is backed by uh SEO Cloud uh there's an",
    "start": "1460760",
    "end": "1468480"
  },
  {
    "text": "token that's going to go away in a second but what what this does is it tells spin",
    "start": "1468480",
    "end": "1475520"
  },
  {
    "text": "that whenever it encounters the infer function instead of using the local GPU it's going to pipe all the data through",
    "start": "1475520",
    "end": "1482159"
  },
  {
    "text": "the internet all the way to uh a GPU to na1 100 running in the cloud and then",
    "start": "1482159",
    "end": "1487720"
  },
  {
    "text": "execute my uh my inferencing and then give me my response so if I pass that runtime",
    "start": "1487720",
    "end": "1493640"
  },
  {
    "text": "config file and start my application again I did not rebuild it's actually the same web assmbly compon component",
    "start": "1493640",
    "end": "1499480"
  },
  {
    "text": "this is it's going to be hopefully somewhat",
    "start": "1499480",
    "end": "1505760"
  },
  {
    "text": "faster and it was uh again shockingly uh using A1 100s to generate inferencing is",
    "start": "1505760",
    "end": "1512159"
  },
  {
    "text": "way way faster so tldr on all of this is once you build your web assembly",
    "start": "1512159",
    "end": "1518880"
  },
  {
    "text": "component you can decide whether you want to execute it on arm or x86 back",
    "start": "1518880",
    "end": "1524520"
  },
  {
    "text": "your inferencing with a Kura GPU or use CPU multi-threading or or some other",
    "start": "1524520",
    "end": "1530039"
  },
  {
    "text": "currently uninvented uh Hardware acceleration device and so what we're trying to do is",
    "start": "1530039",
    "end": "1536760"
  },
  {
    "text": "go from having to wait for an entire 10 gigabyte container to start pull it from",
    "start": "1536760",
    "end": "1541960"
  },
  {
    "text": "internet find a GPU to you have a 2.4 megabyte web assembly component that",
    "start": "1541960",
    "end": "1547000"
  },
  {
    "text": "tries to talk to a host that does already all of that for all the applications that you're going to deploy",
    "start": "1547000",
    "end": "1552480"
  },
  {
    "text": "and um we've seen two places where you can uh where you can run your your application back to I am to see how you",
    "start": "1552480",
    "end": "1559159"
  },
  {
    "text": "can deploy this on spin Cube yeah so the next thing that we'll be doing is deploy the application on",
    "start": "1559159",
    "end": "1565720"
  },
  {
    "start": "1561000",
    "end": "1741000"
  },
  {
    "text": "spin Cube um and we have a cluster already created Ru is telling me to use K but",
    "start": "1565720",
    "end": "1573240"
  },
  {
    "text": "it's me who is not using it so you can see uh I already have a cuberes uh cluster this is a c cuberes",
    "start": "1573240",
    "end": "1580080"
  },
  {
    "text": "Talos cluster which comes pre-built with your uh spin shim um and you we have",
    "start": "1580080",
    "end": "1587159"
  },
  {
    "text": "already installed the spin Cube so you can see the spin operator already here uh so",
    "start": "1587159",
    "end": "1595760"
  },
  {
    "text": "that we can run the spin app which is this so you can see there is a spin",
    "start": "1595760",
    "end": "1603600"
  },
  {
    "text": "app so since we have the operator installed on the cuberes that understand a cuberes object called spin app and in",
    "start": "1603600",
    "end": "1610039"
  },
  {
    "text": "this particular thing you can specify the spec which is the image sentiment analysis uh you can specify the executor",
    "start": "1610039",
    "end": "1616720"
  },
  {
    "text": "in this particular case we are going to to use uh container D sham spin uh and",
    "start": "1616720",
    "end": "1622720"
  },
  {
    "text": "then you can specify the runtime config now here you can specify a bunch of things uh for this particular case it's",
    "start": "1622720",
    "end": "1628399"
  },
  {
    "text": "the remote HTTP type and some of the options and as mentioned by Ru OD token",
    "start": "1628399",
    "end": "1633600"
  },
  {
    "text": "will go away uh so it's it's up to",
    "start": "1633600",
    "end": "1638640"
  },
  {
    "text": "him so we you can see uh we don't have any pods as of now and we'll just apply",
    "start": "1638640",
    "end": "1647159"
  },
  {
    "text": "this and we have the app spin app created so",
    "start": "1647159",
    "end": "1653840"
  },
  {
    "text": "qctl get spin app ports deployment",
    "start": "1653840",
    "end": "1662000"
  },
  {
    "text": "oh spin apps and there's app Cube",
    "start": "1664640",
    "end": "1671640"
  },
  {
    "text": "CTL get pods SVC and spin apps so it should give",
    "start": "1671640",
    "end": "1679279"
  },
  {
    "text": "everything which is there so you can see the ports which are there and the service which is created and um your app",
    "start": "1679279",
    "end": "1687360"
  },
  {
    "text": "yeah the spin app automatically translates it to the kubernetes components that are required to run for",
    "start": "1687360",
    "end": "1692799"
  },
  {
    "text": "the application you can also do Cube CTL reverse",
    "start": "1692799",
    "end": "1698360"
  },
  {
    "text": "proxy without cpg without Yep this and it should actually run Local",
    "start": "1698360",
    "end": "1706840"
  },
  {
    "text": "Host 9090 Local Host 9090 is it yep",
    "start": "1706840",
    "end": "1712159"
  },
  {
    "text": "9090 yep so that is running the same app on humanties using spin",
    "start": "1712159",
    "end": "1720399"
  },
  {
    "text": "Cube that's that's it that we had for this particular demo so we have shown",
    "start": "1720399",
    "end": "1726120"
  },
  {
    "text": "all the three demos life uh and",
    "start": "1726120",
    "end": "1731960"
  },
  {
    "text": "then resources if you want to learn more about spin spin Cube and seos carbon neutral gpus give it a try thank",
    "start": "1731960",
    "end": "1741919"
  },
  {
    "start": "1741000",
    "end": "1928000"
  },
  {
    "text": "you any questions hi CR talk um I have a",
    "start": "1747000",
    "end": "1755840"
  },
  {
    "text": "question so you were mentioning like Hardware devices that are not yet existing maybe so I've seen this fpgas",
    "start": "1755840",
    "end": "1763159"
  },
  {
    "text": "were mentioned on the slides um what would be the process in order to get those hook up and that the data is like",
    "start": "1763159",
    "end": "1770519"
  },
  {
    "text": "properly put to the device and goes back to the like spin app uh spin has an an",
    "start": "1770519",
    "end": "1777279"
  },
  {
    "text": "implementation which if you go to github.com for me on spin you can see how the current implementation works for",
    "start": "1777279",
    "end": "1783200"
  },
  {
    "text": "Apple's metal implementation Cuda and just CPU inferencing and essentially it's a matter of having an",
    "start": "1783200",
    "end": "1789000"
  },
  {
    "text": "implementation of an inferencing framework for the device you're targeting uh tpus is one that exists",
    "start": "1789000",
    "end": "1794720"
  },
  {
    "text": "today that someone can Implement if they wanted to so it's it's a matter of finding a an inferencing library that",
    "start": "1794720",
    "end": "1801000"
  },
  {
    "text": "works on the device you're targeting and it has the ability to execute your inferencing for this the requested model",
    "start": "1801000",
    "end": "1807120"
  },
  {
    "text": "that you want to implement it",
    "start": "1807120",
    "end": "1810279"
  },
  {
    "text": "for thank you thank you for the talk uh so in the uh component contract that you",
    "start": "1818799",
    "end": "1824600"
  },
  {
    "text": "showed I think I noticed that the it looked like it was designed designed for language models is that um is that what",
    "start": "1824600",
    "end": "1830519"
  },
  {
    "text": "it's designed for or is it general for any kind of model uh it was a high level enough interface for now that was",
    "start": "1830519",
    "end": "1836240"
  },
  {
    "text": "specifically designed for language models uh but back to what say was talking about dwann that is a lower",
    "start": "1836240",
    "end": "1842799"
  },
  {
    "text": "level implementation that you can use to Target vision any kind of model that that you",
    "start": "1842799",
    "end": "1848360"
  },
  {
    "text": "want and so good and following the previous question um so let's say you",
    "start": "1848360",
    "end": "1854279"
  },
  {
    "text": "have a cluster that has some Nvidia gpus and some AMD gpus whatever and you get a request for some model",
    "start": "1854279",
    "end": "1860880"
  },
  {
    "text": "that only has operations that are only uh implemented for NVIDIA let's say how do you find out how do you query that",
    "start": "1860880",
    "end": "1868200"
  },
  {
    "text": "okay where is that uh thing that decides this model can only run on this particular thing yeah uh quickly and",
    "start": "1868200",
    "end": "1875399"
  },
  {
    "text": "then if you want to uh essentially it there's a there's a matter of higher order or lower level",
    "start": "1875399",
    "end": "1883799"
  },
  {
    "text": "the decision that you have to make the goal of the SDK is to let a developer",
    "start": "1883799",
    "end": "1889080"
  },
  {
    "text": "get something done whereas application config higher level configuration that targets the infrastructure that's",
    "start": "1889080",
    "end": "1895000"
  },
  {
    "text": "something that you might want to do at the scheduling or orchestration level as opposed to at the application Level",
    "start": "1895000",
    "end": "1901679"
  },
  {
    "text": "right and so if you you've seen the kubernetes Manifest kubernetes is a worked orchestrator in the spin",
    "start": "1901679",
    "end": "1908120"
  },
  {
    "text": "application manifest you can you can specify the kind of note and the kind of infrastructure that your application",
    "start": "1908120",
    "end": "1913600"
  },
  {
    "text": "requires and that's something you can easily do with spin Cube thank",
    "start": "1913600",
    "end": "1919840"
  },
  {
    "text": "we done with okay",
    "start": "1921799",
    "end": "1925919"
  },
  {
    "text": "well",
    "start": "1927039",
    "end": "1930039"
  }
]
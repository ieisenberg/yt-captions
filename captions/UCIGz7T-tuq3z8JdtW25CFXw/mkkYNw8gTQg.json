[
  {
    "text": "[Music]",
    "start": "350",
    "end": "12639"
  },
  {
    "text": "hello everyone my name is yeah luke wagner i work at fastley i'm going to be talking about uh concurrency parallelism",
    "start": "12639",
    "end": "17840"
  },
  {
    "text": "and the component model but first i'd like to take a step back and review why are we excited about",
    "start": "17840",
    "end": "23760"
  },
  {
    "text": "web assembly in the first place well in the browser where web assembly",
    "start": "23760",
    "end": "28840"
  },
  {
    "text": "started initially you know there's there's no native code uh only javascript so you know what web assembly",
    "start": "28840",
    "end": "34880"
  },
  {
    "text": "added was the ability to run any of our programming languages and with a lot more uh performance a lot better",
    "start": "34880",
    "end": "40239"
  },
  {
    "text": "performance predictable performance than we had before outside the browser of course we",
    "start": "40239",
    "end": "45440"
  },
  {
    "text": "can run native code and we do that all the time so the reasons have to be different and so i think there's roughly five reasons first web assembly can be a",
    "start": "45440",
    "end": "52879"
  },
  {
    "text": "lot smaller so we can fit it in a lot smaller hardware like embedded devices and",
    "start": "52879",
    "end": "58520"
  },
  {
    "text": "microcontrollers but even if we have large hardware the smallness of wsm lets us pack a lot more wom in and get higher",
    "start": "58520",
    "end": "64000"
  },
  {
    "text": "density which can lead to cost savings which is our second reason third reason is cold start wom can start a whole lot",
    "start": "64000",
    "end": "70880"
  },
  {
    "text": "faster uh than other units of compute for example in fastly we uh can start a",
    "start": "70880",
    "end": "76000"
  },
  {
    "text": "fresh wasm sandbox in under 35 microsconds which is orders of magnitude faster than alternatives and it's so low",
    "start": "76000",
    "end": "82080"
  },
  {
    "text": "that we can start every hp request in a fresh sandbox which is like a really great default security posture and this",
    "start": "82080",
    "end": "88479"
  },
  {
    "text": "can also lead to cost savings not just for the obvious reason of we're like spending less time cold starting but",
    "start": "88479",
    "end": "94079"
  },
  {
    "text": "when you're not as scared about cold start you can scale aggressively to zero and like spend less money starting uh",
    "start": "94079",
    "end": "99759"
  },
  {
    "text": "keeping warm instances on standby web assembly is also very portable",
    "start": "99759",
    "end": "105200"
  },
  {
    "text": "running over a variety of cpus and this can be especially valuable if you want to run a single module across a wide",
    "start": "105200",
    "end": "110320"
  },
  {
    "text": "variety of devices that can have different cpus including browsers and this can also lead to cost",
    "start": "110320",
    "end": "116880"
  },
  {
    "text": "savings because web assembly can make it easy to shift a workload uh to run on lower power lower cost devices",
    "start": "116880",
    "end": "124240"
  },
  {
    "text": "and lastly if i have some guest code that i want to run as a plug-in in my platform or my system i can start with a",
    "start": "124240",
    "end": "131200"
  },
  {
    "text": "container but then i probably need to wrap it in a microvm uh because i have to protect my platform for any bad stuff",
    "start": "131200",
    "end": "136640"
  },
  {
    "text": "that might be happening inside the container and i probably ask to do some sort of filtering to make sure that my guest code can only access the public",
    "start": "136640",
    "end": "143200"
  },
  {
    "text": "apis that i want it to have access to and not like the private apis that are part of how my system works so instead i",
    "start": "143200",
    "end": "149440"
  },
  {
    "text": "can put the guest code in wom and then the sandboxing just happens as a natural part of the wom engine running the wom",
    "start": "149440",
    "end": "155040"
  },
  {
    "text": "guest code and i can take advantage of the deny by default sandbox of web assembly to only explicitly grant access",
    "start": "155040",
    "end": "160640"
  },
  {
    "text": "to the public apis that i wanted to have access to and just know by construction that it can't access the private apis",
    "start": "160640",
    "end": "166319"
  },
  {
    "text": "which can make it a lot simpler to think about my plug-in situation and this can also lead to cost savings because the",
    "start": "166319",
    "end": "171599"
  },
  {
    "text": "microvm and filtering approach has like you know significant cost overhead so overall five reasons to be excited about",
    "start": "171599",
    "end": "178400"
  },
  {
    "text": "web assembly with cost savings being kind of like a common theme here so that's web assembly what about the",
    "start": "178400",
    "end": "184560"
  },
  {
    "text": "component model and just as background a component is a new binary format being standardized at the w3c that contains",
    "start": "184560",
    "end": "191920"
  },
  {
    "text": "and links together a set of wsa modules and and defines how they interact with the outside world so i think there are",
    "start": "191920",
    "end": "199200"
  },
  {
    "text": "roughly six things the component model gives us that are like worth being excited about for starters in a browser",
    "start": "199200",
    "end": "205040"
  },
  {
    "text": "if i'm a javascript developer and i want to use a wom module that somebody built well today to do that first i need",
    "start": "205040",
    "end": "211280"
  },
  {
    "text": "someone who's kind of advanced in the wizardly arts of the web assembly.js api to wrap it up for me with js glue code",
    "start": "211280",
    "end": "216319"
  },
  {
    "text": "because wom is pretty raw and hard to use directly it feels like making like raw sis calls and furthermore this javascript",
    "start": "216319",
    "end": "222720"
  },
  {
    "text": "sits in between the wom code and the browser's web api so it adds runtime overhead so instead with a component i",
    "start": "222720",
    "end": "229360"
  },
  {
    "text": "can instead uh automatically and mechanically generate that js glue code without having to get a human involved",
    "start": "229360",
    "end": "235440"
  },
  {
    "text": "and also if the browser natively implements components it will be able to make direct native typed calls from the",
    "start": "235440",
    "end": "240640"
  },
  {
    "text": "wom code directly into the web api so it runs faster and so we can say the component model gives us glue code for",
    "start": "240640",
    "end": "247959"
  },
  {
    "text": "free outside the browser if i'm a platform developer embedding wom as a plugin like for example we do at",
    "start": "247959",
    "end": "254280"
  },
  {
    "text": "fastley well when i get started i do some work to bind my initial set of apis to my initial language sdk but then what",
    "start": "254280",
    "end": "261440"
  },
  {
    "text": "i find is as i add more languages and more apis the amount of work to do all this binding grows quadratically and it",
    "start": "261440",
    "end": "267680"
  },
  {
    "text": "it can become prohibitive and you know discourage me from even wanting to add new languages and this is not a new",
    "start": "267680",
    "end": "273360"
  },
  {
    "text": "problem or unique to web assembly and the standard solution across the industry is define your apis in some",
    "start": "273360",
    "end": "278960"
  },
  {
    "text": "sort of language neutral idl and then generate the bindings and so indeed that's what we're doing with the component model and our idl is called",
    "start": "278960",
    "end": "285520"
  },
  {
    "text": "wit and i'll be showing some wit later now these generated bindings might not be as perfectly idiomatic as what i",
    "start": "285520",
    "end": "291919"
  },
  {
    "text": "might have handwritten but now i can do a very small amount of work to add some polish and wrapping on top to make them",
    "start": "291919",
    "end": "297199"
  },
  {
    "text": "as idiomatic as i wanted to and integrate them in standard libraries but it's much easier to do this because i'm building on highle safe bindings instead",
    "start": "297199",
    "end": "303520"
  },
  {
    "text": "of like low-level sys calls and if somebody shows up with a language that i haven't done any polish work for they",
    "start": "303520",
    "end": "308639"
  },
  {
    "text": "can still be off and running using the highle safe automatic bindings and so we say that the component model gives us",
    "start": "308639",
    "end": "314479"
  },
  {
    "text": "sdks for free additionally once i can run wom on top of my platform before too long it",
    "start": "314479",
    "end": "321199"
  },
  {
    "text": "starts to seem like a cool idea to use wom to how i implement the platform and the reasoning here is like well if the",
    "start": "321199",
    "end": "328000"
  },
  {
    "text": "logic i put inside that wom it has a limited i'm limiting the blast radius so any bugs like you know are confined to",
    "start": "328000",
    "end": "333840"
  },
  {
    "text": "just that wama model and this can improve the stability of my platform and this can also let me achieve higher",
    "start": "333840",
    "end": "339199"
  },
  {
    "text": "product velocity because i can push out these new wam modules a lot faster sometimes and i can update the underlying platform",
    "start": "339199",
    "end": "344840"
  },
  {
    "text": "image and so as soon as i want to do this seems like a good idea i'm going to have to confront the following design",
    "start": "344840",
    "end": "349919"
  },
  {
    "text": "question which is this private module i probably want to have access to private apis like billing or things that are",
    "start": "349919",
    "end": "355440"
  },
  {
    "text": "unstable or perhaps dangerous and so i need to make very sure that my guest code cannot access those private apis",
    "start": "355440",
    "end": "362320"
  },
  {
    "text": "and since this is all wom code running in the same wm engine you know this is not a foregone conclusion i need something that like you know makes very",
    "start": "362320",
    "end": "368240"
  },
  {
    "text": "emphatically sure that this cannot happen and so a solution that we found is i can take those wom modules wrap",
    "start": "368240",
    "end": "375440"
  },
  {
    "text": "them up into components link them together and as part of that declaratively only give p access to the",
    "start": "375440",
    "end": "380639"
  },
  {
    "text": "private apis to my private module and now just by running that component in a wom engine as normal the normal",
    "start": "380639",
    "end": "386479"
  },
  {
    "text": "sandboxing performed by the engine makes very sure that the guest code cannot access the private apis and so we call",
    "start": "386479",
    "end": "393840"
  },
  {
    "text": "this uh pattern virtual platform layering and this is something the component model supports directly and in",
    "start": "393840",
    "end": "399759"
  },
  {
    "text": "fact this is a real design question we added fastly and this is a real solution we're working on putting in production",
    "start": "399759",
    "end": "404960"
  },
  {
    "text": "so if you're in interested to hear more about this definitely see my colleagues dan goen and benjamin young's talk you",
    "start": "404960",
    "end": "410240"
  },
  {
    "text": "know first thing tomorrow morning and hear a lot more about it now shifting persona somewhat if i'm",
    "start": "410240",
    "end": "415520"
  },
  {
    "text": "a software architect for let's say a large enterprise application i might start with a modular monolith where i",
    "start": "415520",
    "end": "421440"
  },
  {
    "text": "break my code into different modules with you know nicely defined modular interfaces between them but then if they",
    "start": "421440",
    "end": "427520"
  },
  {
    "text": "have shared global states like global variables or class variables what can happen over time is unofficial",
    "start": "427520",
    "end": "433199"
  },
  {
    "text": "interfaces develop that circumvent the official ones and over time my my my architecture can turn to a big ball of",
    "start": "433199",
    "end": "439120"
  },
  {
    "text": "mud um furthermore if bad code gets into those modules via supply chain attack or",
    "start": "439120",
    "end": "444400"
  },
  {
    "text": "otherwise through that global state it can often impact the whole application so for this reason and others architects",
    "start": "444400",
    "end": "450880"
  },
  {
    "text": "can choose to use a microser architecture instead where the modules go into separate microservices and they",
    "start": "450880",
    "end": "456160"
  },
  {
    "text": "talk to each other only through htp and without using shared memory and this can be a much stronger degree of isolation",
    "start": "456160",
    "end": "461919"
  },
  {
    "text": "but it does come with you know non-trivial complexity and performance overhead so with the component model we",
    "start": "461919",
    "end": "468639"
  },
  {
    "text": "have a new option which is i'll call the strongly modular monolith where i put my different modules into different components and because they can't share",
    "start": "468639",
    "end": "475599"
  },
  {
    "text": "memory we have the same strong degree of isolation between all these modules as we had with the microser architecture",
    "start": "475599",
    "end": "481520"
  },
  {
    "text": "but because it's a module monolith and they're running in the same process they can call each other even on the same thread and have a lot higher performance",
    "start": "481520",
    "end": "487680"
  },
  {
    "text": "calls between them than you know going through an hp and a whole network stack and furthermore we can deploy it just as",
    "start": "487680",
    "end": "493440"
  },
  {
    "text": "a monolith which you know can be a lot simpler operationally and there's no reason i have to do all or nothing i can you know",
    "start": "493440",
    "end": "499840"
  },
  {
    "text": "combine the best of both worlds you know the component is just really just a primitive i can choose my own adventure and say i want to have two components in",
    "start": "499840",
    "end": "506319"
  },
  {
    "text": "one microser so they can talk back and forth efficiently oh and this component c i want to be able to scale it independently so i'll put that in a",
    "start": "506319",
    "end": "512080"
  },
  {
    "text": "separate micro service and so we call this uh use case or what the component gives us is uh modularity without",
    "start": "512080",
    "end": "518479"
  },
  {
    "text": "microservices and then lastly if i'm a developer producing wmo and i want to run it inside and outside of a browser you know",
    "start": "518479",
    "end": "525519"
  },
  {
    "text": "today i have kind of a conundrum because most tool chains only target just one of these things and the component model now",
    "start": "525519",
    "end": "530959"
  },
  {
    "text": "gives me a nice option where i can just emit a component run it in the browser getting glue code for free or directly in wm",
    "start": "530959",
    "end": "536920"
  },
  {
    "text": "engine so we can say the component model gives us browser agnostic binaries and then furthermore when i'm building this",
    "start": "536920",
    "end": "543120"
  },
  {
    "text": "component i can reuse other components that have already been built and deployed let's say to oci registries and these components can have been developed",
    "start": "543120",
    "end": "549360"
  },
  {
    "text": "in different languages and they're sandboxed even when i link them and so we say component lastly gives us secure",
    "start": "549360",
    "end": "555760"
  },
  {
    "text": "polyglot packages thus all together we've got six different things that captool gives us that i think are worth",
    "start": "555760",
    "end": "561839"
  },
  {
    "text": "being excited about so that's uh so to talk about like kind of what's coming next i want to",
    "start": "561839",
    "end": "567839"
  },
  {
    "text": "show a little bit of wits so in this example i'm defining an http interface",
    "start": "567839",
    "end": "572880"
  },
  {
    "text": "that contains a request resource and a headers method that returns a list of pairs of strings and so as we can see in",
    "start": "572880",
    "end": "580320"
  },
  {
    "text": "this example it gives us both value types and resource types values are things like numbers lists records",
    "start": "580320",
    "end": "586080"
  },
  {
    "text": "variants etc that are passed by value and that means they're copied into an out of linear memory or with wmgc passed",
    "start": "586080",
    "end": "592800"
  },
  {
    "text": "by mutable gc reference resource types on the other hand are not copied they're passed by handle resource types are",
    "start": "592800",
    "end": "599760"
  },
  {
    "text": "abstract and they but they do have explicit lifetimes so we can know when they're destroyed so we can free memory and other resources that are you know",
    "start": "599760",
    "end": "605360"
  },
  {
    "text": "used to implement them and our handles say whether they're owned or borrowed so we know during a call contract who's responsible for what so this stuff's all",
    "start": "605360",
    "end": "613040"
  },
  {
    "text": "in wit now and has been since the release of 02 last year so what's coming very soon in 03 is the addition of",
    "start": "613040",
    "end": "619519"
  },
  {
    "text": "concurrency types namely futures and streams and what these allow us to do is asynchronously pass values or handles",
    "start": "619519",
    "end": "626240"
  },
  {
    "text": "across interfaces so for example i could add a body method that returns a pair of",
    "start": "626240",
    "end": "631519"
  },
  {
    "text": "a stream of bytes which is the contents of the request and then a future that resolves to an optional trailers",
    "start": "631519",
    "end": "637040"
  },
  {
    "text": "resource you know at the end of the request and so that's a good start but we need more we need to also say how do",
    "start": "637040",
    "end": "643120"
  },
  {
    "text": "we do concurrent execution at all like in in our functions and so this is a big kind of crosscutting hard problem so",
    "start": "643120",
    "end": "648640"
  },
  {
    "text": "we've broken it into two steps step one is async and step two is threads and so i'm going to talk about these in turn",
    "start": "648640",
    "end": "655680"
  },
  {
    "text": "so with step one and async what i can say in wits is that a function is asynchronous so in this handler",
    "start": "655680",
    "end": "661839"
  },
  {
    "text": "interface i can say handle is an async function that takes a request and asynchronously returns a response and",
    "start": "661839",
    "end": "668240"
  },
  {
    "text": "then from this you know wits i can generate bindings in in my various languages now a lot of languages",
    "start": "668240",
    "end": "673519"
  },
  {
    "text": "literally have an async so the async turns in async go does not have a color on its function so the handle function",
    "start": "673519",
    "end": "679200"
  },
  {
    "text": "would just turn into a regular go function but if i spawn it in a go routine it'll run concurrently and so the async keyword in whit is sort of",
    "start": "679200",
    "end": "685519"
  },
  {
    "text": "like a hint to the go programmer if you didn't want to block you maybe want to spawn this in a go routine and as part of this we've tried",
    "start": "685519",
    "end": "692399"
  },
  {
    "text": "to ensure we have three highle properties with our concurrency the first is that our currency is structured",
    "start": "692399",
    "end": "698320"
  },
  {
    "text": "which means there's a at the component model level there's a well- definfined cross component call stack and this is",
    "start": "698320",
    "end": "703440"
  },
  {
    "text": "especially useful if you're for any sort of debugging profiling and tracing purposes",
    "start": "703440",
    "end": "708720"
  },
  {
    "text": "second our concurrency is cooperative which means we only switch execution at explicit yield points and in particular",
    "start": "708720",
    "end": "714880"
  },
  {
    "text": "we're not forcing you to do multi-threading if you didn't actually want to do multi-threading and lastly a concurrency",
    "start": "714880",
    "end": "720240"
  },
  {
    "text": "is colorless which is to say synchronous functions can call async functions and vice versa and this helps to avoid the",
    "start": "720240",
    "end": "725760"
  },
  {
    "text": "problems described in this by now famous blog post what color is your function and i don't have time to go into all the",
    "start": "725760",
    "end": "731440"
  },
  {
    "text": "technical details of how we achieve this but i did actually give a talk if you want to find out more right here at wmcon last or wm.io last year called a",
    "start": "731440",
    "end": "738399"
  },
  {
    "text": "stream of consciousness on the future of async in the component model that kind of gives a technical sketch and the good",
    "start": "738399",
    "end": "743839"
  },
  {
    "text": "news is that we've been working on this since then a bunch of folks have done a an incredible job implementing this and",
    "start": "743839",
    "end": "748959"
  },
  {
    "text": "it works and we're working to get this code reviewed and merged into wmt time and jo and so this will hopefully uh",
    "start": "748959",
    "end": "755040"
  },
  {
    "text": "very likely be part of a wy 03 release in the first half of this year and then",
    "start": "755040",
    "end": "760079"
  },
  {
    "text": "also good news is that it's backwards compatible with 02 so it's just an extension and this will make it a fairly",
    "start": "760079",
    "end": "765360"
  },
  {
    "text": "smooth roll out when it's ready so that's a lot of the work that has been going on to support async now i'm going",
    "start": "765360",
    "end": "770959"
  },
  {
    "text": "to talk about you know what's coming next with threads so why do we want threads well you know the big reason is",
    "start": "770959",
    "end": "778040"
  },
  {
    "text": "parallelism which is that ideally as i add more cores i would love my workload to run faster now there's a huge caveat",
    "start": "778040",
    "end": "784560"
  },
  {
    "text": "here can be very hard to achieve in practice due to contention and other bottlenecks but you know if i'm careful",
    "start": "784560",
    "end": "789680"
  },
  {
    "text": "you know threads can allow me to get this sort of parallelism and threads are not the only way to achieve parallelism they're a",
    "start": "789680",
    "end": "795600"
  },
  {
    "text": "pretty low-level mechanism but what we find is you can often use them to implement higher level safer kinds of parallelism like pipelines and map query",
    "start": "795600",
    "end": "802560"
  },
  {
    "text": "map produce and query languages and so they're a good low-level primitive which makes them a good you know fit for wm",
    "start": "802560",
    "end": "807680"
  },
  {
    "text": "which provides primitives for languages and runtimes to do their thing so parallelism is one big reason the other",
    "start": "807680",
    "end": "813120"
  },
  {
    "text": "is concurrency which is to say you know various languages literally expose threads or something quite like threads like workers or co- routines and even if",
    "start": "813120",
    "end": "820160"
  },
  {
    "text": "i don't care about the parallelism code is written using these features as the way to structure their code and so we",
    "start": "820160",
    "end": "826560"
  },
  {
    "text": "want to be able to run the code even if on one core and have it just work and you know of course this is possible",
    "start": "826560",
    "end": "831680"
  },
  {
    "text": "today um using a really amazing tool by in as part of binarian called asyncify and this is if i understand right what",
    "start": "831680",
    "end": "837839"
  },
  {
    "text": "uh tiny go uses for go routines and asyncy does the best it can with",
    "start": "837839",
    "end": "843199"
  },
  {
    "text": "features that are already in wom but unfortunately does have pretty significant uh code size and runtime overhead so ideally we'd be able to you",
    "start": "843199",
    "end": "850480"
  },
  {
    "text": "know have the code just work uh without the overhead of asyncify and so that's why we own threads uh let's talk about",
    "start": "850480",
    "end": "857040"
  },
  {
    "text": "uh what the plan is but you know big disclaimer you know the following plans are still in flux and may change or be fatally flawed uh but with that caveat",
    "start": "857040",
    "end": "864800"
  },
  {
    "text": "uh as background you know there is actually a threads proposal in corwin that has been shipping in browsers for years now and what is in this you know",
    "start": "864800",
    "end": "872480"
  },
  {
    "text": "corew threads proposal is a bunch of useful primitives uh first a collection of atomic instructions for atomic loads",
    "start": "872480",
    "end": "879360"
  },
  {
    "text": "stores compare and exchange and other things like that and the ability to mark a memory as being shared and when a",
    "start": "879360",
    "end": "884800"
  },
  {
    "text": "memory is shared that means it can be accessed by multiple threads at the same time and thus it also comes with a memory model that says when we're doing",
    "start": "884800",
    "end": "890880"
  },
  {
    "text": "a bunch of atomic and non-atomic loads and stores all in the same memory at the same time like what can we rely on what",
    "start": "890880",
    "end": "896399"
  },
  {
    "text": "are the allowed interleings and so that's great but it still leaves a number of problems to be solved so one",
    "start": "896399",
    "end": "903360"
  },
  {
    "text": "big one is let's say i have an application with a shared memory and now i have two functions and",
    "start": "903360",
    "end": "909040"
  },
  {
    "text": "i would like to call them indirectly so i put them in a table as required by call indirects well because the",
    "start": "909040",
    "end": "915279"
  },
  {
    "text": "functions are shared and the table's not shared this table is coupled to one thread which means if i want a second",
    "start": "915279",
    "end": "920480"
  },
  {
    "text": "thread i need a second table with a copy of all the function references in that second table and so you can see this is",
    "start": "920480",
    "end": "926000"
  },
  {
    "text": "going to lead to a quadratic amount of memory usage of number of threads times number of alias functions and so this",
    "start": "926000",
    "end": "931040"
  },
  {
    "text": "can become seriously prohibitive if i have like a large number of you know functions and threads and so that's",
    "start": "931040",
    "end": "936560"
  },
  {
    "text": "silly uh and second of all if i'm going to uh load any new code at runtime if i want to mutate one of these tables if",
    "start": "936560",
    "end": "942720"
  },
  {
    "text": "i'm like implementing dl open this is going to be a problem because i'm going to have to somehow mutate all of these tables and coordinate with all the threads so that that's a pain so to",
    "start": "942720",
    "end": "949759"
  },
  {
    "text": "address this and other problems there is now in corem a shared everything threads proposal and true to its name the idea",
    "start": "949759",
    "end": "957040"
  },
  {
    "text": "is it allows us to put shared on everything including importantly the function and table definitions so in my",
    "start": "957040",
    "end": "963199"
  },
  {
    "text": "application in addition to the memory being shared i can say the functions are shared and then put them in a shared table of references to shared functions",
    "start": "963199",
    "end": "970000"
  },
  {
    "text": "and now it can be shared between all the threads so i'm back to the expected linear memory usage for tables and i'm",
    "start": "970000",
    "end": "976880"
  },
  {
    "text": "making dl open happy so it can do the same thing it would do on native so that's a great start that really",
    "start": "976880",
    "end": "982639"
  },
  {
    "text": "improves the situation but there's still one more thing that we need ideally we'd be able to just spawn a thread as a core",
    "start": "982639",
    "end": "988240"
  },
  {
    "text": "wom instruction and the uh wm cg agrees this is this is a a good eventual goal",
    "start": "988240",
    "end": "994160"
  },
  {
    "text": "state but for practical incremental purposes it's it's kind of annoying for browsers to add a thread.spawn instruction uh browsers already have web",
    "start": "994160",
    "end": "1002160"
  },
  {
    "text": "workers as a way to spawn threads and it's already possible to call it to javascript and then you know have that spawn a worker or use a thread a pool of",
    "start": "1002160",
    "end": "1008240"
  },
  {
    "text": "web workers and so browsers would like to for now incrementally not support a thread's instruction uh and punt on that",
    "start": "1008240",
    "end": "1015199"
  },
  {
    "text": "one um so instead the official plan of record is to add thread spawning as a component model built-in and a built-in",
    "start": "1015199",
    "end": "1021839"
  },
  {
    "text": "is just a function that can be imported by corewm that's defined by the component model spec so concretely",
    "start": "1021839",
    "end": "1027918"
  },
  {
    "text": "corewazm could have this import where imports a thread.spawn indirect and the type of this function is that it's",
    "start": "1027919",
    "end": "1034000"
  },
  {
    "text": "shared which means i can spawn a thread from any thread the first parameter is the function pointer which is an index",
    "start": "1034000",
    "end": "1039360"
  },
  {
    "text": "in that shared table of shared function refs and the second parameter is like the closure parameter that's passed to the function pointer when it's run on",
    "start": "1039360",
    "end": "1045678"
  },
  {
    "text": "the other thread and the return value is a boolean i32 indicating whether it succeeded or failed",
    "start": "1045679",
    "end": "1052640"
  },
  {
    "text": "and so if i have a core module that imports this function inside of a browser i can implement that import",
    "start": "1052640",
    "end": "1058080"
  },
  {
    "text": "using a javascript function that dispatches the call to one of the workers in a pool like it does today but",
    "start": "1058080",
    "end": "1064400"
  },
  {
    "text": "then outside of a browser the wm run can can implement this natively which is kind of what we",
    "start": "1064400",
    "end": "1069640"
  },
  {
    "text": "want so in a summary it's mostly you know shared everything threads with thread creation as a component model",
    "start": "1069640",
    "end": "1076520"
  },
  {
    "text": "builtin so is that it you know we make it so and come back when you're done well you know not so fast we we have to",
    "start": "1076520",
    "end": "1083360"
  },
  {
    "text": "ask a few more questions about uh particularly those highle properties of",
    "start": "1083360",
    "end": "1088400"
  },
  {
    "text": "structured cooperative and colorless concurrency that we got from async so what happens when we add threads to the",
    "start": "1088400",
    "end": "1093679"
  },
  {
    "text": "mix do they stay the same do we have to nuance them do we lose them so i'm going to talk through all three of",
    "start": "1093679",
    "end": "1099240"
  },
  {
    "text": "these so first structure concurrency in the with async let's say",
    "start": "1099240",
    "end": "1104960"
  },
  {
    "text": "i've got two components the first one exports a function g that's imported by the second component that exports a function f and then at runtime i call",
    "start": "1104960",
    "end": "1112080"
  },
  {
    "text": "into f well as part of that you know i'm going to push any number of wm frames on the call stack and then what we say with",
    "start": "1112080",
    "end": "1117679"
  },
  {
    "text": "async is that all those calls execute in the context of what we call a task and the task is you know created every time",
    "start": "1117679",
    "end": "1123360"
  },
  {
    "text": "i call an export into a component and it manages very speced state that tracks",
    "start": "1123360",
    "end": "1128480"
  },
  {
    "text": "the call contract like do i have any borrowed handles that i have not yet dropped uh have i returned my value to",
    "start": "1128480",
    "end": "1133679"
  },
  {
    "text": "my asynchronous caller do i have a super task so let's say now corewazm makes a",
    "start": "1133679",
    "end": "1139280"
  },
  {
    "text": "call to g so that'll spawn a new task for g and then corewazm will run as part",
    "start": "1139280",
    "end": "1144400"
  },
  {
    "text": "of that g components and now let's say uh it blocks and suspends control flow",
    "start": "1144400",
    "end": "1149840"
  },
  {
    "text": "back to f before doing that we make sure that g1 remembers that its super task is",
    "start": "1149840",
    "end": "1155360"
  },
  {
    "text": "f or conversely that g1 is a subtask of f so we've now started an async called tree even though corew is not running in",
    "start": "1155360",
    "end": "1162320"
  },
  {
    "text": "g we still remember it's a subtask so now that f is running again it can call g again it can make a new subtask that",
    "start": "1162320",
    "end": "1169760"
  },
  {
    "text": "runs and suspends back so now our call tree has grown and now f can you know suspend and",
    "start": "1169760",
    "end": "1176000"
  },
  {
    "text": "we can do normal asynchronous execution bouncing between g1 and to g2 and now let's say we hit a bug and so we trap at",
    "start": "1176000",
    "end": "1182240"
  },
  {
    "text": "this point we want to debug it so we would say what's our call stack here which gives us the context to debug this problem so the obvious part is we would",
    "start": "1182240",
    "end": "1189760"
  },
  {
    "text": "say well there's three core wo frames on the call stack so we'll start by including those in the call stack and",
    "start": "1189760",
    "end": "1194960"
  },
  {
    "text": "that's all that's on like the native stack so is that do we stop there well no we can follow this super task link",
    "start": "1194960",
    "end": "1200320"
  },
  {
    "text": "and say ah this is a subtask of f so let's go into f now nothing's running at f at the moment but if the woam engine",
    "start": "1200320",
    "end": "1207440"
  },
  {
    "text": "wants to help me to debug this it can save a snapshot of the symbolic call stack when g2 was created which is what",
    "start": "1207440",
    "end": "1213840"
  },
  {
    "text": "like async runtimes do internally to give us nice async call stacks and so we can say is what we're allowing here is",
    "start": "1213840",
    "end": "1219840"
  },
  {
    "text": "to extend that technique to work cross language cross components so we have cross language async call stacks so that",
    "start": "1219840",
    "end": "1226799"
  },
  {
    "text": "is what you know we're specifying today with async and implementing today with async what happens when we add threads",
    "start": "1226799",
    "end": "1232559"
  },
  {
    "text": "into the mix so a call comes into f and that calls a thread.spawn so we spawn a new thread",
    "start": "1232559",
    "end": "1239600"
  },
  {
    "text": "with its own call stack and so the idea is to say let us define threads to be contained by the async task that created",
    "start": "1239600",
    "end": "1246559"
  },
  {
    "text": "them so now that i have a separate thread it can run in parallel we can make call imports in parallel that can",
    "start": "1246559",
    "end": "1252400"
  },
  {
    "text": "make task subtasks in parallel they can run in parallel and now let's say we had a trap in g2 again so what's our call",
    "start": "1252400",
    "end": "1258799"
  },
  {
    "text": "stack well we can basically use the same technique and say uh you know we're going to include all the frames in g2",
    "start": "1258799",
    "end": "1264320"
  },
  {
    "text": "and then we're going to follow the subtask lingot into f and we're going to look at the call stack that created g2",
    "start": "1264320",
    "end": "1270320"
  },
  {
    "text": "which you know would be this thread stack and so now i have all the context that i need to understand why am i running this code in g2 so mostly it's",
    "start": "1270320",
    "end": "1277760"
  },
  {
    "text": "business as usual and so we can preserve our async cross language async call stack even when we add",
    "start": "1277760",
    "end": "1284039"
  },
  {
    "text": "threads what about cooperative concurrency so you know with async cooperative concurrency means we only",
    "start": "1284039",
    "end": "1290559"
  },
  {
    "text": "switch at explicit yield points so like in a javascript setting we would say if i have an async function fu and it only",
    "start": "1290559",
    "end": "1296159"
  },
  {
    "text": "has one await i can only switch execution at that await points before and after that it's all executed",
    "start": "1296159",
    "end": "1301720"
  },
  {
    "text": "synchronously and there's some nice advantages to cooperative concurrency it's easier to understand the possible",
    "start": "1301720",
    "end": "1306960"
  },
  {
    "text": "interleings because they only happen where you see it in the code uh cooperative tasks can be smaller and switch quickly because we're not having",
    "start": "1306960",
    "end": "1312640"
  },
  {
    "text": "to save all the register state or involve the kernel or have interrupts and we can avoid uh the overhead of",
    "start": "1312640",
    "end": "1317919"
  },
  {
    "text": "locks and atomics that we would need in mult fully multi-threaded code but the disadvantages of course is that first of",
    "start": "1317919",
    "end": "1324000"
  },
  {
    "text": "all poorly behaved code can block other tasks and this is like why it's called cooperative concurrency and you know the",
    "start": "1324000",
    "end": "1329840"
  },
  {
    "text": "big one tasks can't execute in parallel we want kind of only one to be running at a time so of course this is what we",
    "start": "1329840",
    "end": "1336080"
  },
  {
    "text": "very much want to fix and address with threads so the idea with threads is you know we're we're using this shared",
    "start": "1336080",
    "end": "1341919"
  },
  {
    "text": "function added by shared everything threads and they are non-ooperative this is their big thing as they can interleaf",
    "start": "1341919",
    "end": "1347039"
  },
  {
    "text": "arbitrarily and this is what allows us to run them on multiple cores and get the parallelism that we want this also",
    "start": "1347039",
    "end": "1352880"
  },
  {
    "text": "means that we depend on the shared everything threads proposal which being is being standardized fully in core wism",
    "start": "1352880",
    "end": "1358320"
  },
  {
    "text": "we need to wait on browsers to fully decide they're happy with this and actually ship it and this is likely one or more years out just because of the",
    "start": "1358320",
    "end": "1364559"
  },
  {
    "text": "normal speed things work especially involving browsers so what if i want to run threads without",
    "start": "1364559",
    "end": "1371440"
  },
  {
    "text": "asyncify as soon as possible in particular without depending fully on shared everything threads or i",
    "start": "1371440",
    "end": "1378320"
  },
  {
    "text": "don't actually care about the parallelism and i'd rather get the benefits of cooperivity because like maybe it's a very short running task or",
    "start": "1378320",
    "end": "1384799"
  },
  {
    "text": "maybe i'm getting parallelism one level up from the serverless model or any of these reasons well if any of those apply",
    "start": "1384799",
    "end": "1390240"
  },
  {
    "text": "i might actually want cooperative threads and so the idea is to say we can allow threads to be either cooperative",
    "start": "1390240",
    "end": "1395840"
  },
  {
    "text": "or non-ooperative by saying on that spawn indirect built-in there's a optional",
    "start": "1395840",
    "end": "1401039"
  },
  {
    "text": "shared immediates and if you say it's shared you get a shared function it's non-ooperative you get the parallelism",
    "start": "1401039",
    "end": "1406159"
  },
  {
    "text": "and it depends on shared everything threads but if you don't say shared you get a normal function it's cooperative",
    "start": "1406159",
    "end": "1412559"
  },
  {
    "text": "and it only switches at explicit yield points just like you know async and that",
    "start": "1412559",
    "end": "1417679"
  },
  {
    "text": "means when we're waiting on io or when we have an explicit yield call now in the worst case if we have some background thread that's purely",
    "start": "1417679",
    "end": "1423360"
  },
  {
    "text": "computational that's not yielding anywhere we can inject yields at compile time either manually just strategically",
    "start": "1423360",
    "end": "1429679"
  },
  {
    "text": "at the points where we have this kind of longunning loop or in the worst possible case brutishly by just injecting them at",
    "start": "1429679",
    "end": "1435360"
  },
  {
    "text": "all loop headers and function prologs so one way or the other we can uh solve that problem so at a high level we with",
    "start": "1435360",
    "end": "1442000"
  },
  {
    "text": "the addition of threads are preserving the optionality of cooperative concurrency and lastly what about",
    "start": "1442000",
    "end": "1448720"
  },
  {
    "text": "colorless concurrency so with async if i take any arbitrary wit function say fu from that returns a",
    "start": "1448720",
    "end": "1455880"
  },
  {
    "text": "string when i implement that as a component i have always have two choices of ais an async one and a synchronous",
    "start": "1455880",
    "end": "1462159"
  },
  {
    "text": "one and by ai i'm referring to the core wazm signature used to implement this wit level function and so at a source",
    "start": "1462159",
    "end": "1468880"
  },
  {
    "text": "level language uh source programming uh level like in js this would mean an exporting an async function or exporting",
    "start": "1468880",
    "end": "1476880"
  },
  {
    "text": "a synchronous function so i have both choices of how to implement that wid function and then symmetrically i have",
    "start": "1476880",
    "end": "1482960"
  },
  {
    "text": "the same choices when i'm importing and calling this function i have both an async api and a synchronous api and so",
    "start": "1482960",
    "end": "1489679"
  },
  {
    "text": "from js perspective either i can call it and it returns a promise that i awaits or do other things with or it's just a",
    "start": "1489679",
    "end": "1495440"
  },
  {
    "text": "synchronous call and what colorlessness means is that all the call combinations",
    "start": "1495440",
    "end": "1500480"
  },
  {
    "text": "are possible the caller can choose independently of the colle and it just works now wait you might be thinking",
    "start": "1500480",
    "end": "1507039"
  },
  {
    "text": "what happens if the asynchronous code calls into the synchronous code and then it blocks wouldn't that block the asynchronous caller and doesn't that",
    "start": "1507039",
    "end": "1512559"
  },
  {
    "text": "defeat the whole point well no what we say is that we suspend the synchronous call and resume immediately the async",
    "start": "1512559",
    "end": "1519279"
  },
  {
    "text": "caller so it can keep going and doing other async stuff well that's not the whole story what happens now if",
    "start": "1519279",
    "end": "1524799"
  },
  {
    "text": "oblivious to this the synchronous caller calls back into the now suspended synchronous call instance and if we just",
    "start": "1524799",
    "end": "1531120"
  },
  {
    "text": "allowed it to run that would blow things up so that wouldn't work but what we can say is synchrony always has to worry",
    "start": "1531120",
    "end": "1536880"
  },
  {
    "text": "about back pressure i can call into a components and it can say hey i'm overloaded uh you're blocked that's",
    "start": "1536880",
    "end": "1542080"
  },
  {
    "text": "always fine to happen so we just say that happens in this case and so you know with this hard case handled you",
    "start": "1542080",
    "end": "1547840"
  },
  {
    "text": "know we've got the colorlessness now you might be remembering that i said earlier that there's this asynchronous keyword",
    "start": "1547840",
    "end": "1553279"
  },
  {
    "text": "on functions what's that about is that a color well no it's a hint it's totally different the hint tells the bindings",
    "start": "1553279",
    "end": "1559520"
  },
  {
    "text": "generator you have a choice between asynchronous and synchronous like what are you going to do are you going to emit them all synchronous by default or",
    "start": "1559520",
    "end": "1565919"
  },
  {
    "text": "all async or emit both to make the programmer decide what we can say with the async hints is that you're kind of",
    "start": "1565919",
    "end": "1571279"
  },
  {
    "text": "saying what should the default be because the author of this interface probably had a notion of oh this is a function that's likely to block so if",
    "start": "1571279",
    "end": "1577520"
  },
  {
    "text": "you've got async in your language you probably want to you know call it asynchronously so ultimately async is a hint that improves our default bindings",
    "start": "1577520",
    "end": "1583279"
  },
  {
    "text": "generation but otherwise all call combinations are possible so what happens to that when we add threads",
    "start": "1583279",
    "end": "1592000"
  },
  {
    "text": "so just as background with shared everything threads if i have a core module i can mark certain memories as",
    "start": "1592000",
    "end": "1597760"
  },
  {
    "text": "being shared which means this memory can be safe to be accessed from multiple threads so if i have an unshared",
    "start": "1597760",
    "end": "1602880"
  },
  {
    "text": "function it can access both my memories here m1 and m2 but if i have a shared function that means this function f2 can",
    "start": "1602880",
    "end": "1609440"
  },
  {
    "text": "be called from multiple threads so it's only safe to access the shared memory so we disallow access or the validation rules disallow access to m1 and then",
    "start": "1609440",
    "end": "1617520"
  },
  {
    "text": "transitively we need to ensure this so f_sub_2 cannot call f_sub_1 and therefore at a corem level we can",
    "start": "1617520",
    "end": "1623919"
  },
  {
    "text": "definitely say that sharedness is a color and that says you know shared functions can't call share unshared",
    "start": "1623919",
    "end": "1629799"
  },
  {
    "text": "functions so then the natural question is at the wit level do we just inherit the same constraint do we say there's a",
    "start": "1629799",
    "end": "1635520"
  },
  {
    "text": "shared color and width but i say ah foo has to be declared shared if it has to if it can be called by multiple threads",
    "start": "1635520",
    "end": "1641679"
  },
  {
    "text": "and that was our initial starting assumption it seems obvious enough but the idea is we can extend what we're",
    "start": "1641679",
    "end": "1647520"
  },
  {
    "text": "doing the technique where i just described for async where we say when shared code calls into unshared code we",
    "start": "1647520",
    "end": "1653840"
  },
  {
    "text": "lock the collies component instance and then if we call in again and the collies instance is already locked we just say",
    "start": "1653840",
    "end": "1660559"
  },
  {
    "text": "back pressure you know which we already have to handle so that kind of just falls out and the back back pressure is relieved when the collie component",
    "start": "1660559",
    "end": "1667039"
  },
  {
    "text": "instance is unlocked and this is not actually a new idea if you kind of swap threads for",
    "start": "1667039",
    "end": "1672559"
  },
  {
    "text": "wind32 event loops this is what happens in mscom which is like alive and kicking in the heart of all windows today uh",
    "start": "1672559",
    "end": "1678240"
  },
  {
    "text": "whenever you make a call from a multi-threaded department into a single threaded department so seems like should work so to answer our question no shared",
    "start": "1678240",
    "end": "1685919"
  },
  {
    "text": "would not be a color not even a hint and therefore we would just have four ai options for how to implement or call a",
    "start": "1685919",
    "end": "1692159"
  },
  {
    "text": "function combining shared or non-shared or sync and async and all 16 call",
    "start": "1692159",
    "end": "1698480"
  },
  {
    "text": "combinations then have to be defined to work and i think this can be well defined and so all the calls",
    "start": "1698480",
    "end": "1704360"
  },
  {
    "text": "compose and so if we zoom out the big picture here is that we're allowing uh giving component authors a spectrum of",
    "start": "1704360",
    "end": "1710880"
  },
  {
    "text": "concurrency to choose from when they implement their components from being on the one side fully synchronous like c call making you know blocking calls to",
    "start": "1710880",
    "end": "1717360"
  },
  {
    "text": "read and write to async where you know for i'm doing async js python c# or rust",
    "start": "1717360",
    "end": "1723360"
  },
  {
    "text": "or other languages and scooting over further i can be threaded for example c using p threads and if i want to really",
    "start": "1723360",
    "end": "1730000"
  },
  {
    "text": "max it out i can use async and threads in combination like i would do with for example async rust using tokyo or",
    "start": "1730000",
    "end": "1735600"
  },
  {
    "text": "async.js running in workers and the colorlessness here says that that the degree of concurrency is",
    "start": "1735600",
    "end": "1742640"
  },
  {
    "text": "kept in implementation detail of each component so i can make my choice independently of other components and",
    "start": "1742640",
    "end": "1747679"
  },
  {
    "text": "also change that choice over time which lets me adopt more of a pay as you go uh you know option where i'm trading off",
    "start": "1747679",
    "end": "1753760"
  },
  {
    "text": "simplicity for performance you know as the situation requires so in conclusion concurrency is",
    "start": "1753760",
    "end": "1760960"
  },
  {
    "text": "coming soon to the component model soon in 030 with async futures and streams",
    "start": "1760960",
    "end": "1766320"
  },
  {
    "text": "and then soon after in some you know soon as possible 03.x x minor release with cooperative threads that would give",
    "start": "1766320",
    "end": "1773039"
  },
  {
    "text": "us concurrency without using asyncify and then once browsers ship shared functions which we depend on could have",
    "start": "1773039",
    "end": "1778720"
  },
  {
    "text": "non-ooperative threads which finally give us that parallelism the addition of threads seeks to preserve the structuredness of",
    "start": "1778720",
    "end": "1785919"
  },
  {
    "text": "as the async calls nest call stack the option of cooperative concurrency and the colorlessness of",
    "start": "1785919",
    "end": "1792120"
  },
  {
    "text": "concurrency so if this is exciting to you and you want to get involved a great introductory material is the component",
    "start": "1792120",
    "end": "1797440"
  },
  {
    "text": "model.bicconlance.org book uh the spec is component model is in the component model repo in the web",
    "start": "1797440",
    "end": "1802720"
  },
  {
    "text": "assembly or and if you want to track or participate in the implementation it's there's a project tracker 16 the by",
    "start": "1802720",
    "end": "1809039"
  },
  {
    "text": "colon or so that's it for me thank [Applause]",
    "start": "1809039",
    "end": "1816410"
  },
  {
    "text": "you i think i might be at the end of time so not sure if we have time for questions but",
    "start": "1820039",
    "end": "1827480"
  },
  {
    "text": "um the question is more about the uh components rather than the threading and all that but it's more a curiosity um",
    "start": "1839360",
    "end": "1847520"
  },
  {
    "text": "when you actually share something between modules so that that's going to be like copying values between u memory",
    "start": "1847520",
    "end": "1855960"
  },
  {
    "text": "locations um does any runtime consider copy and write as a possibility to reduce the",
    "start": "1855960",
    "end": "1863120"
  },
  {
    "text": "memory usage and u improve lots of other stuff yeah that that's a really good question because copy and write's a cool",
    "start": "1863120",
    "end": "1869919"
  },
  {
    "text": "technique a downside is you have to do kind of sis calls to set it up and then as bytes get lazily copied that also",
    "start": "1869919",
    "end": "1876480"
  },
  {
    "text": "triggers you know page faults so it can have some overhead but it is an option especially sometimes it's used with how",
    "start": "1876480",
    "end": "1882159"
  },
  {
    "text": "to implement async data segments which map into a memory so you can like lazily clone the pages as they get dirty and so",
    "start": "1882159",
    "end": "1888480"
  },
  {
    "text": "depending on the concurrency of a machine because it can trigger a lot of kernel contention like that could be a",
    "start": "1888480",
    "end": "1894000"
  },
  {
    "text": "great implementation option often these value copies are really small and so there's not like a whole page that we'd",
    "start": "1894000",
    "end": "1899840"
  },
  {
    "text": "be able to map now for doing bulk data transfer this is the streams provide a",
    "start": "1899840",
    "end": "1905039"
  },
  {
    "text": "much better api that's a lot more kind of in the io ring style of completion based io and that can actually be the",
    "start": "1905039",
    "end": "1910480"
  },
  {
    "text": "more efficient way especially removing bytes bulk into and out of the host into ws of memory we can say the copy that happens into user space goes straight",
    "start": "1910480",
    "end": "1916960"
  },
  {
    "text": "into linear memory directly so it's as fast as you can be so there's streams offer a bunch of options there that you",
    "start": "1916960",
    "end": "1923200"
  },
  {
    "text": "know for bulk moving bytes but i think for normal values they might be too small to benefit from the copyright technique",
    "start": "1923200",
    "end": "1930080"
  },
  {
    "text": "all right looks good uh thank you",
    "start": "1938000",
    "end": "1943320"
  }
]